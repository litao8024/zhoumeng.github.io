{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\u6df1\u5ea6\u5b66\u4e60\u4e0eCV \u00b6 \u4e3b\u8981\u5185\u5bb9 : \u5728\u8be5\u8bfe\u7a0b\u4e2d\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecdtensorFlow,\u56fe\u50cf\u5206\u7c7b,\u68c0\u6d4b\u548c\u5206\u5272\u76f8\u5173\u7684\u5185\u5bb9","title":"\u6df1\u5ea6\u5b66\u4e60\u4e0eCV"},{"location":"#cv","text":"\u4e3b\u8981\u5185\u5bb9 : \u5728\u8be5\u8bfe\u7a0b\u4e2d\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecdtensorFlow,\u56fe\u50cf\u5206\u7c7b,\u68c0\u6d4b\u548c\u5206\u5272\u76f8\u5173\u7684\u5185\u5bb9","title":"\u6df1\u5ea6\u5b66\u4e60\u4e0eCV"},{"location":"deeplearning/","text":"\u56fe\u50cf\u5206\u7c7b1(Image Classification) \u00b6 \u4e86\u89e3\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4ee5\u53ca\u6311\u6218 \u77e5\u9053\u6700\u8fd1\u90bb\u5206\u7c7b\u5668\u7684\u7279\u70b9\u3001L1\u4e0eL2\u8ddd\u79bb\u7684\u7279\u70b9 \u77e5\u9053\u795e\u7ecf\u7f51\u7edc\u7684\u5b9a\u4e49 \u4e86\u89e3\u611f\u77e5\u673a\u4e0e\u795e\u7ecf\u7f51\u7edc\u7684\u8054\u7cfb \u4e86\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u53d1\u5c55\u5386\u53f2 \u77e5\u9053\u57fa\u4e8e\u56fe\u50cf\u50cf\u7d20\u6620\u5c04\u7684\u5206\u7c7b\u8bc4\u5206\u51fd\u6570 \u8bf4\u660eSVM\u548cSoftmax\u7ebf\u6027\u5206\u7c7b\u5668\u53ca\u5176\u635f\u5931\u51fd\u6570\u7279\u70b9\u539f\u7406 \u77e5\u9053\u6700\u4f18\u5316\u7684\u5b9a\u4e49 \u638c\u63e1\u795e\u7ecf\u7f51\u7edc\u7684\u94fe\u5f0f\u6cd5\u5219\u548c\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5 \u638c\u63e1\u8ba1\u7b97\u56fe\u7684\u5411\u91cf\u8ba1\u7b97\u65b9\u5f0f \u5e94\u7528\u5b8c\u6210\u5355\u795e\u7ecf\u5143\u795e\u7ecf\u7f51\u7edc \u77e5\u9053\u6d45\u5c42/\u6df1\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u524d\u5411\u548c\u53cd\u5411\u8ba1\u7b97\u8fc7\u7a0b \u638c\u63e1\u6fc0\u6d3b\u51fd\u6570\u7684\u4f7f\u7528\u4ee5\u53ca\u9009\u62e9 \u77e5\u9053\u795e\u7ecf\u7f51\u7edc\u7684\u53c2\u6570\u548c\u8d85\u53c2\u6570","title":"\u56fe\u50cf\u5206\u7c7b1(Image Classification)"},{"location":"deeplearning/#1image-classification","text":"\u4e86\u89e3\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4ee5\u53ca\u6311\u6218 \u77e5\u9053\u6700\u8fd1\u90bb\u5206\u7c7b\u5668\u7684\u7279\u70b9\u3001L1\u4e0eL2\u8ddd\u79bb\u7684\u7279\u70b9 \u77e5\u9053\u795e\u7ecf\u7f51\u7edc\u7684\u5b9a\u4e49 \u4e86\u89e3\u611f\u77e5\u673a\u4e0e\u795e\u7ecf\u7f51\u7edc\u7684\u8054\u7cfb \u4e86\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u53d1\u5c55\u5386\u53f2 \u77e5\u9053\u57fa\u4e8e\u56fe\u50cf\u50cf\u7d20\u6620\u5c04\u7684\u5206\u7c7b\u8bc4\u5206\u51fd\u6570 \u8bf4\u660eSVM\u548cSoftmax\u7ebf\u6027\u5206\u7c7b\u5668\u53ca\u5176\u635f\u5931\u51fd\u6570\u7279\u70b9\u539f\u7406 \u77e5\u9053\u6700\u4f18\u5316\u7684\u5b9a\u4e49 \u638c\u63e1\u795e\u7ecf\u7f51\u7edc\u7684\u94fe\u5f0f\u6cd5\u5219\u548c\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5 \u638c\u63e1\u8ba1\u7b97\u56fe\u7684\u5411\u91cf\u8ba1\u7b97\u65b9\u5f0f \u5e94\u7528\u5b8c\u6210\u5355\u795e\u7ecf\u5143\u795e\u7ecf\u7f51\u7edc \u77e5\u9053\u6d45\u5c42/\u6df1\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u524d\u5411\u548c\u53cd\u5411\u8ba1\u7b97\u8fc7\u7a0b \u638c\u63e1\u6fc0\u6d3b\u51fd\u6570\u7684\u4f7f\u7528\u4ee5\u53ca\u9009\u62e9 \u77e5\u9053\u795e\u7ecf\u7f51\u7edc\u7684\u53c2\u6570\u548c\u8d85\u53c2\u6570","title":"\u56fe\u50cf\u5206\u7c7b1(Image Classification)"},{"location":"deeplearning/section1/","text":"2.1 \u6df1\u5ea6\u5b66\u4e60\u7b80\u4ecb \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u6df1\u5ea6\u5b66\u4e60\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u5173\u7cfb \u77e5\u9053\u795e\u7ecf\u7f51\u7edc\u662f\u4ec0\u4e48 \u77e5\u9053\u5e38\u89c1\u7684\u6fc0\u6d3b\u51fd\u6570 \u77e5\u9053\u53c2\u6570\u521d\u59cb\u5316\u7684\u5e38\u89c1\u65b9\u6cd5 \u80fd\u591f\u5229\u7528tf.keras\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u6a21\u578b \u4e86\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u4f18\u7f3a\u70b9 1 \u6df1\u5ea6\u5b66\u4e60\u7b80\u4ecb \u00b6 \u5728\u4ecb\u7ecd\u6df1\u5ea6\u5b66\u4e60\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u770b\u4e0b\u8fd9\u5e45\u56fe\uff1a\u4eba\u5de5\u667a\u80fd>\u673a\u5668\u5b66\u4e60>\u6df1\u5ea6\u5b66\u4e60 \u6df1\u5ea6\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e00\u4e2a\u5b50\u96c6\uff0c\u4e5f\u5c31\u662f\u8bf4\u6df1\u5ea6\u5b66\u4e60\u662f\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u7684\u4e00\u79cd\u65b9\u6cd5\u3002\u4e0e\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u4e3b\u8981\u533a\u522b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7b97\u672f\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7279\u5f81\uff0c\u5e76\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e0d\u9700\u8981\u4eba\u5de5\uff0c\u800c\u662f\u4f9d\u8d56\u7b97\u6cd5\u81ea\u52a8\u63d0\u53d6\u7279\u5f81\uff0c\u8fd9\u4e5f\u662f\u6df1\u5ea6\u5b66\u4e60\u88ab\u770b\u505a\u9ed1\u76d2\u5b50\uff0c\u53ef\u89e3\u91ca\u6027\u5dee\u7684\u539f\u56e0\u3002 \u968f\u7740\u8ba1\u7b97\u673a\u8f6f\u786c\u4ef6\u7684\u98de\u901f\u53d1\u5c55\uff0c\u73b0\u9636\u6bb5\u901a\u8fc7**\u62e5\u6709\u4f17\u591a\u5c42\u6570\u795e\u7ecf\u7f51\u7edc(Neural Network)**\u6765\u6a21\u62df\u4eba\u8111\u6765\u89e3\u91ca\u6570\u636e\uff0c\u5305\u62ec\u56fe\u50cf\uff0c\u6587\u672c\uff0c\u97f3\u9891\u7b49\u5185\u5bb9\u3002\u76ee\u524d\u6765\u770b\u5e38\u7528\u7684\u795e\u7ecf\u7f51\u7edc\u5305\u62ec\uff1a \u5377\u79ef\u795e\u7ecf\u7f51\u7edc(Convolutional Neural Network) \u5faa\u73af\u795e\u7ecf\u7f51\u7edc(Recurrent Neural Network) \u751f\u6210\u5bf9\u6297\u7f51\u7edc(Generative Adversarial Networks) **\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60(Deep Reinforcement Learning)**\u7b49\u3002 2 \u4ec0\u4e48\u662f\u795e\u7ecf\u7f51\u7edc \u00b6 \u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff08 Artificial Neural Network\uff0c \u7b80\u5199\u4e3aANN\uff09\u4e5f\u7b80\u79f0\u4e3a\u795e\u7ecf\u7f51\u7edc\uff08NN\uff09 \uff0c\u662f\u4e00\u79cd\u6a21\u4eff\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u548c\u529f\u80fd\u7684 \u8ba1\u7b97\u6a21\u578b \u3002\u4eba\u8111\u53ef\u4ee5\u770b\u505a\u662f\u4e00\u4e2a\u751f\u7269\u795e\u7ecf\u7f51\u7edc\uff0c\u7531\u4f17\u591a\u7684\u795e\u7ecf\u5143\u8fde\u63a5\u800c\u6210\u3002\u5404\u4e2a\u795e\u7ecf\u5143\u4f20\u9012\u590d\u6742\u7684\u7535\u4fe1\u53f7\uff0c\u6811\u7a81\u63a5\u6536\u5230\u8f93\u5165\u4fe1\u53f7\uff0c\u7136\u540e\u5bf9\u4fe1\u53f7\u8fdb\u884c\u5904\u7406\uff0c\u901a\u8fc7\u8f74\u7a81\u8f93\u51fa\u4fe1\u53f7\u3002\u4e0b\u56fe\u662f\u751f\u7269\u795e\u7ecf\u5143\u793a\u610f\u56fe\uff1a \u90a3\u600e\u4e48\u6784\u5efa\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u795e\u7ecf\u5143\u5462\uff1f \u53d7\u751f\u7269\u795e\u7ecf\u5143\u7684\u542f\u53d1\uff0c\u4eba\u5de5\u795e\u7ecf\u5143\u63a5\u6536\u6765\u81ea\u5176\u4ed6\u795e\u7ecf\u5143\u6216\u5916\u90e8\u6e90\u7684\u8f93\u5165\uff0c\u6bcf\u4e2a\u8f93\u5165\u90fd\u6709\u4e00\u4e2a\u76f8\u5173\u7684\u6743\u503c(w)\uff0c\u5b83\u662f\u6839\u636e\u8be5\u8f93\u5165\u5bf9\u5f53\u524d\u795e\u7ecf\u5143\u7684\u91cd\u8981\u6027\u6765\u786e\u5b9a\u7684\uff0c\u5bf9\u8be5\u8f93\u5165\u52a0\u6743\u5e76\u4e0e\u5176\u4ed6\u8f93\u5165\u6c42\u548c\u540e\uff0c\u7ecf\u8fc7\u4e00\u4e2a\u6fc0\u6d3b\u51fd\u6570f\uff0c\u8ba1\u7b97\u5f97\u5230\u8be5\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u3002 \u90a3\u63a5\u4e0b\u6765\u6211\u4eec\u5c31\u5229\u7528\u795e\u7ecf\u5143\u6765\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\uff0c\u76f8\u90bb\u5c42\u4e4b\u95f4\u7684\u795e\u7ecf\u5143\u76f8\u4e92\u8fde\u63a5\uff0c\u5e76\u7ed9\u6bcf\u4e00\u4e2a\u8fde\u63a5\u5206\u914d\u4e00\u4e2a\u5f3a\u5ea6\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u795e\u7ecf\u7f51\u7edc\u4e2d\u4fe1\u606f\u53ea\u5411\u4e00\u4e2a\u65b9\u5411\u79fb\u52a8\uff0c\u5373\u4ece\u8f93\u5165\u8282\u70b9\u5411\u524d\u79fb\u52a8\uff0c\u901a\u8fc7\u9690\u85cf\u8282\u70b9\uff0c\u518d\u5411\u8f93\u51fa\u8282\u70b9\u79fb\u52a8\uff0c\u7f51\u7edc\u4e2d\u6ca1\u6709\u5faa\u73af\u6216\u8005\u73af\u3002\u5176\u4e2d\u7684\u57fa\u672c\u6784\u4ef6\u662f\uff1a \u8f93\u5165\u5c42 \uff1a\u5373\u8f93\u5165x\u7684\u90a3\u4e00\u5c42 \u8f93\u51fa\u5c42 \uff1a\u5373\u8f93\u51fay\u7684\u90a3\u4e00\u5c42 \u9690\u85cf\u5c42 \uff1a\u8f93\u5165\u5c42\u548c\u8f93\u51fa\u5c42\u4e4b\u95f4\u90fd\u662f\u9690\u85cf\u5c42 \u7279\u70b9\u662f\uff1a \u540c\u4e00\u5c42\u7684\u795e\u7ecf\u5143\u4e4b\u95f4\u6ca1\u6709\u8fde\u63a5\u3002 \u7b2cN\u5c42\u7684\u6bcf\u4e2a\u795e\u7ecf\u5143\u548c\u7b2cN-1\u5c42\u7684\u6240\u6709\u795e\u7ecf\u5143\u76f8\u8fde(\u8fd9\u5c31\u662ffull connected\u7684\u542b\u4e49)\uff0c\u7b2cN-1\u5c42\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u5c31\u662f\u7b2cN\u5c42\u795e\u7ecf\u5143\u7684\u8f93\u5165\u3002 \u6bcf\u4e2a\u8fde\u63a5\u90fd\u6709\u4e00\u4e2a\u6743\u503c\u3002 3 \u795e\u7ecf\u5143\u662f\u5982\u4f55\u5de5\u4f5c\u7684\uff1f \u00b6 \u4eba\u5de5\u795e\u7ecf\u5143\u63a5\u6536\u5230\u4e00\u4e2a\u6216\u591a\u4e2a\u8f93\u5165\uff0c\u5bf9\u4ed6\u4eec\u8fdb\u884c\u52a0\u6743\u5e76\u76f8\u52a0\uff0c\u603b\u548c\u901a\u8fc7\u4e00\u4e2a\u975e\u7ebf\u6027\u51fd\u6570\u4ea7\u751f\u8f93\u51fa\u3002 \u6240\u6709\u7684\u8f93\u5165xi\uff0c\u4e0e\u76f8\u5e94\u7684\u6743\u91cdwi\u76f8\u4e58\u5e76\u6c42\u548c\uff1a \u5c06\u6c42\u548c\u7ed3\u679c\u9001\u5165\u5230\u6fc0\u6d3b\u51fd\u6570\u4e2d\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u8f93\u51fa\u7ed3\u679c\uff1a 3.1 \u6fc0\u6d3b\u51fd\u6570 \u00b6 \u5728\u795e\u7ecf\u5143\u4e2d\u5f15\u5165\u4e86\u6fc0\u6d3b\u51fd\u6570\uff0c\u5b83\u7684\u672c\u8d28\u662f\u5411\u795e\u7ecf\u7f51\u7edc\u4e2d\u5f15\u5165\u975e\u7ebf\u6027\u56e0\u7d20\u7684\uff0c\u901a\u8fc7\u6fc0\u6d3b\u51fd\u6570\uff0c\u795e\u7ecf\u7f51\u7edc\u5c31\u53ef\u4ee5\u62df\u5408\u5404\u79cd\u66f2\u7ebf\u3002\u5982\u679c\u4e0d\u7528\u6fc0\u6d3b\u51fd\u6570\uff0c\u6bcf\u4e00\u5c42\u8f93\u51fa\u90fd\u662f\u4e0a\u5c42\u8f93\u5165\u7684\u7ebf\u6027\u51fd\u6570\uff0c\u65e0\u8bba\u795e\u7ecf\u7f51\u7edc\u6709\u591a\u5c11\u5c42\uff0c\u8f93\u51fa\u90fd\u662f\u8f93\u5165\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u5f15\u5165\u975e\u7ebf\u6027\u51fd\u6570\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\uff0c\u90a3\u8f93\u51fa\u4e0d\u518d\u662f\u8f93\u5165\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u53ef\u4ee5\u903c\u8fd1\u4efb\u610f\u51fd\u6570\u3002\u5e38\u7528\u7684\u6fc0\u6d3b\u51fd\u6570\u6709\uff1a 3.1.1.Sigmoid/logistics\u51fd\u6570 \u00b6 \u6570\u5b66\u8868\u8fbe\u5f0f\u4e3a\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a sigmoid \u5728\u5b9a\u4e49\u57df\u5185\u5904\u5904\u53ef\u5bfc\uff0c\u4e14\u4e24\u4fa7\u5bfc\u6570\u9010\u6e10\u8d8b\u8fd1\u4e8e0\u3002\u5982\u679cX\u7684\u503c\u5f88\u5927\u6216\u8005\u5f88\u5c0f\u7684\u65f6\u5019\uff0c\u90a3\u4e48\u51fd\u6570\u7684\u68af\u5ea6\uff08\u51fd\u6570\u7684\u659c\u7387\uff09\u4f1a\u975e\u5e38\u5c0f\uff0c\u5728\u53cd\u5411\u4f20\u64ad\u7684\u8fc7\u7a0b\u4e2d\uff0c\u5bfc\u81f4\u4e86\u5411\u4f4e\u5c42\u4f20\u9012\u7684\u68af\u5ea6\u4e5f\u53d8\u5f97\u975e\u5e38\u5c0f\u3002\u6b64\u65f6\uff0c\u7f51\u7edc\u53c2\u6570\u5f88\u96be\u5f97\u5230\u6709\u6548\u8bad\u7ec3\u3002\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\u68af\u5ea6\u6d88\u5931\u3002\u4e00\u822c\u6765\u8bf4\uff0c sigmoid \u7f51\u7edc\u5728 5 \u5c42\u4e4b\u5185\u5c31\u4f1a\u4ea7\u751f\u68af\u5ea6\u6d88\u5931\u73b0\u8c61\u3002\u800c\u4e14\uff0c\u8be5\u6fc0\u6d3b\u51fd\u6570\u5e76\u4e0d\u662f\u4ee50\u4e3a\u4e2d\u5fc3\u7684\uff0c\u6240\u4ee5\u5728\u5b9e\u8df5\u4e2d\u8fd9\u79cd\u6fc0\u6d3b\u51fd\u6570\u4f7f\u7528\u7684\u5f88\u5c11\u3002sigmoid\u51fd\u6570\u4e00\u822c\u53ea\u7528\u4e8e\u4e8c\u5206\u7c7b\u7684\u8f93\u51fa\u5c42\u3002 \u5b9e\u73b0\u65b9\u6cd5\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u5b9a\u4e49x\u7684\u53d6\u503c\u8303\u56f4 x = np . linspace ( - 10 , 10 , 100 ) # \u76f4\u63a5\u4f7f\u7528tensorflow\u5b9e\u73b0 y = tf . nn . sigmoid ( x ) # \u7ed8\u56fe plt . plot ( x , y ) plt . grid () \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a 3.1.2.tanh(\u53cc\u66f2\u6b63\u5207\u66f2\u7ebf) \u00b6 \u6570\u5b66\u8868\u8fbe\u5f0f\u5982\u4e0b\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a tanh\u4e5f\u662f\u4e00\u79cd\u975e\u5e38\u5e38\u89c1\u7684\u6fc0\u6d3b\u51fd\u6570\u3002\u4e0esigmoid\u76f8\u6bd4\uff0c\u5b83\u662f\u4ee50\u4e3a\u4e2d\u5fc3\u7684\uff0c\u4f7f\u5f97\u5176\u6536\u655b\u901f\u5ea6\u8981\u6bd4sigmoid\u5feb\uff0c\u51cf\u5c11\u8fed\u4ee3\u6b21\u6570\u3002\u7136\u800c\uff0c\u4ece\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0ctanh\u4e24\u4fa7\u7684\u5bfc\u6570\u4e5f\u4e3a0\uff0c\u540c\u6837\u4f1a\u9020\u6210\u68af\u5ea6\u6d88\u5931\u3002 \u82e5\u4f7f\u7528\u65f6\u53ef\u5728\u9690\u85cf\u5c42\u4f7f\u7528tanh\u51fd\u6570\uff0c\u5728\u8f93\u51fa\u5c42\u4f7f\u7528sigmoid\u51fd\u6570\u3002 \u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u5b9a\u4e49x\u7684\u53d6\u503c\u8303\u56f4 x = np . linspace ( - 10 , 10 , 100 ) # \u76f4\u63a5\u4f7f\u7528tensorflow\u5b9e\u73b0 y = tf . nn . tanh ( x ) # \u7ed8\u56fe plt . plot ( x , y ) plt . grid () \u7ed8\u5236\u7ed3\u679c\u4e3a\uff1a 3.1.3.RELU \u00b6 \u6570\u5b66\u8868\u8fbe\u5f0f\u4e3a\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a ReLU\u662f\u76ee\u524d\u6700\u5e38\u7528\u7684\u6fc0\u6d3b\u51fd\u6570\u3002 \u4ece\u56fe\u4e2d\u53ef\u4ee5\u770b\u5230\uff0c\u5f53x<0\u65f6\uff0cReLU\u5bfc\u6570\u4e3a0\uff0c\u800c\u5f53x>0\u65f6\uff0c\u5219\u4e0d\u5b58\u5728\u9971\u548c\u95ee\u9898\u3002\u6240\u4ee5\uff0cReLU \u80fd\u591f\u5728x>0\u65f6\u4fdd\u6301\u68af\u5ea6\u4e0d\u8870\u51cf\uff0c\u4ece\u800c\u7f13\u89e3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002\u7136\u800c\uff0c\u968f\u7740\u8bad\u7ec3\u7684\u63a8\u8fdb\uff0c\u90e8\u5206\u8f93\u5165\u4f1a\u843d\u5165\u5c0f\u4e8e0\u533a\u57df\uff0c\u5bfc\u81f4\u5bf9\u5e94\u6743\u91cd\u65e0\u6cd5\u66f4\u65b0\u3002\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\u201c\u795e\u7ecf\u5143\u6b7b\u4ea1\u201d\u3002 \u4e0esigmoid\u76f8\u6bd4\uff0cRELU\u7684\u4f18\u52bf\u662f\uff1a \u91c7\u7528sigmoid\u51fd\u6570\uff0c\u8ba1\u7b97\u91cf\u5927\uff08\u6307\u6570\u8fd0\u7b97\uff09\uff0c\u53cd\u5411\u4f20\u64ad\u6c42\u8bef\u5dee\u68af\u5ea6\u65f6\uff0c\u6c42\u5bfc\u6d89\u53ca\u9664\u6cd5\uff0c\u8ba1\u7b97\u91cf\u76f8\u5bf9\u5927\uff0c\u800c\u91c7\u7528Relu\u6fc0\u6d3b\u51fd\u6570\uff0c\u6574\u4e2a\u8fc7\u7a0b\u7684\u8ba1\u7b97\u91cf\u8282\u7701\u5f88\u591a\u3002 sigmoid\u51fd\u6570\u53cd\u5411\u4f20\u64ad\u65f6\uff0c\u5f88\u5bb9\u6613\u5c31\u4f1a\u51fa\u73b0\u68af\u5ea6\u6d88\u5931\u7684\u60c5\u51b5\uff0c\u4ece\u800c\u65e0\u6cd5\u5b8c\u6210\u6df1\u5c42\u7f51\u7edc\u7684\u8bad\u7ec3\u3002 Relu\u4f1a\u4f7f\u4e00\u90e8\u5206\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u4e3a0\uff0c\u8fd9\u6837\u5c31\u9020\u6210\u4e86\u7f51\u7edc\u7684\u7a00\u758f\u6027\uff0c\u5e76\u4e14\u51cf\u5c11\u4e86\u53c2\u6570\u7684\u76f8\u4e92\u4f9d\u5b58\u5173\u7cfb\uff0c\u7f13\u89e3\u4e86\u8fc7\u62df\u5408\u95ee\u9898\u7684\u53d1\u751f\u3002 \u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u5b9a\u4e49x\u7684\u53d6\u503c\u8303\u56f4 x = np . linspace ( - 10 , 10 , 100 ) # \u76f4\u63a5\u4f7f\u7528tensorflow\u5b9e\u73b0 y = tf . nn . relu ( x ) # \u7ed8\u56fe plt . plot ( x , y ) plt . grid () \u7ed8\u5236\u7ed3\u679c\u4e3a\uff1a 3.1.4.LeakReLu \u00b6 \u8be5\u6fc0\u6d3b\u51fd\u6570\u662f\u5bf9RELU\u7684\u6539\u8fdb\uff0c\u6570\u5b66\u8868\u8fbe\u5f0f\u4e3a\uff1a \u66f2\u7ebf\u5982\u4e0b\u6240\u793a\uff1a \u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u5b9a\u4e49x\u7684\u53d6\u503c\u8303\u56f4 x = np . linspace ( - 10 , 10 , 100 ) # \u76f4\u63a5\u4f7f\u7528tensorflow\u5b9e\u73b0 y = tf . nn . leaky_relu ( x ) # \u7ed8\u56fe plt . plot ( x , y ) plt . grid () 3.1.5. SoftMax \u00b6 softmax\u7528\u4e8e\u591a\u5206\u7c7b\u8fc7\u7a0b\u4e2d\uff0c\u5b83\u662f\u4e8c\u5206\u7c7b\u51fd\u6570sigmoid\u5728\u591a\u5206\u7c7b\u4e0a\u7684\u63a8\u5e7f\uff0c\u76ee\u7684\u662f\u5c06\u591a\u5206\u7c7b\u7684\u7ed3\u679c\u4ee5\u6982\u7387\u7684\u5f62\u5f0f\u5c55\u73b0\u51fa\u6765\u3002 \u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4f7f\u7528\u65b9\u6cd5\uff1a softmax\u76f4\u767d\u6765\u8bf4\u5c31\u662f\u5c06\u7f51\u7edc\u8f93\u51fa\u7684logits\u901a\u8fc7softmax\u51fd\u6570\uff0c\u5c31\u6620\u5c04\u6210\u4e3a(0,1)\u7684\u503c\uff0c\u800c\u8fd9\u4e9b\u503c\u7684\u7d2f\u548c\u4e3a1\uff08\u6ee1\u8db3\u6982\u7387\u7684\u6027\u8d28\uff09\uff0c\u90a3\u4e48\u6211\u4eec\u5c06\u5b83\u7406\u89e3\u6210\u6982\u7387\uff0c\u9009\u53d6\u6982\u7387\u6700\u5927\uff08\u4e5f\u5c31\u662f\u503c\u5bf9\u5e94\u6700\u5927\u7684\uff09\u63a5\u70b9\uff0c\u4f5c\u4e3a\u6211\u4eec\u7684\u9884\u6d4b\u76ee\u6807\u7c7b\u522b\u3002 \u5b9e\u73b0\uff0c\u4ee5\u4e0a\u56fe\u4e2d\u6570\u5b579\u7684\u5206\u7c7b\u7ed3\u679c\u4e3a\u4f8b\u7ed9\u5927\u5bb6\u8fdb\u884c\u6f14\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u6570\u5b57\u4e2d\u7684score x = tf . constant ([ 0.2 , 0.02 , 0.15 , 1.3 , 0.5 , 0.06 , 1.1 , 0.05 , 3.75 ]) # \u5c06\u5176\u9001\u5165\u5230softmax\u4e2d\u8ba1\u7b97\u5206\u7c7b\u7ed3\u679c y = tf . nn . softmax ( x ) # \u5c06\u7ed3\u679c\u8fdb\u884c\u6253\u5370 print ( y ) \u5206\u7c7b\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [ 0.02167152 0.01810157 0.02061459 0.06510484 0.02925349 0.01884031 0.05330333 0.01865285 0.75445753 ], shape = ( 9 ,), dtype = float32 ) 3.1.6. \u5176\u4ed6\u6fc0\u6d3b\u51fd\u6570 \u00b6 3.1.7.\u5982\u4f55\u9009\u62e9\u6fc0\u6d3b\u51fd\u6570 \u00b6 \u9690\u85cf\u5c42 \u00b6 \u4f18\u5148\u9009\u62e9RELU\u6fc0\u6d3b\u51fd\u6570 \u5982\u679cReLu\u6548\u679c\u4e0d\u597d\uff0c\u90a3\u4e48\u5c1d\u8bd5\u5176\u4ed6\u6fc0\u6d3b\uff0c\u5982Leaky ReLu\u7b49\u3002 \u5982\u679c\u4f60\u4f7f\u7528\u4e86Relu\uff0c \u9700\u8981\u6ce8\u610f\u4e00\u4e0bDead Relu\u95ee\u9898\uff0c \u907f\u514d\u51fa\u73b0\u5927\u7684\u68af\u5ea6\u4ece\u800c\u5bfc\u81f4\u8fc7\u591a\u7684\u795e\u7ecf\u5143\u6b7b\u4ea1\u3002 \u4e0d\u8981\u4f7f\u7528sigmoid\u6fc0\u6d3b\u51fd\u6570\uff0c\u53ef\u4ee5\u5c1d\u8bd5\u4f7f\u7528tanh\u6fc0\u6d3b\u51fd\u6570 \u8f93\u51fa\u5c42 \u00b6 \u4e8c\u5206\u7c7b\u95ee\u9898\u9009\u62e9sigmoid\u6fc0\u6d3b\u51fd\u6570 \u591a\u5206\u7c7b\u95ee\u9898\u9009\u62e9softmax\u6fc0\u6d3b\u51fd\u6570 \u56de\u5f52\u95ee\u9898\u9009\u62e9identity\u6fc0\u6d3b\u51fd\u6570 3.2 \u53c2\u6570\u521d\u59cb\u5316 \u00b6 \u5bf9\u4e8e\u67d0\u4e00\u4e2a\u795e\u7ecf\u5143\u6765\u8bf4\uff0c\u9700\u8981\u521d\u59cb\u5316\u7684\u53c2\u6570\u6709\u4e24\u7c7b\uff1a\u4e00\u7c7b\u662f\u6743\u91cdW\uff0c\u8fd8\u6709\u4e00\u7c7b\u662f\u504f\u7f6eb,\u504f\u7f6eb\u521d\u59cb\u5316\u4e3a0\u5373\u53ef\u3002\u800c\u6743\u91cdW\u7684\u521d\u59cb\u5316\u6bd4\u8f83\u91cd\u8981\uff0c\u6211\u4eec\u7740\u91cd\u6765\u4ecb\u7ecd\u5e38\u89c1\u7684\u521d\u59cb\u5316\u65b9\u5f0f\u3002 3.2.1.\u968f\u673a\u521d\u59cb\u5316 \u00b6 \u968f\u673a\u521d\u59cb\u5316\u4ece\u5747\u503c\u4e3a0\uff0c\u6807\u51c6\u5dee\u662f1\u7684\u9ad8\u65af\u5206\u5e03\u4e2d\u53d6\u6837\uff0c\u4f7f\u7528\u4e00\u4e9b\u5f88\u5c0f\u7684\u503c\u5bf9\u53c2\u6570W\u8fdb\u884c\u521d\u59cb\u5316\u3002 3.2.2.\u6807\u51c6\u521d\u59cb\u5316 \u00b6 \u6743\u91cd\u53c2\u6570\u521d\u59cb\u5316\u4ece\u533a\u95f4\u5747\u5300\u968f\u673a\u53d6\u503c\u3002\u5373\u5728(-1/\u221ad,1/\u221ad)\u5747\u5300\u5206\u5e03\u4e2d\u751f\u6210\u5f53\u524d\u795e\u7ecf\u5143\u7684\u6743\u91cd\uff0c\u5176\u4e2dd\u4e3a\u6bcf\u4e2a\u795e\u7ecf\u5143\u7684\u8f93\u5165\u6570\u91cf\u3002 3.2.3.Xavier\u521d\u59cb\u5316 \u00b6 \u8be5\u65b9\u6cd5\u7684\u57fa\u672c\u601d\u60f3\u662f\u5404\u5c42\u7684\u6fc0\u6d3b\u503c\u548c\u68af\u5ea6\u7684\u65b9\u5dee\u5728\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u4e00\u81f4\uff0c\u4e5f\u53eb\u505aGlorot\u521d\u59cb\u5316\u3002\u5728tf.keras\u4e2d\u5b9e\u73b0\u7684\u65b9\u6cd5\u6709\u4e24\u79cd\uff1a \u6b63\u6001\u5316Xavier\u521d\u59cb\u5316\uff1a Glorot \u6b63\u6001\u5206\u5e03\u521d\u59cb\u5316\u5668\uff0c\u4e5f\u79f0\u4e3a Xavier \u6b63\u6001\u5206\u5e03\u521d\u59cb\u5316\u5668\u3002\u5b83\u4ece\u4ee5 0 \u4e3a\u4e2d\u5fc3\uff0c\u6807\u51c6\u5dee\u4e3a stddev = sqrt(2 / (fan_in + fan_out)) \u7684\u6b63\u6001\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c\uff0c \u5176\u4e2d fan_in \u662f\u8f93\u5165\u795e\u7ecf\u5143\u7684\u4e2a\u6570\uff0c fan_out \u662f\u8f93\u51fa\u7684\u795e\u7ecf\u5143\u4e2a\u6570\u3002 \u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u8fdb\u884c\u5b9e\u4f8b\u5316 initializer = tf . keras . initializers . glorot_normal () # \u91c7\u6837\u5f97\u5230\u6743\u91cd\u503c values = initializer ( shape = ( 9 , 1 )) # \u6253\u5370\u7ed3\u679c print ( values ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ 0.71967787 ] [ 0.56188506 ] [ - 0.7327265 ] [ - 0.05581591 ] [ - 0.05519835 ] [ 0.11283273 ] [ 0.8377778 ] [ 0.5832906 ] [ 0.10221979 ]], shape = ( 9 , 1 ), dtype = float32 ) \u6807\u51c6\u5316Xavier\u521d\u59cb\u5316 Glorot \u5747\u5300\u5206\u5e03\u521d\u59cb\u5316\u5668\uff0c\u4e5f\u79f0\u4e3a Xavier \u5747\u5300\u5206\u5e03\u521d\u59cb\u5316\u5668\u3002\u5b83\u4ece [-limit\uff0climit] \u4e2d\u7684\u5747\u5300\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c\uff0c \u5176\u4e2d limit \u662f sqrt(6 / (fan_in + fan_out)) \uff0c \u5176\u4e2d fan_in \u662f\u8f93\u5165\u795e\u7ecf\u5143\u7684\u4e2a\u6570\uff0c fan_out \u662f\u8f93\u51fa\u7684\u795e\u7ecf\u5143\u4e2a\u6570\u3002 # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u8fdb\u884c\u5b9e\u4f8b\u5316 initializer = tf . keras . initializers . glorot_uniform () # \u91c7\u6837\u5f97\u5230\u6743\u91cd\u503c values = initializer ( shape = ( 9 , 1 )) # \u6253\u5370\u7ed3\u679c print ( values ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ - 0.59119344 ] [ 0.06239486 ] [ 0.65161395 ] [ - 0.30347362 ] [ - 0.5407096 ] [ 0.35138106 ] [ 0.41150713 ] [ 0.32143414 ] [ - 0.57354397 ]], shape = ( 9 , 1 ), dtype = float32 ) 3.2.4.He\u521d\u59cb\u5316 \u00b6 he\u521d\u59cb\u5316\uff0c\u4e5f\u79f0\u4e3aKaiming\u521d\u59cb\u5316\uff0c\u51fa\u81ea\u5927\u795e\u4f55\u607a\u660e\u4e4b\u624b\uff0c\u5b83\u7684\u57fa\u672c\u601d\u60f3\u662f\u6b63\u5411\u4f20\u64ad\u65f6\uff0c\u6fc0\u6d3b\u503c\u7684\u65b9\u5dee\u4fdd\u6301\u4e0d\u53d8\uff1b\u53cd\u5411\u4f20\u64ad\u65f6\uff0c\u5173\u4e8e\u72b6\u6001\u503c\u7684\u68af\u5ea6\u7684\u65b9\u5dee\u4fdd\u6301\u4e0d\u53d8\u3002\u5728tf.keras\u4e2d\u4e5f\u6709\u4e24\u79cd\uff1a \u6b63\u6001\u5316\u7684he\u521d\u59cb\u5316 He \u6b63\u6001\u5206\u5e03\u521d\u59cb\u5316\u662f\u4ee5 0 \u4e3a\u4e2d\u5fc3\uff0c\u6807\u51c6\u5dee\u4e3a stddev = sqrt(2 / fan_in) \u7684\u622a\u65ad\u6b63\u6001\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c\uff0c \u5176\u4e2d fan_in \u662f\u8f93\u5165\u795e\u7ecf\u5143\u7684\u4e2a\u6570\uff0c\u5728tf.keras\u4e2d\u7684\u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u8fdb\u884c\u5b9e\u4f8b\u5316 initializer = tf . keras . initializers . he_normal () # \u91c7\u6837\u5f97\u5230\u6743\u91cd\u503c values = initializer ( shape = ( 9 , 1 )) # \u6253\u5370\u7ed3\u679c print ( values ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ - 0.1488019 ] [ - 0.12102155 ] [ - 0.0163257 ] [ - 0.36920077 ] [ - 0.89464396 ] [ - 0.28749225 ] [ - 0.5467023 ] [ 0.27031776 ] [ - 0.1831588 ]], shape = ( 9 , 1 ), dtype = float32 ) \u6807\u51c6\u5316\u7684he\u521d\u59cb\u5316 He \u5747\u5300\u65b9\u5dee\u7f29\u653e\u521d\u59cb\u5316\u5668\u3002\u5b83\u4ece [-limit\uff0climit] \u4e2d\u7684\u5747\u5300\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c\uff0c \u5176\u4e2d limit \u662f sqrt(6 / fan_in) \uff0c \u5176\u4e2d fan_in \u8f93\u5165\u795e\u7ecf\u5143\u7684\u4e2a\u6570\u3002\u5b9e\u73b0\u4e3a\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u8fdb\u884c\u5b9e\u4f8b\u5316 initializer = tf . keras . initializers . he_uniform () # \u91c7\u6837\u5f97\u5230\u6743\u91cd\u503c values = initializer ( shape = ( 9 , 1 )) # \u6253\u5370\u7ed3\u679c print ( values ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ 0.80033934 ] [ - 0.18773115 ] [ 0.6726284 ] [ - 0.23672342 ] [ - 0.6323329 ] [ 0.6048162 ] [ 0.1637358 ] [ 0.60797024 ] [ - 0.46316862 ]], shape = ( 9 , 1 ), dtype = float32 ) 4 \u795e\u7ecf\u7f51\u7edc\u7684\u642d\u5efa \u00b6 \u63a5\u4e0b\u6765\u6211\u4eec\u6765\u6784\u5efa\u5982\u4e0b\u56fe\u6240\u793a\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff1a tf.Keras\u4e2d\u6784\u5efa\u6a21\u6709\u4e24\u79cd\u65b9\u5f0f\uff0c\u4e00\u79cd\u662f\u901a\u8fc7Sequential\u6784\u5efa\uff0c\u4e00\u79cd\u662f\u901a\u8fc7Model\u7c7b\u6784\u5efa\u3002\u524d\u8005\u662f\u6309\u4e00\u5b9a\u7684\u987a\u5e8f\u5bf9\u5c42\u8fdb\u884c\u5806\u53e0\uff0c\u800c\u540e\u8005\u53ef\u4ee5\u7528\u6765\u6784\u5efa\u8f83\u590d\u6742\u7684\u7f51\u7edc\u6a21\u578b\u3002\u9996\u5148\u6211\u4eec\u4ecb\u7ecd\u4e0b\u7528\u6765\u6784\u5efa\u7f51\u7edc\u7684\u5168\u8fde\u63a5\u5c42\uff1a tf . keras . layers . Dense ( units , activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' ) \u4e3b\u8981\u53c2\u6570\uff1a units: \u5f53\u524d\u5c42\u4e2d\u5305\u542b\u7684\u795e\u7ecf\u5143\u4e2a\u6570 Activation: \u6fc0\u6d3b\u51fd\u6570\uff0crelu,sigmoid\u7b49 use_bias: \u662f\u5426\u4f7f\u7528\u504f\u7f6e\uff0c\u9ed8\u8ba4\u4f7f\u7528\u504f\u7f6e Kernel_initializer: \u6743\u91cd\u7684\u521d\u59cb\u5316\u65b9\u5f0f\uff0c\u9ed8\u8ba4\u662fXavier\u521d\u59cb\u5316 bias_initializer: \u504f\u7f6e\u7684\u521d\u59cb\u5316\u65b9\u5f0f\uff0c\u9ed8\u8ba4\u4e3a0 4.1\u901a\u8fc7Sequential\u6784\u5efa \u00b6 Sequential() \u63d0\u4f9b\u4e00\u4e2a\u5c42\u7684\u5217\u8868\uff0c\u5c31\u80fd\u5feb\u901f\u5730\u5efa\u7acb\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305 import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers # \u5b9a\u4e49\u4e00\u4e2aSequential\u6a21\u578b\uff0c\u5305\u542b3\u5c42 model = keras . Sequential ( [ # \u7b2c\u4e00\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal layers . Dense ( 3 , activation = \"relu\" , kernel_initializer = \"he_normal\" , name = \"layer1\" , input_shape = ( 3 ,)), # \u7b2c\u4e8c\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal layers . Dense ( 2 , activation = \"relu\" , kernel_initializer = \"he_normal\" , name = \"layer2\" ), # \u7b2c\u4e09\u5c42\uff08\u8f93\u51fa\u5c42\uff09\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3asigmoid,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal layers . Dense ( 2 , activation = \"sigmoid\" , kernel_initializer = \"he_normal\" , name = \"layer3\" ), ], name = \"my_Sequential\" ) \u63a5\u4e0b\u6765\u6211\u4eec\u4f7f\u7528\uff1a # \u5c55\u793a\u6a21\u578b\u7ed3\u679c model . summary () \u5982\u4e0b\u6240\u793a\uff1a Model : \"my_Sequential\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= layer1 ( Dense ) ( None , 3 ) 12 _________________________________________________________________ layer2 ( Dense ) ( None , 2 ) 8 _________________________________________________________________ layer3 ( Dense ) ( None , 2 ) 6 ================================================================= Total params : 26 Trainable params : 26 Non - trainable params : 0 _________________________________________________________________ \u901a\u8fc7\u8fd9\u79cdsequential\u7684\u65b9\u5f0f\u53ea\u80fd\u6784\u5efa\u7b80\u5355\u7684\u5e8f\u5217\u6a21\u578b\uff0c\u8f83\u590d\u6742\u7684\u6a21\u578b\u6ca1\u6709\u529e\u6cd5\u5b9e\u73b0\u3002 \u3010\u6269\u5c55\ud83d\udcda\uff1a\u53c2\u6570\u91cf\u8ba1\u7b97\u3011 \u4ee5\u7b2c\u4e00\u4e2a\u9690\u5c42\u4e3a\u4f8b\uff1a\u8be5\u9690\u5c42\u67093\u4e2a\u795e\u7ecf\u5143\uff0c\u6bcf\u4e2a\u795e\u7ecf\u5143\u7684\u53c2\u6570\u4e3a\uff1a4\u4e2a\uff08w1,w2,w3,b1\uff09\uff0c\u6240\u4ee5\u4e00\u5171\u75283x4=12\u4e2a\u53c2\u6570\u3002 4.2 \u5229\u7528function API\u6784\u5efa \u00b6 tf.keras \u63d0\u4f9b\u4e86 Functional API\uff0c\u5efa\u7acb\u66f4\u4e3a\u590d\u6742\u7684\u6a21\u578b\uff0c\u4f7f\u7528\u65b9\u6cd5\u662f\u5c06\u5c42\u4f5c\u4e3a\u53ef\u8c03\u7528\u7684\u5bf9\u8c61\u5e76\u8fd4\u56de\u5f20\u91cf\uff0c\u5e76\u5c06\u8f93\u5165\u5411\u91cf\u548c\u8f93\u51fa\u5411\u91cf\u63d0\u4f9b\u7ed9 tf.keras.Model \u7684 inputs \u548c outputs \u53c2\u6570\uff0c\u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u5b9a\u4e49\u6a21\u578b\u7684\u8f93\u5165 inputs = tf . keras . Input ( shape = ( 3 ,), name = \"input\" ) # \u7b2c\u4e00\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu\uff0c\u5176\u4ed6\u9ed8\u8ba4 x = tf . keras . layers . Dense ( 3 , activation = \"relu\" , name = \"layer1\" )( inputs ) # \u7b2c\u4e8c\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu\uff0c\u5176\u4ed6\u9ed8\u8ba4 x = tf . keras . layers . Dense ( 2 , activation = \"relu\" , name = \"layer2\" )( x ) # \u7b2c\u4e09\u5c42\uff08\u8f93\u51fa\u5c42\uff09\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3asigmoid outputs = tf . keras . layers . Dense ( 2 , activation = \"sigmoid\" , name = \"layer3\" )( x ) # \u4f7f\u7528Model\u6765\u521b\u5efa\u6a21\u578b\uff0c\u6307\u660e\u8f93\u5165\u548c\u8f93\u51fa model = tf . keras . Model ( inputs = inputs , outputs = outputs , name = \"my_model\" ) \u540c\u6837\u901a\u8fc7\uff1a # \u5c55\u793a\u6a21\u578b\u7ed3\u679c model . summary () \u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a Model : \"my_model\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= input ( InputLayer ) [( None , 3 )] 0 _________________________________________________________________ layer1 ( Dense ) ( None , 3 ) 12 _________________________________________________________________ layer2 ( Dense ) ( None , 2 ) 8 _________________________________________________________________ layer3 ( Dense ) ( None , 2 ) 6 ================================================================= Total params : 26 Trainable params : 26 Non - trainable params : 0 _________________________________________________________________ \u53e6\u5916\u4e5f\u53ef\u4ee5\u901a\u8fc7\uff1a # \u6a21\u578b\u5c55\u793a keras . utils . plot_model ( model , show_shapes = True ) 4.3 \u901a\u8fc7model\u7684\u5b50\u7c7b\u6784\u5efa \u00b6 \u901a\u8fc7model\u7684\u5b50\u7c7b\u6784\u5efa\u6a21\u578b\uff0c\u6b64\u65f6\u9700\u8981\u5728__init__\u4e2d\u5b9a\u4e49\u795e\u7ecf\u7f51\u7edc\u7684\u5c42\uff0c\u5728call\u65b9\u6cd5\u4e2d\u5b9a\u4e49\u7f51\u7edc\u7684\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u5b9a\u4e49model\u7684\u5b50\u7c7b class MyModel ( tf . keras . Model ): # \u5728init\u65b9\u6cd5\u4e2d\u5b9a\u4e49\u7f51\u7edc\u7684\u5c42\u7ed3\u6784 def __init__ ( self ): super ( MyModel , self ) . __init__ () # \u7b2c\u4e00\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal self . layer1 = tf . keras . layers . Dense ( 3 , activation = \"relu\" , kernel_initializer = \"he_normal\" , name = \"layer1\" , input_shape = ( 3 ,)) # \u7b2c\u4e8c\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal self . layer2 = tf . keras . layers . Dense ( 2 , activation = \"relu\" , kernel_initializer = \"he_normal\" , name = \"layer2\" ) # \u7b2c\u4e09\u5c42\uff08\u8f93\u51fa\u5c42\uff09\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3asigmoid,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal self . layer3 = tf . keras . layers . Dense ( 2 , activation = \"sigmoid\" , kernel_initializer = \"he_normal\" , name = \"layer3\" ) # \u5728call\u65b9\u6cd5\u4e2d\u4e07\u5b8c\u6210\u524d\u5411\u4f20\u64ad def call ( self , inputs ): x = self . layer1 ( inputs ) x = self . layer2 ( x ) return self . layer3 ( x ) # \u5b9e\u4f8b\u5316\u6a21\u578b model = MyModel () # \u8bbe\u7f6e\u4e00\u4e2a\u8f93\u5165\uff0c\u8c03\u7528\u6a21\u578b\uff08\u5426\u5219\u65e0\u6cd5\u4f7f\u7528summay()\uff09 x = tf . ones (( 1 , 3 )) y = model ( x ) \u540c\u6837\u7684\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7summay\u65b9\u6cd5\u6765\u67e5\u770b\u6a21\u578b\u6784\u5efa\u7684\u7ed3\u679c 5 \u795e\u7ecf\u7f51\u7edc\u7684\u4f18\u7f3a\u70b9 \u00b6 1.\u4f18\u70b9 \u00b6 \u7cbe\u5ea6\u9ad8\uff0c\u6027\u80fd\u4f18\u4e8e\u5176\u4ed6\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u751a\u81f3\u5728\u67d0\u4e9b\u9886\u57df\u8d85\u8fc7\u4e86\u4eba\u7c7b \u53ef\u4ee5\u8fd1\u4f3c\u4efb\u610f\u7684\u975e\u7ebf\u6027\u51fd\u6570 \u968f\u4e4b\u8ba1\u7b97\u673a\u786c\u4ef6\u7684\u53d1\u5c55\uff0c\u8fd1\u5e74\u6765\u5728\u5b66\u754c\u548c\u4e1a\u754c\u53d7\u5230\u4e86\u70ed\u6367\uff0c\u6709\u5927\u91cf\u7684\u6846\u67b6\u548c\u5e93\u53ef\u4f9b\u8c03\u7528 2.\u7f3a\u70b9 \u00b6 \u9ed1\u7bb1\uff0c\u5f88\u96be\u89e3\u91ca\u6a21\u578b\u662f\u600e\u4e48\u5de5\u4f5c\u7684 \u8bad\u7ec3\u65f6\u95f4\u957f\uff0c\u9700\u8981\u5927\u91cf\u7684\u8ba1\u7b97\u529b \u7f51\u7edc\u7ed3\u6784\u590d\u6742\uff0c\u9700\u8981\u8c03\u6574\u8d85\u53c2\u6570 \u5c0f\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u5bb9\u6613\u53d1\u751f\u8fc7\u62df\u5408 \u603b\u7ed3 \u77e5\u9053\u6df1\u5ea6\u5b66\u4e60\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u5173\u7cfb \u6df1\u5ea6\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e00\u4e2a\u5b50\u96c6\uff0c\u4e3b\u8981\u533a\u522b\u5728\u662f\u5426\u5305\u542b\u7279\u5f81\u5de5\u7a0b \u77e5\u9053\u795e\u7ecf\u7f51\u7edc\u662f\u4ec0\u4e48 \u4e00\u79cd\u6a21\u4eff\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u548c\u529f\u80fd\u7684 \u8ba1\u7b97\u6a21\u578b \u77e5\u9053\u5e38\u89c1\u7684\u6fc0\u6d3b\u51fd\u6570 \u9ed8\u8ba4\u4f7f\u7528relu\uff0c\u4e8c\u5206\u7c7b\u662fsigmoid, \u591a\u5206\u7c7b\u662fsoftmaxs \u77e5\u9053\u53c2\u6570\u521d\u59cb\u5316\u7684\u5e38\u89c1\u65b9\u6cd5 \u968f\u673a\u521d\u59cb\u5316\uff0c\u6807\u51c6\u521d\u59cb\u5316\uff0cXavier\u521d\u59cb\u5316\uff0cHe\u521d\u59cb\u5316 \u80fd\u591f\u5229\u7528tf.keras\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u6a21\u578b Sequential\u7684\u65b9\u6cd5\uff0cModel\u7684\u51fd\u6570\u5f0f\u7f16\u7a0b\uff0c\u6784\u5efamodel\u7684\u5b50\u7c7b\u5b9e\u73b0 \u4e86\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u4f18\u7f3a\u70b9","title":"\u795e\u7ecf\u7f51\u7edc\u7b80\u4ecb"},{"location":"deeplearning/section1/#21","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u6df1\u5ea6\u5b66\u4e60\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u5173\u7cfb \u77e5\u9053\u795e\u7ecf\u7f51\u7edc\u662f\u4ec0\u4e48 \u77e5\u9053\u5e38\u89c1\u7684\u6fc0\u6d3b\u51fd\u6570 \u77e5\u9053\u53c2\u6570\u521d\u59cb\u5316\u7684\u5e38\u89c1\u65b9\u6cd5 \u80fd\u591f\u5229\u7528tf.keras\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u6a21\u578b \u4e86\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u4f18\u7f3a\u70b9","title":"2.1 \u6df1\u5ea6\u5b66\u4e60\u7b80\u4ecb"},{"location":"deeplearning/section1/#1","text":"\u5728\u4ecb\u7ecd\u6df1\u5ea6\u5b66\u4e60\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u770b\u4e0b\u8fd9\u5e45\u56fe\uff1a\u4eba\u5de5\u667a\u80fd>\u673a\u5668\u5b66\u4e60>\u6df1\u5ea6\u5b66\u4e60 \u6df1\u5ea6\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e00\u4e2a\u5b50\u96c6\uff0c\u4e5f\u5c31\u662f\u8bf4\u6df1\u5ea6\u5b66\u4e60\u662f\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u7684\u4e00\u79cd\u65b9\u6cd5\u3002\u4e0e\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u4e3b\u8981\u533a\u522b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7b97\u672f\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7279\u5f81\uff0c\u5e76\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e0d\u9700\u8981\u4eba\u5de5\uff0c\u800c\u662f\u4f9d\u8d56\u7b97\u6cd5\u81ea\u52a8\u63d0\u53d6\u7279\u5f81\uff0c\u8fd9\u4e5f\u662f\u6df1\u5ea6\u5b66\u4e60\u88ab\u770b\u505a\u9ed1\u76d2\u5b50\uff0c\u53ef\u89e3\u91ca\u6027\u5dee\u7684\u539f\u56e0\u3002 \u968f\u7740\u8ba1\u7b97\u673a\u8f6f\u786c\u4ef6\u7684\u98de\u901f\u53d1\u5c55\uff0c\u73b0\u9636\u6bb5\u901a\u8fc7**\u62e5\u6709\u4f17\u591a\u5c42\u6570\u795e\u7ecf\u7f51\u7edc(Neural Network)**\u6765\u6a21\u62df\u4eba\u8111\u6765\u89e3\u91ca\u6570\u636e\uff0c\u5305\u62ec\u56fe\u50cf\uff0c\u6587\u672c\uff0c\u97f3\u9891\u7b49\u5185\u5bb9\u3002\u76ee\u524d\u6765\u770b\u5e38\u7528\u7684\u795e\u7ecf\u7f51\u7edc\u5305\u62ec\uff1a \u5377\u79ef\u795e\u7ecf\u7f51\u7edc(Convolutional Neural Network) \u5faa\u73af\u795e\u7ecf\u7f51\u7edc(Recurrent Neural Network) \u751f\u6210\u5bf9\u6297\u7f51\u7edc(Generative Adversarial Networks) **\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60(Deep Reinforcement Learning)**\u7b49\u3002","title":"1 \u6df1\u5ea6\u5b66\u4e60\u7b80\u4ecb"},{"location":"deeplearning/section1/#2","text":"\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff08 Artificial Neural Network\uff0c \u7b80\u5199\u4e3aANN\uff09\u4e5f\u7b80\u79f0\u4e3a\u795e\u7ecf\u7f51\u7edc\uff08NN\uff09 \uff0c\u662f\u4e00\u79cd\u6a21\u4eff\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u548c\u529f\u80fd\u7684 \u8ba1\u7b97\u6a21\u578b \u3002\u4eba\u8111\u53ef\u4ee5\u770b\u505a\u662f\u4e00\u4e2a\u751f\u7269\u795e\u7ecf\u7f51\u7edc\uff0c\u7531\u4f17\u591a\u7684\u795e\u7ecf\u5143\u8fde\u63a5\u800c\u6210\u3002\u5404\u4e2a\u795e\u7ecf\u5143\u4f20\u9012\u590d\u6742\u7684\u7535\u4fe1\u53f7\uff0c\u6811\u7a81\u63a5\u6536\u5230\u8f93\u5165\u4fe1\u53f7\uff0c\u7136\u540e\u5bf9\u4fe1\u53f7\u8fdb\u884c\u5904\u7406\uff0c\u901a\u8fc7\u8f74\u7a81\u8f93\u51fa\u4fe1\u53f7\u3002\u4e0b\u56fe\u662f\u751f\u7269\u795e\u7ecf\u5143\u793a\u610f\u56fe\uff1a \u90a3\u600e\u4e48\u6784\u5efa\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u795e\u7ecf\u5143\u5462\uff1f \u53d7\u751f\u7269\u795e\u7ecf\u5143\u7684\u542f\u53d1\uff0c\u4eba\u5de5\u795e\u7ecf\u5143\u63a5\u6536\u6765\u81ea\u5176\u4ed6\u795e\u7ecf\u5143\u6216\u5916\u90e8\u6e90\u7684\u8f93\u5165\uff0c\u6bcf\u4e2a\u8f93\u5165\u90fd\u6709\u4e00\u4e2a\u76f8\u5173\u7684\u6743\u503c(w)\uff0c\u5b83\u662f\u6839\u636e\u8be5\u8f93\u5165\u5bf9\u5f53\u524d\u795e\u7ecf\u5143\u7684\u91cd\u8981\u6027\u6765\u786e\u5b9a\u7684\uff0c\u5bf9\u8be5\u8f93\u5165\u52a0\u6743\u5e76\u4e0e\u5176\u4ed6\u8f93\u5165\u6c42\u548c\u540e\uff0c\u7ecf\u8fc7\u4e00\u4e2a\u6fc0\u6d3b\u51fd\u6570f\uff0c\u8ba1\u7b97\u5f97\u5230\u8be5\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u3002 \u90a3\u63a5\u4e0b\u6765\u6211\u4eec\u5c31\u5229\u7528\u795e\u7ecf\u5143\u6765\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\uff0c\u76f8\u90bb\u5c42\u4e4b\u95f4\u7684\u795e\u7ecf\u5143\u76f8\u4e92\u8fde\u63a5\uff0c\u5e76\u7ed9\u6bcf\u4e00\u4e2a\u8fde\u63a5\u5206\u914d\u4e00\u4e2a\u5f3a\u5ea6\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u795e\u7ecf\u7f51\u7edc\u4e2d\u4fe1\u606f\u53ea\u5411\u4e00\u4e2a\u65b9\u5411\u79fb\u52a8\uff0c\u5373\u4ece\u8f93\u5165\u8282\u70b9\u5411\u524d\u79fb\u52a8\uff0c\u901a\u8fc7\u9690\u85cf\u8282\u70b9\uff0c\u518d\u5411\u8f93\u51fa\u8282\u70b9\u79fb\u52a8\uff0c\u7f51\u7edc\u4e2d\u6ca1\u6709\u5faa\u73af\u6216\u8005\u73af\u3002\u5176\u4e2d\u7684\u57fa\u672c\u6784\u4ef6\u662f\uff1a \u8f93\u5165\u5c42 \uff1a\u5373\u8f93\u5165x\u7684\u90a3\u4e00\u5c42 \u8f93\u51fa\u5c42 \uff1a\u5373\u8f93\u51fay\u7684\u90a3\u4e00\u5c42 \u9690\u85cf\u5c42 \uff1a\u8f93\u5165\u5c42\u548c\u8f93\u51fa\u5c42\u4e4b\u95f4\u90fd\u662f\u9690\u85cf\u5c42 \u7279\u70b9\u662f\uff1a \u540c\u4e00\u5c42\u7684\u795e\u7ecf\u5143\u4e4b\u95f4\u6ca1\u6709\u8fde\u63a5\u3002 \u7b2cN\u5c42\u7684\u6bcf\u4e2a\u795e\u7ecf\u5143\u548c\u7b2cN-1\u5c42\u7684\u6240\u6709\u795e\u7ecf\u5143\u76f8\u8fde(\u8fd9\u5c31\u662ffull connected\u7684\u542b\u4e49)\uff0c\u7b2cN-1\u5c42\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u5c31\u662f\u7b2cN\u5c42\u795e\u7ecf\u5143\u7684\u8f93\u5165\u3002 \u6bcf\u4e2a\u8fde\u63a5\u90fd\u6709\u4e00\u4e2a\u6743\u503c\u3002","title":"2 \u4ec0\u4e48\u662f\u795e\u7ecf\u7f51\u7edc"},{"location":"deeplearning/section1/#3","text":"\u4eba\u5de5\u795e\u7ecf\u5143\u63a5\u6536\u5230\u4e00\u4e2a\u6216\u591a\u4e2a\u8f93\u5165\uff0c\u5bf9\u4ed6\u4eec\u8fdb\u884c\u52a0\u6743\u5e76\u76f8\u52a0\uff0c\u603b\u548c\u901a\u8fc7\u4e00\u4e2a\u975e\u7ebf\u6027\u51fd\u6570\u4ea7\u751f\u8f93\u51fa\u3002 \u6240\u6709\u7684\u8f93\u5165xi\uff0c\u4e0e\u76f8\u5e94\u7684\u6743\u91cdwi\u76f8\u4e58\u5e76\u6c42\u548c\uff1a \u5c06\u6c42\u548c\u7ed3\u679c\u9001\u5165\u5230\u6fc0\u6d3b\u51fd\u6570\u4e2d\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u8f93\u51fa\u7ed3\u679c\uff1a","title":"3 \u795e\u7ecf\u5143\u662f\u5982\u4f55\u5de5\u4f5c\u7684\uff1f"},{"location":"deeplearning/section1/#31","text":"\u5728\u795e\u7ecf\u5143\u4e2d\u5f15\u5165\u4e86\u6fc0\u6d3b\u51fd\u6570\uff0c\u5b83\u7684\u672c\u8d28\u662f\u5411\u795e\u7ecf\u7f51\u7edc\u4e2d\u5f15\u5165\u975e\u7ebf\u6027\u56e0\u7d20\u7684\uff0c\u901a\u8fc7\u6fc0\u6d3b\u51fd\u6570\uff0c\u795e\u7ecf\u7f51\u7edc\u5c31\u53ef\u4ee5\u62df\u5408\u5404\u79cd\u66f2\u7ebf\u3002\u5982\u679c\u4e0d\u7528\u6fc0\u6d3b\u51fd\u6570\uff0c\u6bcf\u4e00\u5c42\u8f93\u51fa\u90fd\u662f\u4e0a\u5c42\u8f93\u5165\u7684\u7ebf\u6027\u51fd\u6570\uff0c\u65e0\u8bba\u795e\u7ecf\u7f51\u7edc\u6709\u591a\u5c11\u5c42\uff0c\u8f93\u51fa\u90fd\u662f\u8f93\u5165\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u5f15\u5165\u975e\u7ebf\u6027\u51fd\u6570\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\uff0c\u90a3\u8f93\u51fa\u4e0d\u518d\u662f\u8f93\u5165\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u53ef\u4ee5\u903c\u8fd1\u4efb\u610f\u51fd\u6570\u3002\u5e38\u7528\u7684\u6fc0\u6d3b\u51fd\u6570\u6709\uff1a","title":"3.1 \u6fc0\u6d3b\u51fd\u6570"},{"location":"deeplearning/section1/#311sigmoidlogistics","text":"\u6570\u5b66\u8868\u8fbe\u5f0f\u4e3a\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a sigmoid \u5728\u5b9a\u4e49\u57df\u5185\u5904\u5904\u53ef\u5bfc\uff0c\u4e14\u4e24\u4fa7\u5bfc\u6570\u9010\u6e10\u8d8b\u8fd1\u4e8e0\u3002\u5982\u679cX\u7684\u503c\u5f88\u5927\u6216\u8005\u5f88\u5c0f\u7684\u65f6\u5019\uff0c\u90a3\u4e48\u51fd\u6570\u7684\u68af\u5ea6\uff08\u51fd\u6570\u7684\u659c\u7387\uff09\u4f1a\u975e\u5e38\u5c0f\uff0c\u5728\u53cd\u5411\u4f20\u64ad\u7684\u8fc7\u7a0b\u4e2d\uff0c\u5bfc\u81f4\u4e86\u5411\u4f4e\u5c42\u4f20\u9012\u7684\u68af\u5ea6\u4e5f\u53d8\u5f97\u975e\u5e38\u5c0f\u3002\u6b64\u65f6\uff0c\u7f51\u7edc\u53c2\u6570\u5f88\u96be\u5f97\u5230\u6709\u6548\u8bad\u7ec3\u3002\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\u68af\u5ea6\u6d88\u5931\u3002\u4e00\u822c\u6765\u8bf4\uff0c sigmoid \u7f51\u7edc\u5728 5 \u5c42\u4e4b\u5185\u5c31\u4f1a\u4ea7\u751f\u68af\u5ea6\u6d88\u5931\u73b0\u8c61\u3002\u800c\u4e14\uff0c\u8be5\u6fc0\u6d3b\u51fd\u6570\u5e76\u4e0d\u662f\u4ee50\u4e3a\u4e2d\u5fc3\u7684\uff0c\u6240\u4ee5\u5728\u5b9e\u8df5\u4e2d\u8fd9\u79cd\u6fc0\u6d3b\u51fd\u6570\u4f7f\u7528\u7684\u5f88\u5c11\u3002sigmoid\u51fd\u6570\u4e00\u822c\u53ea\u7528\u4e8e\u4e8c\u5206\u7c7b\u7684\u8f93\u51fa\u5c42\u3002 \u5b9e\u73b0\u65b9\u6cd5\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u5b9a\u4e49x\u7684\u53d6\u503c\u8303\u56f4 x = np . linspace ( - 10 , 10 , 100 ) # \u76f4\u63a5\u4f7f\u7528tensorflow\u5b9e\u73b0 y = tf . nn . sigmoid ( x ) # \u7ed8\u56fe plt . plot ( x , y ) plt . grid () \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a","title":"3.1.1.Sigmoid/logistics\u51fd\u6570"},{"location":"deeplearning/section1/#312tanh","text":"\u6570\u5b66\u8868\u8fbe\u5f0f\u5982\u4e0b\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a tanh\u4e5f\u662f\u4e00\u79cd\u975e\u5e38\u5e38\u89c1\u7684\u6fc0\u6d3b\u51fd\u6570\u3002\u4e0esigmoid\u76f8\u6bd4\uff0c\u5b83\u662f\u4ee50\u4e3a\u4e2d\u5fc3\u7684\uff0c\u4f7f\u5f97\u5176\u6536\u655b\u901f\u5ea6\u8981\u6bd4sigmoid\u5feb\uff0c\u51cf\u5c11\u8fed\u4ee3\u6b21\u6570\u3002\u7136\u800c\uff0c\u4ece\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0ctanh\u4e24\u4fa7\u7684\u5bfc\u6570\u4e5f\u4e3a0\uff0c\u540c\u6837\u4f1a\u9020\u6210\u68af\u5ea6\u6d88\u5931\u3002 \u82e5\u4f7f\u7528\u65f6\u53ef\u5728\u9690\u85cf\u5c42\u4f7f\u7528tanh\u51fd\u6570\uff0c\u5728\u8f93\u51fa\u5c42\u4f7f\u7528sigmoid\u51fd\u6570\u3002 \u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u5b9a\u4e49x\u7684\u53d6\u503c\u8303\u56f4 x = np . linspace ( - 10 , 10 , 100 ) # \u76f4\u63a5\u4f7f\u7528tensorflow\u5b9e\u73b0 y = tf . nn . tanh ( x ) # \u7ed8\u56fe plt . plot ( x , y ) plt . grid () \u7ed8\u5236\u7ed3\u679c\u4e3a\uff1a","title":"3.1.2.tanh(\u53cc\u66f2\u6b63\u5207\u66f2\u7ebf)"},{"location":"deeplearning/section1/#313relu","text":"\u6570\u5b66\u8868\u8fbe\u5f0f\u4e3a\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a ReLU\u662f\u76ee\u524d\u6700\u5e38\u7528\u7684\u6fc0\u6d3b\u51fd\u6570\u3002 \u4ece\u56fe\u4e2d\u53ef\u4ee5\u770b\u5230\uff0c\u5f53x<0\u65f6\uff0cReLU\u5bfc\u6570\u4e3a0\uff0c\u800c\u5f53x>0\u65f6\uff0c\u5219\u4e0d\u5b58\u5728\u9971\u548c\u95ee\u9898\u3002\u6240\u4ee5\uff0cReLU \u80fd\u591f\u5728x>0\u65f6\u4fdd\u6301\u68af\u5ea6\u4e0d\u8870\u51cf\uff0c\u4ece\u800c\u7f13\u89e3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002\u7136\u800c\uff0c\u968f\u7740\u8bad\u7ec3\u7684\u63a8\u8fdb\uff0c\u90e8\u5206\u8f93\u5165\u4f1a\u843d\u5165\u5c0f\u4e8e0\u533a\u57df\uff0c\u5bfc\u81f4\u5bf9\u5e94\u6743\u91cd\u65e0\u6cd5\u66f4\u65b0\u3002\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\u201c\u795e\u7ecf\u5143\u6b7b\u4ea1\u201d\u3002 \u4e0esigmoid\u76f8\u6bd4\uff0cRELU\u7684\u4f18\u52bf\u662f\uff1a \u91c7\u7528sigmoid\u51fd\u6570\uff0c\u8ba1\u7b97\u91cf\u5927\uff08\u6307\u6570\u8fd0\u7b97\uff09\uff0c\u53cd\u5411\u4f20\u64ad\u6c42\u8bef\u5dee\u68af\u5ea6\u65f6\uff0c\u6c42\u5bfc\u6d89\u53ca\u9664\u6cd5\uff0c\u8ba1\u7b97\u91cf\u76f8\u5bf9\u5927\uff0c\u800c\u91c7\u7528Relu\u6fc0\u6d3b\u51fd\u6570\uff0c\u6574\u4e2a\u8fc7\u7a0b\u7684\u8ba1\u7b97\u91cf\u8282\u7701\u5f88\u591a\u3002 sigmoid\u51fd\u6570\u53cd\u5411\u4f20\u64ad\u65f6\uff0c\u5f88\u5bb9\u6613\u5c31\u4f1a\u51fa\u73b0\u68af\u5ea6\u6d88\u5931\u7684\u60c5\u51b5\uff0c\u4ece\u800c\u65e0\u6cd5\u5b8c\u6210\u6df1\u5c42\u7f51\u7edc\u7684\u8bad\u7ec3\u3002 Relu\u4f1a\u4f7f\u4e00\u90e8\u5206\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u4e3a0\uff0c\u8fd9\u6837\u5c31\u9020\u6210\u4e86\u7f51\u7edc\u7684\u7a00\u758f\u6027\uff0c\u5e76\u4e14\u51cf\u5c11\u4e86\u53c2\u6570\u7684\u76f8\u4e92\u4f9d\u5b58\u5173\u7cfb\uff0c\u7f13\u89e3\u4e86\u8fc7\u62df\u5408\u95ee\u9898\u7684\u53d1\u751f\u3002 \u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u5b9a\u4e49x\u7684\u53d6\u503c\u8303\u56f4 x = np . linspace ( - 10 , 10 , 100 ) # \u76f4\u63a5\u4f7f\u7528tensorflow\u5b9e\u73b0 y = tf . nn . relu ( x ) # \u7ed8\u56fe plt . plot ( x , y ) plt . grid () \u7ed8\u5236\u7ed3\u679c\u4e3a\uff1a","title":"3.1.3.RELU"},{"location":"deeplearning/section1/#314leakrelu","text":"\u8be5\u6fc0\u6d3b\u51fd\u6570\u662f\u5bf9RELU\u7684\u6539\u8fdb\uff0c\u6570\u5b66\u8868\u8fbe\u5f0f\u4e3a\uff1a \u66f2\u7ebf\u5982\u4e0b\u6240\u793a\uff1a \u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u5b9a\u4e49x\u7684\u53d6\u503c\u8303\u56f4 x = np . linspace ( - 10 , 10 , 100 ) # \u76f4\u63a5\u4f7f\u7528tensorflow\u5b9e\u73b0 y = tf . nn . leaky_relu ( x ) # \u7ed8\u56fe plt . plot ( x , y ) plt . grid ()","title":"3.1.4.LeakReLu"},{"location":"deeplearning/section1/#315-softmax","text":"softmax\u7528\u4e8e\u591a\u5206\u7c7b\u8fc7\u7a0b\u4e2d\uff0c\u5b83\u662f\u4e8c\u5206\u7c7b\u51fd\u6570sigmoid\u5728\u591a\u5206\u7c7b\u4e0a\u7684\u63a8\u5e7f\uff0c\u76ee\u7684\u662f\u5c06\u591a\u5206\u7c7b\u7684\u7ed3\u679c\u4ee5\u6982\u7387\u7684\u5f62\u5f0f\u5c55\u73b0\u51fa\u6765\u3002 \u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4f7f\u7528\u65b9\u6cd5\uff1a softmax\u76f4\u767d\u6765\u8bf4\u5c31\u662f\u5c06\u7f51\u7edc\u8f93\u51fa\u7684logits\u901a\u8fc7softmax\u51fd\u6570\uff0c\u5c31\u6620\u5c04\u6210\u4e3a(0,1)\u7684\u503c\uff0c\u800c\u8fd9\u4e9b\u503c\u7684\u7d2f\u548c\u4e3a1\uff08\u6ee1\u8db3\u6982\u7387\u7684\u6027\u8d28\uff09\uff0c\u90a3\u4e48\u6211\u4eec\u5c06\u5b83\u7406\u89e3\u6210\u6982\u7387\uff0c\u9009\u53d6\u6982\u7387\u6700\u5927\uff08\u4e5f\u5c31\u662f\u503c\u5bf9\u5e94\u6700\u5927\u7684\uff09\u63a5\u70b9\uff0c\u4f5c\u4e3a\u6211\u4eec\u7684\u9884\u6d4b\u76ee\u6807\u7c7b\u522b\u3002 \u5b9e\u73b0\uff0c\u4ee5\u4e0a\u56fe\u4e2d\u6570\u5b579\u7684\u5206\u7c7b\u7ed3\u679c\u4e3a\u4f8b\u7ed9\u5927\u5bb6\u8fdb\u884c\u6f14\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u6570\u5b57\u4e2d\u7684score x = tf . constant ([ 0.2 , 0.02 , 0.15 , 1.3 , 0.5 , 0.06 , 1.1 , 0.05 , 3.75 ]) # \u5c06\u5176\u9001\u5165\u5230softmax\u4e2d\u8ba1\u7b97\u5206\u7c7b\u7ed3\u679c y = tf . nn . softmax ( x ) # \u5c06\u7ed3\u679c\u8fdb\u884c\u6253\u5370 print ( y ) \u5206\u7c7b\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [ 0.02167152 0.01810157 0.02061459 0.06510484 0.02925349 0.01884031 0.05330333 0.01865285 0.75445753 ], shape = ( 9 ,), dtype = float32 )","title":"3.1.5. SoftMax"},{"location":"deeplearning/section1/#316","text":"","title":"3.1.6. \u5176\u4ed6\u6fc0\u6d3b\u51fd\u6570"},{"location":"deeplearning/section1/#317","text":"","title":"3.1.7.\u5982\u4f55\u9009\u62e9\u6fc0\u6d3b\u51fd\u6570"},{"location":"deeplearning/section1/#_1","text":"\u4f18\u5148\u9009\u62e9RELU\u6fc0\u6d3b\u51fd\u6570 \u5982\u679cReLu\u6548\u679c\u4e0d\u597d\uff0c\u90a3\u4e48\u5c1d\u8bd5\u5176\u4ed6\u6fc0\u6d3b\uff0c\u5982Leaky ReLu\u7b49\u3002 \u5982\u679c\u4f60\u4f7f\u7528\u4e86Relu\uff0c \u9700\u8981\u6ce8\u610f\u4e00\u4e0bDead Relu\u95ee\u9898\uff0c \u907f\u514d\u51fa\u73b0\u5927\u7684\u68af\u5ea6\u4ece\u800c\u5bfc\u81f4\u8fc7\u591a\u7684\u795e\u7ecf\u5143\u6b7b\u4ea1\u3002 \u4e0d\u8981\u4f7f\u7528sigmoid\u6fc0\u6d3b\u51fd\u6570\uff0c\u53ef\u4ee5\u5c1d\u8bd5\u4f7f\u7528tanh\u6fc0\u6d3b\u51fd\u6570","title":"\u9690\u85cf\u5c42"},{"location":"deeplearning/section1/#_2","text":"\u4e8c\u5206\u7c7b\u95ee\u9898\u9009\u62e9sigmoid\u6fc0\u6d3b\u51fd\u6570 \u591a\u5206\u7c7b\u95ee\u9898\u9009\u62e9softmax\u6fc0\u6d3b\u51fd\u6570 \u56de\u5f52\u95ee\u9898\u9009\u62e9identity\u6fc0\u6d3b\u51fd\u6570","title":"\u8f93\u51fa\u5c42"},{"location":"deeplearning/section1/#32","text":"\u5bf9\u4e8e\u67d0\u4e00\u4e2a\u795e\u7ecf\u5143\u6765\u8bf4\uff0c\u9700\u8981\u521d\u59cb\u5316\u7684\u53c2\u6570\u6709\u4e24\u7c7b\uff1a\u4e00\u7c7b\u662f\u6743\u91cdW\uff0c\u8fd8\u6709\u4e00\u7c7b\u662f\u504f\u7f6eb,\u504f\u7f6eb\u521d\u59cb\u5316\u4e3a0\u5373\u53ef\u3002\u800c\u6743\u91cdW\u7684\u521d\u59cb\u5316\u6bd4\u8f83\u91cd\u8981\uff0c\u6211\u4eec\u7740\u91cd\u6765\u4ecb\u7ecd\u5e38\u89c1\u7684\u521d\u59cb\u5316\u65b9\u5f0f\u3002","title":"3.2 \u53c2\u6570\u521d\u59cb\u5316"},{"location":"deeplearning/section1/#321","text":"\u968f\u673a\u521d\u59cb\u5316\u4ece\u5747\u503c\u4e3a0\uff0c\u6807\u51c6\u5dee\u662f1\u7684\u9ad8\u65af\u5206\u5e03\u4e2d\u53d6\u6837\uff0c\u4f7f\u7528\u4e00\u4e9b\u5f88\u5c0f\u7684\u503c\u5bf9\u53c2\u6570W\u8fdb\u884c\u521d\u59cb\u5316\u3002","title":"3.2.1.\u968f\u673a\u521d\u59cb\u5316"},{"location":"deeplearning/section1/#322","text":"\u6743\u91cd\u53c2\u6570\u521d\u59cb\u5316\u4ece\u533a\u95f4\u5747\u5300\u968f\u673a\u53d6\u503c\u3002\u5373\u5728(-1/\u221ad,1/\u221ad)\u5747\u5300\u5206\u5e03\u4e2d\u751f\u6210\u5f53\u524d\u795e\u7ecf\u5143\u7684\u6743\u91cd\uff0c\u5176\u4e2dd\u4e3a\u6bcf\u4e2a\u795e\u7ecf\u5143\u7684\u8f93\u5165\u6570\u91cf\u3002","title":"3.2.2.\u6807\u51c6\u521d\u59cb\u5316"},{"location":"deeplearning/section1/#323xavier","text":"\u8be5\u65b9\u6cd5\u7684\u57fa\u672c\u601d\u60f3\u662f\u5404\u5c42\u7684\u6fc0\u6d3b\u503c\u548c\u68af\u5ea6\u7684\u65b9\u5dee\u5728\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u4e00\u81f4\uff0c\u4e5f\u53eb\u505aGlorot\u521d\u59cb\u5316\u3002\u5728tf.keras\u4e2d\u5b9e\u73b0\u7684\u65b9\u6cd5\u6709\u4e24\u79cd\uff1a \u6b63\u6001\u5316Xavier\u521d\u59cb\u5316\uff1a Glorot \u6b63\u6001\u5206\u5e03\u521d\u59cb\u5316\u5668\uff0c\u4e5f\u79f0\u4e3a Xavier \u6b63\u6001\u5206\u5e03\u521d\u59cb\u5316\u5668\u3002\u5b83\u4ece\u4ee5 0 \u4e3a\u4e2d\u5fc3\uff0c\u6807\u51c6\u5dee\u4e3a stddev = sqrt(2 / (fan_in + fan_out)) \u7684\u6b63\u6001\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c\uff0c \u5176\u4e2d fan_in \u662f\u8f93\u5165\u795e\u7ecf\u5143\u7684\u4e2a\u6570\uff0c fan_out \u662f\u8f93\u51fa\u7684\u795e\u7ecf\u5143\u4e2a\u6570\u3002 \u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u8fdb\u884c\u5b9e\u4f8b\u5316 initializer = tf . keras . initializers . glorot_normal () # \u91c7\u6837\u5f97\u5230\u6743\u91cd\u503c values = initializer ( shape = ( 9 , 1 )) # \u6253\u5370\u7ed3\u679c print ( values ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ 0.71967787 ] [ 0.56188506 ] [ - 0.7327265 ] [ - 0.05581591 ] [ - 0.05519835 ] [ 0.11283273 ] [ 0.8377778 ] [ 0.5832906 ] [ 0.10221979 ]], shape = ( 9 , 1 ), dtype = float32 ) \u6807\u51c6\u5316Xavier\u521d\u59cb\u5316 Glorot \u5747\u5300\u5206\u5e03\u521d\u59cb\u5316\u5668\uff0c\u4e5f\u79f0\u4e3a Xavier \u5747\u5300\u5206\u5e03\u521d\u59cb\u5316\u5668\u3002\u5b83\u4ece [-limit\uff0climit] \u4e2d\u7684\u5747\u5300\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c\uff0c \u5176\u4e2d limit \u662f sqrt(6 / (fan_in + fan_out)) \uff0c \u5176\u4e2d fan_in \u662f\u8f93\u5165\u795e\u7ecf\u5143\u7684\u4e2a\u6570\uff0c fan_out \u662f\u8f93\u51fa\u7684\u795e\u7ecf\u5143\u4e2a\u6570\u3002 # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u8fdb\u884c\u5b9e\u4f8b\u5316 initializer = tf . keras . initializers . glorot_uniform () # \u91c7\u6837\u5f97\u5230\u6743\u91cd\u503c values = initializer ( shape = ( 9 , 1 )) # \u6253\u5370\u7ed3\u679c print ( values ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ - 0.59119344 ] [ 0.06239486 ] [ 0.65161395 ] [ - 0.30347362 ] [ - 0.5407096 ] [ 0.35138106 ] [ 0.41150713 ] [ 0.32143414 ] [ - 0.57354397 ]], shape = ( 9 , 1 ), dtype = float32 )","title":"3.2.3.Xavier\u521d\u59cb\u5316"},{"location":"deeplearning/section1/#324he","text":"he\u521d\u59cb\u5316\uff0c\u4e5f\u79f0\u4e3aKaiming\u521d\u59cb\u5316\uff0c\u51fa\u81ea\u5927\u795e\u4f55\u607a\u660e\u4e4b\u624b\uff0c\u5b83\u7684\u57fa\u672c\u601d\u60f3\u662f\u6b63\u5411\u4f20\u64ad\u65f6\uff0c\u6fc0\u6d3b\u503c\u7684\u65b9\u5dee\u4fdd\u6301\u4e0d\u53d8\uff1b\u53cd\u5411\u4f20\u64ad\u65f6\uff0c\u5173\u4e8e\u72b6\u6001\u503c\u7684\u68af\u5ea6\u7684\u65b9\u5dee\u4fdd\u6301\u4e0d\u53d8\u3002\u5728tf.keras\u4e2d\u4e5f\u6709\u4e24\u79cd\uff1a \u6b63\u6001\u5316\u7684he\u521d\u59cb\u5316 He \u6b63\u6001\u5206\u5e03\u521d\u59cb\u5316\u662f\u4ee5 0 \u4e3a\u4e2d\u5fc3\uff0c\u6807\u51c6\u5dee\u4e3a stddev = sqrt(2 / fan_in) \u7684\u622a\u65ad\u6b63\u6001\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c\uff0c \u5176\u4e2d fan_in \u662f\u8f93\u5165\u795e\u7ecf\u5143\u7684\u4e2a\u6570\uff0c\u5728tf.keras\u4e2d\u7684\u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u8fdb\u884c\u5b9e\u4f8b\u5316 initializer = tf . keras . initializers . he_normal () # \u91c7\u6837\u5f97\u5230\u6743\u91cd\u503c values = initializer ( shape = ( 9 , 1 )) # \u6253\u5370\u7ed3\u679c print ( values ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ - 0.1488019 ] [ - 0.12102155 ] [ - 0.0163257 ] [ - 0.36920077 ] [ - 0.89464396 ] [ - 0.28749225 ] [ - 0.5467023 ] [ 0.27031776 ] [ - 0.1831588 ]], shape = ( 9 , 1 ), dtype = float32 ) \u6807\u51c6\u5316\u7684he\u521d\u59cb\u5316 He \u5747\u5300\u65b9\u5dee\u7f29\u653e\u521d\u59cb\u5316\u5668\u3002\u5b83\u4ece [-limit\uff0climit] \u4e2d\u7684\u5747\u5300\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c\uff0c \u5176\u4e2d limit \u662f sqrt(6 / fan_in) \uff0c \u5176\u4e2d fan_in \u8f93\u5165\u795e\u7ecf\u5143\u7684\u4e2a\u6570\u3002\u5b9e\u73b0\u4e3a\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u8fdb\u884c\u5b9e\u4f8b\u5316 initializer = tf . keras . initializers . he_uniform () # \u91c7\u6837\u5f97\u5230\u6743\u91cd\u503c values = initializer ( shape = ( 9 , 1 )) # \u6253\u5370\u7ed3\u679c print ( values ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ 0.80033934 ] [ - 0.18773115 ] [ 0.6726284 ] [ - 0.23672342 ] [ - 0.6323329 ] [ 0.6048162 ] [ 0.1637358 ] [ 0.60797024 ] [ - 0.46316862 ]], shape = ( 9 , 1 ), dtype = float32 )","title":"3.2.4.He\u521d\u59cb\u5316"},{"location":"deeplearning/section1/#4","text":"\u63a5\u4e0b\u6765\u6211\u4eec\u6765\u6784\u5efa\u5982\u4e0b\u56fe\u6240\u793a\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff1a tf.Keras\u4e2d\u6784\u5efa\u6a21\u6709\u4e24\u79cd\u65b9\u5f0f\uff0c\u4e00\u79cd\u662f\u901a\u8fc7Sequential\u6784\u5efa\uff0c\u4e00\u79cd\u662f\u901a\u8fc7Model\u7c7b\u6784\u5efa\u3002\u524d\u8005\u662f\u6309\u4e00\u5b9a\u7684\u987a\u5e8f\u5bf9\u5c42\u8fdb\u884c\u5806\u53e0\uff0c\u800c\u540e\u8005\u53ef\u4ee5\u7528\u6765\u6784\u5efa\u8f83\u590d\u6742\u7684\u7f51\u7edc\u6a21\u578b\u3002\u9996\u5148\u6211\u4eec\u4ecb\u7ecd\u4e0b\u7528\u6765\u6784\u5efa\u7f51\u7edc\u7684\u5168\u8fde\u63a5\u5c42\uff1a tf . keras . layers . Dense ( units , activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' ) \u4e3b\u8981\u53c2\u6570\uff1a units: \u5f53\u524d\u5c42\u4e2d\u5305\u542b\u7684\u795e\u7ecf\u5143\u4e2a\u6570 Activation: \u6fc0\u6d3b\u51fd\u6570\uff0crelu,sigmoid\u7b49 use_bias: \u662f\u5426\u4f7f\u7528\u504f\u7f6e\uff0c\u9ed8\u8ba4\u4f7f\u7528\u504f\u7f6e Kernel_initializer: \u6743\u91cd\u7684\u521d\u59cb\u5316\u65b9\u5f0f\uff0c\u9ed8\u8ba4\u662fXavier\u521d\u59cb\u5316 bias_initializer: \u504f\u7f6e\u7684\u521d\u59cb\u5316\u65b9\u5f0f\uff0c\u9ed8\u8ba4\u4e3a0","title":"4 \u795e\u7ecf\u7f51\u7edc\u7684\u642d\u5efa"},{"location":"deeplearning/section1/#41sequential","text":"Sequential() \u63d0\u4f9b\u4e00\u4e2a\u5c42\u7684\u5217\u8868\uff0c\u5c31\u80fd\u5feb\u901f\u5730\u5efa\u7acb\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305 import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers # \u5b9a\u4e49\u4e00\u4e2aSequential\u6a21\u578b\uff0c\u5305\u542b3\u5c42 model = keras . Sequential ( [ # \u7b2c\u4e00\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal layers . Dense ( 3 , activation = \"relu\" , kernel_initializer = \"he_normal\" , name = \"layer1\" , input_shape = ( 3 ,)), # \u7b2c\u4e8c\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal layers . Dense ( 2 , activation = \"relu\" , kernel_initializer = \"he_normal\" , name = \"layer2\" ), # \u7b2c\u4e09\u5c42\uff08\u8f93\u51fa\u5c42\uff09\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3asigmoid,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal layers . Dense ( 2 , activation = \"sigmoid\" , kernel_initializer = \"he_normal\" , name = \"layer3\" ), ], name = \"my_Sequential\" ) \u63a5\u4e0b\u6765\u6211\u4eec\u4f7f\u7528\uff1a # \u5c55\u793a\u6a21\u578b\u7ed3\u679c model . summary () \u5982\u4e0b\u6240\u793a\uff1a Model : \"my_Sequential\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= layer1 ( Dense ) ( None , 3 ) 12 _________________________________________________________________ layer2 ( Dense ) ( None , 2 ) 8 _________________________________________________________________ layer3 ( Dense ) ( None , 2 ) 6 ================================================================= Total params : 26 Trainable params : 26 Non - trainable params : 0 _________________________________________________________________ \u901a\u8fc7\u8fd9\u79cdsequential\u7684\u65b9\u5f0f\u53ea\u80fd\u6784\u5efa\u7b80\u5355\u7684\u5e8f\u5217\u6a21\u578b\uff0c\u8f83\u590d\u6742\u7684\u6a21\u578b\u6ca1\u6709\u529e\u6cd5\u5b9e\u73b0\u3002 \u3010\u6269\u5c55\ud83d\udcda\uff1a\u53c2\u6570\u91cf\u8ba1\u7b97\u3011 \u4ee5\u7b2c\u4e00\u4e2a\u9690\u5c42\u4e3a\u4f8b\uff1a\u8be5\u9690\u5c42\u67093\u4e2a\u795e\u7ecf\u5143\uff0c\u6bcf\u4e2a\u795e\u7ecf\u5143\u7684\u53c2\u6570\u4e3a\uff1a4\u4e2a\uff08w1,w2,w3,b1\uff09\uff0c\u6240\u4ee5\u4e00\u5171\u75283x4=12\u4e2a\u53c2\u6570\u3002","title":"4.1\u901a\u8fc7Sequential\u6784\u5efa"},{"location":"deeplearning/section1/#42-function-api","text":"tf.keras \u63d0\u4f9b\u4e86 Functional API\uff0c\u5efa\u7acb\u66f4\u4e3a\u590d\u6742\u7684\u6a21\u578b\uff0c\u4f7f\u7528\u65b9\u6cd5\u662f\u5c06\u5c42\u4f5c\u4e3a\u53ef\u8c03\u7528\u7684\u5bf9\u8c61\u5e76\u8fd4\u56de\u5f20\u91cf\uff0c\u5e76\u5c06\u8f93\u5165\u5411\u91cf\u548c\u8f93\u51fa\u5411\u91cf\u63d0\u4f9b\u7ed9 tf.keras.Model \u7684 inputs \u548c outputs \u53c2\u6570\uff0c\u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u5b9a\u4e49\u6a21\u578b\u7684\u8f93\u5165 inputs = tf . keras . Input ( shape = ( 3 ,), name = \"input\" ) # \u7b2c\u4e00\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu\uff0c\u5176\u4ed6\u9ed8\u8ba4 x = tf . keras . layers . Dense ( 3 , activation = \"relu\" , name = \"layer1\" )( inputs ) # \u7b2c\u4e8c\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu\uff0c\u5176\u4ed6\u9ed8\u8ba4 x = tf . keras . layers . Dense ( 2 , activation = \"relu\" , name = \"layer2\" )( x ) # \u7b2c\u4e09\u5c42\uff08\u8f93\u51fa\u5c42\uff09\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3asigmoid outputs = tf . keras . layers . Dense ( 2 , activation = \"sigmoid\" , name = \"layer3\" )( x ) # \u4f7f\u7528Model\u6765\u521b\u5efa\u6a21\u578b\uff0c\u6307\u660e\u8f93\u5165\u548c\u8f93\u51fa model = tf . keras . Model ( inputs = inputs , outputs = outputs , name = \"my_model\" ) \u540c\u6837\u901a\u8fc7\uff1a # \u5c55\u793a\u6a21\u578b\u7ed3\u679c model . summary () \u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a Model : \"my_model\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= input ( InputLayer ) [( None , 3 )] 0 _________________________________________________________________ layer1 ( Dense ) ( None , 3 ) 12 _________________________________________________________________ layer2 ( Dense ) ( None , 2 ) 8 _________________________________________________________________ layer3 ( Dense ) ( None , 2 ) 6 ================================================================= Total params : 26 Trainable params : 26 Non - trainable params : 0 _________________________________________________________________ \u53e6\u5916\u4e5f\u53ef\u4ee5\u901a\u8fc7\uff1a # \u6a21\u578b\u5c55\u793a keras . utils . plot_model ( model , show_shapes = True )","title":"4.2 \u5229\u7528function API\u6784\u5efa"},{"location":"deeplearning/section1/#43-model","text":"\u901a\u8fc7model\u7684\u5b50\u7c7b\u6784\u5efa\u6a21\u578b\uff0c\u6b64\u65f6\u9700\u8981\u5728__init__\u4e2d\u5b9a\u4e49\u795e\u7ecf\u7f51\u7edc\u7684\u5c42\uff0c\u5728call\u65b9\u6cd5\u4e2d\u5b9a\u4e49\u7f51\u7edc\u7684\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u5b9a\u4e49model\u7684\u5b50\u7c7b class MyModel ( tf . keras . Model ): # \u5728init\u65b9\u6cd5\u4e2d\u5b9a\u4e49\u7f51\u7edc\u7684\u5c42\u7ed3\u6784 def __init__ ( self ): super ( MyModel , self ) . __init__ () # \u7b2c\u4e00\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal self . layer1 = tf . keras . layers . Dense ( 3 , activation = \"relu\" , kernel_initializer = \"he_normal\" , name = \"layer1\" , input_shape = ( 3 ,)) # \u7b2c\u4e8c\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal self . layer2 = tf . keras . layers . Dense ( 2 , activation = \"relu\" , kernel_initializer = \"he_normal\" , name = \"layer2\" ) # \u7b2c\u4e09\u5c42\uff08\u8f93\u51fa\u5c42\uff09\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3asigmoid,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal self . layer3 = tf . keras . layers . Dense ( 2 , activation = \"sigmoid\" , kernel_initializer = \"he_normal\" , name = \"layer3\" ) # \u5728call\u65b9\u6cd5\u4e2d\u4e07\u5b8c\u6210\u524d\u5411\u4f20\u64ad def call ( self , inputs ): x = self . layer1 ( inputs ) x = self . layer2 ( x ) return self . layer3 ( x ) # \u5b9e\u4f8b\u5316\u6a21\u578b model = MyModel () # \u8bbe\u7f6e\u4e00\u4e2a\u8f93\u5165\uff0c\u8c03\u7528\u6a21\u578b\uff08\u5426\u5219\u65e0\u6cd5\u4f7f\u7528summay()\uff09 x = tf . ones (( 1 , 3 )) y = model ( x ) \u540c\u6837\u7684\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7summay\u65b9\u6cd5\u6765\u67e5\u770b\u6a21\u578b\u6784\u5efa\u7684\u7ed3\u679c","title":"4.3 \u901a\u8fc7model\u7684\u5b50\u7c7b\u6784\u5efa"},{"location":"deeplearning/section1/#5","text":"","title":"5 \u795e\u7ecf\u7f51\u7edc\u7684\u4f18\u7f3a\u70b9"},{"location":"deeplearning/section1/#1_1","text":"\u7cbe\u5ea6\u9ad8\uff0c\u6027\u80fd\u4f18\u4e8e\u5176\u4ed6\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u751a\u81f3\u5728\u67d0\u4e9b\u9886\u57df\u8d85\u8fc7\u4e86\u4eba\u7c7b \u53ef\u4ee5\u8fd1\u4f3c\u4efb\u610f\u7684\u975e\u7ebf\u6027\u51fd\u6570 \u968f\u4e4b\u8ba1\u7b97\u673a\u786c\u4ef6\u7684\u53d1\u5c55\uff0c\u8fd1\u5e74\u6765\u5728\u5b66\u754c\u548c\u4e1a\u754c\u53d7\u5230\u4e86\u70ed\u6367\uff0c\u6709\u5927\u91cf\u7684\u6846\u67b6\u548c\u5e93\u53ef\u4f9b\u8c03\u7528","title":"1.\u4f18\u70b9"},{"location":"deeplearning/section1/#2_1","text":"\u9ed1\u7bb1\uff0c\u5f88\u96be\u89e3\u91ca\u6a21\u578b\u662f\u600e\u4e48\u5de5\u4f5c\u7684 \u8bad\u7ec3\u65f6\u95f4\u957f\uff0c\u9700\u8981\u5927\u91cf\u7684\u8ba1\u7b97\u529b \u7f51\u7edc\u7ed3\u6784\u590d\u6742\uff0c\u9700\u8981\u8c03\u6574\u8d85\u53c2\u6570 \u5c0f\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u5bb9\u6613\u53d1\u751f\u8fc7\u62df\u5408 \u603b\u7ed3 \u77e5\u9053\u6df1\u5ea6\u5b66\u4e60\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u5173\u7cfb \u6df1\u5ea6\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e00\u4e2a\u5b50\u96c6\uff0c\u4e3b\u8981\u533a\u522b\u5728\u662f\u5426\u5305\u542b\u7279\u5f81\u5de5\u7a0b \u77e5\u9053\u795e\u7ecf\u7f51\u7edc\u662f\u4ec0\u4e48 \u4e00\u79cd\u6a21\u4eff\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u548c\u529f\u80fd\u7684 \u8ba1\u7b97\u6a21\u578b \u77e5\u9053\u5e38\u89c1\u7684\u6fc0\u6d3b\u51fd\u6570 \u9ed8\u8ba4\u4f7f\u7528relu\uff0c\u4e8c\u5206\u7c7b\u662fsigmoid, \u591a\u5206\u7c7b\u662fsoftmaxs \u77e5\u9053\u53c2\u6570\u521d\u59cb\u5316\u7684\u5e38\u89c1\u65b9\u6cd5 \u968f\u673a\u521d\u59cb\u5316\uff0c\u6807\u51c6\u521d\u59cb\u5316\uff0cXavier\u521d\u59cb\u5316\uff0cHe\u521d\u59cb\u5316 \u80fd\u591f\u5229\u7528tf.keras\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u6a21\u578b Sequential\u7684\u65b9\u6cd5\uff0cModel\u7684\u51fd\u6570\u5f0f\u7f16\u7a0b\uff0c\u6784\u5efamodel\u7684\u5b50\u7c7b\u5b9e\u73b0 \u4e86\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u4f18\u7f3a\u70b9","title":"2.\u7f3a\u70b9"},{"location":"deeplearning/section2/","text":"2.2 \u5e38\u89c1\u7684\u635f\u5931\u51fd\u6570 \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u5206\u7c7b\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570 \u77e5\u9053\u56de\u5f52\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570 \u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d, \u635f\u5931\u51fd\u6570\u662f\u7528\u6765\u8861\u91cf\u6a21\u578b\u53c2\u6570\u7684\u8d28\u91cf\u7684\u51fd\u6570, \u8861\u91cf\u7684\u65b9\u5f0f\u662f\u6bd4\u8f83\u7f51\u7edc\u8f93\u51fa\u548c\u771f\u5b9e\u8f93\u51fa\u7684\u5dee\u5f02\uff0c\u635f\u5931\u51fd\u6570\u5728\u4e0d\u540c\u7684\u6587\u732e\u4e2d\u540d\u79f0\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u4e3b\u8981\u6709\u4ee5\u4e0b\u51e0\u79cd\u547d\u540d\u65b9\u5f0f\uff1a 1.\u5206\u7c7b\u4efb\u52a1 \u00b6 \u5728\u6df1\u5ea6\u5b66\u4e60\u7684\u5206\u7c7b\u4efb\u52a1\u4e2d\u4f7f\u7528\u6700\u591a\u7684\u662f\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u6240\u4ee5\u5728\u8fd9\u91cc\u6211\u4eec\u7740\u91cd\u4ecb\u7ecd\u8fd9\u79cd\u635f\u5931\u51fd\u6570\u3002 1.1 \u591a\u5206\u7c7b\u4efb\u52a1 \u00b6 \u5728\u591a\u5206\u7c7b\u4efb\u52a1\u901a\u5e38\u4f7f\u7528softmax\u5c06logits\u8f6c\u6362\u4e3a\u6982\u7387\u7684\u5f62\u5f0f\uff0c\u6240\u4ee5\u591a\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u4e5f\u53eb\u505asoftmax\u635f\u5931\uff0c\u5b83\u7684\u8ba1\u7b97\u65b9\u6cd5\u662f\uff1a \u5176\u4e2d\uff0cy\u662f\u6837\u672cx\u5c5e\u4e8e\u67d0\u4e00\u4e2a\u7c7b\u522b\u7684\u771f\u5b9e\u6982\u7387\uff0c\u800cf(x)\u662f\u6837\u672c\u5c5e\u4e8e\u67d0\u4e00\u7c7b\u522b\u7684\u9884\u6d4b\u5206\u6570\uff0cS\u662fsoftmax\u51fd\u6570\uff0cL\u7528\u6765\u8861\u91cfp,q\u4e4b\u95f4\u5dee\u5f02\u6027\u7684\u635f\u5931\u7ed3\u679c\u3002 \u4f8b\u5b50\uff1a \u4e0a\u56fe\u4e2d\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u4e3a\uff1a \u4ece\u6982\u7387\u89d2\u5ea6\u7406\u89e3\uff0c\u6211\u4eec\u7684\u76ee\u7684\u662f\u6700\u5c0f\u5316\u6b63\u786e\u7c7b\u522b\u6240\u5bf9\u5e94\u7684\u9884\u6d4b\u6982\u7387\u7684\u5bf9\u6570\u7684\u8d1f\u503c\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5728tf.keras\u4e2d\u4f7f\u7528CategoricalCrossentropy\u5b9e\u73b0\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0 , 1 , 0 ], [ 0 , 0 , 1 ]] y_pred = [[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]] # \u5b9e\u4f8b\u5316\u4ea4\u53c9\u71b5\u635f\u5931 cce = tf . keras . losses . CategoricalCrossentropy () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c cce ( y_true , y_pred ) . numpy () \u7ed3\u679c\u4e3a\uff1a 1.176939 1.2 \u4e8c\u5206\u7c7b\u4efb\u52a1 \u00b6 \u5728\u5904\u7406\u4e8c\u5206\u7c7b\u4efb\u52a1\u65f6\uff0c\u6211\u4eec\u4e0d\u5728\u4f7f\u7528softmax\u6fc0\u6d3b\u51fd\u6570\uff0c\u800c\u662f\u4f7f\u7528sigmoid\u6fc0\u6d3b\u51fd\u6570\uff0c\u90a3\u635f\u5931\u51fd\u6570\u4e5f\u76f8\u5e94\u7684\u8fdb\u884c\u8c03\u6574\uff0c\u4f7f\u7528\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff1a \u5176\u4e2d\uff0cy\u662f\u6837\u672cx\u5c5e\u4e8e\u67d0\u4e00\u4e2a\u7c7b\u522b\u7684\u771f\u5b9e\u6982\u7387\uff0c\u800cy^\u662f\u6837\u672c\u5c5e\u4e8e\u67d0\u4e00\u7c7b\u522b\u7684\u9884\u6d4b\u6982\u7387\uff0cL\u7528\u6765\u8861\u91cf\u771f\u5b9e\u503c\u4e0e\u9884\u6d4b\u503c\u4e4b\u95f4\u5dee\u5f02\u6027\u7684\u635f\u5931\u7ed3\u679c\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u65f6\u4f7f\u7528BinaryCrossentropy()\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0 ], [ 1 ]] y_pred = [[ 0.4 ], [ 0.6 ]] # \u5b9e\u4f8b\u5316\u4e8c\u5206\u7c7b\u4ea4\u53c9\u71b5\u635f\u5931 bce = tf . keras . losses . BinaryCrossentropy () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c bce ( y_true , y_pred ) . numpy () \u7ed3\u679c\u4e3a\uff1a 0.5108254 2.\u56de\u5f52\u4efb\u52a1 \u00b6 \u56de\u5f52\u4efb\u52a1\u4e2d\u5e38\u7528\u7684\u635f\u5931\u51fd\u6570\u6709\u4ee5\u4e0b\u51e0\u79cd\uff1a 2.1 MAE\u635f\u5931 \u00b6 Mean absolute loss(MAE)\u4e5f\u88ab\u79f0\u4e3aL1 Loss\uff0c\u662f\u4ee5\u7edd\u5bf9\u8bef\u5dee\u4f5c\u4e3a\u8ddd\u79bb\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7279\u70b9\u662f\uff1a\u7531\u4e8eL1 loss\u5177\u6709\u7a00\u758f\u6027\uff0c\u4e3a\u4e86\u60e9\u7f5a\u8f83\u5927\u7684\u503c\uff0c\u56e0\u6b64\u5e38\u5e38\u5c06\u5176\u4f5c\u4e3a\u6b63\u5219\u9879\u6dfb\u52a0\u5230\u5176\u4ed6loss\u4e2d\u4f5c\u4e3a\u7ea6\u675f\u3002L1 loss\u7684\u6700\u5927\u95ee\u9898\u662f\u68af\u5ea6\u5728\u96f6\u70b9\u4e0d\u5e73\u6ed1\uff0c\u5bfc\u81f4\u4f1a\u8df3\u8fc7\u6781\u5c0f\u503c\u3002 \u5728tf.keras\u4e2d\u4f7f\u7528MeanAbsoluteError\u5b9e\u73b0\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0. ], [ 0. ]] y_pred = [[ 1. ], [ 1. ]] # \u5b9e\u4f8b\u5316MAE\u635f\u5931 mae = tf . keras . losses . MeanAbsoluteError () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c mae ( y_true , y_pred ) . numpy () \u7ed3\u679c\u4e3a\uff1a 1.0 2.2 MSE\u635f\u5931 \u00b6 Mean Squared Loss/ Quadratic Loss(MSE loss)\u4e5f\u88ab\u79f0\u4e3aL2 loss\uff0c\u6216\u6b27\u6c0f\u8ddd\u79bb\uff0c\u5b83\u4ee5\u8bef\u5dee\u7684\u5e73\u65b9\u548c\u4f5c\u4e3a\u8ddd\u79bb\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7279\u70b9\u662f\uff1aL2 loss\u4e5f\u5e38\u5e38\u4f5c\u4e3a\u6b63\u5219\u9879\u3002\u5f53\u9884\u6d4b\u503c\u4e0e\u76ee\u6807\u503c\u76f8\u5dee\u5f88\u5927\u65f6, \u68af\u5ea6\u5bb9\u6613\u7206\u70b8\u3002 \u5728tf.keras\u4e2d\u901a\u8fc7MeanSquaredError\u5b9e\u73b0\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0. ], [ 1. ]] y_pred = [[ 1. ], [ 1. ]] # \u5b9e\u4f8b\u5316MSE\u635f\u5931 mse = tf . keras . losses . MeanSquaredError () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c mse ( y_true , y_pred ) . numpy () \u7ed3\u679c\u4e3a\uff1a 0.5 2.3 smooth L1 \u635f\u5931 \u00b6 Smooth L1\u635f\u5931\u51fd\u6570\u5982\u4e0b\u5f0f\u6240\u793a\uff1a \u5176\u4e2d\uff1a\ud835\udc65=f(x)\u2212y \u4e3a\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c\u7684\u5dee\u503c\u3002 \u4ece\u4e0a\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u8be5\u51fd\u6570\u5b9e\u9645\u4e0a\u5c31\u662f\u4e00\u4e2a\u5206\u6bb5\u51fd\u6570\uff0c\u5728[-1,1]\u4e4b\u95f4\u5b9e\u9645\u4e0a\u5c31\u662fL2\u635f\u5931\uff0c\u8fd9\u6837\u89e3\u51b3\u4e86L1\u7684\u4e0d\u5149\u6ed1\u95ee\u9898\uff0c\u5728[-1,1]\u533a\u95f4\u5916\uff0c\u5b9e\u9645\u4e0a\u5c31\u662fL1\u635f\u5931\uff0c\u8fd9\u6837\u5c31\u89e3\u51b3\u4e86\u79bb\u7fa4\u70b9\u68af\u5ea6\u7206\u70b8\u7684\u95ee\u9898\u3002\u901a\u5e38\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u4f7f\u7528\u8be5\u635f\u5931\u51fd\u6570\u3002 \u5728tf.keras\u4e2d\u4f7f\u7528Huber\u8ba1\u7b97\u8be5\u635f\u5931\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0 ], [ 1 ]] y_pred = [[ 0.6 ], [ 0.4 ]] # \u5b9e\u4f8b\u5316smooth L1\u635f\u5931 h = tf . keras . losses . Huber () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c h ( y_true , y_pred ) . numpy () \u7ed3\u679c\uff1a 0.18 \u603b\u7ed3 \u77e5\u9053\u5206\u7c7b\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570 \u591a\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u548c\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 \u77e5\u9053\u56de\u5f52\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570 MAE\uff0cMSE\uff0csmooth L1\u635f\u5931\u51fd\u6570","title":"\u5e38\u89c1\u7684\u635f\u5931\u51fd\u6570"},{"location":"deeplearning/section2/#22","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u5206\u7c7b\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570 \u77e5\u9053\u56de\u5f52\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570 \u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d, \u635f\u5931\u51fd\u6570\u662f\u7528\u6765\u8861\u91cf\u6a21\u578b\u53c2\u6570\u7684\u8d28\u91cf\u7684\u51fd\u6570, \u8861\u91cf\u7684\u65b9\u5f0f\u662f\u6bd4\u8f83\u7f51\u7edc\u8f93\u51fa\u548c\u771f\u5b9e\u8f93\u51fa\u7684\u5dee\u5f02\uff0c\u635f\u5931\u51fd\u6570\u5728\u4e0d\u540c\u7684\u6587\u732e\u4e2d\u540d\u79f0\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u4e3b\u8981\u6709\u4ee5\u4e0b\u51e0\u79cd\u547d\u540d\u65b9\u5f0f\uff1a","title":"2.2 \u5e38\u89c1\u7684\u635f\u5931\u51fd\u6570"},{"location":"deeplearning/section2/#1","text":"\u5728\u6df1\u5ea6\u5b66\u4e60\u7684\u5206\u7c7b\u4efb\u52a1\u4e2d\u4f7f\u7528\u6700\u591a\u7684\u662f\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u6240\u4ee5\u5728\u8fd9\u91cc\u6211\u4eec\u7740\u91cd\u4ecb\u7ecd\u8fd9\u79cd\u635f\u5931\u51fd\u6570\u3002","title":"1.\u5206\u7c7b\u4efb\u52a1"},{"location":"deeplearning/section2/#11","text":"\u5728\u591a\u5206\u7c7b\u4efb\u52a1\u901a\u5e38\u4f7f\u7528softmax\u5c06logits\u8f6c\u6362\u4e3a\u6982\u7387\u7684\u5f62\u5f0f\uff0c\u6240\u4ee5\u591a\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u4e5f\u53eb\u505asoftmax\u635f\u5931\uff0c\u5b83\u7684\u8ba1\u7b97\u65b9\u6cd5\u662f\uff1a \u5176\u4e2d\uff0cy\u662f\u6837\u672cx\u5c5e\u4e8e\u67d0\u4e00\u4e2a\u7c7b\u522b\u7684\u771f\u5b9e\u6982\u7387\uff0c\u800cf(x)\u662f\u6837\u672c\u5c5e\u4e8e\u67d0\u4e00\u7c7b\u522b\u7684\u9884\u6d4b\u5206\u6570\uff0cS\u662fsoftmax\u51fd\u6570\uff0cL\u7528\u6765\u8861\u91cfp,q\u4e4b\u95f4\u5dee\u5f02\u6027\u7684\u635f\u5931\u7ed3\u679c\u3002 \u4f8b\u5b50\uff1a \u4e0a\u56fe\u4e2d\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u4e3a\uff1a \u4ece\u6982\u7387\u89d2\u5ea6\u7406\u89e3\uff0c\u6211\u4eec\u7684\u76ee\u7684\u662f\u6700\u5c0f\u5316\u6b63\u786e\u7c7b\u522b\u6240\u5bf9\u5e94\u7684\u9884\u6d4b\u6982\u7387\u7684\u5bf9\u6570\u7684\u8d1f\u503c\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5728tf.keras\u4e2d\u4f7f\u7528CategoricalCrossentropy\u5b9e\u73b0\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0 , 1 , 0 ], [ 0 , 0 , 1 ]] y_pred = [[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]] # \u5b9e\u4f8b\u5316\u4ea4\u53c9\u71b5\u635f\u5931 cce = tf . keras . losses . CategoricalCrossentropy () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c cce ( y_true , y_pred ) . numpy () \u7ed3\u679c\u4e3a\uff1a 1.176939","title":"1.1 \u591a\u5206\u7c7b\u4efb\u52a1"},{"location":"deeplearning/section2/#12","text":"\u5728\u5904\u7406\u4e8c\u5206\u7c7b\u4efb\u52a1\u65f6\uff0c\u6211\u4eec\u4e0d\u5728\u4f7f\u7528softmax\u6fc0\u6d3b\u51fd\u6570\uff0c\u800c\u662f\u4f7f\u7528sigmoid\u6fc0\u6d3b\u51fd\u6570\uff0c\u90a3\u635f\u5931\u51fd\u6570\u4e5f\u76f8\u5e94\u7684\u8fdb\u884c\u8c03\u6574\uff0c\u4f7f\u7528\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff1a \u5176\u4e2d\uff0cy\u662f\u6837\u672cx\u5c5e\u4e8e\u67d0\u4e00\u4e2a\u7c7b\u522b\u7684\u771f\u5b9e\u6982\u7387\uff0c\u800cy^\u662f\u6837\u672c\u5c5e\u4e8e\u67d0\u4e00\u7c7b\u522b\u7684\u9884\u6d4b\u6982\u7387\uff0cL\u7528\u6765\u8861\u91cf\u771f\u5b9e\u503c\u4e0e\u9884\u6d4b\u503c\u4e4b\u95f4\u5dee\u5f02\u6027\u7684\u635f\u5931\u7ed3\u679c\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u65f6\u4f7f\u7528BinaryCrossentropy()\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0 ], [ 1 ]] y_pred = [[ 0.4 ], [ 0.6 ]] # \u5b9e\u4f8b\u5316\u4e8c\u5206\u7c7b\u4ea4\u53c9\u71b5\u635f\u5931 bce = tf . keras . losses . BinaryCrossentropy () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c bce ( y_true , y_pred ) . numpy () \u7ed3\u679c\u4e3a\uff1a 0.5108254","title":"1.2 \u4e8c\u5206\u7c7b\u4efb\u52a1"},{"location":"deeplearning/section2/#2","text":"\u56de\u5f52\u4efb\u52a1\u4e2d\u5e38\u7528\u7684\u635f\u5931\u51fd\u6570\u6709\u4ee5\u4e0b\u51e0\u79cd\uff1a","title":"2.\u56de\u5f52\u4efb\u52a1"},{"location":"deeplearning/section2/#21-mae","text":"Mean absolute loss(MAE)\u4e5f\u88ab\u79f0\u4e3aL1 Loss\uff0c\u662f\u4ee5\u7edd\u5bf9\u8bef\u5dee\u4f5c\u4e3a\u8ddd\u79bb\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7279\u70b9\u662f\uff1a\u7531\u4e8eL1 loss\u5177\u6709\u7a00\u758f\u6027\uff0c\u4e3a\u4e86\u60e9\u7f5a\u8f83\u5927\u7684\u503c\uff0c\u56e0\u6b64\u5e38\u5e38\u5c06\u5176\u4f5c\u4e3a\u6b63\u5219\u9879\u6dfb\u52a0\u5230\u5176\u4ed6loss\u4e2d\u4f5c\u4e3a\u7ea6\u675f\u3002L1 loss\u7684\u6700\u5927\u95ee\u9898\u662f\u68af\u5ea6\u5728\u96f6\u70b9\u4e0d\u5e73\u6ed1\uff0c\u5bfc\u81f4\u4f1a\u8df3\u8fc7\u6781\u5c0f\u503c\u3002 \u5728tf.keras\u4e2d\u4f7f\u7528MeanAbsoluteError\u5b9e\u73b0\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0. ], [ 0. ]] y_pred = [[ 1. ], [ 1. ]] # \u5b9e\u4f8b\u5316MAE\u635f\u5931 mae = tf . keras . losses . MeanAbsoluteError () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c mae ( y_true , y_pred ) . numpy () \u7ed3\u679c\u4e3a\uff1a 1.0","title":"2.1 MAE\u635f\u5931"},{"location":"deeplearning/section2/#22-mse","text":"Mean Squared Loss/ Quadratic Loss(MSE loss)\u4e5f\u88ab\u79f0\u4e3aL2 loss\uff0c\u6216\u6b27\u6c0f\u8ddd\u79bb\uff0c\u5b83\u4ee5\u8bef\u5dee\u7684\u5e73\u65b9\u548c\u4f5c\u4e3a\u8ddd\u79bb\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7279\u70b9\u662f\uff1aL2 loss\u4e5f\u5e38\u5e38\u4f5c\u4e3a\u6b63\u5219\u9879\u3002\u5f53\u9884\u6d4b\u503c\u4e0e\u76ee\u6807\u503c\u76f8\u5dee\u5f88\u5927\u65f6, \u68af\u5ea6\u5bb9\u6613\u7206\u70b8\u3002 \u5728tf.keras\u4e2d\u901a\u8fc7MeanSquaredError\u5b9e\u73b0\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0. ], [ 1. ]] y_pred = [[ 1. ], [ 1. ]] # \u5b9e\u4f8b\u5316MSE\u635f\u5931 mse = tf . keras . losses . MeanSquaredError () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c mse ( y_true , y_pred ) . numpy () \u7ed3\u679c\u4e3a\uff1a 0.5","title":"2.2 MSE\u635f\u5931"},{"location":"deeplearning/section2/#23-smooth-l1","text":"Smooth L1\u635f\u5931\u51fd\u6570\u5982\u4e0b\u5f0f\u6240\u793a\uff1a \u5176\u4e2d\uff1a\ud835\udc65=f(x)\u2212y \u4e3a\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c\u7684\u5dee\u503c\u3002 \u4ece\u4e0a\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u8be5\u51fd\u6570\u5b9e\u9645\u4e0a\u5c31\u662f\u4e00\u4e2a\u5206\u6bb5\u51fd\u6570\uff0c\u5728[-1,1]\u4e4b\u95f4\u5b9e\u9645\u4e0a\u5c31\u662fL2\u635f\u5931\uff0c\u8fd9\u6837\u89e3\u51b3\u4e86L1\u7684\u4e0d\u5149\u6ed1\u95ee\u9898\uff0c\u5728[-1,1]\u533a\u95f4\u5916\uff0c\u5b9e\u9645\u4e0a\u5c31\u662fL1\u635f\u5931\uff0c\u8fd9\u6837\u5c31\u89e3\u51b3\u4e86\u79bb\u7fa4\u70b9\u68af\u5ea6\u7206\u70b8\u7684\u95ee\u9898\u3002\u901a\u5e38\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u4f7f\u7528\u8be5\u635f\u5931\u51fd\u6570\u3002 \u5728tf.keras\u4e2d\u4f7f\u7528Huber\u8ba1\u7b97\u8be5\u635f\u5931\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0 ], [ 1 ]] y_pred = [[ 0.6 ], [ 0.4 ]] # \u5b9e\u4f8b\u5316smooth L1\u635f\u5931 h = tf . keras . losses . Huber () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c h ( y_true , y_pred ) . numpy () \u7ed3\u679c\uff1a 0.18 \u603b\u7ed3 \u77e5\u9053\u5206\u7c7b\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570 \u591a\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u548c\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 \u77e5\u9053\u56de\u5f52\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570 MAE\uff0cMSE\uff0csmooth L1\u635f\u5931\u51fd\u6570","title":"2.3 smooth L1 \u635f\u5931"},{"location":"deeplearning/section3/","text":"2.3 \u6df1\u5ea6\u5b66\u4e60\u7684\u4f18\u5316\u65b9\u6cd5 \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5 \u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u94fe\u5f0f\u6cd5\u5219 \u638c\u63e1\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff08BP\u7b97\u6cd5\uff09 \u77e5\u9053\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u7684\u4f18\u5316\u65b9\u6cd5 \u4e86\u89e3\u5b66\u4e60\u7387\u9000\u706b 1.\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u3010\u56de\u987e\u3011 \u00b6 \u68af\u5ea6\u4e0b\u964d\u6cd5\u7b80\u5355\u6765\u8bf4\u5c31\u662f\u4e00\u79cd\u5bfb\u627e\u4f7f\u635f\u5931\u51fd\u6570\u6700\u5c0f\u5316\u7684\u65b9\u6cd5\u3002\u5927\u5bb6\u5728\u673a\u5668\u5b66\u4e60\u9636\u6bb5\u5df2\u7ecf\u5b66\u8fc7\u8be5\u7b97\u6cd5\uff0c\u6240\u4ee5\u6211\u4eec\u5728\u8fd9\u91cc\u5c31\u7b80\u5355\u7684\u56de\u987e\u4e0b\uff0c\u4ece\u6570\u5b66\u4e0a\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u68af\u5ea6\u7684\u65b9\u5411\u662f\u51fd\u6570\u589e\u957f\u901f\u5ea6\u6700\u5feb\u7684\u65b9\u5411\uff0c\u90a3\u4e48\u68af\u5ea6\u7684\u53cd\u65b9\u5411\u5c31\u662f\u51fd\u6570\u51cf\u5c11\u6700\u5feb\u7684\u65b9\u5411\uff0c\u6240\u4ee5\u6709\uff1a \u5176\u4e2d\uff0c\u03b7\u662f\u5b66\u4e60\u7387\uff0c\u5982\u679c\u5b66\u4e60\u7387\u592a\u5c0f\uff0c\u90a3\u4e48\u6bcf\u6b21\u8bad\u7ec3\u4e4b\u540e\u5f97\u5230\u7684\u6548\u679c\u90fd\u592a\u5c0f\uff0c\u589e\u5927\u8bad\u7ec3\u7684\u65f6\u95f4\u6210\u672c\u3002\u5982\u679c\uff0c\u5b66\u4e60\u7387\u592a\u5927\uff0c\u90a3\u5c31\u6709\u53ef\u80fd\u76f4\u63a5\u8df3\u8fc7\u6700\u4f18\u89e3\uff0c\u8fdb\u5165\u65e0\u9650\u7684\u8bad\u7ec3\u4e2d\u3002\u89e3\u51b3\u7684\u65b9\u6cd5\u5c31\u662f\uff0c\u5b66\u4e60\u7387\u4e5f\u9700\u8981\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\u800c\u53d8\u5316\u3002 \u5728\u4e0a\u56fe\u4e2d\u6211\u4eec\u5c55\u793a\u4e86\u4e00\u7ef4\u548c\u591a\u7ef4\u7684\u635f\u5931\u51fd\u6570\uff0c\u635f\u5931\u51fd\u6570\u5448\u7897\u72b6\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u635f\u5931\u51fd\u6570\u5bf9\u6743\u91cd\u7684\u504f\u5bfc\u6570\u5c31\u662f\u635f\u5931\u51fd\u6570\u5728\u8be5\u4f4d\u7f6e\u70b9\u7684\u68af\u5ea6\u3002\u6211\u4eec\u53ef\u4ee5\u770b\u5230\uff0c\u6cbf\u7740\u8d1f\u68af\u5ea6\u65b9\u5411\u79fb\u52a8\uff0c\u5c31\u53ef\u4ee5\u5230\u8fbe\u635f\u5931\u51fd\u6570\u5e95\u90e8\uff0c\u4ece\u800c\u4f7f\u635f\u5931\u51fd\u6570\u6700\u5c0f\u5316\u3002\u8fd9\u79cd\u5229\u7528\u635f\u5931\u51fd\u6570\u7684\u68af\u5ea6\u8fed\u4ee3\u5730\u5bfb\u627e\u5c40\u90e8\u6700\u5c0f\u503c\u7684\u8fc7\u7a0b\u5c31\u662f\u68af\u5ea6\u4e0b\u964d\u7684\u8fc7\u7a0b\u3002 \u6839\u636e\u5728\u8fdb\u884c\u8fed\u4ee3\u65f6\u4f7f\u7528\u7684\u6837\u672c\u91cf\uff0c\u5c06\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5206\u4e3a\u4ee5\u4e0b\u4e09\u7c7b\uff1a \u5b9e\u9645\u4e2d\u4f7f\u7528\u8f83\u591a\u7684\u662f\u5c0f\u6279\u91cf\u7684\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\uff0c\u5728tf.keras\u4e2d\u901a\u8fc7\u4ee5\u4e0b\u65b9\u6cd5\u5b9e\u73b0\uff1a tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 , nesterov = False , name = 'SGD' , ** kwargs ) \u4f8b\u5b50\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5\uff1aSGD opt = tf . keras . optimizers . SGD ( learning_rate = 0.1 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570 var = tf . Variable ( 1.0 ) # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff1a\u65e0\u53c2\u4f46\u6709\u8fd4\u56de\u503c loss = lambda : ( var ** 2 ) / 2.0 # \u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c\u6b65\u957f\u4e3a `- learning_rate * grad` opt . minimize ( loss , [ var ]) . numpy () # \u5c55\u793a\u53c2\u6570\u66f4\u65b0\u7ed3\u679c var . numpy () \u66f4\u65b0\u7ed3\u679c\u4e3a\uff1a # 1-0.1*1=0.9 0.9 \u5728\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u65f6\uff0c\u6709\u4e09\u4e2a\u57fa\u7840\u7684\u6982\u5ff5\uff1a \u5b9e\u9645\u4e0a\uff0c\u68af\u5ea6\u4e0b\u964d\u7684\u51e0\u79cd\u65b9\u5f0f\u7684\u6839\u672c\u533a\u522b\u5c31\u5728\u4e8e Batch Size\u4e0d\u540c,\uff0c\u5982\u4e0b\u8868\u6240\u793a\uff1a \u6ce8\uff1a\u4e0a\u8868\u4e2d Mini-Batch \u7684 Batch \u4e2a\u6570\u4e3a N / B + 1 \u662f\u9488\u5bf9\u672a\u6574\u9664\u7684\u60c5\u51b5\u3002\u6574\u9664\u5219\u662f N / B\u3002 \u5047\u8bbe\u6570\u636e\u96c6\u6709 50000 \u4e2a\u8bad\u7ec3\u6837\u672c\uff0c\u73b0\u5728\u9009\u62e9 Batch Size = 256 \u5bf9\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u3002 \u6bcf\u4e2a Epoch \u8981\u8bad\u7ec3\u7684\u56fe\u7247\u6570\u91cf\uff1a50000 \u8bad\u7ec3\u96c6\u5177\u6709\u7684 Batch \u4e2a\u6570\uff1a50000/256+1=196 \u6bcf\u4e2a Epoch \u5177\u6709\u7684 Iteration \u4e2a\u6570\uff1a196 10\u4e2a Epoch \u5177\u6709\u7684 Iteration \u4e2a\u6570\uff1a1960 2.\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff08BP\u7b97\u6cd5\uff09 \u00b6 \u5229\u7528\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u5bf9\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u3002\u8be5\u65b9\u6cd5\u4e0e\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u76f8\u7ed3\u5408\uff0c\u5bf9\u7f51\u7edc\u4e2d\u6240\u6709\u6743\u91cd\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u7684\u68af\u5ea6\uff0c\u5e76\u5229\u7528\u68af\u5ea6\u503c\u6765\u66f4\u65b0\u6743\u503c\u4ee5\u6700\u5c0f\u5316\u635f\u5931\u51fd\u6570\u3002\u5728\u4ecb\u7ecdBP\u7b97\u6cd5\u524d\uff0c\u6211\u4eec\u5148\u770b\u4e0b\u524d\u5411\u4f20\u64ad\u4e0e\u94fe\u5f0f\u6cd5\u5219\u7684\u5185\u5bb9\u3002 2.1 \u524d\u5411\u4f20\u64ad\u4e0e\u53cd\u5411\u4f20\u64ad \u00b6 \u524d\u5411\u4f20\u64ad\u6307\u7684\u662f\u6570\u636e\u8f93\u5165\u7684\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u9010\u5c42\u5411\u524d\u4f20\u8f93\uff0c\u4e00\u76f4\u5230\u8fd0\u7b97\u5230\u8f93\u51fa\u5c42\u4e3a\u6b62\u3002 \u5728\u7f51\u7edc\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7ecf\u8fc7\u524d\u5411\u4f20\u64ad\u540e\u5f97\u5230\u7684\u6700\u7ec8\u7ed3\u679c\u8ddf\u8bad\u7ec3\u6837\u672c\u7684\u771f\u5b9e\u503c\u603b\u662f\u5b58\u5728\u4e00\u5b9a\u8bef\u5dee\uff0c\u8fd9\u4e2a\u8bef\u5dee\u4fbf\u662f\u635f\u5931\u51fd\u6570\u3002\u60f3\u8981\u51cf\u5c0f\u8fd9\u4e2a\u8bef\u5dee\uff0c\u5c31\u7528\u635f\u5931\u51fd\u6570ERROR\uff0c\u4ece\u540e\u5f80\u524d\uff0c\u4f9d\u6b21\u6c42\u5404\u4e2a\u53c2\u6570\u7684\u504f\u5bfc\uff0c\u8fd9\u5c31\u662f\u53cd\u5411\u4f20\u64ad\uff08Back Propagation\uff09\u3002 2.2 \u94fe\u5f0f\u6cd5\u5219 \u00b6 \u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u662f\u5229\u7528\u94fe\u5f0f\u6cd5\u5219\u8fdb\u884c\u68af\u5ea6\u6c42\u89e3\u53ca\u6743\u91cd\u66f4\u65b0\u7684\u3002\u5bf9\u4e8e\u590d\u6742\u7684\u590d\u5408\u51fd\u6570\uff0c\u6211\u4eec\u5c06\u5176\u62c6\u5206\u4e3a\u4e00\u7cfb\u5217\u7684\u52a0\u51cf\u4e58\u9664\u6216\u6307\u6570\uff0c\u5bf9\u6570\uff0c\u4e09\u89d2\u51fd\u6570\u7b49\u521d\u7b49\u51fd\u6570\uff0c\u901a\u8fc7\u94fe\u5f0f\u6cd5\u5219\u5b8c\u6210\u590d\u5408\u51fd\u6570\u7684\u6c42\u5bfc\u3002\u4e3a\u7b80\u5355\u8d77\u89c1\uff0c\u8fd9\u91cc\u4ee5\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u4e2d\u5e38\u89c1\u7684\u590d\u5408\u51fd\u6570\u7684\u4f8b\u5b50\u6765\u8bf4\u660e \u8fd9\u4e2a\u8fc7\u7a0b. \u4ee4\u590d\u5408\u51fd\u6570 \ud835\udc53(\ud835\udc65; \ud835\udc64, \ud835\udc4f) \u4e3a: \u5176\u4e2dx\u662f\u8f93\u5165\u6570\u636e\uff0cw\u662f\u6743\u91cd\uff0cb\u662f\u504f\u7f6e\u3002\u6211\u4eec\u53ef\u4ee5\u5c06\u8be5\u590d\u5408\u51fd\u6570\u5206\u89e3\u4e3a\uff1a \u5e76\u8fdb\u884c\u56fe\u5f62\u5316\u8868\u793a\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u6574\u4e2a\u590d\u5408\u51fd\u6570 \ud835\udc53(\ud835\udc65; \ud835\udc64, \ud835\udc4f) \u5173\u4e8e\u53c2\u6570 \ud835\udc64 \u548c \ud835\udc4f \u7684\u5bfc\u6570\u53ef\u4ee5\u901a\u8fc7 \ud835\udc53(\ud835\udc65; \ud835\udc64, \ud835\udc4f) \u4e0e\u53c2\u6570 \ud835\udc64 \u548c \ud835\udc4f \u4e4b\u95f4\u8def\u5f84\u4e0a\u6240\u6709\u7684\u5bfc\u6570\u8fde\u4e58\u6765\u5f97\u5230\uff0c\u5373\uff1a \u4ee5w\u4e3a\u4f8b\uff0c\u5f53 \ud835\udc65 = 1, \ud835\udc64 = 0, \ud835\udc4f = 0 \u65f6\uff0c\u53ef\u4ee5\u5f97\u5230\uff1a \u6ce8\u610f\uff1a\u5e38\u7528\u51fd\u6570\u7684\u5bfc\u6570\uff1a 2.3 \u53cd\u5411\u4f20\u64ad\u7b97\u6cd5 \u00b6 \u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u5229\u7528\u94fe\u5f0f\u6cd5\u5219\u5bf9\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u5404\u4e2a\u8282\u70b9\u7684\u6743\u91cd\u8fdb\u884c\u66f4\u65b0\u3002\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u6765\u7ed9\u5927\u5bb6\u4ecb\u7ecd\u6574\u4e2a\u6d41\u7a0b. \u8f93\u51fa\u5c42\u6743\u91cd\uff1a \u9690\u85cf\u5c42\u6743\u91cd\uff1a \u504f\u7f6e\u66f4\u65b0\uff1a \u3010\u4e3e\u4e2a\u6817\u5b50\ud83c\udf30\uff1a\u3011 \u5982\u4e0b\u56fe\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u795e\u7ecf\u7f51\u7edc\u7528\u6765\u4e3e\u4f8b\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3asigmoid \u524d\u5411\u4f20\u64ad\u8fd0\u7b97 \uff1a \u63a5\u4e0b\u6765\u662f**\u53cd\u5411\u4f20\u64ad**\uff08\u6c42\u7f51\u7edc\u8bef\u5dee\u5bf9\u5404\u4e2a\u6743\u91cd\u53c2\u6570\u7684\u68af\u5ea6\uff09\uff1a \u6211\u4eec\u5148\u6765\u6c42\u6700\u7b80\u5355\u7684\uff0c\u6c42\u8bef\u5deeE\u5bf9w5\u7684\u5bfc\u6570\u3002\u9996\u5148\u660e\u786e\u8fd9\u662f\u4e00\u4e2a\u201c \u94fe\u5f0f\u6cd5\u5219 \u201d\u7684\u6c42\u5bfc\u8fc7\u7a0b\uff0c\u8981\u6c42\u8bef\u5deeE\u5bf9w5\u7684\u5bfc\u6570\uff0c\u9700\u8981\u5148\u6c42\u8bef\u5deeE\u5bf9out o1\u7684\u5bfc\u6570\uff0c\u518d\u6c42out o1\u5bf9net o1\u7684\u5bfc\u6570\uff0c\u6700\u540e\u518d\u6c42net o1\u5bf9w5\u7684\u5bfc\u6570\uff0c\u7ecf\u8fc7\u8fd9\u4e2a**\u94fe\u5f0f\u6cd5\u5219**\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u6c42\u51fa\u8bef\u5deeE\u5bf9w5\u7684\u5bfc\u6570\uff08\u504f\u5bfc\uff09\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5bfc\u6570\uff08\u68af\u5ea6\uff09\u5df2\u7ecf\u8ba1\u7b97\u51fa\u6765\u4e86\uff0c\u4e0b\u9762\u5c31\u662f**\u53cd\u5411\u4f20\u64ad\u4e0e\u53c2\u6570\u66f4\u65b0\u8fc7\u7a0b**\uff1a \u5982\u679c\u8981\u60f3\u6c42**\u8bef\u5deeE\u5bf9w1\u7684\u5bfc\u6570**\uff0c\u8bef\u5deeE\u5bf9w1\u7684\u6c42\u5bfc\u8def\u5f84\u4e0d\u6b62\u4e00\u6761\uff0c\u8fd9\u4f1a\u7a0d\u5fae\u590d\u6742\u4e00\u70b9\uff0c\u4f46\u6362\u6c64\u4e0d\u6362\u836f\uff0c\u8ba1\u7b97\u8fc7\u7a0b\u5982\u4e0b\u6240\u793a\uff1a \u540c\u7406\u5f97\u5230\uff1a \u6700\u540e\uff0c\u66f4\u65b0\u4e86\u6240\u6709\u7684\u6743\u91cd\uff01\u5f53\u6700\u521d\u524d\u9988\u4f20\u64ad\u65f6\u8f93\u5165\u4e3a 0.05 \u548c 0.1\uff0c\u7f51\u7edc\u4e0a\u7684\u8bef\u5dee\u662f 0.298371109\u3002\u5728\u7b2c\u4e00\u8f6e\u53cd\u5411\u4f20\u64ad\u4e4b\u540e\uff0c\u603b\u8bef\u5dee\u73b0\u5728\u4e0b\u964d\u5230 0.291027924\u3002\u5b83\u53ef\u80fd\u770b\u8d77\u6765\u4e0d\u592a\u591a\uff0c\u4f46\u662f\u5728\u91cd\u590d\u6b64\u8fc7\u7a0b 10000 \u6b21\u4e4b\u540e\uff0c\u4f8b\u5982\uff1a\u9519\u8bef\u503e\u659c\u5230 0.000035085\u3002 \u5728\u8fd9\u4e00\u70b9\u4e0a\uff0c\u5f53\u524d\u9988\u8f93\u5165\u4e3a 0.05 \u548c 0.1 \u65f6\uff0c\u4e24\u4e2a\u8f93\u51fa\u795e\u7ecf\u5143\u4ea7\u751f 0.015912196\uff08\u76f8\u5bf9\u4e8e\u76ee\u6807\u4e3a 0.01\uff09\u548c0.984065734\uff08\u76f8\u5bf9\u4e8e\u76ee\u6807\u4e3a 0.99\uff09 \u81f3\u6b64\uff0c**\u201c\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u201d**\u7684\u8fc7\u7a0b\u5c31\u8bb2\u5b8c\u4e86\u5566\uff01 3.\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u65b9\u6cd5 \u00b6 \u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5728\u8fdb\u884c\u7f51\u7edc\u8bad\u7ec3\u65f6\uff0c\u4f1a\u9047\u5230\u978d\u70b9\uff0c\u5c40\u90e8\u6781\u5c0f\u503c\u8fd9\u4e9b\u95ee\u9898\uff0c\u90a3\u6211\u4eec\u600e\u4e48\u6539\u8fdbSGD\u5462\uff1f\u5728\u8fd9\u91cc\u6211\u4eec\u4ecb\u7ecd\u51e0\u4e2a\u6bd4\u8f83\u5e38\u7528\u7684 3.1 \u52a8\u91cf\u7b97\u6cd5\uff08Momentum\uff09 \u00b6 \u52a8\u91cf\u7b97\u6cd5\u4e3b\u8981\u89e3\u51b3\u978d\u70b9\u95ee\u9898\u3002\u5728\u4ecb\u7ecd\u52a8\u91cf\u6cd5\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u6765\u770b\u4e0b\u6307\u6570\u52a0\u6743\u5e73\u5747\u6570\u7684\u8ba1\u7b97\u65b9\u6cd5\u3002 \u6307\u6570\u52a0\u6743\u5e73\u5747 \u00b6 \u5047\u8bbe\u7ed9\u5b9a\u4e00\u4e2a\u5e8f\u5217\uff0c\u4f8b\u5982\u5317\u4eac\u4e00\u5e74\u6bcf\u5929\u7684\u6c14\u6e29\u503c\uff0c\u56fe\u4e2d\u84dd\u8272\u7684\u70b9\u4ee3\u8868\u771f\u5b9e\u6570\u636e\uff0c \u8fd9\u65f6\u6e29\u5ea6\u503c\u6ce2\u52a8\u6bd4\u8f83\u5927\uff0c\u90a3\u6211\u4eec\u5c31\u4f7f\u7528\u52a0\u6743\u5e73\u5747\u503c\u6765\u8fdb\u884c\u5e73\u6ed1\uff0c\u5982\u4e0b\u56fe\u7ea2\u7ebf\u5c31\u662f\u5e73\u6ed1\u540e\u7684\u7ed3\u679c\uff1a \u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a \u5176\u4e2dYt\u4e3a t \u65f6\u523b\u65f6\u7684\u771f\u5b9e\u503c\uff0cSt\u4e3at\u52a0\u6743\u5e73\u5747\u540e\u7684\u503c\uff0c\u03b2\u4e3a\u6743\u91cd\u503c\u3002\u7ea2\u7ebf\u5373\u662f\u6307\u6570\u52a0\u6743\u5e73\u5747\u540e\u7684\u7ed3\u679c\u3002 \u4e0a\u56fe\u4e2d\u03b2\u8bbe\u4e3a0.9\uff0c\u90a3\u4e48\u6307\u6570\u52a0\u6743\u5e73\u5747\u7684\u8ba1\u7b97\u7ed3\u679c\u4e3a\uff1a \u90a3\u4e48\u7b2c100\u5929\u7684\u7ed3\u679c\u5c31\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \u52a8\u91cf\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5 \u00b6 \u52a8\u91cf\u68af\u5ea6\u4e0b\u964d\uff08Gradient Descent with Momentum\uff09\u8ba1\u7b97\u68af\u5ea6\u7684\u6307\u6570\u52a0\u6743\u5e73\u5747\u6570\uff0c\u5e76\u5229\u7528\u8be5\u503c\u6765\u66f4\u65b0\u53c2\u6570\u503c\u3002\u52a8\u91cf\u68af\u5ea6\u4e0b\u964d\u6cd5\u7684\u6574\u4e2a\u8fc7\u7a0b\u4e3a\uff0c\u5176\u4e2d\u03b2\u901a\u5e38\u8bbe\u7f6e\u4e3a0.9\uff1a \u4e0e\u539f\u59cb\u7684\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u76f8\u6bd4\uff0c\u5b83\u7684\u4e0b\u964d\u8d8b\u52bf\u66f4\u5e73\u6ed1\u3002 \u5728tf.keras\u4e2d\u4f7f\u7528Momentum\u7b97\u6cd5\u4ecd\u4f7f\u7528\u529f\u80fdSGD\u65b9\u6cd5\uff0c\u4f46\u8981\u8bbe\u7f6emomentum\u53c2\u6570\uff0c\u5b9e\u73b0\u8fc7\u7a0b\u5982\u4e0b\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5\uff1aSGD \u6307\u5b9a\u53c2\u6570beta=0.9 opt = tf . keras . optimizers . SGD ( learning_rate = 0.1 , momentum = 0.9 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570\uff0c\u521d\u59cb\u503c var = tf . Variable ( 1.0 ) val0 = var . value () # \u5b9a\u4e49\u635f\u5931\u51fd\u6570 loss = lambda : ( var ** 2 ) / 2.0 #\u7b2c\u4e00\u6b21\u66f4\u65b0\uff1a\u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c\u6b65\u957f\u4e3a `- learning_rate * grad` opt . minimize ( loss , [ var ]) . numpy () val1 = var . value () # \u7b2c\u4e8c\u6b21\u66f4\u65b0\uff1a\u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c\u56e0\u4e3a\u52a0\u5165\u4e86momentum,\u6b65\u957f\u4f1a\u589e\u52a0 opt . minimize ( loss , [ var ]) . numpy () val2 = var . value () # \u6253\u5370\u4e24\u6b21\u66f4\u65b0\u7684\u6b65\u957f print ( \"\u7b2c\u4e00\u6b21\u66f4\u65b0\u6b65\u957f= {} \" . format (( val0 - val1 ) . numpy ())) print ( \"\u7b2c\u4e8c\u6b21\u66f4\u65b0\u6b65\u957f= {} \" . format (( val1 - val2 ) . numpy ())) \u7ed3\u679c\u4e3a\uff1a \u7b2c\u4e00\u6b21\u66f4\u65b0\u6b65\u957f = 0.10000002384185791 \u7b2c\u4e8c\u6b21\u66f4\u65b0\u6b65\u957f = 0.18000000715255737 \u53e6\u5916\u8fd8\u6709\u4e00\u79cd\u52a8\u91cf\u7b97\u6cd5Nesterov accelerated gradient(NAG)\uff0c\u4f7f\u7528\u4e86\u6839\u636e\u52a8\u91cf\u9879**\u9884\u5148\u4f30\u8ba1**\u7684\u53c2\u6570\uff0c\u5728Momentum\u7684\u57fa\u7840\u4e0a\u8fdb\u4e00\u6b65\u52a0\u5feb\u6536\u655b\uff0c\u63d0\u9ad8\u54cd\u5e94\u6027\uff0c\u8be5\u7b97\u6cd5\u5b9e\u73b0\u4f9d\u7136\u4f7f\u7528SGD\u65b9\u6cd5\uff0c\u8981\u8bbe\u7f6enesterov\u8bbe\u7f6e\u4e3atrue. 3.2 AdaGrad \u00b6 AdaGrad\u7b97\u6cd5\u4f1a\u4f7f\u7528\u4e00\u4e2a\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6 g_t \u6309\u5143\u7d20\u5e73\u65b9\u7684\u7d2f\u52a0\u53d8\u91cfst\u3002\u5728\u9996\u6b21\u8fed\u4ee3\u65f6\uff0cAdaGrad\u5c06s0\u4e2d\u6bcf\u4e2a\u5143\u7d20\u521d\u59cb\u5316\u4e3a0\u3002\u5728t\u6b21\u8fed\u4ee3\uff0c\u9996\u5148\u5c06\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6gt\u6309\u5143\u7d20\u5e73\u65b9\u540e\u7d2f\u52a0\u5230\u53d8\u91cfst\uff1a \u5176\u4e2d\u2299\u662f\u6309\u5143\u7d20\u76f8\u4e58\u3002\u63a5\u7740\uff0c\u6211\u4eec\u5c06\u76ee\u6807\u51fd\u6570\u81ea\u53d8\u91cf\u4e2d\u6bcf\u4e2a\u5143\u7d20\u7684\u5b66\u4e60\u7387\u901a\u8fc7\u6309\u5143\u7d20\u8fd0\u7b97\u91cd\u65b0\u8c03\u6574\u4e00\u4e0b\uff1a \u5176\u4e2d\u03b1\u662f\u5b66\u4e60\u7387\uff0c\u03f5\u662f\u4e3a\u4e86\u7ef4\u6301\u6570\u503c\u7a33\u5b9a\u6027\u800c\u6dfb\u52a0\u7684\u5e38\u6570\uff0c\u5982 10^{-6} 10^{-6} <span><span class=\"MathJax_Preview\">10^{-6}</span><script type=\"math/tex\">10^{-6} \u3002\u8fd9\u91cc\u5f00\u65b9\u3001\u9664\u6cd5\u548c\u4e58\u6cd5\u7684\u8fd0\u7b97\u90fd\u662f\u6309\u5143\u7d20\u8fd0\u7b97\u7684\u3002\u8fd9\u4e9b\u6309\u5143\u7d20\u8fd0\u7b97\u4f7f\u5f97\u76ee\u6807\u51fd\u6570\u81ea\u53d8\u91cf\u4e2d\u6bcf\u4e2a\u5143\u7d20\u90fd\u5206\u522b\u62e5\u6709\u81ea\u5df1\u7684\u5b66\u4e60\u7387\u3002 \u5728tf.keras\u4e2d\u7684\u5b9e\u73b0\u65b9\u6cd5\u662f\uff1a tf . keras . optimizers . Adagrad ( learning_rate = 0.001 , initial_accumulator_value = 0.1 , epsilon = 1e-07 ) \u4f8b\u5b50\u662f\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5\uff1aSGD opt = tf . keras . optimizers . Adagrad ( learning_rate = 0.1 , initial_accumulator_value = 0.1 , epsilon = 1e-07 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570 var = tf . Variable ( 1.0 ) # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff1a\u65e0\u53c2\u4f46\u6709\u8fd4\u56de\u503c def loss (): return ( var ** 2 ) / 2.0 # \u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c opt . minimize ( loss , [ var ]) . numpy () # \u5c55\u793a\u53c2\u6570\u66f4\u65b0\u7ed3\u679c var . numpy () 3.3 RMSprop \u00b6 AdaGrad\u7b97\u6cd5\u5728\u8fed\u4ee3\u540e\u671f\u7531\u4e8e\u5b66\u4e60\u7387\u8fc7\u5c0f,\u80fd\u8f83\u96be\u627e\u5230\u6700\u4f18\u89e3\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0cRMSProp\u7b97\u6cd5\u5bf9AdaGrad\u7b97\u6cd5\u505a\u4e86\u4e00\u70b9\u5c0f\u5c0f\u7684\u4fee\u6539\u3002 \u4e0d\u540c\u4e8eAdaGrad\u7b97\u6cd5\u91cc\u72b6\u6001\u53d8\u91cfst\u662f\u622a\u81f3\u65f6\u95f4\u6b65t\u6240\u6709\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6gt\u6309\u5143\u7d20\u5e73\u65b9\u548c\uff0cRMSProp\uff08Root Mean Square Prop\uff09\u7b97\u6cd5\u5c06\u8fd9\u4e9b\u68af\u5ea6\u6309\u5143\u7d20\u5e73\u65b9\u505a\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747 \u5176\u4e2d\u03f5\u662f\u4e00\u6837\u4e3a\u4e86\u7ef4\u6301\u6570\u503c\u7a33\u5b9a\u4e00\u4e2a\u5e38\u6570\u3002\u6700\u7ec8\u81ea\u53d8\u91cf\u6bcf\u4e2a\u5143\u7d20\u7684\u5b66\u4e60\u7387\u5728\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\u5c31\u4e0d\u518d\u4e00\u76f4\u964d\u4f4e\u3002RMSProp \u6709\u52a9\u4e8e\u51cf\u5c11\u62b5\u8fbe\u6700\u5c0f\u503c\u8def\u5f84\u4e0a\u7684\u6446\u52a8\uff0c\u5e76\u5141\u8bb8\u4f7f\u7528\u4e00\u4e2a\u66f4\u5927\u7684\u5b66\u4e60\u7387 \u03b1\uff0c\u4ece\u800c\u52a0\u5feb\u7b97\u6cd5\u5b66\u4e60\u901f\u5ea6\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u65f6\uff0c\u4f7f\u7528\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . optimizers . RMSprop ( learning_rate = 0.001 , rho = 0.9 , momentum = 0.0 , epsilon = 1e-07 , centered = False , name = 'RMSprop' , ** kwargs ) \u4f8b\u5b50\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5RMSprop opt = tf . keras . optimizers . RMSprop ( learning_rate = 0.1 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570 var = tf . Variable ( 1.0 ) # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff1a\u65e0\u53c2\u4f46\u6709\u8fd4\u56de\u503c def loss (): return ( var ** 2 ) / 2.0 # \u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c opt . minimize ( loss , [ var ]) . numpy () # \u5c55\u793a\u53c2\u6570\u66f4\u65b0\u7ed3\u679c var . numpy () \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a 0.6837723 3.4 Adam \u00b6 Adam \u4f18\u5316\u7b97\u6cd5\uff08Adaptive Moment Estimation\uff0c\u81ea\u9002\u5e94\u77e9\u4f30\u8ba1\uff09\u5c06 Momentum \u548c RMSProp \u7b97\u6cd5\u7ed3\u5408\u5728\u4e00\u8d77\u3002Adam\u7b97\u6cd5\u5728RMSProp\u7b97\u6cd5\u57fa\u7840\u4e0a\u5bf9\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6\u4e5f\u505a\u4e86\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747\u3002 \u5047\u8bbe\u7528\u6bcf\u4e00\u4e2a mini-batch \u8ba1\u7b97 dW\u3001db\uff0c\u7b2ct\u6b21\u8fed\u4ee3\u65f6\uff1a \u5176\u4e2dl\u4e3a\u67d0\u4e00\u5c42\uff0ct\u4e3a\u79fb\u52a8\u5e73\u5747\u7b2c\u6b21\u7684\u503c Adam \u7b97\u6cd5\u7684\u53c2\u6570\u66f4\u65b0\uff1a \u5efa\u8bae\u7684\u53c2\u6570\u8bbe\u7f6e\u7684\u503c\uff1a \u5b66\u4e60\u7387\u03b1\uff1a \u9700\u8981\u5c1d\u8bd5\u4e00\u7cfb\u5217\u7684\u503c\uff0c\u6765\u5bfb\u627e\u6bd4\u8f83\u5408\u9002\u7684 \u03b21\uff1a\u5e38\u7528\u7684\u7f3a\u7701\u503c\u4e3a 0.9 \u03b22\uff1a\u5efa\u8bae\u4e3a 0.999 \u03f5\uff1a\u9ed8\u8ba4\u503c1e-8 \u5728tf.keras\u4e2d\u5b9e\u73b0\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . optimizers . Adam ( learning_rate = 0.001 , beta_1 = 0.9 , beta_2 = 0.999 , epsilon = 1e-07 ) \u4f8b\u5b50\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5Adam opt = tf . keras . optimizers . Adam ( learning_rate = 0.1 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570 var = tf . Variable ( 1.0 ) # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff1a\u65e0\u53c2\u4f46\u6709\u8fd4\u56de\u503c def loss (): return ( var ** 2 ) / 2.0 # \u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c opt . minimize ( loss , [ var ]) . numpy () # \u5c55\u793a\u53c2\u6570\u66f4\u65b0\u7ed3\u679c var . numpy () \u7ed3\u679c\u4e3a\uff1a 0.90000033 4.\u5b66\u4e60\u7387\u9000\u706b \u00b6 \u5728\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u65f6\uff0c\u4e00\u822c\u60c5\u51b5\u4e0b\u5b66\u4e60\u7387\u90fd\u4f1a\u968f\u7740\u8bad\u7ec3\u800c\u53d8\u5316\uff0c\u8fd9\u4e3b\u8981\u662f\u7531\u4e8e\uff0c\u5728\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u7684\u540e\u671f\uff0c\u5982\u679c\u5b66\u4e60\u7387\u8fc7\u9ad8\uff0c\u4f1a\u9020\u6210loss\u7684\u632f\u8361\uff0c\u4f46\u662f\u5982\u679c\u5b66\u4e60\u7387\u51cf\u5c0f\u7684\u8fc7\u5feb\uff0c\u53c8\u4f1a\u9020\u6210\u6536\u655b\u53d8\u6162\u7684\u60c5\u51b5\u3002 4.1 \u5206\u6bb5\u5e38\u6570\u8870\u51cf \u00b6 \u5206\u6bb5\u5e38\u6570\u8870\u51cf\u662f\u5728\u4e8b\u5148\u5b9a\u4e49\u597d\u7684\u8bad\u7ec3\u6b21\u6570\u533a\u95f4\u4e0a\uff0c\u8bbe\u7f6e\u4e0d\u540c\u7684\u5b66\u4e60\u7387\u5e38\u6570\u3002\u521a\u5f00\u59cb\u5b66\u4e60\u7387\u5927\u4e00\u4e9b\uff0c\u4e4b\u540e\u8d8a\u6765\u8d8a\u5c0f\uff0c\u533a\u95f4\u7684\u8bbe\u7f6e\u9700\u8981\u6839\u636e\u6837\u672c\u91cf\u8c03\u6574\uff0c\u4e00\u822c\u6837\u672c\u91cf\u8d8a\u5927\u533a\u95f4\u95f4\u9694\u5e94\u8be5\u8d8a\u5c0f\u3002 \u5728tf.keras\u4e2d\u5bf9\u5e94\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . optimizers . schedules . PiecewiseConstantDecay ( boundaries , values ) \u53c2\u6570\uff1a Boundaries: \u8bbe\u7f6e\u5206\u6bb5\u66f4\u65b0\u7684step\u503c Values: \u9488\u5bf9\u4e0d\u7528\u5206\u6bb5\u7684\u5b66\u4e60\u7387\u503c \u4f8b\u5b50\uff1a\u5bf9\u4e8e\u524d100000\u6b65\uff0c\u5b66\u4e60\u7387\u4e3a1.0\uff0c\u5bf9\u4e8e\u63a5\u4e0b\u6765\u7684100000-110000\u6b65\uff0c\u5b66\u4e60\u7387\u4e3a0.5\uff0c\u4e4b\u540e\u7684\u6b65\u9aa4\u5b66\u4e60\u7387\u4e3a0.1 # \u8bbe\u7f6e\u7684\u5206\u6bb5\u7684step\u503c boundaries = [ 100000 , 110000 ] # \u4e0d\u540c\u7684step\u5bf9\u5e94\u7684\u5b66\u4e60\u7387 values = [ 1.0 , 0.5 , 0.1 ] # \u5b9e\u4f8b\u5316\u8fdb\u884c\u5b66\u4e60\u7684\u66f4\u65b0 learning_rate_fn = keras . optimizers . schedules . PiecewiseConstantDecay ( boundaries , values ) 4.2 \u6307\u6570\u8870\u51cf \u00b6 \u6307\u6570\u8870\u51cf\u53ef\u4ee5\u7528\u5982\u4e0b\u7684\u6570\u5b66\u516c\u5f0f\u8868\u793a, \u5176\u4e2d\uff0ct\u8868\u793a\u8fed\u4ee3\u6b21\u6570\uff0c\u03b10,k\u662f\u8d85\u53c2\u6570 \u5728tf.keras\u4e2d\u7684\u5b9e\u73b0\u662f\uff1a tf . keras . optimizers . schedules . ExponentialDecay ( initial_learning_rate , decay_steps , decay_rate ) \u5177\u4f53\u7684\u5b9e\u73b0\u662f\uff1a def decayed_learning_rate ( step ): return initial_learning_rate * decay_rate ^ ( step / decay_steps ) \u53c2\u6570\uff1a Initial_learning_rate: \u521d\u59cb\u5b66\u4e60\u7387\uff0c\u03b10 decay_steps: k\u503c decay_rate: \u6307\u6570\u7684\u5e95 4.3 1/t\u8870\u51cf \u00b6 1/t\u8870\u51cf\u53ef\u4ee5\u7528\u5982\u4e0b\u7684\u6570\u5b66\u516c\u5f0f\u8868\u793a\uff1a \u5176\u4e2d\uff0ct\u8868\u793a\u8fed\u4ee3\u6b21\u6570\uff0c\u03b10,k\u662f\u8d85\u53c2\u6570 \u5728tf.keras\u4e2d\u7684\u5b9e\u73b0\u662f\uff1a tf . keras . optimizers . schedules . InverseTimeDecay ( initial_learning_rate , decay_steps , decay_rate ) \u5177\u4f53\u7684\u5b9e\u73b0\u662f\uff1a def decayed_learning_rate ( step ): return initial_learning_rate / ( 1 + decay_rate * step / decay_step ) \u53c2\u6570\uff1a Initial_learning_rate: \u521d\u59cb\u5b66\u4e60\u7387\uff0c\u03b10 decay_step/decay_steps: k\u503c \u603b\u7ed3 \u77e5\u9053\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5 \u4e00\u79cd\u5bfb\u627e\u4f7f\u635f\u5931\u51fd\u6570\u6700\u5c0f\u5316\u7684\u65b9\u6cd5\uff1a\u6279\u91cf\u68af\u5ea6\u4e0b\u964d\uff0c\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff0c\u5c0f\u6279\u91cf\u68af\u5ea6\u4e0b\u964d \u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u94fe\u5f0f\u6cd5\u5219 \u590d\u5408\u51fd\u6570\u7684\u6c42\u5bfc \u638c\u63e1\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff08BP\u7b97\u6cd5\uff09 \u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u53c2\u6570\u66f4\u65b0\u7684\u65b9\u6cd5 \u77e5\u9053\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u7684\u4f18\u5316\u65b9\u6cd5 \u52a8\u91cf\u7b97\u6cd5\uff0cadaGrad,RMSProp,Adam \u4e86\u89e3\u5b66\u4e60\u7387\u9000\u706b \u5206\u6bb5\u5e38\u6570\u8870\u51cf\uff0c\u6307\u6570\u8870\u51cf\uff0c1/t\u8870\u51cf","title":"\u6df1\u5ea6\u5b66\u4e60\u7684\u4f18\u5316\u65b9\u6cd5"},{"location":"deeplearning/section3/#23","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5 \u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u94fe\u5f0f\u6cd5\u5219 \u638c\u63e1\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff08BP\u7b97\u6cd5\uff09 \u77e5\u9053\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u7684\u4f18\u5316\u65b9\u6cd5 \u4e86\u89e3\u5b66\u4e60\u7387\u9000\u706b","title":"2.3 \u6df1\u5ea6\u5b66\u4e60\u7684\u4f18\u5316\u65b9\u6cd5"},{"location":"deeplearning/section3/#1","text":"\u68af\u5ea6\u4e0b\u964d\u6cd5\u7b80\u5355\u6765\u8bf4\u5c31\u662f\u4e00\u79cd\u5bfb\u627e\u4f7f\u635f\u5931\u51fd\u6570\u6700\u5c0f\u5316\u7684\u65b9\u6cd5\u3002\u5927\u5bb6\u5728\u673a\u5668\u5b66\u4e60\u9636\u6bb5\u5df2\u7ecf\u5b66\u8fc7\u8be5\u7b97\u6cd5\uff0c\u6240\u4ee5\u6211\u4eec\u5728\u8fd9\u91cc\u5c31\u7b80\u5355\u7684\u56de\u987e\u4e0b\uff0c\u4ece\u6570\u5b66\u4e0a\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u68af\u5ea6\u7684\u65b9\u5411\u662f\u51fd\u6570\u589e\u957f\u901f\u5ea6\u6700\u5feb\u7684\u65b9\u5411\uff0c\u90a3\u4e48\u68af\u5ea6\u7684\u53cd\u65b9\u5411\u5c31\u662f\u51fd\u6570\u51cf\u5c11\u6700\u5feb\u7684\u65b9\u5411\uff0c\u6240\u4ee5\u6709\uff1a \u5176\u4e2d\uff0c\u03b7\u662f\u5b66\u4e60\u7387\uff0c\u5982\u679c\u5b66\u4e60\u7387\u592a\u5c0f\uff0c\u90a3\u4e48\u6bcf\u6b21\u8bad\u7ec3\u4e4b\u540e\u5f97\u5230\u7684\u6548\u679c\u90fd\u592a\u5c0f\uff0c\u589e\u5927\u8bad\u7ec3\u7684\u65f6\u95f4\u6210\u672c\u3002\u5982\u679c\uff0c\u5b66\u4e60\u7387\u592a\u5927\uff0c\u90a3\u5c31\u6709\u53ef\u80fd\u76f4\u63a5\u8df3\u8fc7\u6700\u4f18\u89e3\uff0c\u8fdb\u5165\u65e0\u9650\u7684\u8bad\u7ec3\u4e2d\u3002\u89e3\u51b3\u7684\u65b9\u6cd5\u5c31\u662f\uff0c\u5b66\u4e60\u7387\u4e5f\u9700\u8981\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\u800c\u53d8\u5316\u3002 \u5728\u4e0a\u56fe\u4e2d\u6211\u4eec\u5c55\u793a\u4e86\u4e00\u7ef4\u548c\u591a\u7ef4\u7684\u635f\u5931\u51fd\u6570\uff0c\u635f\u5931\u51fd\u6570\u5448\u7897\u72b6\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u635f\u5931\u51fd\u6570\u5bf9\u6743\u91cd\u7684\u504f\u5bfc\u6570\u5c31\u662f\u635f\u5931\u51fd\u6570\u5728\u8be5\u4f4d\u7f6e\u70b9\u7684\u68af\u5ea6\u3002\u6211\u4eec\u53ef\u4ee5\u770b\u5230\uff0c\u6cbf\u7740\u8d1f\u68af\u5ea6\u65b9\u5411\u79fb\u52a8\uff0c\u5c31\u53ef\u4ee5\u5230\u8fbe\u635f\u5931\u51fd\u6570\u5e95\u90e8\uff0c\u4ece\u800c\u4f7f\u635f\u5931\u51fd\u6570\u6700\u5c0f\u5316\u3002\u8fd9\u79cd\u5229\u7528\u635f\u5931\u51fd\u6570\u7684\u68af\u5ea6\u8fed\u4ee3\u5730\u5bfb\u627e\u5c40\u90e8\u6700\u5c0f\u503c\u7684\u8fc7\u7a0b\u5c31\u662f\u68af\u5ea6\u4e0b\u964d\u7684\u8fc7\u7a0b\u3002 \u6839\u636e\u5728\u8fdb\u884c\u8fed\u4ee3\u65f6\u4f7f\u7528\u7684\u6837\u672c\u91cf\uff0c\u5c06\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5206\u4e3a\u4ee5\u4e0b\u4e09\u7c7b\uff1a \u5b9e\u9645\u4e2d\u4f7f\u7528\u8f83\u591a\u7684\u662f\u5c0f\u6279\u91cf\u7684\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\uff0c\u5728tf.keras\u4e2d\u901a\u8fc7\u4ee5\u4e0b\u65b9\u6cd5\u5b9e\u73b0\uff1a tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 , nesterov = False , name = 'SGD' , ** kwargs ) \u4f8b\u5b50\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5\uff1aSGD opt = tf . keras . optimizers . SGD ( learning_rate = 0.1 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570 var = tf . Variable ( 1.0 ) # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff1a\u65e0\u53c2\u4f46\u6709\u8fd4\u56de\u503c loss = lambda : ( var ** 2 ) / 2.0 # \u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c\u6b65\u957f\u4e3a `- learning_rate * grad` opt . minimize ( loss , [ var ]) . numpy () # \u5c55\u793a\u53c2\u6570\u66f4\u65b0\u7ed3\u679c var . numpy () \u66f4\u65b0\u7ed3\u679c\u4e3a\uff1a # 1-0.1*1=0.9 0.9 \u5728\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u65f6\uff0c\u6709\u4e09\u4e2a\u57fa\u7840\u7684\u6982\u5ff5\uff1a \u5b9e\u9645\u4e0a\uff0c\u68af\u5ea6\u4e0b\u964d\u7684\u51e0\u79cd\u65b9\u5f0f\u7684\u6839\u672c\u533a\u522b\u5c31\u5728\u4e8e Batch Size\u4e0d\u540c,\uff0c\u5982\u4e0b\u8868\u6240\u793a\uff1a \u6ce8\uff1a\u4e0a\u8868\u4e2d Mini-Batch \u7684 Batch \u4e2a\u6570\u4e3a N / B + 1 \u662f\u9488\u5bf9\u672a\u6574\u9664\u7684\u60c5\u51b5\u3002\u6574\u9664\u5219\u662f N / B\u3002 \u5047\u8bbe\u6570\u636e\u96c6\u6709 50000 \u4e2a\u8bad\u7ec3\u6837\u672c\uff0c\u73b0\u5728\u9009\u62e9 Batch Size = 256 \u5bf9\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u3002 \u6bcf\u4e2a Epoch \u8981\u8bad\u7ec3\u7684\u56fe\u7247\u6570\u91cf\uff1a50000 \u8bad\u7ec3\u96c6\u5177\u6709\u7684 Batch \u4e2a\u6570\uff1a50000/256+1=196 \u6bcf\u4e2a Epoch \u5177\u6709\u7684 Iteration \u4e2a\u6570\uff1a196 10\u4e2a Epoch \u5177\u6709\u7684 Iteration \u4e2a\u6570\uff1a1960","title":"1.\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u3010\u56de\u987e\u3011"},{"location":"deeplearning/section3/#2bp","text":"\u5229\u7528\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u5bf9\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u3002\u8be5\u65b9\u6cd5\u4e0e\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u76f8\u7ed3\u5408\uff0c\u5bf9\u7f51\u7edc\u4e2d\u6240\u6709\u6743\u91cd\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u7684\u68af\u5ea6\uff0c\u5e76\u5229\u7528\u68af\u5ea6\u503c\u6765\u66f4\u65b0\u6743\u503c\u4ee5\u6700\u5c0f\u5316\u635f\u5931\u51fd\u6570\u3002\u5728\u4ecb\u7ecdBP\u7b97\u6cd5\u524d\uff0c\u6211\u4eec\u5148\u770b\u4e0b\u524d\u5411\u4f20\u64ad\u4e0e\u94fe\u5f0f\u6cd5\u5219\u7684\u5185\u5bb9\u3002","title":"2.\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff08BP\u7b97\u6cd5\uff09"},{"location":"deeplearning/section3/#21","text":"\u524d\u5411\u4f20\u64ad\u6307\u7684\u662f\u6570\u636e\u8f93\u5165\u7684\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u9010\u5c42\u5411\u524d\u4f20\u8f93\uff0c\u4e00\u76f4\u5230\u8fd0\u7b97\u5230\u8f93\u51fa\u5c42\u4e3a\u6b62\u3002 \u5728\u7f51\u7edc\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7ecf\u8fc7\u524d\u5411\u4f20\u64ad\u540e\u5f97\u5230\u7684\u6700\u7ec8\u7ed3\u679c\u8ddf\u8bad\u7ec3\u6837\u672c\u7684\u771f\u5b9e\u503c\u603b\u662f\u5b58\u5728\u4e00\u5b9a\u8bef\u5dee\uff0c\u8fd9\u4e2a\u8bef\u5dee\u4fbf\u662f\u635f\u5931\u51fd\u6570\u3002\u60f3\u8981\u51cf\u5c0f\u8fd9\u4e2a\u8bef\u5dee\uff0c\u5c31\u7528\u635f\u5931\u51fd\u6570ERROR\uff0c\u4ece\u540e\u5f80\u524d\uff0c\u4f9d\u6b21\u6c42\u5404\u4e2a\u53c2\u6570\u7684\u504f\u5bfc\uff0c\u8fd9\u5c31\u662f\u53cd\u5411\u4f20\u64ad\uff08Back Propagation\uff09\u3002","title":"2.1 \u524d\u5411\u4f20\u64ad\u4e0e\u53cd\u5411\u4f20\u64ad"},{"location":"deeplearning/section3/#22","text":"\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u662f\u5229\u7528\u94fe\u5f0f\u6cd5\u5219\u8fdb\u884c\u68af\u5ea6\u6c42\u89e3\u53ca\u6743\u91cd\u66f4\u65b0\u7684\u3002\u5bf9\u4e8e\u590d\u6742\u7684\u590d\u5408\u51fd\u6570\uff0c\u6211\u4eec\u5c06\u5176\u62c6\u5206\u4e3a\u4e00\u7cfb\u5217\u7684\u52a0\u51cf\u4e58\u9664\u6216\u6307\u6570\uff0c\u5bf9\u6570\uff0c\u4e09\u89d2\u51fd\u6570\u7b49\u521d\u7b49\u51fd\u6570\uff0c\u901a\u8fc7\u94fe\u5f0f\u6cd5\u5219\u5b8c\u6210\u590d\u5408\u51fd\u6570\u7684\u6c42\u5bfc\u3002\u4e3a\u7b80\u5355\u8d77\u89c1\uff0c\u8fd9\u91cc\u4ee5\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u4e2d\u5e38\u89c1\u7684\u590d\u5408\u51fd\u6570\u7684\u4f8b\u5b50\u6765\u8bf4\u660e \u8fd9\u4e2a\u8fc7\u7a0b. \u4ee4\u590d\u5408\u51fd\u6570 \ud835\udc53(\ud835\udc65; \ud835\udc64, \ud835\udc4f) \u4e3a: \u5176\u4e2dx\u662f\u8f93\u5165\u6570\u636e\uff0cw\u662f\u6743\u91cd\uff0cb\u662f\u504f\u7f6e\u3002\u6211\u4eec\u53ef\u4ee5\u5c06\u8be5\u590d\u5408\u51fd\u6570\u5206\u89e3\u4e3a\uff1a \u5e76\u8fdb\u884c\u56fe\u5f62\u5316\u8868\u793a\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u6574\u4e2a\u590d\u5408\u51fd\u6570 \ud835\udc53(\ud835\udc65; \ud835\udc64, \ud835\udc4f) \u5173\u4e8e\u53c2\u6570 \ud835\udc64 \u548c \ud835\udc4f \u7684\u5bfc\u6570\u53ef\u4ee5\u901a\u8fc7 \ud835\udc53(\ud835\udc65; \ud835\udc64, \ud835\udc4f) \u4e0e\u53c2\u6570 \ud835\udc64 \u548c \ud835\udc4f \u4e4b\u95f4\u8def\u5f84\u4e0a\u6240\u6709\u7684\u5bfc\u6570\u8fde\u4e58\u6765\u5f97\u5230\uff0c\u5373\uff1a \u4ee5w\u4e3a\u4f8b\uff0c\u5f53 \ud835\udc65 = 1, \ud835\udc64 = 0, \ud835\udc4f = 0 \u65f6\uff0c\u53ef\u4ee5\u5f97\u5230\uff1a \u6ce8\u610f\uff1a\u5e38\u7528\u51fd\u6570\u7684\u5bfc\u6570\uff1a","title":"2.2 \u94fe\u5f0f\u6cd5\u5219"},{"location":"deeplearning/section3/#23_1","text":"\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u5229\u7528\u94fe\u5f0f\u6cd5\u5219\u5bf9\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u5404\u4e2a\u8282\u70b9\u7684\u6743\u91cd\u8fdb\u884c\u66f4\u65b0\u3002\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u6765\u7ed9\u5927\u5bb6\u4ecb\u7ecd\u6574\u4e2a\u6d41\u7a0b. \u8f93\u51fa\u5c42\u6743\u91cd\uff1a \u9690\u85cf\u5c42\u6743\u91cd\uff1a \u504f\u7f6e\u66f4\u65b0\uff1a \u3010\u4e3e\u4e2a\u6817\u5b50\ud83c\udf30\uff1a\u3011 \u5982\u4e0b\u56fe\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u795e\u7ecf\u7f51\u7edc\u7528\u6765\u4e3e\u4f8b\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3asigmoid \u524d\u5411\u4f20\u64ad\u8fd0\u7b97 \uff1a \u63a5\u4e0b\u6765\u662f**\u53cd\u5411\u4f20\u64ad**\uff08\u6c42\u7f51\u7edc\u8bef\u5dee\u5bf9\u5404\u4e2a\u6743\u91cd\u53c2\u6570\u7684\u68af\u5ea6\uff09\uff1a \u6211\u4eec\u5148\u6765\u6c42\u6700\u7b80\u5355\u7684\uff0c\u6c42\u8bef\u5deeE\u5bf9w5\u7684\u5bfc\u6570\u3002\u9996\u5148\u660e\u786e\u8fd9\u662f\u4e00\u4e2a\u201c \u94fe\u5f0f\u6cd5\u5219 \u201d\u7684\u6c42\u5bfc\u8fc7\u7a0b\uff0c\u8981\u6c42\u8bef\u5deeE\u5bf9w5\u7684\u5bfc\u6570\uff0c\u9700\u8981\u5148\u6c42\u8bef\u5deeE\u5bf9out o1\u7684\u5bfc\u6570\uff0c\u518d\u6c42out o1\u5bf9net o1\u7684\u5bfc\u6570\uff0c\u6700\u540e\u518d\u6c42net o1\u5bf9w5\u7684\u5bfc\u6570\uff0c\u7ecf\u8fc7\u8fd9\u4e2a**\u94fe\u5f0f\u6cd5\u5219**\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u6c42\u51fa\u8bef\u5deeE\u5bf9w5\u7684\u5bfc\u6570\uff08\u504f\u5bfc\uff09\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5bfc\u6570\uff08\u68af\u5ea6\uff09\u5df2\u7ecf\u8ba1\u7b97\u51fa\u6765\u4e86\uff0c\u4e0b\u9762\u5c31\u662f**\u53cd\u5411\u4f20\u64ad\u4e0e\u53c2\u6570\u66f4\u65b0\u8fc7\u7a0b**\uff1a \u5982\u679c\u8981\u60f3\u6c42**\u8bef\u5deeE\u5bf9w1\u7684\u5bfc\u6570**\uff0c\u8bef\u5deeE\u5bf9w1\u7684\u6c42\u5bfc\u8def\u5f84\u4e0d\u6b62\u4e00\u6761\uff0c\u8fd9\u4f1a\u7a0d\u5fae\u590d\u6742\u4e00\u70b9\uff0c\u4f46\u6362\u6c64\u4e0d\u6362\u836f\uff0c\u8ba1\u7b97\u8fc7\u7a0b\u5982\u4e0b\u6240\u793a\uff1a \u540c\u7406\u5f97\u5230\uff1a \u6700\u540e\uff0c\u66f4\u65b0\u4e86\u6240\u6709\u7684\u6743\u91cd\uff01\u5f53\u6700\u521d\u524d\u9988\u4f20\u64ad\u65f6\u8f93\u5165\u4e3a 0.05 \u548c 0.1\uff0c\u7f51\u7edc\u4e0a\u7684\u8bef\u5dee\u662f 0.298371109\u3002\u5728\u7b2c\u4e00\u8f6e\u53cd\u5411\u4f20\u64ad\u4e4b\u540e\uff0c\u603b\u8bef\u5dee\u73b0\u5728\u4e0b\u964d\u5230 0.291027924\u3002\u5b83\u53ef\u80fd\u770b\u8d77\u6765\u4e0d\u592a\u591a\uff0c\u4f46\u662f\u5728\u91cd\u590d\u6b64\u8fc7\u7a0b 10000 \u6b21\u4e4b\u540e\uff0c\u4f8b\u5982\uff1a\u9519\u8bef\u503e\u659c\u5230 0.000035085\u3002 \u5728\u8fd9\u4e00\u70b9\u4e0a\uff0c\u5f53\u524d\u9988\u8f93\u5165\u4e3a 0.05 \u548c 0.1 \u65f6\uff0c\u4e24\u4e2a\u8f93\u51fa\u795e\u7ecf\u5143\u4ea7\u751f 0.015912196\uff08\u76f8\u5bf9\u4e8e\u76ee\u6807\u4e3a 0.01\uff09\u548c0.984065734\uff08\u76f8\u5bf9\u4e8e\u76ee\u6807\u4e3a 0.99\uff09 \u81f3\u6b64\uff0c**\u201c\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u201d**\u7684\u8fc7\u7a0b\u5c31\u8bb2\u5b8c\u4e86\u5566\uff01","title":"2.3 \u53cd\u5411\u4f20\u64ad\u7b97\u6cd5"},{"location":"deeplearning/section3/#3","text":"\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5728\u8fdb\u884c\u7f51\u7edc\u8bad\u7ec3\u65f6\uff0c\u4f1a\u9047\u5230\u978d\u70b9\uff0c\u5c40\u90e8\u6781\u5c0f\u503c\u8fd9\u4e9b\u95ee\u9898\uff0c\u90a3\u6211\u4eec\u600e\u4e48\u6539\u8fdbSGD\u5462\uff1f\u5728\u8fd9\u91cc\u6211\u4eec\u4ecb\u7ecd\u51e0\u4e2a\u6bd4\u8f83\u5e38\u7528\u7684","title":"3.\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u65b9\u6cd5"},{"location":"deeplearning/section3/#31-momentum","text":"\u52a8\u91cf\u7b97\u6cd5\u4e3b\u8981\u89e3\u51b3\u978d\u70b9\u95ee\u9898\u3002\u5728\u4ecb\u7ecd\u52a8\u91cf\u6cd5\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u6765\u770b\u4e0b\u6307\u6570\u52a0\u6743\u5e73\u5747\u6570\u7684\u8ba1\u7b97\u65b9\u6cd5\u3002","title":"3.1 \u52a8\u91cf\u7b97\u6cd5\uff08Momentum\uff09"},{"location":"deeplearning/section3/#_1","text":"\u5047\u8bbe\u7ed9\u5b9a\u4e00\u4e2a\u5e8f\u5217\uff0c\u4f8b\u5982\u5317\u4eac\u4e00\u5e74\u6bcf\u5929\u7684\u6c14\u6e29\u503c\uff0c\u56fe\u4e2d\u84dd\u8272\u7684\u70b9\u4ee3\u8868\u771f\u5b9e\u6570\u636e\uff0c \u8fd9\u65f6\u6e29\u5ea6\u503c\u6ce2\u52a8\u6bd4\u8f83\u5927\uff0c\u90a3\u6211\u4eec\u5c31\u4f7f\u7528\u52a0\u6743\u5e73\u5747\u503c\u6765\u8fdb\u884c\u5e73\u6ed1\uff0c\u5982\u4e0b\u56fe\u7ea2\u7ebf\u5c31\u662f\u5e73\u6ed1\u540e\u7684\u7ed3\u679c\uff1a \u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a \u5176\u4e2dYt\u4e3a t \u65f6\u523b\u65f6\u7684\u771f\u5b9e\u503c\uff0cSt\u4e3at\u52a0\u6743\u5e73\u5747\u540e\u7684\u503c\uff0c\u03b2\u4e3a\u6743\u91cd\u503c\u3002\u7ea2\u7ebf\u5373\u662f\u6307\u6570\u52a0\u6743\u5e73\u5747\u540e\u7684\u7ed3\u679c\u3002 \u4e0a\u56fe\u4e2d\u03b2\u8bbe\u4e3a0.9\uff0c\u90a3\u4e48\u6307\u6570\u52a0\u6743\u5e73\u5747\u7684\u8ba1\u7b97\u7ed3\u679c\u4e3a\uff1a \u90a3\u4e48\u7b2c100\u5929\u7684\u7ed3\u679c\u5c31\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a","title":"\u6307\u6570\u52a0\u6743\u5e73\u5747"},{"location":"deeplearning/section3/#_2","text":"\u52a8\u91cf\u68af\u5ea6\u4e0b\u964d\uff08Gradient Descent with Momentum\uff09\u8ba1\u7b97\u68af\u5ea6\u7684\u6307\u6570\u52a0\u6743\u5e73\u5747\u6570\uff0c\u5e76\u5229\u7528\u8be5\u503c\u6765\u66f4\u65b0\u53c2\u6570\u503c\u3002\u52a8\u91cf\u68af\u5ea6\u4e0b\u964d\u6cd5\u7684\u6574\u4e2a\u8fc7\u7a0b\u4e3a\uff0c\u5176\u4e2d\u03b2\u901a\u5e38\u8bbe\u7f6e\u4e3a0.9\uff1a \u4e0e\u539f\u59cb\u7684\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u76f8\u6bd4\uff0c\u5b83\u7684\u4e0b\u964d\u8d8b\u52bf\u66f4\u5e73\u6ed1\u3002 \u5728tf.keras\u4e2d\u4f7f\u7528Momentum\u7b97\u6cd5\u4ecd\u4f7f\u7528\u529f\u80fdSGD\u65b9\u6cd5\uff0c\u4f46\u8981\u8bbe\u7f6emomentum\u53c2\u6570\uff0c\u5b9e\u73b0\u8fc7\u7a0b\u5982\u4e0b\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5\uff1aSGD \u6307\u5b9a\u53c2\u6570beta=0.9 opt = tf . keras . optimizers . SGD ( learning_rate = 0.1 , momentum = 0.9 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570\uff0c\u521d\u59cb\u503c var = tf . Variable ( 1.0 ) val0 = var . value () # \u5b9a\u4e49\u635f\u5931\u51fd\u6570 loss = lambda : ( var ** 2 ) / 2.0 #\u7b2c\u4e00\u6b21\u66f4\u65b0\uff1a\u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c\u6b65\u957f\u4e3a `- learning_rate * grad` opt . minimize ( loss , [ var ]) . numpy () val1 = var . value () # \u7b2c\u4e8c\u6b21\u66f4\u65b0\uff1a\u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c\u56e0\u4e3a\u52a0\u5165\u4e86momentum,\u6b65\u957f\u4f1a\u589e\u52a0 opt . minimize ( loss , [ var ]) . numpy () val2 = var . value () # \u6253\u5370\u4e24\u6b21\u66f4\u65b0\u7684\u6b65\u957f print ( \"\u7b2c\u4e00\u6b21\u66f4\u65b0\u6b65\u957f= {} \" . format (( val0 - val1 ) . numpy ())) print ( \"\u7b2c\u4e8c\u6b21\u66f4\u65b0\u6b65\u957f= {} \" . format (( val1 - val2 ) . numpy ())) \u7ed3\u679c\u4e3a\uff1a \u7b2c\u4e00\u6b21\u66f4\u65b0\u6b65\u957f = 0.10000002384185791 \u7b2c\u4e8c\u6b21\u66f4\u65b0\u6b65\u957f = 0.18000000715255737 \u53e6\u5916\u8fd8\u6709\u4e00\u79cd\u52a8\u91cf\u7b97\u6cd5Nesterov accelerated gradient(NAG)\uff0c\u4f7f\u7528\u4e86\u6839\u636e\u52a8\u91cf\u9879**\u9884\u5148\u4f30\u8ba1**\u7684\u53c2\u6570\uff0c\u5728Momentum\u7684\u57fa\u7840\u4e0a\u8fdb\u4e00\u6b65\u52a0\u5feb\u6536\u655b\uff0c\u63d0\u9ad8\u54cd\u5e94\u6027\uff0c\u8be5\u7b97\u6cd5\u5b9e\u73b0\u4f9d\u7136\u4f7f\u7528SGD\u65b9\u6cd5\uff0c\u8981\u8bbe\u7f6enesterov\u8bbe\u7f6e\u4e3atrue.","title":"\u52a8\u91cf\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5"},{"location":"deeplearning/section3/#32-adagrad","text":"AdaGrad\u7b97\u6cd5\u4f1a\u4f7f\u7528\u4e00\u4e2a\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6 g_t \u6309\u5143\u7d20\u5e73\u65b9\u7684\u7d2f\u52a0\u53d8\u91cfst\u3002\u5728\u9996\u6b21\u8fed\u4ee3\u65f6\uff0cAdaGrad\u5c06s0\u4e2d\u6bcf\u4e2a\u5143\u7d20\u521d\u59cb\u5316\u4e3a0\u3002\u5728t\u6b21\u8fed\u4ee3\uff0c\u9996\u5148\u5c06\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6gt\u6309\u5143\u7d20\u5e73\u65b9\u540e\u7d2f\u52a0\u5230\u53d8\u91cfst\uff1a \u5176\u4e2d\u2299\u662f\u6309\u5143\u7d20\u76f8\u4e58\u3002\u63a5\u7740\uff0c\u6211\u4eec\u5c06\u76ee\u6807\u51fd\u6570\u81ea\u53d8\u91cf\u4e2d\u6bcf\u4e2a\u5143\u7d20\u7684\u5b66\u4e60\u7387\u901a\u8fc7\u6309\u5143\u7d20\u8fd0\u7b97\u91cd\u65b0\u8c03\u6574\u4e00\u4e0b\uff1a \u5176\u4e2d\u03b1\u662f\u5b66\u4e60\u7387\uff0c\u03f5\u662f\u4e3a\u4e86\u7ef4\u6301\u6570\u503c\u7a33\u5b9a\u6027\u800c\u6dfb\u52a0\u7684\u5e38\u6570\uff0c\u5982 10^{-6} 10^{-6} <span><span class=\"MathJax_Preview\">10^{-6}</span><script type=\"math/tex\">10^{-6} \u3002\u8fd9\u91cc\u5f00\u65b9\u3001\u9664\u6cd5\u548c\u4e58\u6cd5\u7684\u8fd0\u7b97\u90fd\u662f\u6309\u5143\u7d20\u8fd0\u7b97\u7684\u3002\u8fd9\u4e9b\u6309\u5143\u7d20\u8fd0\u7b97\u4f7f\u5f97\u76ee\u6807\u51fd\u6570\u81ea\u53d8\u91cf\u4e2d\u6bcf\u4e2a\u5143\u7d20\u90fd\u5206\u522b\u62e5\u6709\u81ea\u5df1\u7684\u5b66\u4e60\u7387\u3002 \u5728tf.keras\u4e2d\u7684\u5b9e\u73b0\u65b9\u6cd5\u662f\uff1a tf . keras . optimizers . Adagrad ( learning_rate = 0.001 , initial_accumulator_value = 0.1 , epsilon = 1e-07 ) \u4f8b\u5b50\u662f\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5\uff1aSGD opt = tf . keras . optimizers . Adagrad ( learning_rate = 0.1 , initial_accumulator_value = 0.1 , epsilon = 1e-07 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570 var = tf . Variable ( 1.0 ) # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff1a\u65e0\u53c2\u4f46\u6709\u8fd4\u56de\u503c def loss (): return ( var ** 2 ) / 2.0 # \u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c opt . minimize ( loss , [ var ]) . numpy () # \u5c55\u793a\u53c2\u6570\u66f4\u65b0\u7ed3\u679c var . numpy ()","title":"3.2 AdaGrad"},{"location":"deeplearning/section3/#33-rmsprop","text":"AdaGrad\u7b97\u6cd5\u5728\u8fed\u4ee3\u540e\u671f\u7531\u4e8e\u5b66\u4e60\u7387\u8fc7\u5c0f,\u80fd\u8f83\u96be\u627e\u5230\u6700\u4f18\u89e3\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0cRMSProp\u7b97\u6cd5\u5bf9AdaGrad\u7b97\u6cd5\u505a\u4e86\u4e00\u70b9\u5c0f\u5c0f\u7684\u4fee\u6539\u3002 \u4e0d\u540c\u4e8eAdaGrad\u7b97\u6cd5\u91cc\u72b6\u6001\u53d8\u91cfst\u662f\u622a\u81f3\u65f6\u95f4\u6b65t\u6240\u6709\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6gt\u6309\u5143\u7d20\u5e73\u65b9\u548c\uff0cRMSProp\uff08Root Mean Square Prop\uff09\u7b97\u6cd5\u5c06\u8fd9\u4e9b\u68af\u5ea6\u6309\u5143\u7d20\u5e73\u65b9\u505a\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747 \u5176\u4e2d\u03f5\u662f\u4e00\u6837\u4e3a\u4e86\u7ef4\u6301\u6570\u503c\u7a33\u5b9a\u4e00\u4e2a\u5e38\u6570\u3002\u6700\u7ec8\u81ea\u53d8\u91cf\u6bcf\u4e2a\u5143\u7d20\u7684\u5b66\u4e60\u7387\u5728\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\u5c31\u4e0d\u518d\u4e00\u76f4\u964d\u4f4e\u3002RMSProp \u6709\u52a9\u4e8e\u51cf\u5c11\u62b5\u8fbe\u6700\u5c0f\u503c\u8def\u5f84\u4e0a\u7684\u6446\u52a8\uff0c\u5e76\u5141\u8bb8\u4f7f\u7528\u4e00\u4e2a\u66f4\u5927\u7684\u5b66\u4e60\u7387 \u03b1\uff0c\u4ece\u800c\u52a0\u5feb\u7b97\u6cd5\u5b66\u4e60\u901f\u5ea6\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u65f6\uff0c\u4f7f\u7528\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . optimizers . RMSprop ( learning_rate = 0.001 , rho = 0.9 , momentum = 0.0 , epsilon = 1e-07 , centered = False , name = 'RMSprop' , ** kwargs ) \u4f8b\u5b50\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5RMSprop opt = tf . keras . optimizers . RMSprop ( learning_rate = 0.1 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570 var = tf . Variable ( 1.0 ) # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff1a\u65e0\u53c2\u4f46\u6709\u8fd4\u56de\u503c def loss (): return ( var ** 2 ) / 2.0 # \u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c opt . minimize ( loss , [ var ]) . numpy () # \u5c55\u793a\u53c2\u6570\u66f4\u65b0\u7ed3\u679c var . numpy () \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a 0.6837723","title":"3.3 RMSprop"},{"location":"deeplearning/section3/#34-adam","text":"Adam \u4f18\u5316\u7b97\u6cd5\uff08Adaptive Moment Estimation\uff0c\u81ea\u9002\u5e94\u77e9\u4f30\u8ba1\uff09\u5c06 Momentum \u548c RMSProp \u7b97\u6cd5\u7ed3\u5408\u5728\u4e00\u8d77\u3002Adam\u7b97\u6cd5\u5728RMSProp\u7b97\u6cd5\u57fa\u7840\u4e0a\u5bf9\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6\u4e5f\u505a\u4e86\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747\u3002 \u5047\u8bbe\u7528\u6bcf\u4e00\u4e2a mini-batch \u8ba1\u7b97 dW\u3001db\uff0c\u7b2ct\u6b21\u8fed\u4ee3\u65f6\uff1a \u5176\u4e2dl\u4e3a\u67d0\u4e00\u5c42\uff0ct\u4e3a\u79fb\u52a8\u5e73\u5747\u7b2c\u6b21\u7684\u503c Adam \u7b97\u6cd5\u7684\u53c2\u6570\u66f4\u65b0\uff1a \u5efa\u8bae\u7684\u53c2\u6570\u8bbe\u7f6e\u7684\u503c\uff1a \u5b66\u4e60\u7387\u03b1\uff1a \u9700\u8981\u5c1d\u8bd5\u4e00\u7cfb\u5217\u7684\u503c\uff0c\u6765\u5bfb\u627e\u6bd4\u8f83\u5408\u9002\u7684 \u03b21\uff1a\u5e38\u7528\u7684\u7f3a\u7701\u503c\u4e3a 0.9 \u03b22\uff1a\u5efa\u8bae\u4e3a 0.999 \u03f5\uff1a\u9ed8\u8ba4\u503c1e-8 \u5728tf.keras\u4e2d\u5b9e\u73b0\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . optimizers . Adam ( learning_rate = 0.001 , beta_1 = 0.9 , beta_2 = 0.999 , epsilon = 1e-07 ) \u4f8b\u5b50\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5Adam opt = tf . keras . optimizers . Adam ( learning_rate = 0.1 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570 var = tf . Variable ( 1.0 ) # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff1a\u65e0\u53c2\u4f46\u6709\u8fd4\u56de\u503c def loss (): return ( var ** 2 ) / 2.0 # \u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c opt . minimize ( loss , [ var ]) . numpy () # \u5c55\u793a\u53c2\u6570\u66f4\u65b0\u7ed3\u679c var . numpy () \u7ed3\u679c\u4e3a\uff1a 0.90000033","title":"3.4 Adam"},{"location":"deeplearning/section3/#4","text":"\u5728\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u65f6\uff0c\u4e00\u822c\u60c5\u51b5\u4e0b\u5b66\u4e60\u7387\u90fd\u4f1a\u968f\u7740\u8bad\u7ec3\u800c\u53d8\u5316\uff0c\u8fd9\u4e3b\u8981\u662f\u7531\u4e8e\uff0c\u5728\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u7684\u540e\u671f\uff0c\u5982\u679c\u5b66\u4e60\u7387\u8fc7\u9ad8\uff0c\u4f1a\u9020\u6210loss\u7684\u632f\u8361\uff0c\u4f46\u662f\u5982\u679c\u5b66\u4e60\u7387\u51cf\u5c0f\u7684\u8fc7\u5feb\uff0c\u53c8\u4f1a\u9020\u6210\u6536\u655b\u53d8\u6162\u7684\u60c5\u51b5\u3002","title":"4.\u5b66\u4e60\u7387\u9000\u706b"},{"location":"deeplearning/section3/#41","text":"\u5206\u6bb5\u5e38\u6570\u8870\u51cf\u662f\u5728\u4e8b\u5148\u5b9a\u4e49\u597d\u7684\u8bad\u7ec3\u6b21\u6570\u533a\u95f4\u4e0a\uff0c\u8bbe\u7f6e\u4e0d\u540c\u7684\u5b66\u4e60\u7387\u5e38\u6570\u3002\u521a\u5f00\u59cb\u5b66\u4e60\u7387\u5927\u4e00\u4e9b\uff0c\u4e4b\u540e\u8d8a\u6765\u8d8a\u5c0f\uff0c\u533a\u95f4\u7684\u8bbe\u7f6e\u9700\u8981\u6839\u636e\u6837\u672c\u91cf\u8c03\u6574\uff0c\u4e00\u822c\u6837\u672c\u91cf\u8d8a\u5927\u533a\u95f4\u95f4\u9694\u5e94\u8be5\u8d8a\u5c0f\u3002 \u5728tf.keras\u4e2d\u5bf9\u5e94\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . optimizers . schedules . PiecewiseConstantDecay ( boundaries , values ) \u53c2\u6570\uff1a Boundaries: \u8bbe\u7f6e\u5206\u6bb5\u66f4\u65b0\u7684step\u503c Values: \u9488\u5bf9\u4e0d\u7528\u5206\u6bb5\u7684\u5b66\u4e60\u7387\u503c \u4f8b\u5b50\uff1a\u5bf9\u4e8e\u524d100000\u6b65\uff0c\u5b66\u4e60\u7387\u4e3a1.0\uff0c\u5bf9\u4e8e\u63a5\u4e0b\u6765\u7684100000-110000\u6b65\uff0c\u5b66\u4e60\u7387\u4e3a0.5\uff0c\u4e4b\u540e\u7684\u6b65\u9aa4\u5b66\u4e60\u7387\u4e3a0.1 # \u8bbe\u7f6e\u7684\u5206\u6bb5\u7684step\u503c boundaries = [ 100000 , 110000 ] # \u4e0d\u540c\u7684step\u5bf9\u5e94\u7684\u5b66\u4e60\u7387 values = [ 1.0 , 0.5 , 0.1 ] # \u5b9e\u4f8b\u5316\u8fdb\u884c\u5b66\u4e60\u7684\u66f4\u65b0 learning_rate_fn = keras . optimizers . schedules . PiecewiseConstantDecay ( boundaries , values )","title":"4.1 \u5206\u6bb5\u5e38\u6570\u8870\u51cf"},{"location":"deeplearning/section3/#42","text":"\u6307\u6570\u8870\u51cf\u53ef\u4ee5\u7528\u5982\u4e0b\u7684\u6570\u5b66\u516c\u5f0f\u8868\u793a, \u5176\u4e2d\uff0ct\u8868\u793a\u8fed\u4ee3\u6b21\u6570\uff0c\u03b10,k\u662f\u8d85\u53c2\u6570 \u5728tf.keras\u4e2d\u7684\u5b9e\u73b0\u662f\uff1a tf . keras . optimizers . schedules . ExponentialDecay ( initial_learning_rate , decay_steps , decay_rate ) \u5177\u4f53\u7684\u5b9e\u73b0\u662f\uff1a def decayed_learning_rate ( step ): return initial_learning_rate * decay_rate ^ ( step / decay_steps ) \u53c2\u6570\uff1a Initial_learning_rate: \u521d\u59cb\u5b66\u4e60\u7387\uff0c\u03b10 decay_steps: k\u503c decay_rate: \u6307\u6570\u7684\u5e95","title":"4.2 \u6307\u6570\u8870\u51cf"},{"location":"deeplearning/section3/#43-1t","text":"1/t\u8870\u51cf\u53ef\u4ee5\u7528\u5982\u4e0b\u7684\u6570\u5b66\u516c\u5f0f\u8868\u793a\uff1a \u5176\u4e2d\uff0ct\u8868\u793a\u8fed\u4ee3\u6b21\u6570\uff0c\u03b10,k\u662f\u8d85\u53c2\u6570 \u5728tf.keras\u4e2d\u7684\u5b9e\u73b0\u662f\uff1a tf . keras . optimizers . schedules . InverseTimeDecay ( initial_learning_rate , decay_steps , decay_rate ) \u5177\u4f53\u7684\u5b9e\u73b0\u662f\uff1a def decayed_learning_rate ( step ): return initial_learning_rate / ( 1 + decay_rate * step / decay_step ) \u53c2\u6570\uff1a Initial_learning_rate: \u521d\u59cb\u5b66\u4e60\u7387\uff0c\u03b10 decay_step/decay_steps: k\u503c \u603b\u7ed3 \u77e5\u9053\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5 \u4e00\u79cd\u5bfb\u627e\u4f7f\u635f\u5931\u51fd\u6570\u6700\u5c0f\u5316\u7684\u65b9\u6cd5\uff1a\u6279\u91cf\u68af\u5ea6\u4e0b\u964d\uff0c\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff0c\u5c0f\u6279\u91cf\u68af\u5ea6\u4e0b\u964d \u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u94fe\u5f0f\u6cd5\u5219 \u590d\u5408\u51fd\u6570\u7684\u6c42\u5bfc \u638c\u63e1\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff08BP\u7b97\u6cd5\uff09 \u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u53c2\u6570\u66f4\u65b0\u7684\u65b9\u6cd5 \u77e5\u9053\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u7684\u4f18\u5316\u65b9\u6cd5 \u52a8\u91cf\u7b97\u6cd5\uff0cadaGrad,RMSProp,Adam \u4e86\u89e3\u5b66\u4e60\u7387\u9000\u706b \u5206\u6bb5\u5e38\u6570\u8870\u51cf\uff0c\u6307\u6570\u8870\u51cf\uff0c1/t\u8870\u51cf","title":"4.3 1/t\u8870\u51cf"},{"location":"deeplearning/section4/","text":"2.4 \u6df1\u5ea6\u5b66\u4e60\u6b63\u5219\u5316 \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053L2\u6b63\u5219\u5316\u4e0eL1\u6b63\u5219\u5316\u7684\u65b9\u6cd5 \u77e5\u9053\u968f\u673a\u5931\u6d3bdroupout\u7684\u5e94\u7528 \u77e5\u9053\u63d0\u524d\u505c\u6b62\u7684\u4f7f\u7528\u65b9\u6cd5 \u77e5\u9053BN\u5c42\u7684\u4f7f\u7528\u65b9\u6cd5 \u5728\u8bbe\u8ba1\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u65f6\u4e0d\u4ec5\u8981\u6c42\u5728\u8bad\u7ec3\u96c6\u4e0a\u8bef\u5dee\u5c0f\uff0c\u800c\u4e14\u5e0c\u671b\u5728\u65b0\u6837\u672c\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u5f3a\u3002\u8bb8\u591a\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u90fd\u91c7\u7528\u76f8\u5173\u7684\u7b56\u7565\u6765\u51cf\u5c0f\u6d4b\u8bd5\u8bef\u5dee\uff0c\u8fd9\u4e9b\u7b56\u7565\u88ab\u7edf\u79f0\u4e3a\u6b63\u5219\u5316\u3002\u56e0\u4e3a\u795e\u7ecf\u7f51\u7edc\u7684\u5f3a\u5927\u7684\u8868\u793a\u80fd\u529b\u7ecf\u5e38\u9047\u5230\u8fc7\u62df\u5408\uff0c\u6240\u4ee5\u9700\u8981\u4f7f\u7528\u4e0d\u540c\u5f62\u5f0f\u7684\u6b63\u5219\u5316\u7b56\u7565\u3002 \u6b63\u5219\u5316\u901a\u8fc7\u5bf9\u7b97\u6cd5\u7684\u4fee\u6539\u6765\u51cf\u5c11\u6cdb\u5316\u8bef\u5dee\uff0c\u76ee\u524d\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u4f7f\u7528\u8f83\u591a\u7684\u7b56\u7565\u6709\u53c2\u6570\u8303\u6570\u60e9\u7f5a\uff0c\u63d0\u524d\u7ec8\u6b62\uff0cDropOut\u7b49\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u5bf9\u5176\u8fdb\u884c\u8be6\u7ec6\u7684\u4ecb\u7ecd\u3002 1. L1\u4e0eL2\u6b63\u5219\u5316(\u56de\u987e) \u00b6 L1\u548cL2\u662f\u6700\u5e38\u89c1\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u3002\u5b83\u4eec\u5728\u635f\u5931\u51fd\u6570\uff08cost function\uff09\u4e2d\u589e\u52a0\u4e00\u4e2a\u6b63\u5219\u9879\uff0c\u7531\u4e8e\u6dfb\u52a0\u4e86\u8fd9\u4e2a\u6b63\u5219\u5316\u9879\uff0c\u6743\u91cd\u77e9\u9635\u7684\u503c\u51cf\u5c0f\uff0c\u56e0\u4e3a\u5b83\u5047\u5b9a\u5177\u6709\u66f4\u5c0f\u6743\u91cd\u77e9\u9635\u7684\u795e\u7ecf\u7f51\u7edc\u5bfc\u81f4\u66f4\u7b80\u5355\u7684\u6a21\u578b\u3002 \u56e0\u6b64\uff0c\u5b83\u4e5f\u4f1a\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u51cf\u5c11\u8fc7\u62df\u5408\u3002\u7136\u800c\uff0c\u8fd9\u4e2a\u6b63\u5219\u5316\u9879\u5728L1\u548cL2\u4e2d\u662f\u4e0d\u540c\u7684\u3002 L2\u6b63\u5219\u5316 \u8fd9\u91cc\u7684\u03bb\u662f\u6b63\u5219\u5316\u53c2\u6570\uff0c\u5b83\u662f\u4e00\u4e2a\u9700\u8981\u4f18\u5316\u7684\u8d85\u53c2\u6570\u3002L2\u6b63\u5219\u5316\u53c8\u79f0\u4e3a\u6743\u91cd\u8870\u51cf\uff0c\u56e0\u4e3a\u5176\u5bfc\u81f4\u6743\u91cd\u8d8b\u5411\u4e8e0\uff08\u4f46\u4e0d\u5168\u662f0\uff09 L1\u6b63\u5219\u5316 \u8fd9\u91cc\uff0c\u6211\u4eec\u60e9\u7f5a\u6743\u91cd\u77e9\u9635\u7684\u7edd\u5bf9\u503c\u3002\u5176\u4e2d\uff0c\u03bb \u4e3a\u6b63\u5219\u5316\u53c2\u6570\uff0c\u662f\u8d85\u53c2\u6570\uff0c\u4e0d\u540c\u4e8eL2\uff0c\u6743\u91cd\u503c\u53ef\u80fd\u88ab\u51cf\u5c11\u52300.\u56e0\u6b64\uff0cL1\u5bf9\u4e8e\u538b\u7f29\u6a21\u578b\u5f88\u6709\u7528\u3002\u5176\u5b83\u60c5\u51b5\u4e0b\uff0c\u4e00\u822c\u9009\u62e9\u4f18\u5148\u9009\u62e9L2\u6b63\u5219\u5316\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u4f7f\u7528\u7684\u65b9\u6cd5\u662f\uff1a L1\u6b63\u5219\u5316 tf . keras . regularizers . L1 ( l1 = 0.01 ) \u0015L2\u6b63\u5219\u5316 tf . keras . regularizers . L2 ( l2 = 0.01 ) L1L2\u6b63\u5219\u5316 tf . keras . regularizers . L1L2 ( l1 = 0.0 , l2 = 0.0 ) \u6211\u4eec\u76f4\u63a5\u5728\u67d0\u4e00\u5c42\u7684layers\u4e2d\u6307\u660e\u6b63\u5219\u5316\u7c7b\u578b\u548c\u8d85\u53c2\u6570\u5373\u53ef\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf from tensorflow.keras import regularizers # \u521b\u5efa\u6a21\u578b model = tf . keras . models . Sequential () # L2\u6b63\u5219\u5316\uff0clambda\u4e3a0.01 model . add ( tf . keras . layers . Dense ( 16 , kernel_regularizer = regularizers . l2 ( 0.001 ), activation = 'relu' , input_shape = ( 10 ,))) # L1\u6b63\u5219\u5316\uff0clambda\u4e3a0.01 model . add ( tf . keras . layers . Dense ( 16 , kernel_regularizer = regularizers . l1 ( 0.001 ), activation = 'relu' )) # L1L2\u6b63\u5219\u5316\uff0clambda1\u4e3a0.01,lambda2\u4e3a0.01 model . add ( tf . keras . layers . Dense ( 16 , kernel_regularizer = regularizers . L1L2 ( 0.001 , 0.01 ), activation = 'relu' )) 2.Dropout\u6b63\u5219\u5316 \u00b6 dropout\u662f\u5728\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u6700\u5e38\u7528\u7684\u6b63\u5219\u5316\u6280\u672f\u3002Dropout\u7684\u539f\u7406\u5f88\u7b80\u5355\uff1a\u5047\u8bbe\u6211\u4eec\u7684\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff0c\u5728\u6bcf\u4e2a\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\uff0c\u968f\u673a\u9009\u62e9\u67d0\u4e9b\u8282\u70b9\uff0c\u5e76\u4e14\u5220\u9664\u524d\u5411\u548c\u540e\u5411\u8fde\u63a5\u3002 \u56e0\u6b64\uff0c\u6bcf\u4e2a\u8fed\u4ee3\u8fc7\u7a0b\u90fd\u4f1a\u6709\u4e0d\u540c\u7684\u8282\u70b9\u7ec4\u5408\uff0c\u4ece\u800c\u5bfc\u81f4\u4e0d\u540c\u7684\u8f93\u51fa\uff0c\u8fd9\u53ef\u4ee5\u770b\u6210\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u96c6\u6210\u65b9\u6cd5\uff08ensemble technique\uff09\u3002\u96c6\u6210\u6a21\u578b\u4e00\u822c\u4f18\u4e8e\u5355\u4e00\u6a21\u578b\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ef\u4ee5\u6355\u83b7\u66f4\u591a\u7684\u968f\u673a\u6027\u3002\u76f8\u4f3c\u5730\uff0cdropout\u4f7f\u5f97\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4f18\u4e8e\u6b63\u5e38\u7684\u6a21\u578b\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u4f7f\u7528\u7684\u65b9\u6cd5\u662fdropout\uff1a tf . keras . layers . Dropout ( rate ) \u53c2\u6570\uff1a rate\uff1a \u6bcf\u4e00\u4e2a\u795e\u7ecf\u5143\u88ab\u4e22\u5f03\u7684\u6982\u7387 \u4f8b\u5b50\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5e93 import numpy as np import tensorflow as tf # \u5b9a\u4e49dropout\u5c42,\u6bcf\u4e00\u4e2a\u795e\u7ecf\u5143\u67090.2\u7684\u6982\u7387\u88ab\u5931\u6d3b\uff0c\u672a\u88ab\u5931\u6d3b\u7684\u8f93\u5165\u5c06\u63091 /\uff081-rate\uff09\u653e\u5927 layer = tf . keras . layers . Dropout ( 0.2 , input_shape = ( 2 ,)) # \u5b9a\u4e49\u4e94\u4e2a\u6279\u6b21\u7684\u6570\u636e data = np . arange ( 1 , 11 ) . reshape ( 5 , 2 ) . astype ( np . float32 ) # \u539f\u59cb\u6570\u636e\u8fdb\u884c\u6253\u5370 print ( data ) # \u8fdb\u884c\u968f\u673a\u5931\u6d3b\uff1a\u5728training\u6a21\u5f0f\u4e2d\uff0c\u8fd4\u56de\u5e94\u7528dropout\u540e\u7684\u8f93\u51fa\uff1b\u6216\u8005\u5728\u975etraining\u6a21\u5f0f\u4e0b\uff0c\u6b63\u5e38\u8fd4\u56de\u8f93\u51fa\uff08\u6ca1\u6709dropout\uff09 outputs = layer ( data , training = True ) # \u6253\u5370\u5931\u6d3b\u540e\u7684\u7ed3\u679c print ( outputs ) \u7ed3\u679c\u4e3a\uff1a [[ 1. 2. ] [ 3. 4. ] [ 5. 6. ] [ 7. 8. ] [ 9. 10. ]] tf . Tensor ( [[ 1.25 2.5 ] [ 0. 5. ] [ 6.25 7.5 ] [ 8.75 10. ] [ 0. 12.5 ]], shape = ( 5 , 2 ), dtype = float32 ) 3.\u63d0\u524d\u505c\u6b62 \u00b6 \u63d0\u524d\u505c\u6b62\uff08early stopping\uff09\u662f\u5c06\u4e00\u90e8\u5206\u8bad\u7ec3\u96c6\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\uff08validation set\uff09\u3002 \u5f53\u9a8c\u8bc1\u96c6\u7684\u6027\u80fd\u8d8a\u6765\u8d8a\u5dee\u65f6\u6216\u8005\u6027\u80fd\u4e0d\u518d\u63d0\u5347\uff0c\u5219\u7acb\u5373\u505c\u6b62\u5bf9\u8be5\u6a21\u578b\u7684\u8bad\u7ec3\u3002 \u8fd9\u88ab\u79f0\u4e3a\u63d0\u524d\u505c\u6b62\u3002 \u5728\u4e0a\u56fe\u4e2d\uff0c\u5728\u865a\u7ebf\u5904\u505c\u6b62\u6a21\u578b\u7684\u8bad\u7ec3\uff0c\u6b64\u65f6\u6a21\u578b\u5f00\u59cb\u5728\u8bad\u7ec3\u6570\u636e\u4e0a\u8fc7\u62df\u5408\u3002 \u5728tf.keras\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528callbacks\u51fd\u6570\u5b9e\u73b0\u65e9\u671f\u505c\u6b62: tf . keras . callbacks . EarlyStopping ( monitor = 'val_loss' , patience = 5 ) \u4e0a\u9762\uff0cmonitor\u53c2\u6570\u8868\u793a\u76d1\u6d4b\u91cf\uff0c\u8fd9\u91ccval_loss\u8868\u793a\u9a8c\u8bc1\u96c6\u635f\u5931\u3002\u800cpatience\u53c2\u6570epochs\u6570\u91cf\uff0c\u5f53\u5728\u8fd9\u4e2a\u8fc7\u7a0b\u6027\u80fd\u65e0\u63d0\u5347\u65f6\u4f1a\u505c\u6b62\u8bad\u7ec3\u3002\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\uff0c\u8ba9\u6211\u4eec\u518d\u770b\u770b\u4e0a\u9762\u7684\u56fe\u7247\u3002 \u5728\u865a\u7ebf\u4e4b\u540e\uff0c\u6bcf\u4e2aepoch\u90fd\u4f1a\u5bfc\u81f4\u66f4\u9ad8\u7684\u9a8c\u8bc1\u96c6\u8bef\u5dee\u3002 \u56e0\u6b64\uff0c\u865a\u7ebf\u540epatience\u4e2aepoch\uff0c\u6a21\u578b\u5c06\u505c\u6b62\u8bad\u7ec3\uff0c\u56e0\u4e3a\u6ca1\u6709\u8fdb\u4e00\u6b65\u7684\u6539\u5584\u3002 # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import numpy as np # \u5f53\u8fde\u7eed3\u4e2aepoch loss\u4e0d\u4e0b\u964d\u5219\u505c\u6b62\u8bad\u7ec3 callback = tf . keras . callbacks . EarlyStopping ( monitor = 'loss' , patience = 3 ) # \u5b9a\u4e49\u53ea\u6709\u4e00\u5c42\u7684\u795e\u7ecf\u7f51\u7edc model = tf . keras . models . Sequential ([ tf . keras . layers . Dense ( 10 )]) # \u8bbe\u7f6e\u635f\u5931\u51fd\u6570\u548c\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5 model . compile ( tf . keras . optimizers . SGD (), loss = 'mse' ) # \u6a21\u578b\u8bad\u7ec3 history = model . fit ( np . arange ( 100 ) . reshape ( 5 , 20 ), np . array ([ 0 , 1 , 2 , 1 , 2 ]), epochs = 10 , batch_size = 1 , callbacks = [ callback ], verbose = 1 ) # \u6253\u5370\u8fd0\u884c\u7684epoch len ( history . history [ 'loss' ]) \u8f93\u51fa\uff1a Epoch 1 / 10 5 / 5 [ ============================== ] - 0 s 600 us / step - loss : 145774557280600064.0000 Epoch 2 / 10 5 / 5 [ ============================== ] - 0 s 522 us / step - loss : 10077891596456623723194184833695744.0000 Epoch 3 / 10 5 / 5 [ ============================== ] - 0 s 1 ms / step - loss : inf Epoch 4 / 10 5 / 5 [ ============================== ] - 0 s 1 ms / step - loss : inf # \u53ea\u8fd0\u884c\u4e864\u6b21 4 4. \u6279\u6807\u51c6\u5316 \u00b6 \u6279\u6807\u51c6\u5316(BN\u5c42,Batch Normalization)\u662f2015\u5e74\u63d0\u51fa\u7684\u4e00\u79cd\u65b9\u6cd5\uff0c\u5728\u8fdb\u884c\u6df1\u5ea6\u7f51\u7edc\u8bad\u7ec3\u65f6\uff0c\u5927\u591a\u4f1a\u91c7\u53d6\u8fd9\u79cd\u7b97\u6cd5\uff0c\u4e0e\u5168\u8fde\u63a5\u5c42\u4e00\u6837\uff0cBN\u5c42\u4e5f\u662f\u5c5e\u4e8e\u7f51\u7edc\u4e2d\u7684\u4e00\u5c42\u3002 BN\u5c42\u662f\u9488\u5bf9\u5355\u4e2a\u795e\u7ecf\u5143\u8fdb\u884c\uff0c\u5229\u7528\u7f51\u7edc\u8bad\u7ec3\u65f6\u4e00\u4e2a mini-batch \u7684\u6570\u636e\u6765\u8ba1\u7b97\u8be5\u795e\u7ecf\u5143xi \u7684\u5747\u503c\u548c\u65b9\u5dee,\u5f52\u4e00\u5316\u540e\u5e76\u91cd\u6784\uff0c\u56e0\u800c\u79f0\u4e3a Batch Normalization\u3002\u5728\u6bcf\u4e00\u5c42\u8f93\u5165\u4e4b\u524d\uff0c\u5c06\u6570\u636e\u8fdb\u884cBN\uff0c\u7136\u540e\u518d\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u5b66\u4e60\uff1a \u9996\u5148\u6211\u4eec\u5bf9\u67d0\u4e00\u6279\u6b21\u7684\u6570\u636e\u7684\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u8fdb\u884c\u6807\u51c6\u5316\uff0c \u7136\u540e\u5728\u4f7f\u7528\u53d8\u6362\u91cd\u6784\uff0c\u5f15\u5165\u4e86\u53ef\u5b66\u4e60\u53c2\u6570\u03b3\u3001\u03b2\uff0c\u5982\u679c\u5404\u9690\u85cf\u5c42\u7684\u8f93\u5165\u5747\u503c\u5728\u9760\u8fd10\u7684\u533a\u57df\uff0c\u5373\u5904\u4e8e\u6fc0\u6d3b\u51fd\u6570\u7684\u7ebf\u6027\u533a\u57df\uff0c\u4e0d\u5229\u4e8e\u8bad\u7ec3\u975e\u7ebf\u6027\u795e\u7ecf\u7f51\u7edc\uff0c\u4ece\u800c\u5f97\u5230\u6548\u679c\u8f83\u5dee\u7684\u6a21\u578b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u7528 \u03b3 \u548c \u03b2 \u5bf9\u6807\u51c6\u5316\u540e\u7684\u7ed3\u679c\u505a\u8fdb\u4e00\u6b65\u5904\u7406\uff1a \u8fd9\u5c31\u662fBN\u5c42\u6700\u540e\u7684\u7ed3\u679c\u3002\u6574\u4f53\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5728tf.keras\u4e2d\u5b9e\u73b0\u4f7f\u7528\uff1a # \u76f4\u63a5\u5c06\u5176\u653e\u5165\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u7684\u7ed3\u6784\u4e2d\u5373\u53ef tf . keras . layers . BatchNormalization ( epsilon = 0.001 , center = True , scale = True , beta_initializer = 'zeros' , gamma_initializer = 'ones' , ) 3.2.8 \u603b\u7ed3 \u00b6 \u77e5\u9053L2\u6b63\u5219\u5316\u4e0eL1\u6b63\u5219\u5316\u7684\u65b9\u6cd5 \u5728\u635f\u5931\u51fd\u6570\uff08cost function\uff09\u4e2d\u589e\u52a0\u4e00\u4e2a\u6b63\u5219\u9879\uff0c\u7531\u4e8e\u6dfb\u52a0\u4e86\u8fd9\u4e2a\u6b63\u5219\u5316\u9879\uff0c\u6743\u91cd\u77e9\u9635\u7684\u503c\u51cf\u5c0f\uff0c\u56e0\u4e3a\u5b83\u5047\u5b9a\u5177\u6709\u66f4\u5c0f\u6743\u91cd\u77e9\u9635\u7684\u795e\u7ecf\u7f51\u7edc\u5bfc\u81f4\u66f4\u7b80\u5355\u7684\u6a21\u578b \u77e5\u9053\u968f\u673a\u5931\u6d3bdroupout\u7684\u5e94\u7528 \u5728\u6bcf\u4e2a\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\uff0c\u968f\u673a\u9009\u62e9\u67d0\u4e9b\u8282\u70b9\uff0c\u5e76\u4e14\u5220\u9664\u524d\u5411\u548c\u540e\u5411\u8fde\u63a5 \u77e5\u9053\u63d0\u524d\u505c\u6b62\u7684\u4f7f\u7528\u65b9\u6cd5 \u5f53\u770b\u5230\u9a8c\u8bc1\u96c6\u7684\u6027\u80fd\u8d8a\u6765\u8d8a\u5dee\u65f6\u6216\u8005\u6027\u80fd\u4e0d\u518d\u63d0\u5347\uff0c\u7acb\u5373\u505c\u6b62\u5bf9\u8be5\u6a21\u578b\u7684\u8bad\u7ec3 \u77e5\u9053BN\u5c42\u7684\u4f7f\u7528\u65b9\u6cd5 \u5229\u7528\u7f51\u7edc\u8bad\u7ec3\u65f6\u4e00\u4e2a mini-batch \u7684\u6570\u636e\u6765\u8ba1\u7b97\u8be5\u795e\u7ecf\u5143xi \u7684\u5747\u503c\u548c\u65b9\u5dee,\u5f52\u4e00\u5316\u540e\u5e76\u91cd\u6784\uff0c\u56e0\u800c\u79f0\u4e3a Batch Normalization","title":"\u6df1\u5ea6\u5b66\u4e60\u7684\u6b63\u5219\u5316"},{"location":"deeplearning/section4/#24","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053L2\u6b63\u5219\u5316\u4e0eL1\u6b63\u5219\u5316\u7684\u65b9\u6cd5 \u77e5\u9053\u968f\u673a\u5931\u6d3bdroupout\u7684\u5e94\u7528 \u77e5\u9053\u63d0\u524d\u505c\u6b62\u7684\u4f7f\u7528\u65b9\u6cd5 \u77e5\u9053BN\u5c42\u7684\u4f7f\u7528\u65b9\u6cd5 \u5728\u8bbe\u8ba1\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u65f6\u4e0d\u4ec5\u8981\u6c42\u5728\u8bad\u7ec3\u96c6\u4e0a\u8bef\u5dee\u5c0f\uff0c\u800c\u4e14\u5e0c\u671b\u5728\u65b0\u6837\u672c\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u5f3a\u3002\u8bb8\u591a\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u90fd\u91c7\u7528\u76f8\u5173\u7684\u7b56\u7565\u6765\u51cf\u5c0f\u6d4b\u8bd5\u8bef\u5dee\uff0c\u8fd9\u4e9b\u7b56\u7565\u88ab\u7edf\u79f0\u4e3a\u6b63\u5219\u5316\u3002\u56e0\u4e3a\u795e\u7ecf\u7f51\u7edc\u7684\u5f3a\u5927\u7684\u8868\u793a\u80fd\u529b\u7ecf\u5e38\u9047\u5230\u8fc7\u62df\u5408\uff0c\u6240\u4ee5\u9700\u8981\u4f7f\u7528\u4e0d\u540c\u5f62\u5f0f\u7684\u6b63\u5219\u5316\u7b56\u7565\u3002 \u6b63\u5219\u5316\u901a\u8fc7\u5bf9\u7b97\u6cd5\u7684\u4fee\u6539\u6765\u51cf\u5c11\u6cdb\u5316\u8bef\u5dee\uff0c\u76ee\u524d\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u4f7f\u7528\u8f83\u591a\u7684\u7b56\u7565\u6709\u53c2\u6570\u8303\u6570\u60e9\u7f5a\uff0c\u63d0\u524d\u7ec8\u6b62\uff0cDropOut\u7b49\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u5bf9\u5176\u8fdb\u884c\u8be6\u7ec6\u7684\u4ecb\u7ecd\u3002","title":"2.4 \u6df1\u5ea6\u5b66\u4e60\u6b63\u5219\u5316"},{"location":"deeplearning/section4/#1-l1l2","text":"L1\u548cL2\u662f\u6700\u5e38\u89c1\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u3002\u5b83\u4eec\u5728\u635f\u5931\u51fd\u6570\uff08cost function\uff09\u4e2d\u589e\u52a0\u4e00\u4e2a\u6b63\u5219\u9879\uff0c\u7531\u4e8e\u6dfb\u52a0\u4e86\u8fd9\u4e2a\u6b63\u5219\u5316\u9879\uff0c\u6743\u91cd\u77e9\u9635\u7684\u503c\u51cf\u5c0f\uff0c\u56e0\u4e3a\u5b83\u5047\u5b9a\u5177\u6709\u66f4\u5c0f\u6743\u91cd\u77e9\u9635\u7684\u795e\u7ecf\u7f51\u7edc\u5bfc\u81f4\u66f4\u7b80\u5355\u7684\u6a21\u578b\u3002 \u56e0\u6b64\uff0c\u5b83\u4e5f\u4f1a\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u51cf\u5c11\u8fc7\u62df\u5408\u3002\u7136\u800c\uff0c\u8fd9\u4e2a\u6b63\u5219\u5316\u9879\u5728L1\u548cL2\u4e2d\u662f\u4e0d\u540c\u7684\u3002 L2\u6b63\u5219\u5316 \u8fd9\u91cc\u7684\u03bb\u662f\u6b63\u5219\u5316\u53c2\u6570\uff0c\u5b83\u662f\u4e00\u4e2a\u9700\u8981\u4f18\u5316\u7684\u8d85\u53c2\u6570\u3002L2\u6b63\u5219\u5316\u53c8\u79f0\u4e3a\u6743\u91cd\u8870\u51cf\uff0c\u56e0\u4e3a\u5176\u5bfc\u81f4\u6743\u91cd\u8d8b\u5411\u4e8e0\uff08\u4f46\u4e0d\u5168\u662f0\uff09 L1\u6b63\u5219\u5316 \u8fd9\u91cc\uff0c\u6211\u4eec\u60e9\u7f5a\u6743\u91cd\u77e9\u9635\u7684\u7edd\u5bf9\u503c\u3002\u5176\u4e2d\uff0c\u03bb \u4e3a\u6b63\u5219\u5316\u53c2\u6570\uff0c\u662f\u8d85\u53c2\u6570\uff0c\u4e0d\u540c\u4e8eL2\uff0c\u6743\u91cd\u503c\u53ef\u80fd\u88ab\u51cf\u5c11\u52300.\u56e0\u6b64\uff0cL1\u5bf9\u4e8e\u538b\u7f29\u6a21\u578b\u5f88\u6709\u7528\u3002\u5176\u5b83\u60c5\u51b5\u4e0b\uff0c\u4e00\u822c\u9009\u62e9\u4f18\u5148\u9009\u62e9L2\u6b63\u5219\u5316\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u4f7f\u7528\u7684\u65b9\u6cd5\u662f\uff1a L1\u6b63\u5219\u5316 tf . keras . regularizers . L1 ( l1 = 0.01 ) \u0015L2\u6b63\u5219\u5316 tf . keras . regularizers . L2 ( l2 = 0.01 ) L1L2\u6b63\u5219\u5316 tf . keras . regularizers . L1L2 ( l1 = 0.0 , l2 = 0.0 ) \u6211\u4eec\u76f4\u63a5\u5728\u67d0\u4e00\u5c42\u7684layers\u4e2d\u6307\u660e\u6b63\u5219\u5316\u7c7b\u578b\u548c\u8d85\u53c2\u6570\u5373\u53ef\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf from tensorflow.keras import regularizers # \u521b\u5efa\u6a21\u578b model = tf . keras . models . Sequential () # L2\u6b63\u5219\u5316\uff0clambda\u4e3a0.01 model . add ( tf . keras . layers . Dense ( 16 , kernel_regularizer = regularizers . l2 ( 0.001 ), activation = 'relu' , input_shape = ( 10 ,))) # L1\u6b63\u5219\u5316\uff0clambda\u4e3a0.01 model . add ( tf . keras . layers . Dense ( 16 , kernel_regularizer = regularizers . l1 ( 0.001 ), activation = 'relu' )) # L1L2\u6b63\u5219\u5316\uff0clambda1\u4e3a0.01,lambda2\u4e3a0.01 model . add ( tf . keras . layers . Dense ( 16 , kernel_regularizer = regularizers . L1L2 ( 0.001 , 0.01 ), activation = 'relu' ))","title":"1. L1\u4e0eL2\u6b63\u5219\u5316(\u56de\u987e)"},{"location":"deeplearning/section4/#2dropout","text":"dropout\u662f\u5728\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u6700\u5e38\u7528\u7684\u6b63\u5219\u5316\u6280\u672f\u3002Dropout\u7684\u539f\u7406\u5f88\u7b80\u5355\uff1a\u5047\u8bbe\u6211\u4eec\u7684\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff0c\u5728\u6bcf\u4e2a\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\uff0c\u968f\u673a\u9009\u62e9\u67d0\u4e9b\u8282\u70b9\uff0c\u5e76\u4e14\u5220\u9664\u524d\u5411\u548c\u540e\u5411\u8fde\u63a5\u3002 \u56e0\u6b64\uff0c\u6bcf\u4e2a\u8fed\u4ee3\u8fc7\u7a0b\u90fd\u4f1a\u6709\u4e0d\u540c\u7684\u8282\u70b9\u7ec4\u5408\uff0c\u4ece\u800c\u5bfc\u81f4\u4e0d\u540c\u7684\u8f93\u51fa\uff0c\u8fd9\u53ef\u4ee5\u770b\u6210\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u96c6\u6210\u65b9\u6cd5\uff08ensemble technique\uff09\u3002\u96c6\u6210\u6a21\u578b\u4e00\u822c\u4f18\u4e8e\u5355\u4e00\u6a21\u578b\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ef\u4ee5\u6355\u83b7\u66f4\u591a\u7684\u968f\u673a\u6027\u3002\u76f8\u4f3c\u5730\uff0cdropout\u4f7f\u5f97\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4f18\u4e8e\u6b63\u5e38\u7684\u6a21\u578b\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u4f7f\u7528\u7684\u65b9\u6cd5\u662fdropout\uff1a tf . keras . layers . Dropout ( rate ) \u53c2\u6570\uff1a rate\uff1a \u6bcf\u4e00\u4e2a\u795e\u7ecf\u5143\u88ab\u4e22\u5f03\u7684\u6982\u7387 \u4f8b\u5b50\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5e93 import numpy as np import tensorflow as tf # \u5b9a\u4e49dropout\u5c42,\u6bcf\u4e00\u4e2a\u795e\u7ecf\u5143\u67090.2\u7684\u6982\u7387\u88ab\u5931\u6d3b\uff0c\u672a\u88ab\u5931\u6d3b\u7684\u8f93\u5165\u5c06\u63091 /\uff081-rate\uff09\u653e\u5927 layer = tf . keras . layers . Dropout ( 0.2 , input_shape = ( 2 ,)) # \u5b9a\u4e49\u4e94\u4e2a\u6279\u6b21\u7684\u6570\u636e data = np . arange ( 1 , 11 ) . reshape ( 5 , 2 ) . astype ( np . float32 ) # \u539f\u59cb\u6570\u636e\u8fdb\u884c\u6253\u5370 print ( data ) # \u8fdb\u884c\u968f\u673a\u5931\u6d3b\uff1a\u5728training\u6a21\u5f0f\u4e2d\uff0c\u8fd4\u56de\u5e94\u7528dropout\u540e\u7684\u8f93\u51fa\uff1b\u6216\u8005\u5728\u975etraining\u6a21\u5f0f\u4e0b\uff0c\u6b63\u5e38\u8fd4\u56de\u8f93\u51fa\uff08\u6ca1\u6709dropout\uff09 outputs = layer ( data , training = True ) # \u6253\u5370\u5931\u6d3b\u540e\u7684\u7ed3\u679c print ( outputs ) \u7ed3\u679c\u4e3a\uff1a [[ 1. 2. ] [ 3. 4. ] [ 5. 6. ] [ 7. 8. ] [ 9. 10. ]] tf . Tensor ( [[ 1.25 2.5 ] [ 0. 5. ] [ 6.25 7.5 ] [ 8.75 10. ] [ 0. 12.5 ]], shape = ( 5 , 2 ), dtype = float32 )","title":"2.Dropout\u6b63\u5219\u5316"},{"location":"deeplearning/section4/#3","text":"\u63d0\u524d\u505c\u6b62\uff08early stopping\uff09\u662f\u5c06\u4e00\u90e8\u5206\u8bad\u7ec3\u96c6\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\uff08validation set\uff09\u3002 \u5f53\u9a8c\u8bc1\u96c6\u7684\u6027\u80fd\u8d8a\u6765\u8d8a\u5dee\u65f6\u6216\u8005\u6027\u80fd\u4e0d\u518d\u63d0\u5347\uff0c\u5219\u7acb\u5373\u505c\u6b62\u5bf9\u8be5\u6a21\u578b\u7684\u8bad\u7ec3\u3002 \u8fd9\u88ab\u79f0\u4e3a\u63d0\u524d\u505c\u6b62\u3002 \u5728\u4e0a\u56fe\u4e2d\uff0c\u5728\u865a\u7ebf\u5904\u505c\u6b62\u6a21\u578b\u7684\u8bad\u7ec3\uff0c\u6b64\u65f6\u6a21\u578b\u5f00\u59cb\u5728\u8bad\u7ec3\u6570\u636e\u4e0a\u8fc7\u62df\u5408\u3002 \u5728tf.keras\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528callbacks\u51fd\u6570\u5b9e\u73b0\u65e9\u671f\u505c\u6b62: tf . keras . callbacks . EarlyStopping ( monitor = 'val_loss' , patience = 5 ) \u4e0a\u9762\uff0cmonitor\u53c2\u6570\u8868\u793a\u76d1\u6d4b\u91cf\uff0c\u8fd9\u91ccval_loss\u8868\u793a\u9a8c\u8bc1\u96c6\u635f\u5931\u3002\u800cpatience\u53c2\u6570epochs\u6570\u91cf\uff0c\u5f53\u5728\u8fd9\u4e2a\u8fc7\u7a0b\u6027\u80fd\u65e0\u63d0\u5347\u65f6\u4f1a\u505c\u6b62\u8bad\u7ec3\u3002\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\uff0c\u8ba9\u6211\u4eec\u518d\u770b\u770b\u4e0a\u9762\u7684\u56fe\u7247\u3002 \u5728\u865a\u7ebf\u4e4b\u540e\uff0c\u6bcf\u4e2aepoch\u90fd\u4f1a\u5bfc\u81f4\u66f4\u9ad8\u7684\u9a8c\u8bc1\u96c6\u8bef\u5dee\u3002 \u56e0\u6b64\uff0c\u865a\u7ebf\u540epatience\u4e2aepoch\uff0c\u6a21\u578b\u5c06\u505c\u6b62\u8bad\u7ec3\uff0c\u56e0\u4e3a\u6ca1\u6709\u8fdb\u4e00\u6b65\u7684\u6539\u5584\u3002 # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import numpy as np # \u5f53\u8fde\u7eed3\u4e2aepoch loss\u4e0d\u4e0b\u964d\u5219\u505c\u6b62\u8bad\u7ec3 callback = tf . keras . callbacks . EarlyStopping ( monitor = 'loss' , patience = 3 ) # \u5b9a\u4e49\u53ea\u6709\u4e00\u5c42\u7684\u795e\u7ecf\u7f51\u7edc model = tf . keras . models . Sequential ([ tf . keras . layers . Dense ( 10 )]) # \u8bbe\u7f6e\u635f\u5931\u51fd\u6570\u548c\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5 model . compile ( tf . keras . optimizers . SGD (), loss = 'mse' ) # \u6a21\u578b\u8bad\u7ec3 history = model . fit ( np . arange ( 100 ) . reshape ( 5 , 20 ), np . array ([ 0 , 1 , 2 , 1 , 2 ]), epochs = 10 , batch_size = 1 , callbacks = [ callback ], verbose = 1 ) # \u6253\u5370\u8fd0\u884c\u7684epoch len ( history . history [ 'loss' ]) \u8f93\u51fa\uff1a Epoch 1 / 10 5 / 5 [ ============================== ] - 0 s 600 us / step - loss : 145774557280600064.0000 Epoch 2 / 10 5 / 5 [ ============================== ] - 0 s 522 us / step - loss : 10077891596456623723194184833695744.0000 Epoch 3 / 10 5 / 5 [ ============================== ] - 0 s 1 ms / step - loss : inf Epoch 4 / 10 5 / 5 [ ============================== ] - 0 s 1 ms / step - loss : inf # \u53ea\u8fd0\u884c\u4e864\u6b21 4","title":"3.\u63d0\u524d\u505c\u6b62"},{"location":"deeplearning/section4/#4","text":"\u6279\u6807\u51c6\u5316(BN\u5c42,Batch Normalization)\u662f2015\u5e74\u63d0\u51fa\u7684\u4e00\u79cd\u65b9\u6cd5\uff0c\u5728\u8fdb\u884c\u6df1\u5ea6\u7f51\u7edc\u8bad\u7ec3\u65f6\uff0c\u5927\u591a\u4f1a\u91c7\u53d6\u8fd9\u79cd\u7b97\u6cd5\uff0c\u4e0e\u5168\u8fde\u63a5\u5c42\u4e00\u6837\uff0cBN\u5c42\u4e5f\u662f\u5c5e\u4e8e\u7f51\u7edc\u4e2d\u7684\u4e00\u5c42\u3002 BN\u5c42\u662f\u9488\u5bf9\u5355\u4e2a\u795e\u7ecf\u5143\u8fdb\u884c\uff0c\u5229\u7528\u7f51\u7edc\u8bad\u7ec3\u65f6\u4e00\u4e2a mini-batch \u7684\u6570\u636e\u6765\u8ba1\u7b97\u8be5\u795e\u7ecf\u5143xi \u7684\u5747\u503c\u548c\u65b9\u5dee,\u5f52\u4e00\u5316\u540e\u5e76\u91cd\u6784\uff0c\u56e0\u800c\u79f0\u4e3a Batch Normalization\u3002\u5728\u6bcf\u4e00\u5c42\u8f93\u5165\u4e4b\u524d\uff0c\u5c06\u6570\u636e\u8fdb\u884cBN\uff0c\u7136\u540e\u518d\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u5b66\u4e60\uff1a \u9996\u5148\u6211\u4eec\u5bf9\u67d0\u4e00\u6279\u6b21\u7684\u6570\u636e\u7684\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u8fdb\u884c\u6807\u51c6\u5316\uff0c \u7136\u540e\u5728\u4f7f\u7528\u53d8\u6362\u91cd\u6784\uff0c\u5f15\u5165\u4e86\u53ef\u5b66\u4e60\u53c2\u6570\u03b3\u3001\u03b2\uff0c\u5982\u679c\u5404\u9690\u85cf\u5c42\u7684\u8f93\u5165\u5747\u503c\u5728\u9760\u8fd10\u7684\u533a\u57df\uff0c\u5373\u5904\u4e8e\u6fc0\u6d3b\u51fd\u6570\u7684\u7ebf\u6027\u533a\u57df\uff0c\u4e0d\u5229\u4e8e\u8bad\u7ec3\u975e\u7ebf\u6027\u795e\u7ecf\u7f51\u7edc\uff0c\u4ece\u800c\u5f97\u5230\u6548\u679c\u8f83\u5dee\u7684\u6a21\u578b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u7528 \u03b3 \u548c \u03b2 \u5bf9\u6807\u51c6\u5316\u540e\u7684\u7ed3\u679c\u505a\u8fdb\u4e00\u6b65\u5904\u7406\uff1a \u8fd9\u5c31\u662fBN\u5c42\u6700\u540e\u7684\u7ed3\u679c\u3002\u6574\u4f53\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5728tf.keras\u4e2d\u5b9e\u73b0\u4f7f\u7528\uff1a # \u76f4\u63a5\u5c06\u5176\u653e\u5165\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u7684\u7ed3\u6784\u4e2d\u5373\u53ef tf . keras . layers . BatchNormalization ( epsilon = 0.001 , center = True , scale = True , beta_initializer = 'zeros' , gamma_initializer = 'ones' , )","title":"4. \u6279\u6807\u51c6\u5316"},{"location":"deeplearning/section4/#328","text":"\u77e5\u9053L2\u6b63\u5219\u5316\u4e0eL1\u6b63\u5219\u5316\u7684\u65b9\u6cd5 \u5728\u635f\u5931\u51fd\u6570\uff08cost function\uff09\u4e2d\u589e\u52a0\u4e00\u4e2a\u6b63\u5219\u9879\uff0c\u7531\u4e8e\u6dfb\u52a0\u4e86\u8fd9\u4e2a\u6b63\u5219\u5316\u9879\uff0c\u6743\u91cd\u77e9\u9635\u7684\u503c\u51cf\u5c0f\uff0c\u56e0\u4e3a\u5b83\u5047\u5b9a\u5177\u6709\u66f4\u5c0f\u6743\u91cd\u77e9\u9635\u7684\u795e\u7ecf\u7f51\u7edc\u5bfc\u81f4\u66f4\u7b80\u5355\u7684\u6a21\u578b \u77e5\u9053\u968f\u673a\u5931\u6d3bdroupout\u7684\u5e94\u7528 \u5728\u6bcf\u4e2a\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\uff0c\u968f\u673a\u9009\u62e9\u67d0\u4e9b\u8282\u70b9\uff0c\u5e76\u4e14\u5220\u9664\u524d\u5411\u548c\u540e\u5411\u8fde\u63a5 \u77e5\u9053\u63d0\u524d\u505c\u6b62\u7684\u4f7f\u7528\u65b9\u6cd5 \u5f53\u770b\u5230\u9a8c\u8bc1\u96c6\u7684\u6027\u80fd\u8d8a\u6765\u8d8a\u5dee\u65f6\u6216\u8005\u6027\u80fd\u4e0d\u518d\u63d0\u5347\uff0c\u7acb\u5373\u505c\u6b62\u5bf9\u8be5\u6a21\u578b\u7684\u8bad\u7ec3 \u77e5\u9053BN\u5c42\u7684\u4f7f\u7528\u65b9\u6cd5 \u5229\u7528\u7f51\u7edc\u8bad\u7ec3\u65f6\u4e00\u4e2a mini-batch \u7684\u6570\u636e\u6765\u8ba1\u7b97\u8be5\u795e\u7ecf\u5143xi \u7684\u5747\u503c\u548c\u65b9\u5dee,\u5f52\u4e00\u5316\u540e\u5e76\u91cd\u6784\uff0c\u56e0\u800c\u79f0\u4e3a Batch Normalization","title":"3.2.8 \u603b\u7ed3"},{"location":"deeplearning/section5/","text":"2.5 \u795e\u7ecf\u7f51\u7edc\u6848\u4f8b \u00b6 \u5b66\u4e60\u76ee\u6807 \u80fd\u591f\u5229\u7528tf.keras\u83b7\u53d6\u6570\u636e\u96c6 \u80fd\u591f\u7f51\u7edc\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u5efa \u80fd\u591f\u5b8c\u6210\u7f51\u7edc\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30 \u4f7f\u7528\u624b\u5199\u6570\u5b57\u7684MNIST\u6570\u636e\u96c6\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b60,000\u4e2a\u7528\u4e8e\u8bad\u7ec3\u7684\u6837\u672c\u548c10,000\u4e2a\u7528\u4e8e\u6d4b\u8bd5\u7684\u6837\u672c\uff0c\u56fe\u50cf\u662f\u56fa\u5b9a\u5927\u5c0f(28x28\u50cf\u7d20)\uff0c\u5176\u503c\u4e3a0\u5230255\u3002 \u6574\u4e2a\u6848\u4f8b\u7684\u5b9e\u73b0\u6d41\u7a0b\u662f\uff1a \u6570\u636e\u52a0\u8f7d \u6570\u636e\u5904\u7406 \u6a21\u578b\u6784\u5efa \u6a21\u578b\u8bad\u7ec3 \u6a21\u578b\u6d4b\u8bd5 \u6a21\u578b\u4fdd\u5b58 \u9996\u5148\u8981\u5bfc\u5165\u6240\u9700\u7684\u5de5\u5177\u5305\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import numpy as np import matplotlib.pyplot as plt plt . rcParams [ 'figure.figsize' ] = ( 7 , 7 ) # Make the figures a bit bigger import tensorflow as tf # \u6570\u636e\u96c6 from tensorflow.keras.datasets import mnist # \u6784\u5efa\u5e8f\u5217\u6a21\u578b from tensorflow.keras.models import Sequential # \u5bfc\u5165\u9700\u8981\u7684\u5c42 from tensorflow.keras.layers import Dense , Dropout , Activation , BatchNormalization # \u5bfc\u5165\u8f85\u52a9\u5de5\u5177\u5305 from tensorflow.keras import utils # \u6b63\u5219\u5316 from tensorflow.keras import regularizers 1.\u6570\u636e\u52a0\u8f7d \u00b6 \u9996\u5148\u52a0\u8f7d\u624b\u5199\u6570\u5b57\u56fe\u50cf # \u7c7b\u522b\u603b\u6570 nb_classes = 10 # \u52a0\u8f7d\u6570\u636e\u96c6 ( X_train , y_train ), ( X_test , y_test ) = mnist . load_data () # \u6253\u5370\u8f93\u51fa\u6570\u636e\u96c6\u7684\u7ef4\u5ea6 print ( \"\u8bad\u7ec3\u6837\u672c\u521d\u59cb\u7ef4\u5ea6\" , X_train . shape ) print ( \"\u8bad\u7ec3\u6837\u672c\u76ee\u6807\u503c\u521d\u59cb\u7ef4\u5ea6\" , y_train . shape ) \u7ed3\u679c\u4e3a\uff1a \u8bad\u7ec3\u6837\u672c\u521d\u59cb\u7ef4\u5ea6 ( 60000 , 28 , 28 ) \u8bad\u7ec3\u6837\u672c\u76ee\u6807\u503c\u521d\u59cb\u7ef4\u5ea6 ( 60000 ,) \u6570\u636e\u5c55\u793a\uff1a # \u6570\u636e\u5c55\u793a\uff1a\u5c06\u6570\u636e\u96c6\u7684\u524d\u4e5d\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u5c55\u793a for i in range ( 9 ): plt . subplot ( 3 , 3 , i + 1 ) # \u4ee5\u7070\u5ea6\u56fe\u663e\u793a\uff0c\u4e0d\u8fdb\u884c\u63d2\u503c plt . imshow ( X_train [ i ], cmap = 'gray' , interpolation = 'none' ) # \u8bbe\u7f6e\u56fe\u7247\u7684\u6807\u9898\uff1a\u5bf9\u5e94\u7684\u7c7b\u522b plt . title ( \"\u6570\u5b57 {} \" . format ( y_train [ i ])) \u6548\u679c\u5982\u4e0b\u6240\u793a\uff1a 2.\u6570\u636e\u5904\u7406 \u00b6 \u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6bcf\u4e2a\u8bad\u7ec3\u6837\u672c\u662f\u4e00\u4e2a\u5411\u91cf\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u8f93\u5165\u8fdb\u884c\u91cd\u5851\uff0c\u4f7f\u6bcf\u4e2a28x28\u7684\u56fe\u50cf\u6210\u4e3a\u4e00\u4e2a\u7684784\u7ef4\u5411\u91cf\u3002\u53e6\u5916\uff0c\u5c06\u8f93\u5165\u6570\u636e\u8fdb\u884c\u5f52\u4e00\u5316\u5904\u7406\uff0c\u4ece0-255\u8c03\u6574\u52300-1\u3002 # \u8c03\u6574\u6570\u636e\u7ef4\u5ea6\uff1a\u6bcf\u4e00\u4e2a\u6570\u5b57\u8f6c\u6362\u6210\u4e00\u4e2a\u5411\u91cf X_train = X_train . reshape ( 60000 , 784 ) X_test = X_test . reshape ( 10000 , 784 ) # \u683c\u5f0f\u8f6c\u6362 X_train = X_train . astype ( 'float32' ) X_test = X_test . astype ( 'float32' ) # \u5f52\u4e00\u5316 X_train /= 255 X_test /= 255 # \u7ef4\u5ea6\u8c03\u6574\u540e\u7684\u7ed3\u679c print ( \"\u8bad\u7ec3\u96c6\uff1a\" , X_train . shape ) print ( \"\u6d4b\u8bd5\u96c6\uff1a\" , X_test . shape \uff09 \u8f93\u51fa\u4e3a\uff1a \u8bad\u7ec3\u96c6 \uff1a ( 60000 , 784 ) \u6d4b\u8bd5\u96c6 \uff1a ( 10000 , 784 ) \u53e6\u5916\u5bf9\u4e8e\u76ee\u6807\u503c\u6211\u4eec\u4e5f\u9700\u8981\u8fdb\u884c\u5904\u7406\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u70ed\u7f16\u7801\u7684\u5f62\u5f0f\uff1a \u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a # \u5c06\u76ee\u6807\u503c\u8f6c\u6362\u4e3a\u70ed\u7f16\u7801\u7684\u5f62\u5f0f Y_train = utils . to_categorical ( y_train , nb_classes ) Y_test = utils . to_categorical ( y_test , nb_classes ) 3.\u6a21\u578b\u6784\u5efa \u00b6 \u5728\u8fd9\u91cc\u6211\u4eec\u6784\u5efa\u53ea\u67093\u5c42\u5168\u8fde\u63a5\u7684\u7f51\u7edc\u6765\u8fdb\u884c\u5904\u7406\uff1a \u6784\u5efa\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a # \u5229\u7528\u5e8f\u5217\u6a21\u578b\u6765\u6784\u5efa\u6a21\u578b model = Sequential () # \u5168\u8fde\u63a5\u5c42\uff0c\u5171512\u4e2a\u795e\u7ecf\u5143\uff0c\u8f93\u5165\u7ef4\u5ea6\u5927\u5c0f\u4e3a784 model . add ( Dense ( 512 , input_shape = ( 784 ,))) # \u6fc0\u6d3b\u51fd\u6570\u4f7f\u7528relu model . add ( Activation ( 'relu' )) # \u4f7f\u7528\u6b63\u5219\u5316\u65b9\u6cd5drouout model . add ( Dropout ( 0.2 )) # \u5168\u8fde\u63a5\u5c42\uff0c\u5171512\u4e2a\u795e\u7ecf\u5143,\u5e76\u52a0\u5165L2\u6b63\u5219\u5316 model . add ( Dense ( 512 , kernel_regularizer = regularizers . l2 ( 0.001 ))) # BN\u5c42 model . add ( BatchNormalization ()) # \u6fc0\u6d3b\u51fd\u6570 model . add ( Activation ( 'relu' )) model . add ( Dropout ( 0.2 )) # \u5168\u8fde\u63a5\u5c42\uff0c\u8f93\u51fa\u5c42\u517110\u4e2a\u795e\u7ecf\u5143 model . add ( Dense ( 10 )) # softmax\u5c06\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u7684score\u8f6c\u6362\u4e3a\u6982\u7387\u503c model . add ( Activation ( 'softmax' )) \u6211\u4eec\u901a\u8fc7model.summay\u6765\u770b\u4e0b\u7ed3\u679c\uff1a Model : \"sequential_6\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= dense_13 ( Dense ) ( None , 512 ) 401920 _________________________________________________________________ activation_8 ( Activation ) ( None , 512 ) 0 _________________________________________________________________ dropout_7 ( Dropout ) ( None , 512 ) 0 _________________________________________________________________ dense_14 ( Dense ) ( None , 512 ) 262656 _________________________________________________________________ batch_normalization ( BatchNo ( None , 512 ) 2048 _________________________________________________________________ activation_9 ( Activation ) ( None , 512 ) 0 _________________________________________________________________ dropout_8 ( Dropout ) ( None , 512 ) 0 _________________________________________________________________ dense_15 ( Dense ) ( None , 10 ) 5130 _________________________________________________________________ activation_10 ( Activation ) ( None , 10 ) 0 ================================================================= Total params : 671 , 754 Trainable params : 670 , 730 Non - trainable params : 1 , 024 _________________________________________________________________ 4.\u6a21\u578b\u7f16\u8bd1 \u00b6 \u8bbe\u7f6e\u6a21\u578b\u8bad\u7ec3\u4f7f\u7528\u7684\u635f\u5931\u51fd\u6570\u4ea4\u53c9\u71b5\u635f\u5931\u548c\u4f18\u5316\u65b9\u6cd5adam\uff0c\u635f\u5931\u51fd\u6570\u7528\u6765\u8861\u91cf\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u4f18\u5316\u5668\u7528\u6765\u4f7f\u7528\u635f\u5931\u51fd\u6570\u8fbe\u5230\u6700\u4f18\uff1a # \u6a21\u578b\u7f16\u8bd1\uff0c\u6307\u660e\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668\uff0c\u8bc4\u4f30\u6307\u6807 model . compile ( loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) 5.\u6a21\u578b\u8bad\u7ec3 \u00b6 # batch_size\u662f\u6bcf\u6b21\u9001\u5165\u6a21\u578b\u4e2d\u6837\u672c\u4e2a\u6570\uff0cepochs\u662f\u6240\u6709\u6837\u672c\u7684\u8fed\u4ee3\u6b21\u6570\uff0c\u5e76\u6307\u660e\u9a8c\u8bc1\u6570\u636e\u96c6 history = model . fit ( X_train , Y_train , batch_size = 128 , epochs = 4 , verbose = 1 , validation_data = ( X_test , Y_test )) \u8bad\u7ec3\u8fc7\u7a0b\u5982\u4e0b\u6240\u793a\uff1a Epoch 1/4 469/469 [==============================] - 2s 4ms/step - loss: 0.5273 - accuracy: 0.9291 - val_loss: 0.2686 - val_accuracy: 0.9664 Epoch 2/4 469/469 [==============================] - 2s 4ms/step - loss: 0.2213 - accuracy: 0.9662 - val_loss: 0.1672 - val_accuracy: 0.9720 Epoch 3/4 469/469 [==============================] - 2s 4ms/step - loss: 0.1528 - accuracy: 0.9734 - val_loss: 0.1462 - val_accuracy: 0.9735 Epoch 4/4 469/469 [==============================] - 2s 4ms/step - loss: 0.1313 - accuracy: 0.9768 - val_loss: 0.1292 - val_accuracy: 0.9777 \u5c06\u635f\u5931\u7ed8\u5236\u6210\u66f2\u7ebf\uff1a # \u7ed8\u5236\u635f\u5931\u51fd\u6570\u7684\u53d8\u5316\u66f2\u7ebf plt . figure () # \u8bad\u7ec3\u96c6\u635f\u5931\u51fd\u6570\u53d8\u6362 plt . plot ( history . history [ \"loss\" ], label = \"train_loss\" ) # \u9a8c\u8bc1\u96c6\u635f\u5931\u51fd\u6570\u53d8\u5316 plt . plot ( history . history [ \"val_loss\" ], label = \"val_loss\" ) plt . legend () plt . grid () \u5c06\u8bad\u7ec3\u7684\u51c6\u786e\u7387\u7ed8\u5236\u4e3a\u66f2\u7ebf\uff1a # \u7ed8\u5236\u51c6\u786e\u7387\u7684\u53d8\u5316\u66f2\u7ebf plt . figure () # \u8bad\u7ec3\u96c6\u51c6\u786e\u7387 plt . plot ( history . history [ \"accuracy\" ], label = \"train_acc\" ) # \u9a8c\u8bc1\u96c6\u51c6\u786e\u7387 plt . plot ( history . history [ \"val_accuracy\" ], label = \"val_acc\" ) plt . legend () plt . grid () \u53e6\u5916\u53ef\u901a\u8fc7tensorboard\u76d1\u63a7\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u8fd9\u65f6\u6211\u4eec\u6307\u5b9a\u56de\u8c03\u51fd\u6570\uff1a # \u6dfb\u52a0tensoboard\u89c2\u5bdf tensorboard = tf . keras . callbacks . TensorBoard ( log_dir = './graph' , histogram_freq = 1 , write_graph = True , write_images = True ) \u5728\u8fdb\u884c\u8bad\u7ec3\uff1a # \u8bad\u7ec3 history = model . fit ( X_train , Y_train , batch_size = 128 , epochs = 4 , verbose = 1 , callbacks = [ tensorboard ], validation_data = ( X_test , Y_test )) \u6253\u5f00\u7ec8\u7aef\uff1a # \u6307\u5b9a\u5b58\u5728\u6587\u4ef6\u7684\u76ee\u5f55\uff0c\u6253\u5f00\u4e0b\u9762\u547d\u4ee4 tensorboard -- logdir = \"./\" \u5728\u6d4f\u89c8\u5668\u4e2d\u6253\u5f00\u6307\u5b9a\u7f51\u5740\uff0c\u53ef\u67e5\u770b\u635f\u5931\u51fd\u6570\u548c\u51c6\u786e\u7387\u7684\u53d8\u5316\uff0c\u56fe\u7ed3\u6784\u7b49\u3002 6.\u6a21\u578b\u6d4b\u8bd5 \u00b6 # \u6a21\u578b\u6d4b\u8bd5 score = model . evaluate ( X_test , Y_test , verbose = 1 ) # \u6253\u5370\u7ed3\u679c print ( '\u6d4b\u8bd5\u96c6\u51c6\u786e\u7387:' , score ) \u7ed3\u679c\uff1a 313 / 313 [ ============================== ] - 0 s 1 ms / step - loss : 0.1292 - accuracy : 0.9777 Test accuracy : 0.9776999950408936 7.\u6a21\u578b\u4fdd\u5b58 \u00b6 # \u4fdd\u5b58\u6a21\u578b\u67b6\u6784\u4e0e\u6743\u91cd\u5728h5\u6587\u4ef6\u4e2d model . save ( 'my_model.h5' ) # \u52a0\u8f7d\u6a21\u578b\uff1a\u5305\u62ec\u67b6\u6784\u548c\u5bf9\u5e94\u7684\u6743\u91cd model = tf . keras . models . load_model ( 'my_model.h5' ) \u603b\u7ed3 \u80fd\u591f\u5229\u7528tf.keras\u83b7\u53d6\u6570\u636e\u96c6\uff1a load_data() \u80fd\u591f\u8fdb\u884c\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u5efa dense,\u6fc0\u6d3b\u51fd\u6570\uff0cdropout,BN\u5c42\u7b49 \u80fd\u591f\u5b8c\u6210\u7f51\u7edc\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30 fit\uff0c\u56de\u8c03\u51fd\u6570\uff0cevaluate, \u4fdd\u5b58\u6a21\u578b","title":"\u795e\u7ecf\u7f51\u7edc\u6848\u4f8b"},{"location":"deeplearning/section5/#25","text":"\u5b66\u4e60\u76ee\u6807 \u80fd\u591f\u5229\u7528tf.keras\u83b7\u53d6\u6570\u636e\u96c6 \u80fd\u591f\u7f51\u7edc\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u5efa \u80fd\u591f\u5b8c\u6210\u7f51\u7edc\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30 \u4f7f\u7528\u624b\u5199\u6570\u5b57\u7684MNIST\u6570\u636e\u96c6\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b60,000\u4e2a\u7528\u4e8e\u8bad\u7ec3\u7684\u6837\u672c\u548c10,000\u4e2a\u7528\u4e8e\u6d4b\u8bd5\u7684\u6837\u672c\uff0c\u56fe\u50cf\u662f\u56fa\u5b9a\u5927\u5c0f(28x28\u50cf\u7d20)\uff0c\u5176\u503c\u4e3a0\u5230255\u3002 \u6574\u4e2a\u6848\u4f8b\u7684\u5b9e\u73b0\u6d41\u7a0b\u662f\uff1a \u6570\u636e\u52a0\u8f7d \u6570\u636e\u5904\u7406 \u6a21\u578b\u6784\u5efa \u6a21\u578b\u8bad\u7ec3 \u6a21\u578b\u6d4b\u8bd5 \u6a21\u578b\u4fdd\u5b58 \u9996\u5148\u8981\u5bfc\u5165\u6240\u9700\u7684\u5de5\u5177\u5305\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import numpy as np import matplotlib.pyplot as plt plt . rcParams [ 'figure.figsize' ] = ( 7 , 7 ) # Make the figures a bit bigger import tensorflow as tf # \u6570\u636e\u96c6 from tensorflow.keras.datasets import mnist # \u6784\u5efa\u5e8f\u5217\u6a21\u578b from tensorflow.keras.models import Sequential # \u5bfc\u5165\u9700\u8981\u7684\u5c42 from tensorflow.keras.layers import Dense , Dropout , Activation , BatchNormalization # \u5bfc\u5165\u8f85\u52a9\u5de5\u5177\u5305 from tensorflow.keras import utils # \u6b63\u5219\u5316 from tensorflow.keras import regularizers","title":"2.5 \u795e\u7ecf\u7f51\u7edc\u6848\u4f8b"},{"location":"deeplearning/section5/#1","text":"\u9996\u5148\u52a0\u8f7d\u624b\u5199\u6570\u5b57\u56fe\u50cf # \u7c7b\u522b\u603b\u6570 nb_classes = 10 # \u52a0\u8f7d\u6570\u636e\u96c6 ( X_train , y_train ), ( X_test , y_test ) = mnist . load_data () # \u6253\u5370\u8f93\u51fa\u6570\u636e\u96c6\u7684\u7ef4\u5ea6 print ( \"\u8bad\u7ec3\u6837\u672c\u521d\u59cb\u7ef4\u5ea6\" , X_train . shape ) print ( \"\u8bad\u7ec3\u6837\u672c\u76ee\u6807\u503c\u521d\u59cb\u7ef4\u5ea6\" , y_train . shape ) \u7ed3\u679c\u4e3a\uff1a \u8bad\u7ec3\u6837\u672c\u521d\u59cb\u7ef4\u5ea6 ( 60000 , 28 , 28 ) \u8bad\u7ec3\u6837\u672c\u76ee\u6807\u503c\u521d\u59cb\u7ef4\u5ea6 ( 60000 ,) \u6570\u636e\u5c55\u793a\uff1a # \u6570\u636e\u5c55\u793a\uff1a\u5c06\u6570\u636e\u96c6\u7684\u524d\u4e5d\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u5c55\u793a for i in range ( 9 ): plt . subplot ( 3 , 3 , i + 1 ) # \u4ee5\u7070\u5ea6\u56fe\u663e\u793a\uff0c\u4e0d\u8fdb\u884c\u63d2\u503c plt . imshow ( X_train [ i ], cmap = 'gray' , interpolation = 'none' ) # \u8bbe\u7f6e\u56fe\u7247\u7684\u6807\u9898\uff1a\u5bf9\u5e94\u7684\u7c7b\u522b plt . title ( \"\u6570\u5b57 {} \" . format ( y_train [ i ])) \u6548\u679c\u5982\u4e0b\u6240\u793a\uff1a","title":"1.\u6570\u636e\u52a0\u8f7d"},{"location":"deeplearning/section5/#2","text":"\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6bcf\u4e2a\u8bad\u7ec3\u6837\u672c\u662f\u4e00\u4e2a\u5411\u91cf\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u8f93\u5165\u8fdb\u884c\u91cd\u5851\uff0c\u4f7f\u6bcf\u4e2a28x28\u7684\u56fe\u50cf\u6210\u4e3a\u4e00\u4e2a\u7684784\u7ef4\u5411\u91cf\u3002\u53e6\u5916\uff0c\u5c06\u8f93\u5165\u6570\u636e\u8fdb\u884c\u5f52\u4e00\u5316\u5904\u7406\uff0c\u4ece0-255\u8c03\u6574\u52300-1\u3002 # \u8c03\u6574\u6570\u636e\u7ef4\u5ea6\uff1a\u6bcf\u4e00\u4e2a\u6570\u5b57\u8f6c\u6362\u6210\u4e00\u4e2a\u5411\u91cf X_train = X_train . reshape ( 60000 , 784 ) X_test = X_test . reshape ( 10000 , 784 ) # \u683c\u5f0f\u8f6c\u6362 X_train = X_train . astype ( 'float32' ) X_test = X_test . astype ( 'float32' ) # \u5f52\u4e00\u5316 X_train /= 255 X_test /= 255 # \u7ef4\u5ea6\u8c03\u6574\u540e\u7684\u7ed3\u679c print ( \"\u8bad\u7ec3\u96c6\uff1a\" , X_train . shape ) print ( \"\u6d4b\u8bd5\u96c6\uff1a\" , X_test . shape \uff09 \u8f93\u51fa\u4e3a\uff1a \u8bad\u7ec3\u96c6 \uff1a ( 60000 , 784 ) \u6d4b\u8bd5\u96c6 \uff1a ( 10000 , 784 ) \u53e6\u5916\u5bf9\u4e8e\u76ee\u6807\u503c\u6211\u4eec\u4e5f\u9700\u8981\u8fdb\u884c\u5904\u7406\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u70ed\u7f16\u7801\u7684\u5f62\u5f0f\uff1a \u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a # \u5c06\u76ee\u6807\u503c\u8f6c\u6362\u4e3a\u70ed\u7f16\u7801\u7684\u5f62\u5f0f Y_train = utils . to_categorical ( y_train , nb_classes ) Y_test = utils . to_categorical ( y_test , nb_classes )","title":"2.\u6570\u636e\u5904\u7406"},{"location":"deeplearning/section5/#3","text":"\u5728\u8fd9\u91cc\u6211\u4eec\u6784\u5efa\u53ea\u67093\u5c42\u5168\u8fde\u63a5\u7684\u7f51\u7edc\u6765\u8fdb\u884c\u5904\u7406\uff1a \u6784\u5efa\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a # \u5229\u7528\u5e8f\u5217\u6a21\u578b\u6765\u6784\u5efa\u6a21\u578b model = Sequential () # \u5168\u8fde\u63a5\u5c42\uff0c\u5171512\u4e2a\u795e\u7ecf\u5143\uff0c\u8f93\u5165\u7ef4\u5ea6\u5927\u5c0f\u4e3a784 model . add ( Dense ( 512 , input_shape = ( 784 ,))) # \u6fc0\u6d3b\u51fd\u6570\u4f7f\u7528relu model . add ( Activation ( 'relu' )) # \u4f7f\u7528\u6b63\u5219\u5316\u65b9\u6cd5drouout model . add ( Dropout ( 0.2 )) # \u5168\u8fde\u63a5\u5c42\uff0c\u5171512\u4e2a\u795e\u7ecf\u5143,\u5e76\u52a0\u5165L2\u6b63\u5219\u5316 model . add ( Dense ( 512 , kernel_regularizer = regularizers . l2 ( 0.001 ))) # BN\u5c42 model . add ( BatchNormalization ()) # \u6fc0\u6d3b\u51fd\u6570 model . add ( Activation ( 'relu' )) model . add ( Dropout ( 0.2 )) # \u5168\u8fde\u63a5\u5c42\uff0c\u8f93\u51fa\u5c42\u517110\u4e2a\u795e\u7ecf\u5143 model . add ( Dense ( 10 )) # softmax\u5c06\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u7684score\u8f6c\u6362\u4e3a\u6982\u7387\u503c model . add ( Activation ( 'softmax' )) \u6211\u4eec\u901a\u8fc7model.summay\u6765\u770b\u4e0b\u7ed3\u679c\uff1a Model : \"sequential_6\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= dense_13 ( Dense ) ( None , 512 ) 401920 _________________________________________________________________ activation_8 ( Activation ) ( None , 512 ) 0 _________________________________________________________________ dropout_7 ( Dropout ) ( None , 512 ) 0 _________________________________________________________________ dense_14 ( Dense ) ( None , 512 ) 262656 _________________________________________________________________ batch_normalization ( BatchNo ( None , 512 ) 2048 _________________________________________________________________ activation_9 ( Activation ) ( None , 512 ) 0 _________________________________________________________________ dropout_8 ( Dropout ) ( None , 512 ) 0 _________________________________________________________________ dense_15 ( Dense ) ( None , 10 ) 5130 _________________________________________________________________ activation_10 ( Activation ) ( None , 10 ) 0 ================================================================= Total params : 671 , 754 Trainable params : 670 , 730 Non - trainable params : 1 , 024 _________________________________________________________________","title":"3.\u6a21\u578b\u6784\u5efa"},{"location":"deeplearning/section5/#4","text":"\u8bbe\u7f6e\u6a21\u578b\u8bad\u7ec3\u4f7f\u7528\u7684\u635f\u5931\u51fd\u6570\u4ea4\u53c9\u71b5\u635f\u5931\u548c\u4f18\u5316\u65b9\u6cd5adam\uff0c\u635f\u5931\u51fd\u6570\u7528\u6765\u8861\u91cf\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u4f18\u5316\u5668\u7528\u6765\u4f7f\u7528\u635f\u5931\u51fd\u6570\u8fbe\u5230\u6700\u4f18\uff1a # \u6a21\u578b\u7f16\u8bd1\uff0c\u6307\u660e\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668\uff0c\u8bc4\u4f30\u6307\u6807 model . compile ( loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ])","title":"4.\u6a21\u578b\u7f16\u8bd1"},{"location":"deeplearning/section5/#5","text":"# batch_size\u662f\u6bcf\u6b21\u9001\u5165\u6a21\u578b\u4e2d\u6837\u672c\u4e2a\u6570\uff0cepochs\u662f\u6240\u6709\u6837\u672c\u7684\u8fed\u4ee3\u6b21\u6570\uff0c\u5e76\u6307\u660e\u9a8c\u8bc1\u6570\u636e\u96c6 history = model . fit ( X_train , Y_train , batch_size = 128 , epochs = 4 , verbose = 1 , validation_data = ( X_test , Y_test )) \u8bad\u7ec3\u8fc7\u7a0b\u5982\u4e0b\u6240\u793a\uff1a Epoch 1/4 469/469 [==============================] - 2s 4ms/step - loss: 0.5273 - accuracy: 0.9291 - val_loss: 0.2686 - val_accuracy: 0.9664 Epoch 2/4 469/469 [==============================] - 2s 4ms/step - loss: 0.2213 - accuracy: 0.9662 - val_loss: 0.1672 - val_accuracy: 0.9720 Epoch 3/4 469/469 [==============================] - 2s 4ms/step - loss: 0.1528 - accuracy: 0.9734 - val_loss: 0.1462 - val_accuracy: 0.9735 Epoch 4/4 469/469 [==============================] - 2s 4ms/step - loss: 0.1313 - accuracy: 0.9768 - val_loss: 0.1292 - val_accuracy: 0.9777 \u5c06\u635f\u5931\u7ed8\u5236\u6210\u66f2\u7ebf\uff1a # \u7ed8\u5236\u635f\u5931\u51fd\u6570\u7684\u53d8\u5316\u66f2\u7ebf plt . figure () # \u8bad\u7ec3\u96c6\u635f\u5931\u51fd\u6570\u53d8\u6362 plt . plot ( history . history [ \"loss\" ], label = \"train_loss\" ) # \u9a8c\u8bc1\u96c6\u635f\u5931\u51fd\u6570\u53d8\u5316 plt . plot ( history . history [ \"val_loss\" ], label = \"val_loss\" ) plt . legend () plt . grid () \u5c06\u8bad\u7ec3\u7684\u51c6\u786e\u7387\u7ed8\u5236\u4e3a\u66f2\u7ebf\uff1a # \u7ed8\u5236\u51c6\u786e\u7387\u7684\u53d8\u5316\u66f2\u7ebf plt . figure () # \u8bad\u7ec3\u96c6\u51c6\u786e\u7387 plt . plot ( history . history [ \"accuracy\" ], label = \"train_acc\" ) # \u9a8c\u8bc1\u96c6\u51c6\u786e\u7387 plt . plot ( history . history [ \"val_accuracy\" ], label = \"val_acc\" ) plt . legend () plt . grid () \u53e6\u5916\u53ef\u901a\u8fc7tensorboard\u76d1\u63a7\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u8fd9\u65f6\u6211\u4eec\u6307\u5b9a\u56de\u8c03\u51fd\u6570\uff1a # \u6dfb\u52a0tensoboard\u89c2\u5bdf tensorboard = tf . keras . callbacks . TensorBoard ( log_dir = './graph' , histogram_freq = 1 , write_graph = True , write_images = True ) \u5728\u8fdb\u884c\u8bad\u7ec3\uff1a # \u8bad\u7ec3 history = model . fit ( X_train , Y_train , batch_size = 128 , epochs = 4 , verbose = 1 , callbacks = [ tensorboard ], validation_data = ( X_test , Y_test )) \u6253\u5f00\u7ec8\u7aef\uff1a # \u6307\u5b9a\u5b58\u5728\u6587\u4ef6\u7684\u76ee\u5f55\uff0c\u6253\u5f00\u4e0b\u9762\u547d\u4ee4 tensorboard -- logdir = \"./\" \u5728\u6d4f\u89c8\u5668\u4e2d\u6253\u5f00\u6307\u5b9a\u7f51\u5740\uff0c\u53ef\u67e5\u770b\u635f\u5931\u51fd\u6570\u548c\u51c6\u786e\u7387\u7684\u53d8\u5316\uff0c\u56fe\u7ed3\u6784\u7b49\u3002","title":"5.\u6a21\u578b\u8bad\u7ec3"},{"location":"deeplearning/section5/#6","text":"# \u6a21\u578b\u6d4b\u8bd5 score = model . evaluate ( X_test , Y_test , verbose = 1 ) # \u6253\u5370\u7ed3\u679c print ( '\u6d4b\u8bd5\u96c6\u51c6\u786e\u7387:' , score ) \u7ed3\u679c\uff1a 313 / 313 [ ============================== ] - 0 s 1 ms / step - loss : 0.1292 - accuracy : 0.9777 Test accuracy : 0.9776999950408936","title":"6.\u6a21\u578b\u6d4b\u8bd5"},{"location":"deeplearning/section5/#7","text":"# \u4fdd\u5b58\u6a21\u578b\u67b6\u6784\u4e0e\u6743\u91cd\u5728h5\u6587\u4ef6\u4e2d model . save ( 'my_model.h5' ) # \u52a0\u8f7d\u6a21\u578b\uff1a\u5305\u62ec\u67b6\u6784\u548c\u5bf9\u5e94\u7684\u6743\u91cd model = tf . keras . models . load_model ( 'my_model.h5' ) \u603b\u7ed3 \u80fd\u591f\u5229\u7528tf.keras\u83b7\u53d6\u6570\u636e\u96c6\uff1a load_data() \u80fd\u591f\u8fdb\u884c\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u5efa dense,\u6fc0\u6d3b\u51fd\u6570\uff0cdropout,BN\u5c42\u7b49 \u80fd\u591f\u5b8c\u6210\u7f51\u7edc\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30 fit\uff0c\u56de\u8c03\u51fd\u6570\uff0cevaluate, \u4fdd\u5b58\u6a21\u578b","title":"7.\u6a21\u578b\u4fdd\u5b58"},{"location":"deeplearning/section6/","text":"2.6 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc(CNN) \u00b6 \u5b66\u4e60\u76ee\u6807 \u4e86\u89e3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u6210 \u77e5\u9053\u5377\u79ef\u7684\u539f\u7406\u4ee5\u53ca\u8ba1\u7b97\u8fc7\u7a0b \u4e86\u89e3\u6c60\u5316\u7684\u4f5c\u7528\u4ee5\u53ca\u8ba1\u7b97\u8fc7\u7a0b \u5229\u7528\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\u5bf9\u56fe\u50cf\u8fdb\u884c\u5904\u7406\u5b58\u5728\u4ee5\u4e0b\u4e24\u4e2a\u95ee\u9898\uff1a \u9700\u8981\u5904\u7406\u7684\u6570\u636e\u91cf\u5927\uff0c\u6548\u7387\u4f4e \u5047\u5982\u6211\u4eec\u5904\u7406\u4e00\u5f20 1000\u00d71000 \u50cf\u7d20\u7684\u56fe\u7247\uff0c\u53c2\u6570\u91cf\u5982\u4e0b\uff1a 1000\u00d71000\u00d73=3,000,000 \u8fd9\u4e48\u5927\u91cf\u7684\u6570\u636e\u5904\u7406\u8d77\u6765\u662f\u975e\u5e38\u6d88\u8017\u8d44\u6e90\u7684 \u56fe\u50cf\u5728\u7ef4\u5ea6\u8c03\u6574\u7684\u8fc7\u7a0b\u4e2d\u5f88\u96be\u4fdd\u7559\u539f\u6709\u7684\u7279\u5f81\uff0c\u5bfc\u81f4\u56fe\u50cf\u5904\u7406\u7684\u51c6\u786e\u7387\u4e0d\u9ad8 \u5047\u5982\u6709\u5706\u5f62\u662f1\uff0c\u6ca1\u6709\u5706\u5f62\u662f0\uff0c\u90a3\u4e48\u5706\u5f62\u7684\u4f4d\u7f6e\u4e0d\u540c\u5c31\u4f1a\u4ea7\u751f\u5b8c\u5168\u4e0d\u540c\u7684\u6570\u636e\u8868\u8fbe\u3002\u4f46\u662f\u4ece\u56fe\u50cf\u7684\u89d2\u5ea6\u6765\u770b\uff0c \u56fe\u50cf\u7684\u5185\u5bb9\uff08\u672c\u8d28\uff09\u5e76\u6ca1\u6709\u53d1\u751f\u53d8\u5316\uff0c\u53ea\u662f\u4f4d\u7f6e\u53d1\u751f\u4e86\u53d8\u5316 \u3002\u6240\u4ee5\u5f53\u6211\u4eec\u79fb\u52a8\u56fe\u50cf\u4e2d\u7684\u7269\u4f53\uff0c\u7528\u5168\u8fde\u63a5\u5347\u964d\u5f97\u5230\u7684\u7ed3\u679c\u4f1a\u5dee\u5f02\u5f88\u5927\uff0c\u8fd9\u662f\u4e0d\u7b26\u5408\u56fe\u50cf\u5904\u7406\u7684\u8981\u6c42\u7684\u3002 1.CNN\u7f51\u7edc\u7684\u6784\u6210 \u00b6 CNN\u7f51\u7edc\u53d7\u4eba\u7c7b\u89c6\u89c9\u795e\u7ecf\u7cfb\u7edf\u7684\u542f\u53d1\uff0c\u4eba\u7c7b\u7684\u89c6\u89c9\u539f\u7406\uff1a\u4ece\u539f\u59cb\u4fe1\u53f7\u6444\u5165\u5f00\u59cb\uff08\u77b3\u5b54\u6444\u5165\u50cf\u7d20 Pixels\uff09\uff0c\u63a5\u7740\u505a\u521d\u6b65\u5904\u7406\uff08\u5927\u8111\u76ae\u5c42\u67d0\u4e9b\u7ec6\u80de\u53d1\u73b0\u8fb9\u7f18\u548c\u65b9\u5411\uff09\uff0c\u7136\u540e\u62bd\u8c61\uff08\u5927\u8111\u5224\u5b9a\uff0c\u773c\u524d\u7684\u7269\u4f53\u7684\u5f62\u72b6\uff0c\u662f\u5706\u5f62\u7684\uff09\uff0c\u7136\u540e\u8fdb\u4e00\u6b65\u62bd\u8c61\uff08\u5927\u8111\u8fdb\u4e00\u6b65\u5224\u5b9a\u8be5\u7269\u4f53\u662f\u53ea\u4eba\u8138\uff09\u3002\u4e0b\u9762\u662f\u4eba\u8111\u8fdb\u884c\u4eba\u8138\u8bc6\u522b\u7684\u4e00\u4e2a\u793a\u4f8b\uff1a CNN\u7f51\u7edc\u4e3b\u8981\u6709\u4e09\u90e8\u5206\u6784\u6210\uff1a\u5377\u79ef\u5c42\u3001\u6c60\u5316\u5c42\u548c\u5168\u8fde\u63a5\u5c42\u6784\u6210\uff0c\u5176\u4e2d\u5377\u79ef\u5c42\u8d1f\u8d23\u63d0\u53d6\u56fe\u50cf\u4e2d\u7684\u5c40\u90e8\u7279\u5f81\uff1b\u6c60\u5316\u5c42\u7528\u6765\u5927\u5e45\u964d\u4f4e\u53c2\u6570\u91cf\u7ea7(\u964d\u7ef4)\uff1b\u5168\u8fde\u63a5\u5c42\u7c7b\u4f3c\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7684\u90e8\u5206\uff0c\u7528\u6765\u8f93\u51fa\u60f3\u8981\u7684\u7ed3\u679c\u3002 \u6574\u4e2aCNN\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a 2. \u5377\u79ef\u5c42 \u00b6 \u5377\u79ef\u5c42\u662f\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6838\u5fc3\u6a21\u5757\uff0c\u5377\u79ef\u5c42\u7684\u76ee\u7684\u662f\u63d0\u53d6\u8f93\u5165\u7279\u5f81\u56fe\u7684\u7279\u5f81\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5377\u79ef\u6838\u53ef\u4ee5\u63d0\u53d6\u56fe\u50cf\u4e2d\u7684\u8fb9\u7f18\u4fe1\u606f\u3002 2.1 \u5377\u79ef\u7684\u8ba1\u7b97\u65b9\u6cd5 \u00b6 \u90a3\u5377\u79ef\u662f\u600e\u4e48\u8fdb\u884c\u8ba1\u7b97\u7684\u5462\uff1f \u5377\u79ef\u8fd0\u7b97\u672c\u8d28\u4e0a\u5c31\u662f\u5728\u6ee4\u6ce2\u5668\u548c\u8f93\u5165\u6570\u636e\u7684\u5c40\u90e8\u533a\u57df\u95f4\u505a\u70b9\u79ef\u3002 \u5de6\u4e0a\u89d2\u7684\u70b9\u8ba1\u7b97\u65b9\u6cd5\uff1a \u540c\u7406\u53ef\u4ee5\u8ba1\u7b97\u5176\u4ed6\u5404\u70b9\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u5377\u79ef\u7ed3\u679c\uff0c \u6700\u540e\u4e00\u70b9\u7684\u8ba1\u7b97\u65b9\u6cd5\u662f\uff1a 2.2 padding \u00b6 \u5728\u4e0a\u8ff0\u5377\u79ef\u8fc7\u7a0b\u4e2d\uff0c\u7279\u5f81\u56fe\u6bd4\u539f\u59cb\u56fe\u51cf\u5c0f\u4e86\u5f88\u591a\uff0c\u6211\u4eec\u53ef\u4ee5\u5728\u539f\u56fe\u50cf\u7684\u5468\u56f4\u8fdb\u884cpadding,\u6765\u4fdd\u8bc1\u5728\u5377\u79ef\u8fc7\u7a0b\u4e2d\u7279\u5f81\u56fe\u5927\u5c0f\u4e0d\u53d8\u3002 2.3 stride \u00b6 \u6309\u7167\u6b65\u957f\u4e3a1\u6765\u79fb\u52a8\u5377\u79ef\u6838\uff0c\u8ba1\u7b97\u7279\u5f81\u56fe\u5982\u4e0b\u6240\u793a\uff1a \u5982\u679c\u6211\u4eec\u628astride\u589e\u5927,\u6bd4\u5982\u8bbe\u4e3a2\uff0c\u4e5f\u662f\u53ef\u4ee5\u63d0\u53d6\u7279\u5f81\u56fe\u7684\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a 2.4 \u591a\u901a\u9053\u5377\u79ef \u00b6 \u5b9e\u9645\u4e2d\u7684\u56fe\u50cf\u90fd\u662f\u591a\u4e2a\u901a\u9053\u7ec4\u6210\u7684\uff0c\u6211\u4eec\u600e\u4e48\u8ba1\u7b97\u5377\u79ef\u5462\uff1f \u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\uff1a\u5f53\u8f93\u5165\u6709\u591a\u4e2a\u901a\u9053\uff08channel\uff09\u65f6(\u4f8b\u5982\u56fe\u7247\u53ef\u4ee5\u6709 RGB \u4e09\u4e2a\u901a\u9053)\uff0c\u5377\u79ef\u6838\u9700\u8981\u62e5\u6709\u76f8\u540c\u7684channel\u6570,\u6bcf\u4e2a\u5377\u79ef\u6838 channel \u4e0e\u8f93\u5165\u5c42\u7684\u5bf9\u5e94 channel \u8fdb\u884c\u5377\u79ef\uff0c\u5c06\u6bcf\u4e2a channel \u7684\u5377\u79ef\u7ed3\u679c\u6309\u4f4d\u76f8\u52a0\u5f97\u5230\u6700\u7ec8\u7684 Feature Map 2.5 \u591a\u5377\u79ef\u6838\u5377\u79ef \u00b6 \u5982\u679c\u6709\u591a\u4e2a\u5377\u79ef\u6838\u65f6\u600e\u4e48\u8ba1\u7b97\u5462\uff1f\u5f53\u6709\u591a\u4e2a\u5377\u79ef\u6838\u65f6\uff0c\u6bcf\u4e2a\u5377\u79ef\u6838\u5b66\u4e60\u5230\u4e0d\u540c\u7684\u7279\u5f81\uff0c\u5bf9\u5e94\u4ea7\u751f\u5305\u542b\u591a\u4e2a channel \u7684 Feature Map, \u4f8b\u5982\u4e0b\u56fe\u6709\u4e24\u4e2a filter\uff0c\u6240\u4ee5 output \u6709\u4e24\u4e2a channel\u3002 2.6 \u7279\u5f81\u56fe\u5927\u5c0f \u00b6 \u8f93\u51fa\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u4e0e\u4ee5\u4e0b\u53c2\u6570\u606f\u606f\u76f8\u5173\uff1a * size:\u5377\u79ef\u6838/\u8fc7\u6ee4\u5668\u5927\u5c0f\uff0c\u4e00\u822c\u4f1a\u9009\u62e9\u4e3a\u5947\u6570\uff0c\u6bd4\u5982\u67091 * 1\uff0c 3 * 3\uff0c 5 * 5 * padding\uff1a\u96f6\u586b\u5145\u7684\u65b9\u5f0f * stride:\u6b65\u957f \u90a3\u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8f93\u5165\u7279\u5f81\u56fe\u4e3a5x5\uff0c\u5377\u79ef\u6838\u4e3a3x3\uff0c\u5916\u52a0padding \u4e3a1\uff0c\u5219\u5176\u8f93\u51fa\u5c3a\u5bf8\u4e3a\uff1a \u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5728tf.keras\u4e2d\u5377\u79ef\u6838\u7684\u5b9e\u73b0\u4f7f\u7528 tf . keras . layers . Conv2D ( filters , kernel_size , strides = ( 1 , 1 ), padding = 'valid' , activation = None ) \u4e3b\u8981\u53c2\u6570\u8bf4\u660e\u5982\u4e0b\uff1a 3 \u6c60\u5316\u5c42(Pooling) \u00b6 \u6c60\u5316\u5c42\u8fce\u6765\u964d\u4f4e\u4e86\u540e\u7eed\u7f51\u7edc\u5c42\u7684\u8f93\u5165\u7ef4\u5ea6\uff0c\u7f29\u51cf\u6a21\u578b\u5927\u5c0f\uff0c\u63d0\u9ad8\u8ba1\u7b97\u901f\u5ea6\uff0c\u5e76\u63d0\u9ad8\u4e86Feature Map \u7684\u9c81\u68d2\u6027\uff0c\u9632\u6b62\u8fc7\u62df\u5408\uff0c \u5b83\u4e3b\u8981\u5bf9\u5377\u79ef\u5c42\u5b66\u4e60\u5230\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u4e0b\u91c7\u6837\uff08subsampling\uff09\u5904\u7406\uff0c\u4e3b\u8981\u7531\u4e24\u79cd 3.1 \u6700\u5927\u6c60\u5316 \u00b6 Max Pooling,\u53d6\u7a97\u53e3\u5185\u7684\u6700\u5927\u503c\u4f5c\u4e3a\u8f93\u51fa \uff0c\u8fd9\u79cd\u65b9\u5f0f\u4f7f\u7528\u8f83\u5e7f\u6cdb\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . layers . MaxPool2D ( pool_size = ( 2 , 2 ), strides = None , padding = 'valid' ) \u53c2\u6570\uff1a pool_size: \u6c60\u5316\u7a97\u53e3\u7684\u5927\u5c0f strides: \u7a97\u53e3\u79fb\u52a8\u7684\u6b65\u957f\uff0c\u9ed8\u8ba4\u4e3a1 padding: \u662f\u5426\u8fdb\u884c\u586b\u5145\uff0c\u9ed8\u8ba4\u662f\u4e0d\u8fdb\u884c\u586b\u5145\u7684 3.2 \u5e73\u5747\u6c60\u5316 \u00b6 Avg Pooling,\u53d6\u7a97\u53e3\u5185\u7684\u6240\u6709\u503c\u7684\u5747\u503c\u4f5c\u4e3a\u8f93\u51fa \u5728tf.keras\u4e2d\u5b9e\u73b0\u6c60\u5316\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . layers . AveragePooling2D ( pool_size = ( 2 , 2 ), strides = None , padding = 'valid' ) 4. \u5168\u8fde\u63a5\u5c42 \u00b6 \u5168\u8fde\u63a5\u5c42\u4f4d\u4e8eCNN\u7f51\u7edc\u7684\u672b\u7aef\uff0c\u7ecf\u8fc7\u5377\u79ef\u5c42\u7684\u7279\u5f81\u63d0\u53d6\u4e0e\u6c60\u5316\u5c42\u7684\u964d\u7ef4\u540e\uff0c\u5c06\u7279\u5f81\u56fe\u8f6c\u6362\u6210\u4e00\u7ef4\u5411\u91cf\u9001\u5165\u5230\u5168\u8fde\u63a5\u5c42\u4e2d\u8fdb\u884c\u5206\u7c7b\u6216\u56de\u5f52\u7684\u64cd\u4f5c\u3002 \u5728tf.keras\u4e2d\u5168\u8fde\u63a5\u5c42\u4f7f\u7528tf.keras.dense\u5b9e\u73b0\u3002 5.\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u5efa \u00b6 \u6211\u4eec\u6784\u5efa\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5728mnist\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5904\u7406\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1aLeNet-5\u662f\u4e00\u4e2a\u8f83\u7b80\u5355\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc, \u8f93\u5165\u7684\u4e8c\u7ef4\u56fe\u50cf\uff0c\u5148\u7ecf\u8fc7\u4e24\u6b21\u5377\u79ef\u5c42,\u6c60\u5316\u5c42\uff0c\u518d\u7ecf\u8fc7\u5168\u8fde\u63a5\u5c42\uff0c\u6700\u540e\u4f7f\u7528softmax\u5206\u7c7b\u4f5c\u4e3a\u8f93\u51fa\u5c42\u3002 \u5bfc\u5165\u5de5\u5177\u5305\uff1a import tensorflow as tf # \u6570\u636e\u96c6 from tensorflow.keras.datasets import mnist 5.1 \u6570\u636e\u52a0\u8f7d \u00b6 \u4e0e\u795e\u7ecf\u7f51\u7edc\u7684\u6848\u4f8b\u4e00\u81f4\uff0c\u9996\u5148\u52a0\u8f7d\u6570\u636e\u96c6\uff1a ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () 5.2 \u6570\u636e\u5904\u7406 \u00b6 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u8f93\u5165\u8981\u6c42\u662f\uff1aN H W C \uff0c\u5206\u522b\u662f\u56fe\u7247\u6570\u91cf\uff0c\u56fe\u7247\u9ad8\u5ea6\uff0c\u56fe\u7247\u5bbd\u5ea6\u548c\u56fe\u7247\u7684\u901a\u9053\uff0c\u56e0\u4e3a\u662f\u7070\u5ea6\u56fe\uff0c\u901a\u9053\u4e3a1. # \u6570\u636e\u5904\u7406\uff1anum,h,w,c # \u8bad\u7ec3\u96c6\u6570\u636e train_images = tf . reshape ( train_images , ( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) print ( train_images . shape ) # \u6d4b\u8bd5\u96c6\u6570\u636e test_images = tf . reshape ( test_images , ( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7ed3\u679c\u4e3a\uff1a (60000, 28, 28, 1) 5.3 \u6a21\u578b\u642d\u5efa \u00b6 Lenet-5\u6a21\u578b\u8f93\u5165\u7684\u4e8c\u7ef4\u56fe\u50cf\uff0c\u5148\u7ecf\u8fc7\u4e24\u6b21\u5377\u79ef\u5c42,\u6c60\u5316\u5c42\uff0c\u518d\u7ecf\u8fc7\u5168\u8fde\u63a5\u5c42\uff0c\u6700\u540e\u4f7f\u7528softmax\u5206\u7c7b\u4f5c\u4e3a\u8f93\u51fa\u5c42\uff0c\u6a21\u578b\u6784\u5efa\u5982\u4e0b\uff1a # \u6a21\u578b\u6784\u5efa net = tf . keras . models . Sequential ([ # \u5377\u79ef\u5c42\uff1a6\u4e2a5*5\u7684\u5377\u79ef\u6838\uff0c\u6fc0\u6d3b\u662fsigmoid tf . keras . layers . Conv2D ( filters = 6 , kernel_size = 5 , activation = 'sigmoid' , input_shape = ( 28 , 28 , 1 )), # \u6700\u5927\u6c60\u5316 tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 ), # \u5377\u79ef\u5c42\uff1a16\u4e2a5*5\u7684\u5377\u79ef\u6838,\u6fc0\u6d3b\u662fsigmoid tf . keras . layers . Conv2D ( filters = 16 , kernel_size = 5 , activation = 'sigmoid' ), # \u6700\u5927\u6c60\u5316 tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 ), # \u7ef4\u5ea6\u8c03\u6574\u4e3a1\u7ef4\u6570\u636e tf . keras . layers . Flatten (), # \u5168\u5377\u79ef\u5c42\uff0c\u6fc0\u6d3bsigmoid tf . keras . layers . Dense ( 120 , activation = 'sigmoid' ), # \u5168\u5377\u79ef\u5c42\uff0c\u6fc0\u6d3bsigmoid tf . keras . layers . Dense ( 84 , activation = 'sigmoid' ), # \u5168\u5377\u79ef\u5c42\uff0c\u6fc0\u6d3bsoftmax tf . keras . layers . Dense ( 10 , activation = 'softmax' ) ]) \u6211\u4eec\u901a\u8fc7net.summary()\u67e5\u770b\u7f51\u7edc\u7ed3\u6784\uff1a Model : \"sequential_11\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= conv2d_4 ( Conv2D ) ( None , 24 , 24 , 6 ) 156 _________________________________________________________________ max_pooling2d_4 ( MaxPooling2 ( None , 12 , 12 , 6 ) 0 _________________________________________________________________ conv2d_5 ( Conv2D ) ( None , 8 , 8 , 16 ) 2416 _________________________________________________________________ max_pooling2d_5 ( MaxPooling2 ( None , 4 , 4 , 16 ) 0 _________________________________________________________________ flatten_2 ( Flatten ) ( None , 256 ) 0 _________________________________________________________________ dense_25 ( Dense ) ( None , 120 ) 30840 _________________________________________________________________ dense_26 ( Dense ) ( None , 84 ) 10164 dense_27 ( Dense ) ( None , 10 ) 850 ================================================================= Total params : 44 , 426 Trainable params : 44 , 426 Non - trainable params : 0 ______________________________________________________________ \u3010\u6269\u5c55\ud83d\udcda\uff1a\u53c2\u6570\u91cf\u8ba1\u7b97\u3011 \u624b\u5199\u6570\u5b57\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u4e3a28x28x1\uff0c\u5982\u4e0b\u56fe\uff0c\u6211\u4eec\u6765\u770b\u4e0b\u5377\u79ef\u5c42\u7684\u53c2\u6570\u91cf\uff1a conv1\u4e2d\u7684\u5377\u79ef\u6838\u4e3a5x5x1,\u5377\u79ef\u6838\u4e2a\u6570\u4e3a6\uff0c\u6bcf\u4e2a\u5377\u79ef\u6838\u6709\u4e00\u4e2abias\uff0c\u6240\u4ee5\u53c2\u6570\u91cf\u4e3a\uff1a5x5x1x6+6=156\u3002 conv2\u4e2d\u7684\u5377\u79ef\u6838\u4e3a5x5x6,\u5377\u79ef\u6838\u4e2a\u6570\u4e3a16\uff0c\u6bcf\u4e2a\u5377\u79ef\u6838\u6709\u4e00\u4e2abias\uff0c\u6240\u4ee5\u53c2\u6570\u91cf\u4e3a:5x5x6x16+16 = 2416\u3002 5.4 \u6a21\u578b\u7f16\u8bd1 \u00b6 \u8bbe\u7f6e\u4f18\u5316\u5668\u548c\u635f\u5931\u51fd\u6570\uff1a # \u4f18\u5316\u5668 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.9 ) # \u6a21\u578b\u7f16\u8bd1\uff1a\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u5668\u548c\u8bc4\u4ef7\u6307\u6807 net . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ]) 5.5 \u6a21\u578b\u8bad\u7ec3 \u00b6 \u6a21\u578b\u8bad\u7ec3\uff1a # \u6a21\u578b\u8bad\u7ec3 net . fit ( train_images , train_labels , epochs = 5 , validation_split = 0.1 ) \u8bad\u7ec3\u6d41\u7a0b\uff1a Epoch 1 / 5 1688 / 1688 [ ============================== ] - 10 s 6 ms / step - loss : 0.8255 - accuracy : 0.6990 - val_loss : 0.1458 - val_accuracy : 0.9543 Epoch 2 / 5 1688 / 1688 [ ============================== ] - 10 s 6 ms / step - loss : 0.1268 - accuracy : 0.9606 - val_loss : 0.0878 - val_accuracy : 0.9717 Epoch 3 / 5 1688 / 1688 [ ============================== ] - 10 s 6 ms / step - loss : 0.1054 - accuracy : 0.9664 - val_loss : 0.1025 - val_accuracy : 0.9688 Epoch 4 / 5 1688 / 1688 [ ============================== ] - 11 s 6 ms / step - loss : 0.0810 - accuracy : 0.9742 - val_loss : 0.0656 - val_accuracy : 0.9807 Epoch 5 / 5 1688 / 1688 [ ============================== ] - 11 s 6 ms / step - loss : 0.0732 - accuracy : 0.9765 - val_loss : 0.0702 - val_accuracy : 0.9807 5.6 \u6a21\u578b\u8bc4\u4f30 \u00b6 # \u6a21\u578b\u8bc4\u4f30 score = net . evaluate ( test_images , test_labels , verbose = 1 ) print ( 'Test accuracy:' , score [ 1 ]) \u8f93\u51fa\u4e3a\uff1a 313 / 313 [ ============================== ] - 1 s 2 ms / step - loss : 0.0689 - accuracy : 0.9780 Test accuracy : 0.9779999852180481 \u4e0e\u4f7f\u7528\u5168\u8fde\u63a5\u7f51\u7edc\u76f8\u6bd4\uff0c\u51c6\u786e\u5ea6\u63d0\u9ad8\u4e86\u5f88\u591a\u3002 \u5377\u79ef\u795e\u7ecf\u7f51\u8def\u7684\u7ec4\u6210 \u5377\u79ef\u5c42\uff0c\u6c60\u5316\u5c42\uff0c\u5168\u8fde\u63a5\u5c42 \u5377\u79ef\u5c42 \u5377\u79ef\u7684\u8ba1\u7b97\u8fc7\u7a0b\uff0cstride,padding... \u6c60\u5316\u5c42 \u6700\u5927\u6c60\u5316\u548c\u5e73\u5747\u6c60\u5316 CNN\u7ed3\u6784\u7684\u5b9e\u73b0\u548c\u6784\u5efa\u5b9e\u73b0\u7a0b\u5e8f","title":"\u5377\u79ef\u795e\u7ecf\u7f51\u7edcCNN"},{"location":"deeplearning/section6/#26-cnn","text":"\u5b66\u4e60\u76ee\u6807 \u4e86\u89e3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u6210 \u77e5\u9053\u5377\u79ef\u7684\u539f\u7406\u4ee5\u53ca\u8ba1\u7b97\u8fc7\u7a0b \u4e86\u89e3\u6c60\u5316\u7684\u4f5c\u7528\u4ee5\u53ca\u8ba1\u7b97\u8fc7\u7a0b \u5229\u7528\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\u5bf9\u56fe\u50cf\u8fdb\u884c\u5904\u7406\u5b58\u5728\u4ee5\u4e0b\u4e24\u4e2a\u95ee\u9898\uff1a \u9700\u8981\u5904\u7406\u7684\u6570\u636e\u91cf\u5927\uff0c\u6548\u7387\u4f4e \u5047\u5982\u6211\u4eec\u5904\u7406\u4e00\u5f20 1000\u00d71000 \u50cf\u7d20\u7684\u56fe\u7247\uff0c\u53c2\u6570\u91cf\u5982\u4e0b\uff1a 1000\u00d71000\u00d73=3,000,000 \u8fd9\u4e48\u5927\u91cf\u7684\u6570\u636e\u5904\u7406\u8d77\u6765\u662f\u975e\u5e38\u6d88\u8017\u8d44\u6e90\u7684 \u56fe\u50cf\u5728\u7ef4\u5ea6\u8c03\u6574\u7684\u8fc7\u7a0b\u4e2d\u5f88\u96be\u4fdd\u7559\u539f\u6709\u7684\u7279\u5f81\uff0c\u5bfc\u81f4\u56fe\u50cf\u5904\u7406\u7684\u51c6\u786e\u7387\u4e0d\u9ad8 \u5047\u5982\u6709\u5706\u5f62\u662f1\uff0c\u6ca1\u6709\u5706\u5f62\u662f0\uff0c\u90a3\u4e48\u5706\u5f62\u7684\u4f4d\u7f6e\u4e0d\u540c\u5c31\u4f1a\u4ea7\u751f\u5b8c\u5168\u4e0d\u540c\u7684\u6570\u636e\u8868\u8fbe\u3002\u4f46\u662f\u4ece\u56fe\u50cf\u7684\u89d2\u5ea6\u6765\u770b\uff0c \u56fe\u50cf\u7684\u5185\u5bb9\uff08\u672c\u8d28\uff09\u5e76\u6ca1\u6709\u53d1\u751f\u53d8\u5316\uff0c\u53ea\u662f\u4f4d\u7f6e\u53d1\u751f\u4e86\u53d8\u5316 \u3002\u6240\u4ee5\u5f53\u6211\u4eec\u79fb\u52a8\u56fe\u50cf\u4e2d\u7684\u7269\u4f53\uff0c\u7528\u5168\u8fde\u63a5\u5347\u964d\u5f97\u5230\u7684\u7ed3\u679c\u4f1a\u5dee\u5f02\u5f88\u5927\uff0c\u8fd9\u662f\u4e0d\u7b26\u5408\u56fe\u50cf\u5904\u7406\u7684\u8981\u6c42\u7684\u3002","title":"2.6 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc(CNN)"},{"location":"deeplearning/section6/#1cnn","text":"CNN\u7f51\u7edc\u53d7\u4eba\u7c7b\u89c6\u89c9\u795e\u7ecf\u7cfb\u7edf\u7684\u542f\u53d1\uff0c\u4eba\u7c7b\u7684\u89c6\u89c9\u539f\u7406\uff1a\u4ece\u539f\u59cb\u4fe1\u53f7\u6444\u5165\u5f00\u59cb\uff08\u77b3\u5b54\u6444\u5165\u50cf\u7d20 Pixels\uff09\uff0c\u63a5\u7740\u505a\u521d\u6b65\u5904\u7406\uff08\u5927\u8111\u76ae\u5c42\u67d0\u4e9b\u7ec6\u80de\u53d1\u73b0\u8fb9\u7f18\u548c\u65b9\u5411\uff09\uff0c\u7136\u540e\u62bd\u8c61\uff08\u5927\u8111\u5224\u5b9a\uff0c\u773c\u524d\u7684\u7269\u4f53\u7684\u5f62\u72b6\uff0c\u662f\u5706\u5f62\u7684\uff09\uff0c\u7136\u540e\u8fdb\u4e00\u6b65\u62bd\u8c61\uff08\u5927\u8111\u8fdb\u4e00\u6b65\u5224\u5b9a\u8be5\u7269\u4f53\u662f\u53ea\u4eba\u8138\uff09\u3002\u4e0b\u9762\u662f\u4eba\u8111\u8fdb\u884c\u4eba\u8138\u8bc6\u522b\u7684\u4e00\u4e2a\u793a\u4f8b\uff1a CNN\u7f51\u7edc\u4e3b\u8981\u6709\u4e09\u90e8\u5206\u6784\u6210\uff1a\u5377\u79ef\u5c42\u3001\u6c60\u5316\u5c42\u548c\u5168\u8fde\u63a5\u5c42\u6784\u6210\uff0c\u5176\u4e2d\u5377\u79ef\u5c42\u8d1f\u8d23\u63d0\u53d6\u56fe\u50cf\u4e2d\u7684\u5c40\u90e8\u7279\u5f81\uff1b\u6c60\u5316\u5c42\u7528\u6765\u5927\u5e45\u964d\u4f4e\u53c2\u6570\u91cf\u7ea7(\u964d\u7ef4)\uff1b\u5168\u8fde\u63a5\u5c42\u7c7b\u4f3c\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7684\u90e8\u5206\uff0c\u7528\u6765\u8f93\u51fa\u60f3\u8981\u7684\u7ed3\u679c\u3002 \u6574\u4e2aCNN\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a","title":"1.CNN\u7f51\u7edc\u7684\u6784\u6210"},{"location":"deeplearning/section6/#2","text":"\u5377\u79ef\u5c42\u662f\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6838\u5fc3\u6a21\u5757\uff0c\u5377\u79ef\u5c42\u7684\u76ee\u7684\u662f\u63d0\u53d6\u8f93\u5165\u7279\u5f81\u56fe\u7684\u7279\u5f81\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5377\u79ef\u6838\u53ef\u4ee5\u63d0\u53d6\u56fe\u50cf\u4e2d\u7684\u8fb9\u7f18\u4fe1\u606f\u3002","title":"2. \u5377\u79ef\u5c42"},{"location":"deeplearning/section6/#21","text":"\u90a3\u5377\u79ef\u662f\u600e\u4e48\u8fdb\u884c\u8ba1\u7b97\u7684\u5462\uff1f \u5377\u79ef\u8fd0\u7b97\u672c\u8d28\u4e0a\u5c31\u662f\u5728\u6ee4\u6ce2\u5668\u548c\u8f93\u5165\u6570\u636e\u7684\u5c40\u90e8\u533a\u57df\u95f4\u505a\u70b9\u79ef\u3002 \u5de6\u4e0a\u89d2\u7684\u70b9\u8ba1\u7b97\u65b9\u6cd5\uff1a \u540c\u7406\u53ef\u4ee5\u8ba1\u7b97\u5176\u4ed6\u5404\u70b9\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u5377\u79ef\u7ed3\u679c\uff0c \u6700\u540e\u4e00\u70b9\u7684\u8ba1\u7b97\u65b9\u6cd5\u662f\uff1a","title":"2.1 \u5377\u79ef\u7684\u8ba1\u7b97\u65b9\u6cd5"},{"location":"deeplearning/section6/#22-padding","text":"\u5728\u4e0a\u8ff0\u5377\u79ef\u8fc7\u7a0b\u4e2d\uff0c\u7279\u5f81\u56fe\u6bd4\u539f\u59cb\u56fe\u51cf\u5c0f\u4e86\u5f88\u591a\uff0c\u6211\u4eec\u53ef\u4ee5\u5728\u539f\u56fe\u50cf\u7684\u5468\u56f4\u8fdb\u884cpadding,\u6765\u4fdd\u8bc1\u5728\u5377\u79ef\u8fc7\u7a0b\u4e2d\u7279\u5f81\u56fe\u5927\u5c0f\u4e0d\u53d8\u3002","title":"2.2 padding"},{"location":"deeplearning/section6/#23-stride","text":"\u6309\u7167\u6b65\u957f\u4e3a1\u6765\u79fb\u52a8\u5377\u79ef\u6838\uff0c\u8ba1\u7b97\u7279\u5f81\u56fe\u5982\u4e0b\u6240\u793a\uff1a \u5982\u679c\u6211\u4eec\u628astride\u589e\u5927,\u6bd4\u5982\u8bbe\u4e3a2\uff0c\u4e5f\u662f\u53ef\u4ee5\u63d0\u53d6\u7279\u5f81\u56fe\u7684\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a","title":"2.3 stride"},{"location":"deeplearning/section6/#24","text":"\u5b9e\u9645\u4e2d\u7684\u56fe\u50cf\u90fd\u662f\u591a\u4e2a\u901a\u9053\u7ec4\u6210\u7684\uff0c\u6211\u4eec\u600e\u4e48\u8ba1\u7b97\u5377\u79ef\u5462\uff1f \u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\uff1a\u5f53\u8f93\u5165\u6709\u591a\u4e2a\u901a\u9053\uff08channel\uff09\u65f6(\u4f8b\u5982\u56fe\u7247\u53ef\u4ee5\u6709 RGB \u4e09\u4e2a\u901a\u9053)\uff0c\u5377\u79ef\u6838\u9700\u8981\u62e5\u6709\u76f8\u540c\u7684channel\u6570,\u6bcf\u4e2a\u5377\u79ef\u6838 channel \u4e0e\u8f93\u5165\u5c42\u7684\u5bf9\u5e94 channel \u8fdb\u884c\u5377\u79ef\uff0c\u5c06\u6bcf\u4e2a channel \u7684\u5377\u79ef\u7ed3\u679c\u6309\u4f4d\u76f8\u52a0\u5f97\u5230\u6700\u7ec8\u7684 Feature Map","title":"2.4 \u591a\u901a\u9053\u5377\u79ef"},{"location":"deeplearning/section6/#25","text":"\u5982\u679c\u6709\u591a\u4e2a\u5377\u79ef\u6838\u65f6\u600e\u4e48\u8ba1\u7b97\u5462\uff1f\u5f53\u6709\u591a\u4e2a\u5377\u79ef\u6838\u65f6\uff0c\u6bcf\u4e2a\u5377\u79ef\u6838\u5b66\u4e60\u5230\u4e0d\u540c\u7684\u7279\u5f81\uff0c\u5bf9\u5e94\u4ea7\u751f\u5305\u542b\u591a\u4e2a channel \u7684 Feature Map, \u4f8b\u5982\u4e0b\u56fe\u6709\u4e24\u4e2a filter\uff0c\u6240\u4ee5 output \u6709\u4e24\u4e2a channel\u3002","title":"2.5 \u591a\u5377\u79ef\u6838\u5377\u79ef"},{"location":"deeplearning/section6/#26","text":"\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u4e0e\u4ee5\u4e0b\u53c2\u6570\u606f\u606f\u76f8\u5173\uff1a * size:\u5377\u79ef\u6838/\u8fc7\u6ee4\u5668\u5927\u5c0f\uff0c\u4e00\u822c\u4f1a\u9009\u62e9\u4e3a\u5947\u6570\uff0c\u6bd4\u5982\u67091 * 1\uff0c 3 * 3\uff0c 5 * 5 * padding\uff1a\u96f6\u586b\u5145\u7684\u65b9\u5f0f * stride:\u6b65\u957f \u90a3\u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8f93\u5165\u7279\u5f81\u56fe\u4e3a5x5\uff0c\u5377\u79ef\u6838\u4e3a3x3\uff0c\u5916\u52a0padding \u4e3a1\uff0c\u5219\u5176\u8f93\u51fa\u5c3a\u5bf8\u4e3a\uff1a \u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5728tf.keras\u4e2d\u5377\u79ef\u6838\u7684\u5b9e\u73b0\u4f7f\u7528 tf . keras . layers . Conv2D ( filters , kernel_size , strides = ( 1 , 1 ), padding = 'valid' , activation = None ) \u4e3b\u8981\u53c2\u6570\u8bf4\u660e\u5982\u4e0b\uff1a","title":"2.6 \u7279\u5f81\u56fe\u5927\u5c0f"},{"location":"deeplearning/section6/#3-pooling","text":"\u6c60\u5316\u5c42\u8fce\u6765\u964d\u4f4e\u4e86\u540e\u7eed\u7f51\u7edc\u5c42\u7684\u8f93\u5165\u7ef4\u5ea6\uff0c\u7f29\u51cf\u6a21\u578b\u5927\u5c0f\uff0c\u63d0\u9ad8\u8ba1\u7b97\u901f\u5ea6\uff0c\u5e76\u63d0\u9ad8\u4e86Feature Map \u7684\u9c81\u68d2\u6027\uff0c\u9632\u6b62\u8fc7\u62df\u5408\uff0c \u5b83\u4e3b\u8981\u5bf9\u5377\u79ef\u5c42\u5b66\u4e60\u5230\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u4e0b\u91c7\u6837\uff08subsampling\uff09\u5904\u7406\uff0c\u4e3b\u8981\u7531\u4e24\u79cd","title":"3 \u6c60\u5316\u5c42(Pooling)"},{"location":"deeplearning/section6/#31","text":"Max Pooling,\u53d6\u7a97\u53e3\u5185\u7684\u6700\u5927\u503c\u4f5c\u4e3a\u8f93\u51fa \uff0c\u8fd9\u79cd\u65b9\u5f0f\u4f7f\u7528\u8f83\u5e7f\u6cdb\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . layers . MaxPool2D ( pool_size = ( 2 , 2 ), strides = None , padding = 'valid' ) \u53c2\u6570\uff1a pool_size: \u6c60\u5316\u7a97\u53e3\u7684\u5927\u5c0f strides: \u7a97\u53e3\u79fb\u52a8\u7684\u6b65\u957f\uff0c\u9ed8\u8ba4\u4e3a1 padding: \u662f\u5426\u8fdb\u884c\u586b\u5145\uff0c\u9ed8\u8ba4\u662f\u4e0d\u8fdb\u884c\u586b\u5145\u7684","title":"3.1 \u6700\u5927\u6c60\u5316"},{"location":"deeplearning/section6/#32","text":"Avg Pooling,\u53d6\u7a97\u53e3\u5185\u7684\u6240\u6709\u503c\u7684\u5747\u503c\u4f5c\u4e3a\u8f93\u51fa \u5728tf.keras\u4e2d\u5b9e\u73b0\u6c60\u5316\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . layers . AveragePooling2D ( pool_size = ( 2 , 2 ), strides = None , padding = 'valid' )","title":"3.2 \u5e73\u5747\u6c60\u5316"},{"location":"deeplearning/section6/#4","text":"\u5168\u8fde\u63a5\u5c42\u4f4d\u4e8eCNN\u7f51\u7edc\u7684\u672b\u7aef\uff0c\u7ecf\u8fc7\u5377\u79ef\u5c42\u7684\u7279\u5f81\u63d0\u53d6\u4e0e\u6c60\u5316\u5c42\u7684\u964d\u7ef4\u540e\uff0c\u5c06\u7279\u5f81\u56fe\u8f6c\u6362\u6210\u4e00\u7ef4\u5411\u91cf\u9001\u5165\u5230\u5168\u8fde\u63a5\u5c42\u4e2d\u8fdb\u884c\u5206\u7c7b\u6216\u56de\u5f52\u7684\u64cd\u4f5c\u3002 \u5728tf.keras\u4e2d\u5168\u8fde\u63a5\u5c42\u4f7f\u7528tf.keras.dense\u5b9e\u73b0\u3002","title":"4. \u5168\u8fde\u63a5\u5c42"},{"location":"deeplearning/section6/#5","text":"\u6211\u4eec\u6784\u5efa\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5728mnist\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5904\u7406\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1aLeNet-5\u662f\u4e00\u4e2a\u8f83\u7b80\u5355\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc, \u8f93\u5165\u7684\u4e8c\u7ef4\u56fe\u50cf\uff0c\u5148\u7ecf\u8fc7\u4e24\u6b21\u5377\u79ef\u5c42,\u6c60\u5316\u5c42\uff0c\u518d\u7ecf\u8fc7\u5168\u8fde\u63a5\u5c42\uff0c\u6700\u540e\u4f7f\u7528softmax\u5206\u7c7b\u4f5c\u4e3a\u8f93\u51fa\u5c42\u3002 \u5bfc\u5165\u5de5\u5177\u5305\uff1a import tensorflow as tf # \u6570\u636e\u96c6 from tensorflow.keras.datasets import mnist","title":"5.\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u5efa"},{"location":"deeplearning/section6/#51","text":"\u4e0e\u795e\u7ecf\u7f51\u7edc\u7684\u6848\u4f8b\u4e00\u81f4\uff0c\u9996\u5148\u52a0\u8f7d\u6570\u636e\u96c6\uff1a ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data ()","title":"5.1 \u6570\u636e\u52a0\u8f7d"},{"location":"deeplearning/section6/#52","text":"\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u8f93\u5165\u8981\u6c42\u662f\uff1aN H W C \uff0c\u5206\u522b\u662f\u56fe\u7247\u6570\u91cf\uff0c\u56fe\u7247\u9ad8\u5ea6\uff0c\u56fe\u7247\u5bbd\u5ea6\u548c\u56fe\u7247\u7684\u901a\u9053\uff0c\u56e0\u4e3a\u662f\u7070\u5ea6\u56fe\uff0c\u901a\u9053\u4e3a1. # \u6570\u636e\u5904\u7406\uff1anum,h,w,c # \u8bad\u7ec3\u96c6\u6570\u636e train_images = tf . reshape ( train_images , ( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) print ( train_images . shape ) # \u6d4b\u8bd5\u96c6\u6570\u636e test_images = tf . reshape ( test_images , ( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7ed3\u679c\u4e3a\uff1a (60000, 28, 28, 1)","title":"5.2 \u6570\u636e\u5904\u7406"},{"location":"deeplearning/section6/#53","text":"Lenet-5\u6a21\u578b\u8f93\u5165\u7684\u4e8c\u7ef4\u56fe\u50cf\uff0c\u5148\u7ecf\u8fc7\u4e24\u6b21\u5377\u79ef\u5c42,\u6c60\u5316\u5c42\uff0c\u518d\u7ecf\u8fc7\u5168\u8fde\u63a5\u5c42\uff0c\u6700\u540e\u4f7f\u7528softmax\u5206\u7c7b\u4f5c\u4e3a\u8f93\u51fa\u5c42\uff0c\u6a21\u578b\u6784\u5efa\u5982\u4e0b\uff1a # \u6a21\u578b\u6784\u5efa net = tf . keras . models . Sequential ([ # \u5377\u79ef\u5c42\uff1a6\u4e2a5*5\u7684\u5377\u79ef\u6838\uff0c\u6fc0\u6d3b\u662fsigmoid tf . keras . layers . Conv2D ( filters = 6 , kernel_size = 5 , activation = 'sigmoid' , input_shape = ( 28 , 28 , 1 )), # \u6700\u5927\u6c60\u5316 tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 ), # \u5377\u79ef\u5c42\uff1a16\u4e2a5*5\u7684\u5377\u79ef\u6838,\u6fc0\u6d3b\u662fsigmoid tf . keras . layers . Conv2D ( filters = 16 , kernel_size = 5 , activation = 'sigmoid' ), # \u6700\u5927\u6c60\u5316 tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 ), # \u7ef4\u5ea6\u8c03\u6574\u4e3a1\u7ef4\u6570\u636e tf . keras . layers . Flatten (), # \u5168\u5377\u79ef\u5c42\uff0c\u6fc0\u6d3bsigmoid tf . keras . layers . Dense ( 120 , activation = 'sigmoid' ), # \u5168\u5377\u79ef\u5c42\uff0c\u6fc0\u6d3bsigmoid tf . keras . layers . Dense ( 84 , activation = 'sigmoid' ), # \u5168\u5377\u79ef\u5c42\uff0c\u6fc0\u6d3bsoftmax tf . keras . layers . Dense ( 10 , activation = 'softmax' ) ]) \u6211\u4eec\u901a\u8fc7net.summary()\u67e5\u770b\u7f51\u7edc\u7ed3\u6784\uff1a Model : \"sequential_11\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= conv2d_4 ( Conv2D ) ( None , 24 , 24 , 6 ) 156 _________________________________________________________________ max_pooling2d_4 ( MaxPooling2 ( None , 12 , 12 , 6 ) 0 _________________________________________________________________ conv2d_5 ( Conv2D ) ( None , 8 , 8 , 16 ) 2416 _________________________________________________________________ max_pooling2d_5 ( MaxPooling2 ( None , 4 , 4 , 16 ) 0 _________________________________________________________________ flatten_2 ( Flatten ) ( None , 256 ) 0 _________________________________________________________________ dense_25 ( Dense ) ( None , 120 ) 30840 _________________________________________________________________ dense_26 ( Dense ) ( None , 84 ) 10164 dense_27 ( Dense ) ( None , 10 ) 850 ================================================================= Total params : 44 , 426 Trainable params : 44 , 426 Non - trainable params : 0 ______________________________________________________________ \u3010\u6269\u5c55\ud83d\udcda\uff1a\u53c2\u6570\u91cf\u8ba1\u7b97\u3011 \u624b\u5199\u6570\u5b57\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u4e3a28x28x1\uff0c\u5982\u4e0b\u56fe\uff0c\u6211\u4eec\u6765\u770b\u4e0b\u5377\u79ef\u5c42\u7684\u53c2\u6570\u91cf\uff1a conv1\u4e2d\u7684\u5377\u79ef\u6838\u4e3a5x5x1,\u5377\u79ef\u6838\u4e2a\u6570\u4e3a6\uff0c\u6bcf\u4e2a\u5377\u79ef\u6838\u6709\u4e00\u4e2abias\uff0c\u6240\u4ee5\u53c2\u6570\u91cf\u4e3a\uff1a5x5x1x6+6=156\u3002 conv2\u4e2d\u7684\u5377\u79ef\u6838\u4e3a5x5x6,\u5377\u79ef\u6838\u4e2a\u6570\u4e3a16\uff0c\u6bcf\u4e2a\u5377\u79ef\u6838\u6709\u4e00\u4e2abias\uff0c\u6240\u4ee5\u53c2\u6570\u91cf\u4e3a:5x5x6x16+16 = 2416\u3002","title":"5.3 \u6a21\u578b\u642d\u5efa"},{"location":"deeplearning/section6/#54","text":"\u8bbe\u7f6e\u4f18\u5316\u5668\u548c\u635f\u5931\u51fd\u6570\uff1a # \u4f18\u5316\u5668 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.9 ) # \u6a21\u578b\u7f16\u8bd1\uff1a\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u5668\u548c\u8bc4\u4ef7\u6307\u6807 net . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ])","title":"5.4 \u6a21\u578b\u7f16\u8bd1"},{"location":"deeplearning/section6/#55","text":"\u6a21\u578b\u8bad\u7ec3\uff1a # \u6a21\u578b\u8bad\u7ec3 net . fit ( train_images , train_labels , epochs = 5 , validation_split = 0.1 ) \u8bad\u7ec3\u6d41\u7a0b\uff1a Epoch 1 / 5 1688 / 1688 [ ============================== ] - 10 s 6 ms / step - loss : 0.8255 - accuracy : 0.6990 - val_loss : 0.1458 - val_accuracy : 0.9543 Epoch 2 / 5 1688 / 1688 [ ============================== ] - 10 s 6 ms / step - loss : 0.1268 - accuracy : 0.9606 - val_loss : 0.0878 - val_accuracy : 0.9717 Epoch 3 / 5 1688 / 1688 [ ============================== ] - 10 s 6 ms / step - loss : 0.1054 - accuracy : 0.9664 - val_loss : 0.1025 - val_accuracy : 0.9688 Epoch 4 / 5 1688 / 1688 [ ============================== ] - 11 s 6 ms / step - loss : 0.0810 - accuracy : 0.9742 - val_loss : 0.0656 - val_accuracy : 0.9807 Epoch 5 / 5 1688 / 1688 [ ============================== ] - 11 s 6 ms / step - loss : 0.0732 - accuracy : 0.9765 - val_loss : 0.0702 - val_accuracy : 0.9807","title":"5.5 \u6a21\u578b\u8bad\u7ec3"},{"location":"deeplearning/section6/#56","text":"# \u6a21\u578b\u8bc4\u4f30 score = net . evaluate ( test_images , test_labels , verbose = 1 ) print ( 'Test accuracy:' , score [ 1 ]) \u8f93\u51fa\u4e3a\uff1a 313 / 313 [ ============================== ] - 1 s 2 ms / step - loss : 0.0689 - accuracy : 0.9780 Test accuracy : 0.9779999852180481 \u4e0e\u4f7f\u7528\u5168\u8fde\u63a5\u7f51\u7edc\u76f8\u6bd4\uff0c\u51c6\u786e\u5ea6\u63d0\u9ad8\u4e86\u5f88\u591a\u3002 \u5377\u79ef\u795e\u7ecf\u7f51\u8def\u7684\u7ec4\u6210 \u5377\u79ef\u5c42\uff0c\u6c60\u5316\u5c42\uff0c\u5168\u8fde\u63a5\u5c42 \u5377\u79ef\u5c42 \u5377\u79ef\u7684\u8ba1\u7b97\u8fc7\u7a0b\uff0cstride,padding... \u6c60\u5316\u5c42 \u6700\u5927\u6c60\u5316\u548c\u5e73\u5747\u6c60\u5316 CNN\u7ed3\u6784\u7684\u5b9e\u73b0\u548c\u6784\u5efa\u5b9e\u73b0\u7a0b\u5e8f","title":"5.6 \u6a21\u578b\u8bc4\u4f30"},{"location":"imageClassification/","text":"\u56fe\u50cf\u5206\u7c7b(Image Classification)2 \u00b6 \u77e5\u9053\u5c40\u90e8\u6700\u4f18\u95ee\u9898\u3001\u978d\u70b9\u4e0e\u6d77\u68ee\u77e9\u9635 \u8bf4\u660e\u6279\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u7684\u4f18\u5316 \u8bf4\u660e\u4e09\u79cd\u7c7b\u578b\u7684\u4f18\u5316\u7b97\u6cd5 \u77e5\u9053\u5b66\u4e60\u7387\u9000\u706b\u7b56\u7565 \u77e5\u9053\u53c2\u6570\u521d\u59cb\u5316\u7b56\u7565\u4e0e\u8f93\u5165\u5f52\u4e00\u5316\u7b56\u7565 \u5e94\u7528\u5b8c\u6210\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u7b97\u6cd5\u7684\u5b9e\u73b0 \u77e5\u9053\u504f\u5dee\u4e0e\u65b9\u5dee\u7684\u610f\u4e49 \u638c\u63e1L2\u6b63\u5219\u5316\u4e0eL1\u6b63\u5219\u5316\u7684\u6570\u5b66\u539f\u7406 \u638c\u63e1droupout\u539f\u7406\u4ee5\u53ca\u65b9\u6cd5 \u77e5\u9053\u6b63\u5219\u5316\u7684\u4f5c\u7528\u5e94\u7528 \u5e94\u7528\u5b8c\u6210dropout\u7684\u5b9e\u73b0 \u4e86\u89e3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u6210 \u8bb0\u5fc6\u5377\u79ef\u7684\u539f\u7406\u4ee5\u53ca\u8ba1\u7b97\u8fc7\u7a0b \u4e86\u89e3\u6c60\u5316\u7684\u4f5c\u7528\u4ee5\u53ca\u8ba1\u7b97\u8fc7\u7a0b \u77e5\u9053LeNet-5\u7f51\u7edc\u7ed3\u6784 \u4e86\u89e3\u7ecf\u5178\u7684\u5206\u7c7b\u7f51\u7edc\u7ed3\u6784 \u8bf4\u660e\u4e00\u4e9b\u5e38\u89c1\u7684\u5377\u673a\u7f51\u7edc\u7ed3\u6784\u7684\u4f18\u5316 \u77e5\u9053NIN\u4e2d1x1\u5377\u79ef\u539f\u7406\u4ee5\u53ca\u4f5c\u7528 \u77e5\u9053Inception\u7684\u4f5c\u7528 \u8bf4\u660eResNet\u7684\u7ed3\u6784\u7279\u70b9 \u4e86\u89e3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u8fc7\u7a0b\u5185\u5bb9","title":"\u56fe\u50cf\u5206\u7c7b(Image Classification)2"},{"location":"imageClassification/#image-classification2","text":"\u77e5\u9053\u5c40\u90e8\u6700\u4f18\u95ee\u9898\u3001\u978d\u70b9\u4e0e\u6d77\u68ee\u77e9\u9635 \u8bf4\u660e\u6279\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u7684\u4f18\u5316 \u8bf4\u660e\u4e09\u79cd\u7c7b\u578b\u7684\u4f18\u5316\u7b97\u6cd5 \u77e5\u9053\u5b66\u4e60\u7387\u9000\u706b\u7b56\u7565 \u77e5\u9053\u53c2\u6570\u521d\u59cb\u5316\u7b56\u7565\u4e0e\u8f93\u5165\u5f52\u4e00\u5316\u7b56\u7565 \u5e94\u7528\u5b8c\u6210\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u7b97\u6cd5\u7684\u5b9e\u73b0 \u77e5\u9053\u504f\u5dee\u4e0e\u65b9\u5dee\u7684\u610f\u4e49 \u638c\u63e1L2\u6b63\u5219\u5316\u4e0eL1\u6b63\u5219\u5316\u7684\u6570\u5b66\u539f\u7406 \u638c\u63e1droupout\u539f\u7406\u4ee5\u53ca\u65b9\u6cd5 \u77e5\u9053\u6b63\u5219\u5316\u7684\u4f5c\u7528\u5e94\u7528 \u5e94\u7528\u5b8c\u6210dropout\u7684\u5b9e\u73b0 \u4e86\u89e3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u6210 \u8bb0\u5fc6\u5377\u79ef\u7684\u539f\u7406\u4ee5\u53ca\u8ba1\u7b97\u8fc7\u7a0b \u4e86\u89e3\u6c60\u5316\u7684\u4f5c\u7528\u4ee5\u53ca\u8ba1\u7b97\u8fc7\u7a0b \u77e5\u9053LeNet-5\u7f51\u7edc\u7ed3\u6784 \u4e86\u89e3\u7ecf\u5178\u7684\u5206\u7c7b\u7f51\u7edc\u7ed3\u6784 \u8bf4\u660e\u4e00\u4e9b\u5e38\u89c1\u7684\u5377\u673a\u7f51\u7edc\u7ed3\u6784\u7684\u4f18\u5316 \u77e5\u9053NIN\u4e2d1x1\u5377\u79ef\u539f\u7406\u4ee5\u53ca\u4f5c\u7528 \u77e5\u9053Inception\u7684\u4f5c\u7528 \u8bf4\u660eResNet\u7684\u7ed3\u6784\u7279\u70b9 \u4e86\u89e3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u8fc7\u7a0b\u5185\u5bb9","title":"\u56fe\u50cf\u5206\u7c7b(Image Classification)2"},{"location":"imageClassification/section1/","text":"3.1 \u56fe\u50cf\u5206\u7c7b\u7b80\u4ecb \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u56fe\u50cf\u5206\u7c7b\u7684\u76ee\u7684 \u77e5\u9053imageNet\u6570\u636e\u96c6 1 \u56fe\u50cf\u5206\u7c7b \u00b6 \u56fe\u50cf\u5206\u7c7b\u5b9e\u8d28\u4e0a\u5c31\u662f\u4ece\u7ed9\u5b9a\u7684\u7c7b\u522b\u96c6\u5408\u4e2d\u4e3a\u56fe\u50cf\u5206\u914d\u5bf9\u5e94\u6807\u7b7e\u7684\u4efb\u52a1\u3002\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u7684\u4efb\u52a1\u662f\u5206\u6790\u4e00\u4e2a\u8f93\u5165\u56fe\u50cf\u5e76\u8fd4\u56de\u4e00\u4e2a\u8be5\u56fe\u50cf\u7c7b\u522b\u7684\u6807\u7b7e\u3002 \u5047\u5b9a\u7c7b\u522b\u96c6\u4e3acategories = {dog, cat, panda}\uff0c\u4e4b\u540e\u6211\u4eec\u63d0\u4f9b\u4e00\u5f20\u56fe\u7247\u7ed9\u5206\u7c7b\u6a21\u578b\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5206\u7c7b\u6a21\u578b\u7ed9\u56fe\u50cf\u5206\u914d\u591a\u4e2a\u6807\u7b7e\uff0c\u6bcf\u4e2a\u6807\u7b7e\u7684\u6982\u7387\u503c\u4e0d\u540c\uff0c\u5982dog:95%\uff0ccat:4%\uff0cpanda:1%\uff0c\u6839\u636e\u6982\u7387\u503c\u7684\u5927\u5c0f\u5c06\u8be5\u56fe\u7247\u5206\u7c7b\u4e3adog\uff0c\u90a3\u5c31\u5b8c\u6210\u4e86\u56fe\u50cf\u5206\u7c7b\u7684\u4efb\u52a1\u3002 2 \u5e38\u7528\u6570\u636e\u96c6 \u00b6 2.1 mnist\u6570\u636e\u96c6 \u00b6 \u8be5\u6570\u636e\u96c6\u662f\u624b\u5199\u6570\u5b570-9\u7684\u96c6\u5408\uff0c\u5171\u670960k\u8bad\u7ec3\u56fe\u50cf\u300110k\u6d4b\u8bd5\u56fe\u50cf\u300110\u4e2a\u7c7b\u522b\u3001\u56fe\u50cf\u5927\u5c0f28\u00d728\u00d71.\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7tf.keras\u76f4\u63a5\u52a0\u8f7d\u8be5\u6570\u636e\u96c6\uff1a from tensorflow.keras.datasets import mnist # \u52a0\u8f7dmnist\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () \u968f\u673a\u9009\u62e9\u56fe\u50cf\u5c55\u793a\u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a 2.2 CIFAR-10\u548cCIFAR-100 \u00b6 CIFAR-10\u6570\u636e\u96c65\u4e07\u5f20\u8bad\u7ec3\u56fe\u50cf\u30011\u4e07\u5f20\u6d4b\u8bd5\u56fe\u50cf\u300110\u4e2a\u7c7b\u522b\u3001\u6bcf\u4e2a\u7c7b\u522b\u67096k\u4e2a\u56fe\u50cf\uff0c\u56fe\u50cf\u5927\u5c0f32\u00d732\u00d73\u3002\u4e0b\u56fe\u5217\u4e3e\u4e8610\u4e2a\u7c7b\uff0c\u6bcf\u4e00\u7c7b\u968f\u673a\u5c55\u793a\u4e8610\u5f20\u56fe\u7247\uff1a CIFAR-100\u6570\u636e\u96c6\u4e5f\u662f\u67095\u4e07\u5f20\u8bad\u7ec3\u56fe\u50cf\u30011\u4e07\u5f20\u6d4b\u8bd5\u56fe\u50cf\u3001\u5305\u542b100\u4e2a\u7c7b\u522b\u3001\u56fe\u50cf\u5927\u5c0f32\u00d732\u00d73\u3002 \u5728tf.keras\u4e2d\u52a0\u8f7d\u6570\u636e\u96c6\u65f6\uff1a import tensorflow as tf from tensorflow.keras.datasets import cifar10 , cifar100 # \u52a0\u8f7dCifar10\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = cifar10 . load_data () # \u52a0\u8f7dCifar100\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = cifar100 . load_data () 2.3 ImageNet \u00b6 ImageNet\u6570\u636e\u96c6\u662fILSVRC\u7ade\u8d5b\u4f7f\u7528\u7684\u662f\u6570\u636e\u96c6\uff0c\u7531\u65af\u5766\u798f\u5927\u5b66\u674e\u98de\u98de\u6559\u6388\u4e3b\u5bfc\uff0c\u5305\u542b\u4e86\u8d85\u8fc71400\u4e07\u5f20\u5168\u5c3a\u5bf8\u7684\u6709\u6807\u8bb0\u56fe\u7247\uff0c\u5927\u7ea6\u670922000\u4e2a\u7c7b\u522b\u7684\u6570\u636e\u3002ILSVRC\u5168\u79f0ImageNet Large-Scale Visual Recognition Challenge\uff0c\u662f\u89c6\u89c9\u9886\u57df\u6700\u53d7\u8ffd\u6367\u4e5f\u662f\u6700\u5177\u6743\u5a01\u7684\u5b66\u672f\u7ade\u8d5b\u4e4b\u4e00\uff0c\u4ee3\u8868\u4e86\u56fe\u50cf\u9886\u57df\u7684\u6700\u9ad8\u6c34\u5e73\u3002\u4ece2010\u5e74\u5f00\u59cb\u4e3e\u529e\u52302017\u5e74\u6700\u540e\u4e00\u5c4a\uff0c\u4f7f\u7528ImageNet\u6570\u636e\u96c6\u7684\u4e00\u4e2a\u5b50\u96c6\uff0c\u603b\u5171\u67091000\u7c7b\u3002 \u8be5\u6bd4\u8d5b\u7684\u83b7\u80dc\u8005\u4ece2012\u5e74\u5f00\u59cb\u90fd\u662f\u4f7f\u7528\u7684\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\uff1a 2012\u5e74\u51a0\u519b\u662fAlexNet,\u7531\u4e8e\u51c6\u786e\u7387\u8fdc\u8d85\u4f20\u7edf\u65b9\u6cd5\u7684\u7b2c\u4e8c\u540d\uff08top5\u9519\u8bef\u7387\u4e3a15.3%\uff0c\u7b2c\u4e8c\u540d\u4e3a26.2%\uff09\uff0c\u5f15\u8d77\u4e86\u5f88\u5927\u7684\u8f70\u52a8\u3002\u81ea\u6b64\u4e4b\u540e\uff0cCNN\u6210\u4e3a\u5728\u56fe\u50cf\u8bc6\u522b\u5206\u7c7b\u7684\u6838\u5fc3\u7b97\u6cd5\u6a21\u578b\uff0c\u5e26\u6765\u4e86\u6df1\u5ea6\u5b66\u4e60\u7684\u5927\u7206\u53d1\u3002 2013\u5e74\u51a0\u519b\u662fZFNet\uff0c\u7ed3\u6784\u548cAlexNet\u533a\u522b\u4e0d\u5927\uff0c\u5206\u7c7b\u6548\u679c\u4e5f\u5dee\u4e0d\u591a\u3002 2014\u5e74\u4e9a\u519b\u662fVGG\u7f51\u7edc\uff0c\u7f51\u7edc\u7ed3\u6784\u5341\u5206\u7b80\u5355\uff0c\u56e0\u6b64\u81f3\u4ecaVGG-16\u4ecd\u5728\u5e7f\u6cdb\u4f7f\u7528\u3002 2014\u5e74\u7684\u51a0\u519b\u7f51\u7edc\u662fGooLeNet \uff0c\u6838\u5fc3\u6a21\u5757\u662fInception Module\u3002Inception\u5386\u7ecf\u4e86V1\u3001V2\u3001V3\u3001V4\u7b49\u591a\u4e2a\u7248\u672c\u7684\u53d1\u5c55\uff0c\u4e0d\u65ad\u8d8b\u4e8e\u5b8c\u5584\u3002GoogLeNet\u53d6\u540d\u4e2dL\u5927\u5199\u662f\u4e3a\u4e86\u5411LeNet\u81f4\u656c\uff0c\u800cInception\u7684\u540d\u5b57\u6765\u6e90\u4e8e\u76d7\u68a6\u7a7a\u95f4\u4e2d\u7684\"we need to go deeper\"\u6897\u3002 2015\u5e74\u51a0\u519b\u7f51\u7edc\u662fResNet\u3002\u6838\u5fc3\u662f\u5e26\u77ed\u8fde\u63a5\u7684\u6b8b\u5dee\u6a21\u5757\uff0c\u5176\u4e2d\u4e3b\u8def\u5f84\u6709\u4e24\u5c42\u5377\u79ef\u6838\uff08Res34\uff09\uff0c\u77ed\u8fde\u63a5\u628a\u6a21\u5757\u7684\u8f93\u5165\u4fe1\u606f\u76f4\u63a5\u548c\u7ecf\u8fc7\u4e24\u6b21\u5377\u79ef\u4e4b\u540e\u7684\u4fe1\u606f\u878d\u5408\uff0c\u76f8\u5f53\u4e8e\u52a0\u4e86\u4e00\u4e2a\u6052\u7b49\u53d8\u6362\u3002\u77ed\u8fde\u63a5\u662f\u6df1\u5ea6\u5b66\u4e60\u53c8\u4e00\u91cd\u8981\u601d\u60f3\uff0c\u9664\u8ba1\u7b97\u673a\u89c6\u89c9\u5916\uff0c\u77ed\u8fde\u63a5\u601d\u60f3\u4e5f\u88ab\u7528\u5230\u4e86\u673a\u5668\u7ffb\u8bd1\u3001\u8bed\u97f3\u8bc6\u522b/\u5408\u6210\u9886\u57df 2017\u5e74\u51a0\u519bSENet\u662f\u4e00\u4e2a\u6a21\u5757\uff0c\u53ef\u4ee5\u548c\u5176\u4ed6\u7684\u7f51\u7edc\u67b6\u6784\u7ed3\u5408\uff0c\u6bd4\u5982GoogLeNet\u3001ResNet\u7b49\u3002 \u4e0a\u8ff0\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u90fd\u6bd4\u8f83\u7ecf\u5178\uff0c\u7279\u522b\u662fVGG16\u3001GoogLeNet\u548cResNet\uff0c\u73b0\u5728\u4ecd\u7136\u5728\u5e7f\u6cdb\u4f7f\u7528\uff0c\u5728\u63a5\u4e0b\u6765\u7684\u8bfe\u7a0b\u4e2d\u6211\u4eec\u5bf9\u8fd9\u4e9b\u7f51\u7edc\u8fdb\u884c\u9010\u4e00\u4ecb\u7ecd\u3002 \u603b\u7ed3 1.\u56fe\u50cf\u5206\u7c7b\u662f\u4ec0\u4e48\uff1f \u4ece\u7ed9\u5b9a\u7684\u7c7b\u522b\u96c6\u5408\u4e2d\u4e3a\u56fe\u50cf\u5206\u914d\u5bf9\u5e94\u7684\u7c7b\u522b\u6807\u7b7e 2.\u5e38\u7528\u7684\u6570\u636e\u96c6 Mnist,cifar\u6570\u636e\u96c6,ImageNet\u6570\u636e\u96c6","title":"\u56fe\u50cf\u5206\u7c7b\u7b80\u4ecb"},{"location":"imageClassification/section1/#31","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u56fe\u50cf\u5206\u7c7b\u7684\u76ee\u7684 \u77e5\u9053imageNet\u6570\u636e\u96c6","title":"3.1 \u56fe\u50cf\u5206\u7c7b\u7b80\u4ecb"},{"location":"imageClassification/section1/#1","text":"\u56fe\u50cf\u5206\u7c7b\u5b9e\u8d28\u4e0a\u5c31\u662f\u4ece\u7ed9\u5b9a\u7684\u7c7b\u522b\u96c6\u5408\u4e2d\u4e3a\u56fe\u50cf\u5206\u914d\u5bf9\u5e94\u6807\u7b7e\u7684\u4efb\u52a1\u3002\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u7684\u4efb\u52a1\u662f\u5206\u6790\u4e00\u4e2a\u8f93\u5165\u56fe\u50cf\u5e76\u8fd4\u56de\u4e00\u4e2a\u8be5\u56fe\u50cf\u7c7b\u522b\u7684\u6807\u7b7e\u3002 \u5047\u5b9a\u7c7b\u522b\u96c6\u4e3acategories = {dog, cat, panda}\uff0c\u4e4b\u540e\u6211\u4eec\u63d0\u4f9b\u4e00\u5f20\u56fe\u7247\u7ed9\u5206\u7c7b\u6a21\u578b\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5206\u7c7b\u6a21\u578b\u7ed9\u56fe\u50cf\u5206\u914d\u591a\u4e2a\u6807\u7b7e\uff0c\u6bcf\u4e2a\u6807\u7b7e\u7684\u6982\u7387\u503c\u4e0d\u540c\uff0c\u5982dog:95%\uff0ccat:4%\uff0cpanda:1%\uff0c\u6839\u636e\u6982\u7387\u503c\u7684\u5927\u5c0f\u5c06\u8be5\u56fe\u7247\u5206\u7c7b\u4e3adog\uff0c\u90a3\u5c31\u5b8c\u6210\u4e86\u56fe\u50cf\u5206\u7c7b\u7684\u4efb\u52a1\u3002","title":"1 \u56fe\u50cf\u5206\u7c7b"},{"location":"imageClassification/section1/#2","text":"","title":"2 \u5e38\u7528\u6570\u636e\u96c6"},{"location":"imageClassification/section1/#21-mnist","text":"\u8be5\u6570\u636e\u96c6\u662f\u624b\u5199\u6570\u5b570-9\u7684\u96c6\u5408\uff0c\u5171\u670960k\u8bad\u7ec3\u56fe\u50cf\u300110k\u6d4b\u8bd5\u56fe\u50cf\u300110\u4e2a\u7c7b\u522b\u3001\u56fe\u50cf\u5927\u5c0f28\u00d728\u00d71.\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7tf.keras\u76f4\u63a5\u52a0\u8f7d\u8be5\u6570\u636e\u96c6\uff1a from tensorflow.keras.datasets import mnist # \u52a0\u8f7dmnist\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () \u968f\u673a\u9009\u62e9\u56fe\u50cf\u5c55\u793a\u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a","title":"2.1 mnist\u6570\u636e\u96c6"},{"location":"imageClassification/section1/#22-cifar-10cifar-100","text":"CIFAR-10\u6570\u636e\u96c65\u4e07\u5f20\u8bad\u7ec3\u56fe\u50cf\u30011\u4e07\u5f20\u6d4b\u8bd5\u56fe\u50cf\u300110\u4e2a\u7c7b\u522b\u3001\u6bcf\u4e2a\u7c7b\u522b\u67096k\u4e2a\u56fe\u50cf\uff0c\u56fe\u50cf\u5927\u5c0f32\u00d732\u00d73\u3002\u4e0b\u56fe\u5217\u4e3e\u4e8610\u4e2a\u7c7b\uff0c\u6bcf\u4e00\u7c7b\u968f\u673a\u5c55\u793a\u4e8610\u5f20\u56fe\u7247\uff1a CIFAR-100\u6570\u636e\u96c6\u4e5f\u662f\u67095\u4e07\u5f20\u8bad\u7ec3\u56fe\u50cf\u30011\u4e07\u5f20\u6d4b\u8bd5\u56fe\u50cf\u3001\u5305\u542b100\u4e2a\u7c7b\u522b\u3001\u56fe\u50cf\u5927\u5c0f32\u00d732\u00d73\u3002 \u5728tf.keras\u4e2d\u52a0\u8f7d\u6570\u636e\u96c6\u65f6\uff1a import tensorflow as tf from tensorflow.keras.datasets import cifar10 , cifar100 # \u52a0\u8f7dCifar10\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = cifar10 . load_data () # \u52a0\u8f7dCifar100\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = cifar100 . load_data ()","title":"2.2 CIFAR-10\u548cCIFAR-100"},{"location":"imageClassification/section1/#23-imagenet","text":"ImageNet\u6570\u636e\u96c6\u662fILSVRC\u7ade\u8d5b\u4f7f\u7528\u7684\u662f\u6570\u636e\u96c6\uff0c\u7531\u65af\u5766\u798f\u5927\u5b66\u674e\u98de\u98de\u6559\u6388\u4e3b\u5bfc\uff0c\u5305\u542b\u4e86\u8d85\u8fc71400\u4e07\u5f20\u5168\u5c3a\u5bf8\u7684\u6709\u6807\u8bb0\u56fe\u7247\uff0c\u5927\u7ea6\u670922000\u4e2a\u7c7b\u522b\u7684\u6570\u636e\u3002ILSVRC\u5168\u79f0ImageNet Large-Scale Visual Recognition Challenge\uff0c\u662f\u89c6\u89c9\u9886\u57df\u6700\u53d7\u8ffd\u6367\u4e5f\u662f\u6700\u5177\u6743\u5a01\u7684\u5b66\u672f\u7ade\u8d5b\u4e4b\u4e00\uff0c\u4ee3\u8868\u4e86\u56fe\u50cf\u9886\u57df\u7684\u6700\u9ad8\u6c34\u5e73\u3002\u4ece2010\u5e74\u5f00\u59cb\u4e3e\u529e\u52302017\u5e74\u6700\u540e\u4e00\u5c4a\uff0c\u4f7f\u7528ImageNet\u6570\u636e\u96c6\u7684\u4e00\u4e2a\u5b50\u96c6\uff0c\u603b\u5171\u67091000\u7c7b\u3002 \u8be5\u6bd4\u8d5b\u7684\u83b7\u80dc\u8005\u4ece2012\u5e74\u5f00\u59cb\u90fd\u662f\u4f7f\u7528\u7684\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\uff1a 2012\u5e74\u51a0\u519b\u662fAlexNet,\u7531\u4e8e\u51c6\u786e\u7387\u8fdc\u8d85\u4f20\u7edf\u65b9\u6cd5\u7684\u7b2c\u4e8c\u540d\uff08top5\u9519\u8bef\u7387\u4e3a15.3%\uff0c\u7b2c\u4e8c\u540d\u4e3a26.2%\uff09\uff0c\u5f15\u8d77\u4e86\u5f88\u5927\u7684\u8f70\u52a8\u3002\u81ea\u6b64\u4e4b\u540e\uff0cCNN\u6210\u4e3a\u5728\u56fe\u50cf\u8bc6\u522b\u5206\u7c7b\u7684\u6838\u5fc3\u7b97\u6cd5\u6a21\u578b\uff0c\u5e26\u6765\u4e86\u6df1\u5ea6\u5b66\u4e60\u7684\u5927\u7206\u53d1\u3002 2013\u5e74\u51a0\u519b\u662fZFNet\uff0c\u7ed3\u6784\u548cAlexNet\u533a\u522b\u4e0d\u5927\uff0c\u5206\u7c7b\u6548\u679c\u4e5f\u5dee\u4e0d\u591a\u3002 2014\u5e74\u4e9a\u519b\u662fVGG\u7f51\u7edc\uff0c\u7f51\u7edc\u7ed3\u6784\u5341\u5206\u7b80\u5355\uff0c\u56e0\u6b64\u81f3\u4ecaVGG-16\u4ecd\u5728\u5e7f\u6cdb\u4f7f\u7528\u3002 2014\u5e74\u7684\u51a0\u519b\u7f51\u7edc\u662fGooLeNet \uff0c\u6838\u5fc3\u6a21\u5757\u662fInception Module\u3002Inception\u5386\u7ecf\u4e86V1\u3001V2\u3001V3\u3001V4\u7b49\u591a\u4e2a\u7248\u672c\u7684\u53d1\u5c55\uff0c\u4e0d\u65ad\u8d8b\u4e8e\u5b8c\u5584\u3002GoogLeNet\u53d6\u540d\u4e2dL\u5927\u5199\u662f\u4e3a\u4e86\u5411LeNet\u81f4\u656c\uff0c\u800cInception\u7684\u540d\u5b57\u6765\u6e90\u4e8e\u76d7\u68a6\u7a7a\u95f4\u4e2d\u7684\"we need to go deeper\"\u6897\u3002 2015\u5e74\u51a0\u519b\u7f51\u7edc\u662fResNet\u3002\u6838\u5fc3\u662f\u5e26\u77ed\u8fde\u63a5\u7684\u6b8b\u5dee\u6a21\u5757\uff0c\u5176\u4e2d\u4e3b\u8def\u5f84\u6709\u4e24\u5c42\u5377\u79ef\u6838\uff08Res34\uff09\uff0c\u77ed\u8fde\u63a5\u628a\u6a21\u5757\u7684\u8f93\u5165\u4fe1\u606f\u76f4\u63a5\u548c\u7ecf\u8fc7\u4e24\u6b21\u5377\u79ef\u4e4b\u540e\u7684\u4fe1\u606f\u878d\u5408\uff0c\u76f8\u5f53\u4e8e\u52a0\u4e86\u4e00\u4e2a\u6052\u7b49\u53d8\u6362\u3002\u77ed\u8fde\u63a5\u662f\u6df1\u5ea6\u5b66\u4e60\u53c8\u4e00\u91cd\u8981\u601d\u60f3\uff0c\u9664\u8ba1\u7b97\u673a\u89c6\u89c9\u5916\uff0c\u77ed\u8fde\u63a5\u601d\u60f3\u4e5f\u88ab\u7528\u5230\u4e86\u673a\u5668\u7ffb\u8bd1\u3001\u8bed\u97f3\u8bc6\u522b/\u5408\u6210\u9886\u57df 2017\u5e74\u51a0\u519bSENet\u662f\u4e00\u4e2a\u6a21\u5757\uff0c\u53ef\u4ee5\u548c\u5176\u4ed6\u7684\u7f51\u7edc\u67b6\u6784\u7ed3\u5408\uff0c\u6bd4\u5982GoogLeNet\u3001ResNet\u7b49\u3002 \u4e0a\u8ff0\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u90fd\u6bd4\u8f83\u7ecf\u5178\uff0c\u7279\u522b\u662fVGG16\u3001GoogLeNet\u548cResNet\uff0c\u73b0\u5728\u4ecd\u7136\u5728\u5e7f\u6cdb\u4f7f\u7528\uff0c\u5728\u63a5\u4e0b\u6765\u7684\u8bfe\u7a0b\u4e2d\u6211\u4eec\u5bf9\u8fd9\u4e9b\u7f51\u7edc\u8fdb\u884c\u9010\u4e00\u4ecb\u7ecd\u3002 \u603b\u7ed3 1.\u56fe\u50cf\u5206\u7c7b\u662f\u4ec0\u4e48\uff1f \u4ece\u7ed9\u5b9a\u7684\u7c7b\u522b\u96c6\u5408\u4e2d\u4e3a\u56fe\u50cf\u5206\u914d\u5bf9\u5e94\u7684\u7c7b\u522b\u6807\u7b7e 2.\u5e38\u7528\u7684\u6570\u636e\u96c6 Mnist,cifar\u6570\u636e\u96c6,ImageNet\u6570\u636e\u96c6","title":"2.3 ImageNet"},{"location":"imageClassification/section2/","text":"3.2 AlexNet \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053AlexNet\u7f51\u7edc\u7ed3\u6784 \u80fd\u591f\u5229\u7528AlexNet\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b 2012\u5e74\uff0cAlexNet\u6a2a\u7a7a\u51fa\u4e16\uff0c\u8be5\u6a21\u578b\u7684\u540d\u5b57\u6e90\u4e8e\u8bba\u6587\u7b2c\u4e00\u4f5c\u8005\u7684\u59d3\u540dAlex Krizhevsky \u3002AlexNet\u4f7f\u7528\u4e868\u5c42\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u4ee5\u5f88\u5927\u7684\u4f18\u52bf\u8d62\u5f97\u4e86ImageNet 2012\u56fe\u50cf\u8bc6\u522b\u6311\u6218\u8d5b\u3002\u5b83\u9996\u6b21\u8bc1\u660e\u4e86\u5b66\u4e60\u5230\u7684\u7279\u5f81\u53ef\u4ee5\u8d85\u8d8a\u624b\u5de5\u8bbe\u8ba1\u7684\u7279\u5f81\uff0c\u4ece\u800c\u4e00\u4e3e\u6253\u7834\u8ba1\u7b97\u673a\u89c6\u89c9\u7814\u7a76\u7684\u65b9\u5411\u3002 1.AlexNet\u7684\u7f51\u7edc\u67b6\u6784 \u00b6 AlexNet\u4e0eLeNet\u7684\u8bbe\u8ba1\u7406\u5ff5\u975e\u5e38\u76f8\u4f3c\uff0c\u4f46\u4e5f\u6709\u663e\u8457\u7684\u533a\u522b\uff0c\u5176\u7f51\u7edc\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8be5\u7f51\u7edc\u7684\u7279\u70b9\u662f\uff1a AlexNet\u5305\u542b8\u5c42\u53d8\u6362\uff0c\u67095\u5c42\u5377\u79ef\u548c2\u5c42\u5168\u8fde\u63a5\u9690\u85cf\u5c42\uff0c\u4ee5\u53ca1\u4e2a\u5168\u8fde\u63a5\u8f93\u51fa\u5c42 AlexNet\u7b2c\u4e00\u5c42\u4e2d\u7684\u5377\u79ef\u6838\u5f62\u72b6\u662f 11\\times11 11\\times11 \u3002\u7b2c\u4e8c\u5c42\u4e2d\u7684\u5377\u79ef\u6838\u5f62\u72b6\u51cf\u5c0f\u5230 5\\times5 5\\times5 \uff0c\u4e4b\u540e\u5168\u91c7\u7528 3\\times3 3\\times3 \u3002\u6240\u6709\u7684\u6c60\u5316\u5c42\u7a97\u53e3\u5927\u5c0f\u4e3a 3\\times3 3\\times3 \u3001\u6b65\u5e45\u4e3a2\u7684\u6700\u5927\u6c60\u5316\u3002 AlexNet\u5c06sigmoid\u6fc0\u6d3b\u51fd\u6570\u6539\u6210\u4e86ReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u4f7f\u8ba1\u7b97\u66f4\u7b80\u5355\uff0c\u7f51\u7edc\u66f4\u5bb9\u6613\u8bad\u7ec3 AlexNet\u901a\u8fc7dropOut\u6765\u63a7\u5236\u5168\u8fde\u63a5\u5c42\u7684\u6a21\u578b\u590d\u6742\u5ea6\u3002 AlexNet\u5f15\u5165\u4e86\u5927\u91cf\u7684\u56fe\u50cf\u589e\u5f3a\uff0c\u5982\u7ffb\u8f6c\u3001\u88c1\u526a\u548c\u989c\u8272\u53d8\u5316\uff0c\u4ece\u800c\u8fdb\u4e00\u6b65\u6269\u5927\u6570\u636e\u96c6\u6765\u7f13\u89e3\u8fc7\u62df\u5408\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0AlexNet\u6a21\u578b\uff1a # \u6784\u5efaAlexNet\u6a21\u578b net = tf . keras . models . Sequential ([ # \u5377\u79ef\u5c42\uff1a96\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a11*11\uff0c\u6b65\u5e45\u4e3a4\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 96 , kernel_size = 11 , strides = 4 , activation = 'relu' ), # \u6c60\u5316:\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\u3001\u6b65\u5e45\u4e3a2 tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 ), # \u5377\u79ef\u5c42\uff1a256\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a5*5\uff0c\u6b65\u5e45\u4e3a1\uff0cpadding\u4e3asame\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 256 , kernel_size = 5 , padding = 'same' , activation = 'relu' ), # \u6c60\u5316:\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\u3001\u6b65\u5e45\u4e3a2 tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 ), # \u5377\u79ef\u5c42\uff1a384\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a3*3\uff0c\u6b65\u5e45\u4e3a1\uff0cpadding\u4e3asame\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 384 , kernel_size = 3 , padding = 'same' , activation = 'relu' ), # \u5377\u79ef\u5c42\uff1a384\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a3*3\uff0c\u6b65\u5e45\u4e3a1\uff0cpadding\u4e3asame\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 384 , kernel_size = 3 , padding = 'same' , activation = 'relu' ), # \u5377\u79ef\u5c42\uff1a256\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a3*3\uff0c\u6b65\u5e45\u4e3a1\uff0cpadding\u4e3asame\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 256 , kernel_size = 3 , padding = 'same' , activation = 'relu' ), # \u6c60\u5316:\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\u3001\u6b65\u5e45\u4e3a2 tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 ), # \u4f38\u5c55\u4e3a1\u7ef4\u5411\u91cf tf . keras . layers . Flatten (), # \u5168\u8fde\u63a5\u5c42:4096\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Dense ( 4096 , activation = 'relu' ), # \u968f\u673a\u5931\u6d3b tf . keras . layers . Dropout ( 0.5 ), # \u5168\u94fe\u63a5\u5c42\uff1a4096\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Dense ( 4096 , activation = 'relu' ), # \u968f\u673a\u5931\u6d3b tf . keras . layers . Dropout ( 0.5 ), # \u8f93\u51fa\u5c42\uff1a10\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570softmax tf . keras . layers . Dense ( 10 , activation = 'softmax' ) ]) \u6211\u4eec\u6784\u9020\u4e00\u4e2a\u9ad8\u548c\u5bbd\u5747\u4e3a227\u7684\u5355\u901a\u9053\u6570\u636e\u6837\u672c\u6765\u770b\u4e00\u4e0b\u6a21\u578b\u7684\u67b6\u6784\uff1a # \u6784\u9020\u8f93\u5165X\uff0c\u5e76\u5c06\u5176\u9001\u5165\u5230net\u7f51\u7edc\u4e2d X = tf . random . uniform (( 1 , 227 , 227 , 1 ) y = net ( X ) # \u901a\u8fc7net.summay()\u67e5\u770b\u7f51\u7edc\u7684\u5f62\u72b6 net . summay () \u7f51\u7edc\u67b6\u6784\u5982\u4e0b\uff1a Model : \"sequential\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= conv2d ( Conv2D ) ( 1 , 55 , 55 , 96 ) 11712 _________________________________________________________________ max_pooling2d ( MaxPooling2D ) ( 1 , 27 , 27 , 96 ) 0 _________________________________________________________________ conv2d_1 ( Conv2D ) ( 1 , 27 , 27 , 256 ) 614656 _________________________________________________________________ max_pooling2d_1 ( MaxPooling2 ( 1 , 13 , 13 , 256 ) 0 _________________________________________________________________ conv2d_2 ( Conv2D ) ( 1 , 13 , 13 , 384 ) 885120 _________________________________________________________________ conv2d_3 ( Conv2D ) ( 1 , 13 , 13 , 384 ) 1327488 _________________________________________________________________ conv2d_4 ( Conv2D ) ( 1 , 13 , 13 , 256 ) 884992 _________________________________________________________________ max_pooling2d_2 ( MaxPooling2 ( 1 , 6 , 6 , 256 ) 0 _________________________________________________________________ flatten ( Flatten ) ( 1 , 9216 ) 0 _________________________________________________________________ dense ( Dense ) ( 1 , 4096 ) 37752832 _________________________________________________________________ dropout ( Dropout ) ( 1 , 4096 ) 0 _________________________________________________________________ dense_1 ( Dense ) ( 1 , 4096 ) 16781312 _________________________________________________________________ dropout_1 ( Dropout ) ( 1 , 4096 ) 0 _________________________________________________________________ dense_2 ( Dense ) ( 1 , 10 ) 40970 ================================================================= Total params : 58 , 299 , 082 Trainable params : 58 , 299 , 082 Non - trainable params : 0 _________________________________________________________________ 2.\u624b\u5199\u6570\u5b57\u52bf\u8bc6\u522b \u00b6 AlexNet\u4f7f\u7528ImageNet\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u56e0\u4e3aImageNet\u6570\u636e\u96c6\u8f83\u5927\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u4ecd\u7528\u524d\u9762\u7684MNIST\u6570\u636e\u96c6\u6765\u6f14\u793aAlexNet\u3002\u8bfb\u53d6\u6570\u636e\u7684\u65f6\u5c06\u56fe\u50cf\u9ad8\u548c\u5bbd\u6269\u5927\u5230AlexNet\u4f7f\u7528\u7684\u56fe\u50cf\u9ad8\u548c\u5bbd227\u3002\u8fd9\u4e2a\u901a\u8fc7 tf.image.resize_with_pad \u6765\u5b9e\u73b0\u3002 2.1 \u6570\u636e\u8bfb\u53d6 \u00b6 \u9996\u5148\u83b7\u53d6\u6570\u636e,\u5e76\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff1a import numpy as np # \u83b7\u53d6\u624b\u5199\u6570\u5b57\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # \u8bad\u7ec3\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C train_images = np . reshape ( train_images ,( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) # \u6d4b\u8bd5\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C test_images = np . reshape ( test_images ,( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7531\u4e8e\u4f7f\u7528\u5168\u90e8\u6570\u636e\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u83b7\u53d6\u90e8\u5206\u6570\u636e\uff0c\u5e76\u5c06\u56fe\u50cf\u8c03\u6574\u4e3a227*227\u5927\u5c0f\uff0c\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a # \u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u968f\u673a\u62bd\u53d6\u90e8\u5206\u6837\u672c\u6f14\u793a # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e def get_train ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( train_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210227*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( train_images [ index ], 227 , 227 ,) # \u8fd4\u56de\u62bd\u53d6\u7684 return resized_images . numpy (), train_labels [ index ] # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e def get_test ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( test_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210227*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( test_images [ index ], 227 , 227 ,) # \u8fd4\u56de\u62bd\u6837\u7684\u6d4b\u8bd5\u6837\u672c return resized_images . numpy (), test_labels [ index ] \u8c03\u7528\u4e0a\u8ff0\u4e24\u4e2a\u65b9\u6cd5\uff0c\u83b7\u53d6\u53c2\u4e0e\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\uff1a # \u83b7\u53d6\u8bad\u7ec3\u6837\u672c\u548c\u6d4b\u8bd5\u6837\u672c train_images , train_labels = get_train ( 256 ) test_images , test_labels = get_test ( 128 ) \u4e3a\u4e86\u8ba9\u5927\u5bb6\u66f4\u597d\u7684\u7406\u89e3\uff0c\u6211\u4eec\u5c06\u6570\u636e\u5c55\u793a\u51fa\u6765\uff1a # \u6570\u636e\u5c55\u793a\uff1a\u5c06\u6570\u636e\u96c6\u7684\u524d\u4e5d\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u5c55\u793a for i in range ( 9 ): plt . subplot ( 3 , 3 , i + 1 ) # \u4ee5\u7070\u5ea6\u56fe\u663e\u793a\uff0c\u4e0d\u8fdb\u884c\u63d2\u503c plt . imshow ( train_images [ i ] . astype ( np . int8 ) . squeeze (), cmap = 'gray' , interpolation = 'none' ) # \u8bbe\u7f6e\u56fe\u7247\u7684\u6807\u9898\uff1a\u5bf9\u5e94\u7684\u7c7b\u522b plt . title ( \"\u6570\u5b57 {} \" . format ( train_labels [ i ])) \u7ed3\u679c\u4e3a\uff1a \u6211\u4eec\u5c31\u4f7f\u7528\u4e0a\u8ff0\u521b\u5efa\u7684\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002 2.2 \u6a21\u578b\u7f16\u8bd1 \u00b6 # \u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 , nesterov = False ) net . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ]) 2.3 \u6a21\u578b\u8bad\u7ec3 \u00b6 # \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u8bad\u7ec3\u6570\u636e\uff0cbatchsize,epoch,\u9a8c\u8bc1\u96c6 net . fit ( train_images , train_labels , batch_size = 128 , epochs = 3 , verbose = 1 , validation_split = 0.1 ) \u8bad\u7ec3\u8f93\u51fa\u4e3a\uff1a Epoch 1 / 3 2 / 2 [ ============================== ] - 3 s 2 s / step - loss : 2.3003 - accuracy : 0.0913 - val_loss : 2.3026 - val_accuracy : 0.0000e+00 Epoch 2 / 3 2 / 2 [ ============================== ] - 3 s 2 s / step - loss : 2.3069 - accuracy : 0.0957 - val_loss : 2.3026 - val_accuracy : 0.0000e+00 Epoch 3 / 3 2 / 2 [ ============================== ] - 4 s 2 s / step - loss : 2.3117 - accuracy : 0.0826 - val_loss : 2.3026 - val_accuracy : 0.0000e+00 2.4 \u6a21\u578b\u8bc4\u4f30 \u00b6 # \u6307\u5b9a\u6d4b\u8bd5\u6570\u636e net . evaluate ( test_images , test_labels , verbose = 1 ) \u8f93\u51fa\u4e3a\uff1a 4 / 4 [ ============================== ] - 1 s 168 ms / step - loss : 2.3026 - accuracy : 0.0781 [ 2.3025851249694824 , 0.078125 ] \u5982\u679c\u6211\u4eec\u4f7f\u7528\u6574\u4e2a\u6570\u636e\u96c6\u8bad\u7ec3\u7f51\u7edc\uff0c\u5e76\u8fdb\u884c\u8bc4\u4f30\u7684\u7ed3\u679c\uff1a [ 0.4866700246334076 , 0.8395 ] \u603b\u7ed3 \u77e5\u9053AlexNet\u7684\u7f51\u7edc\u67b6\u6784 \u52a8\u624b\u5b9e\u73b0\u624b\u5199\u6570\u5b57\u7684\u8bc6\u522b","title":"AlexNet"},{"location":"imageClassification/section2/#32-alexnet","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053AlexNet\u7f51\u7edc\u7ed3\u6784 \u80fd\u591f\u5229\u7528AlexNet\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b 2012\u5e74\uff0cAlexNet\u6a2a\u7a7a\u51fa\u4e16\uff0c\u8be5\u6a21\u578b\u7684\u540d\u5b57\u6e90\u4e8e\u8bba\u6587\u7b2c\u4e00\u4f5c\u8005\u7684\u59d3\u540dAlex Krizhevsky \u3002AlexNet\u4f7f\u7528\u4e868\u5c42\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u4ee5\u5f88\u5927\u7684\u4f18\u52bf\u8d62\u5f97\u4e86ImageNet 2012\u56fe\u50cf\u8bc6\u522b\u6311\u6218\u8d5b\u3002\u5b83\u9996\u6b21\u8bc1\u660e\u4e86\u5b66\u4e60\u5230\u7684\u7279\u5f81\u53ef\u4ee5\u8d85\u8d8a\u624b\u5de5\u8bbe\u8ba1\u7684\u7279\u5f81\uff0c\u4ece\u800c\u4e00\u4e3e\u6253\u7834\u8ba1\u7b97\u673a\u89c6\u89c9\u7814\u7a76\u7684\u65b9\u5411\u3002","title":"3.2 AlexNet"},{"location":"imageClassification/section2/#1alexnet","text":"AlexNet\u4e0eLeNet\u7684\u8bbe\u8ba1\u7406\u5ff5\u975e\u5e38\u76f8\u4f3c\uff0c\u4f46\u4e5f\u6709\u663e\u8457\u7684\u533a\u522b\uff0c\u5176\u7f51\u7edc\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8be5\u7f51\u7edc\u7684\u7279\u70b9\u662f\uff1a AlexNet\u5305\u542b8\u5c42\u53d8\u6362\uff0c\u67095\u5c42\u5377\u79ef\u548c2\u5c42\u5168\u8fde\u63a5\u9690\u85cf\u5c42\uff0c\u4ee5\u53ca1\u4e2a\u5168\u8fde\u63a5\u8f93\u51fa\u5c42 AlexNet\u7b2c\u4e00\u5c42\u4e2d\u7684\u5377\u79ef\u6838\u5f62\u72b6\u662f 11\\times11 11\\times11 \u3002\u7b2c\u4e8c\u5c42\u4e2d\u7684\u5377\u79ef\u6838\u5f62\u72b6\u51cf\u5c0f\u5230 5\\times5 5\\times5 \uff0c\u4e4b\u540e\u5168\u91c7\u7528 3\\times3 3\\times3 \u3002\u6240\u6709\u7684\u6c60\u5316\u5c42\u7a97\u53e3\u5927\u5c0f\u4e3a 3\\times3 3\\times3 \u3001\u6b65\u5e45\u4e3a2\u7684\u6700\u5927\u6c60\u5316\u3002 AlexNet\u5c06sigmoid\u6fc0\u6d3b\u51fd\u6570\u6539\u6210\u4e86ReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u4f7f\u8ba1\u7b97\u66f4\u7b80\u5355\uff0c\u7f51\u7edc\u66f4\u5bb9\u6613\u8bad\u7ec3 AlexNet\u901a\u8fc7dropOut\u6765\u63a7\u5236\u5168\u8fde\u63a5\u5c42\u7684\u6a21\u578b\u590d\u6742\u5ea6\u3002 AlexNet\u5f15\u5165\u4e86\u5927\u91cf\u7684\u56fe\u50cf\u589e\u5f3a\uff0c\u5982\u7ffb\u8f6c\u3001\u88c1\u526a\u548c\u989c\u8272\u53d8\u5316\uff0c\u4ece\u800c\u8fdb\u4e00\u6b65\u6269\u5927\u6570\u636e\u96c6\u6765\u7f13\u89e3\u8fc7\u62df\u5408\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0AlexNet\u6a21\u578b\uff1a # \u6784\u5efaAlexNet\u6a21\u578b net = tf . keras . models . Sequential ([ # \u5377\u79ef\u5c42\uff1a96\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a11*11\uff0c\u6b65\u5e45\u4e3a4\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 96 , kernel_size = 11 , strides = 4 , activation = 'relu' ), # \u6c60\u5316:\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\u3001\u6b65\u5e45\u4e3a2 tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 ), # \u5377\u79ef\u5c42\uff1a256\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a5*5\uff0c\u6b65\u5e45\u4e3a1\uff0cpadding\u4e3asame\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 256 , kernel_size = 5 , padding = 'same' , activation = 'relu' ), # \u6c60\u5316:\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\u3001\u6b65\u5e45\u4e3a2 tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 ), # \u5377\u79ef\u5c42\uff1a384\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a3*3\uff0c\u6b65\u5e45\u4e3a1\uff0cpadding\u4e3asame\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 384 , kernel_size = 3 , padding = 'same' , activation = 'relu' ), # \u5377\u79ef\u5c42\uff1a384\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a3*3\uff0c\u6b65\u5e45\u4e3a1\uff0cpadding\u4e3asame\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 384 , kernel_size = 3 , padding = 'same' , activation = 'relu' ), # \u5377\u79ef\u5c42\uff1a256\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a3*3\uff0c\u6b65\u5e45\u4e3a1\uff0cpadding\u4e3asame\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 256 , kernel_size = 3 , padding = 'same' , activation = 'relu' ), # \u6c60\u5316:\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\u3001\u6b65\u5e45\u4e3a2 tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 ), # \u4f38\u5c55\u4e3a1\u7ef4\u5411\u91cf tf . keras . layers . Flatten (), # \u5168\u8fde\u63a5\u5c42:4096\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Dense ( 4096 , activation = 'relu' ), # \u968f\u673a\u5931\u6d3b tf . keras . layers . Dropout ( 0.5 ), # \u5168\u94fe\u63a5\u5c42\uff1a4096\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Dense ( 4096 , activation = 'relu' ), # \u968f\u673a\u5931\u6d3b tf . keras . layers . Dropout ( 0.5 ), # \u8f93\u51fa\u5c42\uff1a10\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570softmax tf . keras . layers . Dense ( 10 , activation = 'softmax' ) ]) \u6211\u4eec\u6784\u9020\u4e00\u4e2a\u9ad8\u548c\u5bbd\u5747\u4e3a227\u7684\u5355\u901a\u9053\u6570\u636e\u6837\u672c\u6765\u770b\u4e00\u4e0b\u6a21\u578b\u7684\u67b6\u6784\uff1a # \u6784\u9020\u8f93\u5165X\uff0c\u5e76\u5c06\u5176\u9001\u5165\u5230net\u7f51\u7edc\u4e2d X = tf . random . uniform (( 1 , 227 , 227 , 1 ) y = net ( X ) # \u901a\u8fc7net.summay()\u67e5\u770b\u7f51\u7edc\u7684\u5f62\u72b6 net . summay () \u7f51\u7edc\u67b6\u6784\u5982\u4e0b\uff1a Model : \"sequential\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= conv2d ( Conv2D ) ( 1 , 55 , 55 , 96 ) 11712 _________________________________________________________________ max_pooling2d ( MaxPooling2D ) ( 1 , 27 , 27 , 96 ) 0 _________________________________________________________________ conv2d_1 ( Conv2D ) ( 1 , 27 , 27 , 256 ) 614656 _________________________________________________________________ max_pooling2d_1 ( MaxPooling2 ( 1 , 13 , 13 , 256 ) 0 _________________________________________________________________ conv2d_2 ( Conv2D ) ( 1 , 13 , 13 , 384 ) 885120 _________________________________________________________________ conv2d_3 ( Conv2D ) ( 1 , 13 , 13 , 384 ) 1327488 _________________________________________________________________ conv2d_4 ( Conv2D ) ( 1 , 13 , 13 , 256 ) 884992 _________________________________________________________________ max_pooling2d_2 ( MaxPooling2 ( 1 , 6 , 6 , 256 ) 0 _________________________________________________________________ flatten ( Flatten ) ( 1 , 9216 ) 0 _________________________________________________________________ dense ( Dense ) ( 1 , 4096 ) 37752832 _________________________________________________________________ dropout ( Dropout ) ( 1 , 4096 ) 0 _________________________________________________________________ dense_1 ( Dense ) ( 1 , 4096 ) 16781312 _________________________________________________________________ dropout_1 ( Dropout ) ( 1 , 4096 ) 0 _________________________________________________________________ dense_2 ( Dense ) ( 1 , 10 ) 40970 ================================================================= Total params : 58 , 299 , 082 Trainable params : 58 , 299 , 082 Non - trainable params : 0 _________________________________________________________________","title":"1.AlexNet\u7684\u7f51\u7edc\u67b6\u6784"},{"location":"imageClassification/section2/#2","text":"AlexNet\u4f7f\u7528ImageNet\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u56e0\u4e3aImageNet\u6570\u636e\u96c6\u8f83\u5927\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u4ecd\u7528\u524d\u9762\u7684MNIST\u6570\u636e\u96c6\u6765\u6f14\u793aAlexNet\u3002\u8bfb\u53d6\u6570\u636e\u7684\u65f6\u5c06\u56fe\u50cf\u9ad8\u548c\u5bbd\u6269\u5927\u5230AlexNet\u4f7f\u7528\u7684\u56fe\u50cf\u9ad8\u548c\u5bbd227\u3002\u8fd9\u4e2a\u901a\u8fc7 tf.image.resize_with_pad \u6765\u5b9e\u73b0\u3002","title":"2.\u624b\u5199\u6570\u5b57\u52bf\u8bc6\u522b"},{"location":"imageClassification/section2/#21","text":"\u9996\u5148\u83b7\u53d6\u6570\u636e,\u5e76\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff1a import numpy as np # \u83b7\u53d6\u624b\u5199\u6570\u5b57\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # \u8bad\u7ec3\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C train_images = np . reshape ( train_images ,( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) # \u6d4b\u8bd5\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C test_images = np . reshape ( test_images ,( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7531\u4e8e\u4f7f\u7528\u5168\u90e8\u6570\u636e\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u83b7\u53d6\u90e8\u5206\u6570\u636e\uff0c\u5e76\u5c06\u56fe\u50cf\u8c03\u6574\u4e3a227*227\u5927\u5c0f\uff0c\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a # \u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u968f\u673a\u62bd\u53d6\u90e8\u5206\u6837\u672c\u6f14\u793a # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e def get_train ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( train_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210227*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( train_images [ index ], 227 , 227 ,) # \u8fd4\u56de\u62bd\u53d6\u7684 return resized_images . numpy (), train_labels [ index ] # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e def get_test ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( test_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210227*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( test_images [ index ], 227 , 227 ,) # \u8fd4\u56de\u62bd\u6837\u7684\u6d4b\u8bd5\u6837\u672c return resized_images . numpy (), test_labels [ index ] \u8c03\u7528\u4e0a\u8ff0\u4e24\u4e2a\u65b9\u6cd5\uff0c\u83b7\u53d6\u53c2\u4e0e\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\uff1a # \u83b7\u53d6\u8bad\u7ec3\u6837\u672c\u548c\u6d4b\u8bd5\u6837\u672c train_images , train_labels = get_train ( 256 ) test_images , test_labels = get_test ( 128 ) \u4e3a\u4e86\u8ba9\u5927\u5bb6\u66f4\u597d\u7684\u7406\u89e3\uff0c\u6211\u4eec\u5c06\u6570\u636e\u5c55\u793a\u51fa\u6765\uff1a # \u6570\u636e\u5c55\u793a\uff1a\u5c06\u6570\u636e\u96c6\u7684\u524d\u4e5d\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u5c55\u793a for i in range ( 9 ): plt . subplot ( 3 , 3 , i + 1 ) # \u4ee5\u7070\u5ea6\u56fe\u663e\u793a\uff0c\u4e0d\u8fdb\u884c\u63d2\u503c plt . imshow ( train_images [ i ] . astype ( np . int8 ) . squeeze (), cmap = 'gray' , interpolation = 'none' ) # \u8bbe\u7f6e\u56fe\u7247\u7684\u6807\u9898\uff1a\u5bf9\u5e94\u7684\u7c7b\u522b plt . title ( \"\u6570\u5b57 {} \" . format ( train_labels [ i ])) \u7ed3\u679c\u4e3a\uff1a \u6211\u4eec\u5c31\u4f7f\u7528\u4e0a\u8ff0\u521b\u5efa\u7684\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002","title":"2.1 \u6570\u636e\u8bfb\u53d6"},{"location":"imageClassification/section2/#22","text":"# \u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 , nesterov = False ) net . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ])","title":"2.2 \u6a21\u578b\u7f16\u8bd1"},{"location":"imageClassification/section2/#23","text":"# \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u8bad\u7ec3\u6570\u636e\uff0cbatchsize,epoch,\u9a8c\u8bc1\u96c6 net . fit ( train_images , train_labels , batch_size = 128 , epochs = 3 , verbose = 1 , validation_split = 0.1 ) \u8bad\u7ec3\u8f93\u51fa\u4e3a\uff1a Epoch 1 / 3 2 / 2 [ ============================== ] - 3 s 2 s / step - loss : 2.3003 - accuracy : 0.0913 - val_loss : 2.3026 - val_accuracy : 0.0000e+00 Epoch 2 / 3 2 / 2 [ ============================== ] - 3 s 2 s / step - loss : 2.3069 - accuracy : 0.0957 - val_loss : 2.3026 - val_accuracy : 0.0000e+00 Epoch 3 / 3 2 / 2 [ ============================== ] - 4 s 2 s / step - loss : 2.3117 - accuracy : 0.0826 - val_loss : 2.3026 - val_accuracy : 0.0000e+00","title":"2.3 \u6a21\u578b\u8bad\u7ec3"},{"location":"imageClassification/section2/#24","text":"# \u6307\u5b9a\u6d4b\u8bd5\u6570\u636e net . evaluate ( test_images , test_labels , verbose = 1 ) \u8f93\u51fa\u4e3a\uff1a 4 / 4 [ ============================== ] - 1 s 168 ms / step - loss : 2.3026 - accuracy : 0.0781 [ 2.3025851249694824 , 0.078125 ] \u5982\u679c\u6211\u4eec\u4f7f\u7528\u6574\u4e2a\u6570\u636e\u96c6\u8bad\u7ec3\u7f51\u7edc\uff0c\u5e76\u8fdb\u884c\u8bc4\u4f30\u7684\u7ed3\u679c\uff1a [ 0.4866700246334076 , 0.8395 ] \u603b\u7ed3 \u77e5\u9053AlexNet\u7684\u7f51\u7edc\u67b6\u6784 \u52a8\u624b\u5b9e\u73b0\u624b\u5199\u6570\u5b57\u7684\u8bc6\u522b","title":"2.4 \u6a21\u578b\u8bc4\u4f30"},{"location":"imageClassification/section3/","text":"3.3 VGG \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053VGG\u7f51\u7edc\u7ed3\u6784\u7684\u7279\u70b9 \u80fd\u591f\u5229\u7528VGG\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b 2014\u5e74\uff0c\u725b\u6d25\u5927\u5b66\u8ba1\u7b97\u673a\u89c6\u89c9\u7ec4\uff08Visual Geometry Group\uff09\u548cGoogle DeepMind\u516c\u53f8\u7684\u7814\u7a76\u5458\u4e00\u8d77\u7814\u53d1\u51fa\u4e86\u65b0\u7684\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff1aVGGNet\uff0c\u5e76\u53d6\u5f97\u4e86ILSVRC2014\u6bd4\u8d5b\u5206\u7c7b\u9879\u76ee\u7684\u7b2c\u4e8c\u540d\uff0c\u4e3b\u8981\u8d21\u732e\u662f\u4f7f\u7528\u5f88\u5c0f\u7684\u5377\u79ef\u6838(3\u00d73)\u6784\u5efa\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff0c\u80fd\u591f\u53d6\u5f97\u8f83\u597d\u7684\u8bc6\u522b\u7cbe\u5ea6\uff0c\u5e38\u7528\u6765\u63d0\u53d6\u56fe\u50cf\u7279\u5f81\u7684VGG-16\u548cVGG-19\u3002 1.VGG\u7684\u7f51\u7edc\u67b6\u6784 \u00b6 VGG\u53ef\u4ee5\u770b\u6210\u662f\u52a0\u6df1\u7248\u7684AlexNet\uff0c\u6574\u4e2a\u7f51\u7edc\u7531\u5377\u79ef\u5c42\u548c\u5168\u8fde\u63a5\u5c42\u53e0\u52a0\u800c\u6210\uff0c\u548cAlexNet\u4e0d\u540c\u7684\u662f\uff0cVGG\u4e2d\u4f7f\u7528\u7684\u90fd\u662f\u5c0f\u5c3a\u5bf8\u7684\u5377\u79ef\u6838(3\u00d73)\uff0c\u5176\u7f51\u7edc\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a VGGNet\u4f7f\u7528\u7684\u5168\u90e8\u90fd\u662f3x3\u7684\u5c0f\u5377\u79ef\u6838\u548c2x2\u7684\u6c60\u5316\u6838\uff0c\u901a\u8fc7\u4e0d\u65ad\u52a0\u6df1\u7f51\u7edc\u6765\u63d0\u5347\u6027\u80fd\u3002VGG\u53ef\u4ee5\u901a\u8fc7\u91cd\u590d\u4f7f\u7528\u7b80\u5355\u7684\u57fa\u7840\u5757\u6765\u6784\u5efa\u6df1\u5ea6\u6a21\u578b\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0VGG\u6a21\u578b\uff0c\u9996\u5148\u6765\u5b9e\u73b0VGG\u5757\uff0c\u5b83\u7684\u7ec4\u6210\u89c4\u5f8b\u662f\uff1a\u8fde\u7eed\u4f7f\u7528\u591a\u4e2a\u76f8\u540c\u7684\u586b\u5145\u4e3a1\u3001\u5377\u79ef\u6838\u5927\u5c0f\u4e3a 3\\times 3 3\\times 3 \u7684\u5377\u79ef\u5c42\u540e\u63a5\u4e0a\u4e00\u4e2a\u6b65\u5e45\u4e3a2\u3001\u7a97\u53e3\u5f62\u72b6\u4e3a 2\\times 2 2\\times 2 \u7684\u6700\u5927\u6c60\u5316\u5c42\u3002\u5377\u79ef\u5c42\u4fdd\u6301\u8f93\u5165\u7684\u9ad8\u548c\u5bbd\u4e0d\u53d8\uff0c\u800c\u6c60\u5316\u5c42\u5219\u5bf9\u5176\u51cf\u534a\u3002\u6211\u4eec\u4f7f\u7528 vgg_block \u51fd\u6570\u6765\u5b9e\u73b0\u8fd9\u4e2a\u57fa\u7840\u7684VGG\u5757\uff0c\u5b83\u53ef\u4ee5\u6307\u5b9a\u5377\u79ef\u5c42\u7684\u6570\u91cf num_convs \u548c\u6bcf\u5c42\u7684\u5377\u79ef\u6838\u4e2a\u6570num_filters\uff1a # \u5b9a\u4e49VGG\u7f51\u7edc\u4e2d\u7684\u5377\u79ef\u5757\uff1a\u5377\u79ef\u5c42\u7684\u4e2a\u6570\uff0c\u5377\u79ef\u5c42\u4e2d\u5377\u79ef\u6838\u7684\u4e2a\u6570 def vgg_block ( num_convs , num_filters ): # \u6784\u5efa\u5e8f\u5217\u6a21\u578b blk = tf . keras . models . Sequential () # \u904d\u5386\u6240\u6709\u7684\u5377\u79ef\u5c42 for _ in range ( num_convs ): # \u6bcf\u4e2a\u5377\u79ef\u5c42\uff1anum_filter\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u5927\u5c0f\u4e3a3*3\uff0cpadding\u662fsame\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu blk . add ( tf . keras . layers . Conv2D ( num_filters , kernel_size = 3 , padding = 'same' , activation = 'relu' )) # \u5377\u79ef\u5757\u6700\u540e\u662f\u4e00\u4e2a\u6700\u5927\u6c60\u5316\uff0c\u7a97\u53e3\u5927\u5c0f\u4e3a2*2\uff0c\u6b65\u957f\u4e3a2 blk . add ( tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 )) return blk VGG16\u7f51\u7edc\u67095\u4e2a\u5377\u79ef\u5757\uff0c\u524d2\u5757\u4f7f\u7528\u4e24\u4e2a\u5377\u79ef\u5c42\uff0c\u800c\u540e3\u5757\u4f7f\u7528\u4e09\u4e2a\u5377\u79ef\u5c42\u3002\u7b2c\u4e00\u5757\u7684\u8f93\u51fa\u901a\u9053\u662f64\uff0c\u4e4b\u540e\u6bcf\u6b21\u5bf9\u8f93\u51fa\u901a\u9053\u6570\u7ffb\u500d\uff0c\u76f4\u5230\u53d8\u4e3a512\u3002 # \u5b9a\u4e495\u4e2a\u5377\u79ef\u5757\uff0c\u6307\u660e\u6bcf\u4e2a\u5377\u79ef\u5757\u4e2d\u7684\u5377\u79ef\u5c42\u4e2a\u6570\u53ca\u76f8\u5e94\u7684\u5377\u79ef\u6838\u4e2a\u6570 conv_arch = (( 2 , 64 ), ( 2 , 128 ), ( 3 , 256 ), ( 3 , 512 ), ( 3 , 512 )) \u56e0\u4e3a\u8fd9\u4e2a\u7f51\u7edc\u4f7f\u7528\u4e8613\u4e2a\u5377\u79ef\u5c42\u548c3\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u6240\u4ee5\u7ecf\u5e38\u88ab\u79f0\u4e3aVGG-16,\u901a\u8fc7\u5236\u5b9aconv_arch\u5f97\u5230\u6a21\u578b\u67b6\u6784\u540e\u6784\u5efaVGG16\uff1a # \u5b9a\u4e49VGG\u7f51\u7edc def vgg ( conv_arch ): # \u6784\u5efa\u5e8f\u5217\u6a21\u578b net = tf . keras . models . Sequential () # \u6839\u636econv_arch\u751f\u6210\u5377\u79ef\u90e8\u5206 for ( num_convs , num_filters ) in conv_arch : net . add ( vgg_block ( num_convs , num_filters )) # \u5377\u79ef\u5757\u5e8f\u5217\u540e\u6dfb\u52a0\u5168\u8fde\u63a5\u5c42 net . add ( tf . keras . models . Sequential ([ # \u5c06\u7279\u5f81\u56fe\u5c55\u6210\u4e00\u7ef4\u5411\u91cf tf . keras . layers . Flatten (), # \u5168\u8fde\u63a5\u5c42\uff1a4096\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu tf . keras . layers . Dense ( 4096 , activation = 'relu' ), # \u968f\u673a\u5931\u6d3b tf . keras . layers . Dropout ( 0.5 ), # \u5168\u8fde\u63a5\u5c42\uff1a4096\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu tf . keras . layers . Dense ( 4096 , activation = 'relu' ), # \u968f\u673a\u5931\u6d3b tf . keras . layers . Dropout ( 0.5 ), # \u5168\u8fde\u63a5\u5c42\uff1a10\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570\u662fsoftmax tf . keras . layers . Dense ( 10 , activation = 'softmax' )])) return net # \u7f51\u7edc\u5b9e\u4f8b\u5316 net = vgg ( conv_arch ) \u6211\u4eec\u6784\u9020\u4e00\u4e2a\u9ad8\u548c\u5bbd\u5747\u4e3a224\u7684\u5355\u901a\u9053\u6570\u636e\u6837\u672c\u6765\u770b\u4e00\u4e0b\u6a21\u578b\u7684\u67b6\u6784\uff1a # \u6784\u9020\u8f93\u5165X\uff0c\u5e76\u5c06\u5176\u9001\u5165\u5230net\u7f51\u7edc\u4e2d X = tf . random . uniform (( 1 , 224 , 224 , 1 )) y = net ( X ) # \u901a\u8fc7net.summay()\u67e5\u770b\u7f51\u7edc\u7684\u5f62\u72b6 net . summay () \u7f51\u7edc\u67b6\u6784\u5982\u4e0b\uff1a Model : \"sequential_15\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= sequential_16 ( Sequential ) ( 1 , 112 , 112 , 64 ) 37568 _________________________________________________________________ sequential_17 ( Sequential ) ( 1 , 56 , 56 , 128 ) 221440 _________________________________________________________________ sequential_18 ( Sequential ) ( 1 , 28 , 28 , 256 ) 1475328 _________________________________________________________________ sequential_19 ( Sequential ) ( 1 , 14 , 14 , 512 ) 5899776 _________________________________________________________________ sequential_20 ( Sequential ) ( 1 , 7 , 7 , 512 ) 7079424 _________________________________________________________________ sequential_21 ( Sequential ) ( 1 , 10 ) 119586826 ================================================================= Total params : 134 , 300 , 362 Trainable params : 134 , 300 , 362 Non - trainable params : 0 __________________________________________________________________ 2.\u624b\u5199\u6570\u5b57\u52bf\u8bc6\u522b \u00b6 \u56e0\u4e3aImageNet\u6570\u636e\u96c6\u8f83\u5927\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u4ecd\u7528\u524d\u9762\u7684MNIST\u6570\u636e\u96c6\u6765\u6f14\u793aVGGNet\u3002\u8bfb\u53d6\u6570\u636e\u7684\u65f6\u5c06\u56fe\u50cf\u9ad8\u548c\u5bbd\u6269\u5927\u5230VggNet\u4f7f\u7528\u7684\u56fe\u50cf\u9ad8\u548c\u5bbd224\u3002\u8fd9\u4e2a\u901a\u8fc7 tf.image.resize_with_pad \u6765\u5b9e\u73b0\u3002 2.1 \u6570\u636e\u8bfb\u53d6 \u00b6 \u9996\u5148\u83b7\u53d6\u6570\u636e,\u5e76\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff1a import numpy as np # \u83b7\u53d6\u624b\u5199\u6570\u5b57\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # \u8bad\u7ec3\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C train_images = np . reshape ( train_images ,( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) # \u6d4b\u8bd5\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C test_images = np . reshape ( test_images ,( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7531\u4e8e\u4f7f\u7528\u5168\u90e8\u6570\u636e\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u83b7\u53d6\u90e8\u5206\u6570\u636e\uff0c\u5e76\u5c06\u56fe\u50cf\u8c03\u6574\u4e3a224*224\u5927\u5c0f\uff0c\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a # \u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u968f\u673a\u62bd\u53d6\u90e8\u5206\u6837\u672c\u6f14\u793a # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e def get_train ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( train_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u621022*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( train_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u53d6\u7684 return resized_images . numpy (), train_labels [ index ] # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e def get_test ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( test_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210224*224\u5927\u5c0f resized_images = tf . image . resize_with_pad ( test_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u6837\u7684\u6d4b\u8bd5\u6837\u672c return resized_images . numpy (), test_labels [ index ] \u8c03\u7528\u4e0a\u8ff0\u4e24\u4e2a\u65b9\u6cd5\uff0c\u83b7\u53d6\u53c2\u4e0e\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\uff1a # \u83b7\u53d6\u8bad\u7ec3\u6837\u672c\u548c\u6d4b\u8bd5\u6837\u672c train_images , train_labels = get_train ( 256 ) test_images , test_labels = get_test ( 128 ) \u4e3a\u4e86\u8ba9\u5927\u5bb6\u66f4\u597d\u7684\u7406\u89e3\uff0c\u6211\u4eec\u5c06\u6570\u636e\u5c55\u793a\u51fa\u6765\uff1a # \u6570\u636e\u5c55\u793a\uff1a\u5c06\u6570\u636e\u96c6\u7684\u524d\u4e5d\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u5c55\u793a for i in range ( 9 ): plt . subplot ( 3 , 3 , i + 1 ) # \u4ee5\u7070\u5ea6\u56fe\u663e\u793a\uff0c\u4e0d\u8fdb\u884c\u63d2\u503c plt . imshow ( train_images [ i ] . astype ( np . int8 ) . squeeze (), cmap = 'gray' , interpolation = 'none' ) # \u8bbe\u7f6e\u56fe\u7247\u7684\u6807\u9898\uff1a\u5bf9\u5e94\u7684\u7c7b\u522b plt . title ( \"\u6570\u5b57 {} \" . format ( train_labels [ i ])) \u7ed3\u679c\u4e3a\uff1a \u6211\u4eec\u5c31\u4f7f\u7528\u4e0a\u8ff0\u521b\u5efa\u7684\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002 2.2 \u6a21\u578b\u7f16\u8bd1 \u00b6 # \u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 ) net . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ]) 2.3 \u6a21\u578b\u8bad\u7ec3 \u00b6 # \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u8bad\u7ec3\u6570\u636e\uff0cbatchsize,epoch,\u9a8c\u8bc1\u96c6 net . fit ( train_images , train_labels , batch_size = 128 , epochs = 3 , verbose = 1 , validation_split = 0.1 ) \u8bad\u7ec3\u8f93\u51fa\u4e3a\uff1a Epoch 1 / 3 2 / 2 [ ============================== ] - 34 s 17 s / step - loss : 2.6026 - accuracy : 0.0957 - val_loss : 2.2982 - val_accuracy : 0.0385 Epoch 2 / 3 2 / 2 [ ============================== ] - 27 s 14 s / step - loss : 2.2604 - accuracy : 0.1087 - val_loss : 2.4905 - val_accuracy : 0.1923 Epoch 3 / 3 2 / 2 [ ============================== ] - 29 s 14 s / step - loss : 2.3650 - accuracy : 0.1000 - val_loss : 2.2994 - val_accuracy : 0.1538 2.4 \u6a21\u578b\u8bc4\u4f30 \u00b6 # \u6307\u5b9a\u6d4b\u8bd5\u6570\u636e net . evaluate ( test_images , test_labels , verbose = 1 ) \u8f93\u51fa\u4e3a\uff1a 4 / 4 [ ============================== ] - 5 s 1 s / step - loss : 2.2955 - accuracy : 0.1016 [ 2.2955007553100586 , 0.1015625 ] \u5982\u679c\u6211\u4eec\u4f7f\u7528\u6574\u4e2a\u6570\u636e\u96c6\u8bad\u7ec3\u7f51\u7edc\uff0c\u5e76\u8fdb\u884c\u8bc4\u4f30\u7684\u7ed3\u679c\uff1a [ 0.31822608125209806 , 0.8855 ] \u603b\u7ed3 \u77e5\u9053VGG\u7684\u7f51\u7edc\u67b6\u6784 \u52a8\u624b\u5b9e\u73b0\u624b\u5199\u6570\u5b57\u7684\u8bc6\u522b","title":"VGG"},{"location":"imageClassification/section3/#33-vgg","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053VGG\u7f51\u7edc\u7ed3\u6784\u7684\u7279\u70b9 \u80fd\u591f\u5229\u7528VGG\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b 2014\u5e74\uff0c\u725b\u6d25\u5927\u5b66\u8ba1\u7b97\u673a\u89c6\u89c9\u7ec4\uff08Visual Geometry Group\uff09\u548cGoogle DeepMind\u516c\u53f8\u7684\u7814\u7a76\u5458\u4e00\u8d77\u7814\u53d1\u51fa\u4e86\u65b0\u7684\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff1aVGGNet\uff0c\u5e76\u53d6\u5f97\u4e86ILSVRC2014\u6bd4\u8d5b\u5206\u7c7b\u9879\u76ee\u7684\u7b2c\u4e8c\u540d\uff0c\u4e3b\u8981\u8d21\u732e\u662f\u4f7f\u7528\u5f88\u5c0f\u7684\u5377\u79ef\u6838(3\u00d73)\u6784\u5efa\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff0c\u80fd\u591f\u53d6\u5f97\u8f83\u597d\u7684\u8bc6\u522b\u7cbe\u5ea6\uff0c\u5e38\u7528\u6765\u63d0\u53d6\u56fe\u50cf\u7279\u5f81\u7684VGG-16\u548cVGG-19\u3002","title":"3.3 VGG"},{"location":"imageClassification/section3/#1vgg","text":"VGG\u53ef\u4ee5\u770b\u6210\u662f\u52a0\u6df1\u7248\u7684AlexNet\uff0c\u6574\u4e2a\u7f51\u7edc\u7531\u5377\u79ef\u5c42\u548c\u5168\u8fde\u63a5\u5c42\u53e0\u52a0\u800c\u6210\uff0c\u548cAlexNet\u4e0d\u540c\u7684\u662f\uff0cVGG\u4e2d\u4f7f\u7528\u7684\u90fd\u662f\u5c0f\u5c3a\u5bf8\u7684\u5377\u79ef\u6838(3\u00d73)\uff0c\u5176\u7f51\u7edc\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a VGGNet\u4f7f\u7528\u7684\u5168\u90e8\u90fd\u662f3x3\u7684\u5c0f\u5377\u79ef\u6838\u548c2x2\u7684\u6c60\u5316\u6838\uff0c\u901a\u8fc7\u4e0d\u65ad\u52a0\u6df1\u7f51\u7edc\u6765\u63d0\u5347\u6027\u80fd\u3002VGG\u53ef\u4ee5\u901a\u8fc7\u91cd\u590d\u4f7f\u7528\u7b80\u5355\u7684\u57fa\u7840\u5757\u6765\u6784\u5efa\u6df1\u5ea6\u6a21\u578b\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0VGG\u6a21\u578b\uff0c\u9996\u5148\u6765\u5b9e\u73b0VGG\u5757\uff0c\u5b83\u7684\u7ec4\u6210\u89c4\u5f8b\u662f\uff1a\u8fde\u7eed\u4f7f\u7528\u591a\u4e2a\u76f8\u540c\u7684\u586b\u5145\u4e3a1\u3001\u5377\u79ef\u6838\u5927\u5c0f\u4e3a 3\\times 3 3\\times 3 \u7684\u5377\u79ef\u5c42\u540e\u63a5\u4e0a\u4e00\u4e2a\u6b65\u5e45\u4e3a2\u3001\u7a97\u53e3\u5f62\u72b6\u4e3a 2\\times 2 2\\times 2 \u7684\u6700\u5927\u6c60\u5316\u5c42\u3002\u5377\u79ef\u5c42\u4fdd\u6301\u8f93\u5165\u7684\u9ad8\u548c\u5bbd\u4e0d\u53d8\uff0c\u800c\u6c60\u5316\u5c42\u5219\u5bf9\u5176\u51cf\u534a\u3002\u6211\u4eec\u4f7f\u7528 vgg_block \u51fd\u6570\u6765\u5b9e\u73b0\u8fd9\u4e2a\u57fa\u7840\u7684VGG\u5757\uff0c\u5b83\u53ef\u4ee5\u6307\u5b9a\u5377\u79ef\u5c42\u7684\u6570\u91cf num_convs \u548c\u6bcf\u5c42\u7684\u5377\u79ef\u6838\u4e2a\u6570num_filters\uff1a # \u5b9a\u4e49VGG\u7f51\u7edc\u4e2d\u7684\u5377\u79ef\u5757\uff1a\u5377\u79ef\u5c42\u7684\u4e2a\u6570\uff0c\u5377\u79ef\u5c42\u4e2d\u5377\u79ef\u6838\u7684\u4e2a\u6570 def vgg_block ( num_convs , num_filters ): # \u6784\u5efa\u5e8f\u5217\u6a21\u578b blk = tf . keras . models . Sequential () # \u904d\u5386\u6240\u6709\u7684\u5377\u79ef\u5c42 for _ in range ( num_convs ): # \u6bcf\u4e2a\u5377\u79ef\u5c42\uff1anum_filter\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u5927\u5c0f\u4e3a3*3\uff0cpadding\u662fsame\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu blk . add ( tf . keras . layers . Conv2D ( num_filters , kernel_size = 3 , padding = 'same' , activation = 'relu' )) # \u5377\u79ef\u5757\u6700\u540e\u662f\u4e00\u4e2a\u6700\u5927\u6c60\u5316\uff0c\u7a97\u53e3\u5927\u5c0f\u4e3a2*2\uff0c\u6b65\u957f\u4e3a2 blk . add ( tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 )) return blk VGG16\u7f51\u7edc\u67095\u4e2a\u5377\u79ef\u5757\uff0c\u524d2\u5757\u4f7f\u7528\u4e24\u4e2a\u5377\u79ef\u5c42\uff0c\u800c\u540e3\u5757\u4f7f\u7528\u4e09\u4e2a\u5377\u79ef\u5c42\u3002\u7b2c\u4e00\u5757\u7684\u8f93\u51fa\u901a\u9053\u662f64\uff0c\u4e4b\u540e\u6bcf\u6b21\u5bf9\u8f93\u51fa\u901a\u9053\u6570\u7ffb\u500d\uff0c\u76f4\u5230\u53d8\u4e3a512\u3002 # \u5b9a\u4e495\u4e2a\u5377\u79ef\u5757\uff0c\u6307\u660e\u6bcf\u4e2a\u5377\u79ef\u5757\u4e2d\u7684\u5377\u79ef\u5c42\u4e2a\u6570\u53ca\u76f8\u5e94\u7684\u5377\u79ef\u6838\u4e2a\u6570 conv_arch = (( 2 , 64 ), ( 2 , 128 ), ( 3 , 256 ), ( 3 , 512 ), ( 3 , 512 )) \u56e0\u4e3a\u8fd9\u4e2a\u7f51\u7edc\u4f7f\u7528\u4e8613\u4e2a\u5377\u79ef\u5c42\u548c3\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u6240\u4ee5\u7ecf\u5e38\u88ab\u79f0\u4e3aVGG-16,\u901a\u8fc7\u5236\u5b9aconv_arch\u5f97\u5230\u6a21\u578b\u67b6\u6784\u540e\u6784\u5efaVGG16\uff1a # \u5b9a\u4e49VGG\u7f51\u7edc def vgg ( conv_arch ): # \u6784\u5efa\u5e8f\u5217\u6a21\u578b net = tf . keras . models . Sequential () # \u6839\u636econv_arch\u751f\u6210\u5377\u79ef\u90e8\u5206 for ( num_convs , num_filters ) in conv_arch : net . add ( vgg_block ( num_convs , num_filters )) # \u5377\u79ef\u5757\u5e8f\u5217\u540e\u6dfb\u52a0\u5168\u8fde\u63a5\u5c42 net . add ( tf . keras . models . Sequential ([ # \u5c06\u7279\u5f81\u56fe\u5c55\u6210\u4e00\u7ef4\u5411\u91cf tf . keras . layers . Flatten (), # \u5168\u8fde\u63a5\u5c42\uff1a4096\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu tf . keras . layers . Dense ( 4096 , activation = 'relu' ), # \u968f\u673a\u5931\u6d3b tf . keras . layers . Dropout ( 0.5 ), # \u5168\u8fde\u63a5\u5c42\uff1a4096\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu tf . keras . layers . Dense ( 4096 , activation = 'relu' ), # \u968f\u673a\u5931\u6d3b tf . keras . layers . Dropout ( 0.5 ), # \u5168\u8fde\u63a5\u5c42\uff1a10\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570\u662fsoftmax tf . keras . layers . Dense ( 10 , activation = 'softmax' )])) return net # \u7f51\u7edc\u5b9e\u4f8b\u5316 net = vgg ( conv_arch ) \u6211\u4eec\u6784\u9020\u4e00\u4e2a\u9ad8\u548c\u5bbd\u5747\u4e3a224\u7684\u5355\u901a\u9053\u6570\u636e\u6837\u672c\u6765\u770b\u4e00\u4e0b\u6a21\u578b\u7684\u67b6\u6784\uff1a # \u6784\u9020\u8f93\u5165X\uff0c\u5e76\u5c06\u5176\u9001\u5165\u5230net\u7f51\u7edc\u4e2d X = tf . random . uniform (( 1 , 224 , 224 , 1 )) y = net ( X ) # \u901a\u8fc7net.summay()\u67e5\u770b\u7f51\u7edc\u7684\u5f62\u72b6 net . summay () \u7f51\u7edc\u67b6\u6784\u5982\u4e0b\uff1a Model : \"sequential_15\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= sequential_16 ( Sequential ) ( 1 , 112 , 112 , 64 ) 37568 _________________________________________________________________ sequential_17 ( Sequential ) ( 1 , 56 , 56 , 128 ) 221440 _________________________________________________________________ sequential_18 ( Sequential ) ( 1 , 28 , 28 , 256 ) 1475328 _________________________________________________________________ sequential_19 ( Sequential ) ( 1 , 14 , 14 , 512 ) 5899776 _________________________________________________________________ sequential_20 ( Sequential ) ( 1 , 7 , 7 , 512 ) 7079424 _________________________________________________________________ sequential_21 ( Sequential ) ( 1 , 10 ) 119586826 ================================================================= Total params : 134 , 300 , 362 Trainable params : 134 , 300 , 362 Non - trainable params : 0 __________________________________________________________________","title":"1.VGG\u7684\u7f51\u7edc\u67b6\u6784"},{"location":"imageClassification/section3/#2","text":"\u56e0\u4e3aImageNet\u6570\u636e\u96c6\u8f83\u5927\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u4ecd\u7528\u524d\u9762\u7684MNIST\u6570\u636e\u96c6\u6765\u6f14\u793aVGGNet\u3002\u8bfb\u53d6\u6570\u636e\u7684\u65f6\u5c06\u56fe\u50cf\u9ad8\u548c\u5bbd\u6269\u5927\u5230VggNet\u4f7f\u7528\u7684\u56fe\u50cf\u9ad8\u548c\u5bbd224\u3002\u8fd9\u4e2a\u901a\u8fc7 tf.image.resize_with_pad \u6765\u5b9e\u73b0\u3002","title":"2.\u624b\u5199\u6570\u5b57\u52bf\u8bc6\u522b"},{"location":"imageClassification/section3/#21","text":"\u9996\u5148\u83b7\u53d6\u6570\u636e,\u5e76\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff1a import numpy as np # \u83b7\u53d6\u624b\u5199\u6570\u5b57\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # \u8bad\u7ec3\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C train_images = np . reshape ( train_images ,( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) # \u6d4b\u8bd5\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C test_images = np . reshape ( test_images ,( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7531\u4e8e\u4f7f\u7528\u5168\u90e8\u6570\u636e\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u83b7\u53d6\u90e8\u5206\u6570\u636e\uff0c\u5e76\u5c06\u56fe\u50cf\u8c03\u6574\u4e3a224*224\u5927\u5c0f\uff0c\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a # \u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u968f\u673a\u62bd\u53d6\u90e8\u5206\u6837\u672c\u6f14\u793a # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e def get_train ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( train_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u621022*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( train_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u53d6\u7684 return resized_images . numpy (), train_labels [ index ] # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e def get_test ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( test_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210224*224\u5927\u5c0f resized_images = tf . image . resize_with_pad ( test_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u6837\u7684\u6d4b\u8bd5\u6837\u672c return resized_images . numpy (), test_labels [ index ] \u8c03\u7528\u4e0a\u8ff0\u4e24\u4e2a\u65b9\u6cd5\uff0c\u83b7\u53d6\u53c2\u4e0e\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\uff1a # \u83b7\u53d6\u8bad\u7ec3\u6837\u672c\u548c\u6d4b\u8bd5\u6837\u672c train_images , train_labels = get_train ( 256 ) test_images , test_labels = get_test ( 128 ) \u4e3a\u4e86\u8ba9\u5927\u5bb6\u66f4\u597d\u7684\u7406\u89e3\uff0c\u6211\u4eec\u5c06\u6570\u636e\u5c55\u793a\u51fa\u6765\uff1a # \u6570\u636e\u5c55\u793a\uff1a\u5c06\u6570\u636e\u96c6\u7684\u524d\u4e5d\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u5c55\u793a for i in range ( 9 ): plt . subplot ( 3 , 3 , i + 1 ) # \u4ee5\u7070\u5ea6\u56fe\u663e\u793a\uff0c\u4e0d\u8fdb\u884c\u63d2\u503c plt . imshow ( train_images [ i ] . astype ( np . int8 ) . squeeze (), cmap = 'gray' , interpolation = 'none' ) # \u8bbe\u7f6e\u56fe\u7247\u7684\u6807\u9898\uff1a\u5bf9\u5e94\u7684\u7c7b\u522b plt . title ( \"\u6570\u5b57 {} \" . format ( train_labels [ i ])) \u7ed3\u679c\u4e3a\uff1a \u6211\u4eec\u5c31\u4f7f\u7528\u4e0a\u8ff0\u521b\u5efa\u7684\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002","title":"2.1 \u6570\u636e\u8bfb\u53d6"},{"location":"imageClassification/section3/#22","text":"# \u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 ) net . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ])","title":"2.2 \u6a21\u578b\u7f16\u8bd1"},{"location":"imageClassification/section3/#23","text":"# \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u8bad\u7ec3\u6570\u636e\uff0cbatchsize,epoch,\u9a8c\u8bc1\u96c6 net . fit ( train_images , train_labels , batch_size = 128 , epochs = 3 , verbose = 1 , validation_split = 0.1 ) \u8bad\u7ec3\u8f93\u51fa\u4e3a\uff1a Epoch 1 / 3 2 / 2 [ ============================== ] - 34 s 17 s / step - loss : 2.6026 - accuracy : 0.0957 - val_loss : 2.2982 - val_accuracy : 0.0385 Epoch 2 / 3 2 / 2 [ ============================== ] - 27 s 14 s / step - loss : 2.2604 - accuracy : 0.1087 - val_loss : 2.4905 - val_accuracy : 0.1923 Epoch 3 / 3 2 / 2 [ ============================== ] - 29 s 14 s / step - loss : 2.3650 - accuracy : 0.1000 - val_loss : 2.2994 - val_accuracy : 0.1538","title":"2.3 \u6a21\u578b\u8bad\u7ec3"},{"location":"imageClassification/section3/#24","text":"# \u6307\u5b9a\u6d4b\u8bd5\u6570\u636e net . evaluate ( test_images , test_labels , verbose = 1 ) \u8f93\u51fa\u4e3a\uff1a 4 / 4 [ ============================== ] - 5 s 1 s / step - loss : 2.2955 - accuracy : 0.1016 [ 2.2955007553100586 , 0.1015625 ] \u5982\u679c\u6211\u4eec\u4f7f\u7528\u6574\u4e2a\u6570\u636e\u96c6\u8bad\u7ec3\u7f51\u7edc\uff0c\u5e76\u8fdb\u884c\u8bc4\u4f30\u7684\u7ed3\u679c\uff1a [ 0.31822608125209806 , 0.8855 ] \u603b\u7ed3 \u77e5\u9053VGG\u7684\u7f51\u7edc\u67b6\u6784 \u52a8\u624b\u5b9e\u73b0\u624b\u5199\u6570\u5b57\u7684\u8bc6\u522b","title":"2.4 \u6a21\u578b\u8bc4\u4f30"},{"location":"imageClassification/section4/","text":"3.4 GoogLeNet \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053GoogLeNet\u7f51\u7edc\u7ed3\u6784\u7684\u7279\u70b9 \u80fd\u591f\u5229\u7528GoogLeNet\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b GoogLeNet\u7684\u540d\u5b57\u4e0d\u662fGoogleNet\uff0c\u800c\u662fGoogLeNet\uff0c\u8fd9\u662f\u4e3a\u4e86\u81f4\u656cLeNet\u3002GoogLeNet\u548cAlexNet/VGGNet\u8fd9\u7c7b\u4f9d\u9760\u52a0\u6df1\u7f51\u7edc\u7ed3\u6784\u7684\u6df1\u5ea6\u7684\u601d\u60f3\u4e0d\u5b8c\u5168\u4e00\u6837\u3002GoogLeNet\u5728\u52a0\u6df1\u5ea6\u7684\u540c\u65f6\u505a\u4e86\u7ed3\u6784\u4e0a\u7684\u521b\u65b0\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u53eb\u505aInception\u7684\u7ed3\u6784\u6765\u4ee3\u66ff\u4e4b\u524d\u7684\u5377\u79ef\u52a0\u6fc0\u6d3b\u7684\u7ecf\u5178\u7ec4\u4ef6\u3002GoogLeNet\u5728ImageNet\u5206\u7c7b\u6bd4\u8d5b\u4e0a\u7684Top-5\u9519\u8bef\u7387\u964d\u4f4e\u5230\u4e866.7%\u3002\u3002 1.Inception \u5757 \u00b6 GoogLeNet\u4e2d\u7684\u57fa\u7840\u5377\u79ef\u5757\u53eb\u4f5cInception\u5757\uff0c\u5f97\u540d\u4e8e\u540c\u540d\u7535\u5f71\u300a\u76d7\u68a6\u7a7a\u95f4\u300b\uff08Inception\uff09\u3002Inception\u5757\u5728\u7ed3\u6784\u6bd4\u8f83\u590d\u6742\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a Inception\u5757\u91cc\u67094\u6761\u5e76\u884c\u7684\u7ebf\u8def\u3002\u524d3\u6761\u7ebf\u8def\u4f7f\u7528\u7a97\u53e3\u5927\u5c0f\u5206\u522b\u662f 1\\times 1 1\\times 1 \u3001 3\\times 3 3\\times 3 \u548c 5\\times 5 5\\times 5 \u7684\u5377\u79ef\u5c42\u6765\u62bd\u53d6\u4e0d\u540c\u7a7a\u95f4\u5c3a\u5bf8\u4e0b\u7684\u4fe1\u606f\uff0c\u5176\u4e2d\u4e2d\u95f42\u4e2a\u7ebf\u8def\u4f1a\u5bf9\u8f93\u5165\u5148\u505a 1\\times 1 1\\times 1 \u5377\u79ef\u6765\u51cf\u5c11\u8f93\u5165\u901a\u9053\u6570\uff0c\u4ee5\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\u3002\u7b2c4\u6761\u7ebf\u8def\u5219\u4f7f\u7528 3\\times 3 3\\times 3 \u6700\u5927\u6c60\u5316\u5c42\uff0c\u540e\u63a5 1\\times 1 1\\times 1 \u5377\u79ef\u5c42\u6765\u6539\u53d8\u901a\u9053\u6570\u30024\u6761\u7ebf\u8def\u90fd\u4f7f\u7528\u4e86\u5408\u9002\u7684\u586b\u5145\u6765\u4f7f\u8f93\u5165\u4e0e\u8f93\u51fa\u7684\u9ad8\u548c\u5bbd\u4e00\u81f4\u3002\u6700\u540e\u6211\u4eec\u5c06\u6bcf\u6761\u7ebf\u8def\u7684\u8f93\u51fa\u5728\u901a\u9053\u7ef4\u4e0a\u8fde\u7ed3,\u5e76\u5411\u540e\u8fdb\u884c\u4f20\u8f93\u3002 1\\times 1 1\\times 1 \u5377\u79ef \uff1a \u5b83\u7684\u8ba1\u7b97\u65b9\u6cd5\u548c\u5176\u4ed6\u5377\u79ef\u6838\u4e00\u6837\uff0c\u552f\u4e00\u4e0d\u540c\u7684\u662f\u5b83\u7684\u5927\u5c0f\u662f 1\\times1 1\\times1 \uff0c\u6ca1\u6709\u8003\u8651\u5728\u7279\u5f81\u56fe\u5c40\u90e8\u4fe1\u606f\u4e4b\u95f4\u7684\u5173\u7cfb\u3002 \u5b83\u7684\u4f5c\u7528\u4e3b\u8981\u662f\uff1a \u5b9e\u73b0\u8de8\u901a\u9053\u7684\u4ea4\u4e92\u548c\u4fe1\u606f\u6574\u5408 \u5377\u79ef\u6838\u901a\u9053\u6570\u7684\u964d\u7ef4\u548c\u5347\u7ef4\uff0c\u51cf\u5c11\u7f51\u7edc\u53c2\u6570 \u3010\u6269\u5c55\ud83d\udcda\uff1a\u4e3a\u4ec0\u4e481x1\u5377\u79ef\u53ef\u4ee5\u51cf\u5c11\u7f51\u7edc\u53c2\u6570\uff1f\u3011 \u4ee5inception\u6a21\u5757\u4e3a\u4f8b\uff0c\u6765\u8bf4\u660e1x1\u7684\u5377\u79ef\u5982\u4f55\u6765\u51cf\u5c11\u6a21\u578b\u53c2\u6570\uff1a (a)\u662f\u672a\u52a0\u51651x1\u5377\u79ef\u7684inception\u6a21\u5757\uff0c(b)\u662f\u52a0\u5165\u4e861x1 \u5377\u79ef\u7684inception\u6a21\u5757\u3002 \u6211\u4eec\u4ee53x3\u5377\u79ef\u7ebf\u8def\u4e3a\u4f8b\uff0c\u5047\u8bbe\u8f93\u5165\u7684\u7279\u5f81\u56fe\u5927\u5c0f\u4e3a\uff0828x28x192\uff09\uff0c\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u901a\u9053\u6570\u662f128\uff1a (a)\u56fe\u4e2d\u8be5\u7ebf\u8def\u7684\u53c2\u6570\u91cf\u4e3a\uff1a3x3x192x128 = 221184 (b)\u56fe\u4e2d\u52a0\u51651x1\u5377\u79ef\u540e\u901a\u9053\u4e3a96\uff0c\u518d\u9001\u51653x3\u5377\u79ef\u4e2d\u7684\u53c2\u6570\u91cf\u4e3a\uff1a(1x1x192x96)+(3x3x96x128)=129024. \u5bf9\u6bd4\u53ef\u77e5\uff0c\u52a0\u51651x1\u5377\u79ef\u540e\u53c2\u6570\u91cf\u51cf\u5c11\u4e86\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0Inception\u6a21\u5757\uff0c\u5404\u4e2a\u5377\u79ef\u5c42\u5377\u79ef\u6838\u7684\u4e2a\u6570\u901a\u8fc7\u8f93\u5165\u53c2\u6570\u6765\u63a7\u5236\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5b9a\u4e49Inception\u6a21\u5757 class Inception ( tf . keras . layers . Layer ): # \u8f93\u5165\u53c2\u6570\u4e3a\u5404\u4e2a\u5377\u79ef\u7684\u5377\u79ef\u6838\u4e2a\u6570 def __init__ ( self , c1 , c2 , c3 , c4 ): super () . __init__ () # \u7ebf\u8def1\uff1a1 x 1\u5377\u79ef\u5c42\uff0c\u6fc0\u6d3b\u51fd\u6570\u662fRELU\uff0cpadding\u662fsame self . p1_1 = tf . keras . layers . Conv2D ( c1 , kernel_size = 1 , activation = 'relu' , padding = 'same' ) # \u7ebf\u8def2\uff0c1 x 1\u5377\u79ef\u5c42\u540e\u63a53 x 3\u5377\u79ef\u5c42,\u6fc0\u6d3b\u51fd\u6570\u662fRELU\uff0cpadding\u662fsame self . p2_1 = tf . keras . layers . Conv2D ( c2 [ 0 ], kernel_size = 1 , padding = 'same' , activation = 'relu' ) self . p2_2 = tf . keras . layers . Conv2D ( c2 [ 1 ], kernel_size = 3 , padding = 'same' , activation = 'relu' ) # \u7ebf\u8def3\uff0c1 x 1\u5377\u79ef\u5c42\u540e\u63a55 x 5\u5377\u79ef\u5c42,\u6fc0\u6d3b\u51fd\u6570\u662fRELU\uff0cpadding\u662fsame self . p3_1 = tf . keras . layers . Conv2D ( c3 [ 0 ], kernel_size = 1 , padding = 'same' , activation = 'relu' ) self . p3_2 = tf . keras . layers . Conv2D ( c3 [ 1 ], kernel_size = 5 , padding = 'same' , activation = 'relu' ) # \u7ebf\u8def4\uff0c3 x 3\u6700\u5927\u6c60\u5316\u5c42\u540e\u63a51 x 1\u5377\u79ef\u5c42,\u6fc0\u6d3b\u51fd\u6570\u662fRELU\uff0cpadding\u662fsame self . p4_1 = tf . keras . layers . MaxPool2D ( pool_size = 3 , padding = 'same' , strides = 1 ) self . p4_2 = tf . keras . layers . Conv2D ( c4 , kernel_size = 1 , padding = 'same' , activation = 'relu' ) # \u5b8c\u6210\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b def call ( self , x ): # \u7ebf\u8def1 p1 = self . p1_1 ( x ) # \u7ebf\u8def2 p2 = self . p2_2 ( self . p2_1 ( x )) # \u7ebf\u8def3 p3 = self . p3_2 ( self . p3_1 ( x )) # \u7ebf\u8def4 p4 = self . p4_2 ( self . p4_1 ( x )) # \u5728\u901a\u9053\u7ef4\u4e0aconcat\u8f93\u51fa outputs = tf . concat ([ p1 , p2 , p3 , p4 ], axis =- 1 ) return outputs \u6307\u5b9a\u901a\u9053\u6570\uff0c\u5bf9Inception\u6a21\u5757\u8fdb\u884c\u5b9e\u4f8b\u5316\uff1a Inception ( 64 , ( 96 , 128 ), ( 16 , 32 ), 32 ) 2.GoogLeNet\u6a21\u578b \u00b6 GoogLeNet\u4e3b\u8981\u7531Inception\u6a21\u5757\u6784\u6210\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6574\u4e2a\u7f51\u7edc\u67b6\u6784\u6211\u4eec\u5206\u4e3a\u4e94\u4e2a\u6a21\u5757\uff0c\u6bcf\u4e2a\u6a21\u5757\u4e4b\u95f4\u4f7f\u7528\u6b65\u5e45\u4e3a2\u7684 3\\times 3 3\\times 3 \u6700\u5927\u6c60\u5316\u5c42\u6765\u51cf\u5c0f\u8f93\u51fa\u9ad8\u5bbd\u3002 \u3010\u6269\u5c55\ud83d\udcda\uff1agoogLeNet\u7684\u7f51\u7edc\u8bbe\u8ba1\u3011 2.1 B1\u6a21\u5757 \u00b6 \u7b2c\u4e00\u6a21\u5757\u4f7f\u7528\u4e00\u4e2a64\u901a\u9053\u7684 7\\times 7 7\\times 7 \u5377\u79ef\u5c42\u3002 # \u5b9a\u4e49\u6a21\u578b\u7684\u8f93\u5165 inputs = tf . keras . Input ( shape = ( 224 , 224 , 3 ), name = \"input\" ) # b1 \u6a21\u5757 # \u5377\u79ef\u5c427*7\u7684\u5377\u79ef\u6838\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame\uff0c\u6fc0\u6d3b\u51fd\u6570RELU x = tf . keras . layers . Conv2D ( 64 , kernel_size = 7 , strides = 2 , padding = 'same' , activation = 'relu' )( inputs ) # \u6700\u5927\u6c60\u5316\uff1a\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame x = tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' )( x ) # b2 \u6a21\u5757 2.2 B2\u6a21\u5757 \u00b6 \u7b2c\u4e8c\u6a21\u5757\u4f7f\u75282\u4e2a\u5377\u79ef\u5c42\uff1a\u9996\u5148\u662f64\u901a\u9053\u7684 1\\times 1 1\\times 1 \u5377\u79ef\u5c42\uff0c\u7136\u540e\u662f\u5c06\u901a\u9053\u589e\u59273\u500d\u7684 3\\times 3 3\\times 3 \u5377\u79ef\u5c42\u3002 # b2 \u6a21\u5757 # \u5377\u79ef\u5c421*1\u7684\u5377\u79ef\u6838\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame\uff0c\u6fc0\u6d3b\u51fd\u6570RELU x = tf . keras . layers . Conv2D ( 64 , kernel_size = 1 , padding = 'same' , activation = 'relu' )( x ) # \u5377\u79ef\u5c423*3\u7684\u5377\u79ef\u6838\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame\uff0c\u6fc0\u6d3b\u51fd\u6570RELU x = tf . keras . layers . Conv2D ( 192 , kernel_size = 3 , padding = 'same' , activation = 'relu' )( x ) # \u6700\u5927\u6c60\u5316\uff1a\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame x = tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' )( x ) 2.3 B3\u6a21\u5757 \u00b6 \u7b2c\u4e09\u6a21\u5757\u4e32\u80542\u4e2a\u5b8c\u6574\u7684Inception\u5757\u3002\u7b2c\u4e00\u4e2aInception\u5757\u7684\u8f93\u51fa\u901a\u9053\u6570\u4e3a 64+128+32+32=256 64+128+32+32=256 \u3002\u7b2c\u4e8c\u4e2aInception\u5757\u8f93\u51fa\u901a\u9053\u6570\u589e\u81f3 128+192+96+64=480 128+192+96+64=480 \u3002 # b3 \u6a21\u5757 # Inception x = Inception ( 64 , ( 96 , 128 ), ( 16 , 32 ), 32 )( x ) # Inception x = Inception ( 128 , ( 128 , 192 ), ( 32 , 96 ), 64 )( x ) # \u6700\u5927\u6c60\u5316\uff1a\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame x = tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' )( x ) 2.4 B4\u6a21\u5757 \u00b6 \u7b2c\u56db\u6a21\u5757\u66f4\u52a0\u590d\u6742\u3002\u5b83\u4e32\u8054\u4e865\u4e2aInception\u5757\uff0c\u5176\u8f93\u51fa\u901a\u9053\u6570\u5206\u522b\u662f 192+208+48+64=512 192+208+48+64=512 \u3001 160+224+64+64=512 160+224+64+64=512 \u3001 128+256+64+64=512 128+256+64+64=512 \u3001 112+288+64+64=528 112+288+64+64=528 \u548c 256+320+128+128=832 256+320+128+128=832 \u3002\u5e76\u4e14\u589e\u52a0\u4e86\u8f85\u52a9\u5206\u7c7b\u5668\uff0c\u6839\u636e\u5b9e\u9a8c\u53d1\u73b0\u7f51\u7edc\u7684\u4e2d\u95f4\u5c42\u5177\u6709\u5f88\u5f3a\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u4e3a\u4e86\u5229\u7528\u4e2d\u95f4\u5c42\u62bd\u8c61\u7684\u7279\u5f81\uff0c\u5728\u67d0\u4e9b\u4e2d\u95f4\u5c42\u4e2d\u6dfb\u52a0\u542b\u6709\u591a\u5c42\u7684\u5206\u7c7b\u5668\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5b9e\u73b0\u5982\u4e0b\u6240\u793a\uff1a def aux_classifier ( x , filter_size ): #x:\u8f93\u5165\u6570\u636e\uff0cfilter_size:\u5377\u79ef\u5c42\u5377\u79ef\u6838\u4e2a\u6570\uff0c\u5168\u8fde\u63a5\u5c42\u795e\u7ecf\u5143\u4e2a\u6570 # \u6c60\u5316\u5c42 x = tf . keras . layers . AveragePooling2D ( pool_size = 5 , strides = 3 , padding = 'same' )( x ) # 1x1 \u5377\u79ef\u5c42 x = tf . keras . layers . Conv2D ( filters = filter_size [ 0 ], kernel_size = 1 , strides = 1 , padding = 'valid' , activation = 'relu' )( x ) # \u5c55\u5e73 x = tf . keras . layers . Flatten ()( x ) # \u5168\u8fde\u63a5\u5c421 x = tf . keras . layers . Dense ( units = filter_size [ 1 ], activation = 'relu' )( x ) # softmax\u8f93\u51fa\u5c42 x = tf . keras . layers . Dense ( units = 10 , activation = 'softmax' )( x ) return x b4\u6a21\u5757\u7684\u5b9e\u73b0\uff1a # b4 \u6a21\u5757 # Inception x = Inception ( 192 , ( 96 , 208 ), ( 16 , 48 ), 64 )( x ) # \u8f85\u52a9\u8f93\u51fa1 aux_output_1 = aux_classifier ( x , [ 128 , 1024 ]) # Inception x = Inception ( 160 , ( 112 , 224 ), ( 24 , 64 ), 64 )( x ) # Inception x = Inception ( 128 , ( 128 , 256 ), ( 24 , 64 ), 64 )( x ) # Inception x = Inception ( 112 , ( 144 , 288 ), ( 32 , 64 ), 64 )( x ) # \u8f85\u52a9\u8f93\u51fa2 aux_output_2 = aux_classifier ( x , [ 128 , 1024 ]) # Inception x = Inception ( 256 , ( 160 , 320 ), ( 32 , 128 ), 128 )( x ) # \u6700\u5927\u6c60\u5316 x = tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' )( x ) 2.5 B5\u6a21\u5757 \u00b6 \u7b2c\u4e94\u6a21\u5757\u6709\u8f93\u51fa\u901a\u9053\u6570\u4e3a 256+320+128+128=832 256+320+128+128=832 \u548c 384+384+128+128=1024 384+384+128+128=1024 \u7684\u4e24\u4e2aInception\u5757\u3002\u540e\u9762\u7d27\u8ddf\u8f93\u51fa\u5c42\uff0c\u8be5\u6a21\u5757\u4f7f\u7528\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\uff08GAP\uff09\u6765\u5c06\u6bcf\u4e2a\u901a\u9053\u7684\u9ad8\u548c\u5bbd\u53d8\u62101\u3002\u6700\u540e\u8f93\u51fa\u53d8\u6210\u4e8c\u7ef4\u6570\u7ec4\u540e\u63a5\u8f93\u51fa\u4e2a\u6570\u4e3a\u6807\u7b7e\u7c7b\u522b\u6570\u7684\u5168\u8fde\u63a5\u5c42\u3002 \u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\uff08GAP\uff09 \u7528\u6765\u66ff\u4ee3\u5168\u8fde\u63a5\u5c42\u524d\u7684Flatten\uff0c\u5c06\u7279\u5f81\u56fe\u6bcf\u4e00\u901a\u9053\u4e2d\u6240\u6709\u50cf\u7d20\u503c\u76f8\u52a0\u540e\u6c42\u5e73\u5747\uff0c\u5f97\u5230\u5c31\u662fGAP\u7684\u7ed3\u679c\uff0c\u5728\u5c06\u5176\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u8ba1\u7b97 \u5b9e\u73b0\u8fc7\u7a0b\u662f\uff1a # b5 \u6a21\u5757 # Inception x = Inception ( 256 , ( 160 , 320 ), ( 32 , 128 ), 128 )( x ) # Inception x = Inception ( 384 , ( 192 , 384 ), ( 48 , 128 ), 128 )( x ) # GAP x = tf . keras . layers . GlobalAvgPool2D ()( x ) # \u8f93\u51fa\u5c42 main_outputs = tf . keras . layers . Dense ( 10 , activation = 'softmax' )( x ) # \u4f7f\u7528Model\u6765\u521b\u5efa\u6a21\u578b\uff0c\u6307\u660e\u8f93\u5165\u548c\u8f93\u51fa \u6784\u5efaGoogLeNet\u6a21\u578b\u5e76\u901a\u8fc7summary\u6765\u770b\u4e0b\u6a21\u578b\u7684\u7ed3\u6784\uff1a # \u4f7f\u7528Model\u6765\u521b\u5efa\u6a21\u578b\uff0c\u6307\u660e\u8f93\u5165\u548c\u8f93\u51fa model = tf . keras . Model ( inputs = inputs , outputs = [ main_outputs , aux_output_1 \uff0c aux_output_2 ]) model . summary () Model : \"functional_3\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= input ( InputLayer ) [( None , 224 , 224 , 3 )] 0 _________________________________________________________________ conv2d_122 ( Conv2D ) ( None , 112 , 112 , 64 ) 9472 _________________________________________________________________ max_pooling2d_27 ( MaxPooling ( None , 56 , 56 , 64 ) 0 _________________________________________________________________ conv2d_123 ( Conv2D ) ( None , 56 , 56 , 64 ) 4160 _________________________________________________________________ conv2d_124 ( Conv2D ) ( None , 56 , 56 , 192 ) 110784 _________________________________________________________________ max_pooling2d_28 ( MaxPooling ( None , 28 , 28 , 192 ) 0 _________________________________________________________________ inception_19 ( Inception ) ( None , 28 , 28 , 256 ) 163696 _________________________________________________________________ inception_20 ( Inception ) ( None , 28 , 28 , 480 ) 388736 _________________________________________________________________ max_pooling2d_31 ( MaxPooling ( None , 14 , 14 , 480 ) 0 _________________________________________________________________ inception_21 ( Inception ) ( None , 14 , 14 , 512 ) 376176 _________________________________________________________________ inception_22 ( Inception ) ( None , 14 , 14 , 512 ) 449160 _________________________________________________________________ inception_23 ( Inception ) ( None , 14 , 14 , 512 ) 510104 _________________________________________________________________ inception_24 ( Inception ) ( None , 14 , 14 , 528 ) 605376 _________________________________________________________________ inception_25 ( Inception ) ( None , 14 , 14 , 832 ) 868352 _________________________________________________________________ max_pooling2d_37 ( MaxPooling ( None , 7 , 7 , 832 ) 0 _________________________________________________________________ inception_26 ( Inception ) ( None , 7 , 7 , 832 ) 1043456 _________________________________________________________________ inception_27 ( Inception ) ( None , 7 , 7 , 1024 ) 1444080 _________________________________________________________________ global_average_pooling2d_2 ( ( None , 1024 ) 0 _________________________________________________________________ dense_10 ( Dense ) ( None , 10 ) 10250 ================================================================= Total params : 5 , 983 , 802 Trainable params : 5 , 983 , 802 Non - trainable params : 0 ___________________________________________________________ 3.\u624b\u5199\u6570\u5b57\u8bc6\u522b \u00b6 \u56e0\u4e3aImageNet\u6570\u636e\u96c6\u8f83\u5927\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u4ecd\u7528\u524d\u9762\u7684MNIST\u6570\u636e\u96c6\u6765\u6f14\u793aGoogLeNet\u3002\u8bfb\u53d6\u6570\u636e\u7684\u65f6\u5c06\u56fe\u50cf\u9ad8\u548c\u5bbd\u6269\u5927\u5230\u56fe\u50cf\u9ad8\u548c\u5bbd224\u3002\u8fd9\u4e2a\u901a\u8fc7 tf.image.resize_with_pad \u6765\u5b9e\u73b0\u3002 2.1 \u6570\u636e\u8bfb\u53d6 \u00b6 \u9996\u5148\u83b7\u53d6\u6570\u636e,\u5e76\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff1a import numpy as np # \u83b7\u53d6\u624b\u5199\u6570\u5b57\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # \u8bad\u7ec3\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C train_images = np . reshape ( train_images ,( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) # \u6d4b\u8bd5\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C test_images = np . reshape ( test_images ,( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7531\u4e8e\u4f7f\u7528\u5168\u90e8\u6570\u636e\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u83b7\u53d6\u90e8\u5206\u6570\u636e\uff0c\u5e76\u5c06\u56fe\u50cf\u8c03\u6574\u4e3a224*224\u5927\u5c0f\uff0c\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a(\u4e0eVGG\u4e2d\u662f\u4e00\u6837\u7684) # \u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u968f\u673a\u62bd\u53d6\u90e8\u5206\u6837\u672c\u6f14\u793a # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e def get_train ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( train_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u621022*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( train_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u53d6\u7684 return resized_images . numpy (), train_labels [ index ] # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e def get_test ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( test_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210224*224\u5927\u5c0f resized_images = tf . image . resize_with_pad ( test_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u6837\u7684\u6d4b\u8bd5\u6837\u672c return resized_images . numpy (), test_labels [ index ] \u8c03\u7528\u4e0a\u8ff0\u4e24\u4e2a\u65b9\u6cd5\uff0c\u83b7\u53d6\u53c2\u4e0e\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\uff1a # \u83b7\u53d6\u8bad\u7ec3\u6837\u672c\u548c\u6d4b\u8bd5\u6837\u672c train_images , train_labels = get_train ( 256 ) test_images , test_labels = get_test ( 128 ) 3.2 \u6a21\u578b\u7f16\u8bd1 \u00b6 # \u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 ) # \u6a21\u578b\u67093\u4e2a\u8f93\u51fa\uff0c\u6240\u4ee5\u6307\u5b9a\u635f\u5931\u51fd\u6570\u5bf9\u5e94\u7684\u6743\u91cd\u7cfb\u6570 net . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ], loss_weights = [ 1 , 0.3 , 0.3 ]) 3.3 \u6a21\u578b\u8bad\u7ec3 \u00b6 # \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u8bad\u7ec3\u6570\u636e\uff0cbatchsize,epoch,\u9a8c\u8bc1\u96c6 net . fit ( train_images , train_labels , batch_size = 128 , epochs = 3 , verbose = 1 , validation_split = 0.1 ) \u8bad\u7ec3\u8fc7\u7a0b\uff1a Epoch 1 / 3 2 / 2 [ ============================== ] - 8 s 4 s / step - loss : 2.9527 - accuracy : 0.1174 - val_loss : 3.3254 - val_accuracy : 0.1154 Epoch 2 / 3 2 / 2 [ ============================== ] - 7 s 4 s / step - loss : 2.8111 - accuracy : 0.0957 - val_loss : 2.2718 - val_accuracy : 0.2308 Epoch 3 / 3 2 / 2 [ ============================== ] - 7 s 4 s / step - loss : 2.3055 - accuracy : 0.0957 - val_loss : 2.2669 - val_accuracy : 0.2308 2.4 \u6a21\u578b\u8bc4\u4f30 \u00b6 # \u6307\u5b9a\u6d4b\u8bd5\u6570\u636e net . evaluate ( test_images , test_labels , verbose = 1 ) \u8f93\u51fa\u4e3a\uff1a 4 / 4 [ ============================== ] - 1 s 338 ms / step - loss : 2.3110 - accuracy : 0.0781 [ 2.310971260070801 , 0.078125 ] 4.\u5ef6\u4f38\u7248\u672c \u00b6 GoogLeNet\u662f\u4ee5InceptionV1\u4e3a\u57fa\u7840\u8fdb\u884c\u6784\u5efa\u7684\uff0c\u6240\u4ee5GoogLeNet\u4e5f\u53eb\u505aInceptionNet,\u5728\u968f\u540e\u7684\u2f0f\u5e74\u2fa5\uff0c\u7814\u7a76\u2f08\u5458\u5bf9GoogLeNet\u8fdb\u2f8f\u4e86\u6570\u6b21\u6539\u8fdb\uff0c \u5c31\u53c8\u4ea7\u751f\u4e86InceptionV2\uff0cV3,V4\u7b49\u7248\u672c\u3002 4.1 InceptionV2 \u00b6 \u5728InceptionV2\u4e2d\u5c06\u5927\u5377\u79ef\u6838\u62c6\u5206\u4e3a\u5c0f\u5377\u79ef\u6838\uff0c\u5c06V1\u4e2d\u7684 5\\times 5 5\\times 5 \u7684\u5377\u79ef\u7528\u4e24\u4e2a 3\\times 3 3\\times 3 \u7684\u5377\u79ef\u66ff\u4ee3\uff0c\u4ece\u800c\u589e\u52a0\u7f51\u7edc\u7684\u6df1\u5ea6\uff0c\u51cf\u5c11\u4e86\u53c2\u6570\u3002 4.2 InceptionV3 \u00b6 \u5c06n\u00d7n\u5377\u79ef\u5206\u5272\u4e3a1\u00d7n\u548cn\u00d71\u4e24\u4e2a\u5377\u79ef\uff0c\u4f8b\u5982\uff0c\u4e00\u4e2a\u7684 3\\times3 3\\times3 \u5377\u79ef\u9996\u5148\u6267\u884c\u4e00\u4e2a 1\\times3 1\\times3 \u7684\u5377\u79ef\uff0c\u7136\u540e\u6267\u884c\u4e00\u4e2a 3\\times1 3\\times1 \u7684\u5377\u79ef,\u8fd9\u79cd\u65b9\u6cd5\u7684\u53c2\u6570\u91cf\u548c\u8ba1\u7b97\u91cf\u90fd\u6bd4\u539f\u6765\u964d\u4f4e\u3002 \u603b\u7ed3 \u77e5\u9053GoogLeNet\u7684\u7f51\u7edc\u67b6\u6784\uff1a\u6709\u57fa\u7840\u6a21\u5757Inception\u6784\u6210 \u80fd\u591f\u5229\u7528GoogleNet\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b","title":"GoogLeNet"},{"location":"imageClassification/section4/#34-googlenet","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053GoogLeNet\u7f51\u7edc\u7ed3\u6784\u7684\u7279\u70b9 \u80fd\u591f\u5229\u7528GoogLeNet\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b GoogLeNet\u7684\u540d\u5b57\u4e0d\u662fGoogleNet\uff0c\u800c\u662fGoogLeNet\uff0c\u8fd9\u662f\u4e3a\u4e86\u81f4\u656cLeNet\u3002GoogLeNet\u548cAlexNet/VGGNet\u8fd9\u7c7b\u4f9d\u9760\u52a0\u6df1\u7f51\u7edc\u7ed3\u6784\u7684\u6df1\u5ea6\u7684\u601d\u60f3\u4e0d\u5b8c\u5168\u4e00\u6837\u3002GoogLeNet\u5728\u52a0\u6df1\u5ea6\u7684\u540c\u65f6\u505a\u4e86\u7ed3\u6784\u4e0a\u7684\u521b\u65b0\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u53eb\u505aInception\u7684\u7ed3\u6784\u6765\u4ee3\u66ff\u4e4b\u524d\u7684\u5377\u79ef\u52a0\u6fc0\u6d3b\u7684\u7ecf\u5178\u7ec4\u4ef6\u3002GoogLeNet\u5728ImageNet\u5206\u7c7b\u6bd4\u8d5b\u4e0a\u7684Top-5\u9519\u8bef\u7387\u964d\u4f4e\u5230\u4e866.7%\u3002\u3002","title":"3.4 GoogLeNet"},{"location":"imageClassification/section4/#1inception","text":"GoogLeNet\u4e2d\u7684\u57fa\u7840\u5377\u79ef\u5757\u53eb\u4f5cInception\u5757\uff0c\u5f97\u540d\u4e8e\u540c\u540d\u7535\u5f71\u300a\u76d7\u68a6\u7a7a\u95f4\u300b\uff08Inception\uff09\u3002Inception\u5757\u5728\u7ed3\u6784\u6bd4\u8f83\u590d\u6742\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a Inception\u5757\u91cc\u67094\u6761\u5e76\u884c\u7684\u7ebf\u8def\u3002\u524d3\u6761\u7ebf\u8def\u4f7f\u7528\u7a97\u53e3\u5927\u5c0f\u5206\u522b\u662f 1\\times 1 1\\times 1 \u3001 3\\times 3 3\\times 3 \u548c 5\\times 5 5\\times 5 \u7684\u5377\u79ef\u5c42\u6765\u62bd\u53d6\u4e0d\u540c\u7a7a\u95f4\u5c3a\u5bf8\u4e0b\u7684\u4fe1\u606f\uff0c\u5176\u4e2d\u4e2d\u95f42\u4e2a\u7ebf\u8def\u4f1a\u5bf9\u8f93\u5165\u5148\u505a 1\\times 1 1\\times 1 \u5377\u79ef\u6765\u51cf\u5c11\u8f93\u5165\u901a\u9053\u6570\uff0c\u4ee5\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\u3002\u7b2c4\u6761\u7ebf\u8def\u5219\u4f7f\u7528 3\\times 3 3\\times 3 \u6700\u5927\u6c60\u5316\u5c42\uff0c\u540e\u63a5 1\\times 1 1\\times 1 \u5377\u79ef\u5c42\u6765\u6539\u53d8\u901a\u9053\u6570\u30024\u6761\u7ebf\u8def\u90fd\u4f7f\u7528\u4e86\u5408\u9002\u7684\u586b\u5145\u6765\u4f7f\u8f93\u5165\u4e0e\u8f93\u51fa\u7684\u9ad8\u548c\u5bbd\u4e00\u81f4\u3002\u6700\u540e\u6211\u4eec\u5c06\u6bcf\u6761\u7ebf\u8def\u7684\u8f93\u51fa\u5728\u901a\u9053\u7ef4\u4e0a\u8fde\u7ed3,\u5e76\u5411\u540e\u8fdb\u884c\u4f20\u8f93\u3002 1\\times 1 1\\times 1 \u5377\u79ef \uff1a \u5b83\u7684\u8ba1\u7b97\u65b9\u6cd5\u548c\u5176\u4ed6\u5377\u79ef\u6838\u4e00\u6837\uff0c\u552f\u4e00\u4e0d\u540c\u7684\u662f\u5b83\u7684\u5927\u5c0f\u662f 1\\times1 1\\times1 \uff0c\u6ca1\u6709\u8003\u8651\u5728\u7279\u5f81\u56fe\u5c40\u90e8\u4fe1\u606f\u4e4b\u95f4\u7684\u5173\u7cfb\u3002 \u5b83\u7684\u4f5c\u7528\u4e3b\u8981\u662f\uff1a \u5b9e\u73b0\u8de8\u901a\u9053\u7684\u4ea4\u4e92\u548c\u4fe1\u606f\u6574\u5408 \u5377\u79ef\u6838\u901a\u9053\u6570\u7684\u964d\u7ef4\u548c\u5347\u7ef4\uff0c\u51cf\u5c11\u7f51\u7edc\u53c2\u6570 \u3010\u6269\u5c55\ud83d\udcda\uff1a\u4e3a\u4ec0\u4e481x1\u5377\u79ef\u53ef\u4ee5\u51cf\u5c11\u7f51\u7edc\u53c2\u6570\uff1f\u3011 \u4ee5inception\u6a21\u5757\u4e3a\u4f8b\uff0c\u6765\u8bf4\u660e1x1\u7684\u5377\u79ef\u5982\u4f55\u6765\u51cf\u5c11\u6a21\u578b\u53c2\u6570\uff1a (a)\u662f\u672a\u52a0\u51651x1\u5377\u79ef\u7684inception\u6a21\u5757\uff0c(b)\u662f\u52a0\u5165\u4e861x1 \u5377\u79ef\u7684inception\u6a21\u5757\u3002 \u6211\u4eec\u4ee53x3\u5377\u79ef\u7ebf\u8def\u4e3a\u4f8b\uff0c\u5047\u8bbe\u8f93\u5165\u7684\u7279\u5f81\u56fe\u5927\u5c0f\u4e3a\uff0828x28x192\uff09\uff0c\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u901a\u9053\u6570\u662f128\uff1a (a)\u56fe\u4e2d\u8be5\u7ebf\u8def\u7684\u53c2\u6570\u91cf\u4e3a\uff1a3x3x192x128 = 221184 (b)\u56fe\u4e2d\u52a0\u51651x1\u5377\u79ef\u540e\u901a\u9053\u4e3a96\uff0c\u518d\u9001\u51653x3\u5377\u79ef\u4e2d\u7684\u53c2\u6570\u91cf\u4e3a\uff1a(1x1x192x96)+(3x3x96x128)=129024. \u5bf9\u6bd4\u53ef\u77e5\uff0c\u52a0\u51651x1\u5377\u79ef\u540e\u53c2\u6570\u91cf\u51cf\u5c11\u4e86\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0Inception\u6a21\u5757\uff0c\u5404\u4e2a\u5377\u79ef\u5c42\u5377\u79ef\u6838\u7684\u4e2a\u6570\u901a\u8fc7\u8f93\u5165\u53c2\u6570\u6765\u63a7\u5236\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5b9a\u4e49Inception\u6a21\u5757 class Inception ( tf . keras . layers . Layer ): # \u8f93\u5165\u53c2\u6570\u4e3a\u5404\u4e2a\u5377\u79ef\u7684\u5377\u79ef\u6838\u4e2a\u6570 def __init__ ( self , c1 , c2 , c3 , c4 ): super () . __init__ () # \u7ebf\u8def1\uff1a1 x 1\u5377\u79ef\u5c42\uff0c\u6fc0\u6d3b\u51fd\u6570\u662fRELU\uff0cpadding\u662fsame self . p1_1 = tf . keras . layers . Conv2D ( c1 , kernel_size = 1 , activation = 'relu' , padding = 'same' ) # \u7ebf\u8def2\uff0c1 x 1\u5377\u79ef\u5c42\u540e\u63a53 x 3\u5377\u79ef\u5c42,\u6fc0\u6d3b\u51fd\u6570\u662fRELU\uff0cpadding\u662fsame self . p2_1 = tf . keras . layers . Conv2D ( c2 [ 0 ], kernel_size = 1 , padding = 'same' , activation = 'relu' ) self . p2_2 = tf . keras . layers . Conv2D ( c2 [ 1 ], kernel_size = 3 , padding = 'same' , activation = 'relu' ) # \u7ebf\u8def3\uff0c1 x 1\u5377\u79ef\u5c42\u540e\u63a55 x 5\u5377\u79ef\u5c42,\u6fc0\u6d3b\u51fd\u6570\u662fRELU\uff0cpadding\u662fsame self . p3_1 = tf . keras . layers . Conv2D ( c3 [ 0 ], kernel_size = 1 , padding = 'same' , activation = 'relu' ) self . p3_2 = tf . keras . layers . Conv2D ( c3 [ 1 ], kernel_size = 5 , padding = 'same' , activation = 'relu' ) # \u7ebf\u8def4\uff0c3 x 3\u6700\u5927\u6c60\u5316\u5c42\u540e\u63a51 x 1\u5377\u79ef\u5c42,\u6fc0\u6d3b\u51fd\u6570\u662fRELU\uff0cpadding\u662fsame self . p4_1 = tf . keras . layers . MaxPool2D ( pool_size = 3 , padding = 'same' , strides = 1 ) self . p4_2 = tf . keras . layers . Conv2D ( c4 , kernel_size = 1 , padding = 'same' , activation = 'relu' ) # \u5b8c\u6210\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b def call ( self , x ): # \u7ebf\u8def1 p1 = self . p1_1 ( x ) # \u7ebf\u8def2 p2 = self . p2_2 ( self . p2_1 ( x )) # \u7ebf\u8def3 p3 = self . p3_2 ( self . p3_1 ( x )) # \u7ebf\u8def4 p4 = self . p4_2 ( self . p4_1 ( x )) # \u5728\u901a\u9053\u7ef4\u4e0aconcat\u8f93\u51fa outputs = tf . concat ([ p1 , p2 , p3 , p4 ], axis =- 1 ) return outputs \u6307\u5b9a\u901a\u9053\u6570\uff0c\u5bf9Inception\u6a21\u5757\u8fdb\u884c\u5b9e\u4f8b\u5316\uff1a Inception ( 64 , ( 96 , 128 ), ( 16 , 32 ), 32 )","title":"1.Inception \u5757"},{"location":"imageClassification/section4/#2googlenet","text":"GoogLeNet\u4e3b\u8981\u7531Inception\u6a21\u5757\u6784\u6210\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6574\u4e2a\u7f51\u7edc\u67b6\u6784\u6211\u4eec\u5206\u4e3a\u4e94\u4e2a\u6a21\u5757\uff0c\u6bcf\u4e2a\u6a21\u5757\u4e4b\u95f4\u4f7f\u7528\u6b65\u5e45\u4e3a2\u7684 3\\times 3 3\\times 3 \u6700\u5927\u6c60\u5316\u5c42\u6765\u51cf\u5c0f\u8f93\u51fa\u9ad8\u5bbd\u3002 \u3010\u6269\u5c55\ud83d\udcda\uff1agoogLeNet\u7684\u7f51\u7edc\u8bbe\u8ba1\u3011","title":"2.GoogLeNet\u6a21\u578b"},{"location":"imageClassification/section4/#21-b1","text":"\u7b2c\u4e00\u6a21\u5757\u4f7f\u7528\u4e00\u4e2a64\u901a\u9053\u7684 7\\times 7 7\\times 7 \u5377\u79ef\u5c42\u3002 # \u5b9a\u4e49\u6a21\u578b\u7684\u8f93\u5165 inputs = tf . keras . Input ( shape = ( 224 , 224 , 3 ), name = \"input\" ) # b1 \u6a21\u5757 # \u5377\u79ef\u5c427*7\u7684\u5377\u79ef\u6838\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame\uff0c\u6fc0\u6d3b\u51fd\u6570RELU x = tf . keras . layers . Conv2D ( 64 , kernel_size = 7 , strides = 2 , padding = 'same' , activation = 'relu' )( inputs ) # \u6700\u5927\u6c60\u5316\uff1a\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame x = tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' )( x ) # b2 \u6a21\u5757","title":"2.1 B1\u6a21\u5757"},{"location":"imageClassification/section4/#22-b2","text":"\u7b2c\u4e8c\u6a21\u5757\u4f7f\u75282\u4e2a\u5377\u79ef\u5c42\uff1a\u9996\u5148\u662f64\u901a\u9053\u7684 1\\times 1 1\\times 1 \u5377\u79ef\u5c42\uff0c\u7136\u540e\u662f\u5c06\u901a\u9053\u589e\u59273\u500d\u7684 3\\times 3 3\\times 3 \u5377\u79ef\u5c42\u3002 # b2 \u6a21\u5757 # \u5377\u79ef\u5c421*1\u7684\u5377\u79ef\u6838\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame\uff0c\u6fc0\u6d3b\u51fd\u6570RELU x = tf . keras . layers . Conv2D ( 64 , kernel_size = 1 , padding = 'same' , activation = 'relu' )( x ) # \u5377\u79ef\u5c423*3\u7684\u5377\u79ef\u6838\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame\uff0c\u6fc0\u6d3b\u51fd\u6570RELU x = tf . keras . layers . Conv2D ( 192 , kernel_size = 3 , padding = 'same' , activation = 'relu' )( x ) # \u6700\u5927\u6c60\u5316\uff1a\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame x = tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' )( x )","title":"2.2 B2\u6a21\u5757"},{"location":"imageClassification/section4/#23-b3","text":"\u7b2c\u4e09\u6a21\u5757\u4e32\u80542\u4e2a\u5b8c\u6574\u7684Inception\u5757\u3002\u7b2c\u4e00\u4e2aInception\u5757\u7684\u8f93\u51fa\u901a\u9053\u6570\u4e3a 64+128+32+32=256 64+128+32+32=256 \u3002\u7b2c\u4e8c\u4e2aInception\u5757\u8f93\u51fa\u901a\u9053\u6570\u589e\u81f3 128+192+96+64=480 128+192+96+64=480 \u3002 # b3 \u6a21\u5757 # Inception x = Inception ( 64 , ( 96 , 128 ), ( 16 , 32 ), 32 )( x ) # Inception x = Inception ( 128 , ( 128 , 192 ), ( 32 , 96 ), 64 )( x ) # \u6700\u5927\u6c60\u5316\uff1a\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame x = tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' )( x )","title":"2.3 B3\u6a21\u5757"},{"location":"imageClassification/section4/#24-b4","text":"\u7b2c\u56db\u6a21\u5757\u66f4\u52a0\u590d\u6742\u3002\u5b83\u4e32\u8054\u4e865\u4e2aInception\u5757\uff0c\u5176\u8f93\u51fa\u901a\u9053\u6570\u5206\u522b\u662f 192+208+48+64=512 192+208+48+64=512 \u3001 160+224+64+64=512 160+224+64+64=512 \u3001 128+256+64+64=512 128+256+64+64=512 \u3001 112+288+64+64=528 112+288+64+64=528 \u548c 256+320+128+128=832 256+320+128+128=832 \u3002\u5e76\u4e14\u589e\u52a0\u4e86\u8f85\u52a9\u5206\u7c7b\u5668\uff0c\u6839\u636e\u5b9e\u9a8c\u53d1\u73b0\u7f51\u7edc\u7684\u4e2d\u95f4\u5c42\u5177\u6709\u5f88\u5f3a\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u4e3a\u4e86\u5229\u7528\u4e2d\u95f4\u5c42\u62bd\u8c61\u7684\u7279\u5f81\uff0c\u5728\u67d0\u4e9b\u4e2d\u95f4\u5c42\u4e2d\u6dfb\u52a0\u542b\u6709\u591a\u5c42\u7684\u5206\u7c7b\u5668\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5b9e\u73b0\u5982\u4e0b\u6240\u793a\uff1a def aux_classifier ( x , filter_size ): #x:\u8f93\u5165\u6570\u636e\uff0cfilter_size:\u5377\u79ef\u5c42\u5377\u79ef\u6838\u4e2a\u6570\uff0c\u5168\u8fde\u63a5\u5c42\u795e\u7ecf\u5143\u4e2a\u6570 # \u6c60\u5316\u5c42 x = tf . keras . layers . AveragePooling2D ( pool_size = 5 , strides = 3 , padding = 'same' )( x ) # 1x1 \u5377\u79ef\u5c42 x = tf . keras . layers . Conv2D ( filters = filter_size [ 0 ], kernel_size = 1 , strides = 1 , padding = 'valid' , activation = 'relu' )( x ) # \u5c55\u5e73 x = tf . keras . layers . Flatten ()( x ) # \u5168\u8fde\u63a5\u5c421 x = tf . keras . layers . Dense ( units = filter_size [ 1 ], activation = 'relu' )( x ) # softmax\u8f93\u51fa\u5c42 x = tf . keras . layers . Dense ( units = 10 , activation = 'softmax' )( x ) return x b4\u6a21\u5757\u7684\u5b9e\u73b0\uff1a # b4 \u6a21\u5757 # Inception x = Inception ( 192 , ( 96 , 208 ), ( 16 , 48 ), 64 )( x ) # \u8f85\u52a9\u8f93\u51fa1 aux_output_1 = aux_classifier ( x , [ 128 , 1024 ]) # Inception x = Inception ( 160 , ( 112 , 224 ), ( 24 , 64 ), 64 )( x ) # Inception x = Inception ( 128 , ( 128 , 256 ), ( 24 , 64 ), 64 )( x ) # Inception x = Inception ( 112 , ( 144 , 288 ), ( 32 , 64 ), 64 )( x ) # \u8f85\u52a9\u8f93\u51fa2 aux_output_2 = aux_classifier ( x , [ 128 , 1024 ]) # Inception x = Inception ( 256 , ( 160 , 320 ), ( 32 , 128 ), 128 )( x ) # \u6700\u5927\u6c60\u5316 x = tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' )( x )","title":"2.4 B4\u6a21\u5757"},{"location":"imageClassification/section4/#25-b5","text":"\u7b2c\u4e94\u6a21\u5757\u6709\u8f93\u51fa\u901a\u9053\u6570\u4e3a 256+320+128+128=832 256+320+128+128=832 \u548c 384+384+128+128=1024 384+384+128+128=1024 \u7684\u4e24\u4e2aInception\u5757\u3002\u540e\u9762\u7d27\u8ddf\u8f93\u51fa\u5c42\uff0c\u8be5\u6a21\u5757\u4f7f\u7528\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\uff08GAP\uff09\u6765\u5c06\u6bcf\u4e2a\u901a\u9053\u7684\u9ad8\u548c\u5bbd\u53d8\u62101\u3002\u6700\u540e\u8f93\u51fa\u53d8\u6210\u4e8c\u7ef4\u6570\u7ec4\u540e\u63a5\u8f93\u51fa\u4e2a\u6570\u4e3a\u6807\u7b7e\u7c7b\u522b\u6570\u7684\u5168\u8fde\u63a5\u5c42\u3002 \u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\uff08GAP\uff09 \u7528\u6765\u66ff\u4ee3\u5168\u8fde\u63a5\u5c42\u524d\u7684Flatten\uff0c\u5c06\u7279\u5f81\u56fe\u6bcf\u4e00\u901a\u9053\u4e2d\u6240\u6709\u50cf\u7d20\u503c\u76f8\u52a0\u540e\u6c42\u5e73\u5747\uff0c\u5f97\u5230\u5c31\u662fGAP\u7684\u7ed3\u679c\uff0c\u5728\u5c06\u5176\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u8ba1\u7b97 \u5b9e\u73b0\u8fc7\u7a0b\u662f\uff1a # b5 \u6a21\u5757 # Inception x = Inception ( 256 , ( 160 , 320 ), ( 32 , 128 ), 128 )( x ) # Inception x = Inception ( 384 , ( 192 , 384 ), ( 48 , 128 ), 128 )( x ) # GAP x = tf . keras . layers . GlobalAvgPool2D ()( x ) # \u8f93\u51fa\u5c42 main_outputs = tf . keras . layers . Dense ( 10 , activation = 'softmax' )( x ) # \u4f7f\u7528Model\u6765\u521b\u5efa\u6a21\u578b\uff0c\u6307\u660e\u8f93\u5165\u548c\u8f93\u51fa \u6784\u5efaGoogLeNet\u6a21\u578b\u5e76\u901a\u8fc7summary\u6765\u770b\u4e0b\u6a21\u578b\u7684\u7ed3\u6784\uff1a # \u4f7f\u7528Model\u6765\u521b\u5efa\u6a21\u578b\uff0c\u6307\u660e\u8f93\u5165\u548c\u8f93\u51fa model = tf . keras . Model ( inputs = inputs , outputs = [ main_outputs , aux_output_1 \uff0c aux_output_2 ]) model . summary () Model : \"functional_3\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= input ( InputLayer ) [( None , 224 , 224 , 3 )] 0 _________________________________________________________________ conv2d_122 ( Conv2D ) ( None , 112 , 112 , 64 ) 9472 _________________________________________________________________ max_pooling2d_27 ( MaxPooling ( None , 56 , 56 , 64 ) 0 _________________________________________________________________ conv2d_123 ( Conv2D ) ( None , 56 , 56 , 64 ) 4160 _________________________________________________________________ conv2d_124 ( Conv2D ) ( None , 56 , 56 , 192 ) 110784 _________________________________________________________________ max_pooling2d_28 ( MaxPooling ( None , 28 , 28 , 192 ) 0 _________________________________________________________________ inception_19 ( Inception ) ( None , 28 , 28 , 256 ) 163696 _________________________________________________________________ inception_20 ( Inception ) ( None , 28 , 28 , 480 ) 388736 _________________________________________________________________ max_pooling2d_31 ( MaxPooling ( None , 14 , 14 , 480 ) 0 _________________________________________________________________ inception_21 ( Inception ) ( None , 14 , 14 , 512 ) 376176 _________________________________________________________________ inception_22 ( Inception ) ( None , 14 , 14 , 512 ) 449160 _________________________________________________________________ inception_23 ( Inception ) ( None , 14 , 14 , 512 ) 510104 _________________________________________________________________ inception_24 ( Inception ) ( None , 14 , 14 , 528 ) 605376 _________________________________________________________________ inception_25 ( Inception ) ( None , 14 , 14 , 832 ) 868352 _________________________________________________________________ max_pooling2d_37 ( MaxPooling ( None , 7 , 7 , 832 ) 0 _________________________________________________________________ inception_26 ( Inception ) ( None , 7 , 7 , 832 ) 1043456 _________________________________________________________________ inception_27 ( Inception ) ( None , 7 , 7 , 1024 ) 1444080 _________________________________________________________________ global_average_pooling2d_2 ( ( None , 1024 ) 0 _________________________________________________________________ dense_10 ( Dense ) ( None , 10 ) 10250 ================================================================= Total params : 5 , 983 , 802 Trainable params : 5 , 983 , 802 Non - trainable params : 0 ___________________________________________________________","title":"2.5 B5\u6a21\u5757"},{"location":"imageClassification/section4/#3","text":"\u56e0\u4e3aImageNet\u6570\u636e\u96c6\u8f83\u5927\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u4ecd\u7528\u524d\u9762\u7684MNIST\u6570\u636e\u96c6\u6765\u6f14\u793aGoogLeNet\u3002\u8bfb\u53d6\u6570\u636e\u7684\u65f6\u5c06\u56fe\u50cf\u9ad8\u548c\u5bbd\u6269\u5927\u5230\u56fe\u50cf\u9ad8\u548c\u5bbd224\u3002\u8fd9\u4e2a\u901a\u8fc7 tf.image.resize_with_pad \u6765\u5b9e\u73b0\u3002","title":"3.\u624b\u5199\u6570\u5b57\u8bc6\u522b"},{"location":"imageClassification/section4/#21","text":"\u9996\u5148\u83b7\u53d6\u6570\u636e,\u5e76\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff1a import numpy as np # \u83b7\u53d6\u624b\u5199\u6570\u5b57\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # \u8bad\u7ec3\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C train_images = np . reshape ( train_images ,( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) # \u6d4b\u8bd5\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C test_images = np . reshape ( test_images ,( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7531\u4e8e\u4f7f\u7528\u5168\u90e8\u6570\u636e\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u83b7\u53d6\u90e8\u5206\u6570\u636e\uff0c\u5e76\u5c06\u56fe\u50cf\u8c03\u6574\u4e3a224*224\u5927\u5c0f\uff0c\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a(\u4e0eVGG\u4e2d\u662f\u4e00\u6837\u7684) # \u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u968f\u673a\u62bd\u53d6\u90e8\u5206\u6837\u672c\u6f14\u793a # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e def get_train ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( train_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u621022*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( train_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u53d6\u7684 return resized_images . numpy (), train_labels [ index ] # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e def get_test ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( test_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210224*224\u5927\u5c0f resized_images = tf . image . resize_with_pad ( test_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u6837\u7684\u6d4b\u8bd5\u6837\u672c return resized_images . numpy (), test_labels [ index ] \u8c03\u7528\u4e0a\u8ff0\u4e24\u4e2a\u65b9\u6cd5\uff0c\u83b7\u53d6\u53c2\u4e0e\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\uff1a # \u83b7\u53d6\u8bad\u7ec3\u6837\u672c\u548c\u6d4b\u8bd5\u6837\u672c train_images , train_labels = get_train ( 256 ) test_images , test_labels = get_test ( 128 )","title":"2.1 \u6570\u636e\u8bfb\u53d6"},{"location":"imageClassification/section4/#32","text":"# \u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 ) # \u6a21\u578b\u67093\u4e2a\u8f93\u51fa\uff0c\u6240\u4ee5\u6307\u5b9a\u635f\u5931\u51fd\u6570\u5bf9\u5e94\u7684\u6743\u91cd\u7cfb\u6570 net . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ], loss_weights = [ 1 , 0.3 , 0.3 ])","title":"3.2 \u6a21\u578b\u7f16\u8bd1"},{"location":"imageClassification/section4/#33","text":"# \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u8bad\u7ec3\u6570\u636e\uff0cbatchsize,epoch,\u9a8c\u8bc1\u96c6 net . fit ( train_images , train_labels , batch_size = 128 , epochs = 3 , verbose = 1 , validation_split = 0.1 ) \u8bad\u7ec3\u8fc7\u7a0b\uff1a Epoch 1 / 3 2 / 2 [ ============================== ] - 8 s 4 s / step - loss : 2.9527 - accuracy : 0.1174 - val_loss : 3.3254 - val_accuracy : 0.1154 Epoch 2 / 3 2 / 2 [ ============================== ] - 7 s 4 s / step - loss : 2.8111 - accuracy : 0.0957 - val_loss : 2.2718 - val_accuracy : 0.2308 Epoch 3 / 3 2 / 2 [ ============================== ] - 7 s 4 s / step - loss : 2.3055 - accuracy : 0.0957 - val_loss : 2.2669 - val_accuracy : 0.2308","title":"3.3 \u6a21\u578b\u8bad\u7ec3"},{"location":"imageClassification/section4/#24","text":"# \u6307\u5b9a\u6d4b\u8bd5\u6570\u636e net . evaluate ( test_images , test_labels , verbose = 1 ) \u8f93\u51fa\u4e3a\uff1a 4 / 4 [ ============================== ] - 1 s 338 ms / step - loss : 2.3110 - accuracy : 0.0781 [ 2.310971260070801 , 0.078125 ]","title":"2.4 \u6a21\u578b\u8bc4\u4f30"},{"location":"imageClassification/section4/#4","text":"GoogLeNet\u662f\u4ee5InceptionV1\u4e3a\u57fa\u7840\u8fdb\u884c\u6784\u5efa\u7684\uff0c\u6240\u4ee5GoogLeNet\u4e5f\u53eb\u505aInceptionNet,\u5728\u968f\u540e\u7684\u2f0f\u5e74\u2fa5\uff0c\u7814\u7a76\u2f08\u5458\u5bf9GoogLeNet\u8fdb\u2f8f\u4e86\u6570\u6b21\u6539\u8fdb\uff0c \u5c31\u53c8\u4ea7\u751f\u4e86InceptionV2\uff0cV3,V4\u7b49\u7248\u672c\u3002","title":"4.\u5ef6\u4f38\u7248\u672c"},{"location":"imageClassification/section4/#41-inceptionv2","text":"\u5728InceptionV2\u4e2d\u5c06\u5927\u5377\u79ef\u6838\u62c6\u5206\u4e3a\u5c0f\u5377\u79ef\u6838\uff0c\u5c06V1\u4e2d\u7684 5\\times 5 5\\times 5 \u7684\u5377\u79ef\u7528\u4e24\u4e2a 3\\times 3 3\\times 3 \u7684\u5377\u79ef\u66ff\u4ee3\uff0c\u4ece\u800c\u589e\u52a0\u7f51\u7edc\u7684\u6df1\u5ea6\uff0c\u51cf\u5c11\u4e86\u53c2\u6570\u3002","title":"4.1 InceptionV2"},{"location":"imageClassification/section4/#42-inceptionv3","text":"\u5c06n\u00d7n\u5377\u79ef\u5206\u5272\u4e3a1\u00d7n\u548cn\u00d71\u4e24\u4e2a\u5377\u79ef\uff0c\u4f8b\u5982\uff0c\u4e00\u4e2a\u7684 3\\times3 3\\times3 \u5377\u79ef\u9996\u5148\u6267\u884c\u4e00\u4e2a 1\\times3 1\\times3 \u7684\u5377\u79ef\uff0c\u7136\u540e\u6267\u884c\u4e00\u4e2a 3\\times1 3\\times1 \u7684\u5377\u79ef,\u8fd9\u79cd\u65b9\u6cd5\u7684\u53c2\u6570\u91cf\u548c\u8ba1\u7b97\u91cf\u90fd\u6bd4\u539f\u6765\u964d\u4f4e\u3002 \u603b\u7ed3 \u77e5\u9053GoogLeNet\u7684\u7f51\u7edc\u67b6\u6784\uff1a\u6709\u57fa\u7840\u6a21\u5757Inception\u6784\u6210 \u80fd\u591f\u5229\u7528GoogleNet\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b","title":"4.2 InceptionV3"},{"location":"imageClassification/section5/","text":"2.5 ResNet \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053ResNet\u7f51\u7edc\u7ed3\u6784\u7684\u7279\u70b9 \u80fd\u591f\u5229\u7528ResNet\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b \u7f51\u7edc\u8d8a\u6df1\uff0c\u83b7\u53d6\u7684\u4fe1\u606f\u5c31\u8d8a\u591a\uff0c\u7279\u5f81\u4e5f\u8d8a\u4e30\u5bcc\u3002\u4f46\u662f\u5728\u5b9e\u8df5\u4e2d\uff0c\u968f\u7740\u7f51\u7edc\u7684\u52a0\u6df1\uff0c\u4f18\u5316\u6548\u679c\u53cd\u800c\u8d8a\u5dee\uff0c\u6d4b\u8bd5\u6570\u636e\u548c\u8bad\u7ec3\u6570\u636e\u7684\u51c6\u786e\u7387\u53cd\u800c\u964d\u4f4e\u4e86\u3002 \u9488\u5bf9\u8fd9\u4e00\u95ee\u9898\uff0c\u4f55\u607a\u660e\u7b49\u4eba\u63d0\u51fa\u4e86\u6b8b\u5dee\u7f51\u7edc\uff08ResNet\uff09\u57282015\u5e74\u7684ImageNet\u56fe\u50cf\u8bc6\u522b\u6311\u6218\u8d5b\u593a\u9b41\uff0c\u5e76\u6df1\u523b\u5f71\u54cd\u4e86\u540e\u6765\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u8bbe\u8ba1\u3002 1 \u6b8b\u5dee\u5757 \u00b6 \u5047\u8bbe F(x) \u4ee3\u8868\u67d0\u4e2a\u53ea\u5305\u542b\u6709\u4e24\u5c42\u7684\u6620\u5c04\u51fd\u6570\uff0c x \u662f\u8f93\u5165\uff0c F(x)\u662f\u8f93\u51fa\u3002\u5047\u8bbe\u4ed6\u4eec\u5177\u6709\u76f8\u540c\u7684\u7ef4\u5ea6\u3002\u5728\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u6211\u4eec\u5e0c\u671b\u80fd\u591f\u901a\u8fc7\u4fee\u6539\u7f51\u7edc\u4e2d\u7684 w\u548cb\u53bb\u62df\u5408\u4e00\u4e2a\u7406\u60f3\u7684 H(x)(\u4ece\u8f93\u5165\u5230\u8f93\u51fa\u7684\u4e00\u4e2a\u7406\u60f3\u7684\u6620\u5c04\u51fd\u6570)\u3002\u4e5f\u5c31\u662f\u6211\u4eec\u7684\u76ee\u6807\u662f\u4fee\u6539F(x) \u4e2d\u7684 w\u548cb\u903c\u8fd1 H(x) \u3002\u5982\u679c\u6211\u4eec\u6539\u53d8\u601d\u8def\uff0c\u7528F(x) \u6765\u903c\u8fd1 H(x)-x \uff0c\u90a3\u4e48\u6211\u4eec\u6700\u7ec8\u5f97\u5230\u7684\u8f93\u51fa\u5c31\u53d8\u4e3a F(x)+x\uff08\u8fd9\u91cc\u7684\u52a0\u6307\u7684\u662f\u5bf9\u5e94\u4f4d\u7f6e\u4e0a\u7684\u5143\u7d20\u76f8\u52a0\uff0c\u4e5f\u5c31\u662felement-wise addition\uff09\uff0c\u8fd9\u91cc\u5c06\u76f4\u63a5\u4ece\u8f93\u5165\u8fde\u63a5\u5230\u8f93\u51fa\u7684\u7ed3\u6784\u4e5f\u79f0\u4e3ashortcut\uff0c\u90a3\u6574\u4e2a\u7ed3\u6784\u5c31\u662f\u6b8b\u5dee\u5757\uff0cResNet\u7684\u57fa\u7840\u6a21\u5757\u3002 ResNet\u6cbf\u7528\u4e86VGG\u5168 3\\times 3 3\\times 3 \u5377\u79ef\u5c42\u7684\u8bbe\u8ba1\u3002\u6b8b\u5dee\u5757\u91cc\u9996\u5148\u67092\u4e2a\u6709\u76f8\u540c\u8f93\u51fa\u901a\u9053\u6570\u7684 3\\times 3 3\\times 3 \u5377\u79ef\u5c42\u3002\u6bcf\u4e2a\u5377\u79ef\u5c42\u540e\u63a5BN\u5c42\u548cReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u7136\u540e\u5c06\u8f93\u5165\u76f4\u63a5\u52a0\u5728\u6700\u540e\u7684ReLU\u6fc0\u6d3b\u51fd\u6570\u524d\uff0c\u8fd9\u79cd\u7ed3\u6784\u7528\u4e8e\u5c42\u6570\u8f83\u5c11\u7684\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u6bd4\u5982ResNet34\u3002\u82e5\u8f93\u5165\u901a\u9053\u6570\u6bd4\u8f83\u591a\uff0c\u5c31\u9700\u8981\u5f15\u5165 1\\times 1 1\\times 1 \u5377\u79ef\u5c42\u6765\u8c03\u6574\u8f93\u5165\u7684\u901a\u9053\u6570\uff0c\u8fd9\u79cd\u7ed3\u6784\u4e5f\u53eb\u4f5c\u74f6\u9888\u6a21\u5757\uff0c\u901a\u5e38\u7528\u4e8e\u7f51\u7edc\u5c42\u6570\u8f83\u591a\u7684\u7ed3\u6784\u4e2d\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4e0a\u56fe\u5de6\u4e2d\u7684\u6b8b\u5dee\u5757\u7684\u5b9e\u73b0\u5982\u4e0b\uff0c\u53ef\u4ee5\u8bbe\u5b9a\u8f93\u51fa\u901a\u9053\u6570\uff0c\u662f\u5426\u4f7f\u75281*1\u7684\u5377\u79ef\u53ca\u5377\u79ef\u5c42\u7684\u6b65\u5e45\u3002 # \u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305 import tensorflow as tf from tensorflow.keras import layers , activations # \u5b9a\u4e49ResNet\u7684\u6b8b\u5dee\u5757 class Residual ( tf . keras . Model ): # \u6307\u660e\u6b8b\u5dee\u5757\u7684\u901a\u9053\u6570\uff0c\u662f\u5426\u4f7f\u75281*1\u5377\u79ef\uff0c\u6b65\u957f def __init__ ( self , num_channels , use_1x1conv = False , strides = 1 ): super ( Residual , self ) . __init__ () # \u5377\u79ef\u5c42\uff1a\u6307\u660e\u5377\u79ef\u6838\u4e2a\u6570\uff0cpadding,\u5377\u79ef\u6838\u5927\u5c0f\uff0c\u6b65\u957f self . conv1 = layers . Conv2D ( num_channels , padding = 'same' , kernel_size = 3 , strides = strides ) # \u5377\u79ef\u5c42\uff1a\u6307\u660e\u5377\u79ef\u6838\u4e2a\u6570\uff0cpadding,\u5377\u79ef\u6838\u5927\u5c0f\uff0c\u6b65\u957f self . conv2 = layers . Conv2D ( num_channels , kernel_size = 3 , padding = 'same' ) if use_1x1conv : self . conv3 = layers . Conv2D ( num_channels , kernel_size = 1 , strides = strides ) else : self . conv3 = None # \u6307\u660eBN\u5c42 self . bn1 = layers . BatchNormalization () self . bn2 = layers . BatchNormalization () # \u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b def call ( self , X ): # \u5377\u79ef\uff0cBN\uff0c\u6fc0\u6d3b Y = activations . relu ( self . bn1 ( self . conv1 ( X ))) # \u5377\u79ef\uff0cBN Y = self . bn2 ( self . conv2 ( Y )) # \u5bf9\u8f93\u5165\u6570\u636e\u8fdb\u884c1*1\u5377\u79ef\u4fdd\u8bc1\u901a\u9053\u6570\u76f8\u540c if self . conv3 : X = self . conv3 ( X ) # \u8fd4\u56de\u4e0e\u8f93\u5165\u76f8\u52a0\u540e\u6fc0\u6d3b\u7684\u7ed3\u679c return activations . relu ( Y + X ) 1*1\u5377\u79ef\u7528\u6765\u8c03\u6574\u901a\u9053\u6570\u3002 2 ResNet\u6a21\u578b \u00b6 ResNet\u6a21\u578b\u7684\u6784\u6210\u5982\u4e0b\u56fe\u6240\u793a\uff1a ResNet\u7f51\u7edc\u4e2d\u6309\u7167\u6b8b\u5dee\u5757\u7684\u901a\u9053\u6570\u5206\u4e3a\u4e0d\u540c\u7684\u6a21\u5757\u3002\u7b2c\u4e00\u4e2a\u6a21\u5757\u524d\u4f7f\u7528\u4e86\u6b65\u5e45\u4e3a2\u7684\u6700\u5927\u6c60\u5316\u5c42\uff0c\u6240\u4ee5\u65e0\u987b\u51cf\u5c0f\u9ad8\u548c\u5bbd\u3002\u4e4b\u540e\u7684\u6bcf\u4e2a\u6a21\u5757\u5728\u7b2c\u4e00\u4e2a\u6b8b\u5dee\u5757\u91cc\u5c06\u4e0a\u4e00\u4e2a\u6a21\u5757\u7684\u901a\u9053\u6570\u7ffb\u500d\uff0c\u5e76\u5c06\u9ad8\u548c\u5bbd\u51cf\u534a\u3002 \u4e0b\u9762\u6211\u4eec\u6765\u5b9e\u73b0\u8fd9\u4e9b\u6a21\u5757\u3002\u6ce8\u610f\uff0c\u8fd9\u91cc\u5bf9\u7b2c\u4e00\u4e2a\u6a21\u5757\u505a\u4e86\u7279\u522b\u5904\u7406\u3002 # ResNet\u7f51\u7edc\u4e2d\u6a21\u5757\u7684\u6784\u6210 class ResnetBlock ( tf . keras . layers . Layer ): # \u7f51\u7edc\u5c42\u7684\u5b9a\u4e49\uff1a\u8f93\u51fa\u901a\u9053\u6570\uff08\u5377\u79ef\u6838\u4e2a\u6570\uff09\uff0c\u6a21\u5757\u4e2d\u5305\u542b\u7684\u6b8b\u5dee\u5757\u4e2a\u6570\uff0c\u662f\u5426\u4e3a\u7b2c\u4e00\u4e2a\u6a21\u5757 def __init__ ( self , num_channels , num_residuals , first_block = False ): super ( ResnetBlock , self ) . __init__ () # \u6a21\u5757\u4e2d\u7684\u7f51\u7edc\u5c42 self . listLayers = [] # \u904d\u5386\u6a21\u5757\u4e2d\u6240\u6709\u7684\u5c42 for i in range ( num_residuals ): # \u82e5\u4e3a\u7b2c\u4e00\u4e2a\u6b8b\u5dee\u5757\u5e76\u4e14\u4e0d\u662f\u7b2c\u4e00\u4e2a\u6a21\u5757\uff0c\u5219\u4f7f\u75281*1\u5377\u79ef\uff0c\u6b65\u957f\u4e3a2\uff08\u76ee\u7684\u662f\u51cf\u5c0f\u7279\u5f81\u56fe\uff0c\u5e76\u589e\u5927\u901a\u9053\u6570\uff09 if i == 0 and not first_block : self . listLayers . append ( Residual ( num_channels , use_1x1conv = True , strides = 2 )) # \u5426\u5219\u4e0d\u4f7f\u75281*1\u5377\u79ef\uff0c\u6b65\u957f\u4e3a1 else : self . listLayers . append ( Residual ( num_channels )) # \u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b def call ( self , X ): # \u6240\u6709\u5c42\u4f9d\u6b21\u5411\u524d\u4f20\u64ad\u5373\u53ef for layer in self . listLayers . layers : X = layer ( X ) return X ResNet\u7684\u524d\u4e24\u5c42\u8ddf\u4e4b\u524d\u4ecb\u7ecd\u7684GoogLeNet\u4e2d\u7684\u4e00\u6837\uff1a\u5728\u8f93\u51fa\u901a\u9053\u6570\u4e3a64\u3001\u6b65\u5e45\u4e3a2\u7684 7\\times 7 7\\times 7 \u5377\u79ef\u5c42\u540e\u63a5\u6b65\u5e45\u4e3a2\u7684 3\\times 3 3\\times 3 \u7684\u6700\u5927\u6c60\u5316\u5c42\u3002\u4e0d\u540c\u4e4b\u5904\u5728\u4e8eResNet\u6bcf\u4e2a\u5377\u79ef\u5c42\u540e\u589e\u52a0\u4e86BN\u5c42,\u63a5\u7740\u662f\u6240\u6709\u6b8b\u5dee\u6a21\u5757\uff0c\u6700\u540e\uff0c\u4e0eGoogLeNet\u4e00\u6837\uff0c\u52a0\u5165\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\uff08GAP\uff09\u540e\u63a5\u4e0a\u5168\u8fde\u63a5\u5c42\u8f93\u51fa\u3002 # \u6784\u5efaResNet\u7f51\u7edc class ResNet ( tf . keras . Model ): # \u521d\u59cb\u5316\uff1a\u6307\u5b9a\u6bcf\u4e2a\u6a21\u5757\u4e2d\u7684\u6b8b\u5dee\u5feb\u7684\u4e2a\u6570 def __init__ ( self , num_blocks ): super ( ResNet , self ) . __init__ () # \u8f93\u5165\u5c42\uff1a7*7\u5377\u79ef\uff0c\u6b65\u957f\u4e3a2 self . conv = layers . Conv2D ( 64 , kernel_size = 7 , strides = 2 , padding = 'same' ) # BN\u5c42 self . bn = layers . BatchNormalization () # \u6fc0\u6d3b\u5c42 self . relu = layers . Activation ( 'relu' ) # \u6700\u5927\u6c60\u5316\u5c42 self . mp = layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' ) # \u7b2c\u4e00\u4e2ablock\uff0c\u901a\u9053\u6570\u4e3a64 self . resnet_block1 = ResnetBlock ( 64 , num_blocks [ 0 ], first_block = True ) # \u7b2c\u4e8c\u4e2ablock\uff0c\u901a\u9053\u6570\u4e3a128 self . resnet_block2 = ResnetBlock ( 128 , num_blocks [ 1 ]) # \u7b2c\u4e09\u4e2ablock\uff0c\u901a\u9053\u6570\u4e3a256 self . resnet_block3 = ResnetBlock ( 256 , num_blocks [ 2 ]) # \u7b2c\u56db\u4e2ablock\uff0c\u901a\u9053\u6570\u4e3a512 self . resnet_block4 = ResnetBlock ( 512 , num_blocks [ 3 ]) # \u5168\u5c40\u5e73\u5747\u6c60\u5316 self . gap = layers . GlobalAvgPool2D () # \u5168\u8fde\u63a5\u5c42\uff1a\u5206\u7c7b self . fc = layers . Dense ( units = 10 , activation = tf . keras . activations . softmax ) # \u524d\u5411\u4f20\u64ad\u8fc7\u7a0b def call ( self , x ): # \u5377\u79ef x = self . conv ( x ) # BN x = self . bn ( x ) # \u6fc0\u6d3b x = self . relu ( x ) # \u6700\u5927\u6c60\u5316 x = self . mp ( x ) # \u6b8b\u5dee\u6a21\u5757 x = self . resnet_block1 ( x ) x = self . resnet_block2 ( x ) x = self . resnet_block3 ( x ) x = self . resnet_block4 ( x ) # \u5168\u5c40\u5e73\u5747\u6c60\u5316 x = self . gap ( x ) # \u5168\u94fe\u63a5\u5c42 x = self . fc ( x ) return x # \u6a21\u578b\u5b9e\u4f8b\u5316\uff1a\u6307\u5b9a\u6bcf\u4e2ablock\u4e2d\u7684\u6b8b\u5dee\u5757\u4e2a\u6570 mynet = ResNet ([ 2 , 2 , 2 , 2 ]) \u8fd9\u91cc\u6bcf\u4e2a\u6a21\u5757\u91cc\u67094\u4e2a\u5377\u79ef\u5c42\uff08\u4e0d\u8ba1\u7b97 1\u00d71\u5377\u79ef\u5c42\uff09\uff0c\u52a0\u4e0a\u6700\u5f00\u59cb\u7684\u5377\u79ef\u5c42\u548c\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u5171\u8ba118\u5c42\u3002\u8fd9\u4e2a\u6a21\u578b\u88ab\u79f0\u4e3aResNet-18\u3002\u901a\u8fc7\u914d\u7f6e\u4e0d\u540c\u7684\u901a\u9053\u6570\u548c\u6a21\u5757\u91cc\u7684\u6b8b\u5dee\u5757\u6570\u53ef\u4ee5\u5f97\u5230\u4e0d\u540c\u7684ResNet\u6a21\u578b\uff0c\u4f8b\u5982\u66f4\u6df1\u7684\u542b152\u5c42\u7684ResNet-152\u3002\u867d\u7136ResNet\u7684\u4e3b\u4f53\u67b6\u6784\u8ddfGoogLeNet\u7684\u7c7b\u4f3c\uff0c\u4f46ResNet\u7ed3\u6784\u66f4\u7b80\u5355\uff0c\u4fee\u6539\u4e5f\u66f4\u65b9\u4fbf\u3002\u8fd9\u4e9b\u56e0\u7d20\u90fd\u5bfc\u81f4\u4e86ResNet\u8fc5\u901f\u88ab\u5e7f\u6cdb\u4f7f\u7528\u3002 \u5728\u8bad\u7ec3ResNet\u4e4b\u524d\uff0c\u6211\u4eec\u6765\u89c2\u5bdf\u4e00\u4e0b\u8f93\u5165\u5f62\u72b6\u5728ResNe\u7684\u67b6\u6784\uff1a X = tf . random . uniform ( shape = ( 1 , 224 , 224 , 1 )) y = mynet ( X ) mynet . summary () Model : \"res_net\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= conv2d_2 ( Conv2D ) multiple 3200 _________________________________________________________________ batch_normalization_2 ( Batch multiple 256 _________________________________________________________________ activation ( Activation ) multiple 0 _________________________________________________________________ max_pooling2d ( MaxPooling2D ) multiple 0 _________________________________________________________________ resnet_block ( ResnetBlock ) multiple 148736 _________________________________________________________________ resnet_block_1 ( ResnetBlock ) multiple 526976 _________________________________________________________________ resnet_block_2 ( ResnetBlock ) multiple 2102528 _________________________________________________________________ resnet_block_3 ( ResnetBlock ) multiple 8399360 _________________________________________________________________ global_average_pooling2d ( Gl multiple 0 _________________________________________________________________ dense ( Dense ) multiple 5130 ================================================================= Total params : 11 , 186 , 186 Trainable params : 11 , 178 , 378 Non - trainable params : 7 , 808 _________________________________________________________________ 2.\u624b\u5199\u6570\u5b57\u52bf\u8bc6\u522b \u00b6 \u56e0\u4e3aImageNet\u6570\u636e\u96c6\u8f83\u5927\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u4ecd\u7528\u524d\u9762\u7684MNIST\u6570\u636e\u96c6\u6765\u6f14\u793aresNet\u3002\u8bfb\u53d6\u6570\u636e\u7684\u65f6\u5c06\u56fe\u50cf\u9ad8\u548c\u5bbd\u6269\u5927\u5230ResNet\u4f7f\u7528\u7684\u56fe\u50cf\u9ad8\u548c\u5bbd224\u3002\u8fd9\u4e2a\u901a\u8fc7 tf.image.resize_with_pad \u6765\u5b9e\u73b0\u3002 2.1 \u6570\u636e\u8bfb\u53d6 \u00b6 \u9996\u5148\u83b7\u53d6\u6570\u636e,\u5e76\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff1a import numpy as np # \u83b7\u53d6\u624b\u5199\u6570\u5b57\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # \u8bad\u7ec3\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C train_images = np . reshape ( train_images ,( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) # \u6d4b\u8bd5\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C test_images = np . reshape ( test_images ,( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7531\u4e8e\u4f7f\u7528\u5168\u90e8\u6570\u636e\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u83b7\u53d6\u90e8\u5206\u6570\u636e\uff0c\u5e76\u5c06\u56fe\u50cf\u8c03\u6574\u4e3a224*224\u5927\u5c0f\uff0c\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a # \u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u968f\u673a\u62bd\u53d6\u90e8\u5206\u6837\u672c\u6f14\u793a # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e def get_train ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( train_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u621022*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( train_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u53d6\u7684 return resized_images . numpy (), train_labels [ index ] # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e def get_test ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( test_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210224*224\u5927\u5c0f resized_images = tf . image . resize_with_pad ( test_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u6837\u7684\u6d4b\u8bd5\u6837\u672c return resized_images . numpy (), test_labels [ index ] \u8c03\u7528\u4e0a\u8ff0\u4e24\u4e2a\u65b9\u6cd5\uff0c\u83b7\u53d6\u53c2\u4e0e\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\uff1a # \u83b7\u53d6\u8bad\u7ec3\u6837\u672c\u548c\u6d4b\u8bd5\u6837\u672c train_images , train_labels = get_train ( 256 ) test_images , test_labels = get_test ( 128 ) 2.2 \u6a21\u578b\u7f16\u8bd1 \u00b6 # \u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 ) mynet . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ]) 2.3 \u6a21\u578b\u8bad\u7ec3 \u00b6 # \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u8bad\u7ec3\u6570\u636e\uff0cbatchsize,epoch,\u9a8c\u8bc1\u96c6 mynet . fit ( train_images , train_labels , batch_size = 128 , epochs = 3 , verbose = 1 , validation_split = 0.1 ) \u8bad\u7ec3\u8f93\u51fa\u4e3a\uff1a Epoch 1 / 3 2 / 2 [ ============================== ] - 10 s 5 s / step - loss : 2.7811 - accuracy : 0.1391 - val_loss : 4.7931 - val_accuracy : 0.1923 Epoch 2 / 3 2 / 2 [ ============================== ] - 8 s 4 s / step - loss : 2.2579 - accuracy : 0.2478 - val_loss : 2.9262 - val_accuracy : 0.2692 Epoch 3 / 3 2 / 2 [ ============================== ] - 15 s 7 s / step - loss : 2.0874 - accuracy : 0.2609 - val_loss : 2.5882 - val_accuracy : 0.2692 2.4 \u6a21\u578b\u8bc4\u4f30 \u00b6 # \u6307\u5b9a\u6d4b\u8bd5\u6570\u636e mynet . evaluate ( test_images , test_labels , verbose = 1 ) \u8f93\u51fa\u4e3a\uff1a 4 / 4 [ ============================== ] - 1 s 370 ms / step - loss : 3.4343 - accuracy : 0.1016 [ 3.4342570304870605 , 0.1015625 ] \u603b\u7ed3 \u77e5\u9053ResNet\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u6b8b\u5dee\u5757\u7684\u6784\u6210 \u80fd\u591f\u642d\u5efaResNet\u7f51\u7edc\u7ed3\u6784","title":"ResNet"},{"location":"imageClassification/section5/#25-resnet","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053ResNet\u7f51\u7edc\u7ed3\u6784\u7684\u7279\u70b9 \u80fd\u591f\u5229\u7528ResNet\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b \u7f51\u7edc\u8d8a\u6df1\uff0c\u83b7\u53d6\u7684\u4fe1\u606f\u5c31\u8d8a\u591a\uff0c\u7279\u5f81\u4e5f\u8d8a\u4e30\u5bcc\u3002\u4f46\u662f\u5728\u5b9e\u8df5\u4e2d\uff0c\u968f\u7740\u7f51\u7edc\u7684\u52a0\u6df1\uff0c\u4f18\u5316\u6548\u679c\u53cd\u800c\u8d8a\u5dee\uff0c\u6d4b\u8bd5\u6570\u636e\u548c\u8bad\u7ec3\u6570\u636e\u7684\u51c6\u786e\u7387\u53cd\u800c\u964d\u4f4e\u4e86\u3002 \u9488\u5bf9\u8fd9\u4e00\u95ee\u9898\uff0c\u4f55\u607a\u660e\u7b49\u4eba\u63d0\u51fa\u4e86\u6b8b\u5dee\u7f51\u7edc\uff08ResNet\uff09\u57282015\u5e74\u7684ImageNet\u56fe\u50cf\u8bc6\u522b\u6311\u6218\u8d5b\u593a\u9b41\uff0c\u5e76\u6df1\u523b\u5f71\u54cd\u4e86\u540e\u6765\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u8bbe\u8ba1\u3002","title":"2.5 ResNet"},{"location":"imageClassification/section5/#1","text":"\u5047\u8bbe F(x) \u4ee3\u8868\u67d0\u4e2a\u53ea\u5305\u542b\u6709\u4e24\u5c42\u7684\u6620\u5c04\u51fd\u6570\uff0c x \u662f\u8f93\u5165\uff0c F(x)\u662f\u8f93\u51fa\u3002\u5047\u8bbe\u4ed6\u4eec\u5177\u6709\u76f8\u540c\u7684\u7ef4\u5ea6\u3002\u5728\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u6211\u4eec\u5e0c\u671b\u80fd\u591f\u901a\u8fc7\u4fee\u6539\u7f51\u7edc\u4e2d\u7684 w\u548cb\u53bb\u62df\u5408\u4e00\u4e2a\u7406\u60f3\u7684 H(x)(\u4ece\u8f93\u5165\u5230\u8f93\u51fa\u7684\u4e00\u4e2a\u7406\u60f3\u7684\u6620\u5c04\u51fd\u6570)\u3002\u4e5f\u5c31\u662f\u6211\u4eec\u7684\u76ee\u6807\u662f\u4fee\u6539F(x) \u4e2d\u7684 w\u548cb\u903c\u8fd1 H(x) \u3002\u5982\u679c\u6211\u4eec\u6539\u53d8\u601d\u8def\uff0c\u7528F(x) \u6765\u903c\u8fd1 H(x)-x \uff0c\u90a3\u4e48\u6211\u4eec\u6700\u7ec8\u5f97\u5230\u7684\u8f93\u51fa\u5c31\u53d8\u4e3a F(x)+x\uff08\u8fd9\u91cc\u7684\u52a0\u6307\u7684\u662f\u5bf9\u5e94\u4f4d\u7f6e\u4e0a\u7684\u5143\u7d20\u76f8\u52a0\uff0c\u4e5f\u5c31\u662felement-wise addition\uff09\uff0c\u8fd9\u91cc\u5c06\u76f4\u63a5\u4ece\u8f93\u5165\u8fde\u63a5\u5230\u8f93\u51fa\u7684\u7ed3\u6784\u4e5f\u79f0\u4e3ashortcut\uff0c\u90a3\u6574\u4e2a\u7ed3\u6784\u5c31\u662f\u6b8b\u5dee\u5757\uff0cResNet\u7684\u57fa\u7840\u6a21\u5757\u3002 ResNet\u6cbf\u7528\u4e86VGG\u5168 3\\times 3 3\\times 3 \u5377\u79ef\u5c42\u7684\u8bbe\u8ba1\u3002\u6b8b\u5dee\u5757\u91cc\u9996\u5148\u67092\u4e2a\u6709\u76f8\u540c\u8f93\u51fa\u901a\u9053\u6570\u7684 3\\times 3 3\\times 3 \u5377\u79ef\u5c42\u3002\u6bcf\u4e2a\u5377\u79ef\u5c42\u540e\u63a5BN\u5c42\u548cReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u7136\u540e\u5c06\u8f93\u5165\u76f4\u63a5\u52a0\u5728\u6700\u540e\u7684ReLU\u6fc0\u6d3b\u51fd\u6570\u524d\uff0c\u8fd9\u79cd\u7ed3\u6784\u7528\u4e8e\u5c42\u6570\u8f83\u5c11\u7684\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u6bd4\u5982ResNet34\u3002\u82e5\u8f93\u5165\u901a\u9053\u6570\u6bd4\u8f83\u591a\uff0c\u5c31\u9700\u8981\u5f15\u5165 1\\times 1 1\\times 1 \u5377\u79ef\u5c42\u6765\u8c03\u6574\u8f93\u5165\u7684\u901a\u9053\u6570\uff0c\u8fd9\u79cd\u7ed3\u6784\u4e5f\u53eb\u4f5c\u74f6\u9888\u6a21\u5757\uff0c\u901a\u5e38\u7528\u4e8e\u7f51\u7edc\u5c42\u6570\u8f83\u591a\u7684\u7ed3\u6784\u4e2d\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4e0a\u56fe\u5de6\u4e2d\u7684\u6b8b\u5dee\u5757\u7684\u5b9e\u73b0\u5982\u4e0b\uff0c\u53ef\u4ee5\u8bbe\u5b9a\u8f93\u51fa\u901a\u9053\u6570\uff0c\u662f\u5426\u4f7f\u75281*1\u7684\u5377\u79ef\u53ca\u5377\u79ef\u5c42\u7684\u6b65\u5e45\u3002 # \u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305 import tensorflow as tf from tensorflow.keras import layers , activations # \u5b9a\u4e49ResNet\u7684\u6b8b\u5dee\u5757 class Residual ( tf . keras . Model ): # \u6307\u660e\u6b8b\u5dee\u5757\u7684\u901a\u9053\u6570\uff0c\u662f\u5426\u4f7f\u75281*1\u5377\u79ef\uff0c\u6b65\u957f def __init__ ( self , num_channels , use_1x1conv = False , strides = 1 ): super ( Residual , self ) . __init__ () # \u5377\u79ef\u5c42\uff1a\u6307\u660e\u5377\u79ef\u6838\u4e2a\u6570\uff0cpadding,\u5377\u79ef\u6838\u5927\u5c0f\uff0c\u6b65\u957f self . conv1 = layers . Conv2D ( num_channels , padding = 'same' , kernel_size = 3 , strides = strides ) # \u5377\u79ef\u5c42\uff1a\u6307\u660e\u5377\u79ef\u6838\u4e2a\u6570\uff0cpadding,\u5377\u79ef\u6838\u5927\u5c0f\uff0c\u6b65\u957f self . conv2 = layers . Conv2D ( num_channels , kernel_size = 3 , padding = 'same' ) if use_1x1conv : self . conv3 = layers . Conv2D ( num_channels , kernel_size = 1 , strides = strides ) else : self . conv3 = None # \u6307\u660eBN\u5c42 self . bn1 = layers . BatchNormalization () self . bn2 = layers . BatchNormalization () # \u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b def call ( self , X ): # \u5377\u79ef\uff0cBN\uff0c\u6fc0\u6d3b Y = activations . relu ( self . bn1 ( self . conv1 ( X ))) # \u5377\u79ef\uff0cBN Y = self . bn2 ( self . conv2 ( Y )) # \u5bf9\u8f93\u5165\u6570\u636e\u8fdb\u884c1*1\u5377\u79ef\u4fdd\u8bc1\u901a\u9053\u6570\u76f8\u540c if self . conv3 : X = self . conv3 ( X ) # \u8fd4\u56de\u4e0e\u8f93\u5165\u76f8\u52a0\u540e\u6fc0\u6d3b\u7684\u7ed3\u679c return activations . relu ( Y + X ) 1*1\u5377\u79ef\u7528\u6765\u8c03\u6574\u901a\u9053\u6570\u3002","title":"1 \u6b8b\u5dee\u5757"},{"location":"imageClassification/section5/#2-resnet","text":"ResNet\u6a21\u578b\u7684\u6784\u6210\u5982\u4e0b\u56fe\u6240\u793a\uff1a ResNet\u7f51\u7edc\u4e2d\u6309\u7167\u6b8b\u5dee\u5757\u7684\u901a\u9053\u6570\u5206\u4e3a\u4e0d\u540c\u7684\u6a21\u5757\u3002\u7b2c\u4e00\u4e2a\u6a21\u5757\u524d\u4f7f\u7528\u4e86\u6b65\u5e45\u4e3a2\u7684\u6700\u5927\u6c60\u5316\u5c42\uff0c\u6240\u4ee5\u65e0\u987b\u51cf\u5c0f\u9ad8\u548c\u5bbd\u3002\u4e4b\u540e\u7684\u6bcf\u4e2a\u6a21\u5757\u5728\u7b2c\u4e00\u4e2a\u6b8b\u5dee\u5757\u91cc\u5c06\u4e0a\u4e00\u4e2a\u6a21\u5757\u7684\u901a\u9053\u6570\u7ffb\u500d\uff0c\u5e76\u5c06\u9ad8\u548c\u5bbd\u51cf\u534a\u3002 \u4e0b\u9762\u6211\u4eec\u6765\u5b9e\u73b0\u8fd9\u4e9b\u6a21\u5757\u3002\u6ce8\u610f\uff0c\u8fd9\u91cc\u5bf9\u7b2c\u4e00\u4e2a\u6a21\u5757\u505a\u4e86\u7279\u522b\u5904\u7406\u3002 # ResNet\u7f51\u7edc\u4e2d\u6a21\u5757\u7684\u6784\u6210 class ResnetBlock ( tf . keras . layers . Layer ): # \u7f51\u7edc\u5c42\u7684\u5b9a\u4e49\uff1a\u8f93\u51fa\u901a\u9053\u6570\uff08\u5377\u79ef\u6838\u4e2a\u6570\uff09\uff0c\u6a21\u5757\u4e2d\u5305\u542b\u7684\u6b8b\u5dee\u5757\u4e2a\u6570\uff0c\u662f\u5426\u4e3a\u7b2c\u4e00\u4e2a\u6a21\u5757 def __init__ ( self , num_channels , num_residuals , first_block = False ): super ( ResnetBlock , self ) . __init__ () # \u6a21\u5757\u4e2d\u7684\u7f51\u7edc\u5c42 self . listLayers = [] # \u904d\u5386\u6a21\u5757\u4e2d\u6240\u6709\u7684\u5c42 for i in range ( num_residuals ): # \u82e5\u4e3a\u7b2c\u4e00\u4e2a\u6b8b\u5dee\u5757\u5e76\u4e14\u4e0d\u662f\u7b2c\u4e00\u4e2a\u6a21\u5757\uff0c\u5219\u4f7f\u75281*1\u5377\u79ef\uff0c\u6b65\u957f\u4e3a2\uff08\u76ee\u7684\u662f\u51cf\u5c0f\u7279\u5f81\u56fe\uff0c\u5e76\u589e\u5927\u901a\u9053\u6570\uff09 if i == 0 and not first_block : self . listLayers . append ( Residual ( num_channels , use_1x1conv = True , strides = 2 )) # \u5426\u5219\u4e0d\u4f7f\u75281*1\u5377\u79ef\uff0c\u6b65\u957f\u4e3a1 else : self . listLayers . append ( Residual ( num_channels )) # \u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b def call ( self , X ): # \u6240\u6709\u5c42\u4f9d\u6b21\u5411\u524d\u4f20\u64ad\u5373\u53ef for layer in self . listLayers . layers : X = layer ( X ) return X ResNet\u7684\u524d\u4e24\u5c42\u8ddf\u4e4b\u524d\u4ecb\u7ecd\u7684GoogLeNet\u4e2d\u7684\u4e00\u6837\uff1a\u5728\u8f93\u51fa\u901a\u9053\u6570\u4e3a64\u3001\u6b65\u5e45\u4e3a2\u7684 7\\times 7 7\\times 7 \u5377\u79ef\u5c42\u540e\u63a5\u6b65\u5e45\u4e3a2\u7684 3\\times 3 3\\times 3 \u7684\u6700\u5927\u6c60\u5316\u5c42\u3002\u4e0d\u540c\u4e4b\u5904\u5728\u4e8eResNet\u6bcf\u4e2a\u5377\u79ef\u5c42\u540e\u589e\u52a0\u4e86BN\u5c42,\u63a5\u7740\u662f\u6240\u6709\u6b8b\u5dee\u6a21\u5757\uff0c\u6700\u540e\uff0c\u4e0eGoogLeNet\u4e00\u6837\uff0c\u52a0\u5165\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\uff08GAP\uff09\u540e\u63a5\u4e0a\u5168\u8fde\u63a5\u5c42\u8f93\u51fa\u3002 # \u6784\u5efaResNet\u7f51\u7edc class ResNet ( tf . keras . Model ): # \u521d\u59cb\u5316\uff1a\u6307\u5b9a\u6bcf\u4e2a\u6a21\u5757\u4e2d\u7684\u6b8b\u5dee\u5feb\u7684\u4e2a\u6570 def __init__ ( self , num_blocks ): super ( ResNet , self ) . __init__ () # \u8f93\u5165\u5c42\uff1a7*7\u5377\u79ef\uff0c\u6b65\u957f\u4e3a2 self . conv = layers . Conv2D ( 64 , kernel_size = 7 , strides = 2 , padding = 'same' ) # BN\u5c42 self . bn = layers . BatchNormalization () # \u6fc0\u6d3b\u5c42 self . relu = layers . Activation ( 'relu' ) # \u6700\u5927\u6c60\u5316\u5c42 self . mp = layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' ) # \u7b2c\u4e00\u4e2ablock\uff0c\u901a\u9053\u6570\u4e3a64 self . resnet_block1 = ResnetBlock ( 64 , num_blocks [ 0 ], first_block = True ) # \u7b2c\u4e8c\u4e2ablock\uff0c\u901a\u9053\u6570\u4e3a128 self . resnet_block2 = ResnetBlock ( 128 , num_blocks [ 1 ]) # \u7b2c\u4e09\u4e2ablock\uff0c\u901a\u9053\u6570\u4e3a256 self . resnet_block3 = ResnetBlock ( 256 , num_blocks [ 2 ]) # \u7b2c\u56db\u4e2ablock\uff0c\u901a\u9053\u6570\u4e3a512 self . resnet_block4 = ResnetBlock ( 512 , num_blocks [ 3 ]) # \u5168\u5c40\u5e73\u5747\u6c60\u5316 self . gap = layers . GlobalAvgPool2D () # \u5168\u8fde\u63a5\u5c42\uff1a\u5206\u7c7b self . fc = layers . Dense ( units = 10 , activation = tf . keras . activations . softmax ) # \u524d\u5411\u4f20\u64ad\u8fc7\u7a0b def call ( self , x ): # \u5377\u79ef x = self . conv ( x ) # BN x = self . bn ( x ) # \u6fc0\u6d3b x = self . relu ( x ) # \u6700\u5927\u6c60\u5316 x = self . mp ( x ) # \u6b8b\u5dee\u6a21\u5757 x = self . resnet_block1 ( x ) x = self . resnet_block2 ( x ) x = self . resnet_block3 ( x ) x = self . resnet_block4 ( x ) # \u5168\u5c40\u5e73\u5747\u6c60\u5316 x = self . gap ( x ) # \u5168\u94fe\u63a5\u5c42 x = self . fc ( x ) return x # \u6a21\u578b\u5b9e\u4f8b\u5316\uff1a\u6307\u5b9a\u6bcf\u4e2ablock\u4e2d\u7684\u6b8b\u5dee\u5757\u4e2a\u6570 mynet = ResNet ([ 2 , 2 , 2 , 2 ]) \u8fd9\u91cc\u6bcf\u4e2a\u6a21\u5757\u91cc\u67094\u4e2a\u5377\u79ef\u5c42\uff08\u4e0d\u8ba1\u7b97 1\u00d71\u5377\u79ef\u5c42\uff09\uff0c\u52a0\u4e0a\u6700\u5f00\u59cb\u7684\u5377\u79ef\u5c42\u548c\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u5171\u8ba118\u5c42\u3002\u8fd9\u4e2a\u6a21\u578b\u88ab\u79f0\u4e3aResNet-18\u3002\u901a\u8fc7\u914d\u7f6e\u4e0d\u540c\u7684\u901a\u9053\u6570\u548c\u6a21\u5757\u91cc\u7684\u6b8b\u5dee\u5757\u6570\u53ef\u4ee5\u5f97\u5230\u4e0d\u540c\u7684ResNet\u6a21\u578b\uff0c\u4f8b\u5982\u66f4\u6df1\u7684\u542b152\u5c42\u7684ResNet-152\u3002\u867d\u7136ResNet\u7684\u4e3b\u4f53\u67b6\u6784\u8ddfGoogLeNet\u7684\u7c7b\u4f3c\uff0c\u4f46ResNet\u7ed3\u6784\u66f4\u7b80\u5355\uff0c\u4fee\u6539\u4e5f\u66f4\u65b9\u4fbf\u3002\u8fd9\u4e9b\u56e0\u7d20\u90fd\u5bfc\u81f4\u4e86ResNet\u8fc5\u901f\u88ab\u5e7f\u6cdb\u4f7f\u7528\u3002 \u5728\u8bad\u7ec3ResNet\u4e4b\u524d\uff0c\u6211\u4eec\u6765\u89c2\u5bdf\u4e00\u4e0b\u8f93\u5165\u5f62\u72b6\u5728ResNe\u7684\u67b6\u6784\uff1a X = tf . random . uniform ( shape = ( 1 , 224 , 224 , 1 )) y = mynet ( X ) mynet . summary () Model : \"res_net\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= conv2d_2 ( Conv2D ) multiple 3200 _________________________________________________________________ batch_normalization_2 ( Batch multiple 256 _________________________________________________________________ activation ( Activation ) multiple 0 _________________________________________________________________ max_pooling2d ( MaxPooling2D ) multiple 0 _________________________________________________________________ resnet_block ( ResnetBlock ) multiple 148736 _________________________________________________________________ resnet_block_1 ( ResnetBlock ) multiple 526976 _________________________________________________________________ resnet_block_2 ( ResnetBlock ) multiple 2102528 _________________________________________________________________ resnet_block_3 ( ResnetBlock ) multiple 8399360 _________________________________________________________________ global_average_pooling2d ( Gl multiple 0 _________________________________________________________________ dense ( Dense ) multiple 5130 ================================================================= Total params : 11 , 186 , 186 Trainable params : 11 , 178 , 378 Non - trainable params : 7 , 808 _________________________________________________________________","title":"2 ResNet\u6a21\u578b"},{"location":"imageClassification/section5/#2","text":"\u56e0\u4e3aImageNet\u6570\u636e\u96c6\u8f83\u5927\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u4ecd\u7528\u524d\u9762\u7684MNIST\u6570\u636e\u96c6\u6765\u6f14\u793aresNet\u3002\u8bfb\u53d6\u6570\u636e\u7684\u65f6\u5c06\u56fe\u50cf\u9ad8\u548c\u5bbd\u6269\u5927\u5230ResNet\u4f7f\u7528\u7684\u56fe\u50cf\u9ad8\u548c\u5bbd224\u3002\u8fd9\u4e2a\u901a\u8fc7 tf.image.resize_with_pad \u6765\u5b9e\u73b0\u3002","title":"2.\u624b\u5199\u6570\u5b57\u52bf\u8bc6\u522b"},{"location":"imageClassification/section5/#21","text":"\u9996\u5148\u83b7\u53d6\u6570\u636e,\u5e76\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff1a import numpy as np # \u83b7\u53d6\u624b\u5199\u6570\u5b57\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # \u8bad\u7ec3\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C train_images = np . reshape ( train_images ,( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) # \u6d4b\u8bd5\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C test_images = np . reshape ( test_images ,( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7531\u4e8e\u4f7f\u7528\u5168\u90e8\u6570\u636e\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u83b7\u53d6\u90e8\u5206\u6570\u636e\uff0c\u5e76\u5c06\u56fe\u50cf\u8c03\u6574\u4e3a224*224\u5927\u5c0f\uff0c\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a # \u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u968f\u673a\u62bd\u53d6\u90e8\u5206\u6837\u672c\u6f14\u793a # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e def get_train ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( train_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u621022*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( train_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u53d6\u7684 return resized_images . numpy (), train_labels [ index ] # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e def get_test ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( test_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210224*224\u5927\u5c0f resized_images = tf . image . resize_with_pad ( test_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u6837\u7684\u6d4b\u8bd5\u6837\u672c return resized_images . numpy (), test_labels [ index ] \u8c03\u7528\u4e0a\u8ff0\u4e24\u4e2a\u65b9\u6cd5\uff0c\u83b7\u53d6\u53c2\u4e0e\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\uff1a # \u83b7\u53d6\u8bad\u7ec3\u6837\u672c\u548c\u6d4b\u8bd5\u6837\u672c train_images , train_labels = get_train ( 256 ) test_images , test_labels = get_test ( 128 )","title":"2.1 \u6570\u636e\u8bfb\u53d6"},{"location":"imageClassification/section5/#22","text":"# \u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 ) mynet . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ])","title":"2.2 \u6a21\u578b\u7f16\u8bd1"},{"location":"imageClassification/section5/#23","text":"# \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u8bad\u7ec3\u6570\u636e\uff0cbatchsize,epoch,\u9a8c\u8bc1\u96c6 mynet . fit ( train_images , train_labels , batch_size = 128 , epochs = 3 , verbose = 1 , validation_split = 0.1 ) \u8bad\u7ec3\u8f93\u51fa\u4e3a\uff1a Epoch 1 / 3 2 / 2 [ ============================== ] - 10 s 5 s / step - loss : 2.7811 - accuracy : 0.1391 - val_loss : 4.7931 - val_accuracy : 0.1923 Epoch 2 / 3 2 / 2 [ ============================== ] - 8 s 4 s / step - loss : 2.2579 - accuracy : 0.2478 - val_loss : 2.9262 - val_accuracy : 0.2692 Epoch 3 / 3 2 / 2 [ ============================== ] - 15 s 7 s / step - loss : 2.0874 - accuracy : 0.2609 - val_loss : 2.5882 - val_accuracy : 0.2692","title":"2.3 \u6a21\u578b\u8bad\u7ec3"},{"location":"imageClassification/section5/#24","text":"# \u6307\u5b9a\u6d4b\u8bd5\u6570\u636e mynet . evaluate ( test_images , test_labels , verbose = 1 ) \u8f93\u51fa\u4e3a\uff1a 4 / 4 [ ============================== ] - 1 s 370 ms / step - loss : 3.4343 - accuracy : 0.1016 [ 3.4342570304870605 , 0.1015625 ] \u603b\u7ed3 \u77e5\u9053ResNet\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u6b8b\u5dee\u5757\u7684\u6784\u6210 \u80fd\u591f\u642d\u5efaResNet\u7f51\u7edc\u7ed3\u6784","title":"2.4 \u6a21\u578b\u8bc4\u4f30"},{"location":"imageClassification/section6/","text":"2.6 \u56fe\u50cf\u589e\u5f3a \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u56fe\u50cf\u589e\u5f3a\u7684\u5e38\u7528\u65b9\u6cd5 \u80fd\u591f\u5229\u7528tf.keras\u6765\u5b8c\u6210\u56fe\u50cf\u589e\u5f3a \u5927\u89c4\u6a21\u6570\u636e\u96c6\u662f\u6210\u529f\u5e94\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u524d\u63d0\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u4ee5\u5bf9\u56fe\u50cf\u8fdb\u884c\u4e0d\u540c\u65b9\u5f0f\u7684\u88c1\u526a\uff0c\u4f7f\u611f\u5174\u8da3\u7684\u7269\u4f53\u51fa\u73b0\u5728\u4e0d\u540c\u4f4d\u7f6e\uff0c\u4ece\u800c\u51cf\u8f7b\u6a21\u578b\u5bf9\u7269\u4f53\u51fa\u73b0\u4f4d\u7f6e\u7684\u4f9d\u8d56\u6027\u3002\u6211\u4eec\u4e5f\u53ef\u4ee5\u8c03\u6574\u4eae\u5ea6\u3001\u8272\u5f69\u7b49\u56e0\u7d20\u6765\u964d\u4f4e\u6a21\u578b\u5bf9\u8272\u5f69\u7684\u654f\u611f\u5ea6\u3002\u53ef\u4ee5\u8bf4\uff0c\u5728\u5f53\u5e74AlexNet\u7684\u6210\u529f\u4e2d\uff0c\u56fe\u50cf\u589e\u5f3a\u6280\u672f\u529f\u4e0d\u53ef\u6ca1 1.\u5e38\u7528\u7684\u56fe\u50cf\u589e\u5f3a\u65b9\u6cd5 \u00b6 \u56fe\u50cf\u589e\u5f3a\uff08image augmentation\uff09\u6307\u901a\u8fc7\u526a\u5207\u3001\u65cb\u8f6c/\u53cd\u5c04/\u7ffb\u8f6c\u53d8\u6362\u3001\u7f29\u653e\u53d8\u6362\u3001\u5e73\u79fb\u53d8\u6362\u3001\u5c3a\u5ea6\u53d8\u6362\u3001\u5bf9\u6bd4\u5ea6\u53d8\u6362\u3001\u566a\u58f0\u6270\u52a8\u3001\u989c\u8272\u53d8\u6362\u7b49\u4e00\u79cd\u6216\u591a\u79cd\u7ec4\u5408\u6570\u636e\u589e\u5f3a\u53d8\u6362\u7684\u65b9\u5f0f\u6765\u589e\u52a0\u6570\u636e\u96c6\u7684\u5927\u5c0f\u3002\u56fe\u50cf\u589e\u5f3a\u7684\u610f\u4e49\u662f\u901a\u8fc7\u5bf9\u8bad\u7ec3\u56fe\u50cf\u505a\u4e00\u7cfb\u5217\u968f\u673a\u6539\u53d8\uff0c\u6765\u4ea7\u751f\u76f8\u4f3c\u4f46\u53c8\u4e0d\u540c\u7684\u8bad\u7ec3\u6837\u672c\uff0c\u4ece\u800c\u6269\u5927\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u89c4\u6a21\uff0c\u800c\u4e14\u968f\u673a\u6539\u53d8\u8bad\u7ec3\u6837\u672c\u53ef\u4ee5\u964d\u4f4e\u6a21\u578b\u5bf9\u67d0\u4e9b\u5c5e\u6027\u7684\u4f9d\u8d56\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002 \u5e38\u89c1\u7684\u56fe\u50cf\u589e\u5f3a\u65b9\u5f0f\u53ef\u4ee5\u5206\u4e3a\u4e24\u7c7b\uff1a\u51e0\u4f55\u53d8\u6362\u7c7b\u548c\u989c\u8272\u53d8\u6362\u7c7b \u51e0\u4f55\u53d8\u6362\u7c7b\uff0c\u4e3b\u8981\u662f\u5bf9\u56fe\u50cf\u8fdb\u884c\u51e0\u4f55\u53d8\u6362\u64cd\u4f5c\uff0c\u5305\u62ec**\u7ffb\u8f6c\uff0c\u65cb\u8f6c\uff0c\u88c1\u526a\uff0c\u53d8\u5f62\uff0c\u7f29\u653e**\u7b49\u3002 \u989c\u8272\u53d8\u6362\u7c7b\uff0c\u6307\u901a\u8fc7\u6a21\u7cca\u3001\u989c\u8272\u53d8\u6362\u3001\u64e6\u9664\u3001\u586b\u5145\u7b49\u65b9\u5f0f\u5bf9\u56fe\u50cf\u8fdb\u884c\u5904\u7406 \u5b9e\u73b0\u56fe\u50cf\u589e\u5f3a\u53ef\u4ee5\u901a\u8fc7tf.image\u6765\u5b8c\u6210\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7tf.keras.imageGenerator\u6765\u5b8c\u6210\u3002 2.tf.image\u8fdb\u884c\u56fe\u50cf\u589e\u5f3a \u00b6 \u5bfc\u5165\u6240\u9700\u7684\u5de5\u5177\u5305\u5e76\u8bfb\u53d6\u8981\u5904\u7406\u7684\u56fe\u50cf\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf import matplotlib.pyplot as plt import numpy as np # \u8bfb\u53d6\u56fe\u50cf\u5e76\u663e\u793a cat = plt . imread ( './cat.jpg' ) plt . imshow ( cat ) 2.1 \u7ffb\u8f6c\u548c\u88c1\u526a \u00b6 \u5de6\u53f3\u7ffb\u8f6c\u56fe\u50cf\u662f\u6700\u65e9\u4e5f\u662f\u6700\u5e7f\u6cdb\u4f7f\u7528\u7684\u4e00\u79cd\u56fe\u50cf\u589e\u5e7f\u65b9\u6cd5\u3002\u53ef\u4ee5\u901a\u8fc7 tf.image.random_flip_left_right \u6765\u5b9e\u73b0\u56fe\u50cf\u5de6\u53f3\u7ffb\u8f6c\u3002 # \u5de6\u53f3\u7ffb\u8f6c\u5e76\u663e\u793a cat1 = tf . image . random_flip_left_right ( cat ) plt . imshow ( cat1 \uff09 \u521b\u5efa tf.image.random_flip_up_down \u5b9e\u4f8b\u6765\u5b9e\u73b0\u56fe\u50cf\u7684\u4e0a\u4e0b\u7ffb\u8f6c\uff0c\u4e0a\u4e0b\u7ffb\u8f6c\u4f7f\u7528\u7684\u8f83\u5c11\u3002 # \u4e0a\u4e0b\u7ffb\u8f6c cat2 = tf . image . random_flip_up_down ( cat ) plt . imshow ( cat2 ) \u968f\u673a\u88c1\u526a\u51fa\u4e00\u5757\u9762\u79ef\u4e3a\u539f\u9762\u79ef 10\\% \\sim 100\\% 10\\% \\sim 100\\% \u7684\u533a\u57df\uff0c\u4e14\u8be5\u533a\u57df\u7684\u5bbd\u548c\u9ad8\u4e4b\u6bd4\u968f\u673a\u53d6\u81ea 0.5 \\sim 2 0.5 \\sim 2 \uff0c\u7136\u540e\u518d\u5c06\u8be5\u533a\u57df\u7684\u5bbd\u548c\u9ad8\u5206\u522b\u7f29\u653e\u5230200\u50cf\u7d20\u3002 # \u968f\u673a\u88c1\u526a cat3 = tf . image . random_crop ( cat ,( 200 , 200 , 3 )) plt . imshow ( cat3 ) 2.2 \u989c\u8272\u53d8\u6362 \u00b6 \u53e6\u4e00\u7c7b\u589e\u5e7f\u65b9\u6cd5\u662f\u989c\u8272\u53d8\u6362\u3002\u6211\u4eec\u53ef\u4ee5\u4ece4\u4e2a\u65b9\u9762\u6539\u53d8\u56fe\u50cf\u7684\u989c\u8272\uff1a\u4eae\u5ea6\u3001\u5bf9\u6bd4\u5ea6\u3001\u9971\u548c\u5ea6\u548c\u8272\u8c03\u3002\u63a5\u4e0b\u6765\u5c06\u56fe\u50cf\u7684\u4eae\u5ea6\u968f\u673a\u53d8\u5316\u4e3a\u539f\u56fe\u4eae\u5ea6\u7684 50\\% 50\\% \uff08\u5373 1-0.5 1-0.5 \uff09 \\sim 150\\% \\sim 150\\% \uff08\u5373 1+0.5 1+0.5 \uff09\u3002 cat4 = tf . image . random_brightness ( cat , 0.5 ) plt . imshow ( cat4 ) \u7c7b\u4f3c\u5730\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u968f\u673a\u53d8\u5316\u56fe\u50cf\u7684\u8272\u8c03 cat5 = tf . image . random_hue ( cat , 0.5 ) plt . imshow ( cat5 ) 3 \u4f7f\u7528ImageDataGenerator()\u8fdb\u884c\u56fe\u50cf\u589e\u5f3a \u00b6 ImageDataGenerator()\u662fkeras.preprocessing.image\u6a21\u5757\u4e2d\u7684\u56fe\u7247\u751f\u6210\u5668\uff0c\u53ef\u4ee5\u5728batch\u4e2d\u5bf9\u6570\u636e\u8fdb\u884c\u589e\u5f3a\uff0c\u6269\u5145\u6570\u636e\u96c6\u5927\u5c0f\uff0c\u589e\u5f3a\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6bd4\u5982\u65cb\u8f6c\uff0c\u53d8\u5f62\u7b49\uff0c\u5982\u4e0b\u6240\u793a\uff1a keras . preprocessing . image . ImageDataGenerator ( rotation_range = 0 , #\u6574\u6570\u3002\u968f\u673a\u65cb\u8f6c\u7684\u5ea6\u6570\u8303\u56f4\u3002 width_shift_range = 0.0 , #\u6d6e\u70b9\u6570\u3001\u5bbd\u5ea6\u5e73\u79fb height_shift_range = 0.0 , #\u6d6e\u70b9\u6570\u3001\u9ad8\u5ea6\u5e73\u79fb brightness_range = None , # \u4eae\u5ea6\u8c03\u6574 shear_range = 0.0 , # \u88c1\u526a zoom_range = 0.0 , #\u6d6e\u70b9\u6570 \u6216 [lower, upper]\u3002\u968f\u673a\u7f29\u653e\u8303\u56f4 horizontal_flip = False , # \u5de6\u53f3\u7ffb\u8f6c vertical_flip = False , # \u5782\u76f4\u7ffb\u8f6c rescale = None # \u5c3a\u5ea6\u8c03\u6574 ) \u6765\u770b\u4e0b\u6c34\u5e73\u7ffb\u8f6c\u7684\u7ed3\u679c\uff1a # \u83b7\u53d6\u6570\u636e\u96c6 ( x_train , y_train ), ( x_test , y_test ) = tf . keras . datasets . mnist . load_data () # \u5c06\u6570\u636e\u8f6c\u6362\u4e3a4\u7ef4\u7684\u5f62\u5f0f x_train = X_train . reshape ( X_train . shape [ 0 ], 28 , 28 , 1 ) x_test = X_test . reshape ( X_test . shape [ 0 ], 28 , 28 , 1 ) # \u8bbe\u7f6e\u56fe\u50cf\u589e\u5f3a\u65b9\u5f0f\uff1a\u6c34\u5e73\u7ffb\u8f6c datagen = ImageDataGenerator ( horizontal_flip = True ) # \u67e5\u770b\u589e\u5f3a\u540e\u7684\u7ed3\u679c for X_batch , y_batch in datagen . flow ( x_train , y_train , batch_size = 9 ): plt . figure ( figsize = ( 8 , 8 )) # \u8bbe\u5b9a\u6bcf\u4e2a\u56fe\u50cf\u663e\u793a\u7684\u5927\u5c0f # \u4ea7\u751f\u4e00\u4e2a3*3\u7f51\u683c\u7684\u56fe\u50cf for i in range ( 0 , 9 ): plt . subplot ( 330 + 1 + i ) plt . title ( y_batch [ i ]) plt . axis ( 'off' ) plt . imshow ( X_batch [ i ] . reshape ( 28 , 28 ), cmap = 'gray' ) plt . show () break \u603b\u7ed3 \u5e38\u7528\u7684\u56fe\u50cf\u589e\u5f3a\u65b9\u6cd5\uff1a\u51e0\u4f55\u548c\u989c\u8272 \u5728tf,keras\u4e2d\u53ef\u4ee5\u901a\u8fc7\uff1atf.image\u548cImageDataGenerator()\u5b8c\u6210\u56fe\u50cf\u589e\u5f3a","title":"\u56fe\u50cf\u589e\u5f3a\u65b9\u6cd5"},{"location":"imageClassification/section6/#26","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u56fe\u50cf\u589e\u5f3a\u7684\u5e38\u7528\u65b9\u6cd5 \u80fd\u591f\u5229\u7528tf.keras\u6765\u5b8c\u6210\u56fe\u50cf\u589e\u5f3a \u5927\u89c4\u6a21\u6570\u636e\u96c6\u662f\u6210\u529f\u5e94\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u524d\u63d0\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u4ee5\u5bf9\u56fe\u50cf\u8fdb\u884c\u4e0d\u540c\u65b9\u5f0f\u7684\u88c1\u526a\uff0c\u4f7f\u611f\u5174\u8da3\u7684\u7269\u4f53\u51fa\u73b0\u5728\u4e0d\u540c\u4f4d\u7f6e\uff0c\u4ece\u800c\u51cf\u8f7b\u6a21\u578b\u5bf9\u7269\u4f53\u51fa\u73b0\u4f4d\u7f6e\u7684\u4f9d\u8d56\u6027\u3002\u6211\u4eec\u4e5f\u53ef\u4ee5\u8c03\u6574\u4eae\u5ea6\u3001\u8272\u5f69\u7b49\u56e0\u7d20\u6765\u964d\u4f4e\u6a21\u578b\u5bf9\u8272\u5f69\u7684\u654f\u611f\u5ea6\u3002\u53ef\u4ee5\u8bf4\uff0c\u5728\u5f53\u5e74AlexNet\u7684\u6210\u529f\u4e2d\uff0c\u56fe\u50cf\u589e\u5f3a\u6280\u672f\u529f\u4e0d\u53ef\u6ca1","title":"2.6 \u56fe\u50cf\u589e\u5f3a"},{"location":"imageClassification/section6/#1","text":"\u56fe\u50cf\u589e\u5f3a\uff08image augmentation\uff09\u6307\u901a\u8fc7\u526a\u5207\u3001\u65cb\u8f6c/\u53cd\u5c04/\u7ffb\u8f6c\u53d8\u6362\u3001\u7f29\u653e\u53d8\u6362\u3001\u5e73\u79fb\u53d8\u6362\u3001\u5c3a\u5ea6\u53d8\u6362\u3001\u5bf9\u6bd4\u5ea6\u53d8\u6362\u3001\u566a\u58f0\u6270\u52a8\u3001\u989c\u8272\u53d8\u6362\u7b49\u4e00\u79cd\u6216\u591a\u79cd\u7ec4\u5408\u6570\u636e\u589e\u5f3a\u53d8\u6362\u7684\u65b9\u5f0f\u6765\u589e\u52a0\u6570\u636e\u96c6\u7684\u5927\u5c0f\u3002\u56fe\u50cf\u589e\u5f3a\u7684\u610f\u4e49\u662f\u901a\u8fc7\u5bf9\u8bad\u7ec3\u56fe\u50cf\u505a\u4e00\u7cfb\u5217\u968f\u673a\u6539\u53d8\uff0c\u6765\u4ea7\u751f\u76f8\u4f3c\u4f46\u53c8\u4e0d\u540c\u7684\u8bad\u7ec3\u6837\u672c\uff0c\u4ece\u800c\u6269\u5927\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u89c4\u6a21\uff0c\u800c\u4e14\u968f\u673a\u6539\u53d8\u8bad\u7ec3\u6837\u672c\u53ef\u4ee5\u964d\u4f4e\u6a21\u578b\u5bf9\u67d0\u4e9b\u5c5e\u6027\u7684\u4f9d\u8d56\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002 \u5e38\u89c1\u7684\u56fe\u50cf\u589e\u5f3a\u65b9\u5f0f\u53ef\u4ee5\u5206\u4e3a\u4e24\u7c7b\uff1a\u51e0\u4f55\u53d8\u6362\u7c7b\u548c\u989c\u8272\u53d8\u6362\u7c7b \u51e0\u4f55\u53d8\u6362\u7c7b\uff0c\u4e3b\u8981\u662f\u5bf9\u56fe\u50cf\u8fdb\u884c\u51e0\u4f55\u53d8\u6362\u64cd\u4f5c\uff0c\u5305\u62ec**\u7ffb\u8f6c\uff0c\u65cb\u8f6c\uff0c\u88c1\u526a\uff0c\u53d8\u5f62\uff0c\u7f29\u653e**\u7b49\u3002 \u989c\u8272\u53d8\u6362\u7c7b\uff0c\u6307\u901a\u8fc7\u6a21\u7cca\u3001\u989c\u8272\u53d8\u6362\u3001\u64e6\u9664\u3001\u586b\u5145\u7b49\u65b9\u5f0f\u5bf9\u56fe\u50cf\u8fdb\u884c\u5904\u7406 \u5b9e\u73b0\u56fe\u50cf\u589e\u5f3a\u53ef\u4ee5\u901a\u8fc7tf.image\u6765\u5b8c\u6210\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7tf.keras.imageGenerator\u6765\u5b8c\u6210\u3002","title":"1.\u5e38\u7528\u7684\u56fe\u50cf\u589e\u5f3a\u65b9\u6cd5"},{"location":"imageClassification/section6/#2tfimage","text":"\u5bfc\u5165\u6240\u9700\u7684\u5de5\u5177\u5305\u5e76\u8bfb\u53d6\u8981\u5904\u7406\u7684\u56fe\u50cf\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf import matplotlib.pyplot as plt import numpy as np # \u8bfb\u53d6\u56fe\u50cf\u5e76\u663e\u793a cat = plt . imread ( './cat.jpg' ) plt . imshow ( cat )","title":"2.tf.image\u8fdb\u884c\u56fe\u50cf\u589e\u5f3a"},{"location":"imageClassification/section6/#21","text":"\u5de6\u53f3\u7ffb\u8f6c\u56fe\u50cf\u662f\u6700\u65e9\u4e5f\u662f\u6700\u5e7f\u6cdb\u4f7f\u7528\u7684\u4e00\u79cd\u56fe\u50cf\u589e\u5e7f\u65b9\u6cd5\u3002\u53ef\u4ee5\u901a\u8fc7 tf.image.random_flip_left_right \u6765\u5b9e\u73b0\u56fe\u50cf\u5de6\u53f3\u7ffb\u8f6c\u3002 # \u5de6\u53f3\u7ffb\u8f6c\u5e76\u663e\u793a cat1 = tf . image . random_flip_left_right ( cat ) plt . imshow ( cat1 \uff09 \u521b\u5efa tf.image.random_flip_up_down \u5b9e\u4f8b\u6765\u5b9e\u73b0\u56fe\u50cf\u7684\u4e0a\u4e0b\u7ffb\u8f6c\uff0c\u4e0a\u4e0b\u7ffb\u8f6c\u4f7f\u7528\u7684\u8f83\u5c11\u3002 # \u4e0a\u4e0b\u7ffb\u8f6c cat2 = tf . image . random_flip_up_down ( cat ) plt . imshow ( cat2 ) \u968f\u673a\u88c1\u526a\u51fa\u4e00\u5757\u9762\u79ef\u4e3a\u539f\u9762\u79ef 10\\% \\sim 100\\% 10\\% \\sim 100\\% \u7684\u533a\u57df\uff0c\u4e14\u8be5\u533a\u57df\u7684\u5bbd\u548c\u9ad8\u4e4b\u6bd4\u968f\u673a\u53d6\u81ea 0.5 \\sim 2 0.5 \\sim 2 \uff0c\u7136\u540e\u518d\u5c06\u8be5\u533a\u57df\u7684\u5bbd\u548c\u9ad8\u5206\u522b\u7f29\u653e\u5230200\u50cf\u7d20\u3002 # \u968f\u673a\u88c1\u526a cat3 = tf . image . random_crop ( cat ,( 200 , 200 , 3 )) plt . imshow ( cat3 )","title":"2.1 \u7ffb\u8f6c\u548c\u88c1\u526a"},{"location":"imageClassification/section6/#22","text":"\u53e6\u4e00\u7c7b\u589e\u5e7f\u65b9\u6cd5\u662f\u989c\u8272\u53d8\u6362\u3002\u6211\u4eec\u53ef\u4ee5\u4ece4\u4e2a\u65b9\u9762\u6539\u53d8\u56fe\u50cf\u7684\u989c\u8272\uff1a\u4eae\u5ea6\u3001\u5bf9\u6bd4\u5ea6\u3001\u9971\u548c\u5ea6\u548c\u8272\u8c03\u3002\u63a5\u4e0b\u6765\u5c06\u56fe\u50cf\u7684\u4eae\u5ea6\u968f\u673a\u53d8\u5316\u4e3a\u539f\u56fe\u4eae\u5ea6\u7684 50\\% 50\\% \uff08\u5373 1-0.5 1-0.5 \uff09 \\sim 150\\% \\sim 150\\% \uff08\u5373 1+0.5 1+0.5 \uff09\u3002 cat4 = tf . image . random_brightness ( cat , 0.5 ) plt . imshow ( cat4 ) \u7c7b\u4f3c\u5730\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u968f\u673a\u53d8\u5316\u56fe\u50cf\u7684\u8272\u8c03 cat5 = tf . image . random_hue ( cat , 0.5 ) plt . imshow ( cat5 )","title":"2.2 \u989c\u8272\u53d8\u6362"},{"location":"imageClassification/section6/#3-imagedatagenerator","text":"ImageDataGenerator()\u662fkeras.preprocessing.image\u6a21\u5757\u4e2d\u7684\u56fe\u7247\u751f\u6210\u5668\uff0c\u53ef\u4ee5\u5728batch\u4e2d\u5bf9\u6570\u636e\u8fdb\u884c\u589e\u5f3a\uff0c\u6269\u5145\u6570\u636e\u96c6\u5927\u5c0f\uff0c\u589e\u5f3a\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6bd4\u5982\u65cb\u8f6c\uff0c\u53d8\u5f62\u7b49\uff0c\u5982\u4e0b\u6240\u793a\uff1a keras . preprocessing . image . ImageDataGenerator ( rotation_range = 0 , #\u6574\u6570\u3002\u968f\u673a\u65cb\u8f6c\u7684\u5ea6\u6570\u8303\u56f4\u3002 width_shift_range = 0.0 , #\u6d6e\u70b9\u6570\u3001\u5bbd\u5ea6\u5e73\u79fb height_shift_range = 0.0 , #\u6d6e\u70b9\u6570\u3001\u9ad8\u5ea6\u5e73\u79fb brightness_range = None , # \u4eae\u5ea6\u8c03\u6574 shear_range = 0.0 , # \u88c1\u526a zoom_range = 0.0 , #\u6d6e\u70b9\u6570 \u6216 [lower, upper]\u3002\u968f\u673a\u7f29\u653e\u8303\u56f4 horizontal_flip = False , # \u5de6\u53f3\u7ffb\u8f6c vertical_flip = False , # \u5782\u76f4\u7ffb\u8f6c rescale = None # \u5c3a\u5ea6\u8c03\u6574 ) \u6765\u770b\u4e0b\u6c34\u5e73\u7ffb\u8f6c\u7684\u7ed3\u679c\uff1a # \u83b7\u53d6\u6570\u636e\u96c6 ( x_train , y_train ), ( x_test , y_test ) = tf . keras . datasets . mnist . load_data () # \u5c06\u6570\u636e\u8f6c\u6362\u4e3a4\u7ef4\u7684\u5f62\u5f0f x_train = X_train . reshape ( X_train . shape [ 0 ], 28 , 28 , 1 ) x_test = X_test . reshape ( X_test . shape [ 0 ], 28 , 28 , 1 ) # \u8bbe\u7f6e\u56fe\u50cf\u589e\u5f3a\u65b9\u5f0f\uff1a\u6c34\u5e73\u7ffb\u8f6c datagen = ImageDataGenerator ( horizontal_flip = True ) # \u67e5\u770b\u589e\u5f3a\u540e\u7684\u7ed3\u679c for X_batch , y_batch in datagen . flow ( x_train , y_train , batch_size = 9 ): plt . figure ( figsize = ( 8 , 8 )) # \u8bbe\u5b9a\u6bcf\u4e2a\u56fe\u50cf\u663e\u793a\u7684\u5927\u5c0f # \u4ea7\u751f\u4e00\u4e2a3*3\u7f51\u683c\u7684\u56fe\u50cf for i in range ( 0 , 9 ): plt . subplot ( 330 + 1 + i ) plt . title ( y_batch [ i ]) plt . axis ( 'off' ) plt . imshow ( X_batch [ i ] . reshape ( 28 , 28 ), cmap = 'gray' ) plt . show () break \u603b\u7ed3 \u5e38\u7528\u7684\u56fe\u50cf\u589e\u5f3a\u65b9\u6cd5\uff1a\u51e0\u4f55\u548c\u989c\u8272 \u5728tf,keras\u4e2d\u53ef\u4ee5\u901a\u8fc7\uff1atf.image\u548cImageDataGenerator()\u5b8c\u6210\u56fe\u50cf\u589e\u5f3a","title":"3 \u4f7f\u7528ImageDataGenerator()\u8fdb\u884c\u56fe\u50cf\u589e\u5f3a"},{"location":"imageClassification/section7/","text":"2.7\u5fae\u8c03 \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u5fae\u8c03\u7684\u539f\u7406 \u80fd\u591f\u5229\u7528\u5fae\u8c03\u6a21\u578b\u6765\u5b8c\u6210\u56fe\u50cf\u7684\u5206\u7c7b\u4efb\u52a1 1.\u5fae\u8c03 \u00b6 \u5982\u4f55\u5728\u53ea\u67096\u4e07\u5f20\u56fe\u50cf\u7684MNIST\u8bad\u7ec3\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6a21\u578b\u3002\u5b66\u672f\u754c\u5f53\u4e0b\u4f7f\u7528\u6700\u5e7f\u6cdb\u7684\u5927\u89c4\u6a21\u56fe\u50cf\u6570\u636e\u96c6ImageNet\uff0c\u5b83\u6709\u8d85\u8fc71,000\u4e07\u7684\u56fe\u50cf\u548c1,000\u7c7b\u7684\u7269\u4f53\u3002\u7136\u800c\uff0c\u6211\u4eec\u5e73\u5e38\u63a5\u89e6\u5230\u6570\u636e\u96c6\u7684\u89c4\u6a21\u901a\u5e38\u5728\u8fd9\u4e24\u8005\u4e4b\u95f4\u3002\u5047\u8bbe\u6211\u4eec\u60f3\u4ece\u56fe\u50cf\u4e2d\u8bc6\u522b\u51fa\u4e0d\u540c\u79cd\u7c7b\u7684\u6905\u5b50\uff0c\u7136\u540e\u5c06\u8d2d\u4e70\u94fe\u63a5\u63a8\u8350\u7ed9\u7528\u6237\u3002\u4e00\u79cd\u53ef\u80fd\u7684\u65b9\u6cd5\u662f\u5148\u627e\u51fa100\u79cd\u5e38\u89c1\u7684\u6905\u5b50\uff0c\u4e3a\u6bcf\u79cd\u6905\u5b50\u62cd\u64441,000\u5f20\u4e0d\u540c\u89d2\u5ea6\u7684\u56fe\u50cf\uff0c\u7136\u540e\u5728\u6536\u96c6\u5230\u7684\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u6a21\u578b\u3002\u53e6\u5916\u4e00\u79cd\u89e3\u51b3\u529e\u6cd5\u662f\u5e94\u7528\u8fc1\u79fb\u5b66\u4e60\uff08transfer learning\uff09\uff0c\u5c06\u4ece\u6e90\u6570\u636e\u96c6\u5b66\u5230\u7684\u77e5\u8bc6\u8fc1\u79fb\u5230\u76ee\u6807\u6570\u636e\u96c6\u4e0a\u3002\u4f8b\u5982\uff0c\u867d\u7136ImageNet\u6570\u636e\u96c6\u7684\u56fe\u50cf\u5927\u591a\u8ddf\u6905\u5b50\u65e0\u5173\uff0c\u4f46\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u53ef\u4ee5\u62bd\u53d6\u8f83\u901a\u7528\u7684\u56fe\u50cf\u7279\u5f81\uff0c\u4ece\u800c\u80fd\u591f\u5e2e\u52a9\u8bc6\u522b\u8fb9\u7f18\u3001\u7eb9\u7406\u3001\u5f62\u72b6\u548c\u7269\u4f53\u7ec4\u6210\u7b49\u3002\u8fd9\u4e9b\u7c7b\u4f3c\u7684\u7279\u5f81\u5bf9\u4e8e\u8bc6\u522b\u6905\u5b50\u4e5f\u53ef\u80fd\u540c\u6837\u6709\u6548\u3002 \u5fae\u8c03\u7531\u4ee5\u4e0b4\u6b65\u6784\u6210\u3002 \u5728\u6e90\u6570\u636e\u96c6\uff08\u5982ImageNet\u6570\u636e\u96c6\uff09\u4e0a\u9884\u8bad\u7ec3\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u5373\u6e90\u6a21\u578b\u3002 \u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u5373\u76ee\u6807\u6a21\u578b\u3002\u5b83\u590d\u5236\u4e86\u6e90\u6a21\u578b\u4e0a\u9664\u4e86\u8f93\u51fa\u5c42\u5916\u7684\u6240\u6709\u6a21\u578b\u8bbe\u8ba1\u53ca\u5176\u53c2\u6570\u3002\u6211\u4eec\u5047\u8bbe\u8fd9\u4e9b\u6a21\u578b\u53c2\u6570\u5305\u542b\u4e86\u6e90\u6570\u636e\u96c6\u4e0a\u5b66\u4e60\u5230\u7684\u77e5\u8bc6\uff0c\u4e14\u8fd9\u4e9b\u77e5\u8bc6\u540c\u6837\u9002\u7528\u4e8e\u76ee\u6807\u6570\u636e\u96c6\u3002\u6211\u4eec\u8fd8\u5047\u8bbe\u6e90\u6a21\u578b\u7684\u8f93\u51fa\u5c42\u8ddf\u6e90\u6570\u636e\u96c6\u7684\u6807\u7b7e\u7d27\u5bc6\u76f8\u5173\uff0c\u56e0\u6b64\u5728\u76ee\u6807\u6a21\u578b\u4e2d\u4e0d\u4e88\u91c7\u7528\u3002 \u4e3a\u76ee\u6807\u6a21\u578b\u6dfb\u52a0\u4e00\u4e2a\u8f93\u51fa\u5927\u5c0f\u4e3a\u76ee\u6807\u6570\u636e\u96c6\u7c7b\u522b\u4e2a\u6570\u7684\u8f93\u51fa\u5c42\uff0c\u5e76\u968f\u673a\u521d\u59cb\u5316\u8be5\u5c42\u7684\u6a21\u578b\u53c2\u6570\u3002 \u5728\u76ee\u6807\u6570\u636e\u96c6\uff08\u5982\u6905\u5b50\u6570\u636e\u96c6\uff09\u4e0a\u8bad\u7ec3\u76ee\u6807\u6a21\u578b\u3002\u6211\u4eec\u5c06\u4ece\u5934\u8bad\u7ec3\u8f93\u51fa\u5c42\uff0c\u800c\u5176\u4f59\u5c42\u7684\u53c2\u6570\u90fd\u662f\u57fa\u4e8e\u6e90\u6a21\u578b\u7684\u53c2\u6570\u5fae\u8c03\u5f97\u5230\u7684\u3002 \u5f53\u76ee\u6807\u6570\u636e\u96c6\u8fdc\u5c0f\u4e8e\u6e90\u6570\u636e\u96c6\u65f6\uff0c\u5fae\u8c03\u6709\u52a9\u4e8e\u63d0\u5347\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002 2.\u70ed\u72d7\u8bc6\u522b \u00b6 \u63a5\u4e0b\u6765\u6211\u4eec\u6765\u5b9e\u8df5\u4e00\u4e2a\u5177\u4f53\u7684\u4f8b\u5b50\uff1a\u70ed\u72d7\u8bc6\u522b\u3002\u5c06\u57fa\u4e8e\u4e00\u4e2a\u5c0f\u6570\u636e\u96c6\u5bf9\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u597d\u7684ResNet\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002\u8be5\u5c0f\u6570\u636e\u96c6\u542b\u6709\u6570\u5343\u5f20\u70ed\u72d7\u6216\u8005\u5176\u4ed6\u4e8b\u7269\u7684\u56fe\u50cf\u3002\u6211\u4eec\u5c06\u4f7f\u7528\u5fae\u8c03\u5f97\u5230\u7684\u6a21\u578b\u6765\u8bc6\u522b\u4e00\u5f20\u56fe\u50cf\u4e2d\u662f\u5426\u5305\u542b\u70ed\u72d7\u3002 \u9996\u5148\uff0c\u5bfc\u5165\u5b9e\u9a8c\u6240\u9700\u7684\u5de5\u5177\u5305\u3002 import tensorflow as tf import numpy as np 2.1 \u83b7\u53d6\u6570\u636e\u96c6 \u00b6 \u6211\u4eec\u9996\u5148\u5c06\u6570\u636e\u96c6\u653e\u5728\u8def\u5f84hotdog/data\u4e4b\u4e0b: \u6bcf\u4e2a\u7c7b\u522b\u6587\u4ef6\u5939\u91cc\u9762\u662f\u56fe\u50cf\u6587\u4ef6\u3002 \u4e0a\u4e00\u8282\u4e2d\u6211\u4eec\u4ecb\u7ecd\u4e86ImageDataGenerator\u8fdb\u884c\u56fe\u50cf\u589e\u5f3a\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u6cd5\u8bfb\u53d6\u56fe\u50cf\u6587\u4ef6\uff0c\u8be5\u65b9\u6cd5\u4ee5\u6587\u4ef6\u5939\u8def\u5f84\u4e3a\u53c2\u6570,\u751f\u6210\u7ecf\u8fc7\u56fe\u50cf\u589e\u5f3a\u540e\u7684\u7ed3\u679c\uff0c\u5e76\u4ea7\u751fbatch\u6570\u636e\uff1a flow_from_directory ( self , directory , target_size = ( 256 , 256 ), color_mode = 'rgb' , classes = None , class_mode = 'categorical' , batch_size = 32 , shuffle = True , seed = None , save_to_dir = None \uff09 \u4e3b\u8981\u53c2\u6570\uff1a directory: \u76ee\u6807\u6587\u4ef6\u5939\u8def\u5f84\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u7c7b\u5bf9\u5e94\u4e00\u4e2a\u5b50\u6587\u4ef6\u5939\uff0c\u8be5\u5b50\u6587\u4ef6\u5939\u4e2d\u4efb\u4f55JPG\u3001PNG\u3001BNP\u3001PPM\u7684\u56fe\u7247\u90fd\u53ef\u4ee5\u8bfb\u53d6\u3002 target_size: \u9ed8\u8ba4\u4e3a(256, 256)\uff0c\u56fe\u50cf\u5c06\u88abresize\u6210\u8be5\u5c3a\u5bf8\u3002 batch_size: batch\u6570\u636e\u7684\u5927\u5c0f\uff0c\u9ed8\u8ba432\u3002 shuffle: \u662f\u5426\u6253\u4e71\u6570\u636e\uff0c\u9ed8\u8ba4\u4e3aTrue\u3002 \u6211\u4eec\u521b\u5efa\u4e24\u4e2a tf.keras.preprocessing.image.ImageDataGenerator \u5b9e\u4f8b\u6765\u5206\u522b\u8bfb\u53d6\u8bad\u7ec3\u6570\u636e\u96c6\u548c\u6d4b\u8bd5\u6570\u636e\u96c6\u4e2d\u7684\u6240\u6709\u56fe\u50cf\u6587\u4ef6\u3002\u5c06\u8bad\u7ec3\u96c6\u56fe\u7247\u5168\u90e8\u5904\u7406\u4e3a\u9ad8\u548c\u5bbd\u5747\u4e3a224\u50cf\u7d20\u7684\u8f93\u5165\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5bf9RGB\uff08\u7ea2\u3001\u7eff\u3001\u84dd\uff09\u4e09\u4e2a\u989c\u8272\u901a\u9053\u7684\u6570\u503c\u505a\u6807\u51c6\u5316\u3002 # \u83b7\u53d6\u6570\u636e\u96c6 import pathlib train_dir = 'transferdata/train' test_dir = 'transferdata/test' # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e train_dir = pathlib . Path ( train_dir ) train_count = len ( list ( train_dir . glob ( '*/*.jpg' ))) # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e test_dir = pathlib . Path ( test_dir ) test_count = len ( list ( test_dir . glob ( '*/*.jpg' ))) # \u521b\u5efaimageDataGenerator\u8fdb\u884c\u56fe\u50cf\u5904\u7406 image_generator = tf . keras . preprocessing . image . ImageDataGenerator ( rescale = 1. / 255 ) # \u8bbe\u7f6e\u53c2\u6570 BATCH_SIZE = 32 IMG_HEIGHT = 224 IMG_WIDTH = 224 # \u83b7\u53d6\u8bad\u7ec3\u6570\u636e train_data_gen = image_generator . flow_from_directory ( directory = str ( train_dir ), batch_size = BATCH_SIZE , target_size = ( IMG_HEIGHT , IMG_WIDTH ), shuffle = True ) # \u83b7\u53d6\u6d4b\u8bd5\u6570\u636e test_data_gen = image_generator . flow_from_directory ( directory = str ( test_dir ), batch_size = BATCH_SIZE , target_size = ( IMG_HEIGHT , IMG_WIDTH ), shuffle = True ) \u4e0b\u9762\u6211\u4eec\u968f\u673a\u53d61\u4e2abatch\u7684\u56fe\u7247\u7136\u540e\u7ed8\u5236\u51fa\u6765\u3002 import matplotlib.pyplot as plt # \u663e\u793a\u56fe\u50cf def show_batch ( image_batch , label_batch ): plt . figure ( figsize = ( 10 , 10 )) for n in range ( 15 ): ax = plt . subplot ( 5 , 5 , n + 1 ) plt . imshow ( image_batch [ n ] \uff09 plt . axis ( 'off' ) # \u968f\u673a\u9009\u62e9\u4e00\u4e2abatch\u7684\u56fe\u50cf image_batch , label_batch = next ( train_data_gen ) # \u56fe\u50cf\u663e\u793a show_batch ( image_batch , label_batch ) 2.2 \u6a21\u578b\u6784\u5efa\u4e0e\u8bad\u7ec3 \u00b6 \u6211\u4eec\u4f7f\u7528\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u7684ResNet-50\u4f5c\u4e3a\u6e90\u6a21\u578b\u3002\u8fd9\u91cc\u6307\u5b9a weights='imagenet' \u6765\u81ea\u52a8\u4e0b\u8f7d\u5e76\u52a0\u8f7d\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u53c2\u6570\u3002\u5728\u7b2c\u4e00\u6b21\u4f7f\u7528\u65f6\u9700\u8981\u8054\u7f51\u4e0b\u8f7d\u6a21\u578b\u53c2\u6570\u3002 Keras\u5e94\u7528\u7a0b\u5e8f\uff08keras.applications\uff09\u662f\u5177\u6709\u9884\u5148\u8bad\u7ec3\u6743\u503c\u7684\u56fa\u5b9a\u67b6\u6784\uff0c\u8be5\u7c7b\u5c01\u88c5\u4e86\u5f88\u591a\u91cd\u91cf\u7ea7\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5b9e\u73b0\u65f6\u5b9e\u4f8b\u5316\u6a21\u578b\u67b6\u6784\uff1a tf . keras . applications . ResNet50 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , ** kwargs ) \u4e3b\u8981\u53c2\u6570\uff1a include_top: \u662f\u5426\u5305\u62ec\u9876\u5c42\u7684\u5168\u8fde\u63a5\u5c42\u3002 weights: None \u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\uff0c 'imagenet' \u4ee3\u8868\u52a0\u8f7d\u5728 ImageNet \u4e0a\u9884\u8bad\u7ec3\u7684\u6743\u503c\u3002 input_shape: \u53ef\u9009\uff0c\u8f93\u5165\u5c3a\u5bf8\u5143\u7ec4\uff0c\u4ec5\u5f53 include_top=False \u65f6\u6709\u6548\uff0c\u5426\u5219\u8f93\u5165\u5f62\u72b6\u5fc5\u987b\u662f (224, 224, 3)\uff08channels_last \u683c\u5f0f\uff09\u6216 (3, 224, 224)\uff08channels_first \u683c\u5f0f\uff09\u3002\u5b83\u5fc5\u987b\u4e3a 3 \u4e2a\u8f93\u5165\u901a\u9053\uff0c\u4e14\u5bbd\u9ad8\u5fc5\u987b\u4e0d\u5c0f\u4e8e 32\uff0c\u6bd4\u5982 (200, 200, 3) \u662f\u4e00\u4e2a\u5408\u6cd5\u7684\u8f93\u5165\u5c3a\u5bf8\u3002 \u5728\u8be5\u6848\u4f8b\u4e2d\u6211\u4eec\u4f7f\u7528resNet50\u9884\u8bad\u7ec3\u6a21\u578b\u6784\u5efa\u6a21\u578b\uff1a # \u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b ResNet50 = tf . keras . applications . ResNet50 ( weights = 'imagenet' , input_shape = ( 224 , 224 , 3 )) # \u8bbe\u7f6e\u6240\u6709\u5c42\u4e0d\u53ef\u8bad\u7ec3 for layer in ResNet50 . layers : layer . trainable = False # \u8bbe\u7f6e\u6a21\u578b net = tf . keras . models . Sequential () # \u9884\u8bad\u7ec3\u6a21\u578b net . add ( ResNet50 ) # \u5c55\u5f00 net . add ( tf . keras . layers . Flatten ()) # \u4e8c\u5206\u7c7b\u7684\u5168\u8fde\u63a5\u5c42 net . add ( tf . keras . layers . Dense ( 2 , activation = 'softmax' )) \u63a5\u4e0b\u6765\u6211\u4eec\u4f7f\u7528\u4e4b\u524d\u5b9a\u4e49\u597d\u7684ImageGenerator\u5c06\u8bad\u7ec3\u96c6\u56fe\u7247\u9001\u5165ResNet50\u8fdb\u884c\u8bad\u7ec3\u3002 # \u6a21\u578b\u7f16\u8bd1\uff1a\u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 net . compile ( optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) # \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u6570\u636e\uff0c\u6bcf\u4e00\u4e2aepoch\u4e2d\u53ea\u8fd0\u884c10\u4e2a\u8fed\u4ee3\uff0c\u6307\u5b9a\u9a8c\u8bc1\u6570\u636e\u96c6 history = net . fit ( train_data_gen , steps_per_epoch = 10 , epochs = 3 , validation_data = test_data_gen , validation_steps = 10 ) Epoch 1 / 3 10 / 10 [ ============================== ] - 28 s 3 s / step - loss : 0.6931 - accuracy : 0.5031 - val_loss : 0.6930 - val_accuracy : 0.5094 Epoch 2 / 3 10 / 10 [ ============================== ] - 29 s 3 s / step - loss : 0.6932 - accuracy : 0.5094 - val_loss : 0.6935 - val_accuracy : 0.4812 Epoch 3 / 3 10 / 10 [ ============================== ] - 31 s 3 s / step - loss : 0.6935 - accuracy : 0.4844 - val_loss : 0.6933 - val_accuracy : 0.4875 \u603b\u7ed3 \u5fae\u8c03\u662f\u76ee\u6807\u6a21\u578b\u590d\u5236\u4e86\u6e90\u6a21\u578b\u4e0a\u9664\u4e86\u8f93\u51fa\u5c42\u5916\u7684\u6240\u6709\u6a21\u578b\u8bbe\u8ba1\u53ca\u5176\u53c2\u6570\uff0c\u5e76\u57fa\u4e8e\u76ee\u6807\u6570\u636e\u96c6\u5fae\u8c03\u8fd9\u4e9b\u53c2\u6570\u3002\u800c\u76ee\u6807\u6a21\u578b\u7684\u8f93\u51fa\u5c42\u9700\u8981\u4ece\u5934\u8bad\u7ec3\u3002 \u5229\u7528tf.keras\u4e2d\u7684application\u5b9e\u73b0\u8fc1\u79fb\u5b66\u4e60","title":"\u6a21\u578b\u5fae\u8c03"},{"location":"imageClassification/section7/#27","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u5fae\u8c03\u7684\u539f\u7406 \u80fd\u591f\u5229\u7528\u5fae\u8c03\u6a21\u578b\u6765\u5b8c\u6210\u56fe\u50cf\u7684\u5206\u7c7b\u4efb\u52a1","title":"2.7\u5fae\u8c03"},{"location":"imageClassification/section7/#1","text":"\u5982\u4f55\u5728\u53ea\u67096\u4e07\u5f20\u56fe\u50cf\u7684MNIST\u8bad\u7ec3\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6a21\u578b\u3002\u5b66\u672f\u754c\u5f53\u4e0b\u4f7f\u7528\u6700\u5e7f\u6cdb\u7684\u5927\u89c4\u6a21\u56fe\u50cf\u6570\u636e\u96c6ImageNet\uff0c\u5b83\u6709\u8d85\u8fc71,000\u4e07\u7684\u56fe\u50cf\u548c1,000\u7c7b\u7684\u7269\u4f53\u3002\u7136\u800c\uff0c\u6211\u4eec\u5e73\u5e38\u63a5\u89e6\u5230\u6570\u636e\u96c6\u7684\u89c4\u6a21\u901a\u5e38\u5728\u8fd9\u4e24\u8005\u4e4b\u95f4\u3002\u5047\u8bbe\u6211\u4eec\u60f3\u4ece\u56fe\u50cf\u4e2d\u8bc6\u522b\u51fa\u4e0d\u540c\u79cd\u7c7b\u7684\u6905\u5b50\uff0c\u7136\u540e\u5c06\u8d2d\u4e70\u94fe\u63a5\u63a8\u8350\u7ed9\u7528\u6237\u3002\u4e00\u79cd\u53ef\u80fd\u7684\u65b9\u6cd5\u662f\u5148\u627e\u51fa100\u79cd\u5e38\u89c1\u7684\u6905\u5b50\uff0c\u4e3a\u6bcf\u79cd\u6905\u5b50\u62cd\u64441,000\u5f20\u4e0d\u540c\u89d2\u5ea6\u7684\u56fe\u50cf\uff0c\u7136\u540e\u5728\u6536\u96c6\u5230\u7684\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u6a21\u578b\u3002\u53e6\u5916\u4e00\u79cd\u89e3\u51b3\u529e\u6cd5\u662f\u5e94\u7528\u8fc1\u79fb\u5b66\u4e60\uff08transfer learning\uff09\uff0c\u5c06\u4ece\u6e90\u6570\u636e\u96c6\u5b66\u5230\u7684\u77e5\u8bc6\u8fc1\u79fb\u5230\u76ee\u6807\u6570\u636e\u96c6\u4e0a\u3002\u4f8b\u5982\uff0c\u867d\u7136ImageNet\u6570\u636e\u96c6\u7684\u56fe\u50cf\u5927\u591a\u8ddf\u6905\u5b50\u65e0\u5173\uff0c\u4f46\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u53ef\u4ee5\u62bd\u53d6\u8f83\u901a\u7528\u7684\u56fe\u50cf\u7279\u5f81\uff0c\u4ece\u800c\u80fd\u591f\u5e2e\u52a9\u8bc6\u522b\u8fb9\u7f18\u3001\u7eb9\u7406\u3001\u5f62\u72b6\u548c\u7269\u4f53\u7ec4\u6210\u7b49\u3002\u8fd9\u4e9b\u7c7b\u4f3c\u7684\u7279\u5f81\u5bf9\u4e8e\u8bc6\u522b\u6905\u5b50\u4e5f\u53ef\u80fd\u540c\u6837\u6709\u6548\u3002 \u5fae\u8c03\u7531\u4ee5\u4e0b4\u6b65\u6784\u6210\u3002 \u5728\u6e90\u6570\u636e\u96c6\uff08\u5982ImageNet\u6570\u636e\u96c6\uff09\u4e0a\u9884\u8bad\u7ec3\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u5373\u6e90\u6a21\u578b\u3002 \u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u5373\u76ee\u6807\u6a21\u578b\u3002\u5b83\u590d\u5236\u4e86\u6e90\u6a21\u578b\u4e0a\u9664\u4e86\u8f93\u51fa\u5c42\u5916\u7684\u6240\u6709\u6a21\u578b\u8bbe\u8ba1\u53ca\u5176\u53c2\u6570\u3002\u6211\u4eec\u5047\u8bbe\u8fd9\u4e9b\u6a21\u578b\u53c2\u6570\u5305\u542b\u4e86\u6e90\u6570\u636e\u96c6\u4e0a\u5b66\u4e60\u5230\u7684\u77e5\u8bc6\uff0c\u4e14\u8fd9\u4e9b\u77e5\u8bc6\u540c\u6837\u9002\u7528\u4e8e\u76ee\u6807\u6570\u636e\u96c6\u3002\u6211\u4eec\u8fd8\u5047\u8bbe\u6e90\u6a21\u578b\u7684\u8f93\u51fa\u5c42\u8ddf\u6e90\u6570\u636e\u96c6\u7684\u6807\u7b7e\u7d27\u5bc6\u76f8\u5173\uff0c\u56e0\u6b64\u5728\u76ee\u6807\u6a21\u578b\u4e2d\u4e0d\u4e88\u91c7\u7528\u3002 \u4e3a\u76ee\u6807\u6a21\u578b\u6dfb\u52a0\u4e00\u4e2a\u8f93\u51fa\u5927\u5c0f\u4e3a\u76ee\u6807\u6570\u636e\u96c6\u7c7b\u522b\u4e2a\u6570\u7684\u8f93\u51fa\u5c42\uff0c\u5e76\u968f\u673a\u521d\u59cb\u5316\u8be5\u5c42\u7684\u6a21\u578b\u53c2\u6570\u3002 \u5728\u76ee\u6807\u6570\u636e\u96c6\uff08\u5982\u6905\u5b50\u6570\u636e\u96c6\uff09\u4e0a\u8bad\u7ec3\u76ee\u6807\u6a21\u578b\u3002\u6211\u4eec\u5c06\u4ece\u5934\u8bad\u7ec3\u8f93\u51fa\u5c42\uff0c\u800c\u5176\u4f59\u5c42\u7684\u53c2\u6570\u90fd\u662f\u57fa\u4e8e\u6e90\u6a21\u578b\u7684\u53c2\u6570\u5fae\u8c03\u5f97\u5230\u7684\u3002 \u5f53\u76ee\u6807\u6570\u636e\u96c6\u8fdc\u5c0f\u4e8e\u6e90\u6570\u636e\u96c6\u65f6\uff0c\u5fae\u8c03\u6709\u52a9\u4e8e\u63d0\u5347\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002","title":"1.\u5fae\u8c03"},{"location":"imageClassification/section7/#2","text":"\u63a5\u4e0b\u6765\u6211\u4eec\u6765\u5b9e\u8df5\u4e00\u4e2a\u5177\u4f53\u7684\u4f8b\u5b50\uff1a\u70ed\u72d7\u8bc6\u522b\u3002\u5c06\u57fa\u4e8e\u4e00\u4e2a\u5c0f\u6570\u636e\u96c6\u5bf9\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u597d\u7684ResNet\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002\u8be5\u5c0f\u6570\u636e\u96c6\u542b\u6709\u6570\u5343\u5f20\u70ed\u72d7\u6216\u8005\u5176\u4ed6\u4e8b\u7269\u7684\u56fe\u50cf\u3002\u6211\u4eec\u5c06\u4f7f\u7528\u5fae\u8c03\u5f97\u5230\u7684\u6a21\u578b\u6765\u8bc6\u522b\u4e00\u5f20\u56fe\u50cf\u4e2d\u662f\u5426\u5305\u542b\u70ed\u72d7\u3002 \u9996\u5148\uff0c\u5bfc\u5165\u5b9e\u9a8c\u6240\u9700\u7684\u5de5\u5177\u5305\u3002 import tensorflow as tf import numpy as np","title":"2.\u70ed\u72d7\u8bc6\u522b"},{"location":"imageClassification/section7/#21","text":"\u6211\u4eec\u9996\u5148\u5c06\u6570\u636e\u96c6\u653e\u5728\u8def\u5f84hotdog/data\u4e4b\u4e0b: \u6bcf\u4e2a\u7c7b\u522b\u6587\u4ef6\u5939\u91cc\u9762\u662f\u56fe\u50cf\u6587\u4ef6\u3002 \u4e0a\u4e00\u8282\u4e2d\u6211\u4eec\u4ecb\u7ecd\u4e86ImageDataGenerator\u8fdb\u884c\u56fe\u50cf\u589e\u5f3a\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u6cd5\u8bfb\u53d6\u56fe\u50cf\u6587\u4ef6\uff0c\u8be5\u65b9\u6cd5\u4ee5\u6587\u4ef6\u5939\u8def\u5f84\u4e3a\u53c2\u6570,\u751f\u6210\u7ecf\u8fc7\u56fe\u50cf\u589e\u5f3a\u540e\u7684\u7ed3\u679c\uff0c\u5e76\u4ea7\u751fbatch\u6570\u636e\uff1a flow_from_directory ( self , directory , target_size = ( 256 , 256 ), color_mode = 'rgb' , classes = None , class_mode = 'categorical' , batch_size = 32 , shuffle = True , seed = None , save_to_dir = None \uff09 \u4e3b\u8981\u53c2\u6570\uff1a directory: \u76ee\u6807\u6587\u4ef6\u5939\u8def\u5f84\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u7c7b\u5bf9\u5e94\u4e00\u4e2a\u5b50\u6587\u4ef6\u5939\uff0c\u8be5\u5b50\u6587\u4ef6\u5939\u4e2d\u4efb\u4f55JPG\u3001PNG\u3001BNP\u3001PPM\u7684\u56fe\u7247\u90fd\u53ef\u4ee5\u8bfb\u53d6\u3002 target_size: \u9ed8\u8ba4\u4e3a(256, 256)\uff0c\u56fe\u50cf\u5c06\u88abresize\u6210\u8be5\u5c3a\u5bf8\u3002 batch_size: batch\u6570\u636e\u7684\u5927\u5c0f\uff0c\u9ed8\u8ba432\u3002 shuffle: \u662f\u5426\u6253\u4e71\u6570\u636e\uff0c\u9ed8\u8ba4\u4e3aTrue\u3002 \u6211\u4eec\u521b\u5efa\u4e24\u4e2a tf.keras.preprocessing.image.ImageDataGenerator \u5b9e\u4f8b\u6765\u5206\u522b\u8bfb\u53d6\u8bad\u7ec3\u6570\u636e\u96c6\u548c\u6d4b\u8bd5\u6570\u636e\u96c6\u4e2d\u7684\u6240\u6709\u56fe\u50cf\u6587\u4ef6\u3002\u5c06\u8bad\u7ec3\u96c6\u56fe\u7247\u5168\u90e8\u5904\u7406\u4e3a\u9ad8\u548c\u5bbd\u5747\u4e3a224\u50cf\u7d20\u7684\u8f93\u5165\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5bf9RGB\uff08\u7ea2\u3001\u7eff\u3001\u84dd\uff09\u4e09\u4e2a\u989c\u8272\u901a\u9053\u7684\u6570\u503c\u505a\u6807\u51c6\u5316\u3002 # \u83b7\u53d6\u6570\u636e\u96c6 import pathlib train_dir = 'transferdata/train' test_dir = 'transferdata/test' # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e train_dir = pathlib . Path ( train_dir ) train_count = len ( list ( train_dir . glob ( '*/*.jpg' ))) # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e test_dir = pathlib . Path ( test_dir ) test_count = len ( list ( test_dir . glob ( '*/*.jpg' ))) # \u521b\u5efaimageDataGenerator\u8fdb\u884c\u56fe\u50cf\u5904\u7406 image_generator = tf . keras . preprocessing . image . ImageDataGenerator ( rescale = 1. / 255 ) # \u8bbe\u7f6e\u53c2\u6570 BATCH_SIZE = 32 IMG_HEIGHT = 224 IMG_WIDTH = 224 # \u83b7\u53d6\u8bad\u7ec3\u6570\u636e train_data_gen = image_generator . flow_from_directory ( directory = str ( train_dir ), batch_size = BATCH_SIZE , target_size = ( IMG_HEIGHT , IMG_WIDTH ), shuffle = True ) # \u83b7\u53d6\u6d4b\u8bd5\u6570\u636e test_data_gen = image_generator . flow_from_directory ( directory = str ( test_dir ), batch_size = BATCH_SIZE , target_size = ( IMG_HEIGHT , IMG_WIDTH ), shuffle = True ) \u4e0b\u9762\u6211\u4eec\u968f\u673a\u53d61\u4e2abatch\u7684\u56fe\u7247\u7136\u540e\u7ed8\u5236\u51fa\u6765\u3002 import matplotlib.pyplot as plt # \u663e\u793a\u56fe\u50cf def show_batch ( image_batch , label_batch ): plt . figure ( figsize = ( 10 , 10 )) for n in range ( 15 ): ax = plt . subplot ( 5 , 5 , n + 1 ) plt . imshow ( image_batch [ n ] \uff09 plt . axis ( 'off' ) # \u968f\u673a\u9009\u62e9\u4e00\u4e2abatch\u7684\u56fe\u50cf image_batch , label_batch = next ( train_data_gen ) # \u56fe\u50cf\u663e\u793a show_batch ( image_batch , label_batch )","title":"2.1 \u83b7\u53d6\u6570\u636e\u96c6"},{"location":"imageClassification/section7/#22","text":"\u6211\u4eec\u4f7f\u7528\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u7684ResNet-50\u4f5c\u4e3a\u6e90\u6a21\u578b\u3002\u8fd9\u91cc\u6307\u5b9a weights='imagenet' \u6765\u81ea\u52a8\u4e0b\u8f7d\u5e76\u52a0\u8f7d\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u53c2\u6570\u3002\u5728\u7b2c\u4e00\u6b21\u4f7f\u7528\u65f6\u9700\u8981\u8054\u7f51\u4e0b\u8f7d\u6a21\u578b\u53c2\u6570\u3002 Keras\u5e94\u7528\u7a0b\u5e8f\uff08keras.applications\uff09\u662f\u5177\u6709\u9884\u5148\u8bad\u7ec3\u6743\u503c\u7684\u56fa\u5b9a\u67b6\u6784\uff0c\u8be5\u7c7b\u5c01\u88c5\u4e86\u5f88\u591a\u91cd\u91cf\u7ea7\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5b9e\u73b0\u65f6\u5b9e\u4f8b\u5316\u6a21\u578b\u67b6\u6784\uff1a tf . keras . applications . ResNet50 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , ** kwargs ) \u4e3b\u8981\u53c2\u6570\uff1a include_top: \u662f\u5426\u5305\u62ec\u9876\u5c42\u7684\u5168\u8fde\u63a5\u5c42\u3002 weights: None \u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\uff0c 'imagenet' \u4ee3\u8868\u52a0\u8f7d\u5728 ImageNet \u4e0a\u9884\u8bad\u7ec3\u7684\u6743\u503c\u3002 input_shape: \u53ef\u9009\uff0c\u8f93\u5165\u5c3a\u5bf8\u5143\u7ec4\uff0c\u4ec5\u5f53 include_top=False \u65f6\u6709\u6548\uff0c\u5426\u5219\u8f93\u5165\u5f62\u72b6\u5fc5\u987b\u662f (224, 224, 3)\uff08channels_last \u683c\u5f0f\uff09\u6216 (3, 224, 224)\uff08channels_first \u683c\u5f0f\uff09\u3002\u5b83\u5fc5\u987b\u4e3a 3 \u4e2a\u8f93\u5165\u901a\u9053\uff0c\u4e14\u5bbd\u9ad8\u5fc5\u987b\u4e0d\u5c0f\u4e8e 32\uff0c\u6bd4\u5982 (200, 200, 3) \u662f\u4e00\u4e2a\u5408\u6cd5\u7684\u8f93\u5165\u5c3a\u5bf8\u3002 \u5728\u8be5\u6848\u4f8b\u4e2d\u6211\u4eec\u4f7f\u7528resNet50\u9884\u8bad\u7ec3\u6a21\u578b\u6784\u5efa\u6a21\u578b\uff1a # \u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b ResNet50 = tf . keras . applications . ResNet50 ( weights = 'imagenet' , input_shape = ( 224 , 224 , 3 )) # \u8bbe\u7f6e\u6240\u6709\u5c42\u4e0d\u53ef\u8bad\u7ec3 for layer in ResNet50 . layers : layer . trainable = False # \u8bbe\u7f6e\u6a21\u578b net = tf . keras . models . Sequential () # \u9884\u8bad\u7ec3\u6a21\u578b net . add ( ResNet50 ) # \u5c55\u5f00 net . add ( tf . keras . layers . Flatten ()) # \u4e8c\u5206\u7c7b\u7684\u5168\u8fde\u63a5\u5c42 net . add ( tf . keras . layers . Dense ( 2 , activation = 'softmax' )) \u63a5\u4e0b\u6765\u6211\u4eec\u4f7f\u7528\u4e4b\u524d\u5b9a\u4e49\u597d\u7684ImageGenerator\u5c06\u8bad\u7ec3\u96c6\u56fe\u7247\u9001\u5165ResNet50\u8fdb\u884c\u8bad\u7ec3\u3002 # \u6a21\u578b\u7f16\u8bd1\uff1a\u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 net . compile ( optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) # \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u6570\u636e\uff0c\u6bcf\u4e00\u4e2aepoch\u4e2d\u53ea\u8fd0\u884c10\u4e2a\u8fed\u4ee3\uff0c\u6307\u5b9a\u9a8c\u8bc1\u6570\u636e\u96c6 history = net . fit ( train_data_gen , steps_per_epoch = 10 , epochs = 3 , validation_data = test_data_gen , validation_steps = 10 ) Epoch 1 / 3 10 / 10 [ ============================== ] - 28 s 3 s / step - loss : 0.6931 - accuracy : 0.5031 - val_loss : 0.6930 - val_accuracy : 0.5094 Epoch 2 / 3 10 / 10 [ ============================== ] - 29 s 3 s / step - loss : 0.6932 - accuracy : 0.5094 - val_loss : 0.6935 - val_accuracy : 0.4812 Epoch 3 / 3 10 / 10 [ ============================== ] - 31 s 3 s / step - loss : 0.6935 - accuracy : 0.4844 - val_loss : 0.6933 - val_accuracy : 0.4875 \u603b\u7ed3 \u5fae\u8c03\u662f\u76ee\u6807\u6a21\u578b\u590d\u5236\u4e86\u6e90\u6a21\u578b\u4e0a\u9664\u4e86\u8f93\u51fa\u5c42\u5916\u7684\u6240\u6709\u6a21\u578b\u8bbe\u8ba1\u53ca\u5176\u53c2\u6570\uff0c\u5e76\u57fa\u4e8e\u76ee\u6807\u6570\u636e\u96c6\u5fae\u8c03\u8fd9\u4e9b\u53c2\u6570\u3002\u800c\u76ee\u6807\u6a21\u578b\u7684\u8f93\u51fa\u5c42\u9700\u8981\u4ece\u5934\u8bad\u7ec3\u3002 \u5229\u7528tf.keras\u4e2d\u7684application\u5b9e\u73b0\u8fc1\u79fb\u5b66\u4e60","title":"2.2 \u6a21\u578b\u6784\u5efa\u4e0e\u8bad\u7ec3"},{"location":"imageSegmentation/","text":"\u76ee\u6807\u5206\u5272(Object Segmentation) \u00b6","title":"\u76ee\u6807\u5206\u5272(Object Segmentation)"},{"location":"imageSegmentation/#object-segmentation","text":"","title":"\u76ee\u6807\u5206\u5272(Object Segmentation)"},{"location":"imageSegmentation/section1/","text":"5.1 \u56fe\u50cf\u5206\u5272 \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u56fe\u50cf\u5206\u5272\u7684\u76ee\u7684 \u77e5\u9053\u56fe\u50cf\u5206\u5272\u7684\u4efb\u52a1\u7c7b\u578b \u77e5\u9053\u56fe\u50cf\u5206\u5272\u7684\u5e38\u89c1\u6570\u636e\u96c6 \u77e5\u9053\u56fe\u50cf\u5206\u5272\u7684\u8bc4\u4f30\u65b9\u6cd5 \u8ba1\u7b97\u673a\u89c6\u89c9\u65e8\u5728\u8bc6\u522b\u548c\u7406\u89e3\u56fe\u50cf\u4e2d\u7684\u5185\u5bb9\uff0c\u5305\u542b\u4e09\u5927\u57fa\u672c\u4efb\u52a1\uff1a\u56fe\u50cf\u5206\u7c7b(\u56fea)\u3001\u76ee\u6807\u68c0\u6d4b(\u56feb)\u548c\u56fe\u50cf\u5206\u5272,\u5176\u4e2d\u56fe\u50cf\u5206\u5272\u53c8\u53ef\u5206\u4e3a\uff1a\u8bed\u4e49\u5206\u5272(\u56fec)\u548c\u5b9e\u4f8b\u5206\u5272(\u56fed)\u3002 \u8fd9\u4e09\u4e2a\u4efb\u52a1\u5bf9\u56fe\u50cf\u7684\u7406\u89e3\u9010\u6b65\u6df1\u5165\u3002\u5047\u8bbe\u7ed9\u5b9a\u4e00\u5f20\u8f93\u5165\u56fe\u50cf\uff0c \u56fe\u50cf\u5206\u7c7b\u65e8\u5728\u5224\u65ad\u8be5\u56fe\u50cf\u6240\u5c5e\u7c7b\u522b\u3002 \u76ee\u6807\u68c0\u6d4b\u662f\u5728\u56fe\u50cf\u5206\u7c7b\u7684\u57fa\u7840\u4e0a\uff0c\u8fdb\u4e00\u6b65\u5224\u65ad\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u5177\u4f53\u5728\u56fe\u50cf\u7684\u4ec0\u4e48\u4f4d\u7f6e\uff0c\u901a\u5e38\u662f\u4ee5\u5916\u5305\u77e9\u5f62(bounding box)\u7684\u5f62\u5f0f\u8868\u793a\u3002 \u56fe\u50cf\u5206\u5272\u662f\u76ee\u6807\u68c0\u6d4b\u66f4\u8fdb\u9636\u7684\u4efb\u52a1\uff0c\u76ee\u6807\u68c0\u6d4b\u53ea\u9700\u8981\u6846\u51fa\u6bcf\u4e2a\u76ee\u6807\u7684\u5305\u56f4\u76d2\uff0c\u8bed\u4e49\u5206\u5272\u9700\u8981\u8fdb\u4e00\u6b65\u5224\u65ad\u56fe\u50cf\u4e2d\u54ea\u4e9b\u50cf\u7d20\u5c5e\u4e8e\u54ea\u4e2a\u76ee\u6807\u3002\u4f46\u662f\uff0c\u8bed\u4e49\u5206\u5272\u4e0d\u533a\u5206\u5c5e\u4e8e\u76f8\u540c\u7c7b\u522b\u7684\u4e0d\u540c\u5b9e\u4f8b\u3002\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u5f53\u56fe\u50cf\u4e2d\u6709\u591a\u4e2acube\u65f6\uff0c\u8bed\u4e49\u5206\u5272\u4f1a\u5c06\u6240\u6709\u7acb\u65b9\u4f53\u6574\u4f53\u7684\u6240\u6709\u50cf\u7d20\u9884\u6d4b\u4e3a\u201ccube\u201d\u8fd9\u4e2a\u7c7b\u522b\u3002\u4e0e\u6b64\u4e0d\u540c\u7684\u662f\uff0c**\u5b9e\u4f8b\u5206\u5272**\u9700\u8981\u533a\u5206\u51fa\u54ea\u4e9b\u50cf\u7d20\u5c5e\u4e8e\u7b2c\u4e00\u4e2acube\u3001\u54ea\u4e9b\u50cf\u7d20\u5c5e\u4e8e\u7b2c\u4e8c\u4e2acube\u2026\u2026\u3002 1.1 \u56fe\u50cf\u5206\u5272\u7684\u5b9a\u4e49 \u00b6 \u5b9a\u4e49\uff1a\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\uff0c\u56fe\u50cf\u5206\u5272\uff08Object Segmentation\uff09\u6307\u7684\u662f\u5c06\u6570\u5b57\u56fe\u50cf\u7ec6\u5206\u4e3a\u591a\u4e2a\u56fe\u50cf\u5b50\u533a\u57df\uff08\u50cf\u7d20\u7684\u96c6\u5408\uff09\u7684\u8fc7\u7a0b\uff0c\u5e76\u4e14\u540c\u4e00\u4e2a\u5b50\u533a\u57df\u5185\u7684\u7279\u5f81\u5177\u6709\u4e00\u5b9a\u76f8\u4f3c\u6027\uff0c\u4e0d\u540c\u5b50\u533a\u57df\u7684\u7279\u5f81\u5448\u73b0\u8f83\u4e3a\u660e\u663e\u7684\u5dee\u5f02\u3002 \u56fe\u50cf\u5206\u5272\u7684\u76ee\u6807\u5c31\u662f\u4e3a\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e2a\u50cf\u7d20\u5206\u7c7b\u3002\u5e94\u7528\u9886\u57df\u975e\u5e38\u7684\u5e7f\u6cdb\uff1a\u81ea\u52a8\u9a7e\u9a76\u3001\u533b\u7597\u5f71\u50cf\uff0c\u56fe\u50cf\u7f8e\u5316\u3001\u4e09\u7ef4\u91cd\u5efa\u7b49\u7b49\u3002 \u81ea\u52a8\u9a7e\u9a76\uff08Autonomous vehicles\uff09\uff1a\u6c7d\u8f66\u9700\u8981\u5b89\u88c5\u5fc5\u8981\u7684\u611f\u77e5\u7cfb\u7edf\u4ee5\u4e86\u89e3\u5b83\u4eec\u7684\u73af\u5883\uff0c\u8fd9\u6837\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u624d\u80fd\u591f\u5b89\u5168\u5730\u9a76\u5165\u73b0\u6709\u7684\u9053\u8def \u533b\u7597\u5f71\u50cf\u8bca\u65ad\uff08Medical image diagnostics\uff09\uff1a\u673a\u5668\u5728\u5206\u6790\u80fd\u529b\u4e0a\u6bd4\u653e\u5c04\u79d1\u533b\u751f\u66f4\u5f3a\uff0c\u800c\u4e14\u53ef\u4ee5\u5927\u5927\u51cf\u5c11\u8bca\u65ad\u6240\u9700\u65f6\u95f4\u3002 \u56fe\u50cf\u5206\u5272\u662f\u4e00\u4e2a\u975e\u5e38\u56f0\u96be\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u6df1\u5ea6\u5b66\u4e60\u4e4b\u524d\u3002\u6df1\u5ea6\u5b66\u4e60\u4f7f\u5f97\u56fe\u50cf\u5206\u5272\u7684\u51c6\u786e\u7387\u63d0\u9ad8\u4e86\u5f88\u591a\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u4e3b\u8981\u56f4\u7ed5\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7ed9\u5927\u5bb6\u4ecb\u7ecd\u56fe\u50cf\u5206\u5272\u7684\u5185\u5bb9\u3002 1.2 \u4efb\u52a1\u7c7b\u578b \u00b6 1.2.1 \u4efb\u52a1\u63cf\u8ff0 \u00b6 \u7b80\u5355\u6765\u8bf4\uff0c\u6211\u4eec\u7684\u76ee\u6807\u662f\u8f93\u5165\u4e00\u4e2aRGB\u5f69\u8272\u56fe\u7247 \uff08height\u00d7width\u00d73\uff09 \uff08height\u00d7width\u00d73\uff09 \u6216\u8005\u4e00\u4e2a\u7070\u5ea6\u56fe \uff08height\u00d7width\u00d71\uff09 \uff08height\u00d7width\u00d71\uff09 \uff0c\u7136\u540e\u8f93\u51fa\u4e00\u4e2a\u5305\u542b\u5404\u4e2a\u50cf\u7d20\u7c7b\u522b\u6807\u7b7e\u7684\u5206\u5272\u56fe \uff08height\u00d7width\u00d71\uff09 \uff08height\u00d7width\u00d71\uff09 \u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4e0e\u6211\u4eec\u5904\u7406\u5206\u7c7b\u503c\u7684\u65b9\u5f0f\u7c7b\u4f3c\uff0c\u9884\u6d4b\u76ee\u6807\u53ef\u4ee5\u91c7\u7528one-hot\u7f16\u7801\uff0c\u5373\u4e3a\u6bcf\u4e00\u4e2a\u53ef\u80fd\u7684\u7c7b\u521b\u5efa\u4e00\u4e2a\u8f93\u51fa\u901a\u9053\u3002\u901a\u8fc7\u53d6\u6bcf\u4e2a\u50cf\u7d20\u70b9\u5728\u5404\u4e2achannel\u7684argmax\u53ef\u4ee5\u5f97\u5230\u6700\u7ec8\u7684\u9884\u6d4b\u5206\u5272\u56fe\uff0c\uff08\u5982\u4e0b\u56fe\u6240\u793a\uff09\uff1a \u6bd4\u5982\uff1aperson\u7684\u7f16\u7801\u4e3a\uff1a10000\uff0c\u800cGrass\u7684\u7f16\u7801\u4e3a\uff1a00100 \u5f53\u5c06\u9884\u6d4b\u7ed3\u679c\u53e0\u52a0\u5230\u5355\u4e2achannel\u65f6\uff0c\u79f0\u8fd9\u4e3a\u4e00\u4e2a\u63a9\u819cmask\uff0c\u5b83\u53ef\u4ee5\u7ed9\u51fa\u4e00\u5f20\u56fe\u50cf\u4e2d\u67d0\u4e2a\u7279\u5b9a\u7c7b\u7684\u6240\u5728\u533a\u57df\uff1a 1.2.2 \u4efb\u52a1\u7c7b\u578b \u00b6 \u76ee\u524d\u7684\u56fe\u50cf\u5206\u5272\u4efb\u52a1\u4e3b\u8981\u6709\u4e24\u7c7b\uff1a \u8bed\u4e49\u5206\u5272\u548c\u5b9e\u4f8b\u5206\u5272 \u6211\u4eec\u4ee5\u4e0b\u56fe\u4e3a\u4f8b\uff0c\u6765\u4ecb\u7ecd\u8fd9\u4e24\u79cd\u5206\u5272\u65b9\u5f0f\uff1a \u8bed\u4e49\u5206\u5272\u5c31\u662f\u628a\u56fe\u50cf\u4e2d\u6bcf\u4e2a\u50cf\u7d20\u8d4b\u4e88\u4e00\u4e2a\u7c7b\u522b\u6807\u7b7e\uff0c\u5982\u4e0b\u56fe\u6211\u4eec\u5c06\u56fe\u50cf\u4e2d\u7684\u50cf\u7d20\u5206\u7c7b\u4e3a\u4eba\uff0c\u7f8a\uff0c\u72d7\uff0c\u8349\u5730\u5373\u53ef\u3002 \u5b9e\u4f8b\u5206\u5272\uff0c\u76f8\u5bf9\u4e8e\u8bed\u4e49\u5206\u5272\u6765\u8bb2\uff0c\u4e0d\u4ec5\u8981\u533a\u5206\u4e0d\u540c\u7c7b\u522b\u7684\u50cf\u7d20\uff0c\u8fd8\u9700\u8981\u9700\u8981\u5bf9\u540c\u4e00\u7c7b\u522b\u7684\u4e0d\u540c\u4e2a\u4f53\u8fdb\u884c\u533a\u5206\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4e0d\u4ec5\u9700\u8981\u8fdb\u884c\u7c7b\u522b\u7684\u5212\u5206\uff0c\u8fd8\u8981\u5c06\u5404\u4e2a\u4e2a\u4f53\u5212\u5206\u51fa\u6765\uff1a\u7f8a1\uff0c\u7f8a2\uff0c\u7f8a3\uff0c\u7f8a4\uff0c\u7f8a5\u7b49\u3002 \u76ee\u524d\u56fe\u50cf\u5206\u5272\u7684\u4efb\u52a1\u4e3b\u8981\u96c6\u4e2d\u5728\u8bed\u4e49\u5206\u5272\uff0c\u800c\u76ee\u524d\u7684\u96be\u70b9\u4e5f\u5728\u4e8e\u201c\u8bed\u4e49\u201d\uff0c\u8868\u8fbe\u67d0\u4e00\u8bed\u4e49\u7684\u540c\u4e00\u7269\u4f53\u5e76\u4e0d\u603b\u662f\u4ee5\u76f8\u540c\u7684\u5f62\u8c61\u51fa\u73b0\uff0c\u5982\u5305\u542b\u4e0d\u540c\u7684\u989c\u8272\u3001\u7eb9\u7406\u7b49\uff0c\u8fd9\u5bf9\u7cbe\u786e\u5206\u5272\u5e26\u6765\u4e86\u5f88\u5927\u7684\u6311\u6218\u3002\u800c\u4e14\u4ee5\u76ee\u524d\u7684\u6a21\u578b\u8868\u73b0\u6765\u770b\uff0c\u5728\u51c6\u786e\u7387\u4e0a\u8fd8\u6709\u5f88\u5927\u7684\u63d0\u5347\u7a7a\u95f4\u3002\u800c\u5b9e\u4f8b\u5206\u5272\u7684\u601d\u8def\u4e3b\u8981\u662f\u76ee\u6807\u68c0\u6d4b+\u8bed\u4e49\u5206\u5272\uff0c\u5373\u7528\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u5c06\u56fe\u50cf\u4e2d\u7684\u4e0d\u540c\u5b9e\u4f8b\u6846\u51fa\uff0c\u518d\u7528\u8bed\u4e49\u5206\u5272\u65b9\u6cd5\u5728\u4e0d\u540c\u68c0\u6d4b\u7ed3\u679c\u5185\u8fdb\u884c\u9010\u50cf\u7d20\u6807\u8bb0\u3002 1.3 \u5e38\u7528\u7684\u5f00\u6e90\u6570\u636e\u96c6 \u00b6 \u56fe\u50cf\u5206\u5272\u5e38\u7528\u7684\u6570\u636e\u96c6\u662fPASCAL VOC\uff0c\u57ce\u5e02\u98ce\u5149\u6570\u636e\u96c6\uff0ccoco\u6570\u636e\u96c6\u7b49\u3002 1.3.1 VOC\u6570\u636e\u96c6 \u00b6 VOC\u6570\u636e\u96c6\u5171\u670920\u7c7b\u6570\u636e\uff0c\u76ee\u5f55\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8fd9\u4e2a\u5728\u76ee\u6807\u68c0\u6d4b\u6982\u8ff0\u4e00\u8282\u4e2d\u5df2\u7ecf\u7ed9\u5927\u5bb6\u4ecb\u7ecd\u8fc7\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecd\u76ee\u6807\u5206\u5272\u76f8\u5173\u7684\u5185\u5bb9\uff1a JPEGImages\u4e2d\u5b58\u653e\u56fe\u7247\u6587\u4ef6 \u0015\u0015imagesets\u4e2d\u7684segmentation\u4e2d\u8bb0\u5f55\u4e86\u7528\u4e8e\u5206\u5272\u7684\u56fe\u50cf\u4fe1\u606f SegmentationClass\u4e2d\u662f\u8bed\u4e49\u5206\u5272\u7684\u6807\u6ce8\u4fe1\u606f SegmentationObject\u4e2d\u662f\u5b9e\u4f8b\u5206\u5272\u7684\u6807\u6ce8\u4fe1\u606f VOC\u4e2d\u7684\u56fe\u7247\u5e76\u4e0d\u662f\u6240\u6709\u90fd\u7528\u4e8e\u5206\u5272\uff0c\u7528\u4e8e\u5206\u5272\u6bd4\u8d5b\u7684\u56fe\u7247\u5b9e\u4f8b\u90fd\u8bb0\u5f55\u5728txt\u6587\u4ef6\u4e2d\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u76f8\u5173\u7684\u56fe\u50cf\u8bb0\u5f55\u5728\u76f8\u5e94\u7684\u6587\u672c\u6587\u4ef6\u4e2d\uff0c\u5982\u8bad\u7ec3\u96c6\u6570\u636e\u8bb0\u5f55\u5728train.txt\u6587\u4ef6\u4e2d\uff0c\u5176\u4e2d\u5185\u5bb9\u5982\u4e0b\uff1a \u90a3\u6211\u4eec\u5c31\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e9b\u6570\u636e\u8fdb\u884c\u56fe\u50cf\u5206\u5272\u6a21\u578b\u7684\u8bad\u7ec3\u3002\u56fe\u50cf\u7684\u6807\u6ce8\u6548\u679c\u5982\u4e0b\u56fe\u6240\u793a: \u539f\u56fe\u50cf002378.jpg\u7684\u8bed\u4e49\u5206\u5272\u548c\u5b9e\u4f8b\u5206\u5272\u7684\u6807\u6ce8\u7ed3\u679c\u5982\u4e0a\u6240\u793a\uff0c\u80cc\u666f\u662f\u9ed1\u8272\u7684\uff0c\u4e0d\u540c\u7c7b\u522b\u7684\u50cf\u7d20\u6807\u6ce8\u4e3a\u4e0d\u540c\u7684\u989c\u8272\u3002\u53ef\u4ee5\u770b\u51fa\uff0c\u8bed\u4e49\u5206\u5272\u53ea\u6807\u6ce8\u4e86\u50cf\u7d20\u7684\u7c7b\u522b\uff0c\u800c\u5b9e\u4f8b\u5206\u5272\u4e0d\u4ec5\u6807\u6ce8\u4e86\u7c7b\u522b\uff0c\u8fd8\u5bf9\u540c\u4e00\u7c7b\u522b\u7684\u4e0d\u540c\u4e2a\u4f53\u8fdb\u884c\u4e86\u533a\u5206\u3002 \u5728\u5199\u7a0b\u5e8f\u7684\u65f6\u5019\u5c31\u5229\u7528 train.txt \u5bf9\u56fe\u7247\u8fdb\u884c\u6311\u9009\uff0c\u56e0\u4e3a\u4e0d\u662f\u6240\u6709\u7684\u56fe\u7247\u90fd\u6709\u5206\u5272\u771f\u5b9e\u503c\uff0c\u83b7\u53d6\u56fe\u7247\u53ca\u5176\u5bf9\u5e94\u7684\u771f\u5b9e\u503c\uff0c\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u5373\u53ef\u3002 1.3.2\u57ce\u5e02\u98ce\u5149Cityscapes\u6570\u636e\u96c6 \u00b6 Cityscapes\u662f\u7531\u5954\u9a70\u4e8e2015\u5e74\u63a8\u51fa\u7684\uff0c\u63d0\u4f9b\u65e0\u4eba\u9a7e\u9a76\u73af\u5883\u4e0b\u7684\u56fe\u50cf\u5206\u5272\u6570\u636e\u96c6\u3002\u5b83\u5305\u542b50\u4e2a\u57ce\u5e02\u4e0d\u540c\u573a\u666f\u3001\u4e0d\u540c\u80cc\u666f\u3001\u4e0d\u540c\u5b63\u8282\u7684\u8857\u666f\uff0c\u63d0\u4f9b\u4e865000\u5f20\u5728\u57ce\u5e02\u73af\u5883\u4e2d\u9a7e\u9a76\u573a\u666f\u7684\u9ad8\u8d28\u91cf\u50cf\u7d20\u7ea7\u6ce8\u91ca\u56fe\u50cf\uff08\u5176\u4e2d 2975 for train\uff0c500 for val\uff0c1525 for test\uff09\u3002 Cityscapes\u662f\u76ee\u524d\u516c\u8ba4\u7684\u81ea\u52a8\u9a7e\u9a76\u9886\u57df\u5185\u6700\u5177\u6743\u5a01\u6027\u548c\u4e13\u4e1a\u6027\u7684\u56fe\u50cf\u8bed\u4e49\u5206\u5272\u8bc4\u6d4b\u96c6\u4e4b\u4e00\uff0c\u5176\u5173\u6ce8\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u57ce\u533a\u9053\u8def\u73af\u5883\u7406\u89e3\uff0c\u4efb\u52a1\u96be\u5ea6\u66f4\u9ad8\u4e14\u66f4\u8d34\u8fd1\u4e8e\u81ea\u52a8\u9a7e\u9a76\u7b49\u70ed\u95e8\u9700\u6c42\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u770b\u4e0b\u6570\u636e\u7684\u5185\u5bb9\uff0c\u6570\u636e\u96c6\u7684\u6587\u4ef6\u76ee\u5f55\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5176\u4e2dtxt\u6587\u4ef6\u4e2d\u4fdd\u5b58\u4e86\u76f8\u5173\u6837\u672c\u56fe\u7247\u7684\u8def\u5f84\u548c\u6587\u4ef6\u540d\uff0c\u4fbf\u4e8e\u67e5\u627e\u76f8\u5e94\u7684\u6570\u636e\uff0c\u6211\u4eec\u4e3b\u8981\u4f7f\u7528\u6570\u636e\u662fleftImg8bit\u548cgtFine\u4e2d\u7684\u5185\u5bb9\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u0015leftImg8bit\u6587\u4ef6\u5939\u6709\u4e09\u4e2a\u5b50\u76ee\u5f55\uff1atest\uff0c train\u4ee5\u53caval\uff0c\u5206\u522b\u4e3a\u6d4b\u8bd5\u96c6\uff0c\u8bad\u7ec3\u96c6\u4ee5\u53ca\u9a8c\u8bc1\u96c6\u56fe\u7247\u3002\u8fd9\u4e09\u4e2a\u5b50\u76ee\u5f55\u7684\u56fe\u7247\u53c8\u4ee5\u57ce\u5e02\u4e3a\u5355\u5143\u6765\u5b58\u653e\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8fd9\u91cc\u89e3\u91ca\u4e0bleftImg8bit\u7684\u542b\u4e49\uff0c\u56e0\u4e3acityscapes\u5b9e\u9645\u4e0a\u6765\u6e90\u4e8e\u53cc\u6444\u50cf\u5934\u62cd\u6444\u7684\u7acb\u4f53\u89c6\u9891\u5e8f\u5217\uff0c\u6240\u4ee5\u8fd9\u91cc\u7684leftImg\u5c31\u662f\u6765\u81ea\u4e8e\u5de6\u6444\u50cf\u5934\u7684\u56fe\u7247\uff0c\u800c8bit\u610f\u5473\u7740\u8be5\u56fe\u7247\u96c6\u90fd\u4e3aRGB\u6bcf\u4e2a\u5206\u91cf\u4e3a8bit\u7684\u56fe\u7247\u3002 gtFine\u662f\u6837\u672c\u56fe\u7247\u5bf9\u5e94\u7684\u6807\u6ce8\u4fe1\u606f\uff0cgtFine\u4e0b\u9762\u4e5f\u662f\u5206\u4e3atrain\uff0c test\u4ee5\u53caval\uff0c\u7136\u540e\u5b83\u4eec\u7684\u5b50\u76ee\u5f55\u4e5f\u662f\u4ee5\u57ce\u5e02\u4e3a\u5355\u4f4d\u6765\u653e\u7f6e\u56fe\u7247\u3002\u8fd9\u4e9b\u90fd\u662f\u548cleftImg8bit\u7684\u4e00\u4e00\u5bf9\u5e94\u3002 \u4e0d\u540c\u7684\u662f\uff0c\u5728\u57ce\u5e02\u5b50\u76ee\u5f55\u4e0b\u9762\uff0c\u6bcf\u5f20\u6837\u672c\u56fe\u7247\u5bf9\u5e94\u67096\u4e2a\u6807\u6ce8\u6587\u4ef6\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u7cbe\u7ec6\u6807\u6ce8\u6570\u636e\u96c6\u91cc\u9762\u6bcf\u5f20\u56fe\u7247\u53ea\u5bf9\u5e94\u56db\u5f20\u6807\u6ce8\u6587\u4ef6\uff1axxx_gtFine_color.png, xxx_gtFine_instanceIds.png, xxx_gtFine_labelsIds.png\u4ee5\u53caxxx_gtFine_polygons.json\u3002 xxx_color.png\u662f\u6807\u6ce8\u7684\u53ef\u89c6\u5316\u56fe\u7247\uff0c\u771f\u6b63\u5bf9\u8bad\u7ec3\u6709\u7528\u7684\u662f\u540e\u9762\u4e09\u4e2a\u6587\u4ef6\u3002xxx_instanceIds.png\u662f\u7528\u6765\u505a\u5b9e\u4f8b\u5206\u5272\u8bad\u7ec3\u7528\u7684\uff0c\u800cxxx_labelsIds.png\u662f\u8bed\u4e49\u5206\u5272\u8bad\u7ec3\u9700\u8981\u7684\u3002\u800c\u6700\u540e\u4e00\u4e2a\u6587\u4ef6xxx_polygons.json\u4e3b\u8981\u8bb0\u5f55\u4e86\u6bcf\u4e2a\u591a\u8fb9\u5f62\u6807\u6ce8\u6846\u4e0a\u7684\u70b9\u96c6\u5750\u6807\u3002 \u8be5\u6570\u636e\u96c6\u7684\u6807\u6ce8\u6548\u679c\u53ef\u89c6\u5316\u5982\u4e0b\u6240\u793a\uff1a 1.4 \u8bc4\u4ef7\u6307\u6807 \u00b6 \u56fe\u50cf\u5206\u5272\u4e2d\u901a\u5e38\u4f7f\u7528\u8bb8\u591a\u6807\u51c6\u6765\u8861\u91cf\u7b97\u6cd5\u7684\u7cbe\u5ea6\u3002\u8fd9\u4e9b\u6807\u51c6\u901a\u5e38\u662f\u50cf\u7d20\u7cbe\u5ea6\u53caIoU\u7684\u53d8\u79cd\uff0c\u4ee5\u4e0b\u6211\u4eec\u5c06\u4f1a\u4ecb\u7ecd\u5e38\u7528\u7684\u51e0\u79cd\u9010\u50cf\u7d20\u6807\u8bb0\u7684\u7cbe\u5ea6\u6807\u51c6\u3002 \u4e3a\u4e86\u4fbf\u4e8e\u89e3\u91ca\uff0c\u5047\u8bbe\u5982\u4e0b\uff1a\u5171\u6709 k+1 k+1 \u4e2a\u7c7b\uff08\u4ece L_0 L_0 \u5230 L_k L_k \uff0c\u5176\u4e2d\u5305\u542b\u4e00\u4e2a\u80cc\u666f\u7c7b\uff09\uff0c p_{ij} p_{ij} \u8868\u793a\u672c\u5c5e\u4e8e\u7c7b i i \u4f46\u88ab\u9884\u6d4b\u4e3a\u7c7b j j \u7684\u50cf\u7d20\u3002\u5373 p_{ii} p_{ii} \u8868\u793a\u9884\u6d4b\u6b63\u786e\u7684\u50cf\u7d20\u3002 1.4.1 \u50cf\u7d20\u7cbe\u5ea6 \u00b6 Pixel Accuracy(PA\uff0c\u50cf\u7d20\u7cbe\u5ea6)\uff1a\u8fd9\u662f\u6700\u7b80\u5355\u7684\u5ea6\u91cf\uff0c\u4e3a\u9884\u6d4b\u6b63\u786e\u7684\u50cf\u7d20\u5360\u603b\u50cf\u7d20\u7684\u6bd4\u4f8b\u3002 \u5bf9\u4e8e\u6837\u672c\u4e0d\u5747\u8861\u7684\u60c5\u51b5\uff0c\u4f8b\u5982\u533b\u5b66\u56fe\u50cf\u5206\u5272\u4e2d\uff0c\u80cc\u666f\u4e0e\u6807\u8bb0\u6837\u672c\u4e4b\u95f4\u7684\u6bd4\u4f8b\u5f80\u5f80\u4e25\u91cd\u5931\u8861\u3002\u56e0\u6b64\u5e76\u4e0d\u9002\u5408\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\u8fdb\u884c\u5ea6\u91cf\u3002 1.4.2 \u5e73\u5747\u50cf\u7d20\u7cbe\u5ea6 \u00b6 Mean Pixel Accuracy(MPA\uff0c\u5e73\u5747\u50cf\u7d20\u7cbe\u5ea6)\uff1a\u662fPA\u7684\u4e00\u79cd\u7b80\u5355\u63d0\u5347\uff0c\u8ba1\u7b97\u6bcf\u4e2a**\u7c7b\u5185**\u88ab\u6b63\u786e\u5206\u7c7b\u50cf\u7d20\u6570\u7684\u6bd4\u4f8b\uff0c\u4e4b\u540e\u6c42\u6240\u6709\u7c7b\u7684\u5e73\u5747\u3002 1.4.3 \u5e73\u5747\u4ea4\u5e76\u6bd4 \u00b6 Mean Intersection over Union(MIoU\uff0c\u5e73\u5747\u4ea4\u5e76\u6bd4)\uff1a\u4e3a\u8bed\u4e49\u5206\u5272\u7684\u6807\u51c6\u5ea6\u91cf\uff0c\u5176\u8ba1\u7b97\u4e24\u4e2a\u96c6\u5408\u7684\u4ea4\u96c6\u548c\u5e76\u96c6\u4e4b\u6bd4\uff0c\u5728\u8bed\u4e49\u5206\u5272\u7684\u95ee\u9898\u4e2d\uff0c\u8fd9\u4e24\u4e2a\u96c6\u5408\u4e3a\u771f\u5b9e\u503c\uff08ground truth\uff09\u548c\u9884\u6d4b\u503c\uff08predicted segmentation\uff09\u3002\u4ea4\u96c6\u4e3a\u9884\u6d4b\u6b63\u786e\u7684\u50cf\u7d20\u6570\uff08intersection\uff09\uff0c\u5e76\u96c6\u4e3a\u9884\u6d4b\u6216\u771f\u5b9e\u503c\u4e3a i i \u7c7b\u7684\u548c\u51cf\u53bb\u9884\u6d4b\u6b63\u786e\u7684\u50cf\u7d20\uff0c\u5728\u6bcf\u4e2a\u7c7b\u4e0a\u8ba1\u7b97IoU\uff0c\u4e4b\u540e\u6c42\u5e73\u5747\u5373\u53ef\u3002 \u90a3\u4e48\uff0c\u5982\u4f55\u7406\u89e3\u8fd9\u91cc\u7684\u516c\u5f0f\u5462\uff1f\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u7ea2\u8272\u5706\u4ee3\u8868\u771f\u5b9e\u503c\uff0c\u9ec4\u8272\u5706\u4ee3\u8868\u9884\u6d4b\u503c\u3002\u6a59\u8272\u90e8\u5206\u7ea2\u8272\u5706\u4e0e\u9ec4\u8272\u5706\u7684\u4ea4\u96c6\uff0c\u5373\u9884\u6d4b\u6b63\u786e\u7684\u90e8\u5206\uff0c\u7ea2\u8272\u90e8\u5206\u8868\u793a\u5047\u8d1f\uff08\u771f\u5b9e\u503c\u4e3a\u8be5\u7c7b\u9884\u6d4b\u9519\u8bef\uff09\u7684\u90e8\u5206\uff0c\u9ec4\u8272\u8868\u793a\u5047\u6b63\uff08\u9884\u6d4b\u503c\u4e3ai\u7c7b\uff0c\u771f\u5b9e\u503c\u4e3a\u5176\u4ed6\uff09\u7684\u90e8\u5206\u3002 MIoU\u8ba1\u7b97\u7684\u662f\u8ba1\u7b97A\u4e0eB\u7684\u4ea4\u96c6\uff08\u6a59\u8272\u90e8\u5206\uff09\u4e0eA\u4e0eB\u7684\u5e76\u96c6\uff08\u7ea2\u8272+\u6a59\u8272+\u9ec4\u8272\uff09\u4e4b\u95f4\u7684\u6bd4\u4f8b\uff0c\u5728\u7406\u60f3\u72b6\u6001\u4e0bA\u4e0eB\u91cd\u5408\uff0c\u4e24\u8005\u6bd4\u4f8b\u4e3a1 \u3002 \u5728\u4ee5\u4e0a\u6240\u6709\u7684\u5ea6\u91cf\u6807\u51c6\u4e2d\uff0cMIoU\u7531\u4e8e\u5176\u7b80\u6d01\u3001\u4ee3\u8868\u6027\u5f3a\u800c\u6210\u4e3a\u6700\u5e38\u7528\u7684\u5ea6\u91cf\u6807\u51c6\uff0c\u5927\u591a\u6570\u7814\u7a76\u4eba\u5458\u90fd\u4f7f\u7528\u8be5\u6807\u51c6\u62a5\u544a\u5176\u7ed3\u679c\u3002PA\u5bf9\u4e8e\u6837\u672c\u4e0d\u5747\u8861\u7684\u60c5\u51b5\u4e0d\u9002\u7528\u3002 \u603b\u7ed3 \u56fe\u50cf\u5206\u5272\u7684\u5b9a\u4e49 \u56fe\u50cf\u5206\u5272\uff08Object Segmentation\uff09\u6307\u7684\u662f\u5c06\u6570\u5b57\u56fe\u50cf\u7ec6\u5206\u4e3a\u591a\u4e2a\u56fe\u50cf\u5b50\u533a\u57df\uff08\u50cf\u7d20\u7684\u96c6\u5408\uff09\u7684\u8fc7\u7a0b\uff0c\u5e76\u4e14\u540c\u4e00\u4e2a\u5b50\u533a\u57df\u5185\u7684\u7279\u5f81\u5177\u6709\u4e00\u5b9a\u76f8\u4f3c\u6027\uff0c\u4e0d\u540c\u5b50\u533a\u57df\u7684\u7279\u5f81\u5448\u73b0\u8f83\u4e3a\u660e\u663e\u7684\u5dee\u5f02\u3002 \u56fe\u50cf\u5206\u5272\u7684\u4efb\u52a1\u7c7b\u578b \u56fe\u50cf\u5206\u5272\u7684\u4efb\u52a1\u5c31\u662f\u7ed9\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e00\u4e2a\u50cf\u7d20\u70b9\u8fdb\u884c\u5206\u7c7b \u8bed\u4e49\u5206\u5272\u548c\u5b9e\u4f8b\u5206\u5272 \u56fe\u50cf\u5206\u5272\u7684\u5e38\u89c1\u6570\u636e\u96c6 Voc \u6570\u636e\u96c6\uff0c\u57ce\u5e02\u98ce\u5149\u6570\u636e\u96c6\uff0ccoco\u6570\u636e\u96c6\u7b49 \u56fe\u50cf\u5206\u5272\u7684\u8bc4\u4f30\u6307\u6807 \u50cf\u7d20\u7cbe\u5ea6\uff08PA\uff09\uff0c\u5e73\u5747\u50cf\u7d20\u7cbe\u5ea6\uff08mPA\uff09\u548c \u5e73\u5747\u4ea4\u5e76\u6bd4\uff08mIOU\uff09 \u6700\u5e38\u7528\u7684\u662fMIOU","title":"\u76ee\u6807\u5206\u5272\u4ecb\u7ecd"},{"location":"imageSegmentation/section1/#51","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u56fe\u50cf\u5206\u5272\u7684\u76ee\u7684 \u77e5\u9053\u56fe\u50cf\u5206\u5272\u7684\u4efb\u52a1\u7c7b\u578b \u77e5\u9053\u56fe\u50cf\u5206\u5272\u7684\u5e38\u89c1\u6570\u636e\u96c6 \u77e5\u9053\u56fe\u50cf\u5206\u5272\u7684\u8bc4\u4f30\u65b9\u6cd5 \u8ba1\u7b97\u673a\u89c6\u89c9\u65e8\u5728\u8bc6\u522b\u548c\u7406\u89e3\u56fe\u50cf\u4e2d\u7684\u5185\u5bb9\uff0c\u5305\u542b\u4e09\u5927\u57fa\u672c\u4efb\u52a1\uff1a\u56fe\u50cf\u5206\u7c7b(\u56fea)\u3001\u76ee\u6807\u68c0\u6d4b(\u56feb)\u548c\u56fe\u50cf\u5206\u5272,\u5176\u4e2d\u56fe\u50cf\u5206\u5272\u53c8\u53ef\u5206\u4e3a\uff1a\u8bed\u4e49\u5206\u5272(\u56fec)\u548c\u5b9e\u4f8b\u5206\u5272(\u56fed)\u3002 \u8fd9\u4e09\u4e2a\u4efb\u52a1\u5bf9\u56fe\u50cf\u7684\u7406\u89e3\u9010\u6b65\u6df1\u5165\u3002\u5047\u8bbe\u7ed9\u5b9a\u4e00\u5f20\u8f93\u5165\u56fe\u50cf\uff0c \u56fe\u50cf\u5206\u7c7b\u65e8\u5728\u5224\u65ad\u8be5\u56fe\u50cf\u6240\u5c5e\u7c7b\u522b\u3002 \u76ee\u6807\u68c0\u6d4b\u662f\u5728\u56fe\u50cf\u5206\u7c7b\u7684\u57fa\u7840\u4e0a\uff0c\u8fdb\u4e00\u6b65\u5224\u65ad\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u5177\u4f53\u5728\u56fe\u50cf\u7684\u4ec0\u4e48\u4f4d\u7f6e\uff0c\u901a\u5e38\u662f\u4ee5\u5916\u5305\u77e9\u5f62(bounding box)\u7684\u5f62\u5f0f\u8868\u793a\u3002 \u56fe\u50cf\u5206\u5272\u662f\u76ee\u6807\u68c0\u6d4b\u66f4\u8fdb\u9636\u7684\u4efb\u52a1\uff0c\u76ee\u6807\u68c0\u6d4b\u53ea\u9700\u8981\u6846\u51fa\u6bcf\u4e2a\u76ee\u6807\u7684\u5305\u56f4\u76d2\uff0c\u8bed\u4e49\u5206\u5272\u9700\u8981\u8fdb\u4e00\u6b65\u5224\u65ad\u56fe\u50cf\u4e2d\u54ea\u4e9b\u50cf\u7d20\u5c5e\u4e8e\u54ea\u4e2a\u76ee\u6807\u3002\u4f46\u662f\uff0c\u8bed\u4e49\u5206\u5272\u4e0d\u533a\u5206\u5c5e\u4e8e\u76f8\u540c\u7c7b\u522b\u7684\u4e0d\u540c\u5b9e\u4f8b\u3002\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u5f53\u56fe\u50cf\u4e2d\u6709\u591a\u4e2acube\u65f6\uff0c\u8bed\u4e49\u5206\u5272\u4f1a\u5c06\u6240\u6709\u7acb\u65b9\u4f53\u6574\u4f53\u7684\u6240\u6709\u50cf\u7d20\u9884\u6d4b\u4e3a\u201ccube\u201d\u8fd9\u4e2a\u7c7b\u522b\u3002\u4e0e\u6b64\u4e0d\u540c\u7684\u662f\uff0c**\u5b9e\u4f8b\u5206\u5272**\u9700\u8981\u533a\u5206\u51fa\u54ea\u4e9b\u50cf\u7d20\u5c5e\u4e8e\u7b2c\u4e00\u4e2acube\u3001\u54ea\u4e9b\u50cf\u7d20\u5c5e\u4e8e\u7b2c\u4e8c\u4e2acube\u2026\u2026\u3002","title":"5.1 \u56fe\u50cf\u5206\u5272"},{"location":"imageSegmentation/section1/#11","text":"\u5b9a\u4e49\uff1a\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\uff0c\u56fe\u50cf\u5206\u5272\uff08Object Segmentation\uff09\u6307\u7684\u662f\u5c06\u6570\u5b57\u56fe\u50cf\u7ec6\u5206\u4e3a\u591a\u4e2a\u56fe\u50cf\u5b50\u533a\u57df\uff08\u50cf\u7d20\u7684\u96c6\u5408\uff09\u7684\u8fc7\u7a0b\uff0c\u5e76\u4e14\u540c\u4e00\u4e2a\u5b50\u533a\u57df\u5185\u7684\u7279\u5f81\u5177\u6709\u4e00\u5b9a\u76f8\u4f3c\u6027\uff0c\u4e0d\u540c\u5b50\u533a\u57df\u7684\u7279\u5f81\u5448\u73b0\u8f83\u4e3a\u660e\u663e\u7684\u5dee\u5f02\u3002 \u56fe\u50cf\u5206\u5272\u7684\u76ee\u6807\u5c31\u662f\u4e3a\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e2a\u50cf\u7d20\u5206\u7c7b\u3002\u5e94\u7528\u9886\u57df\u975e\u5e38\u7684\u5e7f\u6cdb\uff1a\u81ea\u52a8\u9a7e\u9a76\u3001\u533b\u7597\u5f71\u50cf\uff0c\u56fe\u50cf\u7f8e\u5316\u3001\u4e09\u7ef4\u91cd\u5efa\u7b49\u7b49\u3002 \u81ea\u52a8\u9a7e\u9a76\uff08Autonomous vehicles\uff09\uff1a\u6c7d\u8f66\u9700\u8981\u5b89\u88c5\u5fc5\u8981\u7684\u611f\u77e5\u7cfb\u7edf\u4ee5\u4e86\u89e3\u5b83\u4eec\u7684\u73af\u5883\uff0c\u8fd9\u6837\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u624d\u80fd\u591f\u5b89\u5168\u5730\u9a76\u5165\u73b0\u6709\u7684\u9053\u8def \u533b\u7597\u5f71\u50cf\u8bca\u65ad\uff08Medical image diagnostics\uff09\uff1a\u673a\u5668\u5728\u5206\u6790\u80fd\u529b\u4e0a\u6bd4\u653e\u5c04\u79d1\u533b\u751f\u66f4\u5f3a\uff0c\u800c\u4e14\u53ef\u4ee5\u5927\u5927\u51cf\u5c11\u8bca\u65ad\u6240\u9700\u65f6\u95f4\u3002 \u56fe\u50cf\u5206\u5272\u662f\u4e00\u4e2a\u975e\u5e38\u56f0\u96be\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u6df1\u5ea6\u5b66\u4e60\u4e4b\u524d\u3002\u6df1\u5ea6\u5b66\u4e60\u4f7f\u5f97\u56fe\u50cf\u5206\u5272\u7684\u51c6\u786e\u7387\u63d0\u9ad8\u4e86\u5f88\u591a\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u4e3b\u8981\u56f4\u7ed5\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7ed9\u5927\u5bb6\u4ecb\u7ecd\u56fe\u50cf\u5206\u5272\u7684\u5185\u5bb9\u3002","title":"1.1 \u56fe\u50cf\u5206\u5272\u7684\u5b9a\u4e49"},{"location":"imageSegmentation/section1/#12","text":"","title":"1.2 \u4efb\u52a1\u7c7b\u578b"},{"location":"imageSegmentation/section1/#121","text":"\u7b80\u5355\u6765\u8bf4\uff0c\u6211\u4eec\u7684\u76ee\u6807\u662f\u8f93\u5165\u4e00\u4e2aRGB\u5f69\u8272\u56fe\u7247 \uff08height\u00d7width\u00d73\uff09 \uff08height\u00d7width\u00d73\uff09 \u6216\u8005\u4e00\u4e2a\u7070\u5ea6\u56fe \uff08height\u00d7width\u00d71\uff09 \uff08height\u00d7width\u00d71\uff09 \uff0c\u7136\u540e\u8f93\u51fa\u4e00\u4e2a\u5305\u542b\u5404\u4e2a\u50cf\u7d20\u7c7b\u522b\u6807\u7b7e\u7684\u5206\u5272\u56fe \uff08height\u00d7width\u00d71\uff09 \uff08height\u00d7width\u00d71\uff09 \u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4e0e\u6211\u4eec\u5904\u7406\u5206\u7c7b\u503c\u7684\u65b9\u5f0f\u7c7b\u4f3c\uff0c\u9884\u6d4b\u76ee\u6807\u53ef\u4ee5\u91c7\u7528one-hot\u7f16\u7801\uff0c\u5373\u4e3a\u6bcf\u4e00\u4e2a\u53ef\u80fd\u7684\u7c7b\u521b\u5efa\u4e00\u4e2a\u8f93\u51fa\u901a\u9053\u3002\u901a\u8fc7\u53d6\u6bcf\u4e2a\u50cf\u7d20\u70b9\u5728\u5404\u4e2achannel\u7684argmax\u53ef\u4ee5\u5f97\u5230\u6700\u7ec8\u7684\u9884\u6d4b\u5206\u5272\u56fe\uff0c\uff08\u5982\u4e0b\u56fe\u6240\u793a\uff09\uff1a \u6bd4\u5982\uff1aperson\u7684\u7f16\u7801\u4e3a\uff1a10000\uff0c\u800cGrass\u7684\u7f16\u7801\u4e3a\uff1a00100 \u5f53\u5c06\u9884\u6d4b\u7ed3\u679c\u53e0\u52a0\u5230\u5355\u4e2achannel\u65f6\uff0c\u79f0\u8fd9\u4e3a\u4e00\u4e2a\u63a9\u819cmask\uff0c\u5b83\u53ef\u4ee5\u7ed9\u51fa\u4e00\u5f20\u56fe\u50cf\u4e2d\u67d0\u4e2a\u7279\u5b9a\u7c7b\u7684\u6240\u5728\u533a\u57df\uff1a","title":"1.2.1 \u4efb\u52a1\u63cf\u8ff0"},{"location":"imageSegmentation/section1/#122","text":"\u76ee\u524d\u7684\u56fe\u50cf\u5206\u5272\u4efb\u52a1\u4e3b\u8981\u6709\u4e24\u7c7b\uff1a \u8bed\u4e49\u5206\u5272\u548c\u5b9e\u4f8b\u5206\u5272 \u6211\u4eec\u4ee5\u4e0b\u56fe\u4e3a\u4f8b\uff0c\u6765\u4ecb\u7ecd\u8fd9\u4e24\u79cd\u5206\u5272\u65b9\u5f0f\uff1a \u8bed\u4e49\u5206\u5272\u5c31\u662f\u628a\u56fe\u50cf\u4e2d\u6bcf\u4e2a\u50cf\u7d20\u8d4b\u4e88\u4e00\u4e2a\u7c7b\u522b\u6807\u7b7e\uff0c\u5982\u4e0b\u56fe\u6211\u4eec\u5c06\u56fe\u50cf\u4e2d\u7684\u50cf\u7d20\u5206\u7c7b\u4e3a\u4eba\uff0c\u7f8a\uff0c\u72d7\uff0c\u8349\u5730\u5373\u53ef\u3002 \u5b9e\u4f8b\u5206\u5272\uff0c\u76f8\u5bf9\u4e8e\u8bed\u4e49\u5206\u5272\u6765\u8bb2\uff0c\u4e0d\u4ec5\u8981\u533a\u5206\u4e0d\u540c\u7c7b\u522b\u7684\u50cf\u7d20\uff0c\u8fd8\u9700\u8981\u9700\u8981\u5bf9\u540c\u4e00\u7c7b\u522b\u7684\u4e0d\u540c\u4e2a\u4f53\u8fdb\u884c\u533a\u5206\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4e0d\u4ec5\u9700\u8981\u8fdb\u884c\u7c7b\u522b\u7684\u5212\u5206\uff0c\u8fd8\u8981\u5c06\u5404\u4e2a\u4e2a\u4f53\u5212\u5206\u51fa\u6765\uff1a\u7f8a1\uff0c\u7f8a2\uff0c\u7f8a3\uff0c\u7f8a4\uff0c\u7f8a5\u7b49\u3002 \u76ee\u524d\u56fe\u50cf\u5206\u5272\u7684\u4efb\u52a1\u4e3b\u8981\u96c6\u4e2d\u5728\u8bed\u4e49\u5206\u5272\uff0c\u800c\u76ee\u524d\u7684\u96be\u70b9\u4e5f\u5728\u4e8e\u201c\u8bed\u4e49\u201d\uff0c\u8868\u8fbe\u67d0\u4e00\u8bed\u4e49\u7684\u540c\u4e00\u7269\u4f53\u5e76\u4e0d\u603b\u662f\u4ee5\u76f8\u540c\u7684\u5f62\u8c61\u51fa\u73b0\uff0c\u5982\u5305\u542b\u4e0d\u540c\u7684\u989c\u8272\u3001\u7eb9\u7406\u7b49\uff0c\u8fd9\u5bf9\u7cbe\u786e\u5206\u5272\u5e26\u6765\u4e86\u5f88\u5927\u7684\u6311\u6218\u3002\u800c\u4e14\u4ee5\u76ee\u524d\u7684\u6a21\u578b\u8868\u73b0\u6765\u770b\uff0c\u5728\u51c6\u786e\u7387\u4e0a\u8fd8\u6709\u5f88\u5927\u7684\u63d0\u5347\u7a7a\u95f4\u3002\u800c\u5b9e\u4f8b\u5206\u5272\u7684\u601d\u8def\u4e3b\u8981\u662f\u76ee\u6807\u68c0\u6d4b+\u8bed\u4e49\u5206\u5272\uff0c\u5373\u7528\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u5c06\u56fe\u50cf\u4e2d\u7684\u4e0d\u540c\u5b9e\u4f8b\u6846\u51fa\uff0c\u518d\u7528\u8bed\u4e49\u5206\u5272\u65b9\u6cd5\u5728\u4e0d\u540c\u68c0\u6d4b\u7ed3\u679c\u5185\u8fdb\u884c\u9010\u50cf\u7d20\u6807\u8bb0\u3002","title":"1.2.2 \u4efb\u52a1\u7c7b\u578b"},{"location":"imageSegmentation/section1/#13","text":"\u56fe\u50cf\u5206\u5272\u5e38\u7528\u7684\u6570\u636e\u96c6\u662fPASCAL VOC\uff0c\u57ce\u5e02\u98ce\u5149\u6570\u636e\u96c6\uff0ccoco\u6570\u636e\u96c6\u7b49\u3002","title":"1.3 \u5e38\u7528\u7684\u5f00\u6e90\u6570\u636e\u96c6"},{"location":"imageSegmentation/section1/#131-voc","text":"VOC\u6570\u636e\u96c6\u5171\u670920\u7c7b\u6570\u636e\uff0c\u76ee\u5f55\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8fd9\u4e2a\u5728\u76ee\u6807\u68c0\u6d4b\u6982\u8ff0\u4e00\u8282\u4e2d\u5df2\u7ecf\u7ed9\u5927\u5bb6\u4ecb\u7ecd\u8fc7\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecd\u76ee\u6807\u5206\u5272\u76f8\u5173\u7684\u5185\u5bb9\uff1a JPEGImages\u4e2d\u5b58\u653e\u56fe\u7247\u6587\u4ef6 \u0015\u0015imagesets\u4e2d\u7684segmentation\u4e2d\u8bb0\u5f55\u4e86\u7528\u4e8e\u5206\u5272\u7684\u56fe\u50cf\u4fe1\u606f SegmentationClass\u4e2d\u662f\u8bed\u4e49\u5206\u5272\u7684\u6807\u6ce8\u4fe1\u606f SegmentationObject\u4e2d\u662f\u5b9e\u4f8b\u5206\u5272\u7684\u6807\u6ce8\u4fe1\u606f VOC\u4e2d\u7684\u56fe\u7247\u5e76\u4e0d\u662f\u6240\u6709\u90fd\u7528\u4e8e\u5206\u5272\uff0c\u7528\u4e8e\u5206\u5272\u6bd4\u8d5b\u7684\u56fe\u7247\u5b9e\u4f8b\u90fd\u8bb0\u5f55\u5728txt\u6587\u4ef6\u4e2d\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u76f8\u5173\u7684\u56fe\u50cf\u8bb0\u5f55\u5728\u76f8\u5e94\u7684\u6587\u672c\u6587\u4ef6\u4e2d\uff0c\u5982\u8bad\u7ec3\u96c6\u6570\u636e\u8bb0\u5f55\u5728train.txt\u6587\u4ef6\u4e2d\uff0c\u5176\u4e2d\u5185\u5bb9\u5982\u4e0b\uff1a \u90a3\u6211\u4eec\u5c31\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e9b\u6570\u636e\u8fdb\u884c\u56fe\u50cf\u5206\u5272\u6a21\u578b\u7684\u8bad\u7ec3\u3002\u56fe\u50cf\u7684\u6807\u6ce8\u6548\u679c\u5982\u4e0b\u56fe\u6240\u793a: \u539f\u56fe\u50cf002378.jpg\u7684\u8bed\u4e49\u5206\u5272\u548c\u5b9e\u4f8b\u5206\u5272\u7684\u6807\u6ce8\u7ed3\u679c\u5982\u4e0a\u6240\u793a\uff0c\u80cc\u666f\u662f\u9ed1\u8272\u7684\uff0c\u4e0d\u540c\u7c7b\u522b\u7684\u50cf\u7d20\u6807\u6ce8\u4e3a\u4e0d\u540c\u7684\u989c\u8272\u3002\u53ef\u4ee5\u770b\u51fa\uff0c\u8bed\u4e49\u5206\u5272\u53ea\u6807\u6ce8\u4e86\u50cf\u7d20\u7684\u7c7b\u522b\uff0c\u800c\u5b9e\u4f8b\u5206\u5272\u4e0d\u4ec5\u6807\u6ce8\u4e86\u7c7b\u522b\uff0c\u8fd8\u5bf9\u540c\u4e00\u7c7b\u522b\u7684\u4e0d\u540c\u4e2a\u4f53\u8fdb\u884c\u4e86\u533a\u5206\u3002 \u5728\u5199\u7a0b\u5e8f\u7684\u65f6\u5019\u5c31\u5229\u7528 train.txt \u5bf9\u56fe\u7247\u8fdb\u884c\u6311\u9009\uff0c\u56e0\u4e3a\u4e0d\u662f\u6240\u6709\u7684\u56fe\u7247\u90fd\u6709\u5206\u5272\u771f\u5b9e\u503c\uff0c\u83b7\u53d6\u56fe\u7247\u53ca\u5176\u5bf9\u5e94\u7684\u771f\u5b9e\u503c\uff0c\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u5373\u53ef\u3002","title":"1.3.1 VOC\u6570\u636e\u96c6"},{"location":"imageSegmentation/section1/#132cityscapes","text":"Cityscapes\u662f\u7531\u5954\u9a70\u4e8e2015\u5e74\u63a8\u51fa\u7684\uff0c\u63d0\u4f9b\u65e0\u4eba\u9a7e\u9a76\u73af\u5883\u4e0b\u7684\u56fe\u50cf\u5206\u5272\u6570\u636e\u96c6\u3002\u5b83\u5305\u542b50\u4e2a\u57ce\u5e02\u4e0d\u540c\u573a\u666f\u3001\u4e0d\u540c\u80cc\u666f\u3001\u4e0d\u540c\u5b63\u8282\u7684\u8857\u666f\uff0c\u63d0\u4f9b\u4e865000\u5f20\u5728\u57ce\u5e02\u73af\u5883\u4e2d\u9a7e\u9a76\u573a\u666f\u7684\u9ad8\u8d28\u91cf\u50cf\u7d20\u7ea7\u6ce8\u91ca\u56fe\u50cf\uff08\u5176\u4e2d 2975 for train\uff0c500 for val\uff0c1525 for test\uff09\u3002 Cityscapes\u662f\u76ee\u524d\u516c\u8ba4\u7684\u81ea\u52a8\u9a7e\u9a76\u9886\u57df\u5185\u6700\u5177\u6743\u5a01\u6027\u548c\u4e13\u4e1a\u6027\u7684\u56fe\u50cf\u8bed\u4e49\u5206\u5272\u8bc4\u6d4b\u96c6\u4e4b\u4e00\uff0c\u5176\u5173\u6ce8\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u57ce\u533a\u9053\u8def\u73af\u5883\u7406\u89e3\uff0c\u4efb\u52a1\u96be\u5ea6\u66f4\u9ad8\u4e14\u66f4\u8d34\u8fd1\u4e8e\u81ea\u52a8\u9a7e\u9a76\u7b49\u70ed\u95e8\u9700\u6c42\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u770b\u4e0b\u6570\u636e\u7684\u5185\u5bb9\uff0c\u6570\u636e\u96c6\u7684\u6587\u4ef6\u76ee\u5f55\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5176\u4e2dtxt\u6587\u4ef6\u4e2d\u4fdd\u5b58\u4e86\u76f8\u5173\u6837\u672c\u56fe\u7247\u7684\u8def\u5f84\u548c\u6587\u4ef6\u540d\uff0c\u4fbf\u4e8e\u67e5\u627e\u76f8\u5e94\u7684\u6570\u636e\uff0c\u6211\u4eec\u4e3b\u8981\u4f7f\u7528\u6570\u636e\u662fleftImg8bit\u548cgtFine\u4e2d\u7684\u5185\u5bb9\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u0015leftImg8bit\u6587\u4ef6\u5939\u6709\u4e09\u4e2a\u5b50\u76ee\u5f55\uff1atest\uff0c train\u4ee5\u53caval\uff0c\u5206\u522b\u4e3a\u6d4b\u8bd5\u96c6\uff0c\u8bad\u7ec3\u96c6\u4ee5\u53ca\u9a8c\u8bc1\u96c6\u56fe\u7247\u3002\u8fd9\u4e09\u4e2a\u5b50\u76ee\u5f55\u7684\u56fe\u7247\u53c8\u4ee5\u57ce\u5e02\u4e3a\u5355\u5143\u6765\u5b58\u653e\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8fd9\u91cc\u89e3\u91ca\u4e0bleftImg8bit\u7684\u542b\u4e49\uff0c\u56e0\u4e3acityscapes\u5b9e\u9645\u4e0a\u6765\u6e90\u4e8e\u53cc\u6444\u50cf\u5934\u62cd\u6444\u7684\u7acb\u4f53\u89c6\u9891\u5e8f\u5217\uff0c\u6240\u4ee5\u8fd9\u91cc\u7684leftImg\u5c31\u662f\u6765\u81ea\u4e8e\u5de6\u6444\u50cf\u5934\u7684\u56fe\u7247\uff0c\u800c8bit\u610f\u5473\u7740\u8be5\u56fe\u7247\u96c6\u90fd\u4e3aRGB\u6bcf\u4e2a\u5206\u91cf\u4e3a8bit\u7684\u56fe\u7247\u3002 gtFine\u662f\u6837\u672c\u56fe\u7247\u5bf9\u5e94\u7684\u6807\u6ce8\u4fe1\u606f\uff0cgtFine\u4e0b\u9762\u4e5f\u662f\u5206\u4e3atrain\uff0c test\u4ee5\u53caval\uff0c\u7136\u540e\u5b83\u4eec\u7684\u5b50\u76ee\u5f55\u4e5f\u662f\u4ee5\u57ce\u5e02\u4e3a\u5355\u4f4d\u6765\u653e\u7f6e\u56fe\u7247\u3002\u8fd9\u4e9b\u90fd\u662f\u548cleftImg8bit\u7684\u4e00\u4e00\u5bf9\u5e94\u3002 \u4e0d\u540c\u7684\u662f\uff0c\u5728\u57ce\u5e02\u5b50\u76ee\u5f55\u4e0b\u9762\uff0c\u6bcf\u5f20\u6837\u672c\u56fe\u7247\u5bf9\u5e94\u67096\u4e2a\u6807\u6ce8\u6587\u4ef6\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u7cbe\u7ec6\u6807\u6ce8\u6570\u636e\u96c6\u91cc\u9762\u6bcf\u5f20\u56fe\u7247\u53ea\u5bf9\u5e94\u56db\u5f20\u6807\u6ce8\u6587\u4ef6\uff1axxx_gtFine_color.png, xxx_gtFine_instanceIds.png, xxx_gtFine_labelsIds.png\u4ee5\u53caxxx_gtFine_polygons.json\u3002 xxx_color.png\u662f\u6807\u6ce8\u7684\u53ef\u89c6\u5316\u56fe\u7247\uff0c\u771f\u6b63\u5bf9\u8bad\u7ec3\u6709\u7528\u7684\u662f\u540e\u9762\u4e09\u4e2a\u6587\u4ef6\u3002xxx_instanceIds.png\u662f\u7528\u6765\u505a\u5b9e\u4f8b\u5206\u5272\u8bad\u7ec3\u7528\u7684\uff0c\u800cxxx_labelsIds.png\u662f\u8bed\u4e49\u5206\u5272\u8bad\u7ec3\u9700\u8981\u7684\u3002\u800c\u6700\u540e\u4e00\u4e2a\u6587\u4ef6xxx_polygons.json\u4e3b\u8981\u8bb0\u5f55\u4e86\u6bcf\u4e2a\u591a\u8fb9\u5f62\u6807\u6ce8\u6846\u4e0a\u7684\u70b9\u96c6\u5750\u6807\u3002 \u8be5\u6570\u636e\u96c6\u7684\u6807\u6ce8\u6548\u679c\u53ef\u89c6\u5316\u5982\u4e0b\u6240\u793a\uff1a","title":"1.3.2\u57ce\u5e02\u98ce\u5149Cityscapes\u6570\u636e\u96c6"},{"location":"imageSegmentation/section1/#14","text":"\u56fe\u50cf\u5206\u5272\u4e2d\u901a\u5e38\u4f7f\u7528\u8bb8\u591a\u6807\u51c6\u6765\u8861\u91cf\u7b97\u6cd5\u7684\u7cbe\u5ea6\u3002\u8fd9\u4e9b\u6807\u51c6\u901a\u5e38\u662f\u50cf\u7d20\u7cbe\u5ea6\u53caIoU\u7684\u53d8\u79cd\uff0c\u4ee5\u4e0b\u6211\u4eec\u5c06\u4f1a\u4ecb\u7ecd\u5e38\u7528\u7684\u51e0\u79cd\u9010\u50cf\u7d20\u6807\u8bb0\u7684\u7cbe\u5ea6\u6807\u51c6\u3002 \u4e3a\u4e86\u4fbf\u4e8e\u89e3\u91ca\uff0c\u5047\u8bbe\u5982\u4e0b\uff1a\u5171\u6709 k+1 k+1 \u4e2a\u7c7b\uff08\u4ece L_0 L_0 \u5230 L_k L_k \uff0c\u5176\u4e2d\u5305\u542b\u4e00\u4e2a\u80cc\u666f\u7c7b\uff09\uff0c p_{ij} p_{ij} \u8868\u793a\u672c\u5c5e\u4e8e\u7c7b i i \u4f46\u88ab\u9884\u6d4b\u4e3a\u7c7b j j \u7684\u50cf\u7d20\u3002\u5373 p_{ii} p_{ii} \u8868\u793a\u9884\u6d4b\u6b63\u786e\u7684\u50cf\u7d20\u3002","title":"1.4 \u8bc4\u4ef7\u6307\u6807"},{"location":"imageSegmentation/section1/#141","text":"Pixel Accuracy(PA\uff0c\u50cf\u7d20\u7cbe\u5ea6)\uff1a\u8fd9\u662f\u6700\u7b80\u5355\u7684\u5ea6\u91cf\uff0c\u4e3a\u9884\u6d4b\u6b63\u786e\u7684\u50cf\u7d20\u5360\u603b\u50cf\u7d20\u7684\u6bd4\u4f8b\u3002 \u5bf9\u4e8e\u6837\u672c\u4e0d\u5747\u8861\u7684\u60c5\u51b5\uff0c\u4f8b\u5982\u533b\u5b66\u56fe\u50cf\u5206\u5272\u4e2d\uff0c\u80cc\u666f\u4e0e\u6807\u8bb0\u6837\u672c\u4e4b\u95f4\u7684\u6bd4\u4f8b\u5f80\u5f80\u4e25\u91cd\u5931\u8861\u3002\u56e0\u6b64\u5e76\u4e0d\u9002\u5408\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\u8fdb\u884c\u5ea6\u91cf\u3002","title":"1.4.1 \u50cf\u7d20\u7cbe\u5ea6"},{"location":"imageSegmentation/section1/#142","text":"Mean Pixel Accuracy(MPA\uff0c\u5e73\u5747\u50cf\u7d20\u7cbe\u5ea6)\uff1a\u662fPA\u7684\u4e00\u79cd\u7b80\u5355\u63d0\u5347\uff0c\u8ba1\u7b97\u6bcf\u4e2a**\u7c7b\u5185**\u88ab\u6b63\u786e\u5206\u7c7b\u50cf\u7d20\u6570\u7684\u6bd4\u4f8b\uff0c\u4e4b\u540e\u6c42\u6240\u6709\u7c7b\u7684\u5e73\u5747\u3002","title":"1.4.2 \u5e73\u5747\u50cf\u7d20\u7cbe\u5ea6"},{"location":"imageSegmentation/section1/#143","text":"Mean Intersection over Union(MIoU\uff0c\u5e73\u5747\u4ea4\u5e76\u6bd4)\uff1a\u4e3a\u8bed\u4e49\u5206\u5272\u7684\u6807\u51c6\u5ea6\u91cf\uff0c\u5176\u8ba1\u7b97\u4e24\u4e2a\u96c6\u5408\u7684\u4ea4\u96c6\u548c\u5e76\u96c6\u4e4b\u6bd4\uff0c\u5728\u8bed\u4e49\u5206\u5272\u7684\u95ee\u9898\u4e2d\uff0c\u8fd9\u4e24\u4e2a\u96c6\u5408\u4e3a\u771f\u5b9e\u503c\uff08ground truth\uff09\u548c\u9884\u6d4b\u503c\uff08predicted segmentation\uff09\u3002\u4ea4\u96c6\u4e3a\u9884\u6d4b\u6b63\u786e\u7684\u50cf\u7d20\u6570\uff08intersection\uff09\uff0c\u5e76\u96c6\u4e3a\u9884\u6d4b\u6216\u771f\u5b9e\u503c\u4e3a i i \u7c7b\u7684\u548c\u51cf\u53bb\u9884\u6d4b\u6b63\u786e\u7684\u50cf\u7d20\uff0c\u5728\u6bcf\u4e2a\u7c7b\u4e0a\u8ba1\u7b97IoU\uff0c\u4e4b\u540e\u6c42\u5e73\u5747\u5373\u53ef\u3002 \u90a3\u4e48\uff0c\u5982\u4f55\u7406\u89e3\u8fd9\u91cc\u7684\u516c\u5f0f\u5462\uff1f\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u7ea2\u8272\u5706\u4ee3\u8868\u771f\u5b9e\u503c\uff0c\u9ec4\u8272\u5706\u4ee3\u8868\u9884\u6d4b\u503c\u3002\u6a59\u8272\u90e8\u5206\u7ea2\u8272\u5706\u4e0e\u9ec4\u8272\u5706\u7684\u4ea4\u96c6\uff0c\u5373\u9884\u6d4b\u6b63\u786e\u7684\u90e8\u5206\uff0c\u7ea2\u8272\u90e8\u5206\u8868\u793a\u5047\u8d1f\uff08\u771f\u5b9e\u503c\u4e3a\u8be5\u7c7b\u9884\u6d4b\u9519\u8bef\uff09\u7684\u90e8\u5206\uff0c\u9ec4\u8272\u8868\u793a\u5047\u6b63\uff08\u9884\u6d4b\u503c\u4e3ai\u7c7b\uff0c\u771f\u5b9e\u503c\u4e3a\u5176\u4ed6\uff09\u7684\u90e8\u5206\u3002 MIoU\u8ba1\u7b97\u7684\u662f\u8ba1\u7b97A\u4e0eB\u7684\u4ea4\u96c6\uff08\u6a59\u8272\u90e8\u5206\uff09\u4e0eA\u4e0eB\u7684\u5e76\u96c6\uff08\u7ea2\u8272+\u6a59\u8272+\u9ec4\u8272\uff09\u4e4b\u95f4\u7684\u6bd4\u4f8b\uff0c\u5728\u7406\u60f3\u72b6\u6001\u4e0bA\u4e0eB\u91cd\u5408\uff0c\u4e24\u8005\u6bd4\u4f8b\u4e3a1 \u3002 \u5728\u4ee5\u4e0a\u6240\u6709\u7684\u5ea6\u91cf\u6807\u51c6\u4e2d\uff0cMIoU\u7531\u4e8e\u5176\u7b80\u6d01\u3001\u4ee3\u8868\u6027\u5f3a\u800c\u6210\u4e3a\u6700\u5e38\u7528\u7684\u5ea6\u91cf\u6807\u51c6\uff0c\u5927\u591a\u6570\u7814\u7a76\u4eba\u5458\u90fd\u4f7f\u7528\u8be5\u6807\u51c6\u62a5\u544a\u5176\u7ed3\u679c\u3002PA\u5bf9\u4e8e\u6837\u672c\u4e0d\u5747\u8861\u7684\u60c5\u51b5\u4e0d\u9002\u7528\u3002 \u603b\u7ed3 \u56fe\u50cf\u5206\u5272\u7684\u5b9a\u4e49 \u56fe\u50cf\u5206\u5272\uff08Object Segmentation\uff09\u6307\u7684\u662f\u5c06\u6570\u5b57\u56fe\u50cf\u7ec6\u5206\u4e3a\u591a\u4e2a\u56fe\u50cf\u5b50\u533a\u57df\uff08\u50cf\u7d20\u7684\u96c6\u5408\uff09\u7684\u8fc7\u7a0b\uff0c\u5e76\u4e14\u540c\u4e00\u4e2a\u5b50\u533a\u57df\u5185\u7684\u7279\u5f81\u5177\u6709\u4e00\u5b9a\u76f8\u4f3c\u6027\uff0c\u4e0d\u540c\u5b50\u533a\u57df\u7684\u7279\u5f81\u5448\u73b0\u8f83\u4e3a\u660e\u663e\u7684\u5dee\u5f02\u3002 \u56fe\u50cf\u5206\u5272\u7684\u4efb\u52a1\u7c7b\u578b \u56fe\u50cf\u5206\u5272\u7684\u4efb\u52a1\u5c31\u662f\u7ed9\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e00\u4e2a\u50cf\u7d20\u70b9\u8fdb\u884c\u5206\u7c7b \u8bed\u4e49\u5206\u5272\u548c\u5b9e\u4f8b\u5206\u5272 \u56fe\u50cf\u5206\u5272\u7684\u5e38\u89c1\u6570\u636e\u96c6 Voc \u6570\u636e\u96c6\uff0c\u57ce\u5e02\u98ce\u5149\u6570\u636e\u96c6\uff0ccoco\u6570\u636e\u96c6\u7b49 \u56fe\u50cf\u5206\u5272\u7684\u8bc4\u4f30\u6307\u6807 \u50cf\u7d20\u7cbe\u5ea6\uff08PA\uff09\uff0c\u5e73\u5747\u50cf\u7d20\u7cbe\u5ea6\uff08mPA\uff09\u548c \u5e73\u5747\u4ea4\u5e76\u6bd4\uff08mIOU\uff09 \u6700\u5e38\u7528\u7684\u662fMIOU","title":"1.4.3 \u5e73\u5747\u4ea4\u5e76\u6bd4"},{"location":"imageSegmentation/section2/","text":"5.2 \u8bed\u4e49\u5206\u5272\uff1aFCN\u548cUNet \u00b6 \u5b66\u4e60\u76ee\u6807 \u4e86\u89e3FCN\u7684\u7ed3\u6784 \u4e86\u89e3FCN\u7684\u4e0a\u91c7\u6837\u65b9\u6cd5\u53ca\u8df3\u5c42\u8fde\u63a5 \u638c\u63e1Unet\u7f51\u7edc\u7ed3\u6784 1.FCN\u7f51\u7edc \u00b6 FCN\uff08Fully Convolutional Networks\uff09 \u7528\u4e8e\u56fe\u50cf\u8bed\u4e49\u5206\u5272\uff0c\u81ea\u4ece\u8be5\u7f51\u7edc\u63d0\u51fa\u540e\uff0c\u5c31\u6210\u4e3a\u8bed\u4e49\u5206\u5272\u7684\u57fa\u672c\u6846\u67b6\uff0c\u540e\u7eed\u7b97\u6cd5\u57fa\u672c\u90fd\u662f\u5728\u8be5\u7f51\u7edc\u6846\u67b6\u4e2d\u6539\u8fdb\u800c\u6765\u3002 \u5bf9\u4e8e\u4e00\u822c\u7684\u5206\u7c7bCNN\u7f51\u7edc\uff0c\u5982VGG\u548cResnet\uff0c\u90fd\u4f1a\u5728\u7f51\u7edc\u7684\u6700\u540e\u52a0\u5165\u4e00\u4e9b\u5168\u8fde\u63a5\u5c42\uff0c\u7ecf\u8fc7softmax\u540e\u5c31\u53ef\u4ee5\u83b7\u5f97\u7c7b\u522b\u6982\u7387\u4fe1\u606f\u3002 \u4f46\u662f\u8fd9\u4e2a\u6982\u7387\u53ea\u80fd\u6807\u8bc6\u6574\u4e2a\u56fe\u7247\u7684\u7c7b\u522b\uff0c\u4e0d\u80fd\u6807\u8bc6\u6bcf\u4e2a\u50cf\u7d20\u70b9\u7684\u7c7b\u522b\uff0c\u6240\u4ee5\u8fd9\u79cd\u5168\u8fde\u63a5\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u56fe\u50cf\u5206\u5272\u3002 \u800cFCN\u63d0\u51fa\u53ef\u4ee5\u628a\u540e\u9762\u51e0\u4e2a\u5168\u8fde\u63a5\u90fd\u6362\u6210\u5377\u79ef\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u83b7\u5f97\u4e00\u5f202\u7ef4\u7684feature map\uff0c\u540e\u63a5softmax\u83b7\u5f97\u6bcf\u4e2a\u50cf\u7d20\u70b9\u7684\u5206\u7c7b\u4fe1\u606f\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u5206\u5272\u95ee\u9898\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7b80\u800c\u8a00\u4e4b\uff0cFCN\u548cCNN\u7684\u533a\u522b\u5c31\u662f\uff1aCNN\u5377\u79ef\u5c42\u4e4b\u540e\u8fde\u63a5\u7684\u662f\u5168\u8fde\u63a5\u5c42\uff1bFCN\u5377\u79ef\u5c42\u4e4b\u540e\u4ecd\u8fde\u63a5\u5377\u79ef\u5c42\uff0c\u8f93\u51fa\u7684\u662f\u4e0e\u8f93\u5165\u5927\u5c0f\u76f8\u540c\u7684\u7279\u5f81\u56fe\u3002 1.1 \u7f51\u7edc\u7ed3\u6784 \u00b6 FCN\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\uff0c\u50cf\u7d20\u5bf9\u50cf\u7d20\u7684\u5168\u5377\u79ef\u7f51\u7edc\uff0c\u7528\u4e8e\u8fdb\u884c\u56fe\u50cf\u7684\u8bed\u4e49\u5206\u5272\u3002\u6574\u4f53\u7684\u7f51\u7edc\u7ed3\u6784\u5206\u4e3a\u4e24\u4e2a\u90e8\u5206\uff1a\u5168\u5377\u79ef\u90e8\u5206\u548c\u4e0a\u91c7\u6837\u90e8\u5206\u3002 1.1.1 \u5168\u5377\u79ef\u90e8\u5206 \u00b6 \u5168\u5377\u79ef\u90e8\u5206\u4f7f\u7528\u7ecf\u5178\u7684CNN\u7f51\u7edc\uff08\u4ee5AlexNet\u7f51\u7edc\u4e3a\u4f8b\uff09\uff0c\u5e76\u628a\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\u6362\u6210 \u5377\u79ef\uff0c\u7528\u4e8e\u63d0\u53d6\u7279\u5f81\u3002 \u5728\u4f20\u7edf\u7684Alex\u7ed3\u6784\u4e2d\uff0c\u524d5\u5c42\u662f\u5377\u79ef\u5c42\uff0c\u7b2c6\u5c42\u548c\u7b2c7\u5c42\u5206\u522b\u662f\u4e00\u4e2a\u957f\u5ea6\u4e3a4096\u7684\u4e00\u7ef4\u5411\u91cf\uff0c\u7b2c8\u5c42\u662f\u957f\u5ea6\u4e3a1000\u7684\u4e00\u7ef4\u5411\u91cf\uff0c\u5206\u522b\u5bf9\u5e941000\u4e2a\u4e0d\u540c\u7c7b\u522b\u7684\u6982\u7387\u3002 FCN\u5c06\u6700\u540e\u76843\u5c42\u8f6c\u6362\u4e3a\u5377\u79ef\u5c42\uff0c\u5377\u79ef\u6838\u7684\u5927\u5c0f (\u901a\u9053\u6570\uff0c\u5bbd\uff0c\u9ad8) \u5206\u522b\u4e3a (4096,1,1)\u3001(4096,1,1)\u3001(1000,1,1)\uff0c\u867d\u7136\u53c2\u6570\u6570\u76ee\u76f8\u540c\uff0c\u4f46\u662f\u8ba1\u7b97\u65b9\u6cd5\u5c31\u4e0d\u4e00\u6837\u4e86\uff0c\u8fd9\u65f6\u8fd8\u53ef\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u53c2\u6570\u3002 CNN\u4e2d\u8f93\u5165\u7684\u56fe\u50cf\u56fa\u5b9a\u6210227x227\u5927\u5c0f\uff0c\u7b2c\u4e00\u5c42pooling\u540e\u4e3a55x55\uff0c\u7b2c\u4e8c\u5c42pooling\u540e\u56fe\u50cf\u5927\u5c0f\u4e3a27x27\uff0c\u7b2c\u4e94\u5c42pooling\u540e\u7684\u56fe\u50cf\u5927\u5c0f\u4e3a13x13, \u800cFCN\u8f93\u5165\u7684\u56fe\u50cf\u662fH*W\u5927\u5c0f\uff0c\u7b2c\u4e00\u5c42pooling\u540e\u53d8\u4e3a\u539f\u56fe\u5927\u5c0f\u7684\u00bd\uff0c\u7b2c\u4e8c\u5c42\u53d8\u4e3a\u539f\u56fe\u5927\u5c0f\u7684\u00bc\uff0c\u7b2c\u4e94\u5c42\u53d8\u4e3a\u539f\u56fe\u5927\u5c0f\u7684\u215b\uff0c\u7b2c\u516b\u5c42\u53d8\u4e3a\u539f\u56fe\u5927\u5c0f\u76841/16\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u7ecf\u8fc7\u591a\u6b21\u5377\u79ef\u548cpooling\u4ee5\u540e\uff0c\u5f97\u5230\u7684\u56fe\u50cf\u8d8a\u6765\u8d8a\u5c0f\uff0c\u5206\u8fa8\u7387\u8d8a\u6765\u8d8a\u4f4e\u3002\u5bf9\u6700\u7ec8\u7684\u7279\u5f81\u56fe\u8fdb\u884cupsampling\uff0c\u628a\u56fe\u50cf\u8fdb\u884c\u653e\u5927\u5230\u539f\u56fe\u50cf\u7684\u5927\u5c0f\uff0c\u5c31\u5f97\u5230\u539f\u56fe\u50cf\u7684\u5206\u5272\u7ed3\u679c\u3002 1.1.2 \u4e0a\u91c7\u6837\u90e8\u5206 \u00b6 \u4e0a\u91c7\u6837\u90e8\u5206\u5c06\u6700\u7ec8\u5f97\u5230\u7684\u7279\u5f81\u56fe\u4e0a\u91c7\u6837\u5f97\u5230\u539f\u56fe\u50cf\u5927\u5c0f\u7684\u8bed\u4e49\u5206\u5272\u7ed3\u679c\u3002 \u5728\u8fd9\u91cc\u91c7\u7528\u7684\u4e0a\u91c7\u6837\u65b9\u6cd5\u662f\u53cd\u5377\u79ef\uff08Deconvolution\uff09\uff0c\u4e5f\u53eb\u505a\u8f6c\u7f6e\u5377\u79ef\uff08Transposed Convolution\uff09\uff1a \u53cd\u5377\u79ef\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u6b63\u5411\u5377\u79ef \u901a\u4fd7\u7684\u8bb2\uff0c\u5c31\u662f\u8f93\u5165\u88650+\u5377\u79ef\u3002\u5148\u6309\u7167\u4e00\u5b9a\u7684\u6bd4\u4f8b\u901a\u8fc7\u88650\u6765\u6269\u5927\u8f93\u5165\u56fe\u50cf\u7684\u5c3a\u5bf8\uff0c\u518d\u8fdb\u884c\u6b63\u5411\u5377\u79ef\u5373\u53ef\u3002 \u5982\u4e0b\u56fe\u6240\u793a\uff1a\u8f93\u5165\u56fe\u50cf\u5c3a\u5bf8\u4e3a3x3\uff0c\u5377\u79ef\u6838kernel\u4e3a3x3\uff0c\u6b65\u957fstrides=2\uff0c\u586b\u5145padding=1 \u5047\u8bbe\u53cd\u5377\u79ef\u7684\u8f93\u5165\u662fn x n \uff0c\u53cd\u5377\u79ef\u7684\u8f93\u51fa\u4e3amxm \uff0cpadding=p\uff0cstride=s\uff0ckernel_size = k\u3002 \u90a3\u4e48\u6b64\u65f6\u53cd\u5377\u79ef\u7684\u8f93\u51fa\u5c31\u4e3a\uff1a m = s(n-1) + k -2p m = s(n-1) + k -2p \u4e0e\u6b63\u5411\u5377\u79ef\u4e0d\u540c\u7684\u662f\uff0c\u8981\u5148\u6839\u636e\u6b65\u957fstrides\u5bf9\u8f93\u5165\u7684\u5185\u90e8\u8fdb\u884c\u586b\u5145\uff0c\u8fd9\u91ccstrides\u53ef\u4ee5\u7406\u89e3\u6210\u8f93\u5165\u653e\u5927\u7684\u500d\u6570\uff0c\u800c\u4e0d\u80fd\u7406\u89e3\u6210\u5377\u79ef\u79fb\u52a8\u7684\u6b65\u957f\u3002 \u8fd9\u6837\u6211\u4eec\u5c31\u53ef\u4ee5\u901a\u8fc7\u53cd\u5377\u79ef\u5b9e\u73b0\u4e0a\u91c7\u6837\u3002 1.2 \u8df3\u5c42\u8fde\u63a5 \u00b6 \u5982\u679c\u53ea\u5229\u7528\u53cd\u5377\u79ef\u5bf9\u6700\u540e\u4e00\u5c42\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u4e0a\u91c7\u6837\u7684\u5230\u539f\u56fe\u5927\u5c0f\u7684\u5206\u5272\uff0c\u7531\u4e8e\u6700\u540e\u4e00\u5c42\u7684\u7279\u5f81\u56fe\u592a\u5c0f\uff0c\u4f1a\u635f\u5931\u5f88\u591a\u7ec6\u8282\u3002\u56e0\u800c\u63d0\u51fa\u589e\u52a0Skips\u7ed3\u6784\u5c06\u6700\u540e\u4e00\u5c42\u7684\u9884\u6d4b\uff08\u6709\u66f4\u5bcc\u7684\u5168\u5c40\u4fe1\u606f\uff09\u548c\u66f4\u6d45\u5c42\uff08\u6709\u66f4\u591a\u7684\u5c40\u90e8\u7ec6\u8282\uff09\u7684\u9884\u6d4b\u7ed3\u5408\u8d77\u6765\u3002 \u90a3\u4e48\uff1a \u5bf9\u4e8eFCN-32s\uff0c\u76f4\u63a5\u5bf9pool5 feature\u8fdb\u884c32\u500d\u4e0a\u91c7\u6837\u83b7\u5f9732x upsampled feature\uff0c\u518d\u5bf932x upsampled feature\u6bcf\u4e2a\u70b9\u505asoftmax prediction\u83b7\u5f9732x upsampled feature prediction\uff08\u5373\u5206\u5272\u56fe\uff09\u3002 \u5bf9\u4e8eFCN-16s\uff0c\u9996\u5148\u5bf9pool5 feature\u8fdb\u884c2\u500d\u4e0a\u91c7\u6837\u83b7\u5f972x upsampled feature\uff0c\u518d\u628apool4 feature\u548c2x upsampled feature\u9010\u70b9\u76f8\u52a0\uff0c\u7136\u540e\u5bf9\u76f8\u52a0\u7684feature\u8fdb\u884c16\u500d\u4e0a\u91c7\u6837\uff0c\u5e76softmax prediction\uff0c\u83b7\u5f9716x upsampled feature prediction\u3002 \u5bf9\u4e8eFCN-8s\uff0c\u9996\u5148\u8fdb\u884cpool4+2x upsampled feature\u9010\u70b9\u76f8\u52a0\uff0c\u7136\u540e\u53c8\u8fdb\u884cpool3+2x upsampled\u9010\u70b9\u76f8\u52a0\uff0c\u5373\u8fdb\u884c\u66f4\u591a\u6b21\u7279\u5f81\u878d\u5408\u3002\u5177\u4f53\u8fc7\u7a0b\u4e0e16s\u7c7b\u4f3c\uff0c\u4e0d\u518d\u8d58\u8ff0\u3002 \u4e0b\u9762\u6709\u4e00\u5f2032\u500d\uff0c16\u500d\u548c8\u500d\u4e0a\u91c7\u6837\u5f97\u5230\u7684\u7ed3\u679c\u56fe\u5bf9\u6bd4\uff1a \u53ef\u4ee5\u770b\u5230\u968f\u7740\u4e0a\u91c7\u6837\u505a\u5f97\u8d8a\u591a\uff0c\u5206\u5272\u7ed3\u679c\u8d8a\u6765\u8d8a\u7cbe\u7ec6\u3002 1.3 \u603b\u7ed3 \u00b6 \u4f18\u70b9 \u7aef\u5230\u7aef\u7684\uff0c\u53ef\u4ee5\u63a5\u53d7\u4efb\u610f\u5927\u5c0f\u7684\u8f93\u5165\u56fe\u50cf\u5c3a\u5bf8\uff0c\u6bd4\u8f83\u9ad8\u6548\u3002 \u5c40\u9650\u6027 \u5f97\u5230\u7684\u7ed3\u679c\u8fd8\u662f\u4e0d\u591f\u7cbe\u7ec6\u3002\u8fdb\u884c8\u500d\u4e0a\u91c7\u6837\u867d\u7136\u6bd432\u500d\u7684\u6548\u679c\u597d\u4e86\u5f88\u591a\uff0c\u4f46\u662f\u4e0a\u91c7\u6837\u7684\u7ed3\u679c\u8fd8\u662f\u6bd4\u8f83\u6a21\u7cca\u7684\uff0c\u5bf9\u56fe\u50cf\u4e2d\u7684\u7ec6\u8282\u4e0d\u654f\u611f\u3002\u800c\u4e14\u5728\u5bf9\u5404\u4e2a\u50cf\u7d20\u8fdb\u884c\u5206\u7c7b\u65f6\uff0c\u6ca1\u6709\u8003\u8651\u50cf\u7d20\u4e0e\u50cf\u7d20\u4e4b\u95f4\u7684\u5173\u7cfb\u3002 2.Unet\u7f51\u7edc \u00b6 Unet\u7f51\u7edc\u662f\u5efa\u7acb\u5728FCN\u7f51\u7edc\u57fa\u7840\u4e0a\u7684\uff0c\u5b83\u7684\u7f51\u7edc\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u603b\u4f53\u6765\u8bf4\u4e0eFCN\u601d\u8def\u975e\u5e38\u7c7b\u4f3c\u3002 \u6574\u4e2a\u7f51\u7edc\u7531\u7f16\u7801\u90e8\u5206\uff08\u5de6\uff09 \u548c \u89e3\u7801\u90e8\u5206\uff08\u53f3\uff09\u7ec4\u6210\uff0c\u7c7b\u4f3c\u4e8e\u4e00\u4e2a\u5927\u5927\u7684U\u5b57\u6bcd\uff0c\u5177\u4f53\u4ecb\u7ecd\u5982\u4e0b\uff1a 1\u3001\u7f16\u7801\u90e8\u5206\u662f\u5178\u578b\u7684\u5377\u79ef\u7f51\u7edc\u67b6\u6784\uff1a \u67b6\u6784\u4e2d\u542b\u6709\u7740\u4e00\u79cd\u91cd\u590d\u7ed3\u6784\uff0c\u6bcf\u6b21\u91cd\u590d\u4e2d\u90fd\u67092\u4e2a 3 x 3\u5377\u79ef\u5c42\u3001\u975e\u7ebf\u6027ReLU\u5c42\u548c\u4e00\u4e2a 2 x 2 max pooling\u5c42\uff08stride\u4e3a2\uff09\u3002\uff08\u56fe\u4e2d\u7684\u84dd\u7bad\u5934\u3001\u7ea2\u7bad\u5934\uff0c\u6ca1\u753bReLu\uff09 \u6bcf\u4e00\u6b21\u4e0b\u91c7\u6837\u540e\u6211\u4eec\u90fd\u628a\u7279\u5f81\u901a\u9053\u7684\u6570\u91cf\u52a0\u500d 2\u3001\u89e3\u7801\u90e8\u5206\u4e5f\u4f7f\u7528\u4e86\u7c7b\u4f3c\u7684\u6a21\u5f0f\uff1a \u6bcf\u4e00\u6b65\u90fd\u9996\u5148\u4f7f\u7528\u53cd\u5377\u79ef(up-convolution)\uff0c\u6bcf\u6b21\u4f7f\u7528\u53cd\u5377\u79ef\u90fd\u5c06\u7279\u5f81\u901a\u9053\u6570\u91cf\u51cf\u534a\uff0c\u7279\u5f81\u56fe\u5927\u5c0f\u52a0\u500d\u3002\uff08\u56fe\u4e2d\u7eff\u7bad\u5934\uff09 \u53cd\u5377\u79ef\u8fc7\u540e\uff0c\u5c06\u53cd\u5377\u79ef\u7684\u7ed3\u679c\u4e0e\u7f16\u7801\u90e8\u5206\u4e2d\u5bf9\u5e94\u6b65\u9aa4\u7684\u7279\u5f81\u56fe\u62fc\u63a5\u8d77\u6765\u3002\uff08\u767d/\u84dd\u5757\uff09 \u7f16\u7801\u90e8\u5206\u4e2d\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u7a0d\u5927\uff0c\u5c06\u5176\u4fee\u526a\u8fc7\u540e\u8fdb\u884c\u62fc\u63a5\u3002\uff08\u5de6\u8fb9\u6df1\u84dd\u865a\u7ebf\uff09 \u5bf9\u62fc\u63a5\u540e\u7684map\u518d\u8fdb\u884c2\u6b213 x 3\u7684\u5377\u79ef\u3002\uff08\u53f3\u4fa7\u84dd\u7bad\u5934\uff09 \u6700\u540e\u4e00\u5c42\u7684\u5377\u79ef\u6838\u5927\u5c0f\u4e3a1 x 1\uff0c\u5c0664\u901a\u9053\u7684\u7279\u5f81\u56fe\u8f6c\u5316\u4e3a\u7279\u5b9a\u7c7b\u522b\u6570\u91cf\uff08\u5206\u7c7b\u6570\u91cf\uff09\u7684\u7ed3\u679c\u3002\uff08\u56fe\u4e2d\u9752\u8272\u7bad\u5934\uff09 \u603b\u7ed3 \u4e86\u89e3FCN\u7684\u7ed3\u6784 FCN\u7f51\u7edc\u4e0eCNN\u7684\u4e0d\u540c\u662f\u5c06\u5168\u8fde\u63a5\u5c42\u66ff\u6362\u4e3a\u5377\u79ef\u5c42\u63d0\u53d6\u56fe\u50cf\u7684\u7279\u5f81\uff0c\u83b7\u53d6\u4e8c\u7ef4\u7684\u7279\u5f81\u56fe\uff0c\u5f97\u5230\u56fe\u50cf\u7684\u5206\u5272\u7ed3\u679c\uff0c\u6574\u4e2a\u7f51\u7edc\u53ef\u5206\u4e3a\u5168\u5377\u79ef\u90e8\u5206\u548c\u4e0a\u91c7\u6837\u4e24\u90e8\u5206 \u4e86\u89e3FCN\u7684\u4e0a\u91c7\u6837\u65b9\u6cd5\u53ca\u8df3\u5c42\u8fde\u63a5 \u4e0a\u91c7\u6837\uff1a\u4f7f\u7528\u53cd\u5377\u79ef\u5b8c\u6210 \u8df3\u5c42\u8fde\u63a5\uff1a\u5c06\u7f51\u7edc\u63d0\u53d6\u7684\u6df1\u5c42\u7279\u5f81\u548c\u6d45\u5c42\u7279\u5f81\u7ed3\u5408\u8d77\u6765 \u638c\u63e1Unet\u7f51\u7edc\u7ed3\u6784 \u7c7b\u4f3c\u4e8e\u4e00\u4e2a\u5927\u5927\u7684U\u5b57\u6bcd\uff1a\u9996\u5148\u8fdb\u884c\u5377\u79ef\u548c\u6c60\u5316\u6765\u5b8c\u6210\u4e0b\u91c7\u6837\uff1b\u7136\u540e\u901a\u8fc7\u53cd\u5377\u79ef\u8fdb\u884c\u4e0a\u91c7\u6837\uff0ccrop\u4e4b\u524d\u7684\u4f4e\u5c42feature map\uff0c\u8fdb\u884c\u878d\u5408\uff1b\u7136\u540e\u518d\u6b21\u4e0a\u91c7\u6837\u3002\u91cd\u590d\u8fd9\u4e2a\u8fc7\u7a0b\uff0c\u76f4\u5230\u83b7\u5f97\u8f93\u51fa\u7684feature map\uff0c\u6700\u540e\u7ecf\u8fc7softmax\u83b7\u5f97\u8f93\u51fa\u5206\u5272\u7ed3\u679c","title":"\u8bed\u4e49\u5206\u5272\uff1aFCN\u548cUNet"},{"location":"imageSegmentation/section2/#52-fcnunet","text":"\u5b66\u4e60\u76ee\u6807 \u4e86\u89e3FCN\u7684\u7ed3\u6784 \u4e86\u89e3FCN\u7684\u4e0a\u91c7\u6837\u65b9\u6cd5\u53ca\u8df3\u5c42\u8fde\u63a5 \u638c\u63e1Unet\u7f51\u7edc\u7ed3\u6784","title":"5.2 \u8bed\u4e49\u5206\u5272\uff1aFCN\u548cUNet"},{"location":"imageSegmentation/section2/#1fcn","text":"FCN\uff08Fully Convolutional Networks\uff09 \u7528\u4e8e\u56fe\u50cf\u8bed\u4e49\u5206\u5272\uff0c\u81ea\u4ece\u8be5\u7f51\u7edc\u63d0\u51fa\u540e\uff0c\u5c31\u6210\u4e3a\u8bed\u4e49\u5206\u5272\u7684\u57fa\u672c\u6846\u67b6\uff0c\u540e\u7eed\u7b97\u6cd5\u57fa\u672c\u90fd\u662f\u5728\u8be5\u7f51\u7edc\u6846\u67b6\u4e2d\u6539\u8fdb\u800c\u6765\u3002 \u5bf9\u4e8e\u4e00\u822c\u7684\u5206\u7c7bCNN\u7f51\u7edc\uff0c\u5982VGG\u548cResnet\uff0c\u90fd\u4f1a\u5728\u7f51\u7edc\u7684\u6700\u540e\u52a0\u5165\u4e00\u4e9b\u5168\u8fde\u63a5\u5c42\uff0c\u7ecf\u8fc7softmax\u540e\u5c31\u53ef\u4ee5\u83b7\u5f97\u7c7b\u522b\u6982\u7387\u4fe1\u606f\u3002 \u4f46\u662f\u8fd9\u4e2a\u6982\u7387\u53ea\u80fd\u6807\u8bc6\u6574\u4e2a\u56fe\u7247\u7684\u7c7b\u522b\uff0c\u4e0d\u80fd\u6807\u8bc6\u6bcf\u4e2a\u50cf\u7d20\u70b9\u7684\u7c7b\u522b\uff0c\u6240\u4ee5\u8fd9\u79cd\u5168\u8fde\u63a5\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u56fe\u50cf\u5206\u5272\u3002 \u800cFCN\u63d0\u51fa\u53ef\u4ee5\u628a\u540e\u9762\u51e0\u4e2a\u5168\u8fde\u63a5\u90fd\u6362\u6210\u5377\u79ef\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u83b7\u5f97\u4e00\u5f202\u7ef4\u7684feature map\uff0c\u540e\u63a5softmax\u83b7\u5f97\u6bcf\u4e2a\u50cf\u7d20\u70b9\u7684\u5206\u7c7b\u4fe1\u606f\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u5206\u5272\u95ee\u9898\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7b80\u800c\u8a00\u4e4b\uff0cFCN\u548cCNN\u7684\u533a\u522b\u5c31\u662f\uff1aCNN\u5377\u79ef\u5c42\u4e4b\u540e\u8fde\u63a5\u7684\u662f\u5168\u8fde\u63a5\u5c42\uff1bFCN\u5377\u79ef\u5c42\u4e4b\u540e\u4ecd\u8fde\u63a5\u5377\u79ef\u5c42\uff0c\u8f93\u51fa\u7684\u662f\u4e0e\u8f93\u5165\u5927\u5c0f\u76f8\u540c\u7684\u7279\u5f81\u56fe\u3002","title":"1.FCN\u7f51\u7edc"},{"location":"imageSegmentation/section2/#11","text":"FCN\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\uff0c\u50cf\u7d20\u5bf9\u50cf\u7d20\u7684\u5168\u5377\u79ef\u7f51\u7edc\uff0c\u7528\u4e8e\u8fdb\u884c\u56fe\u50cf\u7684\u8bed\u4e49\u5206\u5272\u3002\u6574\u4f53\u7684\u7f51\u7edc\u7ed3\u6784\u5206\u4e3a\u4e24\u4e2a\u90e8\u5206\uff1a\u5168\u5377\u79ef\u90e8\u5206\u548c\u4e0a\u91c7\u6837\u90e8\u5206\u3002","title":"1.1 \u7f51\u7edc\u7ed3\u6784"},{"location":"imageSegmentation/section2/#111","text":"\u5168\u5377\u79ef\u90e8\u5206\u4f7f\u7528\u7ecf\u5178\u7684CNN\u7f51\u7edc\uff08\u4ee5AlexNet\u7f51\u7edc\u4e3a\u4f8b\uff09\uff0c\u5e76\u628a\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\u6362\u6210 \u5377\u79ef\uff0c\u7528\u4e8e\u63d0\u53d6\u7279\u5f81\u3002 \u5728\u4f20\u7edf\u7684Alex\u7ed3\u6784\u4e2d\uff0c\u524d5\u5c42\u662f\u5377\u79ef\u5c42\uff0c\u7b2c6\u5c42\u548c\u7b2c7\u5c42\u5206\u522b\u662f\u4e00\u4e2a\u957f\u5ea6\u4e3a4096\u7684\u4e00\u7ef4\u5411\u91cf\uff0c\u7b2c8\u5c42\u662f\u957f\u5ea6\u4e3a1000\u7684\u4e00\u7ef4\u5411\u91cf\uff0c\u5206\u522b\u5bf9\u5e941000\u4e2a\u4e0d\u540c\u7c7b\u522b\u7684\u6982\u7387\u3002 FCN\u5c06\u6700\u540e\u76843\u5c42\u8f6c\u6362\u4e3a\u5377\u79ef\u5c42\uff0c\u5377\u79ef\u6838\u7684\u5927\u5c0f (\u901a\u9053\u6570\uff0c\u5bbd\uff0c\u9ad8) \u5206\u522b\u4e3a (4096,1,1)\u3001(4096,1,1)\u3001(1000,1,1)\uff0c\u867d\u7136\u53c2\u6570\u6570\u76ee\u76f8\u540c\uff0c\u4f46\u662f\u8ba1\u7b97\u65b9\u6cd5\u5c31\u4e0d\u4e00\u6837\u4e86\uff0c\u8fd9\u65f6\u8fd8\u53ef\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u53c2\u6570\u3002 CNN\u4e2d\u8f93\u5165\u7684\u56fe\u50cf\u56fa\u5b9a\u6210227x227\u5927\u5c0f\uff0c\u7b2c\u4e00\u5c42pooling\u540e\u4e3a55x55\uff0c\u7b2c\u4e8c\u5c42pooling\u540e\u56fe\u50cf\u5927\u5c0f\u4e3a27x27\uff0c\u7b2c\u4e94\u5c42pooling\u540e\u7684\u56fe\u50cf\u5927\u5c0f\u4e3a13x13, \u800cFCN\u8f93\u5165\u7684\u56fe\u50cf\u662fH*W\u5927\u5c0f\uff0c\u7b2c\u4e00\u5c42pooling\u540e\u53d8\u4e3a\u539f\u56fe\u5927\u5c0f\u7684\u00bd\uff0c\u7b2c\u4e8c\u5c42\u53d8\u4e3a\u539f\u56fe\u5927\u5c0f\u7684\u00bc\uff0c\u7b2c\u4e94\u5c42\u53d8\u4e3a\u539f\u56fe\u5927\u5c0f\u7684\u215b\uff0c\u7b2c\u516b\u5c42\u53d8\u4e3a\u539f\u56fe\u5927\u5c0f\u76841/16\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u7ecf\u8fc7\u591a\u6b21\u5377\u79ef\u548cpooling\u4ee5\u540e\uff0c\u5f97\u5230\u7684\u56fe\u50cf\u8d8a\u6765\u8d8a\u5c0f\uff0c\u5206\u8fa8\u7387\u8d8a\u6765\u8d8a\u4f4e\u3002\u5bf9\u6700\u7ec8\u7684\u7279\u5f81\u56fe\u8fdb\u884cupsampling\uff0c\u628a\u56fe\u50cf\u8fdb\u884c\u653e\u5927\u5230\u539f\u56fe\u50cf\u7684\u5927\u5c0f\uff0c\u5c31\u5f97\u5230\u539f\u56fe\u50cf\u7684\u5206\u5272\u7ed3\u679c\u3002","title":"1.1.1 \u5168\u5377\u79ef\u90e8\u5206"},{"location":"imageSegmentation/section2/#112","text":"\u4e0a\u91c7\u6837\u90e8\u5206\u5c06\u6700\u7ec8\u5f97\u5230\u7684\u7279\u5f81\u56fe\u4e0a\u91c7\u6837\u5f97\u5230\u539f\u56fe\u50cf\u5927\u5c0f\u7684\u8bed\u4e49\u5206\u5272\u7ed3\u679c\u3002 \u5728\u8fd9\u91cc\u91c7\u7528\u7684\u4e0a\u91c7\u6837\u65b9\u6cd5\u662f\u53cd\u5377\u79ef\uff08Deconvolution\uff09\uff0c\u4e5f\u53eb\u505a\u8f6c\u7f6e\u5377\u79ef\uff08Transposed Convolution\uff09\uff1a \u53cd\u5377\u79ef\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u6b63\u5411\u5377\u79ef \u901a\u4fd7\u7684\u8bb2\uff0c\u5c31\u662f\u8f93\u5165\u88650+\u5377\u79ef\u3002\u5148\u6309\u7167\u4e00\u5b9a\u7684\u6bd4\u4f8b\u901a\u8fc7\u88650\u6765\u6269\u5927\u8f93\u5165\u56fe\u50cf\u7684\u5c3a\u5bf8\uff0c\u518d\u8fdb\u884c\u6b63\u5411\u5377\u79ef\u5373\u53ef\u3002 \u5982\u4e0b\u56fe\u6240\u793a\uff1a\u8f93\u5165\u56fe\u50cf\u5c3a\u5bf8\u4e3a3x3\uff0c\u5377\u79ef\u6838kernel\u4e3a3x3\uff0c\u6b65\u957fstrides=2\uff0c\u586b\u5145padding=1 \u5047\u8bbe\u53cd\u5377\u79ef\u7684\u8f93\u5165\u662fn x n \uff0c\u53cd\u5377\u79ef\u7684\u8f93\u51fa\u4e3amxm \uff0cpadding=p\uff0cstride=s\uff0ckernel_size = k\u3002 \u90a3\u4e48\u6b64\u65f6\u53cd\u5377\u79ef\u7684\u8f93\u51fa\u5c31\u4e3a\uff1a m = s(n-1) + k -2p m = s(n-1) + k -2p \u4e0e\u6b63\u5411\u5377\u79ef\u4e0d\u540c\u7684\u662f\uff0c\u8981\u5148\u6839\u636e\u6b65\u957fstrides\u5bf9\u8f93\u5165\u7684\u5185\u90e8\u8fdb\u884c\u586b\u5145\uff0c\u8fd9\u91ccstrides\u53ef\u4ee5\u7406\u89e3\u6210\u8f93\u5165\u653e\u5927\u7684\u500d\u6570\uff0c\u800c\u4e0d\u80fd\u7406\u89e3\u6210\u5377\u79ef\u79fb\u52a8\u7684\u6b65\u957f\u3002 \u8fd9\u6837\u6211\u4eec\u5c31\u53ef\u4ee5\u901a\u8fc7\u53cd\u5377\u79ef\u5b9e\u73b0\u4e0a\u91c7\u6837\u3002","title":"1.1.2 \u4e0a\u91c7\u6837\u90e8\u5206"},{"location":"imageSegmentation/section2/#12","text":"\u5982\u679c\u53ea\u5229\u7528\u53cd\u5377\u79ef\u5bf9\u6700\u540e\u4e00\u5c42\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u4e0a\u91c7\u6837\u7684\u5230\u539f\u56fe\u5927\u5c0f\u7684\u5206\u5272\uff0c\u7531\u4e8e\u6700\u540e\u4e00\u5c42\u7684\u7279\u5f81\u56fe\u592a\u5c0f\uff0c\u4f1a\u635f\u5931\u5f88\u591a\u7ec6\u8282\u3002\u56e0\u800c\u63d0\u51fa\u589e\u52a0Skips\u7ed3\u6784\u5c06\u6700\u540e\u4e00\u5c42\u7684\u9884\u6d4b\uff08\u6709\u66f4\u5bcc\u7684\u5168\u5c40\u4fe1\u606f\uff09\u548c\u66f4\u6d45\u5c42\uff08\u6709\u66f4\u591a\u7684\u5c40\u90e8\u7ec6\u8282\uff09\u7684\u9884\u6d4b\u7ed3\u5408\u8d77\u6765\u3002 \u90a3\u4e48\uff1a \u5bf9\u4e8eFCN-32s\uff0c\u76f4\u63a5\u5bf9pool5 feature\u8fdb\u884c32\u500d\u4e0a\u91c7\u6837\u83b7\u5f9732x upsampled feature\uff0c\u518d\u5bf932x upsampled feature\u6bcf\u4e2a\u70b9\u505asoftmax prediction\u83b7\u5f9732x upsampled feature prediction\uff08\u5373\u5206\u5272\u56fe\uff09\u3002 \u5bf9\u4e8eFCN-16s\uff0c\u9996\u5148\u5bf9pool5 feature\u8fdb\u884c2\u500d\u4e0a\u91c7\u6837\u83b7\u5f972x upsampled feature\uff0c\u518d\u628apool4 feature\u548c2x upsampled feature\u9010\u70b9\u76f8\u52a0\uff0c\u7136\u540e\u5bf9\u76f8\u52a0\u7684feature\u8fdb\u884c16\u500d\u4e0a\u91c7\u6837\uff0c\u5e76softmax prediction\uff0c\u83b7\u5f9716x upsampled feature prediction\u3002 \u5bf9\u4e8eFCN-8s\uff0c\u9996\u5148\u8fdb\u884cpool4+2x upsampled feature\u9010\u70b9\u76f8\u52a0\uff0c\u7136\u540e\u53c8\u8fdb\u884cpool3+2x upsampled\u9010\u70b9\u76f8\u52a0\uff0c\u5373\u8fdb\u884c\u66f4\u591a\u6b21\u7279\u5f81\u878d\u5408\u3002\u5177\u4f53\u8fc7\u7a0b\u4e0e16s\u7c7b\u4f3c\uff0c\u4e0d\u518d\u8d58\u8ff0\u3002 \u4e0b\u9762\u6709\u4e00\u5f2032\u500d\uff0c16\u500d\u548c8\u500d\u4e0a\u91c7\u6837\u5f97\u5230\u7684\u7ed3\u679c\u56fe\u5bf9\u6bd4\uff1a \u53ef\u4ee5\u770b\u5230\u968f\u7740\u4e0a\u91c7\u6837\u505a\u5f97\u8d8a\u591a\uff0c\u5206\u5272\u7ed3\u679c\u8d8a\u6765\u8d8a\u7cbe\u7ec6\u3002","title":"1.2 \u8df3\u5c42\u8fde\u63a5"},{"location":"imageSegmentation/section2/#13","text":"\u4f18\u70b9 \u7aef\u5230\u7aef\u7684\uff0c\u53ef\u4ee5\u63a5\u53d7\u4efb\u610f\u5927\u5c0f\u7684\u8f93\u5165\u56fe\u50cf\u5c3a\u5bf8\uff0c\u6bd4\u8f83\u9ad8\u6548\u3002 \u5c40\u9650\u6027 \u5f97\u5230\u7684\u7ed3\u679c\u8fd8\u662f\u4e0d\u591f\u7cbe\u7ec6\u3002\u8fdb\u884c8\u500d\u4e0a\u91c7\u6837\u867d\u7136\u6bd432\u500d\u7684\u6548\u679c\u597d\u4e86\u5f88\u591a\uff0c\u4f46\u662f\u4e0a\u91c7\u6837\u7684\u7ed3\u679c\u8fd8\u662f\u6bd4\u8f83\u6a21\u7cca\u7684\uff0c\u5bf9\u56fe\u50cf\u4e2d\u7684\u7ec6\u8282\u4e0d\u654f\u611f\u3002\u800c\u4e14\u5728\u5bf9\u5404\u4e2a\u50cf\u7d20\u8fdb\u884c\u5206\u7c7b\u65f6\uff0c\u6ca1\u6709\u8003\u8651\u50cf\u7d20\u4e0e\u50cf\u7d20\u4e4b\u95f4\u7684\u5173\u7cfb\u3002","title":"1.3 \u603b\u7ed3"},{"location":"imageSegmentation/section2/#2unet","text":"Unet\u7f51\u7edc\u662f\u5efa\u7acb\u5728FCN\u7f51\u7edc\u57fa\u7840\u4e0a\u7684\uff0c\u5b83\u7684\u7f51\u7edc\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u603b\u4f53\u6765\u8bf4\u4e0eFCN\u601d\u8def\u975e\u5e38\u7c7b\u4f3c\u3002 \u6574\u4e2a\u7f51\u7edc\u7531\u7f16\u7801\u90e8\u5206\uff08\u5de6\uff09 \u548c \u89e3\u7801\u90e8\u5206\uff08\u53f3\uff09\u7ec4\u6210\uff0c\u7c7b\u4f3c\u4e8e\u4e00\u4e2a\u5927\u5927\u7684U\u5b57\u6bcd\uff0c\u5177\u4f53\u4ecb\u7ecd\u5982\u4e0b\uff1a 1\u3001\u7f16\u7801\u90e8\u5206\u662f\u5178\u578b\u7684\u5377\u79ef\u7f51\u7edc\u67b6\u6784\uff1a \u67b6\u6784\u4e2d\u542b\u6709\u7740\u4e00\u79cd\u91cd\u590d\u7ed3\u6784\uff0c\u6bcf\u6b21\u91cd\u590d\u4e2d\u90fd\u67092\u4e2a 3 x 3\u5377\u79ef\u5c42\u3001\u975e\u7ebf\u6027ReLU\u5c42\u548c\u4e00\u4e2a 2 x 2 max pooling\u5c42\uff08stride\u4e3a2\uff09\u3002\uff08\u56fe\u4e2d\u7684\u84dd\u7bad\u5934\u3001\u7ea2\u7bad\u5934\uff0c\u6ca1\u753bReLu\uff09 \u6bcf\u4e00\u6b21\u4e0b\u91c7\u6837\u540e\u6211\u4eec\u90fd\u628a\u7279\u5f81\u901a\u9053\u7684\u6570\u91cf\u52a0\u500d 2\u3001\u89e3\u7801\u90e8\u5206\u4e5f\u4f7f\u7528\u4e86\u7c7b\u4f3c\u7684\u6a21\u5f0f\uff1a \u6bcf\u4e00\u6b65\u90fd\u9996\u5148\u4f7f\u7528\u53cd\u5377\u79ef(up-convolution)\uff0c\u6bcf\u6b21\u4f7f\u7528\u53cd\u5377\u79ef\u90fd\u5c06\u7279\u5f81\u901a\u9053\u6570\u91cf\u51cf\u534a\uff0c\u7279\u5f81\u56fe\u5927\u5c0f\u52a0\u500d\u3002\uff08\u56fe\u4e2d\u7eff\u7bad\u5934\uff09 \u53cd\u5377\u79ef\u8fc7\u540e\uff0c\u5c06\u53cd\u5377\u79ef\u7684\u7ed3\u679c\u4e0e\u7f16\u7801\u90e8\u5206\u4e2d\u5bf9\u5e94\u6b65\u9aa4\u7684\u7279\u5f81\u56fe\u62fc\u63a5\u8d77\u6765\u3002\uff08\u767d/\u84dd\u5757\uff09 \u7f16\u7801\u90e8\u5206\u4e2d\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u7a0d\u5927\uff0c\u5c06\u5176\u4fee\u526a\u8fc7\u540e\u8fdb\u884c\u62fc\u63a5\u3002\uff08\u5de6\u8fb9\u6df1\u84dd\u865a\u7ebf\uff09 \u5bf9\u62fc\u63a5\u540e\u7684map\u518d\u8fdb\u884c2\u6b213 x 3\u7684\u5377\u79ef\u3002\uff08\u53f3\u4fa7\u84dd\u7bad\u5934\uff09 \u6700\u540e\u4e00\u5c42\u7684\u5377\u79ef\u6838\u5927\u5c0f\u4e3a1 x 1\uff0c\u5c0664\u901a\u9053\u7684\u7279\u5f81\u56fe\u8f6c\u5316\u4e3a\u7279\u5b9a\u7c7b\u522b\u6570\u91cf\uff08\u5206\u7c7b\u6570\u91cf\uff09\u7684\u7ed3\u679c\u3002\uff08\u56fe\u4e2d\u9752\u8272\u7bad\u5934\uff09 \u603b\u7ed3 \u4e86\u89e3FCN\u7684\u7ed3\u6784 FCN\u7f51\u7edc\u4e0eCNN\u7684\u4e0d\u540c\u662f\u5c06\u5168\u8fde\u63a5\u5c42\u66ff\u6362\u4e3a\u5377\u79ef\u5c42\u63d0\u53d6\u56fe\u50cf\u7684\u7279\u5f81\uff0c\u83b7\u53d6\u4e8c\u7ef4\u7684\u7279\u5f81\u56fe\uff0c\u5f97\u5230\u56fe\u50cf\u7684\u5206\u5272\u7ed3\u679c\uff0c\u6574\u4e2a\u7f51\u7edc\u53ef\u5206\u4e3a\u5168\u5377\u79ef\u90e8\u5206\u548c\u4e0a\u91c7\u6837\u4e24\u90e8\u5206 \u4e86\u89e3FCN\u7684\u4e0a\u91c7\u6837\u65b9\u6cd5\u53ca\u8df3\u5c42\u8fde\u63a5 \u4e0a\u91c7\u6837\uff1a\u4f7f\u7528\u53cd\u5377\u79ef\u5b8c\u6210 \u8df3\u5c42\u8fde\u63a5\uff1a\u5c06\u7f51\u7edc\u63d0\u53d6\u7684\u6df1\u5c42\u7279\u5f81\u548c\u6d45\u5c42\u7279\u5f81\u7ed3\u5408\u8d77\u6765 \u638c\u63e1Unet\u7f51\u7edc\u7ed3\u6784 \u7c7b\u4f3c\u4e8e\u4e00\u4e2a\u5927\u5927\u7684U\u5b57\u6bcd\uff1a\u9996\u5148\u8fdb\u884c\u5377\u79ef\u548c\u6c60\u5316\u6765\u5b8c\u6210\u4e0b\u91c7\u6837\uff1b\u7136\u540e\u901a\u8fc7\u53cd\u5377\u79ef\u8fdb\u884c\u4e0a\u91c7\u6837\uff0ccrop\u4e4b\u524d\u7684\u4f4e\u5c42feature map\uff0c\u8fdb\u884c\u878d\u5408\uff1b\u7136\u540e\u518d\u6b21\u4e0a\u91c7\u6837\u3002\u91cd\u590d\u8fd9\u4e2a\u8fc7\u7a0b\uff0c\u76f4\u5230\u83b7\u5f97\u8f93\u51fa\u7684feature map\uff0c\u6700\u540e\u7ecf\u8fc7softmax\u83b7\u5f97\u8f93\u51fa\u5206\u5272\u7ed3\u679c","title":"2.Unet\u7f51\u7edc"},{"location":"imageSegmentation/section3/","text":"5.3 UNet\u6848\u4f8b \u00b6 \u5b66\u4e60\u76ee\u6807 \u4e86\u89e3\u5ba0\u7269\u56fe\u50cf\u5206\u5272\u6570\u636e\u96c6 \u80fd\u591f\u5b8c\u6210UNet\u7f51\u7edc\u7684\u642d\u5efa \u80fd\u591f\u5b8c\u6210UNet\u7f51\u7edc\u7684\u8bad\u7ec3\u4e0e\u9884\u6d4b 1.1 \u4efb\u52a1\u53ca\u6570\u636e\u96c6\u7b80\u4ecb \u00b6 \u4f7fOxford-IIIT Pet Dataset\u5ba0\u7269\u56fe\u50cf\u5206\u5272\u6570\u636e\u96c6\uff0c\u5305\u542b37\u79cd\u5ba0\u7269\u7c7b\u522b\uff0c\u5176\u4e2d\u670912\u79cd\u732b\u7684\u7c7b\u522b\u548c25\u79cd\u72d7\u7684\u7c7b\u522b\uff0c\u6bcf\u4e2a\u7c7b\u522b\u5927\u7ea6\u6709200\u5f20\u56fe\u7247\uff0c\u6240\u6709\u56fe\u50cf\u90fd\u5177\u6709\u54c1\u79cd\uff0c\u5934\u90e8ROI\u548c\u50cf\u7d20\u7ea7\u5206\u5272\u7684\u6807\u6ce8\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u56fe\u50cf\u5206\u5272\u65f6\u5171\u5206\u4e3a\u524d\u666f\uff0c\u80cc\u666f\u548c\u4e0d\u786e\u5b9a3\u79cd\uff0c\u56fe\u50cf\u6570\u636e\u5305\u542b\u7684\u7c7b\u522b\u53ca\u5bf9\u5e94\u7684\u6570\u91cf\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6570\u636e\u96c6\u7684\u76ee\u5f55\u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a\\segdata 1\u3001Images\uff1a\u5b58\u50a8\u6570\u636e\u96c6\u7684\u56fe\u7247\u6570\u636e\uff0c\u5176\u4e2d\u56fe\u7247\u6587\u4ef6\u540d\u662f\u4ee5\u5927\u5199\u5f00\u5934\u4e3a\u201ccat\u201d\uff0c\u5c0f\u5199\u5f00\u5934\u4e3a\u201cdog\u201d\u3002 2\u3001Annotations\uff1a\u6807\u6ce8\u4fe1\u606f\uff0c\u5185\u5bb9\u5982\u4e0b\u6240\u793a\uff1a list.txt\u4e2d\u7684\u5185\u5bb9\u683c\u5f0f\u5982\u4e0b\u6240\u793a\uff0c\u5176\u4e2dClass ID\u5bf9\u5e94\u774037\u7c7b\u4e2d\u7684\u67d0\u4e00\u7c7b\uff0cSPECIES\u662f\u603b\u5206\u7c7b\uff0c1\u662f\u732b\uff0c2\u662f\u72d7\uff1bBreedID\u662f\u732b\u72d7\u5206\u7c7b\u4e2d\u7684\u5b50\u5206\u7c7b\uff0c\u732b\u7684\u5b50\u5206\u7c7b\u4e3a12\u7c7b\uff0c\u800c\u72d7\u7684\u5b50\u5206\u7c7b\u4e3a25\u7c7b\u3002 trimaps\u662f\u56fe\u50cf\u7684\u50cf\u7d20\u7ea7\u6807\u6ce8\u4fe1\u606f\uff0c\u662f\u6211\u4eec\u7684\u76ee\u6807\u503c \u63a5\u4e0b\u6765\u6211\u4eec\u5229\u7528UNET\u7f51\u7edc\u8fdb\u884c\u5ba0\u7269\u6570\u636e\u96c6\u5206\u5272\u3002 1.2 \u6570\u636e\u96c6\u83b7\u53d6 \u00b6 \u5728\u8fdb\u884c\u6a21\u578b\u6784\u5efa\u4e4b\u524d\uff0c\u6211\u4eec\u5c06\u8bfb\u53d6\u6570\u636e\u96c6\uff0c\u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305\uff1a import os from IPython.display import Image , display from tensorflow.keras.preprocessing.image import load_img import PIL from PIL import ImageOps 1.2.1 \u8def\u5f84\u53ca\u76f8\u5173\u53c2\u6570\u8bbe\u7f6e \u00b6 \u5728\u8fd9\u91cc\u6211\u4eec\u8bbe\u7f6e\u6570\u636e\u7684\u8def\u5f84\uff0c\u56fe\u50cf\u7684\u5927\u5c0f\uff0cbatch_size\u548c\u7c7b\u522b\u6570\u91cf\uff0c\u5728\u8fd9\u91cc\u4f7f\u7528\u4e86\u4e00\u4e2a\u6280\u5de7\uff0c\u56fe\u50cf\u5206\u5272\u65f6\u5171\u5206\u4e3a\u524d\u666f\uff0c\u80cc\u666f\u548c\u4e0d\u786e\u5b9a3\u79cd\uff0c\u5206\u522b\u6807\u6ce8\u4e3a\uff1a1\uff0c2\uff0c3\uff0c\u5bf9\u7c7b\u522b\u8fdb\u884c\u70ed\u7f16\u7801\u65f6\uff0c\u6211\u4eec\u7f16\u7801\u4e3a\uff1a1\uff1a0010\uff1b2\uff1a0100\uff1b3\uff1a1000\uff0c\u8fd9\u6837\u5728\u8bbe\u7f6e\u7c7b\u522b\u4e2a\u6570\u65f6\u8bbe\u4e3a4\u5373\u53ef\u3002 # \u56fe\u7247\u4f4d\u7f6e input_dir = \"segdata/images/\" # \u6807\u6ce8\u4fe1\u606f\u4f4d\u7f6e target_dir = \"segdata/annotations/trimaps/\" # \u56fe\u50cf\u5927\u5c0f\u8bbe\u7f6e\u53ca\u7c7b\u522b\u4fe1\u606f img_size = ( 160 , 160 ) batch_size = 32 num_classes = 4 # \u56fe\u50cf\u7684\u8def\u5f84 input_img_paths = sorted ( [ os . path . join ( input_dir , fname ) for fname in os . listdir ( input_dir ) if fname . endswith ( \".jpg\" ) ] ) # \u76ee\u6807\u503c\u8def\u5f84 target_img_paths = sorted ( [ os . path . join ( target_dir , fname ) for fname in os . listdir ( target_dir ) if fname . endswith ( \".png\" ) and not fname . startswith ( \".\" ) ] ) 1.2.2 \u6570\u636e\u5c55\u793a \u00b6 \u5c06\u56fe\u50cf\u53ca\u5bf9\u5e94\u7684\u7ed3\u679c\u8fdb\u884c\u5c55\u793a\uff1a # \u663e\u793a\u4e00\u4e2a\u56fe\u50cf display ( Image ( filename = input_img_paths [ 10 ])) \u6807\u6ce8\u4fe1\u606f\u4e2d\u53ea\u67093\u4e2a\u503c\uff0c\u6211\u4eec\u4f7f\u7528PIL.ImageOps.autocontrast\u8fdb\u884c\u5c55\u793a\uff0c\u8be5\u65b9\u6cd5\u8ba1\u7b97\u8f93\u5165\u56fe\u50cf\u7684\u76f4\u65b9\u56fe\uff0c\u7136\u540e\u91cd\u65b0\u6620\u5c04\u56fe\u50cf\uff0c\u6700\u6697\u50cf\u7d20\u53d8\u4e3a\u9ed1\u8272\uff0c\u53730\uff0c\u6700\u4eae\u7684\u53d8\u4e3a\u767d\u8272\uff0c\u5373255\uff0c\u5176\u4ed6\u7684\u503c\u4ee5\u5176\u4ed6\u7684\u7070\u5ea6\u503c\u8fdb\u884c\u663e\u793a\uff0c\u5728\u8fd9\u91cc\u524d\u666f\uff0c\u80cc\u666f\u548c\u4e0d\u786e\u5b9a\u5206\u522b\u6807\u6ce8\u4e3a\uff1a1\uff0c2\uff0c3\uff0c\u6240\u4ee5\u524d\u666f\u6700\u5c0f\u663e\u793a\u4e3a\u9ed1\u8272\uff0c\u4e0d\u786e\u5b9a\u7684\u533a\u57df\u6700\u5927\u663e\u793a\u4e3a\u767d\u8272\u3002 # \u663e\u793a\u6807\u6ce8\u56fe\u50cf img = PIL . ImageOps . autocontrast ( load_img ( target_img_paths [ 10 ])) display ( img ) 1.2.3 \u6784\u5efa\u6570\u636e\u96c6\u751f\u6210\u5668 \u00b6 \u5229\u7528keras.utils.Sequence\u6784\u5efa\u56fe\u50cf\u751f\u6210\u5668\u6765\u8bfb\u53d6\u6570\u636e\uff0c\u6bcf\u4e2aSequence\u5fc5\u987b\u5b9e\u73b0 getitem \u548c len \u65b9\u6cd5\uff0c\u901a\u8fc7 getitem \u5e94\u8fd4\u56de\u5b8c\u6574\u7684\u6279\u6b21\uff0c Sequence\u662f\u8fdb\u884c\u591a\u5904\u7406\u7684\u66f4\u5b89\u5168\u65b9\u6cd5\u3002\u8fd9\u79cd\u7ed3\u6784\u4fdd\u8bc1\u4e86\u7f51\u7edc\u5728\u6bcf\u4e2a\u65f6\u95f4\u6bb5\u7684\u6bcf\u4e2a\u6837\u672c\u4e0a\u53ea\u4f1a\u8bad\u7ec3\u4e00\u6b21\u3002\u4e3b\u8981\u5b9e\u73b03\u4e2a\u65b9\u6cd5\uff1binit,len\u548cgetitem\u5373\u53ef\u3002 from tensorflow import keras import numpy as np from tensorflow.keras.preprocessing.image import load_img # \u6570\u636e\u96c6\u83b7\u53d6\uff1a class OxfordPets ( keras . utils . Sequence ): # \u5728__init__\u65b9\u6cd5\u4e2d\u6307\u5b9abatch_size,img_size,input_img_paths,target_img_paths def __init__ ( self , batch_size , img_size , input_img_paths , target_img_paths ): self . batch_size = batch_size # \u6279\u91cf\u5927\u5c0f self . img_size = img_size # \u56fe\u50cf\u5927\u5c0f self . input_img_paths = input_img_paths # \u8f93\u5165\u56fe\u50cf\u8def\u5f84 self . target_img_paths = target_img_paths # \u6807\u6ce8\u56fe\u50cf\u8def\u5f84 def __len__ ( self ): # \u8ba1\u7b97\u8fed\u4ee3\u6b21\u6570 return len ( self . target_img_paths ) // self . batch_size def __getitem__ ( self , idx ): \"\"\" \u83b7\u53d6\u6bcf\u4e00\u4e2abatch\u6570\u636e \"\"\" i = idx * self . batch_size # \u83b7\u53d6\u8f93\u5165\u7684\u56fe\u50cf\u6570\u636e batch_input_img_paths = self . input_img_paths [ i : i + self . batch_size ] # \u83b7\u53d6\u6807\u7b7e\u6570\u636e batch_target_img_paths = self . target_img_paths [ i : i + self . batch_size ] # \u6784\u5efa\u7279\u5f81\u503c\u6570\u636e\uff1a\u83b7\u53d6\u56fe\u50cf\u6570\u636e\u4e2d\u6bcf\u4e2a\u50cf\u7d20\u7684\u6570\u636e\u5b58\u50a8\u5728x\u4e2d x = np . zeros (( batch_size ,) + self . img_size + ( 3 ,), dtype = \"float32\" ) for j , path in enumerate ( batch_input_img_paths ): img = load_img ( path , target_size = self . img_size ) x [ j ] = img # \u6784\u5efa\u76ee\u6807\u503c\u6570\u636e\uff1a\u83b7\u53d6\u6807\u6ce8\u56fe\u50cf\u4e2d\u6bcf\u4e2a\u50cf\u7d20\u4e2d\u7684\u6570\u636e\u5b58\u5728y\u4e2d y = np . zeros (( batch_size ,) + self . img_size + ( 1 ,), dtype = \"uint8\" ) for j , path in enumerate ( batch_target_img_paths ): img = load_img ( path , target_size = self . img_size , color_mode = \"grayscale\" ) y [ j ] = np . expand_dims ( img , 2 ) return x , y \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u4f7f\u7528\u8be5\u65b9\u6cd5\u6765\u83b7\u53d6\u6570\u636e\u3002 1.3 \u6a21\u578b\u6784\u5efa \u00b6 Unet\u7684\u7f51\u7edc\u7684\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4e3b\u8981\u5206\u4e3a\u4e24\u90e8\u5206\uff1a\u7f16\u7801\u548c\u89e3\u7801\u90e8\u5206\uff0c\u6211\u4eec\u5206\u522b\u8fdb\u884c\u6784\u5efa \u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305\uff1a import tensorflow as tf import tensorflow.keras as keras from tensorflow.keras.layers import Input , Conv2D , Conv2DTranspose from tensorflow.keras.layers import MaxPooling2D , Cropping2D , Concatenate from tensorflow.keras.layers import Lambda , Activation , BatchNormalization , Dropout from tensorflow.keras.models import Model 1.3.1 \u7f16\u7801\u90e8\u5206 \u00b6 \u7f16\u7801\u90e8\u5206\u7684\u7279\u70b9\u662f\uff1a \u67b6\u6784\u4e2d\u542b\u6709\u7740\u4e00\u79cd\u91cd\u590d\u7ed3\u6784\uff0c\u6bcf\u6b21\u91cd\u590d\u4e2d\u90fd\u67092\u4e2a 3 x 3\u5377\u79ef\u5c42\u3001\u975e\u7ebf\u6027ReLU\u5c42\u548c\u4e00\u4e2a 2 x 2 max pooling\u5c42\uff08stride\u4e3a2\uff09\u3002 \u6bcf\u4e00\u6b21\u4e0b\u91c7\u6837\u540e\u6211\u4eec\u90fd\u628a\u7279\u5f81\u901a\u9053\u7684\u6570\u91cf\u52a0\u500d \u6bcf\u6b21\u91cd\u590d\u90fd\u6709\u4e24\u4e2a\u8f93\u51fa\uff1a\u4e00\u4e2a\u7528\u4e8e\u7f16\u7801\u90e8\u5206\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u4e00\u4e2a\u7528\u4e8e\u89e3\u7801\u90e8\u5206\u7684\u7279\u5f81\u878d\u5408 \u6784\u5efa\u7684\u4ee3\u7801\u5982\u4e0b\u6240\u793a\uff1a # \u8f93\u5165\uff1a\u8f93\u5165\u5f20\u91cf\uff0c\u5377\u79ef\u6838\u4e2a\u6570 def downsampling_block ( input_tensor , filters ): # \u8f93\u5165\u5c42 x = Conv2D ( filters , kernel_size = ( 3 , 3 ), padding = 'same' )( input_tensor ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b\u51fd\u6570 x = Activation ( 'relu' )( x ) # \u5377\u79ef\u5c42 x = Conv2D ( filters , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b\u5c42 x = Activation ( 'relu' )( x ) # \u8fd4\u56de\u7684\u662f\u6c60\u5316\u540e\u7684\u503c\u548c\u6fc0\u6d3b\u672a\u6c60\u5316\u7684\u503c\uff0c\u6fc0\u6d3b\u540e\u672a\u6c60\u5316\u7684\u503c\u7528\u4e8e\u89e3\u7801\u90e8\u5206\u7279\u5f81\u7ea7\u8054 return MaxPooling2D ( pool_size = ( 2 , 2 ))( x ), x 1.3.2 \u89e3\u7801\u90e8\u5206 \u00b6 \u89e3\u7801\u90e8\u5206\u4e5f\u4f7f\u7528\u4e86\u91cd\u590d\u6a21\u5757\uff1a \u6bcf\u4e00\u4e2a\u6a21\u5757\u6709\u4e24\u4e2a\u8f93\u5165\uff1a\u4e00\u4e2a\u662f\u7f16\u7801\u9636\u6bb5\u7684\u7279\u5f81\u56fe\uff0c\u4e00\u4e2a\u662f\u89e3\u7801\u90e8\u5206\u7684\u7279\u5f81\u56fe \u6bcf\u4e00\u6b65\u90fd\u9996\u5148\u4f7f\u7528\u53cd\u5377\u79ef(up-convolution)\uff0c\u6bcf\u6b21\u4f7f\u7528\u53cd\u5377\u79ef\u90fd\u5c06\u7279\u5f81\u901a\u9053\u6570\u91cf\u51cf\u534a\uff0c\u7279\u5f81\u56fe\u5927\u5c0f\u52a0\u500d\u3002\uff08\u56fe\u4e2d\u7eff\u7bad\u5934\uff09 \u53cd\u5377\u79ef\u8fc7\u540e\uff0c\u5c06\u53cd\u5377\u79ef\u7684\u7ed3\u679c\u4e0e\u7f16\u7801\u90e8\u5206\u4e2d\u5bf9\u5e94\u6b65\u9aa4\u7684\u7279\u5f81\u56fe\u62fc\u63a5\u8d77\u6765\u3002\uff08\u767d/\u84dd\u5757\uff09 \u7f16\u7801\u90e8\u5206\u4e2d\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u7a0d\u5927\uff0c\u5c06\u5176\u4fee\u526a\u8fc7\u540e\u8fdb\u884c\u62fc\u63a5\u3002\uff08\u5de6\u8fb9\u6df1\u84dd\u865a\u7ebf\uff09 \u5bf9\u62fc\u63a5\u540e\u7684map\u518d\u8fdb\u884c2\u6b213 x 3\u7684\u5377\u79ef\u3002\uff08\u53f3\u4fa7\u84dd\u7bad\u5934\uff09 \u7f16\u7801\u5b9e\u73b0\u5982\u4e0b\uff1a # \u8f93\u5165\uff1a\u8f93\u5165\u5f20\u91cf\uff0c\u7279\u5f81\u878d\u5408\u7684\u5f20\u91cf\uff0c\u5377\u79ef\u6838\u4e2a\u6570 def upsampling_block ( input_tensor , skip_tensor , filters ): # \u53cd\u5377\u79ef x = Conv2DTranspose ( filters , kernel_size = ( 2 , 2 ), strides = ( 2 , 2 ), padding = \"same\" )( input_tensor ) # \u83b7\u53d6\u5f53\u524d\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8 _ , x_height , x_width , _ = x . shape # \u83b7\u53d6\u8981\u878d\u5408\u7684\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8 _ , s_height , s_width , _ = skip_tensor . shape # \u83b7\u53d6\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u5dee\u5f02 h_crop = s_height - x_height w_crop = s_width - x_width # \u82e5\u7279\u5f81\u56fe\u5927\u5c0f\u76f8\u540c\u4e0d\u8fdb\u884c\u88c1\u526a if h_crop == 0 and w_crop == 0 : y = skip_tensor #\u82e5\u7279\u5f81\u56fe\u5927\u5c0f\u4e0d\u540c\uff0c\u4f7f\u7ea7\u8054\u65f6\u50cf\u7d20\u5927\u5c0f\u4e00\u81f4 else : # \u83b7\u53d6\u7279\u5f81\u56fe\u88c1\u526a\u540e\u7684\u7279\u5f81\u56fe\u7684\u5927\u5c0f cropping = (( h_crop // 2 , h_crop - h_crop // 2 ), ( w_crop // 2 , w_crop - w_crop // 2 )) # \u7279\u5f81\u56fe\u88c1\u526a y = Cropping2D ( cropping = cropping )( skip_tensor ) # \u7279\u5f81\u878d\u5408 x = Concatenate ()([ x , y ]) # \u5377\u79ef x = Conv2D ( filters , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b\u5c42 x = Activation ( 'relu' )( x ) # \u5377\u79ef\u5c42 x = Conv2D ( filters , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b\u5c42 x = Activation ( 'relu' )( x ) return x 1.3.3 \u6a21\u578b\u6784\u5efa \u00b6 \u5c06\u7f16\u7801\u90e8\u5206\u548c\u89e3\u7801\u90e8\u5206\u7ec4\u5408\u4e00\u8d77\uff0c\u5c31\u53ef\u6784\u5efaunet\u7f51\u7edc\uff0c\u5728\u8fd9\u91ccunet\u7f51\u7edc\u7684\u6df1\u5ea6\u901a\u8fc7depth\u8fdb\u884c\u8bbe\u7f6e\uff0c\u5e76\u8bbe\u7f6e\u7b2c\u4e00\u4e2a\u7f16\u7801\u6a21\u5757\u7684\u5377\u79ef\u6838\u4e2a\u6570\u901a\u8fc7filter\u8fdb\u884c\u8bbe\u7f6e\uff0c\u901a\u8fc7\u4ee5\u4e0b\u6a21\u5757\u5c06\u7f16\u7801\u548c\u89e3\u7801\u90e8\u5206\u8fdb\u884c\u7ec4\u5408\uff1a # \u4f7f\u75283\u4e2a\u6df1\u5ea6\u6784\u5efaunet\u7f51\u7edc def unet ( imagesize , classes , features = 64 , depth = 3 ): # \u5b9a\u4e49\u8f93\u5165\u6570\u636e inputs = keras . Input ( shape = img_size + ( 3 ,)) x = inputs # \u7528\u6765\u5b58\u653e\u8fdb\u884c\u7279\u5f81\u878d\u5408\u7684\u7279\u5f81\u56fe skips = [] # \u6784\u5efa\u7f16\u7801\u90e8\u5206 for i in range ( depth ): x , x0 = downsampling_block ( x , features ) skips . append ( x0 ) # \u4e0b\u91c7\u6837\u8fc7\u7a0b\u4e2d\uff0c\u6df1\u5ea6\u589e\u52a0\uff0c\u7279\u5f81\u7ffb\u500d\uff0c\u5373\u6bcf\u6b21\u4f7f\u7528\u7ffb\u500d\u6570\u76ee\u7684\u6ee4\u6ce2\u5668 features *= 2 # \u5377\u79ef x = Conv2D ( filters = features , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b x = Activation ( 'relu' )( x ) # \u5377\u79ef x = Conv2D ( filters = features , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b x = Activation ( 'relu' )( x ) # \u89e3\u7801\u8fc7\u7a0b for i in reversed ( range ( depth )): # \u6df1\u5ea6\u589e\u52a0\uff0c\u7279\u5f81\u56fe\u901a\u9053\u51cf\u534a features //= 2 # \u4e0a\u91c7\u6837 x = upsampling_block ( x , skips [ i ], features ) # \u5377\u79ef x = Conv2D ( filters = classes , kernel_size = ( 1 , 1 ), padding = \"same\" )( x ) # \u6fc0\u6d3b outputs = Activation ( 'softmax' )( x ) # \u6a21\u578b\u5b9a\u4e49 model = keras . Model ( inputs , outputs ) return model \u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\uff1a model = unet ( img_size , 4 ) model . summary () \u67e5\u770b\u6a21\u578b\u7ed3\u6784\uff0c\u4e5f\u53ef\u4f7f\u7528\uff1a keras . utils . plot_model ( model ) \u8fdb\u884c\u53ef\u89c6\u5316\u3002 1.4 \u6a21\u578b\u8bad\u7ec3 \u00b6 1.4.1 \u6570\u636e\u96c6\u5212\u5206 \u00b6 \u6570\u636e\u96c6\u4e2d\u7684\u56fe\u50cf\u662f\u6309\u987a\u5e8f\u8fdb\u884c\u5b58\u50a8\u7684\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u5c06\u6570\u636e\u96c6\u6253\u4e71\u540e\uff0c\u9a8c\u8bc1\u96c6\u7684\u6570\u91cf1000\uff0c\u5269\u4f59\u7684\u4e3a\u8bad\u7ec3\u96c6\uff0c\u5212\u5206\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\uff1a import random # \u5c06\u6570\u636e\u96c6\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\uff0c\u5176\u4e2d\u9a8c\u8bc1\u96c6\u7684\u6570\u91cf\u8bbe\u4e3a1000 val_samples = 1000 # \u5c06\u6570\u636e\u96c6\u6253\u4e71(\u56fe\u50cf\u4e0e\u6807\u6ce8\u4fe1\u606f\u7684\u968f\u673a\u6570\u79cd\u5b50\u662f\u4e00\u6837\u7684\uff0c\u624d\u80fd\u4fdd\u8bc1\u6570\u636e\u7684\u6b63\u786e\u6027) random . Random ( 1337 ) . shuffle ( input_img_paths ) random . Random ( 1337 ) . shuffle ( target_img_paths ) # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e\u8def\u5f84 train_input_img_paths = input_img_paths [: - val_samples ] train_target_img_paths = target_img_paths [: - val_samples ] # \u83b7\u53d6\u9a8c\u8bc1\u96c6\u6570\u636e\u8def\u5f84 val_input_img_paths = input_img_paths [ - val_samples :] val_target_img_paths = target_img_paths [ - val_samples :] 1.4.2 \u6570\u636e\u83b7\u53d6 \u00b6 \u8bfb\u53d6\u5212\u5206\u597d\u7684\u6570\u636e\u96c6\u5f97\u5230\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a # \u83b7\u53d6\u8bad\u7ec3\u96c6 train_gen = OxfordPets ( batch_size , img_size , train_input_img_paths , train_target_img_paths ) # \u6a21\u578b\u9a8c\u8bc1\u96c6 val_gen = OxfordPets ( batch_size , img_size , val_input_img_paths , val_target_img_paths ) 1.4.3 \u6a21\u578b\u7f16\u8bd1 \u00b6 \u8fdb\u884c\u6a21\u578b\u7f16\u8bd1\uff0c\u8bbe\u7f6e\uff1a \u4f18\u5316\u65b9\u6cd5\uff1a\u4f7f\u7528rmsprop\u4f18\u5316\u65b9\u6cd5 \u635f\u5931\u51fd\u6570\uff1a\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u56e0\u4e3a\u6ca1\u6709\u5bf9\u76ee\u6807\u503c\u8fdb\u884c\u70ed\u7f16\u7801\uff0c\u6240\u4ee5\u4f7f\u7528sparse_categorical_crossentropy # \u6a21\u578b\u7f16\u8bd1 model . compile ( optimizer = \"rmsprop\" , loss = \"sparse_categorical_crossentropy\" ) 1.4.4 \u6a21\u578b\u8bad\u7ec3 \u00b6 \u8bbe\u7f6eepoch\u5bf9\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u6307\u660e\u9a8c\u8bc1\u96c6\u6570\u636e\uff1a # \u6a21\u578b\u8bad\u7ec3\uff0cepoch\u8bbe\u4e3a5 epochs = 15 model . fit ( train_gen , epochs = epochs , validation_data = val_gen ) \u8bad\u7ec3\u8fc7\u7a0b\u5982\u4e0b\uff1a Epoch 1 / 15 199 / 199 [ ============================== ] - 44 s 223 ms / step - loss : 0.9539 - val_loss : 13.5056 Epoch 2 / 15 199 / 199 [ ============================== ] - 44 s 221 ms / step - loss : 0.5145 - val_loss : 2.2228 Epoch 3 / 15 199 / 199 [ ============================== ] - 44 s 222 ms / step - loss : 0.4318 - val_loss : 0.4182 Epoch 4 / 15 199 / 199 [ ============================== ] - 44 s 221 ms / step - loss : 0.4027 - val_loss : 0.4100 Epoch 5 / 15 199 / 199 [ ============================== ] - 44 s 223 ms / step - loss : 0.3551 - val_loss : 0.3894 Epoch 6 / 15 199 / 199 [ ============================== ] - 44 s 220 ms / step - loss : 0.3226 - val_loss : 0.4020 Epoch 7 / 15 199 / 199 [ ============================== ] - 44 s 219 ms / step - loss : 0.3195 - val_loss : 0.4273 Epoch 8 / 15 199 / 199 [ ============================== ] - 44 s 220 ms / step - loss : 0.2789 - val_loss : 0.3707 Epoch 9 / 15 199 / 199 [ ============================== ] - 43 s 219 ms / step - loss : 0.2599 - val_loss : 0.4059 Epoch 10 / 15 199 / 199 [ ============================== ] - 44 s 222 ms / step - loss : 0.2440 - val_loss : 0.3799 Epoch 11 / 15 199 / 199 [ ============================== ] - 43 s 218 ms / step - loss : 0.2297 - val_loss : 0.4244 Epoch 12 / 15 199 / 199 [ ============================== ] - 43 s 218 ms / step - loss : 0.2179 - val_loss : 0.4320 Epoch 13 / 15 199 / 199 [ ============================== ] - 43 s 218 ms / step - loss : 0.2081 - val_loss : 0.4034 Epoch 14 / 15 199 / 199 [ ============================== ] - 44 s 220 ms / step - loss : 0.1977 - val_loss : 0.4034 Epoch 15 / 15 199 / 199 [ ============================== ] - 44 s 222 ms / step - loss : 0.1901 - val_loss : 0.4150 < tensorflow . python . keras . callbacks . History at 0x110063898 > \u968f\u7740\u8fed\u4ee3\u6b21\u6570\u7684\u589e\u52a0\uff0c\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u7684\u635f\u5931\u51fd\u6570\u53d8\u6362\u5982\u4e0b\u56fe\u6240\u793a\uff1a 1.5 \u6a21\u578b\u9884\u6d4b \u00b6 \u83b7\u53d6\u9a8c\u8bc1\u6570\u636e\u5e76\u8fdb\u884c\u9884\u6d4b # \u83b7\u53d6\u9a8c\u8bc1\u96c6\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u9884\u6d4b val_gen = OxfordPets ( batch_size , img_size , val_input_img_paths , val_target_img_paths ) val_preds = model . predict ( val_gen ) \u5b9a\u4e49\u9884\u6d4b\u7ed3\u679c\u663e\u793a\u7684\u65b9\u6cd5 # \u56fe\u50cf\u663e\u793a def display_mask ( i ): # \u83b7\u53d6\u5230\u7b2ci\u4e2a\u6837\u672c\u7684\u9884\u6d4b\u7ed3\u679c mask = np . argmax ( val_preds [ i ], axis =- 1 ) # \u7ef4\u5ea6\u8c03\u6574 mask = np . expand_dims ( mask , axis =- 1 ) # \u8f6c\u6362\u4e3a\u56fe\u50cf\uff0c\u5e76\u8fdb\u884c\u663e\u793a img = PIL . ImageOps . autocontrast ( keras . preprocessing . image . array_to_img ( mask )) display ( img ) \u9009\u62e9\u67d0\u4e00\u4e2a\u56fe\u50cf\u8fdb\u884c\u9884\u6d4b # \u9009\u4e2d\u9a8c\u8bc1\u96c6\u7684\u7b2c10\u4e2a\u56fe\u50cf i = 10 \u539f\u56fe\u50cf\u5c55\u793a # \u8f93\u5165\u56fe\u50cf\u663e\u793a display ( Image ( filename = val_input_img_paths [ i ])) \u76ee\u6807\u503c\u5c55\u793a # \u771f\u5b9e\u503c\u663e\u793a img = PIL . ImageOps . autocontrast ( load_img ( val_target_img_paths [ i ])) display ( img ) \u6a21\u578b\u9884\u6d4b\u7ed3\u679c # \u663e\u793a\u9884\u6d4b\u7ed3\u679c display_mask ( i ) \u603b\u7ed3 \u4e86\u89e3\u5ba0\u7269\u56fe\u50cf\u5206\u5272\u6570\u636e\u96c6 \u5ba0\u7269\u6570\u636e\u96c6\u8fdb\u884c\u5206\u5272\u65f6\u53ea\u6709\u524d\u666f\u3001\u80cc\u666f\u548c\u4e0d\u786e\u5b9a\u7684\u50cf\u7d20\u4e09\u79cd \u80fd\u591f\u5b8c\u6210UNet\u7f51\u7edc\u7684\u642d\u5efa \u642d\u5efa\u7f16\u7801\uff0c\u89e3\u7801\u90e8\u5206\u7684\u7f51\u7edc\uff0c\u5e76\u5c06\u4e24\u8005\u7ed3\u5408\u5728\u4e00\u8d77\u6784\u5efaUnet\u7f51\u7edc \u80fd\u591f\u5b8c\u6210UNet\u7f51\u7edc\u7684\u8bad\u7ec3\u4e0e\u9884\u6d4b","title":"UNet\u6848\u4f8b"},{"location":"imageSegmentation/section3/#53-unet","text":"\u5b66\u4e60\u76ee\u6807 \u4e86\u89e3\u5ba0\u7269\u56fe\u50cf\u5206\u5272\u6570\u636e\u96c6 \u80fd\u591f\u5b8c\u6210UNet\u7f51\u7edc\u7684\u642d\u5efa \u80fd\u591f\u5b8c\u6210UNet\u7f51\u7edc\u7684\u8bad\u7ec3\u4e0e\u9884\u6d4b","title":"5.3 UNet\u6848\u4f8b"},{"location":"imageSegmentation/section3/#11","text":"\u4f7fOxford-IIIT Pet Dataset\u5ba0\u7269\u56fe\u50cf\u5206\u5272\u6570\u636e\u96c6\uff0c\u5305\u542b37\u79cd\u5ba0\u7269\u7c7b\u522b\uff0c\u5176\u4e2d\u670912\u79cd\u732b\u7684\u7c7b\u522b\u548c25\u79cd\u72d7\u7684\u7c7b\u522b\uff0c\u6bcf\u4e2a\u7c7b\u522b\u5927\u7ea6\u6709200\u5f20\u56fe\u7247\uff0c\u6240\u6709\u56fe\u50cf\u90fd\u5177\u6709\u54c1\u79cd\uff0c\u5934\u90e8ROI\u548c\u50cf\u7d20\u7ea7\u5206\u5272\u7684\u6807\u6ce8\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u56fe\u50cf\u5206\u5272\u65f6\u5171\u5206\u4e3a\u524d\u666f\uff0c\u80cc\u666f\u548c\u4e0d\u786e\u5b9a3\u79cd\uff0c\u56fe\u50cf\u6570\u636e\u5305\u542b\u7684\u7c7b\u522b\u53ca\u5bf9\u5e94\u7684\u6570\u91cf\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6570\u636e\u96c6\u7684\u76ee\u5f55\u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a\\segdata 1\u3001Images\uff1a\u5b58\u50a8\u6570\u636e\u96c6\u7684\u56fe\u7247\u6570\u636e\uff0c\u5176\u4e2d\u56fe\u7247\u6587\u4ef6\u540d\u662f\u4ee5\u5927\u5199\u5f00\u5934\u4e3a\u201ccat\u201d\uff0c\u5c0f\u5199\u5f00\u5934\u4e3a\u201cdog\u201d\u3002 2\u3001Annotations\uff1a\u6807\u6ce8\u4fe1\u606f\uff0c\u5185\u5bb9\u5982\u4e0b\u6240\u793a\uff1a list.txt\u4e2d\u7684\u5185\u5bb9\u683c\u5f0f\u5982\u4e0b\u6240\u793a\uff0c\u5176\u4e2dClass ID\u5bf9\u5e94\u774037\u7c7b\u4e2d\u7684\u67d0\u4e00\u7c7b\uff0cSPECIES\u662f\u603b\u5206\u7c7b\uff0c1\u662f\u732b\uff0c2\u662f\u72d7\uff1bBreedID\u662f\u732b\u72d7\u5206\u7c7b\u4e2d\u7684\u5b50\u5206\u7c7b\uff0c\u732b\u7684\u5b50\u5206\u7c7b\u4e3a12\u7c7b\uff0c\u800c\u72d7\u7684\u5b50\u5206\u7c7b\u4e3a25\u7c7b\u3002 trimaps\u662f\u56fe\u50cf\u7684\u50cf\u7d20\u7ea7\u6807\u6ce8\u4fe1\u606f\uff0c\u662f\u6211\u4eec\u7684\u76ee\u6807\u503c \u63a5\u4e0b\u6765\u6211\u4eec\u5229\u7528UNET\u7f51\u7edc\u8fdb\u884c\u5ba0\u7269\u6570\u636e\u96c6\u5206\u5272\u3002","title":"1.1 \u4efb\u52a1\u53ca\u6570\u636e\u96c6\u7b80\u4ecb"},{"location":"imageSegmentation/section3/#12","text":"\u5728\u8fdb\u884c\u6a21\u578b\u6784\u5efa\u4e4b\u524d\uff0c\u6211\u4eec\u5c06\u8bfb\u53d6\u6570\u636e\u96c6\uff0c\u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305\uff1a import os from IPython.display import Image , display from tensorflow.keras.preprocessing.image import load_img import PIL from PIL import ImageOps","title":"1.2 \u6570\u636e\u96c6\u83b7\u53d6"},{"location":"imageSegmentation/section3/#121","text":"\u5728\u8fd9\u91cc\u6211\u4eec\u8bbe\u7f6e\u6570\u636e\u7684\u8def\u5f84\uff0c\u56fe\u50cf\u7684\u5927\u5c0f\uff0cbatch_size\u548c\u7c7b\u522b\u6570\u91cf\uff0c\u5728\u8fd9\u91cc\u4f7f\u7528\u4e86\u4e00\u4e2a\u6280\u5de7\uff0c\u56fe\u50cf\u5206\u5272\u65f6\u5171\u5206\u4e3a\u524d\u666f\uff0c\u80cc\u666f\u548c\u4e0d\u786e\u5b9a3\u79cd\uff0c\u5206\u522b\u6807\u6ce8\u4e3a\uff1a1\uff0c2\uff0c3\uff0c\u5bf9\u7c7b\u522b\u8fdb\u884c\u70ed\u7f16\u7801\u65f6\uff0c\u6211\u4eec\u7f16\u7801\u4e3a\uff1a1\uff1a0010\uff1b2\uff1a0100\uff1b3\uff1a1000\uff0c\u8fd9\u6837\u5728\u8bbe\u7f6e\u7c7b\u522b\u4e2a\u6570\u65f6\u8bbe\u4e3a4\u5373\u53ef\u3002 # \u56fe\u7247\u4f4d\u7f6e input_dir = \"segdata/images/\" # \u6807\u6ce8\u4fe1\u606f\u4f4d\u7f6e target_dir = \"segdata/annotations/trimaps/\" # \u56fe\u50cf\u5927\u5c0f\u8bbe\u7f6e\u53ca\u7c7b\u522b\u4fe1\u606f img_size = ( 160 , 160 ) batch_size = 32 num_classes = 4 # \u56fe\u50cf\u7684\u8def\u5f84 input_img_paths = sorted ( [ os . path . join ( input_dir , fname ) for fname in os . listdir ( input_dir ) if fname . endswith ( \".jpg\" ) ] ) # \u76ee\u6807\u503c\u8def\u5f84 target_img_paths = sorted ( [ os . path . join ( target_dir , fname ) for fname in os . listdir ( target_dir ) if fname . endswith ( \".png\" ) and not fname . startswith ( \".\" ) ] )","title":"1.2.1 \u8def\u5f84\u53ca\u76f8\u5173\u53c2\u6570\u8bbe\u7f6e"},{"location":"imageSegmentation/section3/#122","text":"\u5c06\u56fe\u50cf\u53ca\u5bf9\u5e94\u7684\u7ed3\u679c\u8fdb\u884c\u5c55\u793a\uff1a # \u663e\u793a\u4e00\u4e2a\u56fe\u50cf display ( Image ( filename = input_img_paths [ 10 ])) \u6807\u6ce8\u4fe1\u606f\u4e2d\u53ea\u67093\u4e2a\u503c\uff0c\u6211\u4eec\u4f7f\u7528PIL.ImageOps.autocontrast\u8fdb\u884c\u5c55\u793a\uff0c\u8be5\u65b9\u6cd5\u8ba1\u7b97\u8f93\u5165\u56fe\u50cf\u7684\u76f4\u65b9\u56fe\uff0c\u7136\u540e\u91cd\u65b0\u6620\u5c04\u56fe\u50cf\uff0c\u6700\u6697\u50cf\u7d20\u53d8\u4e3a\u9ed1\u8272\uff0c\u53730\uff0c\u6700\u4eae\u7684\u53d8\u4e3a\u767d\u8272\uff0c\u5373255\uff0c\u5176\u4ed6\u7684\u503c\u4ee5\u5176\u4ed6\u7684\u7070\u5ea6\u503c\u8fdb\u884c\u663e\u793a\uff0c\u5728\u8fd9\u91cc\u524d\u666f\uff0c\u80cc\u666f\u548c\u4e0d\u786e\u5b9a\u5206\u522b\u6807\u6ce8\u4e3a\uff1a1\uff0c2\uff0c3\uff0c\u6240\u4ee5\u524d\u666f\u6700\u5c0f\u663e\u793a\u4e3a\u9ed1\u8272\uff0c\u4e0d\u786e\u5b9a\u7684\u533a\u57df\u6700\u5927\u663e\u793a\u4e3a\u767d\u8272\u3002 # \u663e\u793a\u6807\u6ce8\u56fe\u50cf img = PIL . ImageOps . autocontrast ( load_img ( target_img_paths [ 10 ])) display ( img )","title":"1.2.2 \u6570\u636e\u5c55\u793a"},{"location":"imageSegmentation/section3/#123","text":"\u5229\u7528keras.utils.Sequence\u6784\u5efa\u56fe\u50cf\u751f\u6210\u5668\u6765\u8bfb\u53d6\u6570\u636e\uff0c\u6bcf\u4e2aSequence\u5fc5\u987b\u5b9e\u73b0 getitem \u548c len \u65b9\u6cd5\uff0c\u901a\u8fc7 getitem \u5e94\u8fd4\u56de\u5b8c\u6574\u7684\u6279\u6b21\uff0c Sequence\u662f\u8fdb\u884c\u591a\u5904\u7406\u7684\u66f4\u5b89\u5168\u65b9\u6cd5\u3002\u8fd9\u79cd\u7ed3\u6784\u4fdd\u8bc1\u4e86\u7f51\u7edc\u5728\u6bcf\u4e2a\u65f6\u95f4\u6bb5\u7684\u6bcf\u4e2a\u6837\u672c\u4e0a\u53ea\u4f1a\u8bad\u7ec3\u4e00\u6b21\u3002\u4e3b\u8981\u5b9e\u73b03\u4e2a\u65b9\u6cd5\uff1binit,len\u548cgetitem\u5373\u53ef\u3002 from tensorflow import keras import numpy as np from tensorflow.keras.preprocessing.image import load_img # \u6570\u636e\u96c6\u83b7\u53d6\uff1a class OxfordPets ( keras . utils . Sequence ): # \u5728__init__\u65b9\u6cd5\u4e2d\u6307\u5b9abatch_size,img_size,input_img_paths,target_img_paths def __init__ ( self , batch_size , img_size , input_img_paths , target_img_paths ): self . batch_size = batch_size # \u6279\u91cf\u5927\u5c0f self . img_size = img_size # \u56fe\u50cf\u5927\u5c0f self . input_img_paths = input_img_paths # \u8f93\u5165\u56fe\u50cf\u8def\u5f84 self . target_img_paths = target_img_paths # \u6807\u6ce8\u56fe\u50cf\u8def\u5f84 def __len__ ( self ): # \u8ba1\u7b97\u8fed\u4ee3\u6b21\u6570 return len ( self . target_img_paths ) // self . batch_size def __getitem__ ( self , idx ): \"\"\" \u83b7\u53d6\u6bcf\u4e00\u4e2abatch\u6570\u636e \"\"\" i = idx * self . batch_size # \u83b7\u53d6\u8f93\u5165\u7684\u56fe\u50cf\u6570\u636e batch_input_img_paths = self . input_img_paths [ i : i + self . batch_size ] # \u83b7\u53d6\u6807\u7b7e\u6570\u636e batch_target_img_paths = self . target_img_paths [ i : i + self . batch_size ] # \u6784\u5efa\u7279\u5f81\u503c\u6570\u636e\uff1a\u83b7\u53d6\u56fe\u50cf\u6570\u636e\u4e2d\u6bcf\u4e2a\u50cf\u7d20\u7684\u6570\u636e\u5b58\u50a8\u5728x\u4e2d x = np . zeros (( batch_size ,) + self . img_size + ( 3 ,), dtype = \"float32\" ) for j , path in enumerate ( batch_input_img_paths ): img = load_img ( path , target_size = self . img_size ) x [ j ] = img # \u6784\u5efa\u76ee\u6807\u503c\u6570\u636e\uff1a\u83b7\u53d6\u6807\u6ce8\u56fe\u50cf\u4e2d\u6bcf\u4e2a\u50cf\u7d20\u4e2d\u7684\u6570\u636e\u5b58\u5728y\u4e2d y = np . zeros (( batch_size ,) + self . img_size + ( 1 ,), dtype = \"uint8\" ) for j , path in enumerate ( batch_target_img_paths ): img = load_img ( path , target_size = self . img_size , color_mode = \"grayscale\" ) y [ j ] = np . expand_dims ( img , 2 ) return x , y \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u4f7f\u7528\u8be5\u65b9\u6cd5\u6765\u83b7\u53d6\u6570\u636e\u3002","title":"1.2.3 \u6784\u5efa\u6570\u636e\u96c6\u751f\u6210\u5668"},{"location":"imageSegmentation/section3/#13","text":"Unet\u7684\u7f51\u7edc\u7684\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4e3b\u8981\u5206\u4e3a\u4e24\u90e8\u5206\uff1a\u7f16\u7801\u548c\u89e3\u7801\u90e8\u5206\uff0c\u6211\u4eec\u5206\u522b\u8fdb\u884c\u6784\u5efa \u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305\uff1a import tensorflow as tf import tensorflow.keras as keras from tensorflow.keras.layers import Input , Conv2D , Conv2DTranspose from tensorflow.keras.layers import MaxPooling2D , Cropping2D , Concatenate from tensorflow.keras.layers import Lambda , Activation , BatchNormalization , Dropout from tensorflow.keras.models import Model","title":"1.3 \u6a21\u578b\u6784\u5efa"},{"location":"imageSegmentation/section3/#131","text":"\u7f16\u7801\u90e8\u5206\u7684\u7279\u70b9\u662f\uff1a \u67b6\u6784\u4e2d\u542b\u6709\u7740\u4e00\u79cd\u91cd\u590d\u7ed3\u6784\uff0c\u6bcf\u6b21\u91cd\u590d\u4e2d\u90fd\u67092\u4e2a 3 x 3\u5377\u79ef\u5c42\u3001\u975e\u7ebf\u6027ReLU\u5c42\u548c\u4e00\u4e2a 2 x 2 max pooling\u5c42\uff08stride\u4e3a2\uff09\u3002 \u6bcf\u4e00\u6b21\u4e0b\u91c7\u6837\u540e\u6211\u4eec\u90fd\u628a\u7279\u5f81\u901a\u9053\u7684\u6570\u91cf\u52a0\u500d \u6bcf\u6b21\u91cd\u590d\u90fd\u6709\u4e24\u4e2a\u8f93\u51fa\uff1a\u4e00\u4e2a\u7528\u4e8e\u7f16\u7801\u90e8\u5206\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u4e00\u4e2a\u7528\u4e8e\u89e3\u7801\u90e8\u5206\u7684\u7279\u5f81\u878d\u5408 \u6784\u5efa\u7684\u4ee3\u7801\u5982\u4e0b\u6240\u793a\uff1a # \u8f93\u5165\uff1a\u8f93\u5165\u5f20\u91cf\uff0c\u5377\u79ef\u6838\u4e2a\u6570 def downsampling_block ( input_tensor , filters ): # \u8f93\u5165\u5c42 x = Conv2D ( filters , kernel_size = ( 3 , 3 ), padding = 'same' )( input_tensor ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b\u51fd\u6570 x = Activation ( 'relu' )( x ) # \u5377\u79ef\u5c42 x = Conv2D ( filters , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b\u5c42 x = Activation ( 'relu' )( x ) # \u8fd4\u56de\u7684\u662f\u6c60\u5316\u540e\u7684\u503c\u548c\u6fc0\u6d3b\u672a\u6c60\u5316\u7684\u503c\uff0c\u6fc0\u6d3b\u540e\u672a\u6c60\u5316\u7684\u503c\u7528\u4e8e\u89e3\u7801\u90e8\u5206\u7279\u5f81\u7ea7\u8054 return MaxPooling2D ( pool_size = ( 2 , 2 ))( x ), x","title":"1.3.1 \u7f16\u7801\u90e8\u5206"},{"location":"imageSegmentation/section3/#132","text":"\u89e3\u7801\u90e8\u5206\u4e5f\u4f7f\u7528\u4e86\u91cd\u590d\u6a21\u5757\uff1a \u6bcf\u4e00\u4e2a\u6a21\u5757\u6709\u4e24\u4e2a\u8f93\u5165\uff1a\u4e00\u4e2a\u662f\u7f16\u7801\u9636\u6bb5\u7684\u7279\u5f81\u56fe\uff0c\u4e00\u4e2a\u662f\u89e3\u7801\u90e8\u5206\u7684\u7279\u5f81\u56fe \u6bcf\u4e00\u6b65\u90fd\u9996\u5148\u4f7f\u7528\u53cd\u5377\u79ef(up-convolution)\uff0c\u6bcf\u6b21\u4f7f\u7528\u53cd\u5377\u79ef\u90fd\u5c06\u7279\u5f81\u901a\u9053\u6570\u91cf\u51cf\u534a\uff0c\u7279\u5f81\u56fe\u5927\u5c0f\u52a0\u500d\u3002\uff08\u56fe\u4e2d\u7eff\u7bad\u5934\uff09 \u53cd\u5377\u79ef\u8fc7\u540e\uff0c\u5c06\u53cd\u5377\u79ef\u7684\u7ed3\u679c\u4e0e\u7f16\u7801\u90e8\u5206\u4e2d\u5bf9\u5e94\u6b65\u9aa4\u7684\u7279\u5f81\u56fe\u62fc\u63a5\u8d77\u6765\u3002\uff08\u767d/\u84dd\u5757\uff09 \u7f16\u7801\u90e8\u5206\u4e2d\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u7a0d\u5927\uff0c\u5c06\u5176\u4fee\u526a\u8fc7\u540e\u8fdb\u884c\u62fc\u63a5\u3002\uff08\u5de6\u8fb9\u6df1\u84dd\u865a\u7ebf\uff09 \u5bf9\u62fc\u63a5\u540e\u7684map\u518d\u8fdb\u884c2\u6b213 x 3\u7684\u5377\u79ef\u3002\uff08\u53f3\u4fa7\u84dd\u7bad\u5934\uff09 \u7f16\u7801\u5b9e\u73b0\u5982\u4e0b\uff1a # \u8f93\u5165\uff1a\u8f93\u5165\u5f20\u91cf\uff0c\u7279\u5f81\u878d\u5408\u7684\u5f20\u91cf\uff0c\u5377\u79ef\u6838\u4e2a\u6570 def upsampling_block ( input_tensor , skip_tensor , filters ): # \u53cd\u5377\u79ef x = Conv2DTranspose ( filters , kernel_size = ( 2 , 2 ), strides = ( 2 , 2 ), padding = \"same\" )( input_tensor ) # \u83b7\u53d6\u5f53\u524d\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8 _ , x_height , x_width , _ = x . shape # \u83b7\u53d6\u8981\u878d\u5408\u7684\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8 _ , s_height , s_width , _ = skip_tensor . shape # \u83b7\u53d6\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u5dee\u5f02 h_crop = s_height - x_height w_crop = s_width - x_width # \u82e5\u7279\u5f81\u56fe\u5927\u5c0f\u76f8\u540c\u4e0d\u8fdb\u884c\u88c1\u526a if h_crop == 0 and w_crop == 0 : y = skip_tensor #\u82e5\u7279\u5f81\u56fe\u5927\u5c0f\u4e0d\u540c\uff0c\u4f7f\u7ea7\u8054\u65f6\u50cf\u7d20\u5927\u5c0f\u4e00\u81f4 else : # \u83b7\u53d6\u7279\u5f81\u56fe\u88c1\u526a\u540e\u7684\u7279\u5f81\u56fe\u7684\u5927\u5c0f cropping = (( h_crop // 2 , h_crop - h_crop // 2 ), ( w_crop // 2 , w_crop - w_crop // 2 )) # \u7279\u5f81\u56fe\u88c1\u526a y = Cropping2D ( cropping = cropping )( skip_tensor ) # \u7279\u5f81\u878d\u5408 x = Concatenate ()([ x , y ]) # \u5377\u79ef x = Conv2D ( filters , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b\u5c42 x = Activation ( 'relu' )( x ) # \u5377\u79ef\u5c42 x = Conv2D ( filters , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b\u5c42 x = Activation ( 'relu' )( x ) return x","title":"1.3.2 \u89e3\u7801\u90e8\u5206"},{"location":"imageSegmentation/section3/#133","text":"\u5c06\u7f16\u7801\u90e8\u5206\u548c\u89e3\u7801\u90e8\u5206\u7ec4\u5408\u4e00\u8d77\uff0c\u5c31\u53ef\u6784\u5efaunet\u7f51\u7edc\uff0c\u5728\u8fd9\u91ccunet\u7f51\u7edc\u7684\u6df1\u5ea6\u901a\u8fc7depth\u8fdb\u884c\u8bbe\u7f6e\uff0c\u5e76\u8bbe\u7f6e\u7b2c\u4e00\u4e2a\u7f16\u7801\u6a21\u5757\u7684\u5377\u79ef\u6838\u4e2a\u6570\u901a\u8fc7filter\u8fdb\u884c\u8bbe\u7f6e\uff0c\u901a\u8fc7\u4ee5\u4e0b\u6a21\u5757\u5c06\u7f16\u7801\u548c\u89e3\u7801\u90e8\u5206\u8fdb\u884c\u7ec4\u5408\uff1a # \u4f7f\u75283\u4e2a\u6df1\u5ea6\u6784\u5efaunet\u7f51\u7edc def unet ( imagesize , classes , features = 64 , depth = 3 ): # \u5b9a\u4e49\u8f93\u5165\u6570\u636e inputs = keras . Input ( shape = img_size + ( 3 ,)) x = inputs # \u7528\u6765\u5b58\u653e\u8fdb\u884c\u7279\u5f81\u878d\u5408\u7684\u7279\u5f81\u56fe skips = [] # \u6784\u5efa\u7f16\u7801\u90e8\u5206 for i in range ( depth ): x , x0 = downsampling_block ( x , features ) skips . append ( x0 ) # \u4e0b\u91c7\u6837\u8fc7\u7a0b\u4e2d\uff0c\u6df1\u5ea6\u589e\u52a0\uff0c\u7279\u5f81\u7ffb\u500d\uff0c\u5373\u6bcf\u6b21\u4f7f\u7528\u7ffb\u500d\u6570\u76ee\u7684\u6ee4\u6ce2\u5668 features *= 2 # \u5377\u79ef x = Conv2D ( filters = features , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b x = Activation ( 'relu' )( x ) # \u5377\u79ef x = Conv2D ( filters = features , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b x = Activation ( 'relu' )( x ) # \u89e3\u7801\u8fc7\u7a0b for i in reversed ( range ( depth )): # \u6df1\u5ea6\u589e\u52a0\uff0c\u7279\u5f81\u56fe\u901a\u9053\u51cf\u534a features //= 2 # \u4e0a\u91c7\u6837 x = upsampling_block ( x , skips [ i ], features ) # \u5377\u79ef x = Conv2D ( filters = classes , kernel_size = ( 1 , 1 ), padding = \"same\" )( x ) # \u6fc0\u6d3b outputs = Activation ( 'softmax' )( x ) # \u6a21\u578b\u5b9a\u4e49 model = keras . Model ( inputs , outputs ) return model \u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\uff1a model = unet ( img_size , 4 ) model . summary () \u67e5\u770b\u6a21\u578b\u7ed3\u6784\uff0c\u4e5f\u53ef\u4f7f\u7528\uff1a keras . utils . plot_model ( model ) \u8fdb\u884c\u53ef\u89c6\u5316\u3002","title":"1.3.3 \u6a21\u578b\u6784\u5efa"},{"location":"imageSegmentation/section3/#14","text":"","title":"1.4 \u6a21\u578b\u8bad\u7ec3"},{"location":"imageSegmentation/section3/#141","text":"\u6570\u636e\u96c6\u4e2d\u7684\u56fe\u50cf\u662f\u6309\u987a\u5e8f\u8fdb\u884c\u5b58\u50a8\u7684\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u5c06\u6570\u636e\u96c6\u6253\u4e71\u540e\uff0c\u9a8c\u8bc1\u96c6\u7684\u6570\u91cf1000\uff0c\u5269\u4f59\u7684\u4e3a\u8bad\u7ec3\u96c6\uff0c\u5212\u5206\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\uff1a import random # \u5c06\u6570\u636e\u96c6\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\uff0c\u5176\u4e2d\u9a8c\u8bc1\u96c6\u7684\u6570\u91cf\u8bbe\u4e3a1000 val_samples = 1000 # \u5c06\u6570\u636e\u96c6\u6253\u4e71(\u56fe\u50cf\u4e0e\u6807\u6ce8\u4fe1\u606f\u7684\u968f\u673a\u6570\u79cd\u5b50\u662f\u4e00\u6837\u7684\uff0c\u624d\u80fd\u4fdd\u8bc1\u6570\u636e\u7684\u6b63\u786e\u6027) random . Random ( 1337 ) . shuffle ( input_img_paths ) random . Random ( 1337 ) . shuffle ( target_img_paths ) # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e\u8def\u5f84 train_input_img_paths = input_img_paths [: - val_samples ] train_target_img_paths = target_img_paths [: - val_samples ] # \u83b7\u53d6\u9a8c\u8bc1\u96c6\u6570\u636e\u8def\u5f84 val_input_img_paths = input_img_paths [ - val_samples :] val_target_img_paths = target_img_paths [ - val_samples :]","title":"1.4.1 \u6570\u636e\u96c6\u5212\u5206"},{"location":"imageSegmentation/section3/#142","text":"\u8bfb\u53d6\u5212\u5206\u597d\u7684\u6570\u636e\u96c6\u5f97\u5230\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a # \u83b7\u53d6\u8bad\u7ec3\u96c6 train_gen = OxfordPets ( batch_size , img_size , train_input_img_paths , train_target_img_paths ) # \u6a21\u578b\u9a8c\u8bc1\u96c6 val_gen = OxfordPets ( batch_size , img_size , val_input_img_paths , val_target_img_paths )","title":"1.4.2 \u6570\u636e\u83b7\u53d6"},{"location":"imageSegmentation/section3/#143","text":"\u8fdb\u884c\u6a21\u578b\u7f16\u8bd1\uff0c\u8bbe\u7f6e\uff1a \u4f18\u5316\u65b9\u6cd5\uff1a\u4f7f\u7528rmsprop\u4f18\u5316\u65b9\u6cd5 \u635f\u5931\u51fd\u6570\uff1a\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u56e0\u4e3a\u6ca1\u6709\u5bf9\u76ee\u6807\u503c\u8fdb\u884c\u70ed\u7f16\u7801\uff0c\u6240\u4ee5\u4f7f\u7528sparse_categorical_crossentropy # \u6a21\u578b\u7f16\u8bd1 model . compile ( optimizer = \"rmsprop\" , loss = \"sparse_categorical_crossentropy\" )","title":"1.4.3 \u6a21\u578b\u7f16\u8bd1"},{"location":"imageSegmentation/section3/#144","text":"\u8bbe\u7f6eepoch\u5bf9\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u6307\u660e\u9a8c\u8bc1\u96c6\u6570\u636e\uff1a # \u6a21\u578b\u8bad\u7ec3\uff0cepoch\u8bbe\u4e3a5 epochs = 15 model . fit ( train_gen , epochs = epochs , validation_data = val_gen ) \u8bad\u7ec3\u8fc7\u7a0b\u5982\u4e0b\uff1a Epoch 1 / 15 199 / 199 [ ============================== ] - 44 s 223 ms / step - loss : 0.9539 - val_loss : 13.5056 Epoch 2 / 15 199 / 199 [ ============================== ] - 44 s 221 ms / step - loss : 0.5145 - val_loss : 2.2228 Epoch 3 / 15 199 / 199 [ ============================== ] - 44 s 222 ms / step - loss : 0.4318 - val_loss : 0.4182 Epoch 4 / 15 199 / 199 [ ============================== ] - 44 s 221 ms / step - loss : 0.4027 - val_loss : 0.4100 Epoch 5 / 15 199 / 199 [ ============================== ] - 44 s 223 ms / step - loss : 0.3551 - val_loss : 0.3894 Epoch 6 / 15 199 / 199 [ ============================== ] - 44 s 220 ms / step - loss : 0.3226 - val_loss : 0.4020 Epoch 7 / 15 199 / 199 [ ============================== ] - 44 s 219 ms / step - loss : 0.3195 - val_loss : 0.4273 Epoch 8 / 15 199 / 199 [ ============================== ] - 44 s 220 ms / step - loss : 0.2789 - val_loss : 0.3707 Epoch 9 / 15 199 / 199 [ ============================== ] - 43 s 219 ms / step - loss : 0.2599 - val_loss : 0.4059 Epoch 10 / 15 199 / 199 [ ============================== ] - 44 s 222 ms / step - loss : 0.2440 - val_loss : 0.3799 Epoch 11 / 15 199 / 199 [ ============================== ] - 43 s 218 ms / step - loss : 0.2297 - val_loss : 0.4244 Epoch 12 / 15 199 / 199 [ ============================== ] - 43 s 218 ms / step - loss : 0.2179 - val_loss : 0.4320 Epoch 13 / 15 199 / 199 [ ============================== ] - 43 s 218 ms / step - loss : 0.2081 - val_loss : 0.4034 Epoch 14 / 15 199 / 199 [ ============================== ] - 44 s 220 ms / step - loss : 0.1977 - val_loss : 0.4034 Epoch 15 / 15 199 / 199 [ ============================== ] - 44 s 222 ms / step - loss : 0.1901 - val_loss : 0.4150 < tensorflow . python . keras . callbacks . History at 0x110063898 > \u968f\u7740\u8fed\u4ee3\u6b21\u6570\u7684\u589e\u52a0\uff0c\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u7684\u635f\u5931\u51fd\u6570\u53d8\u6362\u5982\u4e0b\u56fe\u6240\u793a\uff1a","title":"1.4.4 \u6a21\u578b\u8bad\u7ec3"},{"location":"imageSegmentation/section3/#15","text":"\u83b7\u53d6\u9a8c\u8bc1\u6570\u636e\u5e76\u8fdb\u884c\u9884\u6d4b # \u83b7\u53d6\u9a8c\u8bc1\u96c6\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u9884\u6d4b val_gen = OxfordPets ( batch_size , img_size , val_input_img_paths , val_target_img_paths ) val_preds = model . predict ( val_gen ) \u5b9a\u4e49\u9884\u6d4b\u7ed3\u679c\u663e\u793a\u7684\u65b9\u6cd5 # \u56fe\u50cf\u663e\u793a def display_mask ( i ): # \u83b7\u53d6\u5230\u7b2ci\u4e2a\u6837\u672c\u7684\u9884\u6d4b\u7ed3\u679c mask = np . argmax ( val_preds [ i ], axis =- 1 ) # \u7ef4\u5ea6\u8c03\u6574 mask = np . expand_dims ( mask , axis =- 1 ) # \u8f6c\u6362\u4e3a\u56fe\u50cf\uff0c\u5e76\u8fdb\u884c\u663e\u793a img = PIL . ImageOps . autocontrast ( keras . preprocessing . image . array_to_img ( mask )) display ( img ) \u9009\u62e9\u67d0\u4e00\u4e2a\u56fe\u50cf\u8fdb\u884c\u9884\u6d4b # \u9009\u4e2d\u9a8c\u8bc1\u96c6\u7684\u7b2c10\u4e2a\u56fe\u50cf i = 10 \u539f\u56fe\u50cf\u5c55\u793a # \u8f93\u5165\u56fe\u50cf\u663e\u793a display ( Image ( filename = val_input_img_paths [ i ])) \u76ee\u6807\u503c\u5c55\u793a # \u771f\u5b9e\u503c\u663e\u793a img = PIL . ImageOps . autocontrast ( load_img ( val_target_img_paths [ i ])) display ( img ) \u6a21\u578b\u9884\u6d4b\u7ed3\u679c # \u663e\u793a\u9884\u6d4b\u7ed3\u679c display_mask ( i ) \u603b\u7ed3 \u4e86\u89e3\u5ba0\u7269\u56fe\u50cf\u5206\u5272\u6570\u636e\u96c6 \u5ba0\u7269\u6570\u636e\u96c6\u8fdb\u884c\u5206\u5272\u65f6\u53ea\u6709\u524d\u666f\u3001\u80cc\u666f\u548c\u4e0d\u786e\u5b9a\u7684\u50cf\u7d20\u4e09\u79cd \u80fd\u591f\u5b8c\u6210UNet\u7f51\u7edc\u7684\u642d\u5efa \u642d\u5efa\u7f16\u7801\uff0c\u89e3\u7801\u90e8\u5206\u7684\u7f51\u7edc\uff0c\u5e76\u5c06\u4e24\u8005\u7ed3\u5408\u5728\u4e00\u8d77\u6784\u5efaUnet\u7f51\u7edc \u80fd\u591f\u5b8c\u6210UNet\u7f51\u7edc\u7684\u8bad\u7ec3\u4e0e\u9884\u6d4b","title":"1.5 \u6a21\u578b\u9884\u6d4b"},{"location":"imageSegmentation/section4/","text":"5.4 Mask RCNN \u00b6 \u5b66\u4e60\u76ee\u6807 \u8bf4\u660eMask RCNN\u7684\u7ed3\u6784\u7279\u70b9 \u638c\u63e1Mask RCNN\u7684RoIAlign\u65b9\u6cd5 \u638c\u63e1Mask RCNN\u7684mask\u539f\u7406 \u77e5\u9053Mask RCNN\u7684\u635f\u5931\u51fd\u6570 \u4e0a\u56fe\u662fMaskRCNN\u9884\u6d4b\u7684\u7ed3\u679c 1.1 Mask RCNN\u6d41\u7a0b \u00b6 Mask-RCNN\u662f\u4e00\u4e2a\u5b9e\u4f8b\u5206\u5272\uff08Instance segmentation\uff09\u7f51\u7edc\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u52a0\u4e0d\u540c\u7684\u5206\u652f\u53ef\u4ee5\u5b8c\u6210\u76ee\u6807\u5206\u7c7b\uff0c\u76ee\u6807\u68c0\u6d4b\uff0c\u5b9e\u4f8b\u5206\u5272\u7b49\u591a\u79cd\u4efb\u52a1\u3002\u5177\u4f53\u6765\u8bb2\uff0c\u5c31\u662f\u5728Faster-RCNN\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u4e00\u4e2a\u5206\u652f\uff0c\u5728\u5b9e\u73b0\u76ee\u6807\u68c0\u6d4b\u7684\u540c\u65f6\u5206\u5272\u76ee\u6807\u50cf\u7d20\uff0c\u5176\u5206\u652f\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u63a9\u7801\u5206\u652f\u662f\u4f5c\u7528\u4e8e\u6bcf\u4e2aRoI\u533a\u57df\uff08\u5019\u9009\u533a\u57df\uff09\uff0c\u4ee5\u50cf\u7d20\u5230\u50cf\u7d20\u7684\u65b9\u5f0f\u9884\u6d4b\u5206\u5272\u63a9\u7801\uff0c\u5f97\u5230\u5b9e\u4f8b\u5206\u5272\u7684\u7ed3\u679c\u3002 Mask RCNN\u7684\u6574\u4f53\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6574\u4f53\u7684\u6d41\u7a0b\u662f\uff1a \u8f93\u5165\u8981\u5904\u7406\u7684\u56fe\u7247\u3002 \u5c06\u56fe\u7247\u9001\u5165\u5230CNN\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u5f97\u5230\u7279\u5f81\u56fe\u3002 \u7136\u540e\u5bf9\u7279\u5f81\u56fe\u7684\u6bcf\u4e00\u4e2a\u50cf\u7d20\u4f4d\u7f6e\u8bbe\u5b9a\u56fa\u5b9a\u4e2a\u6570\u7684ROI\uff08\u5bf9\u5e94\u4e8e\u5728FasterRCNN\u4e2d\u7684Anchor\uff09\uff0c\u7136\u540e\u5c06ROI\u533a\u57df\u9001\u5165RPN\u7f51\u7edc\u8fdb\u884c\u4e8c\u5206\u7c7b(\u524d\u666f\u548c\u80cc\u666f)\u4ee5\u53ca\u5750\u6807\u56de\u5f52\uff0c\u4ee5\u83b7\u5f97\u7cbe\u70bc\u540e\u7684ROI\u533a\u57df\uff08\u5bf9\u5e94\u4e8eFasterRCNN\u4e2d\u7684\u5019\u9009\u533a\u57df\uff09\u3002 \u5bf9\u4e0a\u4e2a\u6b65\u9aa4\u4e2d\u83b7\u5f97\u7684ROI\u533a\u57df\u6267\u884cROIAlign\u64cd\u4f5c\uff08\u662f\u5bf9ROIPooling\u7684\u6539\u8fdb\uff09\uff0c\u5373\u5148\u5c06\u539f\u56fe\u548cfeature map\u7684pixel\u5bf9\u5e94\u8d77\u6765\uff0c\u7136\u540e\u5c06feature map\u548c\u56fa\u5b9a\u5927\u5c0f\u7684feature\u5bf9\u5e94\u8d77\u6765\u3002 \u6700\u540e\u5bf9\u8fd9\u4e9bROI\u533a\u57df\u8fdb\u884c\u591a\u7c7b\u522b\u5206\u7c7b\uff0c\u5019\u9009\u6846\u56de\u5f52\u548c\u5f15\u5165FCN\u751f\u6210Mask\uff0c\u5b8c\u6210\u5b9e\u4f8b\u5206\u5272\u4efb\u52a1\u3002 \u6574\u4e2a\u8fc7\u7a0b\u4e2d\u4e0eFasterRCNN\u4e2d\u4e0d\u540c\u7684\u662fROIAlign\u548c\u5206\u5272\u5206\u652f\uff0c\u5176\u4ed6\u90fd\u662f\u76f8\u540c\u7684\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u7740\u91cd\u4ecb\u7ecd\u8fd9\u4e24\u4e2a\u5185\u5bb9\u3002 1.2 ROIAlign \u00b6 1.2.1 \u539f\u7406\u4ecb\u7ecd \u00b6 FasterRCNN\u4e2d\u7684ROIPooling\u8fc7\u7a0b\u5982\u4e0b\u6240\u793a\uff1a \u5b83\u7684\u6d41\u7a0b\u662f\uff1a \u8f93\u5165\u56fe\u7247\u7684\u5927\u5c0f\u4e3a800x800\uff0c\u5176\u4e2d\u72d7\u8fd9\u4e2a\u76ee\u6807\u6846\u7684\u5927\u5c0f\u4e3a665x665\uff0c\u7ecf\u8fc7VGG16\u7f51\u7edc\u4e4b\u540e\u83b7\u5f97\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u4e3a800/32x800/32=25x25\uff0c\u5176\u4e2d32\u4ee3\u8868VGG16\u4e2d\u76845\u6b21\u4e0b\u91c7\u6837\uff08\u6b65\u957f\u4e3a2\uff09\u64cd\u4f5c\u3002\u90a3\u4e48\uff0c\u5bf9\u4e8e\u72d7\u8fd9\u4e2a\u76ee\u6807\uff0c\u6211\u4eec\u5c06\u5176\u5bf9\u5e94\u5230\u7279\u5f81\u56fe\u4e0a\u5f97\u5230\u7684\u7ed3\u679c\u662f665/32x665/32=20.78x20.78=20x20\uff0c\u56e0\u4e3a\u5750\u6807\u8981\u4fdd\u7559\u6574\u6570\u6240\u4ee5\u8fd9\u91cc\u5f15\u5165\u4e86\u7b2c\u4e00\u4e2a\u91cf\u5316\u8bef\u5dee\u5373\u820d\u5f03\u4e86\u76ee\u6807\u6846\u5728\u7279\u5f81\u56fe\u4e0a\u5bf9\u5e94\u957f\u5bbd\u7684\u6d6e\u70b9\u6570\u90e8\u5206\u3002 \u63a5\u4e0b\u6765\u9700\u8981\u5c06\u8fd9\u4e2a20x20\u7684ROI\u533a\u57df\u6620\u5c04\u4e3a7x7\u7684ROI\u7279\u5f81\u56fe\uff0c\u6839\u636eROI Pooling\u7684\u8ba1\u7b97\u65b9\u5f0f\uff0c\u5176\u7ed3\u679c\u5c31\u662f20/7x20/7=2.86x2.86\uff0c\u540c\u6837\u6267\u884c\u53d6\u6574\u64cd\u4f5c\u64cd\u4f5c\u540eROI\u7279\u5f81\u533a\u57df\u7684\u5c3a\u5bf8\u4e3a2x2\uff0c\u8fd9\u91cc\u5f15\u5165\u4e86\u7b2c\u4e8c\u6b21\u91cf\u5316\u8bef\u5dee\u3002 \u4ece\u4e0a\u9762\u7684\u5206\u6790\u53ef\u4ee5\u770b\u51fa\uff0c\u8fd9\u4e24\u6b21\u91cf\u5316\u8bef\u5dee\u4f1a\u5bfc\u81f4\u539f\u59cb\u56fe\u50cf\u4e2d\u7684\u50cf\u7d20\u548c\u7279\u5f81\u56fe\u4e2d\u7684\u50cf\u7d20\u8fdb\u884c\u5bf9\u5e94\u65f6\u51fa\u73b0\u504f\u5dee\uff0c\u4f8b\u5982\u4e0a\u9762\u5c062.86\u91cf\u5316\u4e3a2\u7684\u65f6\u5019\u5c31\u5f15\u5165\u4e860.86\u7684\u504f\u5dee\uff0c\u8fd9\u4e2a\u504f\u5dee\u6620\u5c04\u56de\u539f\u56fe\u5c31\u662f0.86x32=27.52\uff0c\u53ef\u4ee5\u770b\u5230\u8fd9\u4e2a\u50cf\u7d20\u504f\u5dee\u662f\u5f88\u5927\u7684\uff0c\u800c\u4e14\u8fd9\u4ec5\u4ec5\u8003\u8651\u4e86\u7b2c\u4e8c\u6b21\u7684\u91cf\u5316\u8bef\u5dee\uff0c\u6240\u4ee5\u8fd9\u4f1a\u5f71\u54cd\u6574\u4e2a\u7b97\u6cd5\u7684\u6027\u80fd\u3002 \u4e3a\u4e86\u7f13\u89e3ROI Pooling\u91cf\u5316\u8bef\u5dee\u8fc7\u5927\u7684\u95ee\u9898\uff0cMaskRCNN\u63d0\u51fa\u4e86ROIAlign\uff0cROIAlign\u6ca1\u6709\u4f7f\u7528\u91cf\u5316\u64cd\u4f5c\uff0c\u800c\u662f\u4f7f\u7528\u4e86\u53cc\u7ebf\u6027\u63d2\u503c\u4f30\u8ba1\u975e\u6574\u6570\u70b9\u7684\u50cf\u7d20\u503c\u3002\u8fd9\u4e00\u8fc7\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u9488\u5bf9\u4e0a\u56fe\u7684\u6d41\u7a0b\u662f\uff1a \u8f93\u5165\u56fe\u7247\u7684\u5927\u5c0f\u4e3a800x800\uff0c\u5176\u4e2d\u72d7\u8fd9\u4e2a\u76ee\u6807\u6846\u7684\u5927\u5c0f\u4e3a665x665\uff0c\u7ecf\u8fc7VGG16\u7f51\u7edc\u4e4b\u540e\u83b7\u5f97\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u4e3a800/32x800/32=25x25\uff0c\u5176\u4e2d32\u4ee3\u8868VGG16\u4e2d\u76845\u6b21\u4e0b\u91c7\u6837\uff08\u6b65\u957f\u4e3a2\uff09\u64cd\u4f5c\u3002\u90a3\u4e48\uff0c\u5bf9\u4e8e\u72d7\u8fd9\u4e2a\u76ee\u6807\uff0c\u6211\u4eec\u5c06\u5176\u5bf9\u5e94\u5230\u7279\u5f81\u56fe\u4e0a\u5f97\u5230\u7684\u7ed3\u679c\u662f665/32x665/32=20.78x20.78\uff0c\u6b64\u65f6\uff0c\u6ca1\u6709\u50cfRoiPooling\u90a3\u6837\u5c31\u884c\u53d6\u6574\u64cd\u4f5c\uff0c\u800c\u662f\u4fdd\u7559\u6d6e\u70b9\u6570\u3002 \u63a5\u4e0b\u6765\u9700\u8981\u5c06\u8fd9\u4e2a20.78x20.78\u7684ROI\u533a\u57df\u6620\u5c04\u4e3a7x7\u7684ROI\u7279\u5f81\u56fe\uff0c\u7ed3\u679c\u5c31\u662f20.78/7x20.78/7=2.97x2.97\uff0c\u5373\u6bcf\u4e2a\u5c0f\u533a\u57df\u7684\u5927\u5c0f\u4e3a2.97x2.97\u3002 \u5047\u5b9a\u6bcf\u4e2a\u5c0f\u533a\u57df\u91c7\u6837\u70b9\u6570\u4e3a4\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u5bf9\u4e8e\u6bcf\u4e2a2.97*2.97\u7684\u5c0f\u533a\u57df\uff0c\u5e73\u5206\u56db\u4efd\uff0c\u6bcf\u4e00\u4efd\u53d6\u5176\u4e2d\u5fc3\u70b9\u4f4d\u7f6e\uff0c\u800c\u4e2d\u5fc3\u70b9\u4f4d\u7f6e\u7684\u50cf\u7d20\uff0c\u91c7\u7528\u53cc\u7ebf\u6027\u63d2\u503c\u6cd5\u8fdb\u884c\u8ba1\u7b97\uff0c\u8fd9\u6837\uff0c\u5c31\u4f1a\u5f97\u5230\u56db\u4e2a\u70b9\u7684\u50cf\u7d20\u503c\uff0c\u5982\u4e0b\u56fe\uff1a \u4e0a\u56fe\u4e2d\uff0c\u56db\u4e2a\u7ea2\u8272\u53c9\u53c9\u2018\u00d7\u2019\u7684\u50cf\u7d20\u503c\u662f\u901a\u8fc7\u53cc\u7ebf\u6027\u63d2\u503c\u7b97\u6cd5\u8ba1\u7b97\u5f97\u5230\u7684\u3002 \u6700\u540e\uff0c\u53d6\u56db\u4e2a\u50cf\u7d20\u503c\u4e2d\u6700\u5927\u503c\uff08\u6700\u5927\u6c60\u5316\uff09\u4f5c\u4e3a\u8fd9\u4e2a\u5c0f\u533a\u57df(\u5373\uff1a2.97x2.97\u5927\u5c0f\u7684\u533a\u57df)\u7684\u50cf\u7d20\u503c\uff0c\u5982\u6b64\u7c7b\u63a8\uff0c\u540c\u6837\u662f49\u4e2a\u5c0f\u533a\u57df\u5f97\u523049\u4e2a\u50cf\u7d20\u503c\uff0c\u7ec4\u62107x7\u5927\u5c0f\u7684\u7279\u5f81\u56fe\u3002 \u53cc\u7ebf\u6027\u63d2\u503c\u662f\u4e00\u79cd\u56fe\u50cf\u7f29\u653e\u586b\u5145\u7b97\u6cd5\uff0c\u5b83\u5145\u5206\u7684\u5229\u7528\u4e86\u539f\u56fe\u4e2d\u865a\u62df\u70b9\uff08\u6bd4\u598220.56\u8fd9\u4e2a\u6d6e\u70b9\u6570\uff0c\u50cf\u7d20\u4f4d\u7f6e\u4e0d\u662f\u6574\u6570\u503c\uff0c\u800c\u662f\u6d6e\u70b9\u503c\uff09\u56db\u5468\u7684\u771f\u5b9e\u5b58\u5728\u7684\u50cf\u7d20\u503c\u6765\u5171\u540c\u51b3\u5b9a\u76ee\u6807\u56fe\u4e2d\u7684\u4e00\u4e2a\u50cf\u7d20\u503c\uff0c\u5373\u53ef\u4ee5\u5c0620.56\u8fd9\u4e2a\u865a\u62df\u7684\u4f4d\u7f6e\u70b9\u5bf9\u5e94\u7684\u50cf\u7d20\u503c\u4f30\u8ba1\u51fa\u6765\u3002 1.2.2 \u5b9e\u73b0\u6548\u679c \u00b6 \u5728tensorFlow\u4e2d\u5b9e\u73b0\u65f6\u4f7f\u7528\uff1a tf . image . crop_and_resize ( image , boxes , box_indices , crop_size , method = 'bilinear' , extrapolation_value = 0 , name = None ) \u53c2\u6570\u4ecb\u7ecd\uff1a image: \u8868\u793a\u7279\u5f81\u56fe boxes\uff1a\u6307\u9700\u8981\u5212\u5206\u7684ROI\u533a\u57df\uff0c\u8f93\u5165\u683c\u5f0f\u4e3a[ymin\uff0cxmin\uff0cymax\uff0cxmax]\uff0c\u6ce8\u610f\u662f\u5f52\u4e00\u5316\u7684\u7ed3\u679c\u3002 \u5047\u8bbe\u5019\u9009\u533a\u57df\u5750\u6807\u662f[y1,x1,y2,x2]\uff0c\u90a3\u4e48\u60f3\u8981\u5f97\u5230\u76f8\u5e94\u6b63\u786e\u7684crop\u56fe\u5f62\u5c31\u4e00\u5b9a\u8981\u5f52\u4e00\u5316,\u5373\u56fe\u7247\u7684\u957f\u5ea6\u662f[w,h],\u5219\u5b9e\u9645\u8f93\u5165\u7684boxes\u4e3a[y1/h,x1/w,y2/h,x2/w]\uff0c\u8d85\u51fa1\u7684\u90e8\u5206\u4f7f\u7528\u9ed1\u82720\u8fdb\u884c\u586b\u5145\u3002 box_indice: \u662fboxes\u548cimage\u4e4b\u95f4\u7684\u7d22\u5f15\uff0c\u5373box\u5bf9\u5e94\u7684\u56fe\u50cf\u7d22\u5f15 crop_size: \u8868\u793aRoiAlign\u4e4b\u540e\u7684\u5019\u9009\u533a\u57df\u7684\u5927\u5c0f\u3002 method\uff1a\u63d2\u503c\u65b9\u6cd5\uff0c\u9ed8\u8ba4\u662f\u53cc\u7ebf\u6027\u63d2\u503c \u4e0b\u9762\u6211\u4eec\u5229\u7528\u4e24\u5f20\u56fe\u7247\u770b\u4e0bROIAlign\u7684\u6548\u679c\uff1a \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf import matplotlib.pyplot as plt \u539f\u56fe\u50cf\u8bfb\u53d6\u548c\u5c55\u793a # \u56fe\u50cf\u8bfb\u53d6 img = plt . imread ( 'Trump.jpg' ) / 255. img2 = plt . imread ( 'Trump2.jpg' ) / 255. # \u56fe\u50cf\u5c55\u793a plt . figure ( figsize = ( 10 , 8 )) plt . subplot ( 1 , 2 , 1 ) plt . imshow ( img ) plt . subplot ( 1 , 2 , 2 ) plt . imshow ( img2 ) \u6784\u5efabatch_size\u6570\u636e\uff08batch_size=2\uff09 # \u5bf9\u56fe\u50cf\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362\uff0c\u5e76\u6dfb\u52a0batch\u7ef4 img = tf . convert_to_tensor ( img , dtype = tf . float32 ) img = tf . expand_dims ( img , axis = 0 ) img = tf . image . resize ( img , ( 500 , 500 )) img2 = tf . convert_to_tensor ( img2 , dtype = tf . float32 ) img2 = tf . expand_dims ( img2 , axis = 0 ) img2 = tf . image . resize ( img2 , ( 500 , 500 )) # \u5c06\u4e24\u4e2a\u56fe\u50cf\u62fc\u63a5\u5728\u4e00\u8d77 img = tf . concat ([ img , img2 ], axis = 0 ) print ( 'img:' , img . shape ) \u8f93\u51fa\u4e3a\uff1a img : ( 2 , 500 , 500 , 3 ) \u4e00\u4e2abatch\u4e2d\u5305\u542b2\u4e2a\u56fe\u50cf\uff0c\u6bcf\u4e2a\u56fe\u50cf\u7684\u5927\u5c0f\u4e3a500x500x3\uff0c\u7406\u89e3\u4e3a\u4e24\u4e2a\u7279\u5f81\u56fe ROIAlign # \u8fdb\u884cROIAlign\u5904\u7406\uff1a\u7279\u5f81\u56fe\uff0c2\u4e2aboxes\uff0c\u5206\u522b\u5bf9\u5e94\u56fe\u50cf\u7d22\u5f150\u548c1\uff0cROIAlign\u540e\u7684\u5927\u5c0f\u4e3a50x50 out = tf . image . crop_and_resize ( img , [[ 0.5 , 0.5 , 1.0 , 1.0 ], [ 0.5 , 0.5 , 1.5 , 1.5 ]], [ 0 , 1 ], crop_size = ( 50 , 50 )) print ( 'out:' , a . shape ) \u8f93\u51fa\u4e3a\uff1a out : ( 2 , 50 , 50 , 3 ) \u6548\u679c\u5c55\u793a plt . figure ( figsize = ( 10 , 8 )) # \u5c3a\u5bf8\u8c03\u6574\u540e\u7684\u56fe\u50cf plt . subplot ( 2 , 2 , 1 ) plt . imshow ( img [ 0 ]) plt . subplot ( 2 , 2 , 2 ) plt . imshow ( img [ 1 ]) # ROIAlign\u7684\u7ed3\u679c plt . subplot ( 2 , 2 , 3 ) plt . imshow ( a [ 0 ]) plt . subplot ( 2 , 2 , 4 ) plt . imshow ( a [ 1 ]) plt . show () 1.3 \u7f51\u7edc\u7ed3\u6784 \u00b6 \u4e0a\u8ff0\u5df2\u7ecf\u4ecb\u7ecd\u4e86Mask-RCNN \u7684\u7ed3\u6784\u4e0eFasterRCNN\u662f\u76f8\u540c\u7684\uff0c\u589e\u52a0\u4e86\u4e00\u4e2a\u5206\u5272\u7684\u5934\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u9aa8\u5e72\u7f51\u7edcResNet-FPN\u7528\u4e8e\u7279\u5f81\u63d0\u53d6\uff0cRPN\u7f51\u7edc\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u63d0\u53d6\uff0cROIAlign\u83b7\u53d6\u56fa\u5b9a\u5927\u5c0f\u7684\u7279\u5f81\u56fe\uff0c\u5934\u90e8\u7f51\u7edc\u5305\u62ec\u8fb9\u754c\u6846\u8bc6\u522b\uff08\u5206\u7c7b\u548c\u56de\u5f52\uff09+mask\u9884\u6d4b\uff0c\u5177\u4f53\u5982\u4e0b\u6240\u793a\uff1a mask\u5206\u652f\u662f\u4e00\u4e2a\u5168\u5377\u79ef\u7f51\u7edc\uff0c\u5b9e\u9645\u5de5\u4f5c\u4e2d\u6211\u4eec\u4f7f\u7528\u53f3\u56fe\u8f83\u591a\u4e00\u4e9b\uff0c\u5176\u4e2d\u4f7f\u75282x2\u7684\u53cd\u5377\u79ef\u8fdb\u884c\u4e0a\u91c7\u6837\u3002\u9884\u6d4b\u65f6 mask \u5206\u652f\u8f93\u51fa\u7ed3\u679c resize \u5230 RoI \u7684\u5927\u5c0f, \u7136\u540e\u5e94\u7528 0.5 \u7684\u9608\u503c\u8fdb\u884c\u4e8c\u503c\u5316\u5f97\u5230\u6700\u7ec8\u7684\u5206\u5272\u7ed3\u679c\u3002 1.4 \u635f\u5931\u51fd\u6570 \u00b6 Mask-RCNN\u5728Faster-RCNN\u7684\u57fa\u7840\u4e0a\u591a\u4e86\u4e00\u4e2aROIAligin\u548cMask\u9884\u6d4b\u5206\u652f\uff0c\u56e0\u6b64Mask R-CNN\u7684\u635f\u5931\u4e5f\u662f\u591a\u4efb\u52a1\u635f\u5931\uff1a L_{cls} L_{cls} \u548c L_{box} L_{box} \u4e0efaster rcnn\u7684\u5b9a\u4e49\u6ca1\u6709\u533a\u522b\u3002\u5177\u4f53\u6765\u770b\u4e0b L_{mask} L_{mask} \u3002 Mask\u5206\u652f\u5bf9\u6bcf\u4e2aROI\u533a\u57df\u4ea7\u751f\u4e00\u4e2amxmxK\u7684\u8f93\u51fa\u7279\u5f81\u56fe\uff0c\u5373K\u4e2a\u7684\u4e8c\u503c\u63a9\u819c\u56fe\u50cf\uff0c\u5176\u4e2dK\u4ee3\u8868\u76ee\u6807\u79cd\u7c7b\u6570\u3002\u5bf9\u4e8e\u9884\u6d4b\u7684\u4e8c\u503c\u63a9\u819c\u8f93\u51fa\uff0c\u5bf9\u6bcf\u4e00\u4e2a\u50cf\u7d20\u70b9\u5e94\u7528 sigmoid \u51fd\u6570\uff0c\u6574\u4f53\u635f\u5931\u5b9a\u4e49\u4e3a\u5e73\u5747\u4e8c\u503c\u4ea4\u53c9\u635f\u5931\u71b5\u3002\u5bf9\u4e8e\u771f\u5b9e\u7c7b\u522b\u4e3a\ud835\udc58\u7684\ud835\udc45\ud835\udc5c\ud835\udc3c\uff0c\u4ec5\u5728\u7b2ck\u4e2a\u63a9\u7801\u4e0a\u8ba1\u7b97\u635f\u5931\uff08\u5176\u4ed6\u63a9\u7801\u8f93\u51fa\u4e0d\u8ba1\u5165\uff09\u3002\u8fd9\u6837\u505a\u89e3\u8026\u4e86\u63a9\u819c\u548c\u79cd\u7c7b\u9884\u6d4b\u3002 \u4e0d\u50cfFCN\u7684\u505a\u6cd5\uff0c\u5728\u6bcf\u4e2a\u50cf\u7d20\u70b9\u4e0a\u5e94\u7528 softmax \u51fd\u6570\uff0c\u6574\u4f53\u91c7\u7528\u7684\u591a\u4efb\u52a1\u4ea4\u53c9\u71b5\uff0c\u8fd9\u6837\u4f1a\u5bfc\u81f4\u7c7b\u95f4\u7ade\u4e89\uff0c\u6700\u7ec8\u5bfc\u81f4\u5206\u5272\u6548\u679c\u5dee\u3002 \u603b\u7ed3 \u8bf4\u660eMask RCNN\u7684\u7ed3\u6784\u7279\u70b9 \u5728Faster-RCNN\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u4e00\u4e2a\u5206\u652f\uff0c\u5728\u5b9e\u73b0\u76ee\u6807\u68c0\u6d4b\u7684\u540c\u65f6\u5206\u5272\u76ee\u6807\u50cf\u7d20 \u638c\u63e1Mask RCNN\u7684RoIAlign\u65b9\u6cd5 ROIAlign\u6ca1\u6709\u4f7f\u7528\u91cf\u5316\u64cd\u4f5c\uff0c\u800c\u662f\u4f7f\u7528\u4e86\u53cc\u7ebf\u6027\u63d2\u503c\u4f30\u8ba1\u975e\u6574\u6570\u70b9\u7684\u50cf\u7d20\u503c \u638c\u63e1Mask RCNN\u7684mask\u539f\u7406 mask\u5206\u652f\u662f\u4e00\u4e2a\u5168\u5377\u79ef\u7f51\u7edc\uff0c\u4f7f\u75282x2\u7684\u53cd\u5377\u79ef\u8fdb\u884c\u4e0a\u91c7\u6837 \u77e5\u9053Mask RCNN\u7684\u635f\u5931\u51fd\u6570 \u591a\u4efb\u52a1\u635f\u5931\u51fd\u6570\uff1a\u6709\u5206\u7c7b\uff0c\u56de\u5f52\u548c\u5206\u5272\u4e09\u90e8\u5206\u7ec4\u6210","title":"\u5b9e\u4f8b\u5206\u5272\uff1aMask RCNN"},{"location":"imageSegmentation/section4/#54-mask-rcnn","text":"\u5b66\u4e60\u76ee\u6807 \u8bf4\u660eMask RCNN\u7684\u7ed3\u6784\u7279\u70b9 \u638c\u63e1Mask RCNN\u7684RoIAlign\u65b9\u6cd5 \u638c\u63e1Mask RCNN\u7684mask\u539f\u7406 \u77e5\u9053Mask RCNN\u7684\u635f\u5931\u51fd\u6570 \u4e0a\u56fe\u662fMaskRCNN\u9884\u6d4b\u7684\u7ed3\u679c","title":"5.4 Mask RCNN"},{"location":"imageSegmentation/section4/#11-mask-rcnn","text":"Mask-RCNN\u662f\u4e00\u4e2a\u5b9e\u4f8b\u5206\u5272\uff08Instance segmentation\uff09\u7f51\u7edc\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u52a0\u4e0d\u540c\u7684\u5206\u652f\u53ef\u4ee5\u5b8c\u6210\u76ee\u6807\u5206\u7c7b\uff0c\u76ee\u6807\u68c0\u6d4b\uff0c\u5b9e\u4f8b\u5206\u5272\u7b49\u591a\u79cd\u4efb\u52a1\u3002\u5177\u4f53\u6765\u8bb2\uff0c\u5c31\u662f\u5728Faster-RCNN\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u4e00\u4e2a\u5206\u652f\uff0c\u5728\u5b9e\u73b0\u76ee\u6807\u68c0\u6d4b\u7684\u540c\u65f6\u5206\u5272\u76ee\u6807\u50cf\u7d20\uff0c\u5176\u5206\u652f\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u63a9\u7801\u5206\u652f\u662f\u4f5c\u7528\u4e8e\u6bcf\u4e2aRoI\u533a\u57df\uff08\u5019\u9009\u533a\u57df\uff09\uff0c\u4ee5\u50cf\u7d20\u5230\u50cf\u7d20\u7684\u65b9\u5f0f\u9884\u6d4b\u5206\u5272\u63a9\u7801\uff0c\u5f97\u5230\u5b9e\u4f8b\u5206\u5272\u7684\u7ed3\u679c\u3002 Mask RCNN\u7684\u6574\u4f53\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6574\u4f53\u7684\u6d41\u7a0b\u662f\uff1a \u8f93\u5165\u8981\u5904\u7406\u7684\u56fe\u7247\u3002 \u5c06\u56fe\u7247\u9001\u5165\u5230CNN\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u5f97\u5230\u7279\u5f81\u56fe\u3002 \u7136\u540e\u5bf9\u7279\u5f81\u56fe\u7684\u6bcf\u4e00\u4e2a\u50cf\u7d20\u4f4d\u7f6e\u8bbe\u5b9a\u56fa\u5b9a\u4e2a\u6570\u7684ROI\uff08\u5bf9\u5e94\u4e8e\u5728FasterRCNN\u4e2d\u7684Anchor\uff09\uff0c\u7136\u540e\u5c06ROI\u533a\u57df\u9001\u5165RPN\u7f51\u7edc\u8fdb\u884c\u4e8c\u5206\u7c7b(\u524d\u666f\u548c\u80cc\u666f)\u4ee5\u53ca\u5750\u6807\u56de\u5f52\uff0c\u4ee5\u83b7\u5f97\u7cbe\u70bc\u540e\u7684ROI\u533a\u57df\uff08\u5bf9\u5e94\u4e8eFasterRCNN\u4e2d\u7684\u5019\u9009\u533a\u57df\uff09\u3002 \u5bf9\u4e0a\u4e2a\u6b65\u9aa4\u4e2d\u83b7\u5f97\u7684ROI\u533a\u57df\u6267\u884cROIAlign\u64cd\u4f5c\uff08\u662f\u5bf9ROIPooling\u7684\u6539\u8fdb\uff09\uff0c\u5373\u5148\u5c06\u539f\u56fe\u548cfeature map\u7684pixel\u5bf9\u5e94\u8d77\u6765\uff0c\u7136\u540e\u5c06feature map\u548c\u56fa\u5b9a\u5927\u5c0f\u7684feature\u5bf9\u5e94\u8d77\u6765\u3002 \u6700\u540e\u5bf9\u8fd9\u4e9bROI\u533a\u57df\u8fdb\u884c\u591a\u7c7b\u522b\u5206\u7c7b\uff0c\u5019\u9009\u6846\u56de\u5f52\u548c\u5f15\u5165FCN\u751f\u6210Mask\uff0c\u5b8c\u6210\u5b9e\u4f8b\u5206\u5272\u4efb\u52a1\u3002 \u6574\u4e2a\u8fc7\u7a0b\u4e2d\u4e0eFasterRCNN\u4e2d\u4e0d\u540c\u7684\u662fROIAlign\u548c\u5206\u5272\u5206\u652f\uff0c\u5176\u4ed6\u90fd\u662f\u76f8\u540c\u7684\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u7740\u91cd\u4ecb\u7ecd\u8fd9\u4e24\u4e2a\u5185\u5bb9\u3002","title":"1.1 Mask RCNN\u6d41\u7a0b"},{"location":"imageSegmentation/section4/#12-roialign","text":"","title":"1.2 ROIAlign"},{"location":"imageSegmentation/section4/#121","text":"FasterRCNN\u4e2d\u7684ROIPooling\u8fc7\u7a0b\u5982\u4e0b\u6240\u793a\uff1a \u5b83\u7684\u6d41\u7a0b\u662f\uff1a \u8f93\u5165\u56fe\u7247\u7684\u5927\u5c0f\u4e3a800x800\uff0c\u5176\u4e2d\u72d7\u8fd9\u4e2a\u76ee\u6807\u6846\u7684\u5927\u5c0f\u4e3a665x665\uff0c\u7ecf\u8fc7VGG16\u7f51\u7edc\u4e4b\u540e\u83b7\u5f97\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u4e3a800/32x800/32=25x25\uff0c\u5176\u4e2d32\u4ee3\u8868VGG16\u4e2d\u76845\u6b21\u4e0b\u91c7\u6837\uff08\u6b65\u957f\u4e3a2\uff09\u64cd\u4f5c\u3002\u90a3\u4e48\uff0c\u5bf9\u4e8e\u72d7\u8fd9\u4e2a\u76ee\u6807\uff0c\u6211\u4eec\u5c06\u5176\u5bf9\u5e94\u5230\u7279\u5f81\u56fe\u4e0a\u5f97\u5230\u7684\u7ed3\u679c\u662f665/32x665/32=20.78x20.78=20x20\uff0c\u56e0\u4e3a\u5750\u6807\u8981\u4fdd\u7559\u6574\u6570\u6240\u4ee5\u8fd9\u91cc\u5f15\u5165\u4e86\u7b2c\u4e00\u4e2a\u91cf\u5316\u8bef\u5dee\u5373\u820d\u5f03\u4e86\u76ee\u6807\u6846\u5728\u7279\u5f81\u56fe\u4e0a\u5bf9\u5e94\u957f\u5bbd\u7684\u6d6e\u70b9\u6570\u90e8\u5206\u3002 \u63a5\u4e0b\u6765\u9700\u8981\u5c06\u8fd9\u4e2a20x20\u7684ROI\u533a\u57df\u6620\u5c04\u4e3a7x7\u7684ROI\u7279\u5f81\u56fe\uff0c\u6839\u636eROI Pooling\u7684\u8ba1\u7b97\u65b9\u5f0f\uff0c\u5176\u7ed3\u679c\u5c31\u662f20/7x20/7=2.86x2.86\uff0c\u540c\u6837\u6267\u884c\u53d6\u6574\u64cd\u4f5c\u64cd\u4f5c\u540eROI\u7279\u5f81\u533a\u57df\u7684\u5c3a\u5bf8\u4e3a2x2\uff0c\u8fd9\u91cc\u5f15\u5165\u4e86\u7b2c\u4e8c\u6b21\u91cf\u5316\u8bef\u5dee\u3002 \u4ece\u4e0a\u9762\u7684\u5206\u6790\u53ef\u4ee5\u770b\u51fa\uff0c\u8fd9\u4e24\u6b21\u91cf\u5316\u8bef\u5dee\u4f1a\u5bfc\u81f4\u539f\u59cb\u56fe\u50cf\u4e2d\u7684\u50cf\u7d20\u548c\u7279\u5f81\u56fe\u4e2d\u7684\u50cf\u7d20\u8fdb\u884c\u5bf9\u5e94\u65f6\u51fa\u73b0\u504f\u5dee\uff0c\u4f8b\u5982\u4e0a\u9762\u5c062.86\u91cf\u5316\u4e3a2\u7684\u65f6\u5019\u5c31\u5f15\u5165\u4e860.86\u7684\u504f\u5dee\uff0c\u8fd9\u4e2a\u504f\u5dee\u6620\u5c04\u56de\u539f\u56fe\u5c31\u662f0.86x32=27.52\uff0c\u53ef\u4ee5\u770b\u5230\u8fd9\u4e2a\u50cf\u7d20\u504f\u5dee\u662f\u5f88\u5927\u7684\uff0c\u800c\u4e14\u8fd9\u4ec5\u4ec5\u8003\u8651\u4e86\u7b2c\u4e8c\u6b21\u7684\u91cf\u5316\u8bef\u5dee\uff0c\u6240\u4ee5\u8fd9\u4f1a\u5f71\u54cd\u6574\u4e2a\u7b97\u6cd5\u7684\u6027\u80fd\u3002 \u4e3a\u4e86\u7f13\u89e3ROI Pooling\u91cf\u5316\u8bef\u5dee\u8fc7\u5927\u7684\u95ee\u9898\uff0cMaskRCNN\u63d0\u51fa\u4e86ROIAlign\uff0cROIAlign\u6ca1\u6709\u4f7f\u7528\u91cf\u5316\u64cd\u4f5c\uff0c\u800c\u662f\u4f7f\u7528\u4e86\u53cc\u7ebf\u6027\u63d2\u503c\u4f30\u8ba1\u975e\u6574\u6570\u70b9\u7684\u50cf\u7d20\u503c\u3002\u8fd9\u4e00\u8fc7\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u9488\u5bf9\u4e0a\u56fe\u7684\u6d41\u7a0b\u662f\uff1a \u8f93\u5165\u56fe\u7247\u7684\u5927\u5c0f\u4e3a800x800\uff0c\u5176\u4e2d\u72d7\u8fd9\u4e2a\u76ee\u6807\u6846\u7684\u5927\u5c0f\u4e3a665x665\uff0c\u7ecf\u8fc7VGG16\u7f51\u7edc\u4e4b\u540e\u83b7\u5f97\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u4e3a800/32x800/32=25x25\uff0c\u5176\u4e2d32\u4ee3\u8868VGG16\u4e2d\u76845\u6b21\u4e0b\u91c7\u6837\uff08\u6b65\u957f\u4e3a2\uff09\u64cd\u4f5c\u3002\u90a3\u4e48\uff0c\u5bf9\u4e8e\u72d7\u8fd9\u4e2a\u76ee\u6807\uff0c\u6211\u4eec\u5c06\u5176\u5bf9\u5e94\u5230\u7279\u5f81\u56fe\u4e0a\u5f97\u5230\u7684\u7ed3\u679c\u662f665/32x665/32=20.78x20.78\uff0c\u6b64\u65f6\uff0c\u6ca1\u6709\u50cfRoiPooling\u90a3\u6837\u5c31\u884c\u53d6\u6574\u64cd\u4f5c\uff0c\u800c\u662f\u4fdd\u7559\u6d6e\u70b9\u6570\u3002 \u63a5\u4e0b\u6765\u9700\u8981\u5c06\u8fd9\u4e2a20.78x20.78\u7684ROI\u533a\u57df\u6620\u5c04\u4e3a7x7\u7684ROI\u7279\u5f81\u56fe\uff0c\u7ed3\u679c\u5c31\u662f20.78/7x20.78/7=2.97x2.97\uff0c\u5373\u6bcf\u4e2a\u5c0f\u533a\u57df\u7684\u5927\u5c0f\u4e3a2.97x2.97\u3002 \u5047\u5b9a\u6bcf\u4e2a\u5c0f\u533a\u57df\u91c7\u6837\u70b9\u6570\u4e3a4\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u5bf9\u4e8e\u6bcf\u4e2a2.97*2.97\u7684\u5c0f\u533a\u57df\uff0c\u5e73\u5206\u56db\u4efd\uff0c\u6bcf\u4e00\u4efd\u53d6\u5176\u4e2d\u5fc3\u70b9\u4f4d\u7f6e\uff0c\u800c\u4e2d\u5fc3\u70b9\u4f4d\u7f6e\u7684\u50cf\u7d20\uff0c\u91c7\u7528\u53cc\u7ebf\u6027\u63d2\u503c\u6cd5\u8fdb\u884c\u8ba1\u7b97\uff0c\u8fd9\u6837\uff0c\u5c31\u4f1a\u5f97\u5230\u56db\u4e2a\u70b9\u7684\u50cf\u7d20\u503c\uff0c\u5982\u4e0b\u56fe\uff1a \u4e0a\u56fe\u4e2d\uff0c\u56db\u4e2a\u7ea2\u8272\u53c9\u53c9\u2018\u00d7\u2019\u7684\u50cf\u7d20\u503c\u662f\u901a\u8fc7\u53cc\u7ebf\u6027\u63d2\u503c\u7b97\u6cd5\u8ba1\u7b97\u5f97\u5230\u7684\u3002 \u6700\u540e\uff0c\u53d6\u56db\u4e2a\u50cf\u7d20\u503c\u4e2d\u6700\u5927\u503c\uff08\u6700\u5927\u6c60\u5316\uff09\u4f5c\u4e3a\u8fd9\u4e2a\u5c0f\u533a\u57df(\u5373\uff1a2.97x2.97\u5927\u5c0f\u7684\u533a\u57df)\u7684\u50cf\u7d20\u503c\uff0c\u5982\u6b64\u7c7b\u63a8\uff0c\u540c\u6837\u662f49\u4e2a\u5c0f\u533a\u57df\u5f97\u523049\u4e2a\u50cf\u7d20\u503c\uff0c\u7ec4\u62107x7\u5927\u5c0f\u7684\u7279\u5f81\u56fe\u3002 \u53cc\u7ebf\u6027\u63d2\u503c\u662f\u4e00\u79cd\u56fe\u50cf\u7f29\u653e\u586b\u5145\u7b97\u6cd5\uff0c\u5b83\u5145\u5206\u7684\u5229\u7528\u4e86\u539f\u56fe\u4e2d\u865a\u62df\u70b9\uff08\u6bd4\u598220.56\u8fd9\u4e2a\u6d6e\u70b9\u6570\uff0c\u50cf\u7d20\u4f4d\u7f6e\u4e0d\u662f\u6574\u6570\u503c\uff0c\u800c\u662f\u6d6e\u70b9\u503c\uff09\u56db\u5468\u7684\u771f\u5b9e\u5b58\u5728\u7684\u50cf\u7d20\u503c\u6765\u5171\u540c\u51b3\u5b9a\u76ee\u6807\u56fe\u4e2d\u7684\u4e00\u4e2a\u50cf\u7d20\u503c\uff0c\u5373\u53ef\u4ee5\u5c0620.56\u8fd9\u4e2a\u865a\u62df\u7684\u4f4d\u7f6e\u70b9\u5bf9\u5e94\u7684\u50cf\u7d20\u503c\u4f30\u8ba1\u51fa\u6765\u3002","title":"1.2.1 \u539f\u7406\u4ecb\u7ecd"},{"location":"imageSegmentation/section4/#122","text":"\u5728tensorFlow\u4e2d\u5b9e\u73b0\u65f6\u4f7f\u7528\uff1a tf . image . crop_and_resize ( image , boxes , box_indices , crop_size , method = 'bilinear' , extrapolation_value = 0 , name = None ) \u53c2\u6570\u4ecb\u7ecd\uff1a image: \u8868\u793a\u7279\u5f81\u56fe boxes\uff1a\u6307\u9700\u8981\u5212\u5206\u7684ROI\u533a\u57df\uff0c\u8f93\u5165\u683c\u5f0f\u4e3a[ymin\uff0cxmin\uff0cymax\uff0cxmax]\uff0c\u6ce8\u610f\u662f\u5f52\u4e00\u5316\u7684\u7ed3\u679c\u3002 \u5047\u8bbe\u5019\u9009\u533a\u57df\u5750\u6807\u662f[y1,x1,y2,x2]\uff0c\u90a3\u4e48\u60f3\u8981\u5f97\u5230\u76f8\u5e94\u6b63\u786e\u7684crop\u56fe\u5f62\u5c31\u4e00\u5b9a\u8981\u5f52\u4e00\u5316,\u5373\u56fe\u7247\u7684\u957f\u5ea6\u662f[w,h],\u5219\u5b9e\u9645\u8f93\u5165\u7684boxes\u4e3a[y1/h,x1/w,y2/h,x2/w]\uff0c\u8d85\u51fa1\u7684\u90e8\u5206\u4f7f\u7528\u9ed1\u82720\u8fdb\u884c\u586b\u5145\u3002 box_indice: \u662fboxes\u548cimage\u4e4b\u95f4\u7684\u7d22\u5f15\uff0c\u5373box\u5bf9\u5e94\u7684\u56fe\u50cf\u7d22\u5f15 crop_size: \u8868\u793aRoiAlign\u4e4b\u540e\u7684\u5019\u9009\u533a\u57df\u7684\u5927\u5c0f\u3002 method\uff1a\u63d2\u503c\u65b9\u6cd5\uff0c\u9ed8\u8ba4\u662f\u53cc\u7ebf\u6027\u63d2\u503c \u4e0b\u9762\u6211\u4eec\u5229\u7528\u4e24\u5f20\u56fe\u7247\u770b\u4e0bROIAlign\u7684\u6548\u679c\uff1a \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf import matplotlib.pyplot as plt \u539f\u56fe\u50cf\u8bfb\u53d6\u548c\u5c55\u793a # \u56fe\u50cf\u8bfb\u53d6 img = plt . imread ( 'Trump.jpg' ) / 255. img2 = plt . imread ( 'Trump2.jpg' ) / 255. # \u56fe\u50cf\u5c55\u793a plt . figure ( figsize = ( 10 , 8 )) plt . subplot ( 1 , 2 , 1 ) plt . imshow ( img ) plt . subplot ( 1 , 2 , 2 ) plt . imshow ( img2 ) \u6784\u5efabatch_size\u6570\u636e\uff08batch_size=2\uff09 # \u5bf9\u56fe\u50cf\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362\uff0c\u5e76\u6dfb\u52a0batch\u7ef4 img = tf . convert_to_tensor ( img , dtype = tf . float32 ) img = tf . expand_dims ( img , axis = 0 ) img = tf . image . resize ( img , ( 500 , 500 )) img2 = tf . convert_to_tensor ( img2 , dtype = tf . float32 ) img2 = tf . expand_dims ( img2 , axis = 0 ) img2 = tf . image . resize ( img2 , ( 500 , 500 )) # \u5c06\u4e24\u4e2a\u56fe\u50cf\u62fc\u63a5\u5728\u4e00\u8d77 img = tf . concat ([ img , img2 ], axis = 0 ) print ( 'img:' , img . shape ) \u8f93\u51fa\u4e3a\uff1a img : ( 2 , 500 , 500 , 3 ) \u4e00\u4e2abatch\u4e2d\u5305\u542b2\u4e2a\u56fe\u50cf\uff0c\u6bcf\u4e2a\u56fe\u50cf\u7684\u5927\u5c0f\u4e3a500x500x3\uff0c\u7406\u89e3\u4e3a\u4e24\u4e2a\u7279\u5f81\u56fe ROIAlign # \u8fdb\u884cROIAlign\u5904\u7406\uff1a\u7279\u5f81\u56fe\uff0c2\u4e2aboxes\uff0c\u5206\u522b\u5bf9\u5e94\u56fe\u50cf\u7d22\u5f150\u548c1\uff0cROIAlign\u540e\u7684\u5927\u5c0f\u4e3a50x50 out = tf . image . crop_and_resize ( img , [[ 0.5 , 0.5 , 1.0 , 1.0 ], [ 0.5 , 0.5 , 1.5 , 1.5 ]], [ 0 , 1 ], crop_size = ( 50 , 50 )) print ( 'out:' , a . shape ) \u8f93\u51fa\u4e3a\uff1a out : ( 2 , 50 , 50 , 3 ) \u6548\u679c\u5c55\u793a plt . figure ( figsize = ( 10 , 8 )) # \u5c3a\u5bf8\u8c03\u6574\u540e\u7684\u56fe\u50cf plt . subplot ( 2 , 2 , 1 ) plt . imshow ( img [ 0 ]) plt . subplot ( 2 , 2 , 2 ) plt . imshow ( img [ 1 ]) # ROIAlign\u7684\u7ed3\u679c plt . subplot ( 2 , 2 , 3 ) plt . imshow ( a [ 0 ]) plt . subplot ( 2 , 2 , 4 ) plt . imshow ( a [ 1 ]) plt . show ()","title":"1.2.2 \u5b9e\u73b0\u6548\u679c"},{"location":"imageSegmentation/section4/#13","text":"\u4e0a\u8ff0\u5df2\u7ecf\u4ecb\u7ecd\u4e86Mask-RCNN \u7684\u7ed3\u6784\u4e0eFasterRCNN\u662f\u76f8\u540c\u7684\uff0c\u589e\u52a0\u4e86\u4e00\u4e2a\u5206\u5272\u7684\u5934\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u9aa8\u5e72\u7f51\u7edcResNet-FPN\u7528\u4e8e\u7279\u5f81\u63d0\u53d6\uff0cRPN\u7f51\u7edc\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u63d0\u53d6\uff0cROIAlign\u83b7\u53d6\u56fa\u5b9a\u5927\u5c0f\u7684\u7279\u5f81\u56fe\uff0c\u5934\u90e8\u7f51\u7edc\u5305\u62ec\u8fb9\u754c\u6846\u8bc6\u522b\uff08\u5206\u7c7b\u548c\u56de\u5f52\uff09+mask\u9884\u6d4b\uff0c\u5177\u4f53\u5982\u4e0b\u6240\u793a\uff1a mask\u5206\u652f\u662f\u4e00\u4e2a\u5168\u5377\u79ef\u7f51\u7edc\uff0c\u5b9e\u9645\u5de5\u4f5c\u4e2d\u6211\u4eec\u4f7f\u7528\u53f3\u56fe\u8f83\u591a\u4e00\u4e9b\uff0c\u5176\u4e2d\u4f7f\u75282x2\u7684\u53cd\u5377\u79ef\u8fdb\u884c\u4e0a\u91c7\u6837\u3002\u9884\u6d4b\u65f6 mask \u5206\u652f\u8f93\u51fa\u7ed3\u679c resize \u5230 RoI \u7684\u5927\u5c0f, \u7136\u540e\u5e94\u7528 0.5 \u7684\u9608\u503c\u8fdb\u884c\u4e8c\u503c\u5316\u5f97\u5230\u6700\u7ec8\u7684\u5206\u5272\u7ed3\u679c\u3002","title":"1.3 \u7f51\u7edc\u7ed3\u6784"},{"location":"imageSegmentation/section4/#14","text":"Mask-RCNN\u5728Faster-RCNN\u7684\u57fa\u7840\u4e0a\u591a\u4e86\u4e00\u4e2aROIAligin\u548cMask\u9884\u6d4b\u5206\u652f\uff0c\u56e0\u6b64Mask R-CNN\u7684\u635f\u5931\u4e5f\u662f\u591a\u4efb\u52a1\u635f\u5931\uff1a L_{cls} L_{cls} \u548c L_{box} L_{box} \u4e0efaster rcnn\u7684\u5b9a\u4e49\u6ca1\u6709\u533a\u522b\u3002\u5177\u4f53\u6765\u770b\u4e0b L_{mask} L_{mask} \u3002 Mask\u5206\u652f\u5bf9\u6bcf\u4e2aROI\u533a\u57df\u4ea7\u751f\u4e00\u4e2amxmxK\u7684\u8f93\u51fa\u7279\u5f81\u56fe\uff0c\u5373K\u4e2a\u7684\u4e8c\u503c\u63a9\u819c\u56fe\u50cf\uff0c\u5176\u4e2dK\u4ee3\u8868\u76ee\u6807\u79cd\u7c7b\u6570\u3002\u5bf9\u4e8e\u9884\u6d4b\u7684\u4e8c\u503c\u63a9\u819c\u8f93\u51fa\uff0c\u5bf9\u6bcf\u4e00\u4e2a\u50cf\u7d20\u70b9\u5e94\u7528 sigmoid \u51fd\u6570\uff0c\u6574\u4f53\u635f\u5931\u5b9a\u4e49\u4e3a\u5e73\u5747\u4e8c\u503c\u4ea4\u53c9\u635f\u5931\u71b5\u3002\u5bf9\u4e8e\u771f\u5b9e\u7c7b\u522b\u4e3a\ud835\udc58\u7684\ud835\udc45\ud835\udc5c\ud835\udc3c\uff0c\u4ec5\u5728\u7b2ck\u4e2a\u63a9\u7801\u4e0a\u8ba1\u7b97\u635f\u5931\uff08\u5176\u4ed6\u63a9\u7801\u8f93\u51fa\u4e0d\u8ba1\u5165\uff09\u3002\u8fd9\u6837\u505a\u89e3\u8026\u4e86\u63a9\u819c\u548c\u79cd\u7c7b\u9884\u6d4b\u3002 \u4e0d\u50cfFCN\u7684\u505a\u6cd5\uff0c\u5728\u6bcf\u4e2a\u50cf\u7d20\u70b9\u4e0a\u5e94\u7528 softmax \u51fd\u6570\uff0c\u6574\u4f53\u91c7\u7528\u7684\u591a\u4efb\u52a1\u4ea4\u53c9\u71b5\uff0c\u8fd9\u6837\u4f1a\u5bfc\u81f4\u7c7b\u95f4\u7ade\u4e89\uff0c\u6700\u7ec8\u5bfc\u81f4\u5206\u5272\u6548\u679c\u5dee\u3002 \u603b\u7ed3 \u8bf4\u660eMask RCNN\u7684\u7ed3\u6784\u7279\u70b9 \u5728Faster-RCNN\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u4e00\u4e2a\u5206\u652f\uff0c\u5728\u5b9e\u73b0\u76ee\u6807\u68c0\u6d4b\u7684\u540c\u65f6\u5206\u5272\u76ee\u6807\u50cf\u7d20 \u638c\u63e1Mask RCNN\u7684RoIAlign\u65b9\u6cd5 ROIAlign\u6ca1\u6709\u4f7f\u7528\u91cf\u5316\u64cd\u4f5c\uff0c\u800c\u662f\u4f7f\u7528\u4e86\u53cc\u7ebf\u6027\u63d2\u503c\u4f30\u8ba1\u975e\u6574\u6570\u70b9\u7684\u50cf\u7d20\u503c \u638c\u63e1Mask RCNN\u7684mask\u539f\u7406 mask\u5206\u652f\u662f\u4e00\u4e2a\u5168\u5377\u79ef\u7f51\u7edc\uff0c\u4f7f\u75282x2\u7684\u53cd\u5377\u79ef\u8fdb\u884c\u4e0a\u91c7\u6837 \u77e5\u9053Mask RCNN\u7684\u635f\u5931\u51fd\u6570 \u591a\u4efb\u52a1\u635f\u5931\u51fd\u6570\uff1a\u6709\u5206\u7c7b\uff0c\u56de\u5f52\u548c\u5206\u5272\u4e09\u90e8\u5206\u7ec4\u6210","title":"1.4 \u635f\u5931\u51fd\u6570"},{"location":"introduction/","text":"\u8ba1\u7b97\u673a\u89c6\u89c9\u7b80\u4ecb \u00b6","title":"\u8ba1\u7b97\u673a\u89c6\u89c9\u7b80\u4ecb"},{"location":"introduction/#_1","text":"","title":"\u8ba1\u7b97\u673a\u89c6\u89c9\u7b80\u4ecb"},{"location":"introduction/section1/","text":"\u6df1\u5ea6\u5b66\u4e60 \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u4ec0\u4e48\u662f\u6df1\u5ea6\u5b66\u4e60 \u77e5\u9053\u6df1\u5ea6\u5b66\u4e60\u7684\u5e94\u7528\u573a\u666f 1.\u4ec0\u4e48\u662f\u6df1\u5ea6\u5b66\u4e60 \u00b6 \u5728\u4ecb\u7ecd\u6df1\u5ea6\u5b66\u4e60\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u770b\u4e0b\u4eba\u5de5\u667a\u80fd\uff0c\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u4e4b\u95f4\u7684\u5173\u7cfb\uff1a \u673a\u5668\u5b66\u4e60\u662f\u5b9e\u73b0\u4eba\u5de5\u667a\u80fd\u7684\u4e00\u79cd\u9014\u5f84\uff0c\u6df1\u5ea6\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e00\u4e2a\u5b50\u96c6\uff0c\u4e5f\u5c31\u662f\u8bf4\u6df1\u5ea6\u5b66\u4e60\u662f\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u7684\u4e00\u79cd\u65b9\u6cd5\u3002\u4e0e\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u4e3b\u8981\u533a\u522b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7b97\u672f\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7279\u5f81\uff0c\u5e76\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e0d\u9700\u8981\u4eba\u5de5\uff0c\u800c\u662f\u4f9d\u8d56\u7b97\u6cd5\u81ea\u52a8\u63d0\u53d6\u7279\u5f81\u3002\u6df1\u5ea6\u5b66\u4e60\u6a21\u4eff\u4eba\u7c7b\u5927\u8111\u7684\u8fd0\u884c\u65b9\u5f0f\uff0c\u4ece\u7ecf\u9a8c\u4e2d\u5b66\u4e60\u83b7\u53d6\u77e5\u8bc6\u3002\u8fd9\u4e5f\u662f\u6df1\u5ea6\u5b66\u4e60\u88ab\u770b\u505a\u9ed1\u76d2\u5b50\uff0c\u53ef\u89e3\u91ca\u6027\u5dee\u7684\u539f\u56e0\u3002 \u968f\u7740\u8ba1\u7b97\u673a\u8f6f\u786c\u4ef6\u7684\u98de\u901f\u53d1\u5c55\uff0c\u73b0\u9636\u6bb5\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u6765\u6a21\u62df\u4eba\u8111\u6765\u89e3\u91ca\u6570\u636e\uff0c\u5305\u62ec\u56fe\u50cf\uff0c\u6587\u672c\uff0c\u97f3\u9891\u7b49\u5185\u5bb9\u3002\u76ee\u524d\u6df1\u5ea6\u5b66\u4e60\u7684\u4e3b\u8981\u5e94\u7528\u9886\u57df\u6709\uff1a \u667a\u80fd\u624b\u673a \u8bed\u97f3\u8bc6\u522b \u6bd4\u5982\u82f9\u679c\u7684\u667a\u80fd\u8bed\u97f3\u52a9\u624bsiri \u673a\u5668\u7ffb\u8bd1 \u8c37\u6b4c\u5c06\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5d4c\u5165\u5230\u8c37\u6b4c\u7ffb\u8bd1\u4e2d\uff0c\u80fd\u591f\u652f\u6301100\u591a\u79cd\u8bed\u8a00\u7684\u5373\u65f6\u7ffb\u8bd1\u3002 \u62cd\u7167\u7ffb\u8bd1 \u81ea\u52a8\u9a7e\u9a76 \u5f53\u7136\u5728\u5176\u4ed6\u9886\u57df\u4e5f\u80fd\u89c1\u5230\u6df1\u5ea6\u5b66\u4e60\u7684\u8eab\u5f71\uff0c\u6bd4\u5982\u98ce\u63a7\uff0c\u5b89\u9632\uff0c\u667a\u80fd\u96f6\u552e\uff0c\u533b\u7597\u9886\u57df\uff0c\u63a8\u8350\u7cfb\u7edf\u7b49\u3002 \u5728\u8be5\u8bfe\u7a0b\u4e2d\uff0c\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecd\uff1a \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6TensorFlow\u7684\u5e94\u7528 \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc \u4e24\u90e8\u5206\u5185\u5bb9\u3002 2 \u53d1\u5c55\u5386\u53f2\uff08\u4e86\u89e3\uff09 \u00b6 \u6df1\u5ea6\u5b66\u4e60\u5176\u5b9e\u5e76\u4e0d\u662f\u65b0\u7684\u4e8b\u7269\uff0c\u6df1\u5ea6\u5b66\u4e60\u6240\u9700\u8981\u7684\u795e\u7ecf\u7f51\u7edc\u6280\u672f\u8d77\u6e90\u4e8e20\u4e16\u7eaa50\u5e74\u4ee3\uff0c\u53eb\u505a\u611f\u77e5\u673a\u3002\u5f53\u65f6\u4e5f\u901a\u5e38\u4f7f\u7528\u5355\u5c42\u611f\u77e5\u673a\uff0c\u5c3d\u7ba1\u7ed3\u6784\u7b80\u5355\uff0c\u4f46\u662f\u80fd\u591f\u89e3\u51b3\u590d\u6742\u7684\u95ee\u9898\u3002\u540e\u6765\u611f\u77e5\u673a\u88ab\u8bc1\u660e\u5b58\u5728\u4e25\u91cd\u7684\u95ee\u9898\uff0c\u56e0\u4e3a\u53ea\u80fd\u5b66\u4e60\u7ebf\u6027\u53ef\u5206\u51fd\u6570\uff0c\u8fde\u7b80\u5355\u7684\u5f02\u6216(XOR)\u7b49\u7ebf\u6027\u4e0d\u53ef\u5206\u95ee\u9898\u90fd\u65e0\u80fd\u4e3a\u529b\uff0c1969\u5e74Marvin Minsky\u5199\u4e86\u4e00\u672c\u53eb\u505a\u300aPerceptrons\u300b\u7684\u4e66\uff0c\u4ed6\u63d0\u51fa\u4e86\u8457\u540d\u7684\u4e24\u4e2a\u89c2\u70b9\uff1a1.\u5355\u5c42\u611f\u77e5\u673a\u6ca1\u7528\uff0c\u6211\u4eec\u9700\u8981\u591a\u5c42\u611f\u77e5\u673a\u6765\u89e3\u51b3\u590d\u6742\u95ee\u9898 2.\u6ca1\u6709\u6709\u6548\u7684\u8bad\u7ec3\u7b97\u6cd5\u3002 20\u4e16\u7eaa80\u5e74\u4ee3\u672b\u671f\uff0c\u7528\u4e8e\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7684\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff08\u4e5f\u53ebBack Propagation\u7b97\u6cd5\u6216\u8005BP\u7b97\u6cd5\uff09\u7684\u53d1\u660e\uff0c\u7ed9\u673a\u5668\u5b66\u4e60\u5e26\u6765\u4e86\u5e0c\u671b\uff0c\u6380\u8d77\u4e86\u57fa\u4e8e\u7edf\u8ba1\u6a21\u578b\u7684\u673a\u5668\u5b66\u4e60\u70ed\u6f6e\u3002\u8fd9\u4e2a\u70ed\u6f6e\u4e00\u76f4\u6301\u7eed\u5230\u4eca\u5929\u3002\u4eba\u4eec\u53d1\u73b0\uff0c\u5229\u7528BP\u7b97\u6cd5\u53ef\u4ee5\u8ba9\u4e00\u4e2a\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4ece\u5927\u91cf\u8bad\u7ec3\u6837\u672c\u4e2d\u5b66\u4e60\u7edf\u8ba1\u89c4\u5f8b\uff0c\u4ece\u800c\u5bf9\u672a\u77e5\u4e8b\u4ef6\u505a\u9884\u6d4b\u3002\u8fd9\u79cd\u57fa\u4e8e\u7edf\u8ba1\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6bd4\u8d77\u8fc7\u53bb\u57fa\u4e8e\u4eba\u5de5\u89c4\u5219\u7684\u7cfb\u7edf\uff0c\u5728\u5f88\u591a\u65b9\u9762\u663e\u51fa\u4f18\u8d8a\u6027\u3002\u8fd9\u4e2a\u65f6\u5019\u7684\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff0c\u867d\u4e5f\u88ab\u79f0\u4f5c\u591a\u5c42\u611f\u77e5\u673a\uff08Multi-layer Perceptron\uff09\uff0c\u4f46\u5b9e\u9645\u662f\u79cd\u53ea\u542b\u6709\u4e00\u5c42\u9690\u5c42\u8282\u70b9\u7684\u6d45\u5c42\u6a21\u578b\u3002 20\u4e16\u7eaa90\u5e74\u4ee3\uff0c\u5404\u79cd\u5404\u6837\u7684\u6d45\u5c42\u673a\u5668\u5b66\u4e60\u6a21\u578b\u76f8\u7ee7\u88ab\u63d0\u51fa\uff0c\u4f8b\u5982\u652f\u6491\u5411\u91cf\u673a\uff08SVM\uff0cSupport Vector Machines\uff09\u3001 Boosting\u3001\u6700\u5927\u71b5\u65b9\u6cd5\uff08\u5982LR\uff0cLogistic Regression\uff09\u7b49\u3002\u8fd9\u4e9b\u6a21\u578b\u7684\u7ed3\u6784\u57fa\u672c\u4e0a\u53ef\u4ee5\u770b\u6210\u5e26\u6709\u4e00\u5c42\u9690\u5c42\u8282\u70b9\uff08\u5982SVM\u3001Boosting\uff09\uff0c\u6216\u6ca1\u6709\u9690\u5c42\u8282\u70b9\uff08\u5982LR\uff09\u3002\u8fd9\u4e9b\u6a21\u578b\u65e0\u8bba\u662f\u5728\u7406\u8bba\u5206\u6790\u8fd8\u662f\u5e94\u7528\u4e2d\u90fd\u83b7\u5f97\u4e86\u5de8\u5927\u7684\u6210\u529f\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u7531\u4e8e\u7406\u8bba\u5206\u6790\u7684\u96be\u5ea6\u5927\uff0c\u8bad\u7ec3\u65b9\u6cd5\u53c8\u9700\u8981\u5f88\u591a\u7ecf\u9a8c\u548c\u6280\u5de7\uff0c\u8fd9\u4e2a\u65f6\u671f\u6d45\u5c42\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u53cd\u800c\u76f8\u5bf9\u6c89\u5bc2. 2006\u5e74\uff0c\u6770\u5f17\u91cc\u00b7\u8f9b\u987f\u4ee5\u53ca\u4ed6\u7684\u5b66\u751f\u9c81\u65af\u5170\u00b7\u8428\u62c9\u8d6b\u4e01\u8bfa\u592b\u6b63\u5f0f\u63d0\u51fa\u4e86\u6df1\u5ea6\u5b66\u4e60\u7684\u6982\u5ff5\u3002\u4ed6\u4eec\u5728\u4e16\u754c\u9876\u7ea7\u5b66\u672f\u671f\u520a\u300a\u79d1\u5b66\u300b\u53d1\u8868\u7684\u4e00\u7bc7\u6587\u7ae0\u4e2d\u8be6\u7ec6\u7684\u7ed9\u51fa\u4e86\u201c\u68af\u5ea6\u6d88\u5931\u201d\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\u2014\u2014\u901a\u8fc7\u65e0\u76d1\u7763\u7684\u5b66\u4e60\u65b9\u6cd5\u9010\u5c42\u8bad\u7ec3\u7b97\u6cd5\uff0c\u518d\u4f7f\u7528\u6709\u76d1\u7763\u7684\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u8fdb\u884c\u8c03\u4f18\u3002\u8be5\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u63d0\u51fa\uff0c\u7acb\u5373\u5728\u5b66\u672f\u5708\u5f15\u8d77\u4e86\u5de8\u5927\u7684\u53cd\u54cd\uff0c\u4ee5\u65af\u5766\u798f\u5927\u5b66\u3001\u591a\u4f26\u591a\u5927\u5b66\u4e3a\u4ee3\u8868\u7684\u4f17\u591a\u4e16\u754c\u77e5\u540d\u9ad8\u6821\u7eb7\u7eb7\u6295\u5165\u5de8\u5927\u7684\u4eba\u529b\u3001\u8d22\u529b\u8fdb\u884c\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u7684\u76f8\u5173\u7814\u7a76\u3002\u800c\u540e\u53c8\u8fc5\u901f\u8513\u5ef6\u5230\u5de5\u4e1a\u754c\u4e2d\u3002 2012\u5e74\uff0c\u5728\u8457\u540d\u7684ImageNet\u56fe\u50cf\u8bc6\u522b\u5927\u8d5b\u4e2d\uff0c\u6770\u5f17\u91cc\u00b7\u8f9b\u987f\u9886\u5bfc\u7684\u5c0f\u7ec4\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578bAlexNet\u4e00\u4e3e\u593a\u51a0\u3002AlexNet\u91c7\u7528ReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u4ece\u6839\u672c\u4e0a\u89e3\u51b3\u4e86\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u5e76\u91c7\u7528GPU\u6781\u5927\u7684\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u8fd0\u7b97\u901f\u5ea6\u3002\u540c\u5e74\uff0c\u7531\u65af\u5766\u798f\u5927\u5b66\u8457\u540d\u7684\u5434\u6069\u8fbe\u6559\u6388\u548c\u4e16\u754c\u9876\u5c16\u8ba1\u7b97\u673a\u4e13\u5bb6Jeff Dean\u5171\u540c\u4e3b\u5bfc\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u2014\u2014DNN\u6280\u672f\u5728\u56fe\u50cf\u8bc6\u522b\u9886\u57df\u53d6\u5f97\u4e86\u60ca\u4eba\u7684\u6210\u7ee9\uff0c\u5728ImageNet\u8bc4\u6d4b\u4e2d\u6210\u529f\u7684\u628a\u9519\u8bef\u7387\u4ece26\uff05\u964d\u4f4e\u5230\u4e8615\uff05\u3002\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u5728\u4e16\u754c\u5927\u8d5b\u7684\u8131\u9896\u800c\u51fa\uff0c\u4e5f\u518d\u4e00\u6b21\u5438\u5f15\u4e86\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u5bf9\u4e8e\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u7684\u5173\u6ce8\u3002 2016\u5e74\uff0c\u968f\u7740\u8c37\u6b4c\u516c\u53f8\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u5f00\u53d1\u7684AlphaGo\u4ee54:1\u7684\u6bd4\u5206\u6218\u80dc\u4e86\u56fd\u9645\u9876\u5c16\u56f4\u68cb\u9ad8\u624b\u674e\u4e16\u77f3\uff0c\u6df1\u5ea6\u5b66\u4e60\u7684\u70ed\u5ea6\u4e00\u65f6\u65e0\u4e24\u3002\u540e\u6765\uff0cAlphaGo\u53c8\u63a5\u8fde\u548c\u4f17\u591a\u4e16\u754c\u7ea7\u56f4\u68cb\u9ad8\u624b\u8fc7\u62db\uff0c\u5747\u53d6\u5f97\u4e86\u5b8c\u80dc\u3002\u8fd9\u4e5f\u8bc1\u660e\u4e86\u5728\u56f4\u68cb\u754c\uff0c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u7684\u673a\u5668\u4eba\u5df2\u7ecf\u8d85\u8d8a\u4e86\u4eba\u7c7b\u3002 2017\u5e74\uff0c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684AlphaGo\u5347\u7ea7\u7248AlphaGo Zero\u6a2a\u7a7a\u51fa\u4e16\u3002\u5176\u91c7\u7528\u201c\u4ece\u96f6\u5f00\u59cb\u201d\u3001\u201c\u65e0\u5e08\u81ea\u901a\u201d\u7684\u5b66\u4e60\u6a21\u5f0f\uff0c\u4ee5100:0\u7684\u6bd4\u5206\u8f7b\u800c\u6613\u4e3e\u6253\u8d25\u4e86\u4e4b\u524d\u7684AlphaGo\u3002\u9664\u4e86\u56f4\u68cb\uff0c\u5b83\u8fd8\u7cbe\u901a\u56fd\u9645\u8c61\u68cb\u7b49\u5176\u5b83\u68cb\u7c7b\u6e38\u620f\uff0c\u53ef\u4ee5\u8bf4\u662f\u771f\u6b63\u7684\u68cb\u7c7b\u201c\u5929\u624d\u201d\u3002\u6b64\u5916\u5728\u8fd9\u4e00\u5e74\uff0c\u6df1\u5ea6\u5b66\u4e60\u7684\u76f8\u5173\u7b97\u6cd5\u5728\u533b\u7597\u3001\u91d1\u878d\u3001\u827a\u672f\u3001\u65e0\u4eba\u9a7e\u9a76\u7b49\u591a\u4e2a\u9886\u57df\u5747\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u679c\u3002\u6240\u4ee5\uff0c\u4e5f\u6709\u4e13\u5bb6\u628a2017\u5e74\u770b\u4f5c\u662f\u6df1\u5ea6\u5b66\u4e60\u751a\u81f3\u662f\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u6700\u4e3a\u7a81\u98de\u731b\u8fdb\u7684\u4e00\u5e74\u3002 2019\u5e74\uff0c\u57fa\u4e8eTransformer \u7684\u81ea\u7136\u8bed\u8a00\u6a21\u578b\u7684\u6301\u7eed\u589e\u957f\u548c\u6269\u6563\uff0c\u8fd9\u662f\u4e00\u79cd\u8bed\u8a00\u5efa\u6a21\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u53ef\u4ee5\u5728\u51e0\u4e4e\u6240\u6709\u4efb\u52a1\u4e0a\u63d0\u9ad8NLP\u7684\u8d28\u91cf\u3002Google\u751a\u81f3\u5c06\u5176\u7528\u4f5c\u76f8\u5173\u6027\u7684\u4e3b\u8981\u4fe1\u53f7\u4e4b\u4e00\uff0c\u8fd9\u662f\u591a\u5e74\u6765\u6700\u91cd\u8981\u7684\u66f4\u65b0 2020\u5e74\uff0c\u6df1\u5ea6\u5b66\u4e60\u6269\u5c55\u5230\u66f4\u591a\u7684\u5e94\u7528\u573a\u666f\uff0c\u6bd4\u5982\u79ef\u6c34\u8bc6\u522b\uff0c\u8def\u9762\u584c\u9677\u7b49\uff0c\u800c\u4e14\u75ab\u60c5\u671f\u95f4\uff0c\u5728\u667a\u80fd\u5916\u547c\u7cfb\u7edf\uff0c\u4eba\u7fa4\u6d4b\u6e29\u7cfb\u7edf\uff0c\u53e3\u7f69\u4eba\u8138\u8bc6\u522b\u7b49\u90fd\u6709\u6df1\u5ea6\u5b66\u4e60\u7684\u5e94\u7528\u3002 \u603b\u7ed3 \u6df1\u5ea6\u5b66\u4e60\u662f\u4ec0\u4e48 \u6df1\u5ea6\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u4e00\u79cd\uff0c\u901a\u8fc7\u6a21\u62df\u4eba\u8111\u5b9e\u73b0\u76f8\u5e94\u7684\u529f\u80fd \u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u573a\u666f \u624b\u673a\uff0c\u673a\u5668\u7ffb\u8bd1\uff0c\u81ea\u52a8\u9a7e\u9a76\uff0c\u8bed\u97f3\u8bc6\u522b\uff0c\u533b\u7597\uff0c\u5b89\u9632\u7b49\u3002","title":"\u6df1\u5ea6\u5b66\u4e60"},{"location":"introduction/section1/#_1","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u4ec0\u4e48\u662f\u6df1\u5ea6\u5b66\u4e60 \u77e5\u9053\u6df1\u5ea6\u5b66\u4e60\u7684\u5e94\u7528\u573a\u666f","title":"\u6df1\u5ea6\u5b66\u4e60"},{"location":"introduction/section1/#1","text":"\u5728\u4ecb\u7ecd\u6df1\u5ea6\u5b66\u4e60\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u770b\u4e0b\u4eba\u5de5\u667a\u80fd\uff0c\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u4e4b\u95f4\u7684\u5173\u7cfb\uff1a \u673a\u5668\u5b66\u4e60\u662f\u5b9e\u73b0\u4eba\u5de5\u667a\u80fd\u7684\u4e00\u79cd\u9014\u5f84\uff0c\u6df1\u5ea6\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e00\u4e2a\u5b50\u96c6\uff0c\u4e5f\u5c31\u662f\u8bf4\u6df1\u5ea6\u5b66\u4e60\u662f\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u7684\u4e00\u79cd\u65b9\u6cd5\u3002\u4e0e\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u4e3b\u8981\u533a\u522b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7b97\u672f\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7279\u5f81\uff0c\u5e76\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e0d\u9700\u8981\u4eba\u5de5\uff0c\u800c\u662f\u4f9d\u8d56\u7b97\u6cd5\u81ea\u52a8\u63d0\u53d6\u7279\u5f81\u3002\u6df1\u5ea6\u5b66\u4e60\u6a21\u4eff\u4eba\u7c7b\u5927\u8111\u7684\u8fd0\u884c\u65b9\u5f0f\uff0c\u4ece\u7ecf\u9a8c\u4e2d\u5b66\u4e60\u83b7\u53d6\u77e5\u8bc6\u3002\u8fd9\u4e5f\u662f\u6df1\u5ea6\u5b66\u4e60\u88ab\u770b\u505a\u9ed1\u76d2\u5b50\uff0c\u53ef\u89e3\u91ca\u6027\u5dee\u7684\u539f\u56e0\u3002 \u968f\u7740\u8ba1\u7b97\u673a\u8f6f\u786c\u4ef6\u7684\u98de\u901f\u53d1\u5c55\uff0c\u73b0\u9636\u6bb5\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u6765\u6a21\u62df\u4eba\u8111\u6765\u89e3\u91ca\u6570\u636e\uff0c\u5305\u62ec\u56fe\u50cf\uff0c\u6587\u672c\uff0c\u97f3\u9891\u7b49\u5185\u5bb9\u3002\u76ee\u524d\u6df1\u5ea6\u5b66\u4e60\u7684\u4e3b\u8981\u5e94\u7528\u9886\u57df\u6709\uff1a \u667a\u80fd\u624b\u673a \u8bed\u97f3\u8bc6\u522b \u6bd4\u5982\u82f9\u679c\u7684\u667a\u80fd\u8bed\u97f3\u52a9\u624bsiri \u673a\u5668\u7ffb\u8bd1 \u8c37\u6b4c\u5c06\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5d4c\u5165\u5230\u8c37\u6b4c\u7ffb\u8bd1\u4e2d\uff0c\u80fd\u591f\u652f\u6301100\u591a\u79cd\u8bed\u8a00\u7684\u5373\u65f6\u7ffb\u8bd1\u3002 \u62cd\u7167\u7ffb\u8bd1 \u81ea\u52a8\u9a7e\u9a76 \u5f53\u7136\u5728\u5176\u4ed6\u9886\u57df\u4e5f\u80fd\u89c1\u5230\u6df1\u5ea6\u5b66\u4e60\u7684\u8eab\u5f71\uff0c\u6bd4\u5982\u98ce\u63a7\uff0c\u5b89\u9632\uff0c\u667a\u80fd\u96f6\u552e\uff0c\u533b\u7597\u9886\u57df\uff0c\u63a8\u8350\u7cfb\u7edf\u7b49\u3002 \u5728\u8be5\u8bfe\u7a0b\u4e2d\uff0c\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecd\uff1a \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6TensorFlow\u7684\u5e94\u7528 \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc \u4e24\u90e8\u5206\u5185\u5bb9\u3002","title":"1.\u4ec0\u4e48\u662f\u6df1\u5ea6\u5b66\u4e60"},{"location":"introduction/section1/#2","text":"\u6df1\u5ea6\u5b66\u4e60\u5176\u5b9e\u5e76\u4e0d\u662f\u65b0\u7684\u4e8b\u7269\uff0c\u6df1\u5ea6\u5b66\u4e60\u6240\u9700\u8981\u7684\u795e\u7ecf\u7f51\u7edc\u6280\u672f\u8d77\u6e90\u4e8e20\u4e16\u7eaa50\u5e74\u4ee3\uff0c\u53eb\u505a\u611f\u77e5\u673a\u3002\u5f53\u65f6\u4e5f\u901a\u5e38\u4f7f\u7528\u5355\u5c42\u611f\u77e5\u673a\uff0c\u5c3d\u7ba1\u7ed3\u6784\u7b80\u5355\uff0c\u4f46\u662f\u80fd\u591f\u89e3\u51b3\u590d\u6742\u7684\u95ee\u9898\u3002\u540e\u6765\u611f\u77e5\u673a\u88ab\u8bc1\u660e\u5b58\u5728\u4e25\u91cd\u7684\u95ee\u9898\uff0c\u56e0\u4e3a\u53ea\u80fd\u5b66\u4e60\u7ebf\u6027\u53ef\u5206\u51fd\u6570\uff0c\u8fde\u7b80\u5355\u7684\u5f02\u6216(XOR)\u7b49\u7ebf\u6027\u4e0d\u53ef\u5206\u95ee\u9898\u90fd\u65e0\u80fd\u4e3a\u529b\uff0c1969\u5e74Marvin Minsky\u5199\u4e86\u4e00\u672c\u53eb\u505a\u300aPerceptrons\u300b\u7684\u4e66\uff0c\u4ed6\u63d0\u51fa\u4e86\u8457\u540d\u7684\u4e24\u4e2a\u89c2\u70b9\uff1a1.\u5355\u5c42\u611f\u77e5\u673a\u6ca1\u7528\uff0c\u6211\u4eec\u9700\u8981\u591a\u5c42\u611f\u77e5\u673a\u6765\u89e3\u51b3\u590d\u6742\u95ee\u9898 2.\u6ca1\u6709\u6709\u6548\u7684\u8bad\u7ec3\u7b97\u6cd5\u3002 20\u4e16\u7eaa80\u5e74\u4ee3\u672b\u671f\uff0c\u7528\u4e8e\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7684\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff08\u4e5f\u53ebBack Propagation\u7b97\u6cd5\u6216\u8005BP\u7b97\u6cd5\uff09\u7684\u53d1\u660e\uff0c\u7ed9\u673a\u5668\u5b66\u4e60\u5e26\u6765\u4e86\u5e0c\u671b\uff0c\u6380\u8d77\u4e86\u57fa\u4e8e\u7edf\u8ba1\u6a21\u578b\u7684\u673a\u5668\u5b66\u4e60\u70ed\u6f6e\u3002\u8fd9\u4e2a\u70ed\u6f6e\u4e00\u76f4\u6301\u7eed\u5230\u4eca\u5929\u3002\u4eba\u4eec\u53d1\u73b0\uff0c\u5229\u7528BP\u7b97\u6cd5\u53ef\u4ee5\u8ba9\u4e00\u4e2a\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4ece\u5927\u91cf\u8bad\u7ec3\u6837\u672c\u4e2d\u5b66\u4e60\u7edf\u8ba1\u89c4\u5f8b\uff0c\u4ece\u800c\u5bf9\u672a\u77e5\u4e8b\u4ef6\u505a\u9884\u6d4b\u3002\u8fd9\u79cd\u57fa\u4e8e\u7edf\u8ba1\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6bd4\u8d77\u8fc7\u53bb\u57fa\u4e8e\u4eba\u5de5\u89c4\u5219\u7684\u7cfb\u7edf\uff0c\u5728\u5f88\u591a\u65b9\u9762\u663e\u51fa\u4f18\u8d8a\u6027\u3002\u8fd9\u4e2a\u65f6\u5019\u7684\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff0c\u867d\u4e5f\u88ab\u79f0\u4f5c\u591a\u5c42\u611f\u77e5\u673a\uff08Multi-layer Perceptron\uff09\uff0c\u4f46\u5b9e\u9645\u662f\u79cd\u53ea\u542b\u6709\u4e00\u5c42\u9690\u5c42\u8282\u70b9\u7684\u6d45\u5c42\u6a21\u578b\u3002 20\u4e16\u7eaa90\u5e74\u4ee3\uff0c\u5404\u79cd\u5404\u6837\u7684\u6d45\u5c42\u673a\u5668\u5b66\u4e60\u6a21\u578b\u76f8\u7ee7\u88ab\u63d0\u51fa\uff0c\u4f8b\u5982\u652f\u6491\u5411\u91cf\u673a\uff08SVM\uff0cSupport Vector Machines\uff09\u3001 Boosting\u3001\u6700\u5927\u71b5\u65b9\u6cd5\uff08\u5982LR\uff0cLogistic Regression\uff09\u7b49\u3002\u8fd9\u4e9b\u6a21\u578b\u7684\u7ed3\u6784\u57fa\u672c\u4e0a\u53ef\u4ee5\u770b\u6210\u5e26\u6709\u4e00\u5c42\u9690\u5c42\u8282\u70b9\uff08\u5982SVM\u3001Boosting\uff09\uff0c\u6216\u6ca1\u6709\u9690\u5c42\u8282\u70b9\uff08\u5982LR\uff09\u3002\u8fd9\u4e9b\u6a21\u578b\u65e0\u8bba\u662f\u5728\u7406\u8bba\u5206\u6790\u8fd8\u662f\u5e94\u7528\u4e2d\u90fd\u83b7\u5f97\u4e86\u5de8\u5927\u7684\u6210\u529f\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u7531\u4e8e\u7406\u8bba\u5206\u6790\u7684\u96be\u5ea6\u5927\uff0c\u8bad\u7ec3\u65b9\u6cd5\u53c8\u9700\u8981\u5f88\u591a\u7ecf\u9a8c\u548c\u6280\u5de7\uff0c\u8fd9\u4e2a\u65f6\u671f\u6d45\u5c42\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u53cd\u800c\u76f8\u5bf9\u6c89\u5bc2. 2006\u5e74\uff0c\u6770\u5f17\u91cc\u00b7\u8f9b\u987f\u4ee5\u53ca\u4ed6\u7684\u5b66\u751f\u9c81\u65af\u5170\u00b7\u8428\u62c9\u8d6b\u4e01\u8bfa\u592b\u6b63\u5f0f\u63d0\u51fa\u4e86\u6df1\u5ea6\u5b66\u4e60\u7684\u6982\u5ff5\u3002\u4ed6\u4eec\u5728\u4e16\u754c\u9876\u7ea7\u5b66\u672f\u671f\u520a\u300a\u79d1\u5b66\u300b\u53d1\u8868\u7684\u4e00\u7bc7\u6587\u7ae0\u4e2d\u8be6\u7ec6\u7684\u7ed9\u51fa\u4e86\u201c\u68af\u5ea6\u6d88\u5931\u201d\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\u2014\u2014\u901a\u8fc7\u65e0\u76d1\u7763\u7684\u5b66\u4e60\u65b9\u6cd5\u9010\u5c42\u8bad\u7ec3\u7b97\u6cd5\uff0c\u518d\u4f7f\u7528\u6709\u76d1\u7763\u7684\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u8fdb\u884c\u8c03\u4f18\u3002\u8be5\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u63d0\u51fa\uff0c\u7acb\u5373\u5728\u5b66\u672f\u5708\u5f15\u8d77\u4e86\u5de8\u5927\u7684\u53cd\u54cd\uff0c\u4ee5\u65af\u5766\u798f\u5927\u5b66\u3001\u591a\u4f26\u591a\u5927\u5b66\u4e3a\u4ee3\u8868\u7684\u4f17\u591a\u4e16\u754c\u77e5\u540d\u9ad8\u6821\u7eb7\u7eb7\u6295\u5165\u5de8\u5927\u7684\u4eba\u529b\u3001\u8d22\u529b\u8fdb\u884c\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u7684\u76f8\u5173\u7814\u7a76\u3002\u800c\u540e\u53c8\u8fc5\u901f\u8513\u5ef6\u5230\u5de5\u4e1a\u754c\u4e2d\u3002 2012\u5e74\uff0c\u5728\u8457\u540d\u7684ImageNet\u56fe\u50cf\u8bc6\u522b\u5927\u8d5b\u4e2d\uff0c\u6770\u5f17\u91cc\u00b7\u8f9b\u987f\u9886\u5bfc\u7684\u5c0f\u7ec4\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578bAlexNet\u4e00\u4e3e\u593a\u51a0\u3002AlexNet\u91c7\u7528ReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u4ece\u6839\u672c\u4e0a\u89e3\u51b3\u4e86\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u5e76\u91c7\u7528GPU\u6781\u5927\u7684\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u8fd0\u7b97\u901f\u5ea6\u3002\u540c\u5e74\uff0c\u7531\u65af\u5766\u798f\u5927\u5b66\u8457\u540d\u7684\u5434\u6069\u8fbe\u6559\u6388\u548c\u4e16\u754c\u9876\u5c16\u8ba1\u7b97\u673a\u4e13\u5bb6Jeff Dean\u5171\u540c\u4e3b\u5bfc\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u2014\u2014DNN\u6280\u672f\u5728\u56fe\u50cf\u8bc6\u522b\u9886\u57df\u53d6\u5f97\u4e86\u60ca\u4eba\u7684\u6210\u7ee9\uff0c\u5728ImageNet\u8bc4\u6d4b\u4e2d\u6210\u529f\u7684\u628a\u9519\u8bef\u7387\u4ece26\uff05\u964d\u4f4e\u5230\u4e8615\uff05\u3002\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u5728\u4e16\u754c\u5927\u8d5b\u7684\u8131\u9896\u800c\u51fa\uff0c\u4e5f\u518d\u4e00\u6b21\u5438\u5f15\u4e86\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u5bf9\u4e8e\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u7684\u5173\u6ce8\u3002 2016\u5e74\uff0c\u968f\u7740\u8c37\u6b4c\u516c\u53f8\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u5f00\u53d1\u7684AlphaGo\u4ee54:1\u7684\u6bd4\u5206\u6218\u80dc\u4e86\u56fd\u9645\u9876\u5c16\u56f4\u68cb\u9ad8\u624b\u674e\u4e16\u77f3\uff0c\u6df1\u5ea6\u5b66\u4e60\u7684\u70ed\u5ea6\u4e00\u65f6\u65e0\u4e24\u3002\u540e\u6765\uff0cAlphaGo\u53c8\u63a5\u8fde\u548c\u4f17\u591a\u4e16\u754c\u7ea7\u56f4\u68cb\u9ad8\u624b\u8fc7\u62db\uff0c\u5747\u53d6\u5f97\u4e86\u5b8c\u80dc\u3002\u8fd9\u4e5f\u8bc1\u660e\u4e86\u5728\u56f4\u68cb\u754c\uff0c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u7684\u673a\u5668\u4eba\u5df2\u7ecf\u8d85\u8d8a\u4e86\u4eba\u7c7b\u3002 2017\u5e74\uff0c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684AlphaGo\u5347\u7ea7\u7248AlphaGo Zero\u6a2a\u7a7a\u51fa\u4e16\u3002\u5176\u91c7\u7528\u201c\u4ece\u96f6\u5f00\u59cb\u201d\u3001\u201c\u65e0\u5e08\u81ea\u901a\u201d\u7684\u5b66\u4e60\u6a21\u5f0f\uff0c\u4ee5100:0\u7684\u6bd4\u5206\u8f7b\u800c\u6613\u4e3e\u6253\u8d25\u4e86\u4e4b\u524d\u7684AlphaGo\u3002\u9664\u4e86\u56f4\u68cb\uff0c\u5b83\u8fd8\u7cbe\u901a\u56fd\u9645\u8c61\u68cb\u7b49\u5176\u5b83\u68cb\u7c7b\u6e38\u620f\uff0c\u53ef\u4ee5\u8bf4\u662f\u771f\u6b63\u7684\u68cb\u7c7b\u201c\u5929\u624d\u201d\u3002\u6b64\u5916\u5728\u8fd9\u4e00\u5e74\uff0c\u6df1\u5ea6\u5b66\u4e60\u7684\u76f8\u5173\u7b97\u6cd5\u5728\u533b\u7597\u3001\u91d1\u878d\u3001\u827a\u672f\u3001\u65e0\u4eba\u9a7e\u9a76\u7b49\u591a\u4e2a\u9886\u57df\u5747\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u679c\u3002\u6240\u4ee5\uff0c\u4e5f\u6709\u4e13\u5bb6\u628a2017\u5e74\u770b\u4f5c\u662f\u6df1\u5ea6\u5b66\u4e60\u751a\u81f3\u662f\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u6700\u4e3a\u7a81\u98de\u731b\u8fdb\u7684\u4e00\u5e74\u3002 2019\u5e74\uff0c\u57fa\u4e8eTransformer \u7684\u81ea\u7136\u8bed\u8a00\u6a21\u578b\u7684\u6301\u7eed\u589e\u957f\u548c\u6269\u6563\uff0c\u8fd9\u662f\u4e00\u79cd\u8bed\u8a00\u5efa\u6a21\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u53ef\u4ee5\u5728\u51e0\u4e4e\u6240\u6709\u4efb\u52a1\u4e0a\u63d0\u9ad8NLP\u7684\u8d28\u91cf\u3002Google\u751a\u81f3\u5c06\u5176\u7528\u4f5c\u76f8\u5173\u6027\u7684\u4e3b\u8981\u4fe1\u53f7\u4e4b\u4e00\uff0c\u8fd9\u662f\u591a\u5e74\u6765\u6700\u91cd\u8981\u7684\u66f4\u65b0 2020\u5e74\uff0c\u6df1\u5ea6\u5b66\u4e60\u6269\u5c55\u5230\u66f4\u591a\u7684\u5e94\u7528\u573a\u666f\uff0c\u6bd4\u5982\u79ef\u6c34\u8bc6\u522b\uff0c\u8def\u9762\u584c\u9677\u7b49\uff0c\u800c\u4e14\u75ab\u60c5\u671f\u95f4\uff0c\u5728\u667a\u80fd\u5916\u547c\u7cfb\u7edf\uff0c\u4eba\u7fa4\u6d4b\u6e29\u7cfb\u7edf\uff0c\u53e3\u7f69\u4eba\u8138\u8bc6\u522b\u7b49\u90fd\u6709\u6df1\u5ea6\u5b66\u4e60\u7684\u5e94\u7528\u3002 \u603b\u7ed3 \u6df1\u5ea6\u5b66\u4e60\u662f\u4ec0\u4e48 \u6df1\u5ea6\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u4e00\u79cd\uff0c\u901a\u8fc7\u6a21\u62df\u4eba\u8111\u5b9e\u73b0\u76f8\u5e94\u7684\u529f\u80fd \u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u573a\u666f \u624b\u673a\uff0c\u673a\u5668\u7ffb\u8bd1\uff0c\u81ea\u52a8\u9a7e\u9a76\uff0c\u8bed\u97f3\u8bc6\u522b\uff0c\u533b\u7597\uff0c\u5b89\u9632\u7b49\u3002","title":"2 \u53d1\u5c55\u5386\u53f2\uff08\u4e86\u89e3\uff09"},{"location":"introduction/section2/","text":"\u8ba1\u7b97\u673a\u89c6\u89c9 \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5b9a\u4e49 \u77e5\u9053\u8ba1\u7b97\u673a\u89c6\u89c9\u5e38\u89c1\u4efb\u52a1 \u77e5\u9053\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5e94\u7528\u573a\u666f 1.\u8ba1\u7b97\u673a\u89c6\u89c9\u5b9a\u4e49 \u00b6 \u8ba1\u7b97\u673a\u89c6\u89c9\u662f\u6307\u7528\u6444\u50cf\u673a\u548c\u7535\u8111\u53ca\u5176\u4ed6\u76f8\u5173\u8bbe\u5907\uff0c\u5bf9\u751f\u7269\u89c6\u89c9\u7684\u4e00\u79cd\u6a21\u62df\u3002\u5b83\u7684\u4e3b\u8981\u4efb\u52a1\u8ba9\u8ba1\u7b97\u673a\u7406\u89e3\u56fe\u7247\u6216\u8005\u89c6\u9891\u4e2d\u7684\u5185\u5bb9\uff0c\u5c31\u50cf\u4eba\u7c7b\u548c\u8bb8\u591a\u5176\u4ed6\u751f\u7269\u6bcf\u5929\u6240\u505a\u7684\u90a3\u6837\u3002 \u6211\u4eec\u53ef\u4ee5\u5c06\u5176\u4efb\u52a1\u76ee\u6807\u62c6\u5206\u4e3a\uff1a \u8ba9\u8ba1\u7b97\u673a\u7406\u89e3\u56fe\u7247\u4e2d\u7684\u573a\u666f\uff08\u529e\u516c\u5ba4\uff0c\u5ba2\u5385\uff0c\u5496\u5561\u5385\u7b49\uff09 \u8ba9\u8ba1\u7b97\u673a\u8bc6\u522b\u573a\u666f\u4e2d\u5305\u542b\u7684\u7269\u4f53\uff08\u5ba0\u7269\uff0c\u4ea4\u901a\u5de5\u5177\uff0c\u4eba\u7b49\uff09 \u8ba9\u8ba1\u7b97\u673a\u5b9a\u4f4d\u7269\u4f53\u5728\u56fe\u50cf\u4e2d\u7684\u4f4d\u7f6e\uff08\u7269\u4f53\u7684\u5927\u5c0f\uff0c\u8fb9\u754c\u7b49\uff09 \u8ba9\u8ba1\u7b97\u673a\u7406\u89e3\u7269\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb\u6216\u884c\u4e3a\uff08\u662f\u5728\u5bf9\u8bdd\uff0c\u6bd4\u8d5b\u6216\u5435\u67b6\u7b49\uff09\uff0c\u4ee5\u53ca\u56fe\u50cf\u8868\u8fbe\u7684\u610f\u4e49\uff08\u559c\u5e86\u7684\uff0c\u60b2\u4f24\u7684\u7b49\uff09 \u90a3\u6211\u4eec\u5728OpenCV\u9636\u6bb5\uff0c\u4e3b\u8981\u5b66\u4e60\u56fe\u50cf\u5904\u7406\uff0c\u800c\u56fe\u50cf\u5904\u7406\u4e3b\u8981\u76ee\u7684\u662f\u5bf9\u56fe\u50cf\u7684\u5904\u7406\uff0c\u6bd4\u5982\u5e73\u6ed1\uff0c\u7f29\u653e\u7b49\uff0c\u60f3\u3001\u4ece\u800c\u4e3a\u5176\u4ed6\u4efb\u52a1\uff08\u6bd4\u5982\u201c\u8ba1\u7b97\u673a\u89c6\u89c9\u201d\uff09\u505a\u597d\u524d\u671f\u5de5\u4f5c\u3002 2.\u5e38\u89c1\u4efb\u52a1 \u00b6 \u6839\u636e\u4e0a\u8ff0\u5bf9\u8ba1\u7b97\u673a\u89c6\u89c9\u76ee\u6807\u4efb\u52a1\u7684\u5206\u89e3\uff0c\u53ef\u5c06\u5176\u5206\u4e3a\u4e09\u5927\u7ecf\u5178\u4efb\u52a1\uff1a\u56fe\u50cf\u5206\u7c7b\u3001\u76ee\u6807\u68c0\u6d4b\u3001\u56fe\u50cf\u5206\u5272 \u56fe\u50cf\u5206\u7c7b\uff08Classification\uff09\uff1a\u5373\u662f\u5c06\u56fe\u50cf\u7ed3\u6784\u5316\u4e3a\u67d0\u4e00\u7c7b\u522b\u7684\u4fe1\u606f\uff0c\u7528\u4e8b\u5148\u786e\u5b9a\u597d\u7684\u7c7b\u522b(category)\u6765\u63cf\u8ff0\u56fe\u7247\u3002 \u76ee\u6807\u68c0\u6d4b\uff08Detection\uff09\uff1a\u5206\u7c7b\u4efb\u52a1\u5173\u5fc3\u6574\u4f53\uff0c\u7ed9\u51fa\u7684\u662f\u6574\u5f20\u56fe\u7247\u7684\u5185\u5bb9\u63cf\u8ff0\uff0c\u800c\u68c0\u6d4b\u5219\u5173\u6ce8\u7279\u5b9a\u7684\u7269\u4f53\u76ee\u6807\uff0c\u8981\u6c42\u540c\u65f6\u83b7\u5f97\u8fd9\u4e00\u76ee\u6807\u7684\u7c7b\u522b\u4fe1\u606f\u548c\u4f4d\u7f6e\u4fe1\u606f\uff08classification + localization\uff09\u3002 \u56fe\u50cf\u5206\u5272\uff08Segmentation\uff09\uff1a\u5206\u5272\u662f\u5bf9\u56fe\u50cf\u7684\u50cf\u7d20\u7ea7\u63cf\u8ff0\uff0c\u5b83\u8d4b\u4e88\u6bcf\u4e2a\u50cf\u7d20\u7c7b\u522b\uff08\u5b9e\u4f8b\uff09\u610f\u4e49\uff0c\u9002\u7528\u4e8e\u7406\u89e3\u8981\u6c42\u8f83\u9ad8\u7684\u573a\u666f\uff0c\u5982\u65e0\u4eba\u9a7e\u9a76\u4e2d\u5bf9\u9053\u8def\u548c\u975e\u9053\u8def\u7684\u5206\u5272\u3002 \u63a5\u4e0b\u6765\u7684\u8bfe\u7a0b\u4e2d\u6211\u4eec\u5c06\u56f4\u7ed5\u8fd9\u4e09\u4e2a\u4efb\u52a1\u5bf9\u8ba1\u7b97\u673a\u89c6\u89c9\u8fdb\u884c\u4ecb\u7ecd\u3002 3.\u5e94\u7528\u573a\u666f \u00b6 \u8ba1\u7b97\u673a\u89c6\u89c9\u6d89\u53ca\u7684\u9886\u57df\u590d\u6742\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5b9e\u9645\u5e94\u7528\u8303\u56f4\u3002\u603b\u4f53\u800c\u8a00\uff0c\u4f9d\u8d56\u4e8e\u4eba\u5de5\u667a\u80fd\u548c\u673a\u5668\u5b66\u4e60\uff0c\u5c24\u5176\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u521b\u65b0\u7684\u597d\u5904\u662f\uff0c\u4ece\u7535\u5b50\u5546\u52a1\u884c\u4e1a\u5230\u66f4\u7ecf\u5178\u7684\u5404\u79cd\u7c7b\u578b\u548c\u89c4\u6a21\u7684\u516c\u53f8\u90fd\u53ef\u4ee5\u5229\u7528\u5176\u5f3a\u5927\u7684\u529f\u80fd\uff0c\u4e0b\u56fe\u5c55\u793a\u4e86\u76f8\u5173\u7684\u5e94\u7528\u573a\u666f\u53ca\u76f8\u5173\u7684\u4f01\u4e1a\uff1a 3.1 \u4eba\u8138\u8bc6\u522b \u00b6 \u4eba\u8138\u8bc6\u522b\u6280\u672f\u76ee\u524d\u5df2\u7ecf\u5e7f\u6cdb\u5e94\u7528\u4e8e\u91d1\u878d\u3001\u53f8\u6cd5\u3001\u519b\u961f\u3001\u516c\u5b89\u3001\u8fb9\u68c0\u3001\u653f\u5e9c\u3001\u822a\u5929\u3001\u7535\u529b\u3001\u5de5\u5382\u3001\u6559\u80b2\u3001\u533b\u7597\u7b49\u884c\u4e1a\u3002\u636e\u4e1a\u5185\u4eba\u58eb\u5206\u6790\uff0c\u6211\u56fd\u7684\u4eba\u8138\u8bc6\u522b\u4ea7\u4e1a\u7684\u9700\u6c42\u65fa\u76db\uff0c\u9700\u6c42\u63a8\u52a8\u5bfc\u81f4\u4f01\u4e1a\u6562\u4e8e\u6295\u5165\u8d44\u91d1\u3002 \u4ee3\u8868\u4f01\u4e1a\uff1aFace++\u65f7\u89c6\u79d1\u6280\u3001\u4f9d\u56fe\u79d1\u6280\u3001\u5546\u6c64\u79d1\u6280\u3001\u6df1\u9192\u79d1\u6280\u3001\u4e91\u4ece\u79d1\u6280\u7b49\u3002 3.2 \u89c6\u9891\u76d1\u63a7 \u00b6 \u4eba\u5de5\u667a\u80fd\u6280\u672f\u53ef\u4ee5\u5bf9\u7ed3\u6784\u5316\u7684\u4eba\u3001\u8f66\u3001\u7269\u7b49\u89c6\u9891\u5185\u5bb9\u4fe1\u606f\u8fdb\u884c\u5feb\u901f\u68c0\u7d22\u3001\u67e5\u8be2\u3002\u8fd9\u9879\u5e94\u7528\u4f7f\u5f97\u8ba9\u516c\u5b89\u7cfb\u7edf\u5728\u7e41\u6742\u7684\u76d1\u63a7\u89c6\u9891\u4e2d\u641c\u5bfb\u5230\u7f6a\u72af\u7684\u6709\u4e86\u53ef\u80fd\u3002\u5728\u5927\u91cf\u4eba\u7fa4\u6d41\u52a8\u7684\u4ea4\u901a\u67a2\u7ebd\uff0c\u8be5\u6280\u672f\u4e5f\u88ab\u5e7f\u6cdb\u7528\u4e8e\u4eba\u7fa4\u5206\u6790\u3001\u9632\u63a7\u9884\u8b66\u7b49\u3002 \u4ee3\u8868\u4f01\u4e1a\uff1aSenseTime \u5546\u6c64\u79d1\u6280\u3001DeepGlint \u683c\u7075\u6df1\u77b3\u3001\u4f9d\u56fe\u79d1\u6280\u3001\u4e91\u5929\u52b1\u98de\u3001\u6df1\u7f51\u89c6\u754c\u7b49\u3002 3.3 \u56fe\u7247\u8bc6\u522b\u5206\u6790 \u00b6 \u4ee3\u8868\u4f01\u4e1a\uff1aFace++\u65f7\u89c6\u79d1\u6280\u3001\u56fe\u666e\u79d1\u6280\u3001\u7801\u9686\u79d1\u6280\u3001\u9152\u5494\u5693\u3001YI+\u964c\u4e0a\u82b1\u79d1\u6280\u7b49\u3002 3.4 \u8f85\u52a9\u9a7e\u9a76 \u00b6 \u968f\u7740\u6c7d\u8f66\u7684\u666e\u53ca\uff0c\u6c7d\u8f66\u5df2\u7ecf\u6210\u4e3a\u4eba\u5de5\u667a\u80fd\u6280\u672f\u975e\u5e38\u5927\u7684\u5e94\u7528\u6295\u653e\u65b9\u5411\uff0c\u4f46\u5c31\u76ee\u524d\u6765\u8bf4\uff0c\u60f3\u8981\u5b8c\u5168\u5b9e\u73b0\u81ea\u52a8\u9a7e\u9a76/\u65e0\u4eba\u9a7e\u9a76\uff0c\u8ddd\u79bb\u6280\u672f\u6210\u719f\u8fd8\u6709\u4e00\u6bb5\u8def\u8981\u8d70\u3002\u4e0d\u8fc7\u5229\u7528\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff0c\u6c7d\u8f66\u7684\u9a7e\u9a76\u8f85\u52a9\u7684\u529f\u80fd\u53ca\u5e94\u7528\u8d8a\u6765\u8d8a\u591a\uff0c\u8fd9\u4e9b\u5e94\u7528\u591a\u534a\u662f\u57fa\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u56fe\u50cf\u5904\u7406\u6280\u672f\u6765\u5b9e\u73b0\u3002 \u4ee3\u8868\u4f01\u4e1a\uff1a\u7eb5\u76ee\u79d1\u6280\u3001TuSimple \u56fe\u68ee\u79d1\u6280\u3001\u9a6d\u52bf\u79d1\u6280\u3001MINIEYE \u4f51\u9a7e\u521b\u65b0\u3001\u4e2d\u5929\u5b89\u9a70\u7b49\u3002 \u9664\u4e86\u4e0a\u8ff0\u8fd9\u4e9b\uff0c\u8ba1\u7b97\u673a\u89c6\u89c9\u5728\u4e09\u7ef4\u89c6\u89c9\uff0c\u4e09\u7ef4\u91cd\u5efa\uff0c\u5de5\u4e1a\u4eff\u771f\uff0c\u5730\u7406\u4fe1\u606f\u7cfb\u7edf\uff0c\u5de5\u4e1a\u89c6\u89c9\uff0c\u533b\u7597\u5f71\u50cf\u8bca\u65ad\uff0c\u6587\u5b57\u8bc6\u522b\uff08OCR\uff09\uff0c\u56fe\u50cf\u53ca\u89c6\u9891\u7f16\u8f91\u7b49\u9886\u57df\u4e5f\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u3002 5.\u53d1\u5c55\u5386\u53f2\uff08\u4e86\u89e3\uff09 \u00b6 1963\u5e74\uff0cLarry Roberts\u53d1\u8868\u4e86CV\u9886\u57df\u7684\u7b2c\u4e00\u7bc7\u4e13\u4e1a\u8bba\u6587\uff0c\u7528\u4ee5\u5bf9\u7b80\u5355\u51e0\u4f55\u4f53\u8fdb\u884c\u8fb9\u7f18\u63d0\u53d6\u548c\u4e09\u7ef4\u91cd\u5efa\u3002 1966\u5e74\uff0c\u9ebb\u7701\u7406\u5de5\u5b66\u9662(MIT)\u53d1\u8d77\u4e86\u4e00\u4e2a\u590f\u5b63\u9879\u76ee\uff0c\u76ee\u6807\u662f\u642d\u5efa\u4e00\u4e2a\u673a\u5668\u89c6\u89c9\u7cfb\u7edf\uff0c\u5b8c\u6210\u6a21\u5f0f\u8bc6\u522b(pattern recognition)\u7b49\u5de5\u4f5c\u3002\u867d\u7136\u672a\u6210\u529f\uff0c\u4f46\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u4f5c\u4e3a\u4e00\u4e2a\u79d1\u5b66\u9886\u57df\u7684\u6b63\u5f0f\u8bde\u751f\u7684\u6807\u5fd7\u3002 1982\u5e74\uff0c\u5b66\u8005David Marr\u53d1\u8868\u7684\u8457\u4f5c\u300aVision\u300b\u4ece\u4e25\u8c28\u53c8\u957f\u8fdc\u7684\u89d2\u5ea6\u7ed9\u51fa\u4e86CV\u7684\u53d1\u5c55\u65b9\u5411\u548c\u4e00\u4e9b\u57fa\u672c\u7b97\u6cd5\uff0c\u5176\u4e2d\u4e0d\u4e4f\u73b0\u5728\u4e3a\u4eba\u719f\u77e5\u7684\u201c\u56fe\u5c42\u201d\u7684\u6982\u5ff5\u3001\u8fb9\u7f18\u63d0\u53d6\u3001\u4e09\u7ef4\u91cd\u5efa\u7b49\uff0c\u6807\u5fd7\u7740\u8ba1\u7b97\u673a\u89c6\u89c9\u6210\u4e3a\u4e86\u4e00\u95e8\u72ec\u7acb\u5b66\u79d1\u3002 1999\u5e74David Lowe\u63d0\u51fa\u4e86\u5c3a\u5ea6\u4e0d\u53d8\u7279\u5f81\u53d8\u6362\uff08SIFT, Scale-invariant feature transform\uff09\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\uff0c\u7528\u4e8e\u5339\u914d\u4e0d\u540c\u62cd\u6444\u65b9\u5411\u3001\u7eb5\u6df1\u3001\u5149\u7ebf\u7b49\u56fe\u7247\u4e2d\u7684\u76f8\u540c\u5143\u7d20\u3002 2009\u5e74\uff0c\u7531Felzenszwalb\u6559\u6388\u5728\u63d0\u51fa\u57fa\u4e8eHOG\u7684deformable parts model\uff0c\u53ef\u53d8\u5f62\u96f6\u4ef6\u6a21\u578b\u5f00\u53d1\uff0c\u5b83\u662f\u6df1\u5ea6\u5b66\u4e60\u4e4b\u524d\u6700\u597d\u7684\u6700\u6210\u529f\u7684objectdetection & recognition\u7b97\u6cd5\u3002 Everingham\u7b49\u4eba\u57282006\u5e74\u81f32012\u5e74\u95f4\u642d\u5efa\u4e86\u4e00\u4e2a\u5927\u578b\u56fe\u7247\u6570\u636e\u5e93\uff0c\u4f9b\u673a\u5668\u8bc6\u522b\u548c\u8bad\u7ec3\uff0c\u79f0\u4e3aPASCAL Visual Object Challenge\uff0c\u8be5\u6570\u636e\u5e93\u4e2d\u670920\u79cd\u7c7b\u522b\u7684\u56fe\u7247\uff0c\u6bcf\u79cd\u56fe\u7247\u6570\u91cf\u5728\u4e00\u5343\u81f3\u4e00\u4e07\u5f20\u4e0d\u7b49\u3002 2009\u5e74\uff0c\u674e\u98de\u98de\u6559\u6388\u7b49\u5728CVPR2009\u4e0a\u53d1\u8868\u4e86\u4e00\u7bc7\u540d\u4e3a\u300aImageNet: A Large-Scale Hierarchical Image Database\u300b\u7684\u8bba\u6587\uff0c\u53d1\u5e03\u4e86ImageNet\u6570\u636e\u96c6\uff0c\u8fd9\u662f\u4e3a\u4e86\u68c0\u6d4b\u8ba1\u7b97\u673a\u89c6\u89c9\u80fd\u5426\u8bc6\u522b\u81ea\u7136\u4e07\u7269\uff0c\u56de\u5f52\u673a\u5668\u5b66\u4e60\uff0c\u514b\u670d\u8fc7\u62df\u5408\u95ee\u9898\u3002 2012 \u5e74\uff0cAlex Krizhevsky\u3001Ilya Sutskever \u548c Geoffrey Hinton \u521b\u9020\u4e86\u4e00\u4e2a\u201c\u5927\u578b\u7684\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u201d\uff0c\u4e5f\u5373\u73b0\u5728\u4f17\u6240\u5468\u77e5\u7684 AlexNet\uff0c\u8d62\u5f97\u4e86\u5f53\u5e74\u7684 ILSVRC\u3002\u8fd9\u662f\u53f2\u4e0a\u7b2c\u4e00\u6b21\u6709\u6a21\u578b\u5728 ImageNet \u6570\u636e\u96c6\u8868\u73b0\u5982\u6b64\u51fa\u8272\u3002\u81ea\u90a3\u65f6\u8d77\uff0cCNN \u624d\u6210\u4e86\u5bb6\u55bb\u6237\u6653\u7684\u540d\u5b57\u3002 2014\u5e74\uff0c\u8499\u7279\u5229\u5c14\u5927\u5b66\u63d0\u51fa\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\uff1a\u62e5\u6709\u4e24\u4e2a\u76f8\u4e92\u7ade\u4e89\u7684\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u4f7f\u673a\u5668\u5b66\u4e60\u5f97\u66f4\u5feb\u3002\u4e00\u4e2a\u7f51\u7edc\u5c1d\u8bd5\u6a21\u4eff\u771f\u5b9e\u6570\u636e\u751f\u6210\u5047\u7684\u6570\u636e\uff0c\u800c\u53e6\u4e00\u4e2a\u7f51\u7edc\u5219\u8bd5\u56fe\u5c06\u5047\u6570\u636e\u533a\u5206\u51fa\u6765\u3002\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\uff0c\u4e24\u4e2a\u7f51\u7edc\u90fd\u4f1a\u5f97\u5230\u8bad\u7ec3\uff0c\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u88ab\u8ba4\u4e3a\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u7684\u91cd\u5927\u7a81\u7834\u3002 2018\u5e74\u672b\uff0c\u82f1\u4f1f\u8fbe\u53d1\u5e03\u7684\u89c6\u9891\u5230\u89c6\u9891\u751f\u6210\uff08Video-to-Video synthesis\uff09\uff0c\u5b83\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u53d1\u751f\u5668\u3001\u9274\u522b\u5668\u7f51\u7edc\u4ee5\u53ca\u65f6\u7a7a\u5bf9\u6297\u7269\u955c\uff0c\u5408\u6210\u9ad8\u5206\u8fa8\u7387\u3001\u7167\u7247\u7ea7\u771f\u5b9e\u3001\u65f6\u95f4\u4e00\u81f4\u7684\u89c6\u9891\uff0c\u5b9e\u73b0\u4e86\u8ba9AI\u66f4\u5177\u7269\u7406\u610f\u8bc6\uff0c\u66f4\u5f3a\u5927\uff0c\u5e76\u80fd\u591f\u63a8\u5e7f\u5230\u65b0\u7684\u548c\u770b\u4e0d\u89c1\u7684\u66f4\u591a\u573a\u666f\u3002 2019\uff0c\u66f4\u5f3a\u5927\u7684GAN\uff0cBigGAN\uff0c\u662f\u62e5\u6709\u4e86\u66f4\u806a\u660e\u7684\u5b66\u4e60\u6280\u5de7\u7684GAN\uff0c\u7531\u5b83\u8bad\u7ec3\u751f\u6210\u7684\u56fe\u50cf\u8fde\u5b83\u81ea\u5df1\u90fd\u5206\u8fa8\u4e0d\u51fa\u771f\u5047\uff0c\u56e0\u4e3a\u9664\u975e\u62ff\u663e\u5fae\u955c\u770b\uff0c\u5426\u5219\u5c06\u65e0\u6cd5\u5224\u65ad\u8be5\u56fe\u50cf\u662f\u5426\u6709\u4efb\u4f55\u95ee\u9898\uff0c\u56e0\u800c\uff0c\u5b83\u66f4\u88ab\u8a89\u4e3a\u53f2\u4e0a\u6700\u5f3a\u7684\u56fe\u50cf\u751f\u6210\u5668. \u603b\u7ed3 \u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5b9a\u4e49 \u8ba9\u8ba1\u7b97\u673a\u7406\u89e3\u56fe\u7247\u6216\u8005\u89c6\u9891\u4e2d\u7684\u5185\u5bb9 \u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u4efb\u52a1 \u56fe\u50cf\u5206\u7c7b\uff0c\u76ee\u6807\u68c0\u6d4b\uff0c\u56fe\u50cf\u5206\u5272 \u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5e94\u7528\u573a\u666f \u4eba\u8138\u8bc6\u522b\uff0c\u89c6\u9891\u76d1\u63a7\uff0c\u56fe\u7247\u8bc6\u522b\u5206\u6790\uff0c\u8f85\u52a9\u9a7e\u9a76","title":"\u8ba1\u7b97\u673a\u89c6\u89c9\uff08CV\uff09"},{"location":"introduction/section2/#_1","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5b9a\u4e49 \u77e5\u9053\u8ba1\u7b97\u673a\u89c6\u89c9\u5e38\u89c1\u4efb\u52a1 \u77e5\u9053\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5e94\u7528\u573a\u666f","title":"\u8ba1\u7b97\u673a\u89c6\u89c9"},{"location":"introduction/section2/#1","text":"\u8ba1\u7b97\u673a\u89c6\u89c9\u662f\u6307\u7528\u6444\u50cf\u673a\u548c\u7535\u8111\u53ca\u5176\u4ed6\u76f8\u5173\u8bbe\u5907\uff0c\u5bf9\u751f\u7269\u89c6\u89c9\u7684\u4e00\u79cd\u6a21\u62df\u3002\u5b83\u7684\u4e3b\u8981\u4efb\u52a1\u8ba9\u8ba1\u7b97\u673a\u7406\u89e3\u56fe\u7247\u6216\u8005\u89c6\u9891\u4e2d\u7684\u5185\u5bb9\uff0c\u5c31\u50cf\u4eba\u7c7b\u548c\u8bb8\u591a\u5176\u4ed6\u751f\u7269\u6bcf\u5929\u6240\u505a\u7684\u90a3\u6837\u3002 \u6211\u4eec\u53ef\u4ee5\u5c06\u5176\u4efb\u52a1\u76ee\u6807\u62c6\u5206\u4e3a\uff1a \u8ba9\u8ba1\u7b97\u673a\u7406\u89e3\u56fe\u7247\u4e2d\u7684\u573a\u666f\uff08\u529e\u516c\u5ba4\uff0c\u5ba2\u5385\uff0c\u5496\u5561\u5385\u7b49\uff09 \u8ba9\u8ba1\u7b97\u673a\u8bc6\u522b\u573a\u666f\u4e2d\u5305\u542b\u7684\u7269\u4f53\uff08\u5ba0\u7269\uff0c\u4ea4\u901a\u5de5\u5177\uff0c\u4eba\u7b49\uff09 \u8ba9\u8ba1\u7b97\u673a\u5b9a\u4f4d\u7269\u4f53\u5728\u56fe\u50cf\u4e2d\u7684\u4f4d\u7f6e\uff08\u7269\u4f53\u7684\u5927\u5c0f\uff0c\u8fb9\u754c\u7b49\uff09 \u8ba9\u8ba1\u7b97\u673a\u7406\u89e3\u7269\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb\u6216\u884c\u4e3a\uff08\u662f\u5728\u5bf9\u8bdd\uff0c\u6bd4\u8d5b\u6216\u5435\u67b6\u7b49\uff09\uff0c\u4ee5\u53ca\u56fe\u50cf\u8868\u8fbe\u7684\u610f\u4e49\uff08\u559c\u5e86\u7684\uff0c\u60b2\u4f24\u7684\u7b49\uff09 \u90a3\u6211\u4eec\u5728OpenCV\u9636\u6bb5\uff0c\u4e3b\u8981\u5b66\u4e60\u56fe\u50cf\u5904\u7406\uff0c\u800c\u56fe\u50cf\u5904\u7406\u4e3b\u8981\u76ee\u7684\u662f\u5bf9\u56fe\u50cf\u7684\u5904\u7406\uff0c\u6bd4\u5982\u5e73\u6ed1\uff0c\u7f29\u653e\u7b49\uff0c\u60f3\u3001\u4ece\u800c\u4e3a\u5176\u4ed6\u4efb\u52a1\uff08\u6bd4\u5982\u201c\u8ba1\u7b97\u673a\u89c6\u89c9\u201d\uff09\u505a\u597d\u524d\u671f\u5de5\u4f5c\u3002","title":"1.\u8ba1\u7b97\u673a\u89c6\u89c9\u5b9a\u4e49"},{"location":"introduction/section2/#2","text":"\u6839\u636e\u4e0a\u8ff0\u5bf9\u8ba1\u7b97\u673a\u89c6\u89c9\u76ee\u6807\u4efb\u52a1\u7684\u5206\u89e3\uff0c\u53ef\u5c06\u5176\u5206\u4e3a\u4e09\u5927\u7ecf\u5178\u4efb\u52a1\uff1a\u56fe\u50cf\u5206\u7c7b\u3001\u76ee\u6807\u68c0\u6d4b\u3001\u56fe\u50cf\u5206\u5272 \u56fe\u50cf\u5206\u7c7b\uff08Classification\uff09\uff1a\u5373\u662f\u5c06\u56fe\u50cf\u7ed3\u6784\u5316\u4e3a\u67d0\u4e00\u7c7b\u522b\u7684\u4fe1\u606f\uff0c\u7528\u4e8b\u5148\u786e\u5b9a\u597d\u7684\u7c7b\u522b(category)\u6765\u63cf\u8ff0\u56fe\u7247\u3002 \u76ee\u6807\u68c0\u6d4b\uff08Detection\uff09\uff1a\u5206\u7c7b\u4efb\u52a1\u5173\u5fc3\u6574\u4f53\uff0c\u7ed9\u51fa\u7684\u662f\u6574\u5f20\u56fe\u7247\u7684\u5185\u5bb9\u63cf\u8ff0\uff0c\u800c\u68c0\u6d4b\u5219\u5173\u6ce8\u7279\u5b9a\u7684\u7269\u4f53\u76ee\u6807\uff0c\u8981\u6c42\u540c\u65f6\u83b7\u5f97\u8fd9\u4e00\u76ee\u6807\u7684\u7c7b\u522b\u4fe1\u606f\u548c\u4f4d\u7f6e\u4fe1\u606f\uff08classification + localization\uff09\u3002 \u56fe\u50cf\u5206\u5272\uff08Segmentation\uff09\uff1a\u5206\u5272\u662f\u5bf9\u56fe\u50cf\u7684\u50cf\u7d20\u7ea7\u63cf\u8ff0\uff0c\u5b83\u8d4b\u4e88\u6bcf\u4e2a\u50cf\u7d20\u7c7b\u522b\uff08\u5b9e\u4f8b\uff09\u610f\u4e49\uff0c\u9002\u7528\u4e8e\u7406\u89e3\u8981\u6c42\u8f83\u9ad8\u7684\u573a\u666f\uff0c\u5982\u65e0\u4eba\u9a7e\u9a76\u4e2d\u5bf9\u9053\u8def\u548c\u975e\u9053\u8def\u7684\u5206\u5272\u3002 \u63a5\u4e0b\u6765\u7684\u8bfe\u7a0b\u4e2d\u6211\u4eec\u5c06\u56f4\u7ed5\u8fd9\u4e09\u4e2a\u4efb\u52a1\u5bf9\u8ba1\u7b97\u673a\u89c6\u89c9\u8fdb\u884c\u4ecb\u7ecd\u3002","title":"2.\u5e38\u89c1\u4efb\u52a1"},{"location":"introduction/section2/#3","text":"\u8ba1\u7b97\u673a\u89c6\u89c9\u6d89\u53ca\u7684\u9886\u57df\u590d\u6742\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5b9e\u9645\u5e94\u7528\u8303\u56f4\u3002\u603b\u4f53\u800c\u8a00\uff0c\u4f9d\u8d56\u4e8e\u4eba\u5de5\u667a\u80fd\u548c\u673a\u5668\u5b66\u4e60\uff0c\u5c24\u5176\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u521b\u65b0\u7684\u597d\u5904\u662f\uff0c\u4ece\u7535\u5b50\u5546\u52a1\u884c\u4e1a\u5230\u66f4\u7ecf\u5178\u7684\u5404\u79cd\u7c7b\u578b\u548c\u89c4\u6a21\u7684\u516c\u53f8\u90fd\u53ef\u4ee5\u5229\u7528\u5176\u5f3a\u5927\u7684\u529f\u80fd\uff0c\u4e0b\u56fe\u5c55\u793a\u4e86\u76f8\u5173\u7684\u5e94\u7528\u573a\u666f\u53ca\u76f8\u5173\u7684\u4f01\u4e1a\uff1a","title":"3.\u5e94\u7528\u573a\u666f"},{"location":"introduction/section2/#31","text":"\u4eba\u8138\u8bc6\u522b\u6280\u672f\u76ee\u524d\u5df2\u7ecf\u5e7f\u6cdb\u5e94\u7528\u4e8e\u91d1\u878d\u3001\u53f8\u6cd5\u3001\u519b\u961f\u3001\u516c\u5b89\u3001\u8fb9\u68c0\u3001\u653f\u5e9c\u3001\u822a\u5929\u3001\u7535\u529b\u3001\u5de5\u5382\u3001\u6559\u80b2\u3001\u533b\u7597\u7b49\u884c\u4e1a\u3002\u636e\u4e1a\u5185\u4eba\u58eb\u5206\u6790\uff0c\u6211\u56fd\u7684\u4eba\u8138\u8bc6\u522b\u4ea7\u4e1a\u7684\u9700\u6c42\u65fa\u76db\uff0c\u9700\u6c42\u63a8\u52a8\u5bfc\u81f4\u4f01\u4e1a\u6562\u4e8e\u6295\u5165\u8d44\u91d1\u3002 \u4ee3\u8868\u4f01\u4e1a\uff1aFace++\u65f7\u89c6\u79d1\u6280\u3001\u4f9d\u56fe\u79d1\u6280\u3001\u5546\u6c64\u79d1\u6280\u3001\u6df1\u9192\u79d1\u6280\u3001\u4e91\u4ece\u79d1\u6280\u7b49\u3002","title":"3.1 \u4eba\u8138\u8bc6\u522b"},{"location":"introduction/section2/#32","text":"\u4eba\u5de5\u667a\u80fd\u6280\u672f\u53ef\u4ee5\u5bf9\u7ed3\u6784\u5316\u7684\u4eba\u3001\u8f66\u3001\u7269\u7b49\u89c6\u9891\u5185\u5bb9\u4fe1\u606f\u8fdb\u884c\u5feb\u901f\u68c0\u7d22\u3001\u67e5\u8be2\u3002\u8fd9\u9879\u5e94\u7528\u4f7f\u5f97\u8ba9\u516c\u5b89\u7cfb\u7edf\u5728\u7e41\u6742\u7684\u76d1\u63a7\u89c6\u9891\u4e2d\u641c\u5bfb\u5230\u7f6a\u72af\u7684\u6709\u4e86\u53ef\u80fd\u3002\u5728\u5927\u91cf\u4eba\u7fa4\u6d41\u52a8\u7684\u4ea4\u901a\u67a2\u7ebd\uff0c\u8be5\u6280\u672f\u4e5f\u88ab\u5e7f\u6cdb\u7528\u4e8e\u4eba\u7fa4\u5206\u6790\u3001\u9632\u63a7\u9884\u8b66\u7b49\u3002 \u4ee3\u8868\u4f01\u4e1a\uff1aSenseTime \u5546\u6c64\u79d1\u6280\u3001DeepGlint \u683c\u7075\u6df1\u77b3\u3001\u4f9d\u56fe\u79d1\u6280\u3001\u4e91\u5929\u52b1\u98de\u3001\u6df1\u7f51\u89c6\u754c\u7b49\u3002","title":"3.2 \u89c6\u9891\u76d1\u63a7"},{"location":"introduction/section2/#33","text":"\u4ee3\u8868\u4f01\u4e1a\uff1aFace++\u65f7\u89c6\u79d1\u6280\u3001\u56fe\u666e\u79d1\u6280\u3001\u7801\u9686\u79d1\u6280\u3001\u9152\u5494\u5693\u3001YI+\u964c\u4e0a\u82b1\u79d1\u6280\u7b49\u3002","title":"3.3 \u56fe\u7247\u8bc6\u522b\u5206\u6790"},{"location":"introduction/section2/#34","text":"\u968f\u7740\u6c7d\u8f66\u7684\u666e\u53ca\uff0c\u6c7d\u8f66\u5df2\u7ecf\u6210\u4e3a\u4eba\u5de5\u667a\u80fd\u6280\u672f\u975e\u5e38\u5927\u7684\u5e94\u7528\u6295\u653e\u65b9\u5411\uff0c\u4f46\u5c31\u76ee\u524d\u6765\u8bf4\uff0c\u60f3\u8981\u5b8c\u5168\u5b9e\u73b0\u81ea\u52a8\u9a7e\u9a76/\u65e0\u4eba\u9a7e\u9a76\uff0c\u8ddd\u79bb\u6280\u672f\u6210\u719f\u8fd8\u6709\u4e00\u6bb5\u8def\u8981\u8d70\u3002\u4e0d\u8fc7\u5229\u7528\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff0c\u6c7d\u8f66\u7684\u9a7e\u9a76\u8f85\u52a9\u7684\u529f\u80fd\u53ca\u5e94\u7528\u8d8a\u6765\u8d8a\u591a\uff0c\u8fd9\u4e9b\u5e94\u7528\u591a\u534a\u662f\u57fa\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u56fe\u50cf\u5904\u7406\u6280\u672f\u6765\u5b9e\u73b0\u3002 \u4ee3\u8868\u4f01\u4e1a\uff1a\u7eb5\u76ee\u79d1\u6280\u3001TuSimple \u56fe\u68ee\u79d1\u6280\u3001\u9a6d\u52bf\u79d1\u6280\u3001MINIEYE \u4f51\u9a7e\u521b\u65b0\u3001\u4e2d\u5929\u5b89\u9a70\u7b49\u3002 \u9664\u4e86\u4e0a\u8ff0\u8fd9\u4e9b\uff0c\u8ba1\u7b97\u673a\u89c6\u89c9\u5728\u4e09\u7ef4\u89c6\u89c9\uff0c\u4e09\u7ef4\u91cd\u5efa\uff0c\u5de5\u4e1a\u4eff\u771f\uff0c\u5730\u7406\u4fe1\u606f\u7cfb\u7edf\uff0c\u5de5\u4e1a\u89c6\u89c9\uff0c\u533b\u7597\u5f71\u50cf\u8bca\u65ad\uff0c\u6587\u5b57\u8bc6\u522b\uff08OCR\uff09\uff0c\u56fe\u50cf\u53ca\u89c6\u9891\u7f16\u8f91\u7b49\u9886\u57df\u4e5f\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u3002","title":"3.4 \u8f85\u52a9\u9a7e\u9a76"},{"location":"introduction/section2/#5","text":"1963\u5e74\uff0cLarry Roberts\u53d1\u8868\u4e86CV\u9886\u57df\u7684\u7b2c\u4e00\u7bc7\u4e13\u4e1a\u8bba\u6587\uff0c\u7528\u4ee5\u5bf9\u7b80\u5355\u51e0\u4f55\u4f53\u8fdb\u884c\u8fb9\u7f18\u63d0\u53d6\u548c\u4e09\u7ef4\u91cd\u5efa\u3002 1966\u5e74\uff0c\u9ebb\u7701\u7406\u5de5\u5b66\u9662(MIT)\u53d1\u8d77\u4e86\u4e00\u4e2a\u590f\u5b63\u9879\u76ee\uff0c\u76ee\u6807\u662f\u642d\u5efa\u4e00\u4e2a\u673a\u5668\u89c6\u89c9\u7cfb\u7edf\uff0c\u5b8c\u6210\u6a21\u5f0f\u8bc6\u522b(pattern recognition)\u7b49\u5de5\u4f5c\u3002\u867d\u7136\u672a\u6210\u529f\uff0c\u4f46\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u4f5c\u4e3a\u4e00\u4e2a\u79d1\u5b66\u9886\u57df\u7684\u6b63\u5f0f\u8bde\u751f\u7684\u6807\u5fd7\u3002 1982\u5e74\uff0c\u5b66\u8005David Marr\u53d1\u8868\u7684\u8457\u4f5c\u300aVision\u300b\u4ece\u4e25\u8c28\u53c8\u957f\u8fdc\u7684\u89d2\u5ea6\u7ed9\u51fa\u4e86CV\u7684\u53d1\u5c55\u65b9\u5411\u548c\u4e00\u4e9b\u57fa\u672c\u7b97\u6cd5\uff0c\u5176\u4e2d\u4e0d\u4e4f\u73b0\u5728\u4e3a\u4eba\u719f\u77e5\u7684\u201c\u56fe\u5c42\u201d\u7684\u6982\u5ff5\u3001\u8fb9\u7f18\u63d0\u53d6\u3001\u4e09\u7ef4\u91cd\u5efa\u7b49\uff0c\u6807\u5fd7\u7740\u8ba1\u7b97\u673a\u89c6\u89c9\u6210\u4e3a\u4e86\u4e00\u95e8\u72ec\u7acb\u5b66\u79d1\u3002 1999\u5e74David Lowe\u63d0\u51fa\u4e86\u5c3a\u5ea6\u4e0d\u53d8\u7279\u5f81\u53d8\u6362\uff08SIFT, Scale-invariant feature transform\uff09\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\uff0c\u7528\u4e8e\u5339\u914d\u4e0d\u540c\u62cd\u6444\u65b9\u5411\u3001\u7eb5\u6df1\u3001\u5149\u7ebf\u7b49\u56fe\u7247\u4e2d\u7684\u76f8\u540c\u5143\u7d20\u3002 2009\u5e74\uff0c\u7531Felzenszwalb\u6559\u6388\u5728\u63d0\u51fa\u57fa\u4e8eHOG\u7684deformable parts model\uff0c\u53ef\u53d8\u5f62\u96f6\u4ef6\u6a21\u578b\u5f00\u53d1\uff0c\u5b83\u662f\u6df1\u5ea6\u5b66\u4e60\u4e4b\u524d\u6700\u597d\u7684\u6700\u6210\u529f\u7684objectdetection & recognition\u7b97\u6cd5\u3002 Everingham\u7b49\u4eba\u57282006\u5e74\u81f32012\u5e74\u95f4\u642d\u5efa\u4e86\u4e00\u4e2a\u5927\u578b\u56fe\u7247\u6570\u636e\u5e93\uff0c\u4f9b\u673a\u5668\u8bc6\u522b\u548c\u8bad\u7ec3\uff0c\u79f0\u4e3aPASCAL Visual Object Challenge\uff0c\u8be5\u6570\u636e\u5e93\u4e2d\u670920\u79cd\u7c7b\u522b\u7684\u56fe\u7247\uff0c\u6bcf\u79cd\u56fe\u7247\u6570\u91cf\u5728\u4e00\u5343\u81f3\u4e00\u4e07\u5f20\u4e0d\u7b49\u3002 2009\u5e74\uff0c\u674e\u98de\u98de\u6559\u6388\u7b49\u5728CVPR2009\u4e0a\u53d1\u8868\u4e86\u4e00\u7bc7\u540d\u4e3a\u300aImageNet: A Large-Scale Hierarchical Image Database\u300b\u7684\u8bba\u6587\uff0c\u53d1\u5e03\u4e86ImageNet\u6570\u636e\u96c6\uff0c\u8fd9\u662f\u4e3a\u4e86\u68c0\u6d4b\u8ba1\u7b97\u673a\u89c6\u89c9\u80fd\u5426\u8bc6\u522b\u81ea\u7136\u4e07\u7269\uff0c\u56de\u5f52\u673a\u5668\u5b66\u4e60\uff0c\u514b\u670d\u8fc7\u62df\u5408\u95ee\u9898\u3002 2012 \u5e74\uff0cAlex Krizhevsky\u3001Ilya Sutskever \u548c Geoffrey Hinton \u521b\u9020\u4e86\u4e00\u4e2a\u201c\u5927\u578b\u7684\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u201d\uff0c\u4e5f\u5373\u73b0\u5728\u4f17\u6240\u5468\u77e5\u7684 AlexNet\uff0c\u8d62\u5f97\u4e86\u5f53\u5e74\u7684 ILSVRC\u3002\u8fd9\u662f\u53f2\u4e0a\u7b2c\u4e00\u6b21\u6709\u6a21\u578b\u5728 ImageNet \u6570\u636e\u96c6\u8868\u73b0\u5982\u6b64\u51fa\u8272\u3002\u81ea\u90a3\u65f6\u8d77\uff0cCNN \u624d\u6210\u4e86\u5bb6\u55bb\u6237\u6653\u7684\u540d\u5b57\u3002 2014\u5e74\uff0c\u8499\u7279\u5229\u5c14\u5927\u5b66\u63d0\u51fa\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\uff1a\u62e5\u6709\u4e24\u4e2a\u76f8\u4e92\u7ade\u4e89\u7684\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u4f7f\u673a\u5668\u5b66\u4e60\u5f97\u66f4\u5feb\u3002\u4e00\u4e2a\u7f51\u7edc\u5c1d\u8bd5\u6a21\u4eff\u771f\u5b9e\u6570\u636e\u751f\u6210\u5047\u7684\u6570\u636e\uff0c\u800c\u53e6\u4e00\u4e2a\u7f51\u7edc\u5219\u8bd5\u56fe\u5c06\u5047\u6570\u636e\u533a\u5206\u51fa\u6765\u3002\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\uff0c\u4e24\u4e2a\u7f51\u7edc\u90fd\u4f1a\u5f97\u5230\u8bad\u7ec3\uff0c\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u88ab\u8ba4\u4e3a\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u7684\u91cd\u5927\u7a81\u7834\u3002 2018\u5e74\u672b\uff0c\u82f1\u4f1f\u8fbe\u53d1\u5e03\u7684\u89c6\u9891\u5230\u89c6\u9891\u751f\u6210\uff08Video-to-Video synthesis\uff09\uff0c\u5b83\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u53d1\u751f\u5668\u3001\u9274\u522b\u5668\u7f51\u7edc\u4ee5\u53ca\u65f6\u7a7a\u5bf9\u6297\u7269\u955c\uff0c\u5408\u6210\u9ad8\u5206\u8fa8\u7387\u3001\u7167\u7247\u7ea7\u771f\u5b9e\u3001\u65f6\u95f4\u4e00\u81f4\u7684\u89c6\u9891\uff0c\u5b9e\u73b0\u4e86\u8ba9AI\u66f4\u5177\u7269\u7406\u610f\u8bc6\uff0c\u66f4\u5f3a\u5927\uff0c\u5e76\u80fd\u591f\u63a8\u5e7f\u5230\u65b0\u7684\u548c\u770b\u4e0d\u89c1\u7684\u66f4\u591a\u573a\u666f\u3002 2019\uff0c\u66f4\u5f3a\u5927\u7684GAN\uff0cBigGAN\uff0c\u662f\u62e5\u6709\u4e86\u66f4\u806a\u660e\u7684\u5b66\u4e60\u6280\u5de7\u7684GAN\uff0c\u7531\u5b83\u8bad\u7ec3\u751f\u6210\u7684\u56fe\u50cf\u8fde\u5b83\u81ea\u5df1\u90fd\u5206\u8fa8\u4e0d\u51fa\u771f\u5047\uff0c\u56e0\u4e3a\u9664\u975e\u62ff\u663e\u5fae\u955c\u770b\uff0c\u5426\u5219\u5c06\u65e0\u6cd5\u5224\u65ad\u8be5\u56fe\u50cf\u662f\u5426\u6709\u4efb\u4f55\u95ee\u9898\uff0c\u56e0\u800c\uff0c\u5b83\u66f4\u88ab\u8a89\u4e3a\u53f2\u4e0a\u6700\u5f3a\u7684\u56fe\u50cf\u751f\u6210\u5668. \u603b\u7ed3 \u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5b9a\u4e49 \u8ba9\u8ba1\u7b97\u673a\u7406\u89e3\u56fe\u7247\u6216\u8005\u89c6\u9891\u4e2d\u7684\u5185\u5bb9 \u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u4efb\u52a1 \u56fe\u50cf\u5206\u7c7b\uff0c\u76ee\u6807\u68c0\u6d4b\uff0c\u56fe\u50cf\u5206\u5272 \u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5e94\u7528\u573a\u666f \u4eba\u8138\u8bc6\u522b\uff0c\u89c6\u9891\u76d1\u63a7\uff0c\u56fe\u7247\u8bc6\u522b\u5206\u6790\uff0c\u8f85\u52a9\u9a7e\u9a76","title":"5.\u53d1\u5c55\u5386\u53f2\uff08\u4e86\u89e3\uff09"},{"location":"objectdection/","text":"\u76ee\u6807\u68c0\u6d4b(Object Detection) \u00b6","title":"\u76ee\u6807\u68c0\u6d4b(Object Detection)"},{"location":"objectdection/#object-detection","text":"","title":"\u76ee\u6807\u68c0\u6d4b(Object Detection)"},{"location":"objectdection/01.overview/","text":"4.1 \u76ee\u6807\u68c0\u6d4b\u6982\u8ff0 \u00b6 \u5b66\u4e60\u76ee\u6807 \u4e86\u89e3\u76ee\u6807\u68c0\u6d4b\u7684\u4efb\u52a1 \u77e5\u9053\u76ee\u6807\u68c0\u6d4b\u7684\u5e38\u7528\u6570\u636e\u96c6 \u77e5\u9053\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u7684\u8bc4\u4ef7\u6307\u6807 \u638c\u63e1\u975e\u6781\u5927\u503cNMS\u7b97\u6cd5\u7684\u5e94\u7528 \u4e86\u89e3\u5e38\u7528\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5206\u7c7b 1. \u76ee\u6807\u68c0\u6d4b \u00b6 \u76ee\u6807\u68c0\u6d4b\uff08Object Detection\uff09\u7684\u4efb\u52a1\u662f\u627e\u51fa\u56fe\u50cf\u4e2d\u6240\u6709\u611f\u5174\u8da3\u7684\u76ee\u6807\uff0c\u5e76\u786e\u5b9a\u5b83\u4eec\u7684\u7c7b\u522b\u548c\u4f4d\u7f6e\u3002 \u76ee\u6807\u68c0\u6d4b\u4e2d\u80fd\u68c0\u6d4b\u51fa\u6765\u7684\u7269\u4f53\u53d6\u51b3\u4e8e\u5f53\u524d\u4efb\u52a1\uff08\u6570\u636e\u96c6\uff09\u9700\u8981\u68c0\u6d4b\u7684\u7269\u4f53\u6709\u54ea\u4e9b\u3002\u5047\u8bbe\u6211\u4eec\u7684\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u5b9a\u4f4d\u662f\u68c0\u6d4b\u52a8\u7269\uff08\u725b\u3001\u7f8a\u3001\u732a\u3001\u72d7\u3001\u732b\u4e94\u79cd\u7ed3\u679c\uff09\uff0c\u90a3\u4e48\u6a21\u578b\u5bf9\u4efb\u4f55\u4e00\u5f20\u56fe\u7247\u8f93\u51fa\u7ed3\u679c\u4e0d\u4f1a\u8f93\u51fa\u9e2d\u5b50\u3001\u4e66\u7c4d\u7b49\u5176\u5b83\u7c7b\u578b\u7ed3\u679c\u3002 \u76ee\u6807\u68c0\u6d4b\u7684\u4f4d\u7f6e\u4fe1\u606f\u4e00\u822c\u7531\u4e24\u79cd\u683c\u5f0f\uff08\u4ee5\u56fe\u7247\u5de6\u4e0a\u89d2\u4e3a\u539f\u70b9(0,0)\uff09\uff1a 1\u3001\u6781\u5750\u6807\u8868\u793a\uff1a(xmin, ymin, xmax, ymax) xmin,ymin:x,y\u5750\u6807\u7684\u6700\u5c0f\u503c xmin,ymin:x,y\u5750\u6807\u7684\u6700\u5927\u503c 2\u3001\u4e2d\u5fc3\u70b9\u5750\u6807\uff1a(x_center, y_center, w, h) x_center, y_center:\u76ee\u6807\u68c0\u6d4b\u6846\u7684\u4e2d\u5fc3\u70b9\u5750\u6807 w,h:\u76ee\u6807\u68c0\u6d4b\u6846\u7684\u5bbd\u3001\u9ad8 \u5047\u8bbe\u5728\u4e0b\u9762\u7684\u56fe\u50cf\u4e2d\u8fdb\u884c\u68c0\u6d4b\uff0c\uff1a \u90a3\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c\u7684\u4e2d\u5fc3\u70b9\u8868\u793a\u5f62\u5f0f\u5982\u4e0b\u6240\u793a\uff1a 2.\u5e38\u7528\u7684\u5f00\u6e90\u6570\u636e\u96c6 \u00b6 \u7ecf\u5178\u7684\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u6709\u4e24\u79cd\uff0c PASCAL VOC\u6570\u636e\u96c6 \u548c MS COCO\u6570\u636e\u96c6 \u3002 2.1 PASCAL VOC\u6570\u636e\u96c6 \u00b6 PASCAL VOC\u662f\u76ee\u6807\u68c0\u6d4b\u9886\u57df\u7684\u7ecf\u5178\u6570\u636e\u96c6\u3002PASCAL VOC\u5305\u542b\u7ea610,000\u5f20\u5e26\u6709\u8fb9\u754c\u6846\u7684\u56fe\u7247\u7528\u4e8e\u8bad\u7ec3\u548c\u9a8c\u8bc1\u3002PASCAL VOC\u6570\u636e\u96c6\u662f\u76ee\u6807\u68c0\u6d4b\u95ee\u9898\u7684\u4e00\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5f88\u591a\u6a21\u578b\u90fd\u662f\u5728\u6b64\u6570\u636e\u96c6\u4e0a\u5f97\u5230\u7684\uff0c\u5e38\u7528\u7684\u662fVOC2007\u548cVOC2012\u4e24\u4e2a\u7248\u672c\u6570\u636e\uff0c\u517120\u4e2a\u7c7b\u522b\uff0c\u5206\u522b\u662f\uff1a \u4e5f\u5c31\u662f\uff1a 1.\u4eba: \u4eba 2.\u52a8\u7269: \u9e1f\uff0c\u732b\uff0c\u725b\uff0c\u72d7\uff0c\u9a6c\uff0c\u7f8a 3.\u4ea4\u901a\u5de5\u5177: \u98de\u673a\uff0c\u81ea\u884c\u8f66\uff0c\u8239\uff0c\u516c\u5171\u6c7d\u8f66\uff0c\u6c7d\u8f66\uff0c\u6469\u6258\u8f66\uff0c\u706b\u8f66 4.\u5ba4\u5185: \u74f6\u5b50\uff0c\u6905\u5b50\uff0c\u9910\u684c\uff0c\u76c6\u683d\uff0c\u6c99\u53d1\uff0c\u7535\u89c6/\u663e\u793a\u5668 \u4e0b\u8f7d\u5730\u5740 \uff1a https://pjreddie.com/projects/pascal-voc-dataset-mirror/ \u6574\u4e2a\u6570\u636e\u7684\u76ee\u5f55\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a \u5176\u4e2d\uff1a JPEGImages\u5b58\u653e\u56fe\u7247\u6587\u4ef6 Annotations\u4e0b\u5b58\u653e\u7684\u662fxml\u6587\u4ef6,\u63cf\u8ff0\u4e86\u56fe\u7247\u4fe1\u606f\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u9700\u8981\u5173\u6ce8\u7684\u5c31\u662f\u8282\u70b9\u4e0b\u7684\u6570\u636e,\u5c24\u5176\u662fbndbox\u4e0b\u7684\u6570\u636e.xmin,ymin\u6784\u6210\u4e86boundingbox\u7684\u5de6\u4e0a\u89d2,xmax,ymax\u6784\u6210\u4e86boundingbox\u7684\u53f3\u4e0b\u89d2\uff0c\u4e5f\u5c31\u662f\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u4f4d\u7f6e\u4fe1\u606f ImageSets\u5305\u542b\u4ee5\u4e0b4\u4e2a\u6587\u4ef6\u5939\uff1a Action\u4e0b\u5b58\u653e\u7684\u662f\u4eba\u7684\u52a8\u4f5c\uff08\u4f8b\u5982running\u3001jumping\u7b49\u7b49\uff09 Layout\u4e0b\u5b58\u653e\u7684\u662f\u5177\u6709\u4eba\u4f53\u90e8\u4f4d\u7684\u6570\u636e\uff08\u4eba\u7684head\u3001hand\u3001feet\u7b49\u7b49\uff09 Segmentation\u4e0b\u5b58\u653e\u7684\u662f\u53ef\u7528\u4e8e\u5206\u5272\u7684\u6570\u636e\u3002 Main\u4e0b\u5b58\u653e\u7684\u662f\u56fe\u50cf\u7269\u4f53\u8bc6\u522b\u7684\u6570\u636e\uff0c\u603b\u5171\u5206\u4e3a20\u7c7b\uff0c\u8fd9\u662f\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u7684\u91cd\u70b9\u3002\u8be5\u6587\u4ef6\u5939\u4e2d\u7684\u6570\u636e\u5bf9\u8d1f\u6837\u672c\u6587\u4ef6\u8fdb\u884c\u4e86\u63cf\u8ff0\u3002 2.2 MS COCO\u6570\u636e\u96c6 \u00b6 MS COCO\u7684\u5168\u79f0\u662fMicrosoft Common Objects in Context\uff0c\u5fae\u8f6f\u4e8e2014\u5e74\u51fa\u8d44\u6807\u6ce8\u7684Microsoft COCO\u6570\u636e\u96c6\uff0c\u4e0eImageNet\u7ade\u8d5b\u4e00\u6837\uff0c\u88ab\u89c6\u4e3a\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u6700\u53d7\u5173\u6ce8\u548c\u6700\u6743\u5a01\u7684\u6bd4\u8d5b\u4e4b\u4e00\u3002 COCO\u6570\u636e\u96c6\u662f\u4e00\u4e2a\u5927\u578b\u7684\u3001\u4e30\u5bcc\u7684\u7269\u4f53\u68c0\u6d4b\uff0c\u5206\u5272\u548c\u5b57\u5e55\u6570\u636e\u96c6\u3002\u8fd9\u4e2a\u6570\u636e\u96c6\u4ee5\u573a\u666f\u7406\u89e3\u4e3a\u76ee\u6807\uff0c\u4e3b\u8981\u4ece\u590d\u6742\u7684\u65e5\u5e38\u573a\u666f\u4e2d\u622a\u53d6\uff0c\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u901a\u8fc7\u7cbe\u786e\u7684\u5206\u5272\u8fdb\u884c\u4f4d\u7f6e\u7684\u6807\u5b9a\u3002\u56fe\u50cf\u5305\u62ec91\u7c7b\u76ee\u6807\uff0c328,000\u5f71\u50cf\u548c2,500,000\u4e2alabel\u3002\u76ee\u524d\u4e3a\u6b62\u76ee\u6807\u68c0\u6d4b\u7684\u6700\u5927\u6570\u636e\u96c6\uff0c\u63d0\u4f9b\u7684\u7c7b\u522b\u670980 \u7c7b\uff0c\u6709\u8d85\u8fc733 \u4e07\u5f20\u56fe\u7247\uff0c\u5176\u4e2d20 \u4e07\u5f20\u6709\u6807\u6ce8\uff0c\u6574\u4e2a\u6570\u636e\u96c6\u4e2d\u4e2a\u4f53\u7684\u6570\u76ee\u8d85\u8fc7150 \u4e07\u4e2a\u3002 \u56fe\u50cf\u793a\u4f8b\uff1a coco\u6570\u636e\u96c6\u7684\u6807\u7b7e\u6587\u4ef6\u6807\u8bb0\u4e86\u6bcf\u4e2asegmentation+bounding box\u7684\u7cbe\u786e\u5750\u6807\uff0c\u5176\u7cbe\u5ea6\u5747\u4e3a\u5c0f\u6570\u70b9\u540e\u4e24\u4f4d\u4e00\u4e2a\u76ee\u6807\u7684\u6807\u7b7e\u793a\u610f\u5982\u4e0b\uff1a {\"segmentation\":[[392.87, 275.77, 402.24, 284.2, 382.54, 342.36, 375.99, 356.43, 372.23, 357.37, 372.23, 397.7, 383.48, 419.27,407.87, 439.91, 427.57, 389.25, 447.26, 346.11, 447.26, 328.29, 468.84, 290.77,472.59, 266.38], [429.44,465.23, 453.83, 473.67, 636.73, 474.61, 636.73, 392.07, 571.07, 364.88, 546.69,363.0]], \"area\": 28458.996150000003, \"iscrowd\": 0,\"image_id\": 503837, \"bbox\": [372.23, 266.38, 264.5,208.23] , \"category_id\": 4, \"id\": 151109}, 3.\u5e38\u7528\u7684\u8bc4\u4ef7\u6307\u6807 \u00b6 3.1 IOU \u00b6 \u5728\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\uff0cIoU\uff08intersection over union\uff0c\u4ea4\u5e76\u6bd4\uff09\u662f\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\u7528\u6765\u8bc4\u4ef72\u4e2a\u77e9\u5f62\u6846\u4e4b\u95f4\u76f8\u4f3c\u5ea6\u7684\u6307\u6807\uff1a IoU = \u4e24\u4e2a\u77e9\u5f62\u6846\u76f8\u4ea4\u7684\u9762\u79ef / \u4e24\u4e2a\u77e9\u5f62\u6846\u76f8\u5e76\u7684\u9762\u79ef \uff0c \u5982\u4e0b\u56fe\u6240\u793a\uff1a \u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u770b\u4e0b\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u7684\u5e94\u7528\uff1a \u5176\u4e2d\u4e0a\u56fe\u84dd\u8272\u6846\u6846\u4e3a\u68c0\u6d4b\u7ed3\u679c\uff0c\u7ea2\u8272\u6846\u6846\u4e3a\u771f\u5b9e\u6807\u6ce8\u3002 \u90a3\u6211\u4eec\u5c31\u53ef\u4ee5\u901a\u8fc7\u9884\u6d4b\u7ed3\u679c\u4e0e\u771f\u5b9e\u7ed3\u679c\u4e4b\u95f4\u7684\u4ea4\u5e76\u6bd4\u6765\u8861\u91cf\u4e24\u8005\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u3002\u4e00\u822c\u60c5\u51b5\u4e0b\u5bf9\u4e8e\u68c0\u6d4b\u6846\u7684\u5224\u5b9a\u90fd\u4f1a\u5b58\u5728\u4e00\u4e2a\u9608\u503c\uff0c\u4e5f\u5c31\u662f IoU \u7684\u9608\u503c\uff0c\u4e00\u822c\u53ef\u4ee5\u8bbe\u7f6e\u5f53 IoU \u7684\u503c\u5927\u4e8e 0.5 \u7684\u65f6\u5019\uff0c\u5219\u53ef\u8ba4\u4e3a\u68c0\u6d4b\u5230\u76ee\u6807\u7269\u4f53\u3002 \u5b9e\u73b0\u65b9\u6cd5\uff1a import numpy as np # \u5b9a\u4e49\u65b9\u6cd5\u8ba1\u7b97IOU def Iou ( box1 , box2 , wh = False ): # \u5224\u65adbbox\u7684\u8868\u793a\u5f62\u5f0f if wh == False : # \u4f7f\u7528\u6781\u5750\u6807\u5f62\u5f0f\u8868\u793a\uff1a\u76f4\u63a5\u83b7\u53d6\u4e24\u4e2abbox\u7684\u5750\u6807 xmin1 , ymin1 , xmax1 , ymax1 = box1 xmin2 , ymin2 , xmax2 , ymax2 = box2 else : # \u4f7f\u7528\u4e2d\u5fc3\u70b9\u5f62\u5f0f\u8868\u793a\uff1a \u83b7\u53d6\u4e24\u4e2a\u4e24\u4e2abbox\u7684\u6781\u5750\u6807\u8868\u793a\u5f62\u5f0f # \u7b2c\u4e00\u4e2a\u6846\u5de6\u4e0a\u89d2\u5750\u6807 xmin1 , ymin1 = int ( box1 [ 0 ] - box1 [ 2 ] / 2.0 ), int ( box1 [ 1 ] - box1 [ 3 ] / 2.0 ) # \u7b2c\u4e00\u4e2a\u6846\u53f3\u4e0b\u89d2\u5750\u6807 xmax1 , ymax1 = int ( box1 [ 0 ] + box1 [ 2 ] / 2.0 ), int ( box1 [ 1 ] + box1 [ 3 ] / 2.0 ) # \u7b2c\u4e8c\u4e2a\u6846\u5de6\u4e0a\u89d2\u5750\u6807 xmin2 , ymin2 = int ( box2 [ 0 ] - box2 [ 2 ] / 2.0 ), int ( box2 [ 1 ] - box2 [ 3 ] / 2.0 ) # \u7b2c\u4e8c\u4e2a\u6846\u53f3\u4e0b\u89d2\u5750\u6807 xmax2 , ymax2 = int ( box2 [ 0 ] + box2 [ 2 ] / 2.0 ), int ( box2 [ 1 ] + box2 [ 3 ] / 2.0 ) # \u83b7\u53d6\u77e9\u5f62\u6846\u4ea4\u96c6\u5bf9\u5e94\u7684\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\u7684\u5750\u6807\uff08intersection\uff09 xx1 = np . max ([ xmin1 , xmin2 ]) yy1 = np . max ([ ymin1 , ymin2 ]) xx2 = np . min ([ xmax1 , xmax2 ]) yy2 = np . min ([ ymax1 , ymax2 ]) # \u8ba1\u7b97\u4e24\u4e2a\u77e9\u5f62\u6846\u9762\u79ef area1 = ( xmax1 - xmin1 ) * ( ymax1 - ymin1 ) area2 = ( xmax2 - xmin2 ) * ( ymax2 - ymin2 ) #\u8ba1\u7b97\u4ea4\u96c6\u9762\u79ef inter_area = ( np . max ([ 0 , xx2 - xx1 ])) * ( np . max ([ 0 , yy2 - yy1 ])) #\u8ba1\u7b97\u4ea4\u5e76\u6bd4 iou = inter_area / ( area1 + area2 - inter_area + 1e-6 ) return iou \u5047\u8bbe\u6211\u4eec\u68c0\u6d4b\u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff0c\u5e76\u5c55\u793a\u5728\u56fe\u50cf\u4e0a\uff1a import matplotlib.pyplot as plt import matplotlib.patches as patches # \u771f\u5b9e\u6846\u4e0e\u9884\u6d4b\u6846 True_bbox , predict_bbox = [ 100 , 35 , 398 , 400 ], [ 40 , 150 , 355 , 398 ] # bbox\u662fbounding box\u7684\u7f29\u5199 img = plt . imread ( 'dog.jpeg' ) fig = plt . imshow ( img ) # \u5c06\u8fb9\u754c\u6846(\u5de6\u4e0ax, \u5de6\u4e0ay, \u53f3\u4e0bx, \u53f3\u4e0by)\u683c\u5f0f\u8f6c\u6362\u6210matplotlib\u683c\u5f0f\uff1a((\u5de6\u4e0ax, \u5de6\u4e0ay), \u5bbd, \u9ad8) # \u771f\u5b9e\u6846\u7ed8\u5236 fig . axes . add_patch ( plt . Rectangle ( xy = ( True_bbox [ 0 ], True_bbox [ 1 ]), width = True_bbox [ 2 ] - True_bbox [ 0 ], height = True_bbox [ 3 ] - True_bbox [ 1 ], fill = False , edgecolor = \"blue\" , linewidth = 2 )) # \u9884\u6d4b\u6846\u7ed8\u5236 fig . axes . add_patch ( plt . Rectangle ( xy = ( predict_bbox [ 0 ], predict_bbox [ 1 ]), width = predict_bbox [ 2 ] - predict_bbox [ 0 ], height = predict_bbox [ 3 ] - predict_bbox [ 1 ], fill = False , edgecolor = \"red\" , linewidth = 2 )) \u8ba1\u7b97IoU\uff1a Iou ( True_bbox , predict_bbox ) \u7ed3\u679c\u4e3a\uff1a 0.5114435907762924 3.2 mAP\uff08 Mean Average Precision \uff09 \u00b6 \u76ee\u6807\u68c0\u6d4b\u95ee\u9898\u4e2d\u7684\u6bcf\u4e2a\u56fe\u7247\u90fd\u53ef\u80fd\u5305\u542b\u4e00\u4e9b\u4e0d\u540c\u7c7b\u522b\u7684\u7269\u4f53\uff0c\u9700\u8981\u8bc4\u4f30\u6a21\u578b\u7684\u7269\u4f53\u5206\u7c7b\u548c\u5b9a\u4f4d\u6027\u80fd\u3002\u56e0\u6b64\uff0c\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\u7684\u6807\u51c6\u6307\u6807precision\u4e0d\u80fd\u76f4\u63a5\u5e94\u7528\u4e8e\u6b64\u3002 \u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0cmAP\u662f\u4e3b\u8981\u7684\u8861\u91cf\u6307\u6807\u3002 mAP\u662f\u591a\u4e2a\u5206\u7c7b\u4efb\u52a1\u7684AP\u7684\u5e73\u5747\u503c\uff0c\u800cAP\uff08average precision\uff09\u662fPR\u66f2\u7ebf\u4e0b\u7684\u9762\u79ef\uff0c\u6240\u4ee5\u5728\u4ecb\u7ecdmAP\u4e4b\u524d\u6211\u4eec\u8981\u5148\u5f97\u5230PR\u66f2\u7ebf\u3002 TP\u3001FP\u3001FN\u3001TN True Positive (TP): IoU> ( \u4e00\u822c\u53d6 0.5 ) \u7684\u68c0\u6d4b\u6846\u6570\u91cf\uff08\u540c\u4e00 Ground Truth \u53ea\u8ba1\u7b97\u4e00\u6b21\uff09 False Positive (FP): IoU<= \u7684\u68c0\u6d4b\u6846\u6570\u91cf\uff0c\u6216\u8005\u662f\u68c0\u6d4b\u5230\u540c\u4e00\u4e2a GT \u7684\u591a\u4f59\u68c0\u6d4b\u6846\u7684\u6570\u91cf False Negative (FN): \u6ca1\u6709\u68c0\u6d4b\u5230\u7684 GT \u7684\u6570\u91cf True Negative (TN): \u5728 mAP \u8bc4\u4ef7\u6307\u6807\u4e2d\u4e0d\u4f1a\u4f7f\u7528\u5230 \u67e5\u51c6\u7387\u3001\u67e5\u5168\u7387 \u67e5\u51c6\u7387\uff08Precision\uff09: TP/(TP + FP) \u67e5\u5168\u7387\uff08Recall\uff09: TP/(TP + FN) \u4e8c\u8005\u7ed8\u5236\u7684\u66f2\u7ebf\u79f0\u4e3a P-R \u66f2\u7ebf \u5148\u5b9a\u4e49\u4e24\u4e2a\u516c\u5f0f\uff0c\u4e00\u4e2a\u662f Precision\uff0c\u4e00\u4e2a\u662f Recall\uff0c\u4e0e\u4e0a\u9762\u7684\u516c\u5f0f\u76f8\u540c\uff0c\u6269\u5c55\u5f00\u6765\uff0c\u7528\u53e6\u5916\u4e00\u79cd\u5f62\u5f0f\u8fdb\u884c\u5c55\u793a\uff0c\u5176\u4e2d all detctions \u4ee3\u8868\u6240\u6709\u9884\u6d4b\u6846\u7684\u6570\u91cf\uff0c all ground truths \u4ee3\u8868\u6240\u6709 GT \u7684\u6570\u91cf\u3002 AP \u662f\u8ba1\u7b97\u67d0\u4e00\u7c7b P-R \u66f2\u7ebf\u4e0b\u7684\u9762\u79ef\uff0cmAP \u5219\u662f\u8ba1\u7b97\u6240\u6709\u7c7b\u522b P-R \u66f2\u7ebf\u4e0b\u9762\u79ef\u7684\u5e73\u5747\u503c\u3002 \u5047\u8bbe\u6211\u4eec\u6709 7 \u5f20\u56fe\u7247\uff08Images1-Image7\uff09\uff0c\u8fd9\u4e9b\u56fe\u7247\u6709 15 \u4e2a\u76ee\u6807\uff08\u7eff\u8272\u7684\u6846\uff0cGT \u7684\u6570\u91cf\uff0c\u4e0a\u6587\u63d0\u53ca\u7684 all ground truths \uff09\u4ee5\u53ca 24 \u4e2a\u9884\u6d4b\u8fb9\u6846\uff08\u7ea2\u8272\u7684\u6846\uff0cA-Y \u7f16\u53f7\u8868\u793a\uff0c\u5e76\u4e14\u6709\u4e00\u4e2a\u7f6e\u4fe1\u5ea6\u503c\uff09\uff1a \u6839\u636e\u4e0a\u56fe\u4ee5\u53ca\u8bf4\u660e\uff0c\u6211\u4eec\u53ef\u4ee5\u5217\u51fa\u4ee5\u4e0b\u8868\u683c\uff0c\u5176\u4e2d Images \u4ee3\u8868\u56fe\u7247\u7684\u7f16\u53f7\uff0cDetections \u4ee3\u8868\u9884\u6d4b\u8fb9\u6846\u7684\u7f16\u53f7\uff0cConfidences \u4ee3\u8868\u9884\u6d4b\u8fb9\u6846\u7684\u7f6e\u4fe1\u5ea6\uff0cTP or FP \u4ee3\u8868\u9884\u6d4b\u7684\u8fb9\u6846\u662f\u6807\u8bb0\u4e3a TP \u8fd8\u662f FP\uff08\u8ba4\u4e3a\u9884\u6d4b\u8fb9\u6846\u4e0e GT \u7684 IOU \u503c\u5927\u4e8e\u7b49\u4e8e 0.3 \u5c31\u6807\u8bb0\u4e3a TP\uff1b\u82e5\u4e00\u4e2a GT \u6709\u591a\u4e2a\u9884\u6d4b\u8fb9\u6846\uff0c\u5219\u8ba4\u4e3a IOU \u6700\u5927\u4e14\u5927\u4e8e\u7b49\u4e8e 0.3 \u7684\u9884\u6d4b\u6846\u6807\u8bb0\u4e3a TP\uff0c\u5176\u4ed6\u7684\u6807\u8bb0\u4e3a FP\uff0c\u5373\u4e00\u4e2a GT \u53ea\u80fd\u6709\u4e00\u4e2a\u9884\u6d4b\u6846\u6807\u8bb0\u4e3a TP\uff09\uff0c\u8fd9\u91cc\u7684 0.3 \u662f\u968f\u673a\u53d6\u7684\u4e00\u4e2a\u503c\u3002 \u901a\u8fc7\u4e0a\u8868\uff0c\u6211\u4eec\u53ef\u4ee5\u7ed8\u5236\u51fa P-R \u66f2\u7ebf\uff08\u56e0\u4e3a AP \u5c31\u662f P-R \u66f2\u7ebf\u4e0b\u9762\u7684\u9762\u79ef\uff09\uff0c\u4f46\u662f\u5728\u6b64\u4e4b\u524d\u6211\u4eec\u9700\u8981\u8ba1\u7b97\u51fa P-R \u66f2\u7ebf\u4e0a\u5404\u4e2a\u70b9\u7684\u5750\u6807\uff0c\u6839\u636e\u7f6e\u4fe1\u5ea6\u4ece\u5927\u5230\u5c0f\u6392\u5e8f\u6240\u6709\u7684\u9884\u6d4b\u6846\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u8ba1\u7b97 Precision \u548c Recall \u7684\u503c\uff0c\u89c1\u4e0b\u8868\u3002\uff08\u9700\u8981\u8bb0\u4f4f\u4e00\u4e2a\u53eb\u7d2f\u52a0\u7684\u6982\u5ff5\uff0c\u5c31\u662f\u4e0b\u56fe\u7684 ACC TP \u548c ACC FP\uff09 \u6807\u53f7\u4e3a 1 \u7684 Precision \u548c Recall \u7684\u8ba1\u7b97\u65b9\u5f0f\uff1aPrecision=TP/(TP+FP)=1/(1+0)=1\uff0cRecall=TP/(TP+FN)=TP/( all ground truths )=1/15=0.0666 \uff08 all ground truths \u4e0a\u9762\u6709\u5b9a\u4e49\u8fc7\u4e86 \uff09 \u6807\u53f7 2\uff1aPrecision=TP/(TP+FP)=1/(1+1)=0.5\uff0cRecall=TP/(TP+FN)=TP/( all ground truths )=1/15=0.0666 \u6807\u53f7 3\uff1aPrecision=TP/(TP+FP)=2/(2+1)=0.6666\uff0cRecall=TP/(TP+FN)=TP/( all ground truths )=2/15=0.1333 \u5176\u4ed6\u7684\u4f9d\u6b21\u7c7b\u63a8 \u7136\u540e\u5c31\u53ef\u4ee5\u7ed8\u5236\u51fa P-R \u66f2\u7ebf \u5f97\u5230 P-R \u66f2\u7ebf\u5c31\u53ef\u4ee5\u8ba1\u7b97 AP\uff08P-R \u66f2\u7ebf\u4e0b\u7684\u9762\u79ef\uff09\uff0c\u8981\u8ba1\u7b97 P-R \u4e0b\u65b9\u7684\u9762\u79ef\uff0c\u6709\u4e24\u79cd\u65b9\u6cd5\uff1a \u5728VOC2010\u4ee5\u524d\uff0c\u53ea\u9700\u8981\u9009\u53d6\u5f53Recall >= 0, 0.1, 0.2, ..., 1\u517111\u4e2a\u70b9\u65f6\u7684Precision\u6700\u5927\u503c\uff0c\u7136\u540eAP\u5c31\u662f\u8fd911\u4e2aPrecision\u7684\u5e73\u5747\u503c\uff0c\u53d6 11 \u4e2a\u70b9 [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1] \u7684\u63d2\u503c\u6240\u5f97 \u5f97\u5230\u4e00\u4e2a\u7c7b\u522b\u7684 AP \u7ed3\u679c\u5982\u4e0b\uff1a \u8981\u8ba1\u7b97 mAP\uff0c\u5c31\u628a\u6240\u6709\u7c7b\u522b\u7684 AP \u8ba1\u7b97\u51fa\u6765\uff0c\u7136\u540e\u6c42\u53d6\u5e73\u5747\u5373\u53ef\u3002 \u5728VOC2010\u53ca\u4ee5\u540e\uff0c\u9700\u8981\u9488\u5bf9\u6bcf\u4e00\u4e2a\u4e0d\u540c\u7684Recall\u503c\uff08\u5305\u62ec0\u548c1\uff09\uff0c\u9009\u53d6\u5176\u5927\u4e8e\u7b49\u4e8e\u8fd9\u4e9bRecall\u503c\u65f6\u7684Precision\u6700\u5927\u503c\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7136\u540e\u8ba1\u7b97PR\u66f2\u7ebf\u4e0b\u9762\u79ef\u4f5c\u4e3aAP\u503c\uff1a \u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a 4.NMS\uff08\u975e\u6781\u5927\u503c\u6291\u5236\uff09 \u00b6 \u975e\u6781\u5927\u503c\u6291\u5236\uff08Non-Maximum Suppression\uff0cNMS\uff09\uff0c\u987e\u540d\u601d\u4e49\u5c31\u662f\u6291\u5236\u4e0d\u662f\u6781\u5927\u503c\u7684\u5143\u7d20\u3002\u4f8b\u5982\u5728\u884c\u4eba\u68c0\u6d4b\u4e2d\uff0c\u6ed1\u52a8\u7a97\u53e3\u7ecf\u63d0\u53d6\u7279\u5f81\uff0c\u7ecf\u5206\u7c7b\u5668\u5206\u7c7b\u8bc6\u522b\u540e\uff0c\u6bcf\u4e2a\u7a97\u53e3\u90fd\u4f1a\u5f97\u5230\u4e00\u4e2a\u5206\u6570\u3002\u4f46\u662f\u6ed1\u52a8\u7a97\u53e3\u4f1a\u5bfc\u81f4\u5f88\u591a\u7a97\u53e3\u4e0e\u5176\u4ed6\u7a97\u53e3\u5b58\u5728\u5305\u542b\u6216\u8005\u5927\u90e8\u5206\u4ea4\u53c9\u7684\u60c5\u51b5\u3002\u8fd9\u65f6\u5c31\u9700\u8981\u7528\u5230NMS\u6765\u9009\u53d6\u90a3\u4e9b\u90bb\u57df\u91cc\u5206\u6570\u6700\u9ad8\uff08\u662f\u884c\u4eba\u7684\u6982\u7387\u6700\u5927\uff09\uff0c\u5e76\u4e14\u6291\u5236\u90a3\u4e9b\u5206\u6570\u4f4e\u7684\u7a97\u53e3\u3002 NMS\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u6709\u7740\u975e\u5e38\u91cd\u8981\u7684\u5e94\u7528\uff0c\u5982\u89c6\u9891\u76ee\u6807\u8ddf\u8e2a\u3001\u6570\u636e\u6316\u6398\u30013D\u91cd\u5efa\u3001\u76ee\u6807\u8bc6\u522b\u4ee5\u53ca\u7eb9\u7406\u5206\u6790\u7b49 \u3002 \u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0cNMS\u7684\u76ee\u7684\u5c31\u662f\u8981\u53bb\u9664\u5197\u4f59\u7684\u68c0\u6d4b\u6846,\u4fdd\u7559\u6700\u597d\u7684\u4e00\u4e2a\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a NMS\u7684\u539f\u7406\u662f\u5bf9\u4e8e\u9884\u6d4b\u6846\u7684\u5217\u8868B\u53ca\u5176\u5bf9\u5e94\u7684\u7f6e\u4fe1\u5ea6S,\u9009\u62e9\u5177\u6709\u6700\u5927score\u7684\u68c0\u6d4b\u6846M,\u5c06\u5176\u4eceB\u96c6\u5408\u4e2d\u79fb\u9664\u5e76\u52a0\u5165\u5230\u6700\u7ec8\u7684\u68c0\u6d4b\u7ed3\u679cD\u4e2d.\u901a\u5e38\u5c06B\u4e2d\u5269\u4f59\u68c0\u6d4b\u6846\u4e2d\u4e0eM\u7684IoU\u5927\u4e8e\u9608\u503cNt\u7684\u6846\u4eceB\u4e2d\u79fb\u9664.\u91cd\u590d\u8fd9\u4e2a\u8fc7\u7a0b,\u76f4\u5230B\u4e3a\u7a7a\u3002 \u4f7f\u7528\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u9996\u5148\u662f\u68c0\u6d4b\u51fa\u4e00\u7cfb\u5217\u7684\u68c0\u6d4b\u6846 \u5c06\u68c0\u6d4b\u6846\u6309\u7167\u7c7b\u522b\u8fdb\u884c\u5206\u7c7b \u5bf9\u540c\u4e00\u7c7b\u522b\u7684\u68c0\u6d4b\u6846\u5e94\u7528NMS\u83b7\u53d6\u6700\u7ec8\u7684\u68c0\u6d4b\u7ed3\u679c \u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u770b\u4e9bNMS\u7684\u4f7f\u7528\u65b9\u6cd5\uff0c\u5047\u8bbe\u5b9a\u4f4d\u8f66\u8f86\uff0c\u7b97\u6cd5\u5c31\u627e\u51fa\u4e86\u4e00\u7cfb\u5217\u7684\u77e9\u5f62\u6846\uff0c\u6211\u4eec\u9700\u8981\u5224\u522b\u54ea\u4e9b\u77e9\u5f62\u6846\u662f\u6ca1\u7528\u7684\uff0c\u9700\u8981\u4f7f\u7528NMS\u7684\u65b9\u6cd5\u6765\u5b9e\u73b0\u3002 \u5047\u8bbe\u73b0\u5728\u68c0\u6d4b\u7a97\u53e3\u6709\uff1aA\u3001B\u3001C\u3001D\u3001E 5\u4e2a\u5019\u9009\u6846\uff0c\u63a5\u4e0b\u6765\u8fdb\u884c\u8fed\u4ee3\u8ba1\u7b97\uff1a \u7b2c\u4e00\u8f6e\uff1a\u56e0\u4e3aB\u662f\u5f97\u5206\u6700\u9ad8\u7684\uff0c\u4e0eB\u7684IoU\uff1e0.5\u5220\u9664\u3002A\uff0cCDE\u4e2d\u73b0\u5728\u4e0eB\u8ba1\u7b97IoU\uff0cDE\u7ed3\u679c\uff1e0.5\uff0c\u5254\u9664DE\uff0cB\u4f5c\u4e3a\u4e00\u4e2a\u9884\u6d4b\u7ed3\u679c\uff0c\u6709\u4e2a\u68c0\u6d4b\u6846\u7559\u4e0bB\uff0c\u653e\u5165\u96c6\u5408 \u7b2c\u4e8c\u8f6e\uff1aA\u7684\u5f97\u5206\u6700\u9ad8\uff0c\u4e0eA\u8ba1\u7b97IoU\uff0cC\u7684\u7ed3\u679c\uff1e0.5\uff0c\u5254\u9664C\uff0cA\u4f5c\u4e3a\u4e00\u4e2a\u7ed3\u679c \u6700\u7ec8\u7ed3\u679c\u4e3a\u5728\u8fd9\u4e2a5\u4e2a\u4e2d\u68c0\u6d4b\u51fa\u4e86\u4e24\u4e2a\u76ee\u6807\u4e3aA\u548cB\u3002 \u5355\u7c7b\u522b\u7684NMS\u7684\u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a import numpy as np def nms ( bboxes , confidence_score , threshold ): \"\"\"\u975e\u6781\u5927\u6291\u5236\u8fc7\u7a0b :param bboxes: \u540c\u7c7b\u522b\u5019\u9009\u6846\u5750\u6807 :param confidence: \u540c\u7c7b\u522b\u5019\u9009\u6846\u5206\u6570 :param threshold: iou\u9608\u503c :return: \"\"\" # 1\u3001\u4f20\u5165\u65e0\u5019\u9009\u6846\u8fd4\u56de\u7a7a if len ( bboxes ) == 0 : return [], [] # \u5f3a\u8f6c\u6570\u7ec4 bboxes = np . array ( bboxes ) score = np . array ( confidence_score ) # \u53d6\u51fan\u4e2a\u7684\u6781\u5750\u6807\u70b9 x1 = bboxes [:, 0 ] y1 = bboxes [:, 1 ] x2 = bboxes [:, 2 ] y2 = bboxes [:, 3 ] # 2\u3001\u5bf9\u5019\u9009\u6846\u8fdb\u884cNMS\u7b5b\u9009 # \u8fd4\u56de\u7684\u6846\u5750\u6807\u548c\u5206\u6570 picked_boxes = [] picked_score = [] # \u5bf9\u7f6e\u4fe1\u5ea6\u8fdb\u884c\u6392\u5e8f, \u83b7\u53d6\u6392\u5e8f\u540e\u7684\u4e0b\u6807\u5e8f\u53f7, argsort\u9ed8\u8ba4\u4ece\u5c0f\u5230\u5927\u6392\u5e8f order = np . argsort ( score ) areas = ( x2 - x1 ) * ( y2 - y1 ) while order . size > 0 : # \u5c06\u5f53\u524d\u7f6e\u4fe1\u5ea6\u6700\u5927\u7684\u6846\u52a0\u5165\u8fd4\u56de\u503c\u5217\u8868\u4e2d index = order [ - 1 ] #\u4fdd\u7559\u8be5\u7c7b\u5269\u4f59box\u4e2d\u5f97\u5206\u6700\u9ad8\u7684\u4e00\u4e2a picked_boxes . append ( bboxes [ index ]) picked_score . append ( confidence_score [ index ]) # \u83b7\u53d6\u5f53\u524d\u7f6e\u4fe1\u5ea6\u6700\u5927\u7684\u5019\u9009\u6846\u4e0e\u5176\u4ed6\u4efb\u610f\u5019\u9009\u6846\u7684\u76f8\u4ea4\u9762\u79ef x11 = np . maximum ( x1 [ index ], x1 [ order [: - 1 ]]) y11 = np . maximum ( y1 [ index ], y1 [ order [: - 1 ]]) x22 = np . minimum ( x2 [ index ], x2 [ order [: - 1 ]]) y22 = np . minimum ( y2 [ index ], y2 [ order [: - 1 ]]) # \u8ba1\u7b97\u76f8\u4ea4\u7684\u9762\u79ef,\u4e0d\u91cd\u53e0\u65f6\u9762\u79ef\u4e3a0 w = np . maximum ( 0.0 , x22 - x11 ) h = np . maximum ( 0.0 , y22 - y11 ) intersection = w * h # \u5229\u7528\u76f8\u4ea4\u7684\u9762\u79ef\u548c\u4e24\u4e2a\u6846\u81ea\u8eab\u7684\u9762\u79ef\u8ba1\u7b97\u6846\u7684\u4ea4\u5e76\u6bd4 ratio = intersection / ( areas [ index ] + areas [ order [: - 1 ]] - intersection ) # \u4fdd\u7559IoU\u5c0f\u4e8e\u9608\u503c\u7684box keep_boxes_indics = np . where ( ratio < threshold ) # \u4fdd\u7559\u5269\u4f59\u7684\u6846 order = order [ keep_boxes_indics ] # \u8fd4\u56deNMS\u540e\u7684\u6846\u53ca\u5206\u7c7b\u7ed3\u679c return picked_boxes , picked_score \u5047\u8bbe\u6709\u68c0\u6d4b\u7ed3\u679c\u5982\u4e0b\uff1a bounding = [( 187 , 82 , 337 , 317 ), ( 150 , 67 , 305 , 282 ), ( 246 , 121 , 368 , 304 )] confidence_score = [ 0.9 , 0.65 , 0.8 ] threshold = 0.3 picked_boxes , picked_score = nms ( bounding , confidence_score , threshold ) print ( '\u9608\u503cthreshold\u4e3a:' , threshold ) print ( 'NMS\u540e\u5f97\u5230\u7684bbox\u662f\uff1a' , picked_boxes ) print ( 'NMS\u540e\u5f97\u5230\u7684bbox\u7684confidences\u662f\uff1a' , picked_score ) \u8fd4\u56de\u7ed3\u679c\uff1a \u9608\u503cthreshold\u4e3a : 0.3 NMS\u540e\u5f97\u5230\u7684bbox\u662f \uff1a [ array ([ 187 , 82 , 337 , 317 ])] NMS\u540e\u5f97\u5230\u7684bbox\u7684confidences\u662f \uff1a [ 0.9 ] 5.\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u5206\u7c7b \u00b6 \u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e3b\u8981\u5206\u4e3atwo-stage\uff08\u4e24\u9636\u6bb5\uff09\u548cone-stage\uff08\u5355\u9636\u6bb5\uff09\u4e24\u7c7b\uff1a two-stage\u7684\u7b97\u6cd5 \u5148\u7531\u7b97\u6cd5\u751f\u6210\u4e00\u7cfb\u5217\u4f5c\u4e3a\u6837\u672c\u7684\u5019\u9009\u6846\uff0c\u518d\u901a\u8fc7\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u6837\u672c\u5206\u7c7b\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4e3b\u8981\u901a\u8fc7\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u5b8c\u6210\u76ee\u6807\u68c0\u6d4b\u8fc7\u7a0b\uff0c\u5176\u63d0\u53d6\u7684\u662fCNN\u5377\u79ef\u7279\u5f81\uff0c\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u7b5b\u9009\u548c\u76ee\u6807\u68c0\u6d4b\u4e24\u90e8\u5206\u3002\u7f51\u7edc\u7684\u51c6\u786e\u5ea6\u9ad8\u3001\u901f\u5ea6\u76f8\u5bf9\u8f83\u6162\u3002 two-stages\u7b97\u6cd5\u7684\u4ee3\u8868\u662fRCNN\u7cfb\u5217\uff1aR-CNN\u5230Faster R-CNN\u7f51\u7edc One-stage\u7684\u7b97\u6cd5 \u76f4\u63a5\u901a\u8fc7\u4e3b\u5e72\u7f51\u7edc\u7ed9\u51fa\u76ee\u6807\u7684\u7c7b\u522b\u548c\u4f4d\u7f6e\u4fe1\u606f\uff0c\u6ca1\u6709\u4f7f\u7528\u5019\u9009\u533a\u57df\u7684\u7b5b\u9009\u7f51\u8def\uff0c\u8fd9\u79cd\u7b97\u6cd5\u901f\u5ea6\u5feb\uff0c\u4f46\u662f\u7cbe\u5ea6\u76f8\u5bf9Two-stage\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u964d\u4f4e\u4e86\u5f88\u591a\u3002 one-stage\u7b97\u6cd5\u7684\u4ee3\u8868\u662f\uff1a YOLO\u7cfb\u5217\uff1aYOLOv1\u3001YOLOv2\u3001YOLOv3\u3001 SSD\u7b49 \u603b\u7ed3 \u4e86\u89e3\u76ee\u6807\u68c0\u6d4b\u7684\u4efb\u52a1 \u627e\u51fa\u56fe\u50cf\u4e2d\u6240\u6709\u611f\u5174\u8da3\u7684\u76ee\u6807\uff0c\u5e76\u786e\u5b9a\u5b83\u4eec\u7684\u7c7b\u522b\u548c\u4f4d\u7f6e \u77e5\u9053\u76ee\u6807\u68c0\u6d4b\u7684\u5e38\u7528\u6570\u636e\u96c6 PASCAL VOC\u6570\u636e\u96c6 \u548c MS COCO\u6570\u636e\u96c6 \u77e5\u9053\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u7684\u8bc4\u4ef7\u6307\u6807 IOU\u548cmAP \u638c\u63e1\u975e\u6781\u5927\u503cNMS\u7b97\u6cd5\u7684\u5e94\u7528 \u8981\u53bb\u9664\u5197\u4f59\u7684\u68c0\u6d4b\u6846,\u4fdd\u7559\u6700\u597d\u7684\u4e00\u4e2a \u4e86\u89e3\u5e38\u7528\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5206\u7c7b two-stage\uff08\u4e24\u9636\u6bb5\uff09\u548cone-stage\uff08\u5355\u9636\u6bb5\uff09","title":"\u76ee\u6807\u68c0\u6d4b\u6982\u8ff0"},{"location":"objectdection/01.overview/#41","text":"\u5b66\u4e60\u76ee\u6807 \u4e86\u89e3\u76ee\u6807\u68c0\u6d4b\u7684\u4efb\u52a1 \u77e5\u9053\u76ee\u6807\u68c0\u6d4b\u7684\u5e38\u7528\u6570\u636e\u96c6 \u77e5\u9053\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u7684\u8bc4\u4ef7\u6307\u6807 \u638c\u63e1\u975e\u6781\u5927\u503cNMS\u7b97\u6cd5\u7684\u5e94\u7528 \u4e86\u89e3\u5e38\u7528\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5206\u7c7b","title":"4.1 \u76ee\u6807\u68c0\u6d4b\u6982\u8ff0"},{"location":"objectdection/01.overview/#1","text":"\u76ee\u6807\u68c0\u6d4b\uff08Object Detection\uff09\u7684\u4efb\u52a1\u662f\u627e\u51fa\u56fe\u50cf\u4e2d\u6240\u6709\u611f\u5174\u8da3\u7684\u76ee\u6807\uff0c\u5e76\u786e\u5b9a\u5b83\u4eec\u7684\u7c7b\u522b\u548c\u4f4d\u7f6e\u3002 \u76ee\u6807\u68c0\u6d4b\u4e2d\u80fd\u68c0\u6d4b\u51fa\u6765\u7684\u7269\u4f53\u53d6\u51b3\u4e8e\u5f53\u524d\u4efb\u52a1\uff08\u6570\u636e\u96c6\uff09\u9700\u8981\u68c0\u6d4b\u7684\u7269\u4f53\u6709\u54ea\u4e9b\u3002\u5047\u8bbe\u6211\u4eec\u7684\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u5b9a\u4f4d\u662f\u68c0\u6d4b\u52a8\u7269\uff08\u725b\u3001\u7f8a\u3001\u732a\u3001\u72d7\u3001\u732b\u4e94\u79cd\u7ed3\u679c\uff09\uff0c\u90a3\u4e48\u6a21\u578b\u5bf9\u4efb\u4f55\u4e00\u5f20\u56fe\u7247\u8f93\u51fa\u7ed3\u679c\u4e0d\u4f1a\u8f93\u51fa\u9e2d\u5b50\u3001\u4e66\u7c4d\u7b49\u5176\u5b83\u7c7b\u578b\u7ed3\u679c\u3002 \u76ee\u6807\u68c0\u6d4b\u7684\u4f4d\u7f6e\u4fe1\u606f\u4e00\u822c\u7531\u4e24\u79cd\u683c\u5f0f\uff08\u4ee5\u56fe\u7247\u5de6\u4e0a\u89d2\u4e3a\u539f\u70b9(0,0)\uff09\uff1a 1\u3001\u6781\u5750\u6807\u8868\u793a\uff1a(xmin, ymin, xmax, ymax) xmin,ymin:x,y\u5750\u6807\u7684\u6700\u5c0f\u503c xmin,ymin:x,y\u5750\u6807\u7684\u6700\u5927\u503c 2\u3001\u4e2d\u5fc3\u70b9\u5750\u6807\uff1a(x_center, y_center, w, h) x_center, y_center:\u76ee\u6807\u68c0\u6d4b\u6846\u7684\u4e2d\u5fc3\u70b9\u5750\u6807 w,h:\u76ee\u6807\u68c0\u6d4b\u6846\u7684\u5bbd\u3001\u9ad8 \u5047\u8bbe\u5728\u4e0b\u9762\u7684\u56fe\u50cf\u4e2d\u8fdb\u884c\u68c0\u6d4b\uff0c\uff1a \u90a3\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c\u7684\u4e2d\u5fc3\u70b9\u8868\u793a\u5f62\u5f0f\u5982\u4e0b\u6240\u793a\uff1a","title":"1. \u76ee\u6807\u68c0\u6d4b"},{"location":"objectdection/01.overview/#2","text":"\u7ecf\u5178\u7684\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u6709\u4e24\u79cd\uff0c PASCAL VOC\u6570\u636e\u96c6 \u548c MS COCO\u6570\u636e\u96c6 \u3002","title":"2.\u5e38\u7528\u7684\u5f00\u6e90\u6570\u636e\u96c6"},{"location":"objectdection/01.overview/#21-pascal-voc","text":"PASCAL VOC\u662f\u76ee\u6807\u68c0\u6d4b\u9886\u57df\u7684\u7ecf\u5178\u6570\u636e\u96c6\u3002PASCAL VOC\u5305\u542b\u7ea610,000\u5f20\u5e26\u6709\u8fb9\u754c\u6846\u7684\u56fe\u7247\u7528\u4e8e\u8bad\u7ec3\u548c\u9a8c\u8bc1\u3002PASCAL VOC\u6570\u636e\u96c6\u662f\u76ee\u6807\u68c0\u6d4b\u95ee\u9898\u7684\u4e00\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5f88\u591a\u6a21\u578b\u90fd\u662f\u5728\u6b64\u6570\u636e\u96c6\u4e0a\u5f97\u5230\u7684\uff0c\u5e38\u7528\u7684\u662fVOC2007\u548cVOC2012\u4e24\u4e2a\u7248\u672c\u6570\u636e\uff0c\u517120\u4e2a\u7c7b\u522b\uff0c\u5206\u522b\u662f\uff1a \u4e5f\u5c31\u662f\uff1a 1.\u4eba: \u4eba 2.\u52a8\u7269: \u9e1f\uff0c\u732b\uff0c\u725b\uff0c\u72d7\uff0c\u9a6c\uff0c\u7f8a 3.\u4ea4\u901a\u5de5\u5177: \u98de\u673a\uff0c\u81ea\u884c\u8f66\uff0c\u8239\uff0c\u516c\u5171\u6c7d\u8f66\uff0c\u6c7d\u8f66\uff0c\u6469\u6258\u8f66\uff0c\u706b\u8f66 4.\u5ba4\u5185: \u74f6\u5b50\uff0c\u6905\u5b50\uff0c\u9910\u684c\uff0c\u76c6\u683d\uff0c\u6c99\u53d1\uff0c\u7535\u89c6/\u663e\u793a\u5668 \u4e0b\u8f7d\u5730\u5740 \uff1a https://pjreddie.com/projects/pascal-voc-dataset-mirror/ \u6574\u4e2a\u6570\u636e\u7684\u76ee\u5f55\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a \u5176\u4e2d\uff1a JPEGImages\u5b58\u653e\u56fe\u7247\u6587\u4ef6 Annotations\u4e0b\u5b58\u653e\u7684\u662fxml\u6587\u4ef6,\u63cf\u8ff0\u4e86\u56fe\u7247\u4fe1\u606f\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u9700\u8981\u5173\u6ce8\u7684\u5c31\u662f\u8282\u70b9\u4e0b\u7684\u6570\u636e,\u5c24\u5176\u662fbndbox\u4e0b\u7684\u6570\u636e.xmin,ymin\u6784\u6210\u4e86boundingbox\u7684\u5de6\u4e0a\u89d2,xmax,ymax\u6784\u6210\u4e86boundingbox\u7684\u53f3\u4e0b\u89d2\uff0c\u4e5f\u5c31\u662f\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u4f4d\u7f6e\u4fe1\u606f ImageSets\u5305\u542b\u4ee5\u4e0b4\u4e2a\u6587\u4ef6\u5939\uff1a Action\u4e0b\u5b58\u653e\u7684\u662f\u4eba\u7684\u52a8\u4f5c\uff08\u4f8b\u5982running\u3001jumping\u7b49\u7b49\uff09 Layout\u4e0b\u5b58\u653e\u7684\u662f\u5177\u6709\u4eba\u4f53\u90e8\u4f4d\u7684\u6570\u636e\uff08\u4eba\u7684head\u3001hand\u3001feet\u7b49\u7b49\uff09 Segmentation\u4e0b\u5b58\u653e\u7684\u662f\u53ef\u7528\u4e8e\u5206\u5272\u7684\u6570\u636e\u3002 Main\u4e0b\u5b58\u653e\u7684\u662f\u56fe\u50cf\u7269\u4f53\u8bc6\u522b\u7684\u6570\u636e\uff0c\u603b\u5171\u5206\u4e3a20\u7c7b\uff0c\u8fd9\u662f\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u7684\u91cd\u70b9\u3002\u8be5\u6587\u4ef6\u5939\u4e2d\u7684\u6570\u636e\u5bf9\u8d1f\u6837\u672c\u6587\u4ef6\u8fdb\u884c\u4e86\u63cf\u8ff0\u3002","title":"2.1 PASCAL VOC\u6570\u636e\u96c6"},{"location":"objectdection/01.overview/#22-ms-coco","text":"MS COCO\u7684\u5168\u79f0\u662fMicrosoft Common Objects in Context\uff0c\u5fae\u8f6f\u4e8e2014\u5e74\u51fa\u8d44\u6807\u6ce8\u7684Microsoft COCO\u6570\u636e\u96c6\uff0c\u4e0eImageNet\u7ade\u8d5b\u4e00\u6837\uff0c\u88ab\u89c6\u4e3a\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u6700\u53d7\u5173\u6ce8\u548c\u6700\u6743\u5a01\u7684\u6bd4\u8d5b\u4e4b\u4e00\u3002 COCO\u6570\u636e\u96c6\u662f\u4e00\u4e2a\u5927\u578b\u7684\u3001\u4e30\u5bcc\u7684\u7269\u4f53\u68c0\u6d4b\uff0c\u5206\u5272\u548c\u5b57\u5e55\u6570\u636e\u96c6\u3002\u8fd9\u4e2a\u6570\u636e\u96c6\u4ee5\u573a\u666f\u7406\u89e3\u4e3a\u76ee\u6807\uff0c\u4e3b\u8981\u4ece\u590d\u6742\u7684\u65e5\u5e38\u573a\u666f\u4e2d\u622a\u53d6\uff0c\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u901a\u8fc7\u7cbe\u786e\u7684\u5206\u5272\u8fdb\u884c\u4f4d\u7f6e\u7684\u6807\u5b9a\u3002\u56fe\u50cf\u5305\u62ec91\u7c7b\u76ee\u6807\uff0c328,000\u5f71\u50cf\u548c2,500,000\u4e2alabel\u3002\u76ee\u524d\u4e3a\u6b62\u76ee\u6807\u68c0\u6d4b\u7684\u6700\u5927\u6570\u636e\u96c6\uff0c\u63d0\u4f9b\u7684\u7c7b\u522b\u670980 \u7c7b\uff0c\u6709\u8d85\u8fc733 \u4e07\u5f20\u56fe\u7247\uff0c\u5176\u4e2d20 \u4e07\u5f20\u6709\u6807\u6ce8\uff0c\u6574\u4e2a\u6570\u636e\u96c6\u4e2d\u4e2a\u4f53\u7684\u6570\u76ee\u8d85\u8fc7150 \u4e07\u4e2a\u3002 \u56fe\u50cf\u793a\u4f8b\uff1a coco\u6570\u636e\u96c6\u7684\u6807\u7b7e\u6587\u4ef6\u6807\u8bb0\u4e86\u6bcf\u4e2asegmentation+bounding box\u7684\u7cbe\u786e\u5750\u6807\uff0c\u5176\u7cbe\u5ea6\u5747\u4e3a\u5c0f\u6570\u70b9\u540e\u4e24\u4f4d\u4e00\u4e2a\u76ee\u6807\u7684\u6807\u7b7e\u793a\u610f\u5982\u4e0b\uff1a {\"segmentation\":[[392.87, 275.77, 402.24, 284.2, 382.54, 342.36, 375.99, 356.43, 372.23, 357.37, 372.23, 397.7, 383.48, 419.27,407.87, 439.91, 427.57, 389.25, 447.26, 346.11, 447.26, 328.29, 468.84, 290.77,472.59, 266.38], [429.44,465.23, 453.83, 473.67, 636.73, 474.61, 636.73, 392.07, 571.07, 364.88, 546.69,363.0]], \"area\": 28458.996150000003, \"iscrowd\": 0,\"image_id\": 503837, \"bbox\": [372.23, 266.38, 264.5,208.23] , \"category_id\": 4, \"id\": 151109},","title":"2.2 MS COCO\u6570\u636e\u96c6"},{"location":"objectdection/01.overview/#3","text":"","title":"3.\u5e38\u7528\u7684\u8bc4\u4ef7\u6307\u6807"},{"location":"objectdection/01.overview/#31-iou","text":"\u5728\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\uff0cIoU\uff08intersection over union\uff0c\u4ea4\u5e76\u6bd4\uff09\u662f\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\u7528\u6765\u8bc4\u4ef72\u4e2a\u77e9\u5f62\u6846\u4e4b\u95f4\u76f8\u4f3c\u5ea6\u7684\u6307\u6807\uff1a IoU = \u4e24\u4e2a\u77e9\u5f62\u6846\u76f8\u4ea4\u7684\u9762\u79ef / \u4e24\u4e2a\u77e9\u5f62\u6846\u76f8\u5e76\u7684\u9762\u79ef \uff0c \u5982\u4e0b\u56fe\u6240\u793a\uff1a \u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u770b\u4e0b\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u7684\u5e94\u7528\uff1a \u5176\u4e2d\u4e0a\u56fe\u84dd\u8272\u6846\u6846\u4e3a\u68c0\u6d4b\u7ed3\u679c\uff0c\u7ea2\u8272\u6846\u6846\u4e3a\u771f\u5b9e\u6807\u6ce8\u3002 \u90a3\u6211\u4eec\u5c31\u53ef\u4ee5\u901a\u8fc7\u9884\u6d4b\u7ed3\u679c\u4e0e\u771f\u5b9e\u7ed3\u679c\u4e4b\u95f4\u7684\u4ea4\u5e76\u6bd4\u6765\u8861\u91cf\u4e24\u8005\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u3002\u4e00\u822c\u60c5\u51b5\u4e0b\u5bf9\u4e8e\u68c0\u6d4b\u6846\u7684\u5224\u5b9a\u90fd\u4f1a\u5b58\u5728\u4e00\u4e2a\u9608\u503c\uff0c\u4e5f\u5c31\u662f IoU \u7684\u9608\u503c\uff0c\u4e00\u822c\u53ef\u4ee5\u8bbe\u7f6e\u5f53 IoU \u7684\u503c\u5927\u4e8e 0.5 \u7684\u65f6\u5019\uff0c\u5219\u53ef\u8ba4\u4e3a\u68c0\u6d4b\u5230\u76ee\u6807\u7269\u4f53\u3002 \u5b9e\u73b0\u65b9\u6cd5\uff1a import numpy as np # \u5b9a\u4e49\u65b9\u6cd5\u8ba1\u7b97IOU def Iou ( box1 , box2 , wh = False ): # \u5224\u65adbbox\u7684\u8868\u793a\u5f62\u5f0f if wh == False : # \u4f7f\u7528\u6781\u5750\u6807\u5f62\u5f0f\u8868\u793a\uff1a\u76f4\u63a5\u83b7\u53d6\u4e24\u4e2abbox\u7684\u5750\u6807 xmin1 , ymin1 , xmax1 , ymax1 = box1 xmin2 , ymin2 , xmax2 , ymax2 = box2 else : # \u4f7f\u7528\u4e2d\u5fc3\u70b9\u5f62\u5f0f\u8868\u793a\uff1a \u83b7\u53d6\u4e24\u4e2a\u4e24\u4e2abbox\u7684\u6781\u5750\u6807\u8868\u793a\u5f62\u5f0f # \u7b2c\u4e00\u4e2a\u6846\u5de6\u4e0a\u89d2\u5750\u6807 xmin1 , ymin1 = int ( box1 [ 0 ] - box1 [ 2 ] / 2.0 ), int ( box1 [ 1 ] - box1 [ 3 ] / 2.0 ) # \u7b2c\u4e00\u4e2a\u6846\u53f3\u4e0b\u89d2\u5750\u6807 xmax1 , ymax1 = int ( box1 [ 0 ] + box1 [ 2 ] / 2.0 ), int ( box1 [ 1 ] + box1 [ 3 ] / 2.0 ) # \u7b2c\u4e8c\u4e2a\u6846\u5de6\u4e0a\u89d2\u5750\u6807 xmin2 , ymin2 = int ( box2 [ 0 ] - box2 [ 2 ] / 2.0 ), int ( box2 [ 1 ] - box2 [ 3 ] / 2.0 ) # \u7b2c\u4e8c\u4e2a\u6846\u53f3\u4e0b\u89d2\u5750\u6807 xmax2 , ymax2 = int ( box2 [ 0 ] + box2 [ 2 ] / 2.0 ), int ( box2 [ 1 ] + box2 [ 3 ] / 2.0 ) # \u83b7\u53d6\u77e9\u5f62\u6846\u4ea4\u96c6\u5bf9\u5e94\u7684\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\u7684\u5750\u6807\uff08intersection\uff09 xx1 = np . max ([ xmin1 , xmin2 ]) yy1 = np . max ([ ymin1 , ymin2 ]) xx2 = np . min ([ xmax1 , xmax2 ]) yy2 = np . min ([ ymax1 , ymax2 ]) # \u8ba1\u7b97\u4e24\u4e2a\u77e9\u5f62\u6846\u9762\u79ef area1 = ( xmax1 - xmin1 ) * ( ymax1 - ymin1 ) area2 = ( xmax2 - xmin2 ) * ( ymax2 - ymin2 ) #\u8ba1\u7b97\u4ea4\u96c6\u9762\u79ef inter_area = ( np . max ([ 0 , xx2 - xx1 ])) * ( np . max ([ 0 , yy2 - yy1 ])) #\u8ba1\u7b97\u4ea4\u5e76\u6bd4 iou = inter_area / ( area1 + area2 - inter_area + 1e-6 ) return iou \u5047\u8bbe\u6211\u4eec\u68c0\u6d4b\u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff0c\u5e76\u5c55\u793a\u5728\u56fe\u50cf\u4e0a\uff1a import matplotlib.pyplot as plt import matplotlib.patches as patches # \u771f\u5b9e\u6846\u4e0e\u9884\u6d4b\u6846 True_bbox , predict_bbox = [ 100 , 35 , 398 , 400 ], [ 40 , 150 , 355 , 398 ] # bbox\u662fbounding box\u7684\u7f29\u5199 img = plt . imread ( 'dog.jpeg' ) fig = plt . imshow ( img ) # \u5c06\u8fb9\u754c\u6846(\u5de6\u4e0ax, \u5de6\u4e0ay, \u53f3\u4e0bx, \u53f3\u4e0by)\u683c\u5f0f\u8f6c\u6362\u6210matplotlib\u683c\u5f0f\uff1a((\u5de6\u4e0ax, \u5de6\u4e0ay), \u5bbd, \u9ad8) # \u771f\u5b9e\u6846\u7ed8\u5236 fig . axes . add_patch ( plt . Rectangle ( xy = ( True_bbox [ 0 ], True_bbox [ 1 ]), width = True_bbox [ 2 ] - True_bbox [ 0 ], height = True_bbox [ 3 ] - True_bbox [ 1 ], fill = False , edgecolor = \"blue\" , linewidth = 2 )) # \u9884\u6d4b\u6846\u7ed8\u5236 fig . axes . add_patch ( plt . Rectangle ( xy = ( predict_bbox [ 0 ], predict_bbox [ 1 ]), width = predict_bbox [ 2 ] - predict_bbox [ 0 ], height = predict_bbox [ 3 ] - predict_bbox [ 1 ], fill = False , edgecolor = \"red\" , linewidth = 2 )) \u8ba1\u7b97IoU\uff1a Iou ( True_bbox , predict_bbox ) \u7ed3\u679c\u4e3a\uff1a 0.5114435907762924","title":"3.1 IOU"},{"location":"objectdection/01.overview/#32-mapmean-average-precision","text":"\u76ee\u6807\u68c0\u6d4b\u95ee\u9898\u4e2d\u7684\u6bcf\u4e2a\u56fe\u7247\u90fd\u53ef\u80fd\u5305\u542b\u4e00\u4e9b\u4e0d\u540c\u7c7b\u522b\u7684\u7269\u4f53\uff0c\u9700\u8981\u8bc4\u4f30\u6a21\u578b\u7684\u7269\u4f53\u5206\u7c7b\u548c\u5b9a\u4f4d\u6027\u80fd\u3002\u56e0\u6b64\uff0c\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\u7684\u6807\u51c6\u6307\u6807precision\u4e0d\u80fd\u76f4\u63a5\u5e94\u7528\u4e8e\u6b64\u3002 \u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0cmAP\u662f\u4e3b\u8981\u7684\u8861\u91cf\u6307\u6807\u3002 mAP\u662f\u591a\u4e2a\u5206\u7c7b\u4efb\u52a1\u7684AP\u7684\u5e73\u5747\u503c\uff0c\u800cAP\uff08average precision\uff09\u662fPR\u66f2\u7ebf\u4e0b\u7684\u9762\u79ef\uff0c\u6240\u4ee5\u5728\u4ecb\u7ecdmAP\u4e4b\u524d\u6211\u4eec\u8981\u5148\u5f97\u5230PR\u66f2\u7ebf\u3002 TP\u3001FP\u3001FN\u3001TN True Positive (TP): IoU> ( \u4e00\u822c\u53d6 0.5 ) \u7684\u68c0\u6d4b\u6846\u6570\u91cf\uff08\u540c\u4e00 Ground Truth \u53ea\u8ba1\u7b97\u4e00\u6b21\uff09 False Positive (FP): IoU<= \u7684\u68c0\u6d4b\u6846\u6570\u91cf\uff0c\u6216\u8005\u662f\u68c0\u6d4b\u5230\u540c\u4e00\u4e2a GT \u7684\u591a\u4f59\u68c0\u6d4b\u6846\u7684\u6570\u91cf False Negative (FN): \u6ca1\u6709\u68c0\u6d4b\u5230\u7684 GT \u7684\u6570\u91cf True Negative (TN): \u5728 mAP \u8bc4\u4ef7\u6307\u6807\u4e2d\u4e0d\u4f1a\u4f7f\u7528\u5230 \u67e5\u51c6\u7387\u3001\u67e5\u5168\u7387 \u67e5\u51c6\u7387\uff08Precision\uff09: TP/(TP + FP) \u67e5\u5168\u7387\uff08Recall\uff09: TP/(TP + FN) \u4e8c\u8005\u7ed8\u5236\u7684\u66f2\u7ebf\u79f0\u4e3a P-R \u66f2\u7ebf \u5148\u5b9a\u4e49\u4e24\u4e2a\u516c\u5f0f\uff0c\u4e00\u4e2a\u662f Precision\uff0c\u4e00\u4e2a\u662f Recall\uff0c\u4e0e\u4e0a\u9762\u7684\u516c\u5f0f\u76f8\u540c\uff0c\u6269\u5c55\u5f00\u6765\uff0c\u7528\u53e6\u5916\u4e00\u79cd\u5f62\u5f0f\u8fdb\u884c\u5c55\u793a\uff0c\u5176\u4e2d all detctions \u4ee3\u8868\u6240\u6709\u9884\u6d4b\u6846\u7684\u6570\u91cf\uff0c all ground truths \u4ee3\u8868\u6240\u6709 GT \u7684\u6570\u91cf\u3002 AP \u662f\u8ba1\u7b97\u67d0\u4e00\u7c7b P-R \u66f2\u7ebf\u4e0b\u7684\u9762\u79ef\uff0cmAP \u5219\u662f\u8ba1\u7b97\u6240\u6709\u7c7b\u522b P-R \u66f2\u7ebf\u4e0b\u9762\u79ef\u7684\u5e73\u5747\u503c\u3002 \u5047\u8bbe\u6211\u4eec\u6709 7 \u5f20\u56fe\u7247\uff08Images1-Image7\uff09\uff0c\u8fd9\u4e9b\u56fe\u7247\u6709 15 \u4e2a\u76ee\u6807\uff08\u7eff\u8272\u7684\u6846\uff0cGT \u7684\u6570\u91cf\uff0c\u4e0a\u6587\u63d0\u53ca\u7684 all ground truths \uff09\u4ee5\u53ca 24 \u4e2a\u9884\u6d4b\u8fb9\u6846\uff08\u7ea2\u8272\u7684\u6846\uff0cA-Y \u7f16\u53f7\u8868\u793a\uff0c\u5e76\u4e14\u6709\u4e00\u4e2a\u7f6e\u4fe1\u5ea6\u503c\uff09\uff1a \u6839\u636e\u4e0a\u56fe\u4ee5\u53ca\u8bf4\u660e\uff0c\u6211\u4eec\u53ef\u4ee5\u5217\u51fa\u4ee5\u4e0b\u8868\u683c\uff0c\u5176\u4e2d Images \u4ee3\u8868\u56fe\u7247\u7684\u7f16\u53f7\uff0cDetections \u4ee3\u8868\u9884\u6d4b\u8fb9\u6846\u7684\u7f16\u53f7\uff0cConfidences \u4ee3\u8868\u9884\u6d4b\u8fb9\u6846\u7684\u7f6e\u4fe1\u5ea6\uff0cTP or FP \u4ee3\u8868\u9884\u6d4b\u7684\u8fb9\u6846\u662f\u6807\u8bb0\u4e3a TP \u8fd8\u662f FP\uff08\u8ba4\u4e3a\u9884\u6d4b\u8fb9\u6846\u4e0e GT \u7684 IOU \u503c\u5927\u4e8e\u7b49\u4e8e 0.3 \u5c31\u6807\u8bb0\u4e3a TP\uff1b\u82e5\u4e00\u4e2a GT \u6709\u591a\u4e2a\u9884\u6d4b\u8fb9\u6846\uff0c\u5219\u8ba4\u4e3a IOU \u6700\u5927\u4e14\u5927\u4e8e\u7b49\u4e8e 0.3 \u7684\u9884\u6d4b\u6846\u6807\u8bb0\u4e3a TP\uff0c\u5176\u4ed6\u7684\u6807\u8bb0\u4e3a FP\uff0c\u5373\u4e00\u4e2a GT \u53ea\u80fd\u6709\u4e00\u4e2a\u9884\u6d4b\u6846\u6807\u8bb0\u4e3a TP\uff09\uff0c\u8fd9\u91cc\u7684 0.3 \u662f\u968f\u673a\u53d6\u7684\u4e00\u4e2a\u503c\u3002 \u901a\u8fc7\u4e0a\u8868\uff0c\u6211\u4eec\u53ef\u4ee5\u7ed8\u5236\u51fa P-R \u66f2\u7ebf\uff08\u56e0\u4e3a AP \u5c31\u662f P-R \u66f2\u7ebf\u4e0b\u9762\u7684\u9762\u79ef\uff09\uff0c\u4f46\u662f\u5728\u6b64\u4e4b\u524d\u6211\u4eec\u9700\u8981\u8ba1\u7b97\u51fa P-R \u66f2\u7ebf\u4e0a\u5404\u4e2a\u70b9\u7684\u5750\u6807\uff0c\u6839\u636e\u7f6e\u4fe1\u5ea6\u4ece\u5927\u5230\u5c0f\u6392\u5e8f\u6240\u6709\u7684\u9884\u6d4b\u6846\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u8ba1\u7b97 Precision \u548c Recall \u7684\u503c\uff0c\u89c1\u4e0b\u8868\u3002\uff08\u9700\u8981\u8bb0\u4f4f\u4e00\u4e2a\u53eb\u7d2f\u52a0\u7684\u6982\u5ff5\uff0c\u5c31\u662f\u4e0b\u56fe\u7684 ACC TP \u548c ACC FP\uff09 \u6807\u53f7\u4e3a 1 \u7684 Precision \u548c Recall \u7684\u8ba1\u7b97\u65b9\u5f0f\uff1aPrecision=TP/(TP+FP)=1/(1+0)=1\uff0cRecall=TP/(TP+FN)=TP/( all ground truths )=1/15=0.0666 \uff08 all ground truths \u4e0a\u9762\u6709\u5b9a\u4e49\u8fc7\u4e86 \uff09 \u6807\u53f7 2\uff1aPrecision=TP/(TP+FP)=1/(1+1)=0.5\uff0cRecall=TP/(TP+FN)=TP/( all ground truths )=1/15=0.0666 \u6807\u53f7 3\uff1aPrecision=TP/(TP+FP)=2/(2+1)=0.6666\uff0cRecall=TP/(TP+FN)=TP/( all ground truths )=2/15=0.1333 \u5176\u4ed6\u7684\u4f9d\u6b21\u7c7b\u63a8 \u7136\u540e\u5c31\u53ef\u4ee5\u7ed8\u5236\u51fa P-R \u66f2\u7ebf \u5f97\u5230 P-R \u66f2\u7ebf\u5c31\u53ef\u4ee5\u8ba1\u7b97 AP\uff08P-R \u66f2\u7ebf\u4e0b\u7684\u9762\u79ef\uff09\uff0c\u8981\u8ba1\u7b97 P-R \u4e0b\u65b9\u7684\u9762\u79ef\uff0c\u6709\u4e24\u79cd\u65b9\u6cd5\uff1a \u5728VOC2010\u4ee5\u524d\uff0c\u53ea\u9700\u8981\u9009\u53d6\u5f53Recall >= 0, 0.1, 0.2, ..., 1\u517111\u4e2a\u70b9\u65f6\u7684Precision\u6700\u5927\u503c\uff0c\u7136\u540eAP\u5c31\u662f\u8fd911\u4e2aPrecision\u7684\u5e73\u5747\u503c\uff0c\u53d6 11 \u4e2a\u70b9 [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1] \u7684\u63d2\u503c\u6240\u5f97 \u5f97\u5230\u4e00\u4e2a\u7c7b\u522b\u7684 AP \u7ed3\u679c\u5982\u4e0b\uff1a \u8981\u8ba1\u7b97 mAP\uff0c\u5c31\u628a\u6240\u6709\u7c7b\u522b\u7684 AP \u8ba1\u7b97\u51fa\u6765\uff0c\u7136\u540e\u6c42\u53d6\u5e73\u5747\u5373\u53ef\u3002 \u5728VOC2010\u53ca\u4ee5\u540e\uff0c\u9700\u8981\u9488\u5bf9\u6bcf\u4e00\u4e2a\u4e0d\u540c\u7684Recall\u503c\uff08\u5305\u62ec0\u548c1\uff09\uff0c\u9009\u53d6\u5176\u5927\u4e8e\u7b49\u4e8e\u8fd9\u4e9bRecall\u503c\u65f6\u7684Precision\u6700\u5927\u503c\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7136\u540e\u8ba1\u7b97PR\u66f2\u7ebf\u4e0b\u9762\u79ef\u4f5c\u4e3aAP\u503c\uff1a \u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a","title":"3.2 mAP\uff08Mean Average Precision\uff09"},{"location":"objectdection/01.overview/#4nms","text":"\u975e\u6781\u5927\u503c\u6291\u5236\uff08Non-Maximum Suppression\uff0cNMS\uff09\uff0c\u987e\u540d\u601d\u4e49\u5c31\u662f\u6291\u5236\u4e0d\u662f\u6781\u5927\u503c\u7684\u5143\u7d20\u3002\u4f8b\u5982\u5728\u884c\u4eba\u68c0\u6d4b\u4e2d\uff0c\u6ed1\u52a8\u7a97\u53e3\u7ecf\u63d0\u53d6\u7279\u5f81\uff0c\u7ecf\u5206\u7c7b\u5668\u5206\u7c7b\u8bc6\u522b\u540e\uff0c\u6bcf\u4e2a\u7a97\u53e3\u90fd\u4f1a\u5f97\u5230\u4e00\u4e2a\u5206\u6570\u3002\u4f46\u662f\u6ed1\u52a8\u7a97\u53e3\u4f1a\u5bfc\u81f4\u5f88\u591a\u7a97\u53e3\u4e0e\u5176\u4ed6\u7a97\u53e3\u5b58\u5728\u5305\u542b\u6216\u8005\u5927\u90e8\u5206\u4ea4\u53c9\u7684\u60c5\u51b5\u3002\u8fd9\u65f6\u5c31\u9700\u8981\u7528\u5230NMS\u6765\u9009\u53d6\u90a3\u4e9b\u90bb\u57df\u91cc\u5206\u6570\u6700\u9ad8\uff08\u662f\u884c\u4eba\u7684\u6982\u7387\u6700\u5927\uff09\uff0c\u5e76\u4e14\u6291\u5236\u90a3\u4e9b\u5206\u6570\u4f4e\u7684\u7a97\u53e3\u3002 NMS\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u6709\u7740\u975e\u5e38\u91cd\u8981\u7684\u5e94\u7528\uff0c\u5982\u89c6\u9891\u76ee\u6807\u8ddf\u8e2a\u3001\u6570\u636e\u6316\u6398\u30013D\u91cd\u5efa\u3001\u76ee\u6807\u8bc6\u522b\u4ee5\u53ca\u7eb9\u7406\u5206\u6790\u7b49 \u3002 \u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0cNMS\u7684\u76ee\u7684\u5c31\u662f\u8981\u53bb\u9664\u5197\u4f59\u7684\u68c0\u6d4b\u6846,\u4fdd\u7559\u6700\u597d\u7684\u4e00\u4e2a\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a NMS\u7684\u539f\u7406\u662f\u5bf9\u4e8e\u9884\u6d4b\u6846\u7684\u5217\u8868B\u53ca\u5176\u5bf9\u5e94\u7684\u7f6e\u4fe1\u5ea6S,\u9009\u62e9\u5177\u6709\u6700\u5927score\u7684\u68c0\u6d4b\u6846M,\u5c06\u5176\u4eceB\u96c6\u5408\u4e2d\u79fb\u9664\u5e76\u52a0\u5165\u5230\u6700\u7ec8\u7684\u68c0\u6d4b\u7ed3\u679cD\u4e2d.\u901a\u5e38\u5c06B\u4e2d\u5269\u4f59\u68c0\u6d4b\u6846\u4e2d\u4e0eM\u7684IoU\u5927\u4e8e\u9608\u503cNt\u7684\u6846\u4eceB\u4e2d\u79fb\u9664.\u91cd\u590d\u8fd9\u4e2a\u8fc7\u7a0b,\u76f4\u5230B\u4e3a\u7a7a\u3002 \u4f7f\u7528\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u9996\u5148\u662f\u68c0\u6d4b\u51fa\u4e00\u7cfb\u5217\u7684\u68c0\u6d4b\u6846 \u5c06\u68c0\u6d4b\u6846\u6309\u7167\u7c7b\u522b\u8fdb\u884c\u5206\u7c7b \u5bf9\u540c\u4e00\u7c7b\u522b\u7684\u68c0\u6d4b\u6846\u5e94\u7528NMS\u83b7\u53d6\u6700\u7ec8\u7684\u68c0\u6d4b\u7ed3\u679c \u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u770b\u4e9bNMS\u7684\u4f7f\u7528\u65b9\u6cd5\uff0c\u5047\u8bbe\u5b9a\u4f4d\u8f66\u8f86\uff0c\u7b97\u6cd5\u5c31\u627e\u51fa\u4e86\u4e00\u7cfb\u5217\u7684\u77e9\u5f62\u6846\uff0c\u6211\u4eec\u9700\u8981\u5224\u522b\u54ea\u4e9b\u77e9\u5f62\u6846\u662f\u6ca1\u7528\u7684\uff0c\u9700\u8981\u4f7f\u7528NMS\u7684\u65b9\u6cd5\u6765\u5b9e\u73b0\u3002 \u5047\u8bbe\u73b0\u5728\u68c0\u6d4b\u7a97\u53e3\u6709\uff1aA\u3001B\u3001C\u3001D\u3001E 5\u4e2a\u5019\u9009\u6846\uff0c\u63a5\u4e0b\u6765\u8fdb\u884c\u8fed\u4ee3\u8ba1\u7b97\uff1a \u7b2c\u4e00\u8f6e\uff1a\u56e0\u4e3aB\u662f\u5f97\u5206\u6700\u9ad8\u7684\uff0c\u4e0eB\u7684IoU\uff1e0.5\u5220\u9664\u3002A\uff0cCDE\u4e2d\u73b0\u5728\u4e0eB\u8ba1\u7b97IoU\uff0cDE\u7ed3\u679c\uff1e0.5\uff0c\u5254\u9664DE\uff0cB\u4f5c\u4e3a\u4e00\u4e2a\u9884\u6d4b\u7ed3\u679c\uff0c\u6709\u4e2a\u68c0\u6d4b\u6846\u7559\u4e0bB\uff0c\u653e\u5165\u96c6\u5408 \u7b2c\u4e8c\u8f6e\uff1aA\u7684\u5f97\u5206\u6700\u9ad8\uff0c\u4e0eA\u8ba1\u7b97IoU\uff0cC\u7684\u7ed3\u679c\uff1e0.5\uff0c\u5254\u9664C\uff0cA\u4f5c\u4e3a\u4e00\u4e2a\u7ed3\u679c \u6700\u7ec8\u7ed3\u679c\u4e3a\u5728\u8fd9\u4e2a5\u4e2a\u4e2d\u68c0\u6d4b\u51fa\u4e86\u4e24\u4e2a\u76ee\u6807\u4e3aA\u548cB\u3002 \u5355\u7c7b\u522b\u7684NMS\u7684\u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a import numpy as np def nms ( bboxes , confidence_score , threshold ): \"\"\"\u975e\u6781\u5927\u6291\u5236\u8fc7\u7a0b :param bboxes: \u540c\u7c7b\u522b\u5019\u9009\u6846\u5750\u6807 :param confidence: \u540c\u7c7b\u522b\u5019\u9009\u6846\u5206\u6570 :param threshold: iou\u9608\u503c :return: \"\"\" # 1\u3001\u4f20\u5165\u65e0\u5019\u9009\u6846\u8fd4\u56de\u7a7a if len ( bboxes ) == 0 : return [], [] # \u5f3a\u8f6c\u6570\u7ec4 bboxes = np . array ( bboxes ) score = np . array ( confidence_score ) # \u53d6\u51fan\u4e2a\u7684\u6781\u5750\u6807\u70b9 x1 = bboxes [:, 0 ] y1 = bboxes [:, 1 ] x2 = bboxes [:, 2 ] y2 = bboxes [:, 3 ] # 2\u3001\u5bf9\u5019\u9009\u6846\u8fdb\u884cNMS\u7b5b\u9009 # \u8fd4\u56de\u7684\u6846\u5750\u6807\u548c\u5206\u6570 picked_boxes = [] picked_score = [] # \u5bf9\u7f6e\u4fe1\u5ea6\u8fdb\u884c\u6392\u5e8f, \u83b7\u53d6\u6392\u5e8f\u540e\u7684\u4e0b\u6807\u5e8f\u53f7, argsort\u9ed8\u8ba4\u4ece\u5c0f\u5230\u5927\u6392\u5e8f order = np . argsort ( score ) areas = ( x2 - x1 ) * ( y2 - y1 ) while order . size > 0 : # \u5c06\u5f53\u524d\u7f6e\u4fe1\u5ea6\u6700\u5927\u7684\u6846\u52a0\u5165\u8fd4\u56de\u503c\u5217\u8868\u4e2d index = order [ - 1 ] #\u4fdd\u7559\u8be5\u7c7b\u5269\u4f59box\u4e2d\u5f97\u5206\u6700\u9ad8\u7684\u4e00\u4e2a picked_boxes . append ( bboxes [ index ]) picked_score . append ( confidence_score [ index ]) # \u83b7\u53d6\u5f53\u524d\u7f6e\u4fe1\u5ea6\u6700\u5927\u7684\u5019\u9009\u6846\u4e0e\u5176\u4ed6\u4efb\u610f\u5019\u9009\u6846\u7684\u76f8\u4ea4\u9762\u79ef x11 = np . maximum ( x1 [ index ], x1 [ order [: - 1 ]]) y11 = np . maximum ( y1 [ index ], y1 [ order [: - 1 ]]) x22 = np . minimum ( x2 [ index ], x2 [ order [: - 1 ]]) y22 = np . minimum ( y2 [ index ], y2 [ order [: - 1 ]]) # \u8ba1\u7b97\u76f8\u4ea4\u7684\u9762\u79ef,\u4e0d\u91cd\u53e0\u65f6\u9762\u79ef\u4e3a0 w = np . maximum ( 0.0 , x22 - x11 ) h = np . maximum ( 0.0 , y22 - y11 ) intersection = w * h # \u5229\u7528\u76f8\u4ea4\u7684\u9762\u79ef\u548c\u4e24\u4e2a\u6846\u81ea\u8eab\u7684\u9762\u79ef\u8ba1\u7b97\u6846\u7684\u4ea4\u5e76\u6bd4 ratio = intersection / ( areas [ index ] + areas [ order [: - 1 ]] - intersection ) # \u4fdd\u7559IoU\u5c0f\u4e8e\u9608\u503c\u7684box keep_boxes_indics = np . where ( ratio < threshold ) # \u4fdd\u7559\u5269\u4f59\u7684\u6846 order = order [ keep_boxes_indics ] # \u8fd4\u56deNMS\u540e\u7684\u6846\u53ca\u5206\u7c7b\u7ed3\u679c return picked_boxes , picked_score \u5047\u8bbe\u6709\u68c0\u6d4b\u7ed3\u679c\u5982\u4e0b\uff1a bounding = [( 187 , 82 , 337 , 317 ), ( 150 , 67 , 305 , 282 ), ( 246 , 121 , 368 , 304 )] confidence_score = [ 0.9 , 0.65 , 0.8 ] threshold = 0.3 picked_boxes , picked_score = nms ( bounding , confidence_score , threshold ) print ( '\u9608\u503cthreshold\u4e3a:' , threshold ) print ( 'NMS\u540e\u5f97\u5230\u7684bbox\u662f\uff1a' , picked_boxes ) print ( 'NMS\u540e\u5f97\u5230\u7684bbox\u7684confidences\u662f\uff1a' , picked_score ) \u8fd4\u56de\u7ed3\u679c\uff1a \u9608\u503cthreshold\u4e3a : 0.3 NMS\u540e\u5f97\u5230\u7684bbox\u662f \uff1a [ array ([ 187 , 82 , 337 , 317 ])] NMS\u540e\u5f97\u5230\u7684bbox\u7684confidences\u662f \uff1a [ 0.9 ]","title":"4.NMS\uff08\u975e\u6781\u5927\u503c\u6291\u5236\uff09"},{"location":"objectdection/01.overview/#5","text":"\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e3b\u8981\u5206\u4e3atwo-stage\uff08\u4e24\u9636\u6bb5\uff09\u548cone-stage\uff08\u5355\u9636\u6bb5\uff09\u4e24\u7c7b\uff1a two-stage\u7684\u7b97\u6cd5 \u5148\u7531\u7b97\u6cd5\u751f\u6210\u4e00\u7cfb\u5217\u4f5c\u4e3a\u6837\u672c\u7684\u5019\u9009\u6846\uff0c\u518d\u901a\u8fc7\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u6837\u672c\u5206\u7c7b\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4e3b\u8981\u901a\u8fc7\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u5b8c\u6210\u76ee\u6807\u68c0\u6d4b\u8fc7\u7a0b\uff0c\u5176\u63d0\u53d6\u7684\u662fCNN\u5377\u79ef\u7279\u5f81\uff0c\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u7b5b\u9009\u548c\u76ee\u6807\u68c0\u6d4b\u4e24\u90e8\u5206\u3002\u7f51\u7edc\u7684\u51c6\u786e\u5ea6\u9ad8\u3001\u901f\u5ea6\u76f8\u5bf9\u8f83\u6162\u3002 two-stages\u7b97\u6cd5\u7684\u4ee3\u8868\u662fRCNN\u7cfb\u5217\uff1aR-CNN\u5230Faster R-CNN\u7f51\u7edc One-stage\u7684\u7b97\u6cd5 \u76f4\u63a5\u901a\u8fc7\u4e3b\u5e72\u7f51\u7edc\u7ed9\u51fa\u76ee\u6807\u7684\u7c7b\u522b\u548c\u4f4d\u7f6e\u4fe1\u606f\uff0c\u6ca1\u6709\u4f7f\u7528\u5019\u9009\u533a\u57df\u7684\u7b5b\u9009\u7f51\u8def\uff0c\u8fd9\u79cd\u7b97\u6cd5\u901f\u5ea6\u5feb\uff0c\u4f46\u662f\u7cbe\u5ea6\u76f8\u5bf9Two-stage\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u964d\u4f4e\u4e86\u5f88\u591a\u3002 one-stage\u7b97\u6cd5\u7684\u4ee3\u8868\u662f\uff1a YOLO\u7cfb\u5217\uff1aYOLOv1\u3001YOLOv2\u3001YOLOv3\u3001 SSD\u7b49 \u603b\u7ed3 \u4e86\u89e3\u76ee\u6807\u68c0\u6d4b\u7684\u4efb\u52a1 \u627e\u51fa\u56fe\u50cf\u4e2d\u6240\u6709\u611f\u5174\u8da3\u7684\u76ee\u6807\uff0c\u5e76\u786e\u5b9a\u5b83\u4eec\u7684\u7c7b\u522b\u548c\u4f4d\u7f6e \u77e5\u9053\u76ee\u6807\u68c0\u6d4b\u7684\u5e38\u7528\u6570\u636e\u96c6 PASCAL VOC\u6570\u636e\u96c6 \u548c MS COCO\u6570\u636e\u96c6 \u77e5\u9053\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u7684\u8bc4\u4ef7\u6307\u6807 IOU\u548cmAP \u638c\u63e1\u975e\u6781\u5927\u503cNMS\u7b97\u6cd5\u7684\u5e94\u7528 \u8981\u53bb\u9664\u5197\u4f59\u7684\u68c0\u6d4b\u6846,\u4fdd\u7559\u6700\u597d\u7684\u4e00\u4e2a \u4e86\u89e3\u5e38\u7528\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5206\u7c7b two-stage\uff08\u4e24\u9636\u6bb5\uff09\u548cone-stage\uff08\u5355\u9636\u6bb5\uff09","title":"5.\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u5206\u7c7b"},{"location":"objectdection/02.RCNN/","text":"4.2 R-CNN\u7f51\u7edc\u57fa\u7840 \u00b6 \u5b66\u4e60\u76ee\u6807 \u4e86\u89e3Overfeat\u6a21\u578b\u7684\u79fb\u52a8\u7a97\u53e3\u65b9\u6cd5 \u4e86\u89e3RCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u4e86\u89e3fastRCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u77e5\u9053\u591a\u4efb\u52a1\u635f\u5931 1.Overfeat\u6a21\u578b \u00b6 Overfeat\u65b9\u6cd5\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff0c\u4e5f\u5c31\u662f\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u548c\u795e\u7ecf\u7f51\u7edc\u6765\u68c0\u6d4b\u76ee\u6807\u3002\u6ed1\u52a8\u7a97\u53e3\u4f7f\u7528\u56fa\u5b9a\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u77e9\u5f62\u533a\u57df\uff0c\u5728\u56fe\u50cf\u4e0a\u201c\u6ed1\u52a8\u201d\uff0c\u5e76\u5c06\u626b\u63cf\u7ed3\u679c\u9001\u5165\u5230\u795e\u7ecf\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\u3002 \u4f8b\u5982\u8981\u68c0\u6d4b\u6c7d\u8f66\uff0c\u5c31\u4f7f\u7528\u4e0b\u56fe\u4e2d\u7ea2\u8272\u6ed1\u52a8\u7a97\u53e3\u8fdb\u884c\u626b\u63cf\uff0c\u5c06\u6240\u6709\u7684\u626b\u63cf\u7ed3\u679c\u9001\u5165\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u6c7d\u8f66\u7684\u68c0\u6d4b\u7ed3\u679c\u3002 \u8fd9\u79cd\u65b9\u6cd5\u7c7b\u4f3c\u4e00\u79cd\u66b4\u529b\u7a77\u4e3e\u7684\u65b9\u5f0f\uff0c\u4f1a\u6d88\u8017\u5927\u91cf\u7684\u8ba1\u7b97\u529b\uff0c\u5e76\u4e14\u7531\u4e8e\u7a97\u53e3\u5927\u5c0f\u95ee\u9898\u53ef\u80fd\u4f1a\u9020\u6210\u6548\u679c\u4e0d\u51c6\u786e\u3002 2.RCNN\u6a21\u578b \u00b6 2014\u5e74\u63d0\u51faR-CNN\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u4e0d\u518d\u4f7f\u7528\u66b4\u529b\u7a77\u4e3e\u7684\u65b9\u6cd5\uff0c\u800c\u662f\u4f7f\u7528\u5019\u9009\u533a\u57df\u65b9\u6cd5\uff08region proposal method\uff09\u521b\u5efa\u76ee\u6807\u68c0\u6d4b\u7684\u533a\u57df\u6765\u5b8c\u6210\u76ee\u6807\u68c0\u6d4b\u7684\u4efb\u52a1\uff0cR-CNN\u662f\u4ee5\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e3a\u57fa\u7840\u7684\u76ee\u6807\u68c0\u6d4b\u7684\u6a21\u578b \uff0c\u4ee5R-CNN\u4e3a\u57fa\u70b9\uff0c\u540e\u7eed\u7684Fast R-CNN\u3001Faster R-CNN\u6a21\u578b\u90fd\u5ef6\u7eed\u4e86\u8fd9\u79cd\u76ee\u6807\u68c0\u6d4b\u601d\u8def\u3002 2.1 \u7b97\u6cd5\u6d41\u7a0b \u00b6 RCNN\u7684\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6b65\u9aa4\u662f\uff1a \u5019\u9009\u533a\u57df\u751f\u6210 \uff1a\u4f7f\u7528\u9009\u62e9\u6027\u641c\u7d22\uff08Selective Search\uff09\u7684\u65b9\u6cd5\u627e\u51fa\u56fe\u7247\u4e2d\u53ef\u80fd\u5b58\u5728\u76ee\u6807\u7684\u4faf\u9009\u533a\u57df CNN\u7f51\u7edc\u63d0\u53d6\u7279\u5f81 \uff1a\u9009\u53d6\u9884\u8bad\u7ec3\u5377\u79ef\u795e\u7ecf\u7f51\u7f51\u7edc\uff08AlexNet\u6216VGG\uff09\u7528\u4e8e\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u3002 \u76ee\u6807\u5206\u7c7b \uff1a\u8bad\u7ec3\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u6765\u8fa8\u522b\u76ee\u6807\u7269\u4f53\u548c\u80cc\u666f\uff0c\u5bf9\u6bcf\u4e2a\u7c7b\u522b\uff0c\u90fd\u8981\u8bad\u7ec3\u4e00\u4e2a\u4e8c\u5143SVM\u3002 \u76ee\u6807\u5b9a\u4f4d \uff1a\u8bad\u7ec3\u4e00\u4e2a\u7ebf\u6027\u56de\u5f52\u6a21\u578b\uff0c\u4e3a\u6bcf\u4e2a\u8fa8\u8bc6\u5230\u7684\u7269\u4f53\u751f\u6210\u66f4\u7cbe\u786e\u7684\u8fb9\u754c\u6846\u3002 2.1.1 \u5019\u9009\u533a\u57df\u751f\u6210\u3010\u4e86\u89e3\u3011 \u00b6 \u5728**\u9009\u62e9\u6027\u641c\u7d22\uff08SelectiveSearch\uff0cSS\uff09\u4e2d**\uff0c\u4f7f\u7528\u8bed\u4e49\u5206\u5272\u7684\u65b9\u6cd5\uff0c\u5b83\u5c06\u989c\u8272\u3001\u8fb9\u754c\u3001\u7eb9\u7406\u7b49\u4fe1\u606f\u4f5c\u4e3a\u5408\u5e76\u6761\u4ef6\uff0c\u91c7\u7528\u591a\u5c3a\u5ea6\u7684\u7efc\u5408\u65b9\u6cd5\uff0c\u5c06\u56fe\u50cf\u5728\u50cf\u7d20\u7ea7\u4e0a\u5212\u5206\u51fa\u4e00\u7cfb\u5217\u7684\u533a\u57df\uff0c\u8fd9\u4e9b\u533a\u57df\u8981\u8fdc\u8fdc\u5c11\u4e8e\u4f20\u7edf\u7684\u6ed1\u52a8\u7a97\u53e3\u7684\u7a77\u4e3e\u6cd5\u4ea7\u751f\u7684\u5019\u9009\u533a\u57df\u3002 SelectiveSearch\u5728\u4e00\u5f20\u56fe\u7247\u4e0a\u63d0\u53d6\u51fa\u6765\u7ea62000\u4e2a\u4faf\u9009\u533a\u57df\uff0c \u9700\u8981\u6ce8\u610f\u7684\u662f\u8fd9\u4e9b\u5019\u9009\u533a\u57df\u7684\u957f\u5bbd\u4e0d\u56fa\u5b9a \u3002 \u800c\u4f7f\u7528CNN\u63d0\u53d6\u5019\u9009\u533a\u57df\u7684\u7279\u5f81\u5411\u91cf\uff0c\u9700\u8981\u63a5\u53d7\u56fa\u5b9a\u957f\u5ea6\u7684\u8f93\u5165\uff0c\u6240\u4ee5\u9700\u8981\u5bf9\u5019\u9009\u533a\u57df\u505a\u4e00\u4e9b\u5c3a\u5bf8\u4e0a\u7684\u4fee\u6539\u3002 2.1.2 CNN\u7f51\u7edc\u63d0\u53d6\u7279\u5f81 \u00b6 \u91c7\u7528\u9884\u8bad\u7ec3\u6a21\u578b(AlexNet\u6216VGG)\u5728\u751f\u6210\u7684\u5019\u9009\u533a\u57df\u4e0a\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5c06\u63d0\u53d6\u597d\u7684\u7279\u5f81\u4fdd\u5b58\u5728\u78c1\u76d8\u4e2d\uff0c\u7528\u4e8e\u540e\u7eed\u6b65\u9aa4\u7684\u5206\u7c7b\u548c\u56de\u5f52\u3002 1.\u5168\u8fde\u63a5\u5c42\u7684\u8f93\u5165\u6570\u636e\u7684\u5c3a\u5bf8\u662f\u56fa\u5b9a\u7684\uff0c\u56e0\u6b64\u5728\u5c06\u5019\u9009\u533a\u57df\u9001\u5165CNN\u7f51\u7edc\u4e2d\u65f6\uff0c\u9700\u8fdb\u884c\u88c1\u526a\u6216\u53d8\u5f62\u4e3a\u56fa\u5b9a\u7684\u5c3a\u5bf8\uff0c\u5728\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u3002 2.\u9884\u8bad\u7ec3\u6a21\u578b\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\uff0c\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\u662f1000\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u9700\u8981\u5c06\u5176\u6539\u4e3aN+1(N\u4e3a\u76ee\u6807\u7c7b\u522b\u7684\u6570\u76ee\uff0c\u4f8b\u5982VOC\u6570\u636e\u96c6\u4e2dN=20\uff0ccoco\u6570\u636e\u96c6\u4e2dN=80\uff0c1\u662f\u52a0\u4e00\u4e2a\u80cc\u666f)\u540e\uff0c\u8fdb\u884c\u5fae\u8c03\u5373\u53ef\u3002 3.\u5229\u7528\u5fae\u8c03\u540e\u7684CNN\u7f51\u7edc\uff0c\u63d0\u53d6\u6bcf\u4e00\u4e2a\u5019\u9009\u533a\u57df\u7684\u7279\u5f81\uff0c\u83b7\u53d6\u4e00\u4e2a4096\u7ef4\u7684\u7279\u5f81\uff0c\u4e00\u5e45\u56fe\u50cf\u5c31\u662f2000x4096\u7ef4\u7279\u5f81\u5b58\u50a8\u5230\u78c1\u76d8\u4e2d\u3002 2.1.3 \u76ee\u6807\u5206\u7c7b\uff08SVM\uff09 \u00b6 \u5047\u8bbe\u6211\u4eec\u8981\u68c0\u6d4b\u732b\u72d7\u4e24\u4e2a\u7c7b\u522b\uff0c\u90a3\u6211\u4eec\u9700\u8981\u8bad\u7ec3\u732b\u548c\u72d7\u4e24\u4e2a\u4e0d\u540c\u7c7b\u522b\u7684SVM\u5206\u7c7b\u5668\uff0c\u7136\u540e\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u5206\u7c7b\u5668\u5bf9\u4e00\u5e45\u56fe\u50cf\u4e2d2000\u4e2a\u5019\u9009\u533a\u57df\u7684\u7279\u5f81\u5411\u91cf\u5206\u522b\u5224\u65ad\u4e00\u6b21\uff0c\u8fd9\u6837\u5f97\u51fa[2000, 2]\u7684\u5f97\u5206\u77e9\u9635\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5bf9\u4e8eN\u4e2a\u7c7b\u522b\u7684\u68c0\u6d4b\u4efb\u52a1\uff0c\u9700\u8981\u8bad\u7ec3N\uff08\u76ee\u6807\u7c7b\u522b\u6570\u76ee\uff09\u4e2aSVM\u5206\u7c7b\u5668\uff0c\u5bf9\u5019\u9009\u533a\u57df\u7684\u7279\u5f81\u5411\u91cf\uff084096\u7ef4\uff09\u8fdb\u884c\u4e8c\u5206\u7c7b\uff0c\u5224\u65ad\u5176\u662f\u67d0\u4e00\u7c7b\u522b\u7684\u76ee\u6807\uff0c\u8fd8\u662f\u80cc\u666f\u6765\u5b8c\u6210\u76ee\u6807\u5206\u7c7b\u3002 2.1.4 \u76ee\u6807\u5b9a\u4f4d \u00b6 \u901a\u8fc7\u9009\u62e9\u6027\u641c\u7d22\u83b7\u53d6\u7684\u76ee\u6807\u4f4d\u7f6e\u4e0d\u662f\u975e\u5e38\u7684\u51c6\u786e\uff0c\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8bad\u7ec3\u4e00\u4e2a\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u5728\u7ed9\u5b9a\u7684\u5019\u9009\u533a\u57df\u7684\u7ed3\u679c\u4e0a\u53bb\u9884\u6d4b\u4e00\u4e2a\u65b0\u7684\u68c0\u6d4b\u7a97\u53e3\uff0c\u80fd\u591f\u83b7\u5f97\u66f4\u7cbe\u786e\u7684\u4f4d\u7f6e\u3002\u4fee\u6b63\u8fc7\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u901a\u8fc7\u8bad\u7ec3\u4e00\u4e2a\u56de\u5f52\u5668\u6765\u5bf9\u5019\u9009\u533a\u57df\u7684\u8303\u56f4\u8fdb\u884c\u4e00\u4e2a\u8c03\u6574\uff0c\u8fd9\u4e9b\u5019\u9009\u533a\u57df\u6700\u5f00\u59cb\u53ea\u662f\u7528\u9009\u62e9\u6027\u641c\u7d22\u7684\u65b9\u6cd5\u7c97\u7565\u5f97\u5230\u7684\uff0c\u901a\u8fc7\u8c03\u6574\u4e4b\u540e\u5f97\u5230\u66f4\u7cbe\u786e\u7684\u4f4d\u7f6e\uff0c\u5982\u4e0b\u6240\u793a\uff1a 2.1.5 \u9884\u6d4b\u8fc7\u7a0b \u00b6 \u4f7f\u7528\u9009\u62e9\u6027\u641c\u7d22\u7684\u65b9\u6cd5\u4ece\u4e00\u5f20\u56fe\u7247\u4e2d\u63d0\u53d62000\u4e2a\u5019\u9009\u533a\u57df\uff0c\u5c06\u6bcf\u4e2a\u533a\u57df\u9001\u5165CNN\u7f51\u7edc\u4e2d\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u7136\u540e\u9001\u5165\u5230SVM\u4e2d\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u4f7f\u7528\u5019\u9009\u6846\u56de\u5f52\u5668\uff0c\u8ba1\u7b97\u51fa\u6bcf\u4e2a\u5019\u9009\u533a\u57df\u7684\u4f4d\u7f6e\u3002 \u5019\u9009\u533a\u57df\u8f83\u591a\uff0c\u67092000\u4e2a\uff0c\u9700\u8981\u5254\u9664\u6389\u90e8\u5206\u68c0\u6d4b\u7ed3\u679c\u3002 \u9488\u5bf9\u6bcf\u4e2a\u7c7b\uff0c\u901a\u8fc7\u8ba1\u7b97IOU,\u91c7\u53d6\u975e\u6700\u5927\u503c\u6291\u5236NMS\u7684\u65b9\u6cd5\uff0c\u4fdd\u7559\u6bd4\u8f83\u597d\u7684\u68c0\u6d4b\u7ed3\u679c\u3002 2.2 \u7b97\u6cd5\u603b\u7ed3 \u00b6 1\u3001\u8bad\u7ec3\u9636\u6bb5\u591a\uff0c\u8bad\u7ec3\u8017\u65f6\uff1a \u5fae\u8c03CNN\u7f51\u7edc+\u8bad\u7ec3SVM+\u8bad\u7ec3\u8fb9\u6846\u56de\u5f52\u5668\u3002 2\u3001\u9884\u6d4b\u901f\u5ea6\u6162: \u4f7f\u7528GPU, VGG16\u6a21\u578b\u5904\u7406\u4e00\u5f20\u56fe\u50cf\u9700\u898147s \u3002 3\u3001\u5360\u7528\u78c1\u76d8\u7a7a\u95f4\u5927\uff1a5000\u5f20\u56fe\u50cf\u4ea7\u751f\u51e0\u767eG\u7684\u7279\u5f81\u6587\u4ef6\u3002 4\u3001\u6570\u636e\u7684\u5f62\u72b6\u53d8\u5316\uff1a\u5019\u9009\u533a\u57df\u8981\u7ecf\u8fc7\u7f29\u653e\u6765\u56fa\u5b9a\u5927\u5c0f\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u76ee\u6807\u7684\u4e0d\u53d8\u5f62 3. Fast RCNN\u6a21\u578b \u00b6 \u8003\u8651\u5230R-CNN\u5b58\u5728\u7684\u95ee\u9898\uff0c2015\u5e74\u63d0\u51fa\u4e86\u4e00\u4e2a\u6539\u5584\u6a21\u578b:Fast R-CNN\u3002 \u76f8\u6bd4\u4e8eR-CNN, Fast R-CNN\u4e3b\u8981\u5728\u4ee5\u4e0b\u4e09\u4e2a\u65b9\u9762\u8fdb\u884c\u4e86\u6539\u8fdb\uff1a 1\u3001\u63d0\u9ad8\u8bad\u7ec3\u548c\u9884\u6d4b\u7684\u901f\u5ea6 R-CNN\u9996\u5148\u4ece\u6d4b\u8bd5\u56fe\u4e2d\u63d0\u53d62000\u4e2a\u5019\u9009\u533a\u57df\uff0c\u7136\u540e\u5c06\u8fd92000\u4e2a\u5019\u9009\u533a\u57df\u5206\u522b\u8f93\u5165\u5230\u9884\u8bad\u7ec3\u597d\u7684CNN\u4e2d\u63d0\u53d6\u7279\u5f81\u3002\u7531\u4e8e\u5019\u9009\u533a\u57df\u6709\u5927\u91cf\u7684\u91cd\u53e0\uff0c\u8fd9\u79cd\u63d0\u53d6\u7279\u5f81\u7684\u65b9\u6cd5\uff0c\u5c31\u4f1a\u91cd\u590d\u7684\u8ba1\u7b97\u91cd\u53e0\u533a\u57df\u7684\u7279\u5f81\u3002\u5728Fast-RCNN\u4e2d\uff0c\u5c06\u6574\u5f20\u56fe\u8f93\u5165\u5230CNN\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u5c06\u5019\u9009\u533a\u57df\u6620\u5c04\u5230\u7279\u5f81\u56fe\u4e0a\uff0c\u8fd9\u6837\u5c31\u907f\u514d\u4e86\u5bf9\u56fe\u50cf\u533a\u57df\u8fdb\u884c\u91cd\u590d\u5904\u7406\uff0c\u63d0\u9ad8\u6548\u7387\u51cf\u5c11\u65f6\u95f4\u3002 2\u3001\u4e0d\u9700\u8981\u989d\u5916\u7684\u7a7a\u95f4\u4fdd\u5b58CNN\u7f51\u7edc\u63d0\u53d6\u7684\u7279\u5f81\u5411\u91cf RCNN\u4e2d\u9700\u8981\u5c06\u63d0\u53d6\u5230\u7684\u7279\u5f81\u4fdd\u5b58\u4e0b\u6765\uff0c\u7528\u4e8e\u4e3a\u6bcf\u4e2a\u7c7b\u8bad\u7ec3\u5355\u72ec\u7684SVM\u5206\u7c7b\u5668\u548c\u8fb9\u6846\u56de\u5f52\u5668\u3002\u5728Fast-RCNN\u4e2d\uff0c\u5c06\u7c7b\u522b\u5224\u65ad\u548c\u8fb9\u6846\u56de\u5f52\u7edf\u4e00\u4f7f\u7528CNN\u5b9e\u73b0\uff0c\u4e0d\u9700\u8981\u5728\u989d\u5916\u7684\u7a7a\u95f4\u5b58\u50a8\u7279\u5f81\u3002 3\u3001\u4e0d\u5728\u76f4\u63a5\u5bf9\u5019\u9009\u533a\u57df\u8fdb\u884c\u7f29\u653e RCNN\u4e2d\u9700\u8981\u5bf9\u5019\u9009\u533a\u57df\u8fdb\u884c\u7f29\u653e\u9001\u5165CNN\u4e2d\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5728Fast-RCNN\u4e2d\u4f7f\u7528ROIpooling\u7684\u65b9\u6cd5\u8fdb\u884c\u5c3a\u5bf8\u7684\u8c03\u6574\u3002 3.1 \u7b97\u6cd5\u6d41\u7a0b \u00b6 Fast_RCNN\u7684\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6b65\u9aa4\u662f\uff1a 1\u3001 \u5019\u9009\u533a\u57df\u751f\u6210 \uff1a\u4f7f\u7528\u9009\u62e9\u6027\u641c\u7d22\uff08Selective Search\uff09\u7684\u65b9\u6cd5\u627e\u51fa\u56fe\u7247\u4e2d\u53ef\u80fd\u5b58\u5728\u76ee\u6807\u7684\u4faf\u9009\u533a\u57df\uff0c\u53ea\u9700\u8981\u5019\u9009\u533a\u57df\u7684\u4f4d\u7f6e\u4fe1\u606f 2\u3001 CNN\u7f51\u7edc\u7279\u5f81\u63d0\u53d6 \uff1a\u5c06\u6574\u5f20\u56fe\u50cf\u8f93\u5165\u5230CNN\u7f51\u7edc\u4e2d\uff0c\u5f97\u5230\u6574\u526f\u56fe\u7684\u7279\u5f81\u56fe\uff0c\u5e76\u5c06\u4e0a\u4e00\u6b65\u83b7\u53d6\u7684\u5019\u9009\u533a\u57df\u4f4d\u7f6e\u4ece\u539f\u56fe\u6620\u5c04\u5230\u8be5\u7279\u5f81\u56fe\u4e0a 3\u3001 ROIPooling : \u5bf9\u4e8e\u6bcf\u4e2a\u7279\u5f81\u56fe\u4e0a\u5019\u9009\u6846\uff0cRoI pooling\u5c42\u4ece\u7279\u5f81\u56fe\u4e2d\u63d0\u53d6\u56fa\u5b9a\u957f\u5ea6\u7684\u7279\u5f81\u5411\u91cf\u6bcf\u4e2a\u7279\u5f81\u5411\u91cf\u88ab\u9001\u5165\u4e00\u7cfb\u5217\u5168\u8fde\u63a5\uff08fc\uff09\u5c42\u4e2d\u3002 4\u3001 \u76ee\u6807\u68c0\u6d4b \uff1a\u5206\u4e24\u90e8\u5206\u5b8c\u6210\uff0c\u4e00\u4e2a\u8f93\u51fa\u5404\u7c7b\u522b\u52a0\u4e0a1\u4e2a\u80cc\u666f\u7c7b\u522b\u7684Softmax\u6982\u7387\u4f30\u8ba1\uff0c\u53e6\u4e00\u4e2a\u4e3a\u5404\u7c7b\u522b\u7684\u6bcf\u4e00\u4e2a\u7c7b\u522b\u8f93\u51fa\u56db\u4e2a\u5b9e\u6570\u503c\uff0c\u6765\u786e\u5b9a\u76ee\u6807\u7684\u4f4d\u7f6e\u4fe1\u606f\u3002 3.1.1 \u5019\u9009\u533a\u57df\u751f\u6210\u3010\u4e86\u89e3\u3011 \u00b6 \u4e0eRCNN\u4e2d\u4e00\u6837\uff0c\u4e0d\u518d\u8d58\u8ff0 3.1.2 CNN\u7f51\u7edc\u7279\u5f81\u63d0\u53d6 \u00b6 \u4e0eRCNN\u4e2d\u4e00\u6837\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u3002 3.1.3 ROI Pooling \u00b6 \u5019\u9009\u533a\u57df\u4ece\u539f\u56fe\u6620\u5c04\u5230\u7279\u5f81\u56fe\u4e2d\u540e\uff0c\u8fdb\u884cROIpooling\u7684\u8ba1\u7b97\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a ROI Pooling\u5c42\u4f7f\u7528\u6700\u5927\u6c60\u5316\u5c06\u8f93\u5165\u7684\u7279\u5f81\u56fe\u4e2d\u7684\u4efb\u610f\u533a\u57df\uff08\u5019\u9009\u533a\u57df\u5bf9\u5e94\u7684\u533a\u57df\uff09\u5185\u7684\u7279\u5f81\u8f6c\u5316\u4e3a\u56fa\u5b9a\u7684\ud835\udc3b\u00d7\ud835\udc4a\u7684\u7279\u5f81\u56fe\uff0c\u5176\u4e2d\ud835\udc3b\u548c\ud835\udc4a\u662f\u8d85\u53c2\u6570\u3002 \u5bf9\u4e8e\u4efb\u610f\u8f93\u5165\u7684\u210e\u00d7\ud835\udc64\u7684\u5019\u9009\u533a\u57df\uff0c\u5c06\u5176\u5206\u5272\u4e3a\ud835\udc3b\u00d7\ud835\udc4a\u7684\u5b50\u7f51\u683c\uff0c\u6bcf\u4e2a\u5b50\u7f51\u683c\u7684\u5927\u5c0f\u4e3a\uff1a(h/H) x (w/W)\uff0c\u53d6\u6bcf\u4e2a\u5b50\u7f51\u683c\u4e2d\u7684\u6700\u5927\u503c\uff0c\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u5904\u7406\u3002 \u4f7f\u7528ROI Pooling\u5c42\u66ff\u6362\u9884\u8bad\u7ec3\u7f51\u7edc\u4e2d\u6700\u540e\u7684\u6c60\u5316\u5c42\uff0c\u5e76\u5c06\u5e76\u5c06\u8d85\u53c2\ud835\udc3b,\ud835\udc4a\u8bbe\u7f6e\u4e3a\u548c\u7f51\u7edc\u7b2c\u4e00\u4e2a\u5168\u8fde\u63a5\u517c\u5bb9\u7684\u503c\uff0c\u4f8b\u5982VGG16\uff0c\u8bbe\ud835\udc3b=\ud835\udc4a=7\u3002 3.1.4 \u76ee\u6807\u5206\u7c7b\u548c\u56de\u5f52 \u00b6 \u539f\u7f51\u7edc\u7684\u6700\u540e\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\u66ff\u6362\u4e3a\u4e24\u4e2a\u540c\u7ea7\u5c42:K+1\u4e2a\u7c7b\u522b\u7684SoftMax\u5206\u7c7b\u5c42\u548c\u8fb9\u6846\u7684\u56de\u5f52\u5c42\u3002 3.2 \u6a21\u578b\u8bad\u7ec3 \u00b6 R-CNN\u4e2d\u7684\u7279\u5f81\u63d0\u53d6\u548c\u68c0\u6d4b\u90e8\u5206\u662f\u5206\u5f00\u8fdb\u884c\u7684\uff0cFast R-CNN\u63d0\u51fa\u4e00\u4e2a\u9ad8\u6548\u7684\u8bad\u7ec3\u65b9\u6cd5\uff1a\u591a\u4efb\u52a1\u8bad\u7ec3 Fast R-CNN\u6709\u4e24\u79cd\u8f93\u51fa\uff1a \u4e00\u90e8\u5206\u8f93\u51fa\u5728K+1\u4e2a\u7c7b\u522b\u4e0a\u7684\u79bb\u6563\u6982\u7387\u5206\u5e03\uff08\u6bcf\u4e2a\u5019\u9009\u533a\u57df\uff09\uff0c p=(p0,p1,...,pk) p=(p0,p1,...,pk) \u3002\u901a\u5e38\uff0c\u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u7684K+1\u4e2a\u8f93\u51fa\u4e0a\u7684Softmax\u6765\u8ba1\u7b97\u6982\u7387\u503c\u3002 \u53e6\u4e00\u90e8\u5206\u8f93\u51fa\u5bf9\u4e8e\u7531K\u4e2a\u7c7b\u522b\u4e2d\u7684\u6bcf\u4e00\u4e2a\u68c0\u6d4b\u6846\u56de\u5f52\u504f\u79fb\uff0c t^{k}=(t_{x}^{k},t_{y}^{k},t_{w}^{k},t_{h}^{k}) t^{k}=(t_{x}^{k},t_{y}^{k},t_{w}^{k},t_{h}^{k}) \u3002\u5176\u4e2d t_k t_k \u6307\u5b9a\u76f8\u5bf9\u4e8e\u5019\u9009\u6846\u7684\u5c3a\u5ea6\u4e0d\u53d8\u8f6c\u6362\u548c\u5bf9\u6570\u7a7a\u95f4\u9ad8\u5ea6/\u5bbd\u5ea6\u79fb\u4f4d\u3002 \u5c06\u4e0a\u9762\u7684\u4e24\u4e2a\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570\u653e\u5728\u4e00\u8d77: \u8054\u5408\u8bad\u7ec3fast-RCNN\u7f51\u7edc\u3002\u5177\u4f53\u7684\u6211\u4eec\u5728\u540e\u7eed\u7ed9\u5927\u5bb6\u8fdb\u884c\u4ecb\u7ecd\u3002 3.3 \u6a21\u578b\u9884\u6d4b \u00b6 fastRCNN\u7684\u5de5\u4f5c\u6d41\u7a0b\u63cf\u8ff0\u5982\u4e0b\uff1a \u8f93\u5165\u56fe\u50cf\uff1a \u56fe\u50cf\u88ab\u9001\u5165\u5230\u5377\u79ef\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5c06\u901a\u8fc7\u9009\u62e9\u6027\u641c\u7d22\u83b7\u53d6\u7684\u5019\u9009\u533a\u57df\u6620\u5c04\u5230\u7279\u5f81\u56fe\u4e2d\uff1a \u5728\u7279\u5f81\u56fe\u4e0aRol\u4e2d\u5e94\u7528RoIPooling\uff0c\u83b7\u53d6\u5c3a\u5bf8\u76f8\u540c\u7684\u7279\u5f81\u5411\u91cf \u5c06\u8fd9\u4e9b\u533a\u57df\u4f20\u9012\u5230\u5168\u8fde\u63a5\u7684\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u5f97\u5230\u76ee\u6807\u68c0\u6d4b\u7684\u7ed3\u679c\u3002 3.4 \u6a21\u578b\u603b\u7ed3 \u00b6 Fast R-CNN\u662f\u5bf9R-CNN\u6a21\u578b\u7684\u4e00\u79cd\u6539\u8fdb\uff1a CNN\u7f51\u7edc\u4e0d\u518d\u5bf9\u6bcf\u4e2a\u5019\u9009\u533a\u57df\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u800c\u662f\u76f4\u63a5\u5bf9\u6574\u5f20\u56fe\u50cf\u8fdb\u884c\u51fa\u8def\uff0c\u8fd9\u6837\u51cf\u5c11\u4e86\u5f88\u591a\u91cd\u590d\u8ba1\u7b97\u3002 \u7528ROI pooling\u8fdb\u884c\u7279\u5f81\u7684\u5c3a\u5bf8\u53d8\u6362\uff0c\u6765\u6ee1\u8db3FC\u5168\u8fde\u63a5\u5c42\u5bf9\u8f93\u5165\u6570\u636e\u5c3a\u5ea6\u7684\u8981\u6c42\u3002 \u5c06\u76ee\u6807\u7684\u56de\u5f52\u548c\u5206\u7c7b\u7edf\u4e00\u5728\u4e00\u4e2a\u7f51\u7edc\u4e2d\uff0c\u4f7f\u7528FC+softmax\u8fdb\u884c\u76ee\u6807\u5206\u7c7b\uff0c\u4f7f\u7528FC Layer\u8fdb\u884c\u76ee\u6807\u6846\u7684\u56de\u5f52\u3002 \u5728Fast R-CNN\u4e2d\u4f7f\u7528\u7684\u76ee\u6807\u68c0\u6d4b\u8bc6\u522b\u7f51\u7edc\uff0c\u5728\u901f\u5ea6\u548c\u7cbe\u5ea6\u4e0a\u90fd\u6709\u4e86\u4e0d\u9519\u7684\u7ed3\u679c\u3002\u4e0d\u8db3\u7684\u662f\uff0c\u5176\u5019\u9009\u533a\u57df\u63d0\u53d6\u65b9\u6cd5\u8017\u65f6\u8f83\u957f\uff0c\u800c\u4e14\u548c\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u662f\u5206\u79bb\u7684\uff0c\u5e76\u4e0d\u662f\u7aef\u5230\u7aef\u7684\uff0c\u57282016\u5e74\u53c8\u63d0\u51fa\u4e86Faster-RCNN\u6a21\u578b\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\uff0c\u5728\u63a5\u4e0b\u6765\u7684\u8bfe\u7a0b\u4e2d\u6211\u4eec\u7740\u91cd\u4ecb\u7ecdFaster-RCNN\u7f51\u7edc\u7684\u539f\u7406\u4e0e\u5b9e\u73b0\u3002 \u603b\u7ed3 \u4e86\u89e3Overfeat\u6a21\u578b\u7684\u79fb\u52a8\u7a97\u53e3\u65b9\u6cd5 \u6ed1\u52a8\u7a97\u53e3\u4f7f\u7528\u56fa\u5b9a\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u77e9\u5f62\u533a\u57df\uff0c\u53ef\u4ee5\u5728\u56fe\u50cf\u4e0a\u201c\u6ed1\u52a8\u201d\uff0c\u5e76\u5c06\u626b\u63cf\u9001\u5165\u5230\u795e\u7ecf\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\u3002 \u4e86\u89e3RCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 R-CNN\u7f51\u7edc\u4f7f\u7528\u5019\u9009\u533a\u57df\u65b9\u6cd5\uff08region proposal method\uff09\uff0c\u5229\u7528CNN\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\uff0cSVM\u5b8c\u6210\u5206\u7c7b\uff0c\u7ebf\u6027\u56de\u5f52\u8fdb\u884cbbox\u7684\u4fee\u6b63 \u4e86\u89e3fastRCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u5229\u7528CNN\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5229\u7528SS\u751f\u6210\u5019\u9009\u533a\u57df\uff0c\u8fdb\u884c\u6620\u5c04\uff0c\u5e76\u4f7f\u7528ROIpooling\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff0c\u6700\u540e\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52 \u77e5\u9053Fast-RCNN\u4e2d\u63d0\u51fa\u7684\u591a\u4efb\u52a1\u635f\u5931\uff1a\u5c06\u5206\u7c7b\u548c\u56de\u5f52\u7684\u635f\u5931\u51fd\u6570\u8054\u5408\u8bad\u7ec3\u7f51\u7edc","title":"RCNN\u7f51\u7edc\u57fa\u7840"},{"location":"objectdection/02.RCNN/#42-r-cnn","text":"\u5b66\u4e60\u76ee\u6807 \u4e86\u89e3Overfeat\u6a21\u578b\u7684\u79fb\u52a8\u7a97\u53e3\u65b9\u6cd5 \u4e86\u89e3RCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u4e86\u89e3fastRCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u77e5\u9053\u591a\u4efb\u52a1\u635f\u5931","title":"4.2 R-CNN\u7f51\u7edc\u57fa\u7840"},{"location":"objectdection/02.RCNN/#1overfeat","text":"Overfeat\u65b9\u6cd5\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff0c\u4e5f\u5c31\u662f\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u548c\u795e\u7ecf\u7f51\u7edc\u6765\u68c0\u6d4b\u76ee\u6807\u3002\u6ed1\u52a8\u7a97\u53e3\u4f7f\u7528\u56fa\u5b9a\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u77e9\u5f62\u533a\u57df\uff0c\u5728\u56fe\u50cf\u4e0a\u201c\u6ed1\u52a8\u201d\uff0c\u5e76\u5c06\u626b\u63cf\u7ed3\u679c\u9001\u5165\u5230\u795e\u7ecf\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\u3002 \u4f8b\u5982\u8981\u68c0\u6d4b\u6c7d\u8f66\uff0c\u5c31\u4f7f\u7528\u4e0b\u56fe\u4e2d\u7ea2\u8272\u6ed1\u52a8\u7a97\u53e3\u8fdb\u884c\u626b\u63cf\uff0c\u5c06\u6240\u6709\u7684\u626b\u63cf\u7ed3\u679c\u9001\u5165\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u6c7d\u8f66\u7684\u68c0\u6d4b\u7ed3\u679c\u3002 \u8fd9\u79cd\u65b9\u6cd5\u7c7b\u4f3c\u4e00\u79cd\u66b4\u529b\u7a77\u4e3e\u7684\u65b9\u5f0f\uff0c\u4f1a\u6d88\u8017\u5927\u91cf\u7684\u8ba1\u7b97\u529b\uff0c\u5e76\u4e14\u7531\u4e8e\u7a97\u53e3\u5927\u5c0f\u95ee\u9898\u53ef\u80fd\u4f1a\u9020\u6210\u6548\u679c\u4e0d\u51c6\u786e\u3002","title":"1.Overfeat\u6a21\u578b"},{"location":"objectdection/02.RCNN/#2rcnn","text":"2014\u5e74\u63d0\u51faR-CNN\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u4e0d\u518d\u4f7f\u7528\u66b4\u529b\u7a77\u4e3e\u7684\u65b9\u6cd5\uff0c\u800c\u662f\u4f7f\u7528\u5019\u9009\u533a\u57df\u65b9\u6cd5\uff08region proposal method\uff09\u521b\u5efa\u76ee\u6807\u68c0\u6d4b\u7684\u533a\u57df\u6765\u5b8c\u6210\u76ee\u6807\u68c0\u6d4b\u7684\u4efb\u52a1\uff0cR-CNN\u662f\u4ee5\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e3a\u57fa\u7840\u7684\u76ee\u6807\u68c0\u6d4b\u7684\u6a21\u578b \uff0c\u4ee5R-CNN\u4e3a\u57fa\u70b9\uff0c\u540e\u7eed\u7684Fast R-CNN\u3001Faster R-CNN\u6a21\u578b\u90fd\u5ef6\u7eed\u4e86\u8fd9\u79cd\u76ee\u6807\u68c0\u6d4b\u601d\u8def\u3002","title":"2.RCNN\u6a21\u578b"},{"location":"objectdection/02.RCNN/#21","text":"RCNN\u7684\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6b65\u9aa4\u662f\uff1a \u5019\u9009\u533a\u57df\u751f\u6210 \uff1a\u4f7f\u7528\u9009\u62e9\u6027\u641c\u7d22\uff08Selective Search\uff09\u7684\u65b9\u6cd5\u627e\u51fa\u56fe\u7247\u4e2d\u53ef\u80fd\u5b58\u5728\u76ee\u6807\u7684\u4faf\u9009\u533a\u57df CNN\u7f51\u7edc\u63d0\u53d6\u7279\u5f81 \uff1a\u9009\u53d6\u9884\u8bad\u7ec3\u5377\u79ef\u795e\u7ecf\u7f51\u7f51\u7edc\uff08AlexNet\u6216VGG\uff09\u7528\u4e8e\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u3002 \u76ee\u6807\u5206\u7c7b \uff1a\u8bad\u7ec3\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u6765\u8fa8\u522b\u76ee\u6807\u7269\u4f53\u548c\u80cc\u666f\uff0c\u5bf9\u6bcf\u4e2a\u7c7b\u522b\uff0c\u90fd\u8981\u8bad\u7ec3\u4e00\u4e2a\u4e8c\u5143SVM\u3002 \u76ee\u6807\u5b9a\u4f4d \uff1a\u8bad\u7ec3\u4e00\u4e2a\u7ebf\u6027\u56de\u5f52\u6a21\u578b\uff0c\u4e3a\u6bcf\u4e2a\u8fa8\u8bc6\u5230\u7684\u7269\u4f53\u751f\u6210\u66f4\u7cbe\u786e\u7684\u8fb9\u754c\u6846\u3002","title":"2.1 \u7b97\u6cd5\u6d41\u7a0b"},{"location":"objectdection/02.RCNN/#211","text":"\u5728**\u9009\u62e9\u6027\u641c\u7d22\uff08SelectiveSearch\uff0cSS\uff09\u4e2d**\uff0c\u4f7f\u7528\u8bed\u4e49\u5206\u5272\u7684\u65b9\u6cd5\uff0c\u5b83\u5c06\u989c\u8272\u3001\u8fb9\u754c\u3001\u7eb9\u7406\u7b49\u4fe1\u606f\u4f5c\u4e3a\u5408\u5e76\u6761\u4ef6\uff0c\u91c7\u7528\u591a\u5c3a\u5ea6\u7684\u7efc\u5408\u65b9\u6cd5\uff0c\u5c06\u56fe\u50cf\u5728\u50cf\u7d20\u7ea7\u4e0a\u5212\u5206\u51fa\u4e00\u7cfb\u5217\u7684\u533a\u57df\uff0c\u8fd9\u4e9b\u533a\u57df\u8981\u8fdc\u8fdc\u5c11\u4e8e\u4f20\u7edf\u7684\u6ed1\u52a8\u7a97\u53e3\u7684\u7a77\u4e3e\u6cd5\u4ea7\u751f\u7684\u5019\u9009\u533a\u57df\u3002 SelectiveSearch\u5728\u4e00\u5f20\u56fe\u7247\u4e0a\u63d0\u53d6\u51fa\u6765\u7ea62000\u4e2a\u4faf\u9009\u533a\u57df\uff0c \u9700\u8981\u6ce8\u610f\u7684\u662f\u8fd9\u4e9b\u5019\u9009\u533a\u57df\u7684\u957f\u5bbd\u4e0d\u56fa\u5b9a \u3002 \u800c\u4f7f\u7528CNN\u63d0\u53d6\u5019\u9009\u533a\u57df\u7684\u7279\u5f81\u5411\u91cf\uff0c\u9700\u8981\u63a5\u53d7\u56fa\u5b9a\u957f\u5ea6\u7684\u8f93\u5165\uff0c\u6240\u4ee5\u9700\u8981\u5bf9\u5019\u9009\u533a\u57df\u505a\u4e00\u4e9b\u5c3a\u5bf8\u4e0a\u7684\u4fee\u6539\u3002","title":"2.1.1 \u5019\u9009\u533a\u57df\u751f\u6210\u3010\u4e86\u89e3\u3011"},{"location":"objectdection/02.RCNN/#212-cnn","text":"\u91c7\u7528\u9884\u8bad\u7ec3\u6a21\u578b(AlexNet\u6216VGG)\u5728\u751f\u6210\u7684\u5019\u9009\u533a\u57df\u4e0a\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5c06\u63d0\u53d6\u597d\u7684\u7279\u5f81\u4fdd\u5b58\u5728\u78c1\u76d8\u4e2d\uff0c\u7528\u4e8e\u540e\u7eed\u6b65\u9aa4\u7684\u5206\u7c7b\u548c\u56de\u5f52\u3002 1.\u5168\u8fde\u63a5\u5c42\u7684\u8f93\u5165\u6570\u636e\u7684\u5c3a\u5bf8\u662f\u56fa\u5b9a\u7684\uff0c\u56e0\u6b64\u5728\u5c06\u5019\u9009\u533a\u57df\u9001\u5165CNN\u7f51\u7edc\u4e2d\u65f6\uff0c\u9700\u8fdb\u884c\u88c1\u526a\u6216\u53d8\u5f62\u4e3a\u56fa\u5b9a\u7684\u5c3a\u5bf8\uff0c\u5728\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u3002 2.\u9884\u8bad\u7ec3\u6a21\u578b\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\uff0c\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\u662f1000\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u9700\u8981\u5c06\u5176\u6539\u4e3aN+1(N\u4e3a\u76ee\u6807\u7c7b\u522b\u7684\u6570\u76ee\uff0c\u4f8b\u5982VOC\u6570\u636e\u96c6\u4e2dN=20\uff0ccoco\u6570\u636e\u96c6\u4e2dN=80\uff0c1\u662f\u52a0\u4e00\u4e2a\u80cc\u666f)\u540e\uff0c\u8fdb\u884c\u5fae\u8c03\u5373\u53ef\u3002 3.\u5229\u7528\u5fae\u8c03\u540e\u7684CNN\u7f51\u7edc\uff0c\u63d0\u53d6\u6bcf\u4e00\u4e2a\u5019\u9009\u533a\u57df\u7684\u7279\u5f81\uff0c\u83b7\u53d6\u4e00\u4e2a4096\u7ef4\u7684\u7279\u5f81\uff0c\u4e00\u5e45\u56fe\u50cf\u5c31\u662f2000x4096\u7ef4\u7279\u5f81\u5b58\u50a8\u5230\u78c1\u76d8\u4e2d\u3002","title":"2.1.2 CNN\u7f51\u7edc\u63d0\u53d6\u7279\u5f81"},{"location":"objectdection/02.RCNN/#213-svm","text":"\u5047\u8bbe\u6211\u4eec\u8981\u68c0\u6d4b\u732b\u72d7\u4e24\u4e2a\u7c7b\u522b\uff0c\u90a3\u6211\u4eec\u9700\u8981\u8bad\u7ec3\u732b\u548c\u72d7\u4e24\u4e2a\u4e0d\u540c\u7c7b\u522b\u7684SVM\u5206\u7c7b\u5668\uff0c\u7136\u540e\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u5206\u7c7b\u5668\u5bf9\u4e00\u5e45\u56fe\u50cf\u4e2d2000\u4e2a\u5019\u9009\u533a\u57df\u7684\u7279\u5f81\u5411\u91cf\u5206\u522b\u5224\u65ad\u4e00\u6b21\uff0c\u8fd9\u6837\u5f97\u51fa[2000, 2]\u7684\u5f97\u5206\u77e9\u9635\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5bf9\u4e8eN\u4e2a\u7c7b\u522b\u7684\u68c0\u6d4b\u4efb\u52a1\uff0c\u9700\u8981\u8bad\u7ec3N\uff08\u76ee\u6807\u7c7b\u522b\u6570\u76ee\uff09\u4e2aSVM\u5206\u7c7b\u5668\uff0c\u5bf9\u5019\u9009\u533a\u57df\u7684\u7279\u5f81\u5411\u91cf\uff084096\u7ef4\uff09\u8fdb\u884c\u4e8c\u5206\u7c7b\uff0c\u5224\u65ad\u5176\u662f\u67d0\u4e00\u7c7b\u522b\u7684\u76ee\u6807\uff0c\u8fd8\u662f\u80cc\u666f\u6765\u5b8c\u6210\u76ee\u6807\u5206\u7c7b\u3002","title":"2.1.3 \u76ee\u6807\u5206\u7c7b\uff08SVM\uff09"},{"location":"objectdection/02.RCNN/#214","text":"\u901a\u8fc7\u9009\u62e9\u6027\u641c\u7d22\u83b7\u53d6\u7684\u76ee\u6807\u4f4d\u7f6e\u4e0d\u662f\u975e\u5e38\u7684\u51c6\u786e\uff0c\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8bad\u7ec3\u4e00\u4e2a\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u5728\u7ed9\u5b9a\u7684\u5019\u9009\u533a\u57df\u7684\u7ed3\u679c\u4e0a\u53bb\u9884\u6d4b\u4e00\u4e2a\u65b0\u7684\u68c0\u6d4b\u7a97\u53e3\uff0c\u80fd\u591f\u83b7\u5f97\u66f4\u7cbe\u786e\u7684\u4f4d\u7f6e\u3002\u4fee\u6b63\u8fc7\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u901a\u8fc7\u8bad\u7ec3\u4e00\u4e2a\u56de\u5f52\u5668\u6765\u5bf9\u5019\u9009\u533a\u57df\u7684\u8303\u56f4\u8fdb\u884c\u4e00\u4e2a\u8c03\u6574\uff0c\u8fd9\u4e9b\u5019\u9009\u533a\u57df\u6700\u5f00\u59cb\u53ea\u662f\u7528\u9009\u62e9\u6027\u641c\u7d22\u7684\u65b9\u6cd5\u7c97\u7565\u5f97\u5230\u7684\uff0c\u901a\u8fc7\u8c03\u6574\u4e4b\u540e\u5f97\u5230\u66f4\u7cbe\u786e\u7684\u4f4d\u7f6e\uff0c\u5982\u4e0b\u6240\u793a\uff1a","title":"2.1.4 \u76ee\u6807\u5b9a\u4f4d"},{"location":"objectdection/02.RCNN/#215","text":"\u4f7f\u7528\u9009\u62e9\u6027\u641c\u7d22\u7684\u65b9\u6cd5\u4ece\u4e00\u5f20\u56fe\u7247\u4e2d\u63d0\u53d62000\u4e2a\u5019\u9009\u533a\u57df\uff0c\u5c06\u6bcf\u4e2a\u533a\u57df\u9001\u5165CNN\u7f51\u7edc\u4e2d\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u7136\u540e\u9001\u5165\u5230SVM\u4e2d\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u4f7f\u7528\u5019\u9009\u6846\u56de\u5f52\u5668\uff0c\u8ba1\u7b97\u51fa\u6bcf\u4e2a\u5019\u9009\u533a\u57df\u7684\u4f4d\u7f6e\u3002 \u5019\u9009\u533a\u57df\u8f83\u591a\uff0c\u67092000\u4e2a\uff0c\u9700\u8981\u5254\u9664\u6389\u90e8\u5206\u68c0\u6d4b\u7ed3\u679c\u3002 \u9488\u5bf9\u6bcf\u4e2a\u7c7b\uff0c\u901a\u8fc7\u8ba1\u7b97IOU,\u91c7\u53d6\u975e\u6700\u5927\u503c\u6291\u5236NMS\u7684\u65b9\u6cd5\uff0c\u4fdd\u7559\u6bd4\u8f83\u597d\u7684\u68c0\u6d4b\u7ed3\u679c\u3002","title":"2.1.5 \u9884\u6d4b\u8fc7\u7a0b"},{"location":"objectdection/02.RCNN/#22","text":"1\u3001\u8bad\u7ec3\u9636\u6bb5\u591a\uff0c\u8bad\u7ec3\u8017\u65f6\uff1a \u5fae\u8c03CNN\u7f51\u7edc+\u8bad\u7ec3SVM+\u8bad\u7ec3\u8fb9\u6846\u56de\u5f52\u5668\u3002 2\u3001\u9884\u6d4b\u901f\u5ea6\u6162: \u4f7f\u7528GPU, VGG16\u6a21\u578b\u5904\u7406\u4e00\u5f20\u56fe\u50cf\u9700\u898147s \u3002 3\u3001\u5360\u7528\u78c1\u76d8\u7a7a\u95f4\u5927\uff1a5000\u5f20\u56fe\u50cf\u4ea7\u751f\u51e0\u767eG\u7684\u7279\u5f81\u6587\u4ef6\u3002 4\u3001\u6570\u636e\u7684\u5f62\u72b6\u53d8\u5316\uff1a\u5019\u9009\u533a\u57df\u8981\u7ecf\u8fc7\u7f29\u653e\u6765\u56fa\u5b9a\u5927\u5c0f\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u76ee\u6807\u7684\u4e0d\u53d8\u5f62","title":"2.2 \u7b97\u6cd5\u603b\u7ed3"},{"location":"objectdection/02.RCNN/#3-fast-rcnn","text":"\u8003\u8651\u5230R-CNN\u5b58\u5728\u7684\u95ee\u9898\uff0c2015\u5e74\u63d0\u51fa\u4e86\u4e00\u4e2a\u6539\u5584\u6a21\u578b:Fast R-CNN\u3002 \u76f8\u6bd4\u4e8eR-CNN, Fast R-CNN\u4e3b\u8981\u5728\u4ee5\u4e0b\u4e09\u4e2a\u65b9\u9762\u8fdb\u884c\u4e86\u6539\u8fdb\uff1a 1\u3001\u63d0\u9ad8\u8bad\u7ec3\u548c\u9884\u6d4b\u7684\u901f\u5ea6 R-CNN\u9996\u5148\u4ece\u6d4b\u8bd5\u56fe\u4e2d\u63d0\u53d62000\u4e2a\u5019\u9009\u533a\u57df\uff0c\u7136\u540e\u5c06\u8fd92000\u4e2a\u5019\u9009\u533a\u57df\u5206\u522b\u8f93\u5165\u5230\u9884\u8bad\u7ec3\u597d\u7684CNN\u4e2d\u63d0\u53d6\u7279\u5f81\u3002\u7531\u4e8e\u5019\u9009\u533a\u57df\u6709\u5927\u91cf\u7684\u91cd\u53e0\uff0c\u8fd9\u79cd\u63d0\u53d6\u7279\u5f81\u7684\u65b9\u6cd5\uff0c\u5c31\u4f1a\u91cd\u590d\u7684\u8ba1\u7b97\u91cd\u53e0\u533a\u57df\u7684\u7279\u5f81\u3002\u5728Fast-RCNN\u4e2d\uff0c\u5c06\u6574\u5f20\u56fe\u8f93\u5165\u5230CNN\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u5c06\u5019\u9009\u533a\u57df\u6620\u5c04\u5230\u7279\u5f81\u56fe\u4e0a\uff0c\u8fd9\u6837\u5c31\u907f\u514d\u4e86\u5bf9\u56fe\u50cf\u533a\u57df\u8fdb\u884c\u91cd\u590d\u5904\u7406\uff0c\u63d0\u9ad8\u6548\u7387\u51cf\u5c11\u65f6\u95f4\u3002 2\u3001\u4e0d\u9700\u8981\u989d\u5916\u7684\u7a7a\u95f4\u4fdd\u5b58CNN\u7f51\u7edc\u63d0\u53d6\u7684\u7279\u5f81\u5411\u91cf RCNN\u4e2d\u9700\u8981\u5c06\u63d0\u53d6\u5230\u7684\u7279\u5f81\u4fdd\u5b58\u4e0b\u6765\uff0c\u7528\u4e8e\u4e3a\u6bcf\u4e2a\u7c7b\u8bad\u7ec3\u5355\u72ec\u7684SVM\u5206\u7c7b\u5668\u548c\u8fb9\u6846\u56de\u5f52\u5668\u3002\u5728Fast-RCNN\u4e2d\uff0c\u5c06\u7c7b\u522b\u5224\u65ad\u548c\u8fb9\u6846\u56de\u5f52\u7edf\u4e00\u4f7f\u7528CNN\u5b9e\u73b0\uff0c\u4e0d\u9700\u8981\u5728\u989d\u5916\u7684\u7a7a\u95f4\u5b58\u50a8\u7279\u5f81\u3002 3\u3001\u4e0d\u5728\u76f4\u63a5\u5bf9\u5019\u9009\u533a\u57df\u8fdb\u884c\u7f29\u653e RCNN\u4e2d\u9700\u8981\u5bf9\u5019\u9009\u533a\u57df\u8fdb\u884c\u7f29\u653e\u9001\u5165CNN\u4e2d\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5728Fast-RCNN\u4e2d\u4f7f\u7528ROIpooling\u7684\u65b9\u6cd5\u8fdb\u884c\u5c3a\u5bf8\u7684\u8c03\u6574\u3002","title":"3. Fast RCNN\u6a21\u578b"},{"location":"objectdection/02.RCNN/#31","text":"Fast_RCNN\u7684\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6b65\u9aa4\u662f\uff1a 1\u3001 \u5019\u9009\u533a\u57df\u751f\u6210 \uff1a\u4f7f\u7528\u9009\u62e9\u6027\u641c\u7d22\uff08Selective Search\uff09\u7684\u65b9\u6cd5\u627e\u51fa\u56fe\u7247\u4e2d\u53ef\u80fd\u5b58\u5728\u76ee\u6807\u7684\u4faf\u9009\u533a\u57df\uff0c\u53ea\u9700\u8981\u5019\u9009\u533a\u57df\u7684\u4f4d\u7f6e\u4fe1\u606f 2\u3001 CNN\u7f51\u7edc\u7279\u5f81\u63d0\u53d6 \uff1a\u5c06\u6574\u5f20\u56fe\u50cf\u8f93\u5165\u5230CNN\u7f51\u7edc\u4e2d\uff0c\u5f97\u5230\u6574\u526f\u56fe\u7684\u7279\u5f81\u56fe\uff0c\u5e76\u5c06\u4e0a\u4e00\u6b65\u83b7\u53d6\u7684\u5019\u9009\u533a\u57df\u4f4d\u7f6e\u4ece\u539f\u56fe\u6620\u5c04\u5230\u8be5\u7279\u5f81\u56fe\u4e0a 3\u3001 ROIPooling : \u5bf9\u4e8e\u6bcf\u4e2a\u7279\u5f81\u56fe\u4e0a\u5019\u9009\u6846\uff0cRoI pooling\u5c42\u4ece\u7279\u5f81\u56fe\u4e2d\u63d0\u53d6\u56fa\u5b9a\u957f\u5ea6\u7684\u7279\u5f81\u5411\u91cf\u6bcf\u4e2a\u7279\u5f81\u5411\u91cf\u88ab\u9001\u5165\u4e00\u7cfb\u5217\u5168\u8fde\u63a5\uff08fc\uff09\u5c42\u4e2d\u3002 4\u3001 \u76ee\u6807\u68c0\u6d4b \uff1a\u5206\u4e24\u90e8\u5206\u5b8c\u6210\uff0c\u4e00\u4e2a\u8f93\u51fa\u5404\u7c7b\u522b\u52a0\u4e0a1\u4e2a\u80cc\u666f\u7c7b\u522b\u7684Softmax\u6982\u7387\u4f30\u8ba1\uff0c\u53e6\u4e00\u4e2a\u4e3a\u5404\u7c7b\u522b\u7684\u6bcf\u4e00\u4e2a\u7c7b\u522b\u8f93\u51fa\u56db\u4e2a\u5b9e\u6570\u503c\uff0c\u6765\u786e\u5b9a\u76ee\u6807\u7684\u4f4d\u7f6e\u4fe1\u606f\u3002","title":"3.1 \u7b97\u6cd5\u6d41\u7a0b"},{"location":"objectdection/02.RCNN/#311","text":"\u4e0eRCNN\u4e2d\u4e00\u6837\uff0c\u4e0d\u518d\u8d58\u8ff0","title":"3.1.1 \u5019\u9009\u533a\u57df\u751f\u6210\u3010\u4e86\u89e3\u3011"},{"location":"objectdection/02.RCNN/#312-cnn","text":"\u4e0eRCNN\u4e2d\u4e00\u6837\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u3002","title":"3.1.2 CNN\u7f51\u7edc\u7279\u5f81\u63d0\u53d6"},{"location":"objectdection/02.RCNN/#313-roi-pooling","text":"\u5019\u9009\u533a\u57df\u4ece\u539f\u56fe\u6620\u5c04\u5230\u7279\u5f81\u56fe\u4e2d\u540e\uff0c\u8fdb\u884cROIpooling\u7684\u8ba1\u7b97\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a ROI Pooling\u5c42\u4f7f\u7528\u6700\u5927\u6c60\u5316\u5c06\u8f93\u5165\u7684\u7279\u5f81\u56fe\u4e2d\u7684\u4efb\u610f\u533a\u57df\uff08\u5019\u9009\u533a\u57df\u5bf9\u5e94\u7684\u533a\u57df\uff09\u5185\u7684\u7279\u5f81\u8f6c\u5316\u4e3a\u56fa\u5b9a\u7684\ud835\udc3b\u00d7\ud835\udc4a\u7684\u7279\u5f81\u56fe\uff0c\u5176\u4e2d\ud835\udc3b\u548c\ud835\udc4a\u662f\u8d85\u53c2\u6570\u3002 \u5bf9\u4e8e\u4efb\u610f\u8f93\u5165\u7684\u210e\u00d7\ud835\udc64\u7684\u5019\u9009\u533a\u57df\uff0c\u5c06\u5176\u5206\u5272\u4e3a\ud835\udc3b\u00d7\ud835\udc4a\u7684\u5b50\u7f51\u683c\uff0c\u6bcf\u4e2a\u5b50\u7f51\u683c\u7684\u5927\u5c0f\u4e3a\uff1a(h/H) x (w/W)\uff0c\u53d6\u6bcf\u4e2a\u5b50\u7f51\u683c\u4e2d\u7684\u6700\u5927\u503c\uff0c\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u5904\u7406\u3002 \u4f7f\u7528ROI Pooling\u5c42\u66ff\u6362\u9884\u8bad\u7ec3\u7f51\u7edc\u4e2d\u6700\u540e\u7684\u6c60\u5316\u5c42\uff0c\u5e76\u5c06\u5e76\u5c06\u8d85\u53c2\ud835\udc3b,\ud835\udc4a\u8bbe\u7f6e\u4e3a\u548c\u7f51\u7edc\u7b2c\u4e00\u4e2a\u5168\u8fde\u63a5\u517c\u5bb9\u7684\u503c\uff0c\u4f8b\u5982VGG16\uff0c\u8bbe\ud835\udc3b=\ud835\udc4a=7\u3002","title":"3.1.3 ROI Pooling"},{"location":"objectdection/02.RCNN/#314","text":"\u539f\u7f51\u7edc\u7684\u6700\u540e\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\u66ff\u6362\u4e3a\u4e24\u4e2a\u540c\u7ea7\u5c42:K+1\u4e2a\u7c7b\u522b\u7684SoftMax\u5206\u7c7b\u5c42\u548c\u8fb9\u6846\u7684\u56de\u5f52\u5c42\u3002","title":"3.1.4 \u76ee\u6807\u5206\u7c7b\u548c\u56de\u5f52"},{"location":"objectdection/02.RCNN/#32","text":"R-CNN\u4e2d\u7684\u7279\u5f81\u63d0\u53d6\u548c\u68c0\u6d4b\u90e8\u5206\u662f\u5206\u5f00\u8fdb\u884c\u7684\uff0cFast R-CNN\u63d0\u51fa\u4e00\u4e2a\u9ad8\u6548\u7684\u8bad\u7ec3\u65b9\u6cd5\uff1a\u591a\u4efb\u52a1\u8bad\u7ec3 Fast R-CNN\u6709\u4e24\u79cd\u8f93\u51fa\uff1a \u4e00\u90e8\u5206\u8f93\u51fa\u5728K+1\u4e2a\u7c7b\u522b\u4e0a\u7684\u79bb\u6563\u6982\u7387\u5206\u5e03\uff08\u6bcf\u4e2a\u5019\u9009\u533a\u57df\uff09\uff0c p=(p0,p1,...,pk) p=(p0,p1,...,pk) \u3002\u901a\u5e38\uff0c\u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u7684K+1\u4e2a\u8f93\u51fa\u4e0a\u7684Softmax\u6765\u8ba1\u7b97\u6982\u7387\u503c\u3002 \u53e6\u4e00\u90e8\u5206\u8f93\u51fa\u5bf9\u4e8e\u7531K\u4e2a\u7c7b\u522b\u4e2d\u7684\u6bcf\u4e00\u4e2a\u68c0\u6d4b\u6846\u56de\u5f52\u504f\u79fb\uff0c t^{k}=(t_{x}^{k},t_{y}^{k},t_{w}^{k},t_{h}^{k}) t^{k}=(t_{x}^{k},t_{y}^{k},t_{w}^{k},t_{h}^{k}) \u3002\u5176\u4e2d t_k t_k \u6307\u5b9a\u76f8\u5bf9\u4e8e\u5019\u9009\u6846\u7684\u5c3a\u5ea6\u4e0d\u53d8\u8f6c\u6362\u548c\u5bf9\u6570\u7a7a\u95f4\u9ad8\u5ea6/\u5bbd\u5ea6\u79fb\u4f4d\u3002 \u5c06\u4e0a\u9762\u7684\u4e24\u4e2a\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570\u653e\u5728\u4e00\u8d77: \u8054\u5408\u8bad\u7ec3fast-RCNN\u7f51\u7edc\u3002\u5177\u4f53\u7684\u6211\u4eec\u5728\u540e\u7eed\u7ed9\u5927\u5bb6\u8fdb\u884c\u4ecb\u7ecd\u3002","title":"3.2 \u6a21\u578b\u8bad\u7ec3"},{"location":"objectdection/02.RCNN/#33","text":"fastRCNN\u7684\u5de5\u4f5c\u6d41\u7a0b\u63cf\u8ff0\u5982\u4e0b\uff1a \u8f93\u5165\u56fe\u50cf\uff1a \u56fe\u50cf\u88ab\u9001\u5165\u5230\u5377\u79ef\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5c06\u901a\u8fc7\u9009\u62e9\u6027\u641c\u7d22\u83b7\u53d6\u7684\u5019\u9009\u533a\u57df\u6620\u5c04\u5230\u7279\u5f81\u56fe\u4e2d\uff1a \u5728\u7279\u5f81\u56fe\u4e0aRol\u4e2d\u5e94\u7528RoIPooling\uff0c\u83b7\u53d6\u5c3a\u5bf8\u76f8\u540c\u7684\u7279\u5f81\u5411\u91cf \u5c06\u8fd9\u4e9b\u533a\u57df\u4f20\u9012\u5230\u5168\u8fde\u63a5\u7684\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u5f97\u5230\u76ee\u6807\u68c0\u6d4b\u7684\u7ed3\u679c\u3002","title":"3.3 \u6a21\u578b\u9884\u6d4b"},{"location":"objectdection/02.RCNN/#34","text":"Fast R-CNN\u662f\u5bf9R-CNN\u6a21\u578b\u7684\u4e00\u79cd\u6539\u8fdb\uff1a CNN\u7f51\u7edc\u4e0d\u518d\u5bf9\u6bcf\u4e2a\u5019\u9009\u533a\u57df\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u800c\u662f\u76f4\u63a5\u5bf9\u6574\u5f20\u56fe\u50cf\u8fdb\u884c\u51fa\u8def\uff0c\u8fd9\u6837\u51cf\u5c11\u4e86\u5f88\u591a\u91cd\u590d\u8ba1\u7b97\u3002 \u7528ROI pooling\u8fdb\u884c\u7279\u5f81\u7684\u5c3a\u5bf8\u53d8\u6362\uff0c\u6765\u6ee1\u8db3FC\u5168\u8fde\u63a5\u5c42\u5bf9\u8f93\u5165\u6570\u636e\u5c3a\u5ea6\u7684\u8981\u6c42\u3002 \u5c06\u76ee\u6807\u7684\u56de\u5f52\u548c\u5206\u7c7b\u7edf\u4e00\u5728\u4e00\u4e2a\u7f51\u7edc\u4e2d\uff0c\u4f7f\u7528FC+softmax\u8fdb\u884c\u76ee\u6807\u5206\u7c7b\uff0c\u4f7f\u7528FC Layer\u8fdb\u884c\u76ee\u6807\u6846\u7684\u56de\u5f52\u3002 \u5728Fast R-CNN\u4e2d\u4f7f\u7528\u7684\u76ee\u6807\u68c0\u6d4b\u8bc6\u522b\u7f51\u7edc\uff0c\u5728\u901f\u5ea6\u548c\u7cbe\u5ea6\u4e0a\u90fd\u6709\u4e86\u4e0d\u9519\u7684\u7ed3\u679c\u3002\u4e0d\u8db3\u7684\u662f\uff0c\u5176\u5019\u9009\u533a\u57df\u63d0\u53d6\u65b9\u6cd5\u8017\u65f6\u8f83\u957f\uff0c\u800c\u4e14\u548c\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u662f\u5206\u79bb\u7684\uff0c\u5e76\u4e0d\u662f\u7aef\u5230\u7aef\u7684\uff0c\u57282016\u5e74\u53c8\u63d0\u51fa\u4e86Faster-RCNN\u6a21\u578b\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\uff0c\u5728\u63a5\u4e0b\u6765\u7684\u8bfe\u7a0b\u4e2d\u6211\u4eec\u7740\u91cd\u4ecb\u7ecdFaster-RCNN\u7f51\u7edc\u7684\u539f\u7406\u4e0e\u5b9e\u73b0\u3002 \u603b\u7ed3 \u4e86\u89e3Overfeat\u6a21\u578b\u7684\u79fb\u52a8\u7a97\u53e3\u65b9\u6cd5 \u6ed1\u52a8\u7a97\u53e3\u4f7f\u7528\u56fa\u5b9a\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u77e9\u5f62\u533a\u57df\uff0c\u53ef\u4ee5\u5728\u56fe\u50cf\u4e0a\u201c\u6ed1\u52a8\u201d\uff0c\u5e76\u5c06\u626b\u63cf\u9001\u5165\u5230\u795e\u7ecf\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\u3002 \u4e86\u89e3RCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 R-CNN\u7f51\u7edc\u4f7f\u7528\u5019\u9009\u533a\u57df\u65b9\u6cd5\uff08region proposal method\uff09\uff0c\u5229\u7528CNN\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\uff0cSVM\u5b8c\u6210\u5206\u7c7b\uff0c\u7ebf\u6027\u56de\u5f52\u8fdb\u884cbbox\u7684\u4fee\u6b63 \u4e86\u89e3fastRCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u5229\u7528CNN\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5229\u7528SS\u751f\u6210\u5019\u9009\u533a\u57df\uff0c\u8fdb\u884c\u6620\u5c04\uff0c\u5e76\u4f7f\u7528ROIpooling\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff0c\u6700\u540e\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52 \u77e5\u9053Fast-RCNN\u4e2d\u63d0\u51fa\u7684\u591a\u4efb\u52a1\u635f\u5931\uff1a\u5c06\u5206\u7c7b\u548c\u56de\u5f52\u7684\u635f\u5931\u51fd\u6570\u8054\u5408\u8bad\u7ec3\u7f51\u7edc","title":"3.4 \u6a21\u578b\u603b\u7ed3"},{"location":"objectdection/03.Faster-RCNN/","text":"4.3 Faster-RCNN\u7f51\u7edc \u00b6 \u5b66\u4e60\u76ee\u6807 \u719f\u6089FasterRCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u77e5\u9053anchor\uff08\u951a\u6846\uff09\u7684\u601d\u60f3 \u638c\u63e1RPN\u7f51\u7edc\u662f\u5982\u4f55\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u751f\u6210\u7684 \u638c\u63e1ROIPooling\u7684\u4f7f\u7528\u65b9\u6cd5 \u77e5\u9053fasterRCNN\u7684\u8bad\u7ec3\u65b9\u6cd5 \u5728R-CNN\u548cFast RCNN\u7684\u57fa\u7840\u4e0a\uff0c\u57282016\u5e74\u63d0\u51fa\u4e86Faster RCNN\u7f51\u7edc\u6a21\u578b\uff0c\u5728\u7ed3\u6784\u4e0a\uff0cFaster RCNN\u5df2\u7ecf\u5c06\u5019\u9009\u533a\u57df\u7684\u751f\u6210\uff0c\u7279\u5f81\u63d0\u53d6\uff0c\u76ee\u6807\u5206\u7c7b\u53ca\u76ee\u6807\u6846\u7684\u56de\u5f52\u90fd\u6574\u5408\u5728\u4e86\u4e00\u4e2a\u7f51\u7edc\u4e2d\uff0c\u7efc\u5408\u6027\u80fd\u6709\u8f83\u5927\u63d0\u9ad8\uff0c\u5728\u68c0\u6d4b\u901f\u5ea6\u65b9\u9762\u5c24\u4e3a\u660e\u663e\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u7ed9\u5927\u5bb6\u8be6\u7ec6\u4ecb\u7ecdfasterRCNN\u7f51\u7edc\u6a21\u578b\u3002\u7f51\u7edc\u57fa\u672c\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a Faster RCNN\u53ef\u4ee5\u770b\u6210\u662f\u533a\u57df\u751f\u6210\u7f51\u7edc(RPN)\u4e0eFast RCNN\u7684\u7ec4\u5408\uff0c\u5176\u4e2d\u533a\u57df\u751f\u6210\u7f51\u7edc(RPN)\u66ff\u4ee3\u9009\u62e9\u6027\u641c\u7d22\u6765\u751f\u6210\u5019\u9009\u533a\u57df\uff0cFast RCNN\u7528\u6765\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u3002 1. \u7f51\u7edc\u5de5\u4f5c\u6d41\u7a0b \u00b6 FasterRCNN\u7684\u5de5\u4f5c\u6d41\u7a0b\u662f\uff1a 1\u3001 \u7279\u5f81\u63d0\u53d6 \uff1a\u5c06\u6574\u4e2a\u56fe\u50cf\u7f29\u653e\u81f3\u56fa\u5b9a\u7684\u5927\u5c0f\u8f93\u5165\u5230CNN\u7f51\u7edc\u4e2d\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5f97\u5230\u7279\u5f81\u56fe\u3002 2\u3001 \u5019\u9009\u533a\u57df\u63d0\u53d6 \uff1a\u8f93\u5165\u7279\u5f81\u56fe\uff0c\u4f7f\u7528\u533a\u57df\u751f\u6210\u7f51\u7edcRPN\uff0c\u4ea7\u751f\u4e00\u4e9b\u5217\u7684\u5019\u9009\u533a\u57df 3\u3001 ROIPooling : \u4e0eFast RCNN\u7f51\u7edc\u4e2d\u4e00\u6837\uff0c\u4f7f\u7528\u6700\u5927\u6c60\u5316\u56fa\u5b9a\u5019\u9009\u533a\u57df\u7684\u5c3a\u5bf8\uff0c\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u5904\u7406 4\u3001 \u76ee\u6807\u5206\u7c7b\u548c\u56de\u5f52 \uff1a\u4e0eFast RCNN\u7f51\u7edc\u4e2d\u4e00\u6837\uff0c\u4f7f\u7528\u4e24\u4e2a\u540c\u7ea7\u5c42:K+1\u4e2a\u7c7b\u522b\u7684SoftMax\u5206\u7c7b\u5c42\u548c\u8fb9\u6846\u7684\u56de\u5f52\u5c42\uff0c\u6765\u5b8c\u6210\u76ee\u6807\u7684\u5206\u7c7b\u548c\u56de\u5f52\u3002 Faster R-CNN\u7684\u6d41\u7a0b\u4e0eFast R-CNN\u7684\u533a\u522b\u4e0d\u662f\u5f88\u5927\uff0c\u91cd\u8981\u7684\u6539\u8fdb\u662f\u4f7f\u7528RPN\u7f51\u7edc\u6765\u66ff\u4ee3\u9009\u62e9\u6027\u641c\u7d22\u83b7\u53d6\u5019\u9009\u533a\u57df\uff0c\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u5c06Faster R-CNN\u7f51\u7edc\u770b\u505aRPN\u548cFast R-CNN\u7f51\u7edc\u7684\u7ed3\u5408\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u6765\u770b\u4e0b\u8be5\u7f51\u7edc\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u4f7f\u7528\u8fc7\u7a0b\uff0c\u6a21\u578b\u6e90\u7801\u4f4d\u7f6e\uff1afasterRCNN\u4e2d\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a detection\u6587\u4ef6\u5939\u4e2d\u662f\u6a21\u578b\uff0c\u6570\u636e\u7684\u5b9e\u73b0\uff0cweights\u4e2d\u5305\u542b\u7f51\u7edc\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u6309\u7167\u4ee5\u4e0b\u6b65\u9aa4\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff1a 1\u3001\u83b7\u53d6\u6570\u636e\u548c\u52a0\u8f7d\u9884\u8bad\u7ec3\u7f51\u7edc 2\u3001\u83b7\u53d6RPN\u7f51\u7edc\u751f\u6210\u7684\u5019\u9009\u533a\u57df 3\u3001\u83b7\u53d6\u7f51\u7edc\u7684\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c \u9996\u5148\u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305\uff1a # \u83b7\u53d6VOC\u6570\u636e\u4f7f\u7528 from detection.datasets import pascal_voc # \u7ed8\u56fe import matplotlib.pyplot as plt import numpy as np # \u6a21\u578b\u6784\u5efa from detection.models.detectors import faster_rcnn import tensorflow as tf # \u56fe\u50cf\u5c55\u793a import visualize 1.1 \u6570\u636e\u52a0\u8f7d \u00b6 \u52a0\u8f7dvoc\u6570\u636e\u96c6\u4e2d\u7684\u4e00\u5f20\u56fe\u7247\u8fdb\u884c\u7f51\u7edc\u9884\u6d4b\uff1a # \u5b9e\u4f8b\u5316voc\u6570\u636e\u96c6\u7684\u7c7b\uff0c\u83b7\u53d6\u9001\u5165\u7f51\u7edc\u4e2d\u7684\u4e00\u5f20\u56fe\u7247 pascal = pascal_voc . pascal_voc ( \"train\" ) # image\uff1a\u9001\u5165\u7f51\u7edc\u4e2d\u7684\u6570\u636e\uff0cimagemeta:\u56fe\u50cf\u7684yuan'x image , imagemeta , bbox , label = pascal [ 218 ] \u5728\u5c06\u56fe\u50cf\u9001\u5165\u7f51\u7edc\u4e4b\u524d\uff0c\u6211\u4eec\u5bf9\u5176\u8fdb\u884c\u4e86\u5c3a\u5ea6\u7684\u8c03\u6574\uff0c\u6807\u51c6\u5316\u7b49\u5904\u7406\uff0c\u83b7\u53d6\u53ef\u5c55\u793a\u7684\u56fe\u50cf\uff1a # \u56fe\u50cf\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee img_mean = ( 122.7717 , 115.9465 , 102.9801 ) img_std = ( 1. , 1. , 1. ) # RGB\u56fe\u50cf rgd_image = np . round ( image + img_mean ) . astype ( np . uint8 ) \u83b7\u53d6\u539f\u59cb\u56fe\u50cf\uff0c\u8fdb\u884c\u6bd4\u8f83\uff1a # \u83b7\u53d6\u539f\u59cb\u56fe\u50cf from detection.datasets.utils import get_original_image ori_img = get_original_image ( image [ 0 ], imagemeta [ 0 ], img_mean ) \u5c06\u56fe\u50cf\u8fdb\u884c\u5bf9\u6bd4\u663e\u793a\uff1a # \u5c55\u793a\u539f\u56fe\u50cf\u548c\u9001\u5165\u7f51\u7edc\u4e2d\u56fe\u50cf rgd_image = np . round ( image + img_mean ) . astype ( np . uint8 ) fig , axes = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 10 , 8 ), dpi = 100 ) axes [ 0 ] . imshow ( ori_img . astype ( 'uint8' )) axes [ 0 ] . set_title ( \"\u539f\u56fe\u50cf\" ) axes [ 1 ] . imshow ( rgd_image [ 0 ]) axes [ 1 ] . set_title ( \"\u9001\u5165\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf\" ) plt . show () \u5c06\u539f\u56fe\u50cf\u7684\u957f\u8fb9\u7f29\u653e\u4e3a1216\uff0c\u77ed\u8fb9\u6309\u76f8\u5e94\u6bd4\u4f8b\u8fdb\u884c\u8c03\u6574\u540e\uff0c\u5e76\u6309\u7167\u5747\u503c\u8fdb\u884c\u586b\u5145 # \u539f\u56fe\u50cf\u7684\u5927\u5c0f ori_img . shape (375, 500, 3) # \u9001\u5165\u7f51\u7edc\u4e2d\u56fe\u50cf\u7684\u5927\u5c0f image . shape (1, 1216, 1216, 3) imagemeta\u4e2d\u7684\u4fe1\u606f\u662f\uff1a\u539f\u56fe\u50cf\u5927\u5c0f\uff0c\u56fe\u50cf\u7f29\u653e\u540e\u7684\u5927\u5c0f\uff0c\u9001\u5165\u7f51\u7edc\u4e2d\u56fe\u50cf\u7684\u5927\u5c0f\uff0c\u56fe\u50cf\u7f29\u653e\u6bd4\u4f8b\uff0c\u56fe\u50cf\u662f\u5426\u7ffb\u8f6c\uff08\u672a\u4f7f\u7528\uff09\u3002 # \u539f\u59cb\u56fe\u50cf\u548c\u9001\u5165\u7f51\u7edc\u4e2d\u56fe\u50cf\u7684\u4fe1\u606f imagemeta array ([[ 375. , 500. , 3. , 912. , 1216. , 3. , 1216. , 1216. , 3. , 2.432 , 0. ]], dtype = float32 ) 1.2 \u6a21\u578b\u52a0\u8f7d \u00b6 \u52a0\u8f7d\u4f7f\u7528coco\u6570\u636e\u96c6\u9884\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u5bf9\u56fe\u50cf\u8fdb\u884c\u9884\u6d4b\u3002 # coco\u6570\u636e\u96c6\u7684class\uff0c\u517180\u4e2a\u7c7b\u522b\uff1a\u4eba\uff0c\u81ea\u884c\u8f66\uff0c\u706b\u8f66\uff0c\u3002\u3002\u3002 classes = [ 'bg' , 'person' , 'bicycle' , 'car' , 'motorcycle' , 'airplane' , 'bus' , 'train' , 'truck' , 'boat' , 'traffic light' , 'fire hydrant' , 'stop sign' , 'parking meter' , 'bench' , 'bird' , 'cat' , 'dog' , 'horse' , 'sheep' , 'cow' , 'elephant' , 'bear' , 'zebra' , 'giraffe' , 'backpack' , 'umbrella' , 'handbag' , 'tie' , 'suitcase' , 'frisbee' , 'skis' , 'snowboard' , 'sports ball' , 'kite' , 'baseball bat' , 'baseball glove' , 'skateboard' , 'surfboard' , 'tennis racket' , 'bottle' , 'wine glass' , 'cup' , 'fork' , 'knife' , 'spoon' , 'bowl' , 'banana' , 'apple' , 'sandwich' , 'orange' , 'broccoli' , 'carrot' , 'hot dog' , 'pizza' , 'donut' , 'cake' , 'chair' , 'couch' , 'potted plant' , 'bed' , 'dining table' , 'toilet' , 'tv' , 'laptop' , 'mouse' , 'remote' , 'keyboard' , 'cell phone' , 'microwave' , 'oven' , 'toaster' , 'sink' , 'refrigerator' , 'book' , 'clock' , 'vase' , 'scissors' , 'teddy bear' , 'hair drier' , 'toothbrush' ] \u5b9e\u4f8b\u5316faster-RCNN\u6a21\u578b\uff1a # \u5b9e\u4f8b\u5316\u6a21\u578b model = faster_rcnn . FasterRCNN ( num_classes = len ( classes )) \u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u7531\u4e8efasterRCNN\u4e0d\u662f\u6309\u7167model\u7684\u5b50\u7c7b\u6784\u5efa\uff0c\u6240\u4ee5\u65e0\u6cd5\u901a\u8fc7h5\u6587\u4ef6\u76f4\u63a5\u52a0\u8f7d\u6a21\u578b\u7ed3\u6784\uff0c\u6211\u4eec\u5c06\u7ed3\u6784\u5b9e\u4f8b\u5316\u540e\uff0c\u5728\u52a0\u8f7d\u6743\u91cd\u83b7\u53d6\u6574\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\u3002 model (( image , imagemeta , bbox , label ), training = True ) # \u52a0\u8f7d\u8bad\u7ec3\u597d\u7684weights model . load_weights ( \"weights/faster_rcnn.h5\" ) \u901a\u8fc7model.summary()\u67e5\u770b\u7f51\u7edc\u67b6\u6784\uff0c\u5982\u4e0b\uff1a 1.3 \u6a21\u578b\u9884\u6d4b\u8fc7\u7a0b \u00b6 \u6a21\u578b\u7684\u9884\u6d4b\u5206\u4e3a\u4e24\u90e8\u5206\uff1aRPN\u751f\u6210\u5019\u9009\u533a\u57df\u548cFast RCNN\u8fdb\u884c\u76ee\u6807\u7684\u5206\u7c7b\u4e0e\u56de\u5f52 1.3.1 RPN\u83b7\u53d6\u5019\u9009\u533a\u57df \u00b6 # RPN\u83b7\u53d6\u5019\u9009\u533a\u57df\uff1a\u8f93\u5165\u56fe\u50cf\u548c\u5bf9\u5e94\u7684\u5143\u4fe1\u606f\uff0c\u8f93\u51fa\u662f\u5019\u9009\u7684\u4f4d\u7f6e\u4fe1\u606f proposals = model . simple_test_rpn ( image [ 0 ], imagemeta [ 0 ]) \u5019\u9009\u533a\u57df\u7684\u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a\u5bf9\u4e8e\u4e0a\u8ff0\u56fe\u50cf\u5171\u4ea7\u751f1533\u4e2a\u5019\u9009\u533a\u57df\uff0c\u6bcf\u4e2a\u5019\u9009\u533a\u57df\u4f7f\u7528\u76f8\u5bf9\u4e8e\u8f93\u5165\u7f51\u7edc\u4e2d\u56fe\u50cf\u5f52\u4e00\u5316\u540e\u7684\u5de6\u4e0a\u89d2\u5750\u6807\u548c\u53f3\u4e0b\u89d2\u5750\u6807\u3002 <tf.Tensor: shape=(1533, 4), dtype=float32, numpy= array([[0.20729761, 0.00852748, 0.748096 , 0.46975034], [0.42213044, 0.5887971 , 0.7810232 , 0.9806169 ], [0.40125194, 0.4384725 , 0.48458642, 0.47913405], ..., [0.25977597, 0.435113 , 0.27290097, 0.4483906 ], [0.38884488, 0.41798416, 0.41393432, 0.4339822 ], [0.5885266 , 0.65331775, 0.62330776, 0.6913476 ]], dtype=float32)> \u6211\u4eec\u5c06\u8fd9\u4e9b\u5019\u9009\u533a\u57df\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a\uff0c\u9700\u8981\u83b7\u53d6\u7edd\u5bf9\u4f4d\u7f6e\uff1a # \u7ed8\u5236\u5728\u56fe\u50cf\u4e0a(\u5c06proposal\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a) visualize . draw_boxes ( rgd_image [ 0 ], boxes = proposals [:,: 4 ] * 1216 ) plt . show () \u5982\u4e0b\u56fe\u6240\u793a\uff1a 1.3.2 FastRCNN\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b \u00b6 \u6211\u4eec\u5c06\u83b7\u53d6\u7684\u5019\u9009\u533a\u57df\u9001\u5165\u5230Fast RCNN\u7f51\u7edc\u4e2d\u8fdb\u884c\u68c0\u6d4b\uff1a # rcnn\u8fdb\u884c\u9884\u6d4b,\u5f97\u5230\u7684\u662f\u539f\u56fe\u50cf\u7684\u68c0\u6d4b\u7ed3\u679c\uff1a # \u8f93\u5165\uff1a\u8981\u68c0\u6d4b\u7684\u9001\u5165\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf\uff0c\u56fe\u50cf\u7684\u5143\u4fe1\u606f\uff0cRPN\u4ea7\u751f\u7684\u5019\u9009\u533a\u57df # \u8f93\u51fa\uff1a\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c\uff1a\u68c0\u6d4b\u6846(\u76f8\u5bf9\u4e8e\u539f\u56fe\u50cf)\uff0c\u7c7b\u522b\uff0c\u7f6e\u4fe1\u5ea6 res = model . simple_test_bboxes ( image [ 0 ], imagemeta [ 0 ], proposals ) res\u662f\u4e00\u4e2a\u5b57\u5178\uff0c\u5176\u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1arois\u662f\u76ee\u6807\u6846\uff0cclass_ids\u662f\u6240\u5c5e\u7684\u7c7b\u522b\uff0cscores\u662f\u7f6e\u4fe1\u5ea6\u3002 {'rois': array([[ 95.65208 , 8.963474 , 370.8639 , 224.11072 ], [ 57.620296 , 226.60101 , 159.39307 , 310.5221 ], [ 86.15405 , 323.98065 , 369.12762 , 497.70337 ], [ 83.67178 , 170.96815 , 135.69716 , 221.05861 ], [ 74.37474 , 327.855 , 210.86298 , 422.48798 ], [ 73.24604 , 0.97371644, 206.86272 , 47.992523 ], [ 63.968616 , 256.5716 , 192.52466 , 365.3871 ], [ 67.055145 , 88.534515 , 137.3221 , 130.74608 ], [227.8164 , 291.93015 , 370.9528 , 434.4086 ], [147.73048 , 218.15501 , 177.35306 , 260.56738 ], [ 82.44483 , 40.140255 , 133.15623 , 107.72627 ], [122.62652 , 239.552 , 141.19394 , 272.06354 ], [154.03288 , 115.91441 , 372.5167 , 426.57187 ], [218.90562 , 364.88345 , 247.20554 , 419.03842 ], [248.15126 , 407.61325 , 373.63068 , 479.57568 ], [139.69551 , 248.66753 , 154.51906 , 264.16055 ], [212.88734 , 195.23204 , 238.25243 , 209.22202 ]], dtype=float32), 'class_ids': array([ 1, 1, 1, 1, 1, 1, 1, 1, 1, 46, 1, 46, 61, 46, 57, 45, 40], dtype=int32), 'scores': array([0.99917287, 0.992269 , 0.99193186, 0.98929125, 0.986894 , 0.98671734, 0.98594207, 0.97716457, 0.97271395, 0.97136974, 0.9637522 , 0.9585419 , 0.9218482 , 0.8920589 , 0.85597926, 0.81343234, 0.78660023], dtype=float32)} \u5c06\u68c0\u6d4b\u7ed3\u679c\u5c55\u793a\u5728\u56fe\u50cf\u4e0a\uff1a # \u5c06\u68c0\u6d4b\u7ed3\u679c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a visualize . display_instances ( ori_img , res [ 'rois' ], res [ 'class_ids' ], classes , res [ 'scores' ]) plt . show () \u4e0a\u8ff0\u6211\u4eec\u4ecb\u7ecd\u4e86Faster RCNN\u7684\u5de5\u4f5c\u6d41\u7a0b\u5e76\u4e14\u7ed9\u5927\u5bb6\u5c55\u793a\u4e86\u7f51\u7edc\u7684\u68c0\u6d4b\u7ed3\u679c\u3002\u90a3\u63a5\u4e0b\u6765\u6211\u4eec\u89e3\u51b3\u4ee5\u4e0b\u51e0\u4e2a\u95ee\u9898\uff1a 1\u3001\u7f51\u7edc\u4e2d\u7684\u6bcf\u4e00\u90e8\u5206\u662f\u600e\u4e48\u6784\u5efa\uff0c\u600e\u4e48\u5b8c\u6210\u76f8\u5e94\u7684\u529f\u80fd\u7684\uff1f 2\u3001\u600e\u4e48\u8bad\u7ec3fastrcnn\u7f51\u7edc\u53bb\u5b8c\u6210\u6211\u4eec\u81ea\u5df1\u7684\u4efb\u52a1\uff1f \u90a3\u63a5\u4e0b\u6765\u6211\u4eec\u5c31\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\u3002 2.\u6a21\u578b\u7ed3\u6784\u8be6\u89e3 \u00b6 Faster RCNN\u7684\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6211\u4eec\u4f9d\u7136\u5c06\u7f51\u7edc\u5206\u4e3a\u56db\u90e8\u5206\uff1a Backbone \uff1aBackbone\u7531CNN\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6784\u6210\uff0c\u5e38\u7528\u7684\u662fVGG\u548cresnet, \u7528\u6765\u63d0\u53d6\u56fe\u50cf\u4e2d\u7684\u7279\u5f81\uff0c\u83b7\u53d6\u56fe\u50cf\u7684\u7279\u5f81\u56fe\u3002\u8be5\u7279\u5f81\u56fe\u88ab\u5171\u4eab\u7528\u4e8e\u540e\u7eedRPN\u5c42\u751f\u6210\u5019\u9009\u533a\u57df\u548cROIPooling\u5c42\u4e2d\u3002 RPN\u7f51\u7edc \uff1aRPN\u7f51\u7edc\u7528\u4e8e\u751f\u6210\u5019\u9009\u533a\u57df\uff0c\u7528\u4e8e\u540e\u7eed\u7684\u76ee\u6807\u68c0\u6d4b\u3002 Roi Pooling : \u8be5\u90e8\u5206\u6536\u96c6\u56fe\u50cf\u7684\u7279\u5f81\u56fe\u548cRPN\u7f51\u7edc\u63d0\u53d6\u7684\u5019\u9009\u533a\u57df\u4f4d\u7f6e\uff0c\u7efc\u5408\u4fe1\u606f\u540e\u83b7\u53d6\u56fa\u5b9a\u5c3a\u5bf8\u7684\u7279\u5f81\uff0c\u9001\u5165\u540e\u7eed\u5168\u8fde\u63a5\u5c42\u5224\u5b9a\u76ee\u6807\u7c7b\u522b\u548c\u786e\u5b9a\u76ee\u6807\u4f4d\u7f6e\u3002 \u76ee\u6807\u5206\u7c7b\u4e0e\u56de\u5f52 : \u8be5\u90e8\u5206\u5229\u7528ROIpooling\u8f93\u51fa\u7279\u5f81\u5411\u91cf\u8ba1\u7b97\u5019\u9009\u533a\u57df\u7684\u7c7b\u522b\uff0c\u5e76\u901a\u8fc7\u56de\u5f52\u83b7\u5f97\u68c0\u6d4b\u6846\u6700\u7ec8\u7684\u7cbe\u786e\u4f4d\u7f6e\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u5c31\u4ece\u8fd9\u56db\u4e2a\u65b9\u9762\u6765\u8be6\u7ec6\u5206\u6790fasterRCNN\u7f51\u7edc\u7684\u6784\u6210\uff0c\u5e76\u7ed3\u5408\u6e90\u7801\u7406\u89e3\u6bcf\u4e00\u90e8\u5206\u5b9e\u73b0\u7684\u529f\u80fd\u3002 2.1backbone \u00b6 backbone\u4e00\u822c\u4e3aVGG\uff0cResNet\u7b49\u7f51\u7edc\u6784\u6210\uff0c\u4e3b\u8981\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5c06\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\u820d\u5f03\uff0c\u5f97\u5230\u7279\u5f81\u56fe\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u5904\u7406\u3002 \u5728\u6e90\u7801\u4e2d\u4f7f\u7528ResNet + FPN \u7ed3\u6784\u6765\u63d0\u53d6\u7279\u5f81\u3002\u4e0e\u666e\u901a\u7684 FasterRCNN \u53ea\u9700\u8981\u5c06\u4e00\u4e2a\u7279\u5f81\u56fe\u8f93\u5165\u5230\u540e\u7eed\u7f51\u7edc\u4e2d\u4e0d\u540c\uff0c\u7531\u4e8e\u52a0\u5165 FPN\u7ed3\u6784\uff0c\u9700\u8981\u5c06\u591a\u4e2a\u7279\u5f81\u56fe\u9010\u4e2a\u9001\u5165\u5230\u540e\u7eed\u7f51\u7edc\u4e2d\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a Resnet\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0cFPN\u7ed3\u6784\u4f5c\u7528\u662f\u5f53\u524d\u5c42\u7684\u7279\u5f81\u56fe\u4f1a\u878d\u5408\u672a\u6765\u5c42\u7684\u7279\u5f81\u8fdb\u884c\u4e0a\u91c7\u6837\uff0c\u5e76\u52a0\u4ee5\u5229\u7528\u3002\u56e0\u4e3a\u6709\u4e86\u8fd9\u6837\u4e00\u4e2a\u7ed3\u6784\uff0c\u5f53\u524d\u7684\u7279\u5f81\u56fe\u5c31\u53ef\u4ee5\u83b7\u53d6\u672a\u6765\u5c42\u7684\u4fe1\u606f\uff0c\u4e5f\u5c31\u5c06\u4f4e\u9636\u7279\u5f81\u4e0e\u9ad8\u9636\u7279\u5f81\u5c31\u6709\u673a\u878d\u5408\u8d77\u6765\u4e86\uff0c\u63d0\u5347\u68c0\u6d4b\u7cbe\u5ea6\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5728\u8fd9\u91ccResNet\u548cFPN\u7684\u5b8c\u6574\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a:Resnet\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0cFPN\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u878d\u5408\u83b7\u53d6\u591a\u4e2a\u7279\u5f81\u56fe\u540e\uff0c\u8f93\u5165\u5230RPN\u7f51\u7edc\u4e2d\u7684\u7279\u5f81\u56fe\u662f[p2,p3,p4,p5,p6] \uff0c\u800c\u4f5c\u4e3a\u540e\u7eed\u76ee\u6807\u68c0\u6d4b\u7f51\u7edcFastRCNN\u7684\u8f93\u5165\u5219\u662f [p2,p3,p4,p5] \u3002 \u6211\u4eec\u770b\u4e0b\u6e90\u7801\u5b9e\u73b0\u7684\u5185\u5bb9\uff1a 1\u3001resnet\u7279\u5f81\u63d0\u53d6\u7684\u7ed3\u679c # \u4f7f\u7528backbone\u83b7\u53d6\u7279\u5f81\u56fe C2 , C3 , C4 , C5 = model . backbone ( image , training = False ) C2,C3,C4,C5\u662fresnet\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u7684\u7ed3\u679c\uff0c\u9001\u5165\u7f51\u7edc\u4e2d\u56fe\u50cf\u5927\u5c0f\u4e3a\uff081216\uff0c1216\uff0c3\uff09\uff0c\u7ecf\u8fc7\u7279\u5f81\u63d0\u53d6\u540e\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u4e3a\uff1a # C2.shape:1216/4 TensorShape ([ 1 , 304 , 304 , 256 ]) # C3.shape:1216/8 TensorShape ([ 1 , 152 , 152 , 512 ]) # C4.shape:1216/16 TensorShape ([ 1 , 76 , 76 , 1024 ]) # C5.shape:1216/32 TensorShape ([ 1 , 38 , 38 , 2048 ]) 2\u3001FPN\u7279\u5f81\u878d\u5408\u7684\u7ed3\u679c # FPN\u7f51\u7edc\u878d\u5408\uff1aC2,C3,C4,C5\u662fresnet\u63d0\u53d6\u7684\u7279\u5f81\u7ed3\u679c P2 , P3 , P4 , P5 , P6 = model . neck ([ C2 , C3 , C4 , C5 ], training = False ) P2,P3,P4,P5,P6\u662f\u7279\u5f81\u878d\u5408\u4e4b\u540e\u7684\u7ed3\u679c\uff0c\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\uff0c\u5176\u7279\u5f81\u56fe\u7684\u5927\u5c0f\uff1a # P2.shape:1216/4 TensorShape ([ 1 , 304 , 304 , 256 ]) # P3.shape:1216/8 TensorShape ([ 1 , 152 , 152 , 512 ]) # P4.shape:1216/16 TensorShape ([ 1 , 76 , 76 , 1024 ]) # P5.shape:1216/32 TensorShape ([ 1 , 38 , 38 , 2048 ]) # P6.shape:1216/64 TensorShape ([ 1 , 19 , 19 , 256 ]) \u90a3\u7f51\u7edc\u7684\u6574\u4f53\u67b6\u6784\u8868\u793a\u6210\uff1a 2.2 RPN\u7f51\u7edc \u00b6 \u7ecf\u5178\u7684\u68c0\u6d4b\u65b9\u6cd5\u751f\u6210\u68c0\u6d4b\u6846\u90fd\u975e\u5e38\u8017\u65f6\uff0c\u5982overfeat\u4e2d\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u751f\u6210\u68c0\u6d4b\u6846\uff1b\u6216\u5982R-CNN\u4f7f\u7528\u9009\u62e9\u6027\u641c\u7d22\u65b9\u6cd5\u751f\u6210\u68c0\u6d4b\u6846\u3002\u800cFaster RCNN\u5219\u629b\u5f03\u4e86\u4f20\u7edf\u7684\u6ed1\u52a8\u7a97\u53e3\u548c\u9009\u62e9\u6027\u641c\u7d22\u7684\u65b9\u6cd5\uff0c\u76f4\u63a5\u4f7f\u7528RPN\u751f\u6210\u5019\u9009\u533a\u57df\uff0c\u80fd\u6781\u5927\u63d0\u5347\u68c0\u6d4b\u901f\u5ea6\u3002 RPN\u7f51\u7edc\u7684\u4e3b\u8981\u6d41\u7a0b\u662f\uff1a 1\u3001\u751f\u6210\u4e00\u7cfb\u5217\u7684\u56fa\u5b9a\u53c2\u8003\u6846anchors,\u8986\u76d6\u56fe\u50cf\u7684\u4efb\u610f\u4f4d\u7f6e\uff0c\u7136\u540e\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52 2\u3001\u5206\u7c7b\u5206\u652f\uff1a\u901a\u8fc7softmax\u5206\u7c7b\u5224\u65adanchor\u4e2d\u662f\u5426\u5305\u542b\u76ee\u6807 3\u3001\u56de\u5f52\u5206\u652f\uff1a\u8ba1\u7b97\u76ee\u6807\u6846\u5bf9\u4e8eanchors\u7684\u504f\u79fb\u91cf\uff0c\u4ee5\u83b7\u5f97\u7cbe\u786e\u7684\u5019\u9009\u533a\u57df 4\u3001\u6700\u540e\u7684Proposal\u5c42\u5219\u8d1f\u8d23\u7efc\u5408\u542b\u6709\u76ee\u6807\u7684anchors\u548c\u5bf9\u5e94bbox\u56de\u5f52\u504f\u79fb\u91cf\u83b7\u53d6\u5019\u9009\u533a\u57df\uff0c\u540c\u65f6\u5254\u9664\u592a\u5c0f\u548c\u8d85\u51fa\u8fb9\u754c\u7684\u5019\u9009\u533a\u57df\u3002 2.2.1 anchors \u00b6 anchor\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u8868\u793a \u56fa\u5b9a\u7684\u53c2\u8003\u6846 \uff0c\u9996\u5148\u9884\u8bbe\u4e00\u7ec4\u4e0d\u540c\u5c3a\u5ea6\u4e0d\u540c\u957f\u5bbd\u6bd4\u7684\u56fa\u5b9a\u53c2\u8003\u6846\uff0c\u8986\u76d6\u51e0\u4e4e\u6240\u6709\u4f4d\u7f6e\uff0c \u6bcf\u4e2a\u53c2\u8003\u6846\u8d1f\u8d23\u68c0\u6d4b\u4e0e\u5176\u4ea4\u5e76\u6bd4\u5927\u4e8e\u9608\u503c (\u8bad\u7ec3\u9884\u8bbe\u503c\uff0c\u5e38\u75280.5\u62160.7) \u7684\u76ee\u6807 \uff0canchor\u6280\u672f\u5c06\u5019\u9009\u533a\u57df\u751f\u6210\u95ee\u9898\u8f6c\u6362\u4e3a \"\u8fd9\u4e2a\u56fa\u5b9a\u53c2\u8003\u6846\u4e2d\u6709\u6ca1\u6709\u76ee\u6807\uff0c\u76ee\u6807\u6846\u504f\u79bb\u53c2\u8003\u6846\u591a\u8fdc\" \uff0c\u4e0d\u518d\u9700\u8981\u591a\u5c3a\u5ea6\u904d\u5386\u6ed1\u7a97\uff0c\u771f\u6b63\u5b9e\u73b0\u4e86\u53c8\u597d\u53c8\u5feb\u3002 \u5728FastRCNN\u4e2d\u6846\u51fa\u591a\u5c3a\u5ea6\u3001\u591a\u79cd\u957f\u5bbd\u6bd4\u7684anchors,\u5982\u4e0b\u56fe\u6240\u793a\uff1a\u4e0b\u56fe\u4e2d\u5206\u522b\u662f\u5c3a\u5ea6\u4e3a32\uff0c64\uff0c128\uff0c\u957f\u5bbd\u6bd4\u4e3a1\uff1a1\uff0c1:2\uff0c2\uff1a1\u7684\u4e00\u7ec4anchors,\u6211\u4eec\u5229\u7528\u8fd9\u7ec4anchor\u5728\u7279\u5f81\u56fe\u4e0a\u8fdb\u884c\u6ed1\u52a8\uff0c\u5e76\u5bf9\u5e94\u5230\u539f\u56fe\u4e0a\u5373\u53ef\u83b7\u53d6\u4e00\u7cfb\u5217\u7684\u56fa\u5b9a\u53c2\u8003\u6846\u3002 \u7531\u4e8e\u6709 FPN \u7f51\u7edc\uff0c\u6240\u4ee5\u4f1a\u5728\u591a\u4e2a\u4e0d\u540c\u5c3a\u5ea6\u7279\u5f81\u56fe\u4e2d\u751f\u6210anchor\uff0c\u5047\u8bbe\u67d0\u4e00\u4e2a\u7279\u5f81\u56fe\u5927\u5c0f\u4e3ahxw\uff0c\u9996\u5148\u4f1a\u8ba1\u7b97\u8fd9\u4e2a\u7279\u5f81\u76f8\u5bf9\u4e8e\u8f93\u5165\u56fe\u50cf\u7684\u4e0b\u91c7\u6837\u500d\u6570 stride\uff1a \u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6bcf\u4e00\u4e2a\u5c3a\u5ea6\u7279\u5f81\u56fe\u4e0a\u751f\u6210\u4e0d\u540c\u6bd4\u5217\u7684anchor: \u5f97\u5230\u4e00\u7cfb\u5217\u7684anchors\u540e\u5c31\u53ef\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\u3002 \u5728\u6e90\u7801\u4e2d\u6211\u4eec\u53ef\u751f\u6210\u4e00\u5e45\u56fe\u50cf\u5bf9\u5e94\u7684anchors: # \u4ea7\u751fanchor\uff1a\u8f93\u5165\u56fe\u50cf\u5143\u4fe1\u606f\u5373\u53ef\uff0c\u8f93\u51faanchor\u5bf9\u5e94\u4e8e\u539f\u56fe\u7684\u5750\u6807\u503c anchors , valid_flags = model . rpn_head . generator . generate_pyramid_anchors ( imagemeta ) \u5bf9\u4e8e1216x1216\u7684\u56fe\u50cf\u751f\u6210\u7684anchor\u7684\u6570\u91cf\u4e3a\uff1a # anchors.shape\uff1a #304*304*3+152*152*3+76*76*3+38*38*3+19*19*3=369303 TensorShape ([ 369303 , 4 ]) anchor\u7684\u53d6\u503c\u4e3a\uff1a < tf . Tensor : shape = ( 369303 , 4 ), dtype = float32 , numpy = array ([[ - 22.627417 , - 11.313708 , 22.627417 , 11.313708 ], [ - 16. , - 16. , 16. , 16. ], [ - 11.313708 , - 22.627417 , 11.313708 , 22.627417 ], ... , [ 789.9613 , 970.98065 , 1514.0387 , 1333.0193 ], [ 896. , 896. , 1408. , 1408. ], [ 970.98065 , 789.9613 , 1333.0193 , 1514.0387 ]], dtype = float32 ) > \u6211\u4eec\u5c06\u524d10000\u4e2aanchor\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a\uff1a # \u7ed8\u5236\u5728\u56fe\u50cf\u4e0a(\u5c06anchor\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a) visualize . draw_boxes ( rgd_image [ 0 ], boxes = anchors [: 10000 ,: 4 ]) plt . show () 2.2.2 RPN\u5206\u7c7b \u00b6 \u4e00\u526fMxN\u5927\u5c0f\u7684\u77e9\u9635\u9001\u5165Faster RCNN\u7f51\u7edc\u540e\uff0c\u7ecf\u8fc7backbone\u7279\u5f81\u63d0\u53d6\u5230RPN\u7f51\u7edc\u53d8\u4e3aHxW\u5927\u5c0f\u7684\u7279\u5f81\u56fe\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u662fRPN\u8fdb\u884c\u5206\u7c7b\u7684\u7f51\u7edc\u7ed3\u6784\uff1a(k=9) \u5148\u505a\u4e00\u4e2a1x1\u7684\u5377\u79ef\uff0c\u5f97\u5230[batchsize,H,W,18]\u7684\u7279\u5f81\u56fe\uff0c\u7136\u540e\u8fdb\u884c\u53d8\u5f62,\u5c06\u7279\u5f81\u56fe\u8f6c\u6362\u4e3a[batchsize,9xH,W,2]\u7684\u7279\u5f81\u56fe\u540e\uff0c\u9001\u5165softmax\u4e2d\u8fdb\u884c\u5206\u7c7b\uff0c\u5f97\u5230\u5206\u7c7b\u7ed3\u679c\u540e\uff0c\u518d\u8fdb\u884creshape\u6700\u7ec8\u5f97\u5230[batchsize,H,W,18]\u5927\u5c0f\u7684\u7ed3\u679c,18\u8868\u793ak=9\u4e2aanchor\u662f\u5426\u5305\u542b\u76ee\u6807\u7684\u6982\u7387\u503c\u3002 2.2.3 RPN\u56de\u5f52 \u00b6 RPN\u56de\u5f52\u7684\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a(k=9) \u7ecf\u8fc7\u8be5\u5377\u79ef\u8f93\u51fa\u7279\u5f81\u56fe\u4e3a\u4e3a[1, H, W,4x9]\uff0c\u8fd9\u91cc\u76f8\u5f53\u4e8efeature maps\u6bcf\u4e2a\u70b9\u90fd\u67099\u4e2aanchors\uff0c\u6bcf\u4e2aanchors\u53c8\u90fd\u67094\u4e2a\u7528\u4e8e\u56de\u5f52\u7684: \u53d8\u6362\u91cf\u3002 \u8be5\u53d8\u6362\u91cf\u9884\u6d4b\u7684\u662fanchor\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u5e73\u79fb\u91cf\u548c\u5c3a\u5ea6\u56e0\u5b50\uff1a \u5229\u7528\u6e90\u7801\u6211\u4eec\u53ef\u4ee5\u83b7\u5f97\u5bf9anchors\u7684\u5206\u7c7b\u548c\u56de\u5f52\u7ed3\u679c\uff1a # RPN\u7f51\u7edc\u7684\u8f93\u5165:FPN\u7f51\u7edc\u83b7\u53d6\u7684\u7279\u5f81\u56fe rpn_feature_maps = [ P2 , P3 , P4 , P5 , P6 ] # RPN\u7f51\u7edc\u9884\u6d4b\uff0c\u8fd4\u56de\uff1alogits\u9001\u5165softmax\u4e4b\u524d\u7684\u5206\u6570\uff0c\u5305\u542b\u76ee\u6807\u7684\u6982\u7387\uff0c\u5bf9\u6846\u7684\u4fee\u6b63\u7ed3\u679c rpn_class_logits , rpn_probs , rpn_deltas = model . rpn_head ( rpn_feature_maps , training = False ) \u7ed3\u679c\u5206\u6790\uff1a # rpn_class_logits.shape,\u6bcf\u4e00\u4e2aanchor\u90fd\u8fdb\u884c\u4e86\u5206\u7c7b\u5206\u6790 TensorShape ([ 1 , 369303 , 2 ]) # rpn_probs.shape\uff1asoftmax\u8f93\u51fa\u7684\u6982\u7387\u503c TensorShape ([ 1 , 369303 , 2 ]) # rpn_deltas.shape \uff1a\u56de\u5f52\u7ed3\u679c TensorShape ([ 1 , 369303 , 4 ]) \u5176\u4e2d rpn_probs\u7684\u53d6\u503c\u4e3a\uff1a <tf.Tensor: shape=(1, 369303, 2), dtype=float32, numpy= array([[[9.94552910e-01, 5.44707105e-03], [9.97310877e-01, 2.68914248e-03], [9.95540321e-01, 4.45961533e-03], ..., [9.99888301e-01, 1.11637215e-04], [9.99961257e-01, 3.87872169e-05], [9.99820888e-01, 1.79159630e-04]]], dtype=float32)> \u6211\u4eec\u83b7\u53d6\u4e00\u4e9b\u5206\u7c7b\u7f6e\u4fe1\u5ea6\u8f83\u9ad8\u7684\u7ed3\u679c\uff0c\u5c06\u8fd9\u4e9banchor\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a\uff1a # \u83b7\u53d6\u5206\u7c7b\u7ed3\u679c\u4e2d\u5305\u542b\u76ee\u6807\u7684\u6982\u7387\u503c rpn_probs_tmp = rpn_probs [ 0 ,:, 1 ] # \u83b7\u53d6\u524d100\u4e2a\u8f83\u9ad8\u7684anchor limit = 100 ix = tf . nn . top_k ( rpn_probs_tmp , k = limit ) . indices [:: - 1 ] # \u83b7\u53d6\u5bf9\u5e94\u7684anchor\u7ed8\u5236\u56fe\u50cf\u4e0a\uff0c\u90a3\u8fd9\u4e9banchor\u5c31\u6709\u5f88\u5927\u6982\u7387\u751f\u6210\u5019\u9009\u533a\u57df visualize . draw_boxes ( rgd_image [ 0 ], tf . gather ( anchors , ix ) . numpy ()) 4.2.4 Proposal\u5c42 \u00b6 Proposal\u5c42\u8d1f\u8d23\u7efc\u5408RPN\u7f51\u7edc\u5bf9anchors\u5206\u7c7b\u548c\u56de\u5f52\u7684\u7ed3\u679c\uff0c\u5229\u7528\u56de\u5f52\u7684\u7ed3\u679c\u5bf9\u5305\u542b\u76ee\u6807\u7684anchors\u8fdb\u884c\u4fee\u6b63\uff0c\u8ba1\u7b97\u51fa\u5019\u9009\u533a\u57df\uff0c\u9001\u5165\u540e\u7eedRoI Pooling\u5c42\u4e2d\u3002 Proposal\u5c42\u5904\u7406\u6d41\u7a0b\u5982\u4e0b\uff1a \u5229\u7528RPN\u7f51\u7edc\u56de\u5f52\u7684\u7ed3\u679c \u5bf9\u6240\u6709\u7684anchors\u8fdb\u884c\u4fee\u6b63\uff0c\u5f97\u5230\u4fee\u6b63\u540e\u7684\u68c0\u6d4b\u6846 \u6839\u636eRPN\u7f51\u7edc\u5206\u7c7b\u7684softmax\u8f93\u51fa\u7684\u6982\u7387\u503c\u7531\u5927\u5230\u5c0f\u5bf9\u68c0\u6d4b\u6846\u8fdb\u884c\u6392\u5e8f\uff0c\u63d0\u53d6\u524d6000\u4e2a\u7ed3\u679c\uff0c\u5373\u63d0\u53d6\u4fee\u6b63\u4f4d\u7f6e\u540e\u7684\u68c0\u6d4b\u6846 \u9650\u5b9a\u8d85\u51fa\u56fe\u50cf\u8fb9\u754c\u7684\u68c0\u6d4b\u6846\u4e3a\u56fe\u50cf\u8fb9\u754c\uff0c\u9632\u6b62\u540e\u7eedroi pooling\u65f6\u5019\u9009\u533a\u57df\u8d85\u51fa\u56fe\u50cf\u8fb9\u754c\u3002 \u5bf9\u5269\u4f59\u7684\u68c0\u6d4b\u6846\u8fdb\u884c\u975e\u6781\u5927\u503c\u6291\u5236NMS Proposal\u5c42\u7684\u8f93\u51fa\u662f\u5bf9\u5e94\u8f93\u5165\u7f51\u7edc\u56fe\u50cf\u5c3a\u5ea6\u7684\u5f52\u4e00\u5316\u540e\u7684\u5750\u6807\u503c[x1, y1, x2, y2]\u3002 \u5230\u6b64RPN\u7f51\u7edc\u7684\u5de5\u4f5c\u5c31\u7ed3\u675f\u4e86\u3002 Proposal\u5c42\u67093\u4e2a\u8f93\u5165\uff1aRPN\u5206\u7c7b\u548c\u56de\u5f52\u7ed3\u679c\uff0c\u4ee5\u53ca\u56fe\u50cf\u7684\u5143\u4fe1\u606f\u3002 # \u83b7\u53d6\u5019\u9009\u533a\u57df proposals_list = model . rpn_head . get_proposals ( rpn_probs , rpn_deltas , imagemeta ) \u7ed3\u679c\u4e3a\uff1a [ < tf . Tensor : shape = ( 1533 , 4 ), dtype = float32 , numpy = array ([[ 0.20729761 , 0.00852748 , 0.748096 , 0.46975034 ], [ 0.42213044 , 0.5887971 , 0.7810232 , 0.9806169 ], [ 0.40125194 , 0.4384725 , 0.48458642 , 0.47913405 ], ... , [ 0.25977597 , 0.435113 , 0.27290097 , 0.4483906 ], [ 0.38884488 , 0.41798416 , 0.41393432 , 0.4339822 ], [ 0.5885266 , 0.65331775 , 0.62330776 , 0.6913476 ]], dtype = float32 ) > ] \u5c06\u5176\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a # \u7ed8\u5236\u5728\u56fe\u50cf\u4e0a(\u5c06proposal\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a) visualize . draw_boxes ( rgd_image [ 0 ], boxes = proposals_list [ 0 ] . numpy ()[:,: 4 ] * 1216 ) plt . show () 2.3 ROIPooling \u00b6 RoI Pooling\u5c42\u5219\u8d1f\u8d23\u6536\u96c6RPN\u7f51\u7edc\u751f\u6210\u7684\u5019\u9009\u533a\u57df\uff0c\u5e76\u5c06\u5176\u6620\u5c04\u5230\u7279\u5f81\u56fe\u4e2d\u5e76\u56fa\u5b9a\u7ef4\u5ea6\uff0c\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\u3002 RoI Pooling \u7684\u4f5c\u7528\u8fc7\u7a0b\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a RoIpooling\u4f7f\u7528\u6700\u5927\u6c60\u5316\u5c06\u4efb\u4f55\u6709\u6548\u7684RoI\u533a\u57df\u5185\u7684\u7279\u5f81\u8f6c\u6362\u6210\u5177\u6709pool_H\u00d7pool_W\u7684\u56fa\u5b9a\u7a7a\u95f4\u8303\u56f4\u7684\u5c0f\u7684\u7279\u5f81\u56fe\uff0c\u5176\u4e2dpool_H\u548cpool_W\u662f\u8d85\u53c2\u6570\uff0c\u6bd4\u5982\u8bbe\u7f6e\u4e3a7x7, \u5b83\u4eec\u72ec\u7acb\u4e8e\u4efb\u4f55\u7279\u5b9a\u7684RoI,\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5728\u5b9e\u73b0\u8fc7\u7a0b\u4e2d\uff0cFPN\u7f51\u7edc\u4ea7\u751f\u4e86\u591a\u4e2a\u5c3a\u5ea6\u7279\u5f81\u56fe\uff0c\u90a3\u5019\u9009\u533a\u57df\u8981\u6620\u5c04\u5230\u54ea\u4e2a\u7279\u5f81\u56fe\u4e2d\u5462\uff1f \u5728\u8fd9\u91cc\uff0c\u4e0d\u540c\u5c3a\u5ea6\u7684ROI\u4f7f\u7528\u4e0d\u540c\u7279\u5f81\u5c42\u4f5c\u4e3aROI pooling\u5c42\u7684\u8f93\u5165\uff0c\u5927\u5c3a\u5ea6ROI\u5c31\u7528\u540e\u9762\u4e00\u4e9b\u7684\u91d1\u5b57\u5854\u5c42\uff0c\u6bd4\u5982P5\uff1b\u5c0f\u5c3a\u5ea6ROI\u5c31\u7528\u524d\u9762\u4e00\u70b9\u7684\u7279\u5f81\u5c42\uff0c\u6bd4\u5982P3\uff0c\u6211\u4eec\u4f7f\u7528\u4e0b\u9762\u7684\u516c\u5f0f\u786e\u5b9aROI\u6240\u5728\u7684\u7279\u5f81\u5c42\uff1a \u5176\u4e2d\uff0c224\u662fImageNet\u7684\u6807\u51c6\u8f93\u5165\uff0ck0\u662f\u57fa\u51c6\u503c\uff0c\u8bbe\u7f6e\u4e3a4\uff0cw\u548ch\u662fROI\u533a\u57df\u7684\u957f\u548c\u5bbd\uff0c\u5047\u8bbeROI\u662f112x112\u7684\u5927\u5c0f\uff0c\u90a3\u4e48k = k0-1 = 4-1 = 3\uff0c\u610f\u5473\u7740\u8be5ROI\u5e94\u8be5\u4f7f\u7528P3\u7684\u7279\u5f81\u5c42\u3002k\u503c\u4f1a\u505a\u53d6\u6574\u5904\u7406\uff0c\u9632\u6b62\u7ed3\u679c\u4e0d\u662f\u6574\u6570\uff0c\u800c\u4e14\u4e3a\u4e86\u4fdd\u8bc1k\u503c\u57282-5\u4e4b\u95f4\uff0c\u8fd8\u4f1a\u505a\u622a\u65ad\u5904\u7406\u3002 # ROI Pooling\u5c42\u5b9e\u73b0:\u8f93\u5165\u662f\u5019\u9009\u533a\u57df\uff0c\u7279\u5f81\u56fe\uff0c\u56fe\u50cf\u7684\u5143\u4fe1\u606f pool_region_list = model . roi_align (( proposals_list , rcnn_feature_maps , imagemeta ), training = False ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a\u6bcf\u4e00\u4e2a\u5019\u9009\u533a\u57df\u90fd\u88ab\u56fa\u5b9a\u4e3a7x7\u5927\u5c0f [ < tf . Tensor : shape = ( 1533 , 7 , 7 , 256 ), dtype = float32 , numpy = array ([[[[ - 6.26428795e+00 , 3.55317879e+00 , 3.37260556e+00 , ... , 6.22574663e+00 , 3.75851846e+00 , - 2.49103808e+00 ], [ - 9.01443863e+00 , 7.67611027e-01 , 7.18744850e+00 , ... , 6.20492172e+00 , 4.09835625e+00 , 6.05924249e-01 ], [ - 7.43907213e+00 , - 3.76329374e+00 , 5.01457691e+00 , ... , 6.22656918e+00 , 1.19414163e+00 , 3.06410480e+00 ], ... , [ 1.39127302e+00 , - 1.71078873e+00 , 4.01916075e+00 , ... , 5.94641972e+00 , 3.63194764e-01 , 2.91014194e+00 ], [ - 5.21681070e+00 , 2.39917469e+00 , 2.49682212e+00 , ... , 5.92232943e+00 , 3.01222801e+00 , 1.63518691e+00 ], [ - 1.26697767e+00 , - 6.90211892e-01 , 4.50919747e-01 , ... , 1.97156405e+00 , - 1.07467103e+00 , 4.54943466e+00 ]] 2.4 \u76ee\u6807\u5206\u7c7b\u4e0e\u56de\u5f52 \u00b6 \u8be5\u90e8\u5206\u5229\u7528\u83b7\u5f97\u7684\u5019\u9009\u533a\u57df\u7684\u7279\u5f81\u56fe\uff0c\u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u4e0esoftmax\u8ba1\u7b97\u6bcf\u4e2a\u5019\u9009\u533a\u57df\u5177\u4f53\u5c5e\u4e8e\u7684\u7c7b\u522b\uff08\u5982\u4eba\uff0c\u8f66\uff0c\u7535\u89c6\u7b49\uff09\uff0c\u8f93\u51fa\u6982\u7387\u503c\uff1b\u540c\u65f6\u518d\u6b21\u5229\u7528\u56de\u5f52\u65b9\u6cd5\u83b7\u5f97\u6bcf\u4e2a\u5019\u9009\u533a\u57df\u7684\u4f4d\u7f6e\u504f\u79fb\u91cf\uff0c\u7528\u4e8e\u56de\u5f52\u66f4\u52a0\u7cbe\u786e\u7684\u76ee\u6807\u68c0\u6d4b\u6846\u3002\u8be5\u90e8\u5206\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a \u4eceRoI Pooling\u5c42\u83b7\u53d6\u5230\u56fa\u5b9a\u5927\u5c0f\u7684\u7279\u5f81\u56fe\u540e\uff0c\u9001\u5165\u540e\u7eed\u7f51\u7edc\uff0c\u53ef\u4ee5\u770b\u5230\u505a\u4e86\u5982\u4e0b2\u4ef6\u4e8b\uff1a \u901a\u8fc7\u5168\u8fde\u63a5\u548csoftmax\u5bf9\u5019\u9009\u533a\u57df\u8fdb\u884c\u5206\u7c7b \u518d\u6b21\u5bf9\u5019\u9009\u533a\u57df\u8fdb\u884c\u56de\u5f52\u4fee\u6b63\uff0c\u83b7\u53d6\u66f4\u9ad8\u7cbe\u5ea6\u7684\u68c0\u6d4b\u6846 \u5b9e\u73b0\u6d41\u7a0b\u5982\u4e0b\uff1a \u9996\u5148\u83b7\u53d6\u7f51\u7edc\u5206\u7c7b\u548c\u56de\u5f52\u7684\u7ed3\u679c\uff1a # RCNN\u7f51\u7edc\u7684\u9884\u6d4b:\u8f93\u5165\u662fROIPooling\u5c42\u7684\u7279\u5f81\uff0c\u8f93\u51fa\uff1a\u7c7b\u522b\u7684score,\u7c7b\u522b\u7684\u6982\u7387\u503c\uff0c\u56de\u5f52\u7ed3\u679c rcnn_class_logits , rcnn_class_probs , rcnn_deltas_list = model . bbox_head ( pool_region_list , training = False \uff09 \u5229\u7528\u7ed3\u679c\u5bf9\u5019\u9009\u533a\u57df\u8fdb\u884c\u4fee\u6b63\uff1a # \u83b7\u53d6\u9884\u6d4b\u7ed3\u679c:\u8f93\u5165\uff1arcnn\u8fd4\u56de\u7684\u5206\u7c7b\u548c\u56de\u5f52\u7ed3\u679c\uff0c\u5019\u9009\u533a\u57df\uff0c\u56fe\u50cf\u5143\u4fe1\u606f\uff0c\u8f93\u51fa\uff1a\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c detection_list = model . bbox_head . get_bboxes ( rcnn_class_probs , rcnn_deltas_list , proposals_list , imagemeta ) \u7ed3\u679c\u4e3a\uff1a\u4e00\u5171\u68c0\u6d4b\u51fa17\u4e2a\u76ee\u6807\uff0c\u6bcf\u4e2a\u76ee\u6807\u53f3\u76ee\u6807\u4f4d\u7f6e\uff0c\u76ee\u6807\u7c7b\u522bid\uff0c\u76ee\u6807\u7c7b\u522b\u7f6e\u4fe1\u5ea66\u4e2a\u503c\u6784\u6210\u3002 [ < tf . Tensor : shape = ( 17 , 6 ), dtype = float32 , numpy = array ([[ 2.3262584e+02 , 2.1799168e+01 , 9.0194098e+02 , 5.4503723e+02 , 1.0000000e+00 , 9.9917287e-01 ], [ 1.4013255e+02 , 5.5109363e+02 , 3.8764392e+02 , 7.5518970e+02 , 1.0000000e+00 , 9.9226898e-01 ], [ 2.0952664e+02 , 7.8792090e+02 , 8.9771838e+02 , 1.2104146e+03 , 1.0000000e+00 , 9.9193186e-01 ], [ 2.0348978e+02 , 4.1579453e+02 , 3.3001547e+02 , 5.3761450e+02 , 1.0000000e+00 , 9.8929125e-01 ], [ 1.8087936e+02 , 7.9734338e+02 , 5.1281873e+02 , 1.0274907e+03 , 1.0000000e+00 , 9.8689401e-01 ], [ 1.7813437e+02 , 2.3680782e+00 , 5.0309012e+02 , 1.1671781e+02 , 1.0000000e+00 , 9.8671734e-01 ], [ 1.5557167e+02 , 6.2398212e+02 , 4.6821997e+02 , 8.8862134e+02 , 1.0000000e+00 , 9.8594207e-01 ], [ 1.6307811e+02 , 2.1531593e+02 , 3.3396735e+02 , 3.1797446e+02 , 1.0000000e+00 , 9.7716457e-01 ], [ 5.5404950e+02 , 7.0997412e+02 , 9.0215717e+02 , 1.0564817e+03 , 1.0000000e+00 , 9.7271395e-01 ], [ 3.5928052e+02 , 5.3055298e+02 , 4.3132263e+02 , 6.3369983e+02 , 4.6000000e+01 , 9.7136974e-01 ], [ 2.0050583e+02 , 9.7621101e+01 , 3.2383597e+02 , 2.6199030e+02 , 1.0000000e+00 , 9.6375221e-01 ], [ 2.9822769e+02 , 5.8259045e+02 , 3.4338364e+02 , 6.6165851e+02 , 4.6000000e+01 , 9.5854193e-01 ], [ 3.7460797e+02 , 2.8190384e+02 , 9.0596057e+02 , 1.0374227e+03 , 6.1000000e+01 , 9.2184818e-01 ], [ 5.3237848e+02 , 8.8739655e+02 , 6.0120386e+02 , 1.0191014e+03 , 4.6000000e+01 , 8.9205891e-01 ], [ 6.0350385e+02 , 9.9131537e+02 , 9.0866974e+02 , 1.1663280e+03 , 5.7000000e+01 , 8.5597926e-01 ], [ 3.3973947e+02 , 6.0475940e+02 , 3.7579034e+02 , 6.4243842e+02 , 4.5000000e+01 , 8.1343234e-01 ], [ 5.1774200e+02 , 4.7480432e+02 , 5.7942987e+02 , 5.0882794e+02 , 4.0000000e+01 , 7.8660023e-01 ]], dtype = float32 ) > ] \u53ef\u4ee5\u5c06\u5176\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a\uff1a # \u7ed8\u5236\u5728\u56fe\u50cf\u4e0a visualize . draw_boxes ( rgd_image [ 0 ], boxes = detection_list [ 0 ][:,: 4 ]) plt . show ( \uff09 \u5230\u8fd9\u6211\u4eec\u5c31\u5b8c\u6210\u4e86\u6574\u4e2a\u7f51\u7edc\u7684\u4ecb\u7ecd\u3002 3 FasterRCNN\u7684\u8bad\u7ec3 \u00b6 Faster R-CNN\u7684\u8bad\u7ec3\u5206\u4e3a\u4e24\u90e8\u5206\uff0c\u5373RPN\u7f51\u7edc\u548c\u68c0\u6d4b\u7f51\u7edcfastRCNN\u7684\u8bad\u7ec3\uff1a \u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u5206\u4e3a\u56db\u6b65\uff1a \u7b2c\u4e00\u6b65\uff1aRPN\u7f51\u7edc\u7684\u8bad\u7ec3\uff0c\u4f7f\u7528ImageNet\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u521d\u59cb\u5316\uff0c\u5e76\u7aef\u5230\u7aef\u5fae\u8c03\u7528\u4e8e\u533a\u57df\u5efa\u8bae\u4efb\u52a1\u3002 \u7b2c\u4e8c\u6b65\uff1a\u5229\u7528\u7b2c\u4e00\u6b65\u7684RPN\u751f\u6210\u7684\u5efa\u8bae\u6846\uff0c\u7531Fast R-CNN\u8bad\u7ec3\u4e00\u4e2a\u5355\u72ec\u7684\u68c0\u6d4b\u7f51\u7edc\uff0c\u8fd9\u4e2a\u68c0\u6d4b\u7f51\u7edc\u540c\u6837\u662f\u7531ImageNet\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u521d\u59cb\u5316\u7684\uff0c\u8fd9\u65f6\u5019\u4e24\u4e2a\u7f51\u7edc\u8fd8\u6ca1\u6709\u5171\u4eab\u5377\u79ef\u5c42\u3002 \u7b2c\u4e09\u6b65\uff1a\u7528\u68c0\u6d4b\u7f51\u7edc\u521d\u59cb\u5316RPN\u8bad\u7ec3\uff0c\u4f46\u662f\u56fa\u5b9a\u5171\u4eab\u7684\u5377\u79ef\u5c42\uff0c\u5e76\u4e14\u53ea\u5fae\u8c03RPN\u72ec\u6709\u7684\u5c42\uff0c\u73b0\u5728\u4e24\u4e2a\u7f51\u7edc\u5171\u4eab\u5377\u79ef\u5c42\u4e86\u3002 \u7b2c\u56db\u6b65\uff1a\u4fdd\u6301\u5171\u4eab\u7684\u5377\u79ef\u5c42\u56fa\u5b9a\uff0c\u5fae\u8c03Fast R-CNN\u7684fc\u5c42\u3002\u8fd9\u6837\uff0c\u4e24\u4e2a\u7f51\u7edc\u5171\u4eab\u76f8\u540c\u7684\u5377\u79ef\u5c42\uff0c\u6784\u6210\u4e00\u4e2a\u7edf\u4e00\u7684\u7f51\u7edc\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u5206\u522b\u4ecb\u7ecd\u5404\u4e2a\u8bad\u7ec3\u6b65\u9aa4\uff1a 3.1 RPN\u7f51\u7edc\u7684\u8bad\u7ec3 \u00b6 RPN\u7f51\u7edc\u7684\u4f5c\u7528\u4ece\u4f17\u591a\u7684anchors\u4e2d\u63d0\u53d6\u5305\u542b\u76ee\u6807\u7684\uff0c\u5e76\u4e14\u7ecf\u8fc7\u56de\u5f52\u8c03\u6574\u7684\u5019\u9009\u533a\u57df\u3002\u4e3a\u4e86\u8bad\u7ec3RPN\uff0c\u7ed9\u6bcf\u4e2aanchor\u5206\u914d\u662f\u5426\u5305\u542b\u76ee\u6807\u7684\u6807\u7b7e\uff0c\u4e5f\u5c31\u662f\u6b63\u8d1f\u6837\u672c\u7684\u6807\u8bb0\uff0c\u7136\u540e\u8fdb\u884c\u8bad\u7ec3\u3002 3.1.1\u6b63\u8d1f\u6837\u672c\u6807\u8bb0 \u00b6 \u4e0e\u771f\u5b9e\u6846ground truth\uff08GT\uff09\u4ea4\u5e76\u6bd4IOU\u5927\u4e8e0.7\u7684anchor\u662f\u6b63\u6837\u672c\uff0c\u5373anchor\u4e2d\u5305\u542b\u76ee\u6807\uff0c\u76ee\u6807\u503c\u8bbe\u4e3a1 \u4e0e\u771f\u5b9e\u6846ground truth\uff08GT\uff09\u4ea4\u5e76\u6bd4IOU\u5c0f\u4e8e0.3\u7684anchor\u662f\u8d1f\u6837\u672c\uff0c\u5373anchor\u4e2d\u4e0d\u5305\u542b\u76ee\u6807\uff0c\u76ee\u6807\u503c\u8bbe\u4e3a-1 \u5176\u4ed6\u7684anchor\u820d\u5f03\uff0c\u4e0d\u53c2\u4e0e\u7f51\u7edc\u7684\u8bad\u7ec3\uff0c\u76ee\u6807\u503c\u8bbe\u4e3a0 3.1.2 RPN\u7f51\u7edc\u7684\u635f\u5931\u51fd\u6570 \u00b6 RPN\u7f51\u7edc\u7684\u635f\u5931\u51fd\u6570\u662f\uff1a \u5176\u4e2d i i \u8868\u793aanchor\u7684\u7d22\u5f15 p_i p_i \u662f\u7b2ci\u4e2aanchor \u9884\u6d4b\u4e3a\u76ee\u6807\u7684\u53ef\u80fd\u6027\uff0c p_i^{*} p_i^{*} \u4e3aground-truth\u6807\u7b7e\u3002\u5982\u679c\u8fd9\u4e2aanchor\u662fpositive\u7684\uff0c\u5219ground-truth\u6807\u7b7e\u4e3a1\uff0c\u5426\u5219\u4e3a0\u3002\uff08\u5373\u5f53\u7b2ci\u4e2aanchor\u4e0eGT\u95f4IoU>0.7\uff0c\u8ba4\u4e3a\u662f\u8be5anchor\u662fpositive\uff0c\u6807\u7b7e\u4e3a1\uff1b\u53cd\u4e4bIoU<0.3\u65f6\uff0c\u8ba4\u4e3a\u662f\u8be5anchor\u662fnegative\uff0c\u6807\u7b7e\u4e3a0\uff09 t_i t_i \u8868\u793a\u8868\u793a\u6b63\u6837\u672canchor\u5230\u9884\u6d4b\u533a\u57dfbounding box\u76844\u4e2a\u53c2\u6570\u5316\u9884\u6d4b\u7ed3\u679c, t_i^{*} t_i^{*} \u662f\u8fd9\u4e2apositive anchor\u5bf9\u5e94\u7684ground-truth box\u7684\u504f\u79fb\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u9884\u6d4b\u503c\uff1a \u771f\u5b9e\u503c\uff1a \u5176\u4e2d\uff0cx\uff0cy\uff0cw\uff0ch\u8868\u793a\u7a97\u53e3\u4e2d\u5fc3\u5750\u6807\u548c\u7a97\u53e3\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff0c\u53d8\u91cfx\uff0c x_a \u548cx^{*} x_a \u548cx^{*} \u5206\u522b\u8868\u793a\u9884\u6d4b\u7a97\u53e3\u3001anchor\u7a97\u53e3\u548cGround Truth\u7684\u5750\u6807\uff08y\uff0cw\uff0ch\u540c\u7406\uff09 \u6574\u4e2aLoss\u5206\u4e3a\u4e24\u90e8\u5206\uff1a\u5206\u7c7b\u548c\u56de\u5f52\u7684\u635f\u5931 L_{cls} L_{cls} \u5206\u7c7b\u7684\u635f\u5931\uff08classification loss\uff09\uff0c\u662f\u4e00\u4e2a\u4e8c\u5206\u7c7b\u5668\u7684softmax loss\u3002 L_{reg} L_{reg} \u662f\u56de\u5f52\u635f\u5931\uff0c\u4e3a smooth(x) smooth(x) \u635f\u5931,\u5e76\u4e14\u53ea\u6709\u6b63\u6837\u672c\u624d\u53c2\u4e0e\u56de\u5f52\u635f\u5931\u8ba1\u7b97 N_{cls} N_{cls} \u548c N_{reg} N_{reg} \u5206\u522b\u7528\u6765\u6807\u51c6\u5316\u5206\u7c7b\u635f\u5931\u9879 L_{cls} L_{cls} \u548c\u56de\u5f52\u635f\u5931\u9879 L_{reg} L_{reg} \uff0c\u9ed8\u8ba4\u7528batch size\u8bbe\u7f6e N_{cls} N_{cls} \uff0c\u7528anchor\u4f4d\u7f6e\u6570\u76ee~2000\u521d\u59cb\u5316 N_{reg} N_{reg} N_{cls} N_{cls} \u548c N_{reg} N_{reg} \u76f8\u5dee\u8fc7\u5927\uff0c\u7528\u53c2\u6570\u03bb\u6765\u5e73\u8861\u4e24\u8005\uff0c\u4e00\u822c\u53d6\u503c\u4e3a N_{reg} N_{reg} \u548c N_{cls} N_{cls} \u7684\u6bd4\u503c10\u5373\u53ef\u3002 3.1.3 \u8bad\u7ec3\u8fc7\u7a0b \u00b6 \u5728\u8bad\u7ec3\u65f6\u6bcf\u6b21\u8fed\u4ee3\u7684\u6b63\u8d1f\u6837\u672c\u662f\u7531\u4e00\u5e45\u56fe\u50cf\u7684\u6b63\u8d1f\u6837\u672c\u7ec4\u6210\u7684\uff1a \u968f\u673a\u91c7\u6837256\u4e2aanchor\uff0c\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u5176\u4e2d\u91c7\u6837\u7684\u6b63\u8d1fanchor\u7684\u6bd4\u4f8b\u662f1:1\u3002 \u901a\u8fc7\u4ece\u96f6\u5747\u503c\u6807\u51c6\u5dee\u4e3a0.01\u7684\u9ad8\u65af\u5206\u5e03\u4e2d\u83b7\u53d6\u7684\u6743\u91cd\u6765\u968f\u673a\u521d\u59cb\u5316\u6240\u6709\u65b0\u5c42\uff08\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5c42\u5176\u540e\u7684\u5c42\uff09\uff0c\u6240\u6709\u5176\u4ed6\u5c42\uff08\u5373\u5171\u4eab\u7684\u5377\u79ef\u5c42\uff09\u662f\u901a\u8fc7\u5bf9ImageNet\u5206\u7c7b\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u6765\u521d\u59cb\u5316\u7684 \u91c7\u7528\u5e26\u52a8\u91cf\u7684\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3 3.1.4 \u5b9e\u73b0 \u00b6 1\u3001\u6b63\u8d1f\u6837\u672c\u8bbe\u7f6e \u00b6 \u5c06\u4ea7\u751f\u7684369303\u4e2aanchor\u4e0e\u76ee\u6807\u771f\u5b9e\u503c\u7684\u8ba1\u7b97\u4ea4\u5e76\u6bd4\u8bbe\u7f6e\u6b63\u8d1f\u6837\u672c\uff1a # \u83b7\u53d6\u5bf9\u5e94\u7684\u76ee\u6807\u503c\uff1a\u8f93\u5165\uff1a\u8981\u8bbe\u7f6e\u6b63\u8d1f\u6837\u672c\u7684anchors\uff0canchor\u5728\u6709\u6548\u533a\u57df\u7684\u6807\u8bc6\uff0c\u6837\u672c\u6807\u8bb0\u7684bbox\u53ca\u7c7b\u522blabel\uff1b\u8f93\u51fa\uff1arpn\u7684\u5206\u7c7b\u76ee\u6807\u503c\uff0cRPN\u7684\u56de\u5f52\u76ee\u6807\u503c rpn_target_matchs , rpn_target_deltas = model . rpn_head . anchor_target . build_targets ( anchors , valid_flags , bbox , label ) \u6240\u6709\u7684anchor\u90fd\u8bbe\u7f6e\u4e86\u5206\u7c7b\u7684\u76ee\u6807\u503c\uff0c\u56de\u5f52\u7684\u76ee\u6807\u503c\u53ea\u6709\u6b63\u8d1f\u6837\u672c\u8bbe\u7f6e\u4e86\u76ee\u6807\u503c\uff0c\u4e00\u5171\u6709369303\u4e2aAnchor\uff0c\u53c2\u4e0e\u8bad\u7ec3\u7684\u6709256\u4e2aanchor\u3002 # rpn_target_matchs.shape TensorShape ([ 1 , 369303 ]) # rpn_target_deltas.shape TensorShape ([ 1 , 256 , 4 ]) \u83b7\u53d6\u6b63\u6837\u672c\uff1a\u6b63\u6837\u672c\u662f\u5305\u542b\u76ee\u6807\u7684anchor\uff0c\u5176\u76ee\u6807\u503c\u8bbe\u4e3a1\uff0c\u6b63\u6837\u672c\u7684\u4e2a\u6570\u662f29\u4e2a # \u5c5e\u4e8e\u6b63\u6837\u672c\u7684anchors\uff0c\u4e0eGT\u4ea4\u5e76\u6bd4\u8f83\u5927\u7684anchor,\u76ee\u6807\u503c\u8bbe\u4e3a1 positive_anchors = tf . gather ( anchors , tf . where ( tf . equal ( rpn_target_matchs , 1 ))[:, 1 ]) # \u6b63\u6837\u672c\u7684\u4e2a\u6570\uff1a\u4e00\u5171\u4f7f\u752829\u4e2a\u5c5e\u4e8e\u6b63\u6837\u672c\u7684anchor TensorShape ([ 29 , 4 ]) \u6211\u4eec\u5c06\u8fd9\u4e9b\u6b63\u6837\u672c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a\uff1a\u53ef\u4ee5\u770b\u51fa\u8fd9\u4e9banchor\u4e0e\u76ee\u6807\u8fd8\u662f\u975e\u5e38\u63a5\u8fd1\u7684 \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u770b\u4e0b\u8d1f\u6837\u672c\u7684\u7ed3\u679c\uff0c\u8d1f\u6837\u672c\u7684\u76ee\u6807\u503c\u662f-1\uff0c\u8d1f\u6837\u672c\u7684\u4e2a\u6570\u662f227\uff0c\u4e0e29\u4e2a\u6b63\u6837\u672c\u4e00\u5171\u662f256\u4e2aanchor\u53c2\u4e0e\u7f51\u7edc\u8bad\u7ec3\uff0c\u5176\u4f59\u7684\u4e0d\u53c2\u4e0e\u7f51\u7edc\u8bad\u7ec3\u3002 # \u8d1f\u6837\u672c negtivate_anchors = tf . gather ( anchors , tf . where ( tf . equal ( rpn_target_matchs , - 1 ))[:, 1 ]) # negtivate_anchors.shape TensorShape ([ 227 , 4 ]) \u540c\u6837\u6211\u4eec\u4e5f\u5c06\u8d1f\u6837\u672c\u5c55\u793a\u5728\u56fe\u50cf\u4e0a\uff0c\u4ece\u56fe\u50cf\u53ef\u4ee5\u770b\u51fa\u8fd9\u4e9b\u8d1f\u6837\u672c\u7684anchor\u4e0e\u76ee\u6807\u5dee\u8ddd\u8fd8\u662f\u5f88\u5927\u7684\u3002 2\u3001\u635f\u5931\u51fd\u6570 \u00b6 \u635f\u5931\u51fd\u6570\u8ba1\u7b97\u662f\u5c06\u7f51\u7edc\u9884\u6d4b\u7ed3\u679c\u548c\u771f\u5b9e\u503c\u8fdb\u884c\u6bd4\u8f83\uff0c\u83b7\u53d6\u4e24\u8005\u4e4b\u95f4\u7684\u5dee\u522b\u3002\u635f\u5931\u51fd\u6570\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff1a\u5206\u7c7b\u548c\u56de\u5f52 # RPN\u7f51\u7edc\u7684\u635f\u5931\u51fd\u6570 # \u8f93\u5165\uff1arpn\u7684\u5206\u7c7b\u7ed3\u679crpn_class_logits\uff0crpn\u7684\u56de\u5f52\u7ed3\u679c\uff0cbbox\u6807\u6ce8\u6846\uff0clabel\u662f\u76ee\u6807\u7d2f\u5457\uff0cimagemera\u56fe\u50cf\u5143\u4fe1\u606f # \u8f93\u51fa\uff1a\u5206\u7c7b\u635f\u5931\u548c\u56de\u5f52\u635f\u5931 rpn_class_loss , rpn_bbox_loss = model . rpn_head . loss ( rpn_class_logits , rpn_deltas , bbox , label , imagemeta ) # \u5206\u7c7b\u635f\u5931\uff1arpn_bbox_loss < tf . Tensor : shape = (), dtype = float32 , numpy = 0.20614956 > # \u56de\u5f52\u635f\u5931\uff1arpn_class_loss < tf . Tensor : shape = (), dtype = float32 , numpy = 0.034301624 > \u63a5\u4e0b\u6765\u6211\u4eec\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u5c31\u53ef\u4ee5\u4e86 3.2 FastRCNN\u7f51\u7edc\u7684\u8bad\u7ec3 \u00b6 \u4f7f\u7528RPN\u7f51\u7edc\u6536\u96c6\u5230\u7684\u5019\u9009\u533a\u57df\u548cimageNet\u9884\u8bad\u7ec3\u7684\u5377\u79ef\u7f51\u7edc\u63d0\u53d6\u7684\u7279\u5f81\u5bf9\u68c0\u6d4b\u7684FastRCNN\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u3002 3.2.1 \u6b63\u8d1f\u6837\u672c\u6807\u8bb0 \u00b6 \u5728FastRCNN\u7f51\u7edc\u8bad\u7ec3\u65f6\uff1a \u9996\u5148\u5c06\u4e0e\u771f\u5b9e\u6846ground truth\uff08GT\uff09\u4ea4\u5e76\u6bd4IOU\u5927\u4e8e0.5\u7684\u5019\u9009\u533a\u57df\u8bbe\u4e3a\u6b63\u6837\u672c\uff0c\u7c7b\u522b\u7684\u76ee\u6807\u503c\u662fGT\u7684\u7c7b\u522b \u5c06\u4e0e\u771f\u5b9e\u6846ground truth\uff08GT\uff09\u4ea4\u5e76\u6bd4IOU\u5c0f\u4e8e0.5\u7684\u5019\u9009\u533a\u57df\u8bbe\u4e3a\u8d1f\u6837\u672c\uff0c\u7c7b\u522b\u7684\u76ee\u6807\u503c\u662f0 3.1.2 FastRCNN\u7684\u635f\u5931\u51fd\u6570 \u00b6 FastRCNN\u7684\u8f93\u51fa\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff1a\u4e00\u90e8\u5206\u662fsoftmax\u5c42\u8fdb\u884c\u5206\u7c7b\uff0c\u8f93\u51fa\u7c7b\u522b\u6709K\u4e2a\u7c7b\u522b\u52a0\u4e0a\u201d\u80cc\u666f\u201d\u7c7b\uff0c\u53e6\u4e00\u90e8\u5206\u662f\u56de\u5f52bounding box regressor\u3002\u4e5f\u5c31\u662f\uff1a \u4e00\u90e8\u5206\u8f93\u51fa\u5728K+1\u4e2a\u7c7b\u522b\u4e0a\u7684\u79bb\u6563\u6982\u7387\u5206\u5e03\uff08\u6bcf\u4e2a\u5019\u9009\u533a\u57df\uff09\uff0c p=(p0,p1,...,pk) p=(p0,p1,...,pk) \u3002\u901a\u5e38\uff0c\u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u7684K+1\u4e2a\u8f93\u51fa\u4e0a\u7684Softmax\u6765\u8ba1\u7b97p\u3002 \u53e6\u4e00\u90e8\u5206\u8f93\u51fa\u5bf9\u4e8e\u7531K\u4e2a\u7c7b\u522b\u4e2d\u7684\u6bcf\u4e00\u4e2a\u68c0\u6d4b\u6846\u56de\u5f52\u504f\u79fb\uff0c t^{k}=(t_{x}^{k},t_{y}^{k},t_{w}^{k},t_{h}^{k}) t^{k}=(t_{x}^{k},t_{y}^{k},t_{w}^{k},t_{h}^{k}) \u3002\u5176\u4e2d t_k t_k \u6307\u5b9a\u76f8\u5bf9\u4e8e\u5019\u9009\u6846\u7684\u5c3a\u5ea6\u4e0d\u53d8\u8f6c\u6362\u548c\u5bf9\u6570\u7a7a\u95f4\u9ad8\u5ea6/\u5bbd\u5ea6\u79fb\u4f4d\uff0c\u4e0e\u5728RPN\u7f51\u7edc\u4e2d\u662f\u4e00\u6837\u7684\u3002 \u6bcf\u4e2a\u8bad\u7ec3\u7684\u5019\u9009\u533a\u57df\u7528 \u5206\u7c7b\u76ee\u6807\u503cu\u548c\u68c0\u6d4b\u6846\u56de\u5f52\u76ee\u6807\u503cv\u6807\u8bb0 \u3002\u80cc\u666f\u6837\u672c\u7528u=0\u6765\u8868\u793a\uff0c\u5bf9\u6bcf\u4e2a\u6807\u8bb0\u7684\u5019\u9009\u533a\u57df\u4f7f\u7528\u591a\u4efb\u52a1\u635f\u5931L\u4ee5\u8054\u5408\u8bad\u7ec3\u5206\u7c7b\u548c\u68c0\u6d4b\u6846\u56de\u5f52\uff1a \u5176\u4e2d L_{cls}(p, u) = -\\log p_u L_{cls}(p, u) = -\\log p_u \uff0c\u8868\u793a\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u7b2c\u4e8c\u4e2a\u635f\u5931 L_{loc} L_{loc} \uff0c\u662f\u5b9a\u4e49\u76ee\u6807\u503c\u548c\u9884\u6d4b\u68c0\u6d4b\u6846\u7684\u56db\u5143\u7ec4\u4e4b\u95f4\u7684\u635f\u5931\u4f7f\u7528smoothL1\u635f\u5931\u8ba1\u7b97\uff0c\u540c\u6837\u662f\u53ea\u6709\u6b63\u6837\u672c\uff08\u975e\u80cc\u666f\uff09\u7684\u5019\u9009\u533a\u57df\u624d\u8ba1\u7b97\u56de\u5f52\u635f\u5931\uff0c\u53c2\u6570\u03bb\u8bbe\u4e3a1\u3002 3.2.3.\u8bad\u7ec3\u8fc7\u7a0b \u00b6 FastRCNN\u7684\u8bad\u7ec3\u83b7\u53d6\u6bcf\u5f20\u56fe\u7247\u4e2d\u7684\u6b63\u8d1f\u6837\u672c\uff1a \u5bf9\u6240\u6709\u6b63\u6837\u672c\u6839\u636eIOU\u503c\u8fdb\u884c\u6392\u5e8f\uff0c\u6bcf\u5f20\u56fe\u7247\u53d6\u524d256\u4e2a\u533a\u57df\uff0c\u5c06\u8fd9\u4e9b\u533a\u57df\u7684\u5750\u6807\u4fdd\u5b58\u4e0b\u6765\uff0c\u4f5c\u4e3a\u8be5\u56fe\u7247\u7684\u8bad\u7ec3\u6837\u672c \u7528\u4e8eSoftmax\u5206\u7c7b\u548c\u68c0\u6d4b\u6846\u56de\u5f52\u7684\u5168\u8fde\u63a5\u5c42\u7684\u6743\u91cd\u5206\u522b\u4f7f\u7528\u5177\u6709\u65b9\u5dee0.01\u548c0.001\u7684\u96f6\u5747\u503c\u9ad8\u65af\u5206\u5e03\u521d\u59cb\u5316\uff0c\u504f\u7f6e\u521d\u59cb\u5316\u4e3a0\uff0c\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4f7f\u7528ImageNet\u7684\u9884\u8bad\u7ec3\u7f51\u7edc \u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u8fdb\u884c\u4f18\u5316 3.2.4 \u5b9e\u73b0 \u00b6 1\u3001\u6b63\u8d1f\u6837\u672c\u8bbe\u7f6e \u00b6 \u5c06proposal\u5c42\u4ea7\u751f\u7684\u5019\u9009\u533a\u57df\u4e0e\u76ee\u6807\u771f\u5b9e\u503c\u7684\u8ba1\u7b97\u4ea4\u5e76\u6bd4\u8bbe\u7f6e\u6b63\u8d1f\u6837\u672c\uff1a # fastRCNN\u7684\u6b63\u8d1f\u6837\u672c\u8bbe\u7f6e # \u8f93\u5165\uff1aRPN\u7f51\u7edc\u751f\u6210\u7684\u5019\u9009\u533a\u57df\uff0cbbox\u662f\u6807\u8bb0\u6846\uff0clabel\u662f\u76ee\u6807\u7c7b\u522b # \u8f93\u51fa\uff1a\u53c2\u4e0e\u8bad\u7ec3\u7684\u5019\u9009\u533a\u57dfrois_list,\u5019\u9009\u533a\u57df\u5206\u7c7b\u7684\u76ee\u6807\u503crcnn_target_matchs_list\uff0c\u56de\u5f52\u7684\u76ee\u6807\u503crcnn_target_deltas_list rois_list , rcnn_target_matchs_list , rcnn_target_deltas_list = \\ model . bbox_target . build_targets ( proposals_list , bbox , label , imagemeta ) \u83b7\u53d6\u6b63\u6837\u672c\uff1a\u6b63\u6837\u672c\u662f\u8d1f\u8d23\u76ee\u6807\u68c0\u6d4b\u7684\u5019\u9009\u533a\u57df\uff0c\u5176\u76ee\u6807\u503c\u4e0d\u662f0\uff0c\u6b63\u6837\u672c\u7684\u4e2a\u6570\u662f64\u4e2a # \u83b7\u53d6\u6b63\u6837\u672c\uff1a positive_proposal = tf . gather ( rois_list [ 0 ], tf . where ( tf . not_equal ( rcnn_target_matchs_list , 0 ))[:, 1 ]) # positive_proposal.shape TensorShape ([ 64 , 4 ]) \u5c06\u5176\u5c55\u793a\u5728\u56fe\u50cf\u4e0a\uff1a\u53ef\u4ee5\u8fd9\u4e9b\u6846\u8ddf\u771f\u5b9e\u503c\u662f\u975e\u5e38\u63a5\u8fd1\u7684 # \u663e\u793a visualize . draw_boxes ( rgd_image [ 0 ], positive_proposal . numpy () * 1216 ) plt . show () \u540c\u6837\u6211\u4eec\u4e5f\u53ef\u4ee5\u83b7\u53d6\u8d1f\u6837\u672c\uff08\u80cc\u666f\uff09\uff0c\u5e76\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a\uff1a # \u8d1f\u6837\u672c negtivate_proposal = tf . gather ( rois_list [ 0 ], tf . where ( tf . equal ( rcnn_target_matchs_list , 0 ))[:, 1 ]) # negtivate_proposal.shape TensorShape ([ 192 , 4 ]) # \u663e\u793a visualize . draw_boxes ( rgd_image [ 0 ], negtivate_proposal . numpy () * 1216 ) plt . show () 2\u3001\u635f\u5931\u51fd\u6570 \u00b6 \u635f\u5931\u51fd\u6570\u8ba1\u7b97\u662f\u5c06\u7f51\u7edc\u9884\u6d4b\u7ed3\u679c\u548c\u771f\u5b9e\u503c\u8fdb\u884c\u6bd4\u8f83\uff0c\u83b7\u53d6\u4e24\u8005\u4e4b\u95f4\u7684\u5dee\u522b\u3002\u5728\u8fd9\u91cc\u6211\u4eec\u9700\u8981\u5c06\u53c2\u4e0e\u7f51\u7edc\u8bad\u7ec3\u7684\u5019\u9009\u533a\u57df\u8fdb\u884cROIPooling\u540e\u9001\u5165\u7f51\u7edc\u4e2d\u8bad\u7ec3\u3002\u635f\u5931\u51fd\u6570\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff1a\u5206\u7c7b\u548c\u56de\u5f52\uff1a # \u5c06\u53c2\u4e0e\u7f51\u7edc\u8bad\u7ec3\u7684\u5019\u9009\u533a\u57dfrois_list\u9001\u5165\u5230ROIpooling\u5c42\u4e2d\u8fdb\u884c\u7ef4\u5ea6\u56fa\u5b9a pooled_regions_list = model . roi_align ( ( rois_list , rcnn_feature_maps , imagemeta ), training = True \uff09 # \u9001\u5165\u7f51\u7edc\u4e2d\u8fdb\u884c\u9884\u6d4b\uff0c\u5f97\u5230\u9884\u6d4b\u7ed3\u679c rcnn_class_logits_list , rcnn_probs_list , rcnn_deltas_list = \\ model . bbox_head ( pooled_regions_list , training = True ) # \u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff1a\u5206\u7c7b\u548c\u56de\u5f52 # \u8f93\u5165\uff1a\u7f51\u7edc\u7684\u9884\u6d4b\u7ed3\u679c\u548c\u76ee\u6807\u503c rcnn_class_loss , rcnn_bbox_loss = model . bbox_head . loss ( rcnn_class_logits_list , rcnn_deltas_list , rcnn_target_matchs_list , rcnn_target_deltas_list ) # \u5206\u7c7b\u635f\u5931rcnn_class_loss < tf . Tensor : shape = (), dtype = float32 , numpy = 0.56958425 > # \u56de\u5f52\u635f\u5931rcnn_bbox_loss < tf . Tensor : shape = (), dtype = float32 , numpy = 0.28708345 > \u63a5\u4e0b\u6765\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u8fdb\u884c\u9884\u6d4b\u5373\u53ef 3.3 \u5171\u4eab\u5377\u79ef\u8bad\u7ec3 \u00b6 \u7528fastRCNN\u68c0\u6d4b\u7f51\u7edc\u521d\u59cb\u5316RPN\u8bad\u7ec3\uff0c\u4f46\u662f\u56fa\u5b9a\u5171\u4eab\u7684\u5377\u79ef\u5c42\uff0c\u5e76\u4e14\u53ea\u5fae\u8c03RPN\u72ec\u6709\u7684\u5c42\uff0c\u73b0\u5728\u4e24\u4e2a\u7f51\u7edc\u5171\u4eab\u5377\u79ef\u5c42\u4e86\uff0c\u63a5\u4e0b\u6765\u4fdd\u6301\u5171\u4eab\u7684\u5377\u79ef\u5c42\u56fa\u5b9a\uff0c\u5fae\u8c03Fast R-CNN\u7684fc\u5c42\u3002\u8fd9\u6837\uff0cRPN\u7f51\u7edc\u548cFast R-CNN\u7f51\u7edc\u5171\u4eab\u76f8\u540c\u7684\u5377\u79ef\u5c42\uff0c\u6784\u6210\u4e00\u4e2a\u7edf\u4e00\u7684\u7f51\u7edc\u3002 Faster R-CNN\u8fd8\u6709\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u8bad\u7ec3\u65b9\u5f0f\uff0c\u53ef\u4ee5\u4e00\u6b21\u5b8c\u6210\u8bad\u7ec3\uff0c\u5c06RPN loss\u4e0eFast RCNN loss\u76f8\u52a0\uff0c\u7136\u540e\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\uff0c\u66f4\u65b0\u53c2\u6570\u3002 4 \u7aef\u5230\u7aef\u8bad\u7ec3 \u00b6 \u524d\u9762\u6211\u4eec\u5df2\u7ecf\u4ecb\u7ecd\u4e86\u7f51\u7edc\u6a21\u578b\u67b6\u6784\u548c\u9884\u6d4b\u7ed3\u679c\uff0c\u5728\u7f51\u7edc\u9884\u6d4b\u524d\u6211\u4eec\u9700\u8981\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\uff0c\u63a5\u4e0b\u6765\u4f7f\u7528\u7aef\u5230\u7aef\u7684\u65b9\u5f0f\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u57fa\u672c\u6b65\u9aa4\u662f\uff1a 1\u3001\u52a0\u8f7d\u6570\u636e\u96c6\uff1a\u6211\u4eec\u5728\u8fd9\u91cc\u4f7f\u7528VOC\u6570\u636e\u96c6\uff0c\u6240\u4ee5\u9700\u8981\u52a0\u8f7dVOC\u6570\u636e\u96c6 2\u3001\u6a21\u578b\u5b9e\u4f8b\u5316\uff1a\u52a0\u8f7dfaster RCNN\u6a21\u578b 3\u3001\u6a21\u578b\u8bad\u7ec3\uff1a\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u5bf9\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3 \u5b8c\u6210\u7f51\u7edc\u7684\u8bad\u7ec3\u3002\u9996\u5148\u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305\uff1a # \u6570\u636e\u96c6\u52a0\u8f7d from detection.datasets import pascal_voc # \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6 import tensorflow as tf import numpy as np # \u7ed8\u56fe from matplotlib import pyplot as plt # \u8981\u8bad\u7ec3\u7684\u6a21\u578b from detection.models.detectors import faster_rcnn 4.1 \u6570\u636e\u52a0\u8f7d \u00b6 # \u52a0\u8f7d\u6570\u636e\u96c6 train_dataset = pascal_voc . pascal_voc ( 'train' ) # \u6570\u636e\u7684\u7c7b\u522b\uff1a train_dataset.classes [ 'background' , 'person' , 'aeroplane' , 'bicycle' , 'bird' , 'boat' , 'bottle' , 'bus' , 'car' , 'cat' , 'chair' , 'cow' , 'diningtable' , 'dog' , 'horse' , 'motorbike' , 'pottedplant' , 'sheep' , 'sofa' , 'train' , 'tvmonitor' ] # \u6570\u636e\u7c7b\u522b\u6570\u91cf\uff1a21 num_classes = len ( train_dataset . classes ) 4.2. \u6a21\u578b\u5b9e\u4f8b\u5316 \u00b6 # \u6307\u5b9a\u6570\u636e\u96c6\u4e2d\u7c7b\u522b\u4e2a\u6570 model = faster_rcnn . FasterRCNN ( num_classes = num_classes ) 4.3 \u6a21\u578b\u8bad\u7ec3 \u00b6 \u6a21\u578b\u8bad\u7ec3\u4e5f\u5c31\u662f\u8981\u4f7f\u7528\u635f\u5931\u51fd\u6570\uff0c\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\uff0c\u5229\u7528\u4f18\u5316\u5668\u8fdb\u884c\u53c2\u6570\u66f4\u65b0\uff0c\u8bad\u7ec3\u7684\u6d41\u7a0b\u662f\uff1a 1\u3001\u6307\u5b9a\u4f18\u5316\u5668\uff1a\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u52a0\u52a8\u91cf\u7684SGD\u65b9\u6cd5 2\u3001\u8bbe\u7f6eepoch\uff0c\u8fdb\u884c\u904d\u5386\u83b7\u53d6batch\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\u8fdb\u884c\u9884\u6d4b 3\u3001\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u66f4\u65b0\u53c2\u6570\uff0c\u6211\u4eec\u4f7f\u7528tf.GradientTape\u5b9e\u73b0\uff1a \u5b9a\u4e49\u4e0a\u4e0b\u6587\u73af\u5883\uff1atf.GradientTape \u8ba1\u7b97\u635f\u5931\u51fd\u6570loss \u4f7f\u7528 tape.gradient(loss,model.trainable_variables) \u81ea\u52a8\u8ba1\u7b97\u68af\u5ea6\uff0closs\u662f\u635f\u5931\u7ed3\u679c\uff0ctrainable_variables\u4e3a\u6240\u6709\u9700\u8981\u8bad\u7ec3\u7684\u53d8\u91cf\u3002 \u4f7f\u7528 optimizer.apply_gradients(zip(grads,model.trainable_variables)) \u81ea\u52a8\u66f4\u65b0\u6a21\u578b\u53c2\u6570\uff0czip(grads, trainable_variables)\u5c06\u68af\u5ea6\u548c\u53c2\u6570\u5173\u8054\u8d77\u6765\uff0c\u7136\u540eapply_gradients\u4f1a\u81ea\u52a8\u7684\u5229\u7528\u68af\u5ea6\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u6309\u7167\u8fd9\u4e2a\u6d41\u7a0b\u5b8c\u6210\u6a21\u578b\u8bad\u7ec3\u3002 # 1.\u5b9a\u4e49\u4f18\u5316\u5668 optimizer = tf . keras . optimizers . SGD ( 1e-3 , momentum = 0.9 , nesterov = True ) # \u6a21\u578b\u4f18\u5316 loss_his = [] # 2.\u8bbe\u7f6eepoch\uff0c\u8fdb\u884c\u904d\u5386\u83b7\u53d6batch\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\u8fdb\u884c\u9884\u6d4b for epoch in range ( 7 ): # \u83b7\u53d6\u7d22\u5f15 indices = np . arange ( train_dataset . num_gtlabels ) # \u6253\u4e71 np . random . shuffle ( indices ) # \u8fed\u4ee3\u6b21\u6570 iter = np . round ( train_dataset . num_gtlabels / train_dataset . batch_size ) . astype ( np . uint8 ) for idx in range ( iter ): # \u83b7\u53d6batch\u6570\u636e\u7d22\u5f15 idx = indices [ idx ] # \u83b7\u53d6batch_size batch_image , batch_metas , batch_bboxes , batch_label = train_dataset [ idx ] # 3.\u6a21\u578b\u8bad\u7ec3\uff0c\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u66f4\u65b0\u53c2\u6570 # 3.1 \u5b9a\u4e49\u4f5c\u7528\u57df with tf . GradientTape () as tape : # 3.2 \u8ba1\u7b97\u635f\u5931\u51fd\u6570 rpn_class_loss , rpn_bbox_loss , rcnn_class_loss , rcnn_bbox_loss = model (( batch_image , batch_metas , batch_bboxes , batch_label ), training = True ) # \u603b\u635f\u5931 loss = rpn_class_loss + rpn_bbox_loss + rcnn_class_loss + rcnn_bbox_loss # 3.3 \u8ba1\u7b97\u68af\u5ea6 grads = tape . gradient ( loss , model . trainable_variables ) # 3.4 \u66f4\u65b0\u53c2\u6570\u503c optimizer . apply_gradients ( zip ( grads , model . trainable_variables )) print ( \"epoch: %d ,batch: %d ,loss: %f \" % ( epoch + 1 , idx , loss )) loss_his . append ( loss ) \u7ed3\u679c\u4e3a\uff1a epoch \uff1a 1 , loss \uff1a 147.117371 epoch \uff1a 2 , loss \uff1a 72.580498 epoch \uff1a 3 , loss \uff1a 79.347351 epoch \uff1a 4 , loss \uff1a 41.220577 epoch \uff1a 5 , loss \uff1a 5.238140 epoch \uff1a 6 , loss \uff1a 2.924250 epoch \uff1a 7 , loss \uff1a 5.287500 \u635f\u5931\u51fd\u6570\u7684\u53d8\u6362\u5982\u4e0b\u56fe\u6240\u793a\uff1a # \u7ed8\u5236\u635f\u5931\u51fd\u6570\u53d8\u5316\u7684\u66f2\u7ebf plt . plot ( range ( len ( loss_his )),[ loss . numpy () for loss in loss_his ]) plt . grid () \u5f53\u6211\u4eec\u8bad\u7ec3\u597d\u6a21\u578b\u540e\uff0c\u5c31\u53ef\u4ee5\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u4e86\uff0c\u4e5f\u5c31\u662f\u672c\u8282\u5f00\u5934\u7ed9\u5927\u5bb6\u4ecb\u7ecd\u7684\u5185\u5bb9\u3002 \u603b\u7ed3 \u719f\u6089FasterRCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u5229\u7528CNN\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5229\u7528RPN\u751f\u6210\u5019\u9009\u533a\u57df\uff0c\u6700\u540e\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52 \u77e5\u9053anchor\u7684\u601d\u60f3 anchor\u6280\u672f\u5c06\u68c0\u6d4b\u95ee\u9898\u8f6c\u6362\u4e3a**\"\u8fd9\u4e2a\u56fa\u5b9a\u53c2\u8003\u6846\u4e2d\u6709\u6ca1\u6709\u76ee\u6807\uff0c\u76ee\u6807\u6846\u504f\u79bb\u53c2\u8003\u6846\u591a\u8fdc\"**\uff0c\u4e0d\u518d\u9700\u8981\u591a\u5c3a\u5ea6\u904d\u5386\u6ed1\u7a97 \u638c\u63e1RPN\u7f51\u7edc\u662f\u5982\u4f55\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u751f\u6210\u7684 \u901a\u8fc7softmax\u5224\u65adanchors\u5c5e\u4e8epositive\u6216\u8005negative\uff0c\u518d\u5229\u7528bounding box regression\u4fee\u6b63anchors\u83b7\u5f97\u7cbe\u786e\u7684proposals \u638c\u63e1ROIPooling\u7684\u4f7f\u7528\u65b9\u6cd5 RoIpooling\u4f7f\u7528\u6700\u5927\u6c60\u5316\u5c06\u4efb\u4f55\u6709\u6548\u7684RoI\u533a\u57df\u5185\u7684\u7279\u5f81\u8f6c\u6362\u6210\u5177\u6709H\u00d7W\u7684\u56fa\u5b9a\u7a7a\u95f4\u8303\u56f4\u7684\u5c0ffeature map \u77e5\u9053fasterRCNN\u7684\u8bad\u7ec3\u65b9\u6cd5 \u5206\u6b65\u8bad\u7ec3\uff1aRPN\u7f51\u7edc\uff0cfastrcnn\u8bad\u7ec3\uff0c\u5171\u4eab\u7f51\u7edc\u8bad\u7ec3\uff0c\u7aef\u5230\u7aef\u7684\u7f51\u7edc\u8bad\u7ec3","title":"Faster-RCNN\u539f\u7406\u4e0e\u5b9e\u73b0"},{"location":"objectdection/03.Faster-RCNN/#43-faster-rcnn","text":"\u5b66\u4e60\u76ee\u6807 \u719f\u6089FasterRCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u77e5\u9053anchor\uff08\u951a\u6846\uff09\u7684\u601d\u60f3 \u638c\u63e1RPN\u7f51\u7edc\u662f\u5982\u4f55\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u751f\u6210\u7684 \u638c\u63e1ROIPooling\u7684\u4f7f\u7528\u65b9\u6cd5 \u77e5\u9053fasterRCNN\u7684\u8bad\u7ec3\u65b9\u6cd5 \u5728R-CNN\u548cFast RCNN\u7684\u57fa\u7840\u4e0a\uff0c\u57282016\u5e74\u63d0\u51fa\u4e86Faster RCNN\u7f51\u7edc\u6a21\u578b\uff0c\u5728\u7ed3\u6784\u4e0a\uff0cFaster RCNN\u5df2\u7ecf\u5c06\u5019\u9009\u533a\u57df\u7684\u751f\u6210\uff0c\u7279\u5f81\u63d0\u53d6\uff0c\u76ee\u6807\u5206\u7c7b\u53ca\u76ee\u6807\u6846\u7684\u56de\u5f52\u90fd\u6574\u5408\u5728\u4e86\u4e00\u4e2a\u7f51\u7edc\u4e2d\uff0c\u7efc\u5408\u6027\u80fd\u6709\u8f83\u5927\u63d0\u9ad8\uff0c\u5728\u68c0\u6d4b\u901f\u5ea6\u65b9\u9762\u5c24\u4e3a\u660e\u663e\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u7ed9\u5927\u5bb6\u8be6\u7ec6\u4ecb\u7ecdfasterRCNN\u7f51\u7edc\u6a21\u578b\u3002\u7f51\u7edc\u57fa\u672c\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a Faster RCNN\u53ef\u4ee5\u770b\u6210\u662f\u533a\u57df\u751f\u6210\u7f51\u7edc(RPN)\u4e0eFast RCNN\u7684\u7ec4\u5408\uff0c\u5176\u4e2d\u533a\u57df\u751f\u6210\u7f51\u7edc(RPN)\u66ff\u4ee3\u9009\u62e9\u6027\u641c\u7d22\u6765\u751f\u6210\u5019\u9009\u533a\u57df\uff0cFast RCNN\u7528\u6765\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u3002","title":"4.3 Faster-RCNN\u7f51\u7edc"},{"location":"objectdection/03.Faster-RCNN/#1","text":"FasterRCNN\u7684\u5de5\u4f5c\u6d41\u7a0b\u662f\uff1a 1\u3001 \u7279\u5f81\u63d0\u53d6 \uff1a\u5c06\u6574\u4e2a\u56fe\u50cf\u7f29\u653e\u81f3\u56fa\u5b9a\u7684\u5927\u5c0f\u8f93\u5165\u5230CNN\u7f51\u7edc\u4e2d\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5f97\u5230\u7279\u5f81\u56fe\u3002 2\u3001 \u5019\u9009\u533a\u57df\u63d0\u53d6 \uff1a\u8f93\u5165\u7279\u5f81\u56fe\uff0c\u4f7f\u7528\u533a\u57df\u751f\u6210\u7f51\u7edcRPN\uff0c\u4ea7\u751f\u4e00\u4e9b\u5217\u7684\u5019\u9009\u533a\u57df 3\u3001 ROIPooling : \u4e0eFast RCNN\u7f51\u7edc\u4e2d\u4e00\u6837\uff0c\u4f7f\u7528\u6700\u5927\u6c60\u5316\u56fa\u5b9a\u5019\u9009\u533a\u57df\u7684\u5c3a\u5bf8\uff0c\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u5904\u7406 4\u3001 \u76ee\u6807\u5206\u7c7b\u548c\u56de\u5f52 \uff1a\u4e0eFast RCNN\u7f51\u7edc\u4e2d\u4e00\u6837\uff0c\u4f7f\u7528\u4e24\u4e2a\u540c\u7ea7\u5c42:K+1\u4e2a\u7c7b\u522b\u7684SoftMax\u5206\u7c7b\u5c42\u548c\u8fb9\u6846\u7684\u56de\u5f52\u5c42\uff0c\u6765\u5b8c\u6210\u76ee\u6807\u7684\u5206\u7c7b\u548c\u56de\u5f52\u3002 Faster R-CNN\u7684\u6d41\u7a0b\u4e0eFast R-CNN\u7684\u533a\u522b\u4e0d\u662f\u5f88\u5927\uff0c\u91cd\u8981\u7684\u6539\u8fdb\u662f\u4f7f\u7528RPN\u7f51\u7edc\u6765\u66ff\u4ee3\u9009\u62e9\u6027\u641c\u7d22\u83b7\u53d6\u5019\u9009\u533a\u57df\uff0c\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u5c06Faster R-CNN\u7f51\u7edc\u770b\u505aRPN\u548cFast R-CNN\u7f51\u7edc\u7684\u7ed3\u5408\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u6765\u770b\u4e0b\u8be5\u7f51\u7edc\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u4f7f\u7528\u8fc7\u7a0b\uff0c\u6a21\u578b\u6e90\u7801\u4f4d\u7f6e\uff1afasterRCNN\u4e2d\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a detection\u6587\u4ef6\u5939\u4e2d\u662f\u6a21\u578b\uff0c\u6570\u636e\u7684\u5b9e\u73b0\uff0cweights\u4e2d\u5305\u542b\u7f51\u7edc\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u6309\u7167\u4ee5\u4e0b\u6b65\u9aa4\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff1a 1\u3001\u83b7\u53d6\u6570\u636e\u548c\u52a0\u8f7d\u9884\u8bad\u7ec3\u7f51\u7edc 2\u3001\u83b7\u53d6RPN\u7f51\u7edc\u751f\u6210\u7684\u5019\u9009\u533a\u57df 3\u3001\u83b7\u53d6\u7f51\u7edc\u7684\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c \u9996\u5148\u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305\uff1a # \u83b7\u53d6VOC\u6570\u636e\u4f7f\u7528 from detection.datasets import pascal_voc # \u7ed8\u56fe import matplotlib.pyplot as plt import numpy as np # \u6a21\u578b\u6784\u5efa from detection.models.detectors import faster_rcnn import tensorflow as tf # \u56fe\u50cf\u5c55\u793a import visualize","title":"1. \u7f51\u7edc\u5de5\u4f5c\u6d41\u7a0b"},{"location":"objectdection/03.Faster-RCNN/#11","text":"\u52a0\u8f7dvoc\u6570\u636e\u96c6\u4e2d\u7684\u4e00\u5f20\u56fe\u7247\u8fdb\u884c\u7f51\u7edc\u9884\u6d4b\uff1a # \u5b9e\u4f8b\u5316voc\u6570\u636e\u96c6\u7684\u7c7b\uff0c\u83b7\u53d6\u9001\u5165\u7f51\u7edc\u4e2d\u7684\u4e00\u5f20\u56fe\u7247 pascal = pascal_voc . pascal_voc ( \"train\" ) # image\uff1a\u9001\u5165\u7f51\u7edc\u4e2d\u7684\u6570\u636e\uff0cimagemeta:\u56fe\u50cf\u7684yuan'x image , imagemeta , bbox , label = pascal [ 218 ] \u5728\u5c06\u56fe\u50cf\u9001\u5165\u7f51\u7edc\u4e4b\u524d\uff0c\u6211\u4eec\u5bf9\u5176\u8fdb\u884c\u4e86\u5c3a\u5ea6\u7684\u8c03\u6574\uff0c\u6807\u51c6\u5316\u7b49\u5904\u7406\uff0c\u83b7\u53d6\u53ef\u5c55\u793a\u7684\u56fe\u50cf\uff1a # \u56fe\u50cf\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee img_mean = ( 122.7717 , 115.9465 , 102.9801 ) img_std = ( 1. , 1. , 1. ) # RGB\u56fe\u50cf rgd_image = np . round ( image + img_mean ) . astype ( np . uint8 ) \u83b7\u53d6\u539f\u59cb\u56fe\u50cf\uff0c\u8fdb\u884c\u6bd4\u8f83\uff1a # \u83b7\u53d6\u539f\u59cb\u56fe\u50cf from detection.datasets.utils import get_original_image ori_img = get_original_image ( image [ 0 ], imagemeta [ 0 ], img_mean ) \u5c06\u56fe\u50cf\u8fdb\u884c\u5bf9\u6bd4\u663e\u793a\uff1a # \u5c55\u793a\u539f\u56fe\u50cf\u548c\u9001\u5165\u7f51\u7edc\u4e2d\u56fe\u50cf rgd_image = np . round ( image + img_mean ) . astype ( np . uint8 ) fig , axes = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 10 , 8 ), dpi = 100 ) axes [ 0 ] . imshow ( ori_img . astype ( 'uint8' )) axes [ 0 ] . set_title ( \"\u539f\u56fe\u50cf\" ) axes [ 1 ] . imshow ( rgd_image [ 0 ]) axes [ 1 ] . set_title ( \"\u9001\u5165\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf\" ) plt . show () \u5c06\u539f\u56fe\u50cf\u7684\u957f\u8fb9\u7f29\u653e\u4e3a1216\uff0c\u77ed\u8fb9\u6309\u76f8\u5e94\u6bd4\u4f8b\u8fdb\u884c\u8c03\u6574\u540e\uff0c\u5e76\u6309\u7167\u5747\u503c\u8fdb\u884c\u586b\u5145 # \u539f\u56fe\u50cf\u7684\u5927\u5c0f ori_img . shape (375, 500, 3) # \u9001\u5165\u7f51\u7edc\u4e2d\u56fe\u50cf\u7684\u5927\u5c0f image . shape (1, 1216, 1216, 3) imagemeta\u4e2d\u7684\u4fe1\u606f\u662f\uff1a\u539f\u56fe\u50cf\u5927\u5c0f\uff0c\u56fe\u50cf\u7f29\u653e\u540e\u7684\u5927\u5c0f\uff0c\u9001\u5165\u7f51\u7edc\u4e2d\u56fe\u50cf\u7684\u5927\u5c0f\uff0c\u56fe\u50cf\u7f29\u653e\u6bd4\u4f8b\uff0c\u56fe\u50cf\u662f\u5426\u7ffb\u8f6c\uff08\u672a\u4f7f\u7528\uff09\u3002 # \u539f\u59cb\u56fe\u50cf\u548c\u9001\u5165\u7f51\u7edc\u4e2d\u56fe\u50cf\u7684\u4fe1\u606f imagemeta array ([[ 375. , 500. , 3. , 912. , 1216. , 3. , 1216. , 1216. , 3. , 2.432 , 0. ]], dtype = float32 )","title":"1.1 \u6570\u636e\u52a0\u8f7d"},{"location":"objectdection/03.Faster-RCNN/#12","text":"\u52a0\u8f7d\u4f7f\u7528coco\u6570\u636e\u96c6\u9884\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u5bf9\u56fe\u50cf\u8fdb\u884c\u9884\u6d4b\u3002 # coco\u6570\u636e\u96c6\u7684class\uff0c\u517180\u4e2a\u7c7b\u522b\uff1a\u4eba\uff0c\u81ea\u884c\u8f66\uff0c\u706b\u8f66\uff0c\u3002\u3002\u3002 classes = [ 'bg' , 'person' , 'bicycle' , 'car' , 'motorcycle' , 'airplane' , 'bus' , 'train' , 'truck' , 'boat' , 'traffic light' , 'fire hydrant' , 'stop sign' , 'parking meter' , 'bench' , 'bird' , 'cat' , 'dog' , 'horse' , 'sheep' , 'cow' , 'elephant' , 'bear' , 'zebra' , 'giraffe' , 'backpack' , 'umbrella' , 'handbag' , 'tie' , 'suitcase' , 'frisbee' , 'skis' , 'snowboard' , 'sports ball' , 'kite' , 'baseball bat' , 'baseball glove' , 'skateboard' , 'surfboard' , 'tennis racket' , 'bottle' , 'wine glass' , 'cup' , 'fork' , 'knife' , 'spoon' , 'bowl' , 'banana' , 'apple' , 'sandwich' , 'orange' , 'broccoli' , 'carrot' , 'hot dog' , 'pizza' , 'donut' , 'cake' , 'chair' , 'couch' , 'potted plant' , 'bed' , 'dining table' , 'toilet' , 'tv' , 'laptop' , 'mouse' , 'remote' , 'keyboard' , 'cell phone' , 'microwave' , 'oven' , 'toaster' , 'sink' , 'refrigerator' , 'book' , 'clock' , 'vase' , 'scissors' , 'teddy bear' , 'hair drier' , 'toothbrush' ] \u5b9e\u4f8b\u5316faster-RCNN\u6a21\u578b\uff1a # \u5b9e\u4f8b\u5316\u6a21\u578b model = faster_rcnn . FasterRCNN ( num_classes = len ( classes )) \u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u7531\u4e8efasterRCNN\u4e0d\u662f\u6309\u7167model\u7684\u5b50\u7c7b\u6784\u5efa\uff0c\u6240\u4ee5\u65e0\u6cd5\u901a\u8fc7h5\u6587\u4ef6\u76f4\u63a5\u52a0\u8f7d\u6a21\u578b\u7ed3\u6784\uff0c\u6211\u4eec\u5c06\u7ed3\u6784\u5b9e\u4f8b\u5316\u540e\uff0c\u5728\u52a0\u8f7d\u6743\u91cd\u83b7\u53d6\u6574\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\u3002 model (( image , imagemeta , bbox , label ), training = True ) # \u52a0\u8f7d\u8bad\u7ec3\u597d\u7684weights model . load_weights ( \"weights/faster_rcnn.h5\" ) \u901a\u8fc7model.summary()\u67e5\u770b\u7f51\u7edc\u67b6\u6784\uff0c\u5982\u4e0b\uff1a","title":"1.2 \u6a21\u578b\u52a0\u8f7d"},{"location":"objectdection/03.Faster-RCNN/#13","text":"\u6a21\u578b\u7684\u9884\u6d4b\u5206\u4e3a\u4e24\u90e8\u5206\uff1aRPN\u751f\u6210\u5019\u9009\u533a\u57df\u548cFast RCNN\u8fdb\u884c\u76ee\u6807\u7684\u5206\u7c7b\u4e0e\u56de\u5f52","title":"1.3 \u6a21\u578b\u9884\u6d4b\u8fc7\u7a0b"},{"location":"objectdection/03.Faster-RCNN/#131-rpn","text":"# RPN\u83b7\u53d6\u5019\u9009\u533a\u57df\uff1a\u8f93\u5165\u56fe\u50cf\u548c\u5bf9\u5e94\u7684\u5143\u4fe1\u606f\uff0c\u8f93\u51fa\u662f\u5019\u9009\u7684\u4f4d\u7f6e\u4fe1\u606f proposals = model . simple_test_rpn ( image [ 0 ], imagemeta [ 0 ]) \u5019\u9009\u533a\u57df\u7684\u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a\u5bf9\u4e8e\u4e0a\u8ff0\u56fe\u50cf\u5171\u4ea7\u751f1533\u4e2a\u5019\u9009\u533a\u57df\uff0c\u6bcf\u4e2a\u5019\u9009\u533a\u57df\u4f7f\u7528\u76f8\u5bf9\u4e8e\u8f93\u5165\u7f51\u7edc\u4e2d\u56fe\u50cf\u5f52\u4e00\u5316\u540e\u7684\u5de6\u4e0a\u89d2\u5750\u6807\u548c\u53f3\u4e0b\u89d2\u5750\u6807\u3002 <tf.Tensor: shape=(1533, 4), dtype=float32, numpy= array([[0.20729761, 0.00852748, 0.748096 , 0.46975034], [0.42213044, 0.5887971 , 0.7810232 , 0.9806169 ], [0.40125194, 0.4384725 , 0.48458642, 0.47913405], ..., [0.25977597, 0.435113 , 0.27290097, 0.4483906 ], [0.38884488, 0.41798416, 0.41393432, 0.4339822 ], [0.5885266 , 0.65331775, 0.62330776, 0.6913476 ]], dtype=float32)> \u6211\u4eec\u5c06\u8fd9\u4e9b\u5019\u9009\u533a\u57df\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a\uff0c\u9700\u8981\u83b7\u53d6\u7edd\u5bf9\u4f4d\u7f6e\uff1a # \u7ed8\u5236\u5728\u56fe\u50cf\u4e0a(\u5c06proposal\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a) visualize . draw_boxes ( rgd_image [ 0 ], boxes = proposals [:,: 4 ] * 1216 ) plt . show () \u5982\u4e0b\u56fe\u6240\u793a\uff1a","title":"1.3.1 RPN\u83b7\u53d6\u5019\u9009\u533a\u57df"},{"location":"objectdection/03.Faster-RCNN/#132-fastrcnn","text":"\u6211\u4eec\u5c06\u83b7\u53d6\u7684\u5019\u9009\u533a\u57df\u9001\u5165\u5230Fast RCNN\u7f51\u7edc\u4e2d\u8fdb\u884c\u68c0\u6d4b\uff1a # rcnn\u8fdb\u884c\u9884\u6d4b,\u5f97\u5230\u7684\u662f\u539f\u56fe\u50cf\u7684\u68c0\u6d4b\u7ed3\u679c\uff1a # \u8f93\u5165\uff1a\u8981\u68c0\u6d4b\u7684\u9001\u5165\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf\uff0c\u56fe\u50cf\u7684\u5143\u4fe1\u606f\uff0cRPN\u4ea7\u751f\u7684\u5019\u9009\u533a\u57df # \u8f93\u51fa\uff1a\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c\uff1a\u68c0\u6d4b\u6846(\u76f8\u5bf9\u4e8e\u539f\u56fe\u50cf)\uff0c\u7c7b\u522b\uff0c\u7f6e\u4fe1\u5ea6 res = model . simple_test_bboxes ( image [ 0 ], imagemeta [ 0 ], proposals ) res\u662f\u4e00\u4e2a\u5b57\u5178\uff0c\u5176\u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1arois\u662f\u76ee\u6807\u6846\uff0cclass_ids\u662f\u6240\u5c5e\u7684\u7c7b\u522b\uff0cscores\u662f\u7f6e\u4fe1\u5ea6\u3002 {'rois': array([[ 95.65208 , 8.963474 , 370.8639 , 224.11072 ], [ 57.620296 , 226.60101 , 159.39307 , 310.5221 ], [ 86.15405 , 323.98065 , 369.12762 , 497.70337 ], [ 83.67178 , 170.96815 , 135.69716 , 221.05861 ], [ 74.37474 , 327.855 , 210.86298 , 422.48798 ], [ 73.24604 , 0.97371644, 206.86272 , 47.992523 ], [ 63.968616 , 256.5716 , 192.52466 , 365.3871 ], [ 67.055145 , 88.534515 , 137.3221 , 130.74608 ], [227.8164 , 291.93015 , 370.9528 , 434.4086 ], [147.73048 , 218.15501 , 177.35306 , 260.56738 ], [ 82.44483 , 40.140255 , 133.15623 , 107.72627 ], [122.62652 , 239.552 , 141.19394 , 272.06354 ], [154.03288 , 115.91441 , 372.5167 , 426.57187 ], [218.90562 , 364.88345 , 247.20554 , 419.03842 ], [248.15126 , 407.61325 , 373.63068 , 479.57568 ], [139.69551 , 248.66753 , 154.51906 , 264.16055 ], [212.88734 , 195.23204 , 238.25243 , 209.22202 ]], dtype=float32), 'class_ids': array([ 1, 1, 1, 1, 1, 1, 1, 1, 1, 46, 1, 46, 61, 46, 57, 45, 40], dtype=int32), 'scores': array([0.99917287, 0.992269 , 0.99193186, 0.98929125, 0.986894 , 0.98671734, 0.98594207, 0.97716457, 0.97271395, 0.97136974, 0.9637522 , 0.9585419 , 0.9218482 , 0.8920589 , 0.85597926, 0.81343234, 0.78660023], dtype=float32)} \u5c06\u68c0\u6d4b\u7ed3\u679c\u5c55\u793a\u5728\u56fe\u50cf\u4e0a\uff1a # \u5c06\u68c0\u6d4b\u7ed3\u679c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a visualize . display_instances ( ori_img , res [ 'rois' ], res [ 'class_ids' ], classes , res [ 'scores' ]) plt . show () \u4e0a\u8ff0\u6211\u4eec\u4ecb\u7ecd\u4e86Faster RCNN\u7684\u5de5\u4f5c\u6d41\u7a0b\u5e76\u4e14\u7ed9\u5927\u5bb6\u5c55\u793a\u4e86\u7f51\u7edc\u7684\u68c0\u6d4b\u7ed3\u679c\u3002\u90a3\u63a5\u4e0b\u6765\u6211\u4eec\u89e3\u51b3\u4ee5\u4e0b\u51e0\u4e2a\u95ee\u9898\uff1a 1\u3001\u7f51\u7edc\u4e2d\u7684\u6bcf\u4e00\u90e8\u5206\u662f\u600e\u4e48\u6784\u5efa\uff0c\u600e\u4e48\u5b8c\u6210\u76f8\u5e94\u7684\u529f\u80fd\u7684\uff1f 2\u3001\u600e\u4e48\u8bad\u7ec3fastrcnn\u7f51\u7edc\u53bb\u5b8c\u6210\u6211\u4eec\u81ea\u5df1\u7684\u4efb\u52a1\uff1f \u90a3\u63a5\u4e0b\u6765\u6211\u4eec\u5c31\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\u3002","title":"1.3.2 FastRCNN\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b"},{"location":"objectdection/03.Faster-RCNN/#2","text":"Faster RCNN\u7684\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6211\u4eec\u4f9d\u7136\u5c06\u7f51\u7edc\u5206\u4e3a\u56db\u90e8\u5206\uff1a Backbone \uff1aBackbone\u7531CNN\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6784\u6210\uff0c\u5e38\u7528\u7684\u662fVGG\u548cresnet, \u7528\u6765\u63d0\u53d6\u56fe\u50cf\u4e2d\u7684\u7279\u5f81\uff0c\u83b7\u53d6\u56fe\u50cf\u7684\u7279\u5f81\u56fe\u3002\u8be5\u7279\u5f81\u56fe\u88ab\u5171\u4eab\u7528\u4e8e\u540e\u7eedRPN\u5c42\u751f\u6210\u5019\u9009\u533a\u57df\u548cROIPooling\u5c42\u4e2d\u3002 RPN\u7f51\u7edc \uff1aRPN\u7f51\u7edc\u7528\u4e8e\u751f\u6210\u5019\u9009\u533a\u57df\uff0c\u7528\u4e8e\u540e\u7eed\u7684\u76ee\u6807\u68c0\u6d4b\u3002 Roi Pooling : \u8be5\u90e8\u5206\u6536\u96c6\u56fe\u50cf\u7684\u7279\u5f81\u56fe\u548cRPN\u7f51\u7edc\u63d0\u53d6\u7684\u5019\u9009\u533a\u57df\u4f4d\u7f6e\uff0c\u7efc\u5408\u4fe1\u606f\u540e\u83b7\u53d6\u56fa\u5b9a\u5c3a\u5bf8\u7684\u7279\u5f81\uff0c\u9001\u5165\u540e\u7eed\u5168\u8fde\u63a5\u5c42\u5224\u5b9a\u76ee\u6807\u7c7b\u522b\u548c\u786e\u5b9a\u76ee\u6807\u4f4d\u7f6e\u3002 \u76ee\u6807\u5206\u7c7b\u4e0e\u56de\u5f52 : \u8be5\u90e8\u5206\u5229\u7528ROIpooling\u8f93\u51fa\u7279\u5f81\u5411\u91cf\u8ba1\u7b97\u5019\u9009\u533a\u57df\u7684\u7c7b\u522b\uff0c\u5e76\u901a\u8fc7\u56de\u5f52\u83b7\u5f97\u68c0\u6d4b\u6846\u6700\u7ec8\u7684\u7cbe\u786e\u4f4d\u7f6e\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u5c31\u4ece\u8fd9\u56db\u4e2a\u65b9\u9762\u6765\u8be6\u7ec6\u5206\u6790fasterRCNN\u7f51\u7edc\u7684\u6784\u6210\uff0c\u5e76\u7ed3\u5408\u6e90\u7801\u7406\u89e3\u6bcf\u4e00\u90e8\u5206\u5b9e\u73b0\u7684\u529f\u80fd\u3002","title":"2.\u6a21\u578b\u7ed3\u6784\u8be6\u89e3"},{"location":"objectdection/03.Faster-RCNN/#21backbone","text":"backbone\u4e00\u822c\u4e3aVGG\uff0cResNet\u7b49\u7f51\u7edc\u6784\u6210\uff0c\u4e3b\u8981\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5c06\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\u820d\u5f03\uff0c\u5f97\u5230\u7279\u5f81\u56fe\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u5904\u7406\u3002 \u5728\u6e90\u7801\u4e2d\u4f7f\u7528ResNet + FPN \u7ed3\u6784\u6765\u63d0\u53d6\u7279\u5f81\u3002\u4e0e\u666e\u901a\u7684 FasterRCNN \u53ea\u9700\u8981\u5c06\u4e00\u4e2a\u7279\u5f81\u56fe\u8f93\u5165\u5230\u540e\u7eed\u7f51\u7edc\u4e2d\u4e0d\u540c\uff0c\u7531\u4e8e\u52a0\u5165 FPN\u7ed3\u6784\uff0c\u9700\u8981\u5c06\u591a\u4e2a\u7279\u5f81\u56fe\u9010\u4e2a\u9001\u5165\u5230\u540e\u7eed\u7f51\u7edc\u4e2d\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a Resnet\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0cFPN\u7ed3\u6784\u4f5c\u7528\u662f\u5f53\u524d\u5c42\u7684\u7279\u5f81\u56fe\u4f1a\u878d\u5408\u672a\u6765\u5c42\u7684\u7279\u5f81\u8fdb\u884c\u4e0a\u91c7\u6837\uff0c\u5e76\u52a0\u4ee5\u5229\u7528\u3002\u56e0\u4e3a\u6709\u4e86\u8fd9\u6837\u4e00\u4e2a\u7ed3\u6784\uff0c\u5f53\u524d\u7684\u7279\u5f81\u56fe\u5c31\u53ef\u4ee5\u83b7\u53d6\u672a\u6765\u5c42\u7684\u4fe1\u606f\uff0c\u4e5f\u5c31\u5c06\u4f4e\u9636\u7279\u5f81\u4e0e\u9ad8\u9636\u7279\u5f81\u5c31\u6709\u673a\u878d\u5408\u8d77\u6765\u4e86\uff0c\u63d0\u5347\u68c0\u6d4b\u7cbe\u5ea6\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5728\u8fd9\u91ccResNet\u548cFPN\u7684\u5b8c\u6574\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a:Resnet\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0cFPN\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u878d\u5408\u83b7\u53d6\u591a\u4e2a\u7279\u5f81\u56fe\u540e\uff0c\u8f93\u5165\u5230RPN\u7f51\u7edc\u4e2d\u7684\u7279\u5f81\u56fe\u662f[p2,p3,p4,p5,p6] \uff0c\u800c\u4f5c\u4e3a\u540e\u7eed\u76ee\u6807\u68c0\u6d4b\u7f51\u7edcFastRCNN\u7684\u8f93\u5165\u5219\u662f [p2,p3,p4,p5] \u3002 \u6211\u4eec\u770b\u4e0b\u6e90\u7801\u5b9e\u73b0\u7684\u5185\u5bb9\uff1a 1\u3001resnet\u7279\u5f81\u63d0\u53d6\u7684\u7ed3\u679c # \u4f7f\u7528backbone\u83b7\u53d6\u7279\u5f81\u56fe C2 , C3 , C4 , C5 = model . backbone ( image , training = False ) C2,C3,C4,C5\u662fresnet\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u7684\u7ed3\u679c\uff0c\u9001\u5165\u7f51\u7edc\u4e2d\u56fe\u50cf\u5927\u5c0f\u4e3a\uff081216\uff0c1216\uff0c3\uff09\uff0c\u7ecf\u8fc7\u7279\u5f81\u63d0\u53d6\u540e\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u4e3a\uff1a # C2.shape:1216/4 TensorShape ([ 1 , 304 , 304 , 256 ]) # C3.shape:1216/8 TensorShape ([ 1 , 152 , 152 , 512 ]) # C4.shape:1216/16 TensorShape ([ 1 , 76 , 76 , 1024 ]) # C5.shape:1216/32 TensorShape ([ 1 , 38 , 38 , 2048 ]) 2\u3001FPN\u7279\u5f81\u878d\u5408\u7684\u7ed3\u679c # FPN\u7f51\u7edc\u878d\u5408\uff1aC2,C3,C4,C5\u662fresnet\u63d0\u53d6\u7684\u7279\u5f81\u7ed3\u679c P2 , P3 , P4 , P5 , P6 = model . neck ([ C2 , C3 , C4 , C5 ], training = False ) P2,P3,P4,P5,P6\u662f\u7279\u5f81\u878d\u5408\u4e4b\u540e\u7684\u7ed3\u679c\uff0c\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\uff0c\u5176\u7279\u5f81\u56fe\u7684\u5927\u5c0f\uff1a # P2.shape:1216/4 TensorShape ([ 1 , 304 , 304 , 256 ]) # P3.shape:1216/8 TensorShape ([ 1 , 152 , 152 , 512 ]) # P4.shape:1216/16 TensorShape ([ 1 , 76 , 76 , 1024 ]) # P5.shape:1216/32 TensorShape ([ 1 , 38 , 38 , 2048 ]) # P6.shape:1216/64 TensorShape ([ 1 , 19 , 19 , 256 ]) \u90a3\u7f51\u7edc\u7684\u6574\u4f53\u67b6\u6784\u8868\u793a\u6210\uff1a","title":"2.1backbone"},{"location":"objectdection/03.Faster-RCNN/#22-rpn","text":"\u7ecf\u5178\u7684\u68c0\u6d4b\u65b9\u6cd5\u751f\u6210\u68c0\u6d4b\u6846\u90fd\u975e\u5e38\u8017\u65f6\uff0c\u5982overfeat\u4e2d\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u751f\u6210\u68c0\u6d4b\u6846\uff1b\u6216\u5982R-CNN\u4f7f\u7528\u9009\u62e9\u6027\u641c\u7d22\u65b9\u6cd5\u751f\u6210\u68c0\u6d4b\u6846\u3002\u800cFaster RCNN\u5219\u629b\u5f03\u4e86\u4f20\u7edf\u7684\u6ed1\u52a8\u7a97\u53e3\u548c\u9009\u62e9\u6027\u641c\u7d22\u7684\u65b9\u6cd5\uff0c\u76f4\u63a5\u4f7f\u7528RPN\u751f\u6210\u5019\u9009\u533a\u57df\uff0c\u80fd\u6781\u5927\u63d0\u5347\u68c0\u6d4b\u901f\u5ea6\u3002 RPN\u7f51\u7edc\u7684\u4e3b\u8981\u6d41\u7a0b\u662f\uff1a 1\u3001\u751f\u6210\u4e00\u7cfb\u5217\u7684\u56fa\u5b9a\u53c2\u8003\u6846anchors,\u8986\u76d6\u56fe\u50cf\u7684\u4efb\u610f\u4f4d\u7f6e\uff0c\u7136\u540e\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52 2\u3001\u5206\u7c7b\u5206\u652f\uff1a\u901a\u8fc7softmax\u5206\u7c7b\u5224\u65adanchor\u4e2d\u662f\u5426\u5305\u542b\u76ee\u6807 3\u3001\u56de\u5f52\u5206\u652f\uff1a\u8ba1\u7b97\u76ee\u6807\u6846\u5bf9\u4e8eanchors\u7684\u504f\u79fb\u91cf\uff0c\u4ee5\u83b7\u5f97\u7cbe\u786e\u7684\u5019\u9009\u533a\u57df 4\u3001\u6700\u540e\u7684Proposal\u5c42\u5219\u8d1f\u8d23\u7efc\u5408\u542b\u6709\u76ee\u6807\u7684anchors\u548c\u5bf9\u5e94bbox\u56de\u5f52\u504f\u79fb\u91cf\u83b7\u53d6\u5019\u9009\u533a\u57df\uff0c\u540c\u65f6\u5254\u9664\u592a\u5c0f\u548c\u8d85\u51fa\u8fb9\u754c\u7684\u5019\u9009\u533a\u57df\u3002","title":"2.2 RPN\u7f51\u7edc"},{"location":"objectdection/03.Faster-RCNN/#221-anchors","text":"anchor\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u8868\u793a \u56fa\u5b9a\u7684\u53c2\u8003\u6846 \uff0c\u9996\u5148\u9884\u8bbe\u4e00\u7ec4\u4e0d\u540c\u5c3a\u5ea6\u4e0d\u540c\u957f\u5bbd\u6bd4\u7684\u56fa\u5b9a\u53c2\u8003\u6846\uff0c\u8986\u76d6\u51e0\u4e4e\u6240\u6709\u4f4d\u7f6e\uff0c \u6bcf\u4e2a\u53c2\u8003\u6846\u8d1f\u8d23\u68c0\u6d4b\u4e0e\u5176\u4ea4\u5e76\u6bd4\u5927\u4e8e\u9608\u503c (\u8bad\u7ec3\u9884\u8bbe\u503c\uff0c\u5e38\u75280.5\u62160.7) \u7684\u76ee\u6807 \uff0canchor\u6280\u672f\u5c06\u5019\u9009\u533a\u57df\u751f\u6210\u95ee\u9898\u8f6c\u6362\u4e3a \"\u8fd9\u4e2a\u56fa\u5b9a\u53c2\u8003\u6846\u4e2d\u6709\u6ca1\u6709\u76ee\u6807\uff0c\u76ee\u6807\u6846\u504f\u79bb\u53c2\u8003\u6846\u591a\u8fdc\" \uff0c\u4e0d\u518d\u9700\u8981\u591a\u5c3a\u5ea6\u904d\u5386\u6ed1\u7a97\uff0c\u771f\u6b63\u5b9e\u73b0\u4e86\u53c8\u597d\u53c8\u5feb\u3002 \u5728FastRCNN\u4e2d\u6846\u51fa\u591a\u5c3a\u5ea6\u3001\u591a\u79cd\u957f\u5bbd\u6bd4\u7684anchors,\u5982\u4e0b\u56fe\u6240\u793a\uff1a\u4e0b\u56fe\u4e2d\u5206\u522b\u662f\u5c3a\u5ea6\u4e3a32\uff0c64\uff0c128\uff0c\u957f\u5bbd\u6bd4\u4e3a1\uff1a1\uff0c1:2\uff0c2\uff1a1\u7684\u4e00\u7ec4anchors,\u6211\u4eec\u5229\u7528\u8fd9\u7ec4anchor\u5728\u7279\u5f81\u56fe\u4e0a\u8fdb\u884c\u6ed1\u52a8\uff0c\u5e76\u5bf9\u5e94\u5230\u539f\u56fe\u4e0a\u5373\u53ef\u83b7\u53d6\u4e00\u7cfb\u5217\u7684\u56fa\u5b9a\u53c2\u8003\u6846\u3002 \u7531\u4e8e\u6709 FPN \u7f51\u7edc\uff0c\u6240\u4ee5\u4f1a\u5728\u591a\u4e2a\u4e0d\u540c\u5c3a\u5ea6\u7279\u5f81\u56fe\u4e2d\u751f\u6210anchor\uff0c\u5047\u8bbe\u67d0\u4e00\u4e2a\u7279\u5f81\u56fe\u5927\u5c0f\u4e3ahxw\uff0c\u9996\u5148\u4f1a\u8ba1\u7b97\u8fd9\u4e2a\u7279\u5f81\u76f8\u5bf9\u4e8e\u8f93\u5165\u56fe\u50cf\u7684\u4e0b\u91c7\u6837\u500d\u6570 stride\uff1a \u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6bcf\u4e00\u4e2a\u5c3a\u5ea6\u7279\u5f81\u56fe\u4e0a\u751f\u6210\u4e0d\u540c\u6bd4\u5217\u7684anchor: \u5f97\u5230\u4e00\u7cfb\u5217\u7684anchors\u540e\u5c31\u53ef\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\u3002 \u5728\u6e90\u7801\u4e2d\u6211\u4eec\u53ef\u751f\u6210\u4e00\u5e45\u56fe\u50cf\u5bf9\u5e94\u7684anchors: # \u4ea7\u751fanchor\uff1a\u8f93\u5165\u56fe\u50cf\u5143\u4fe1\u606f\u5373\u53ef\uff0c\u8f93\u51faanchor\u5bf9\u5e94\u4e8e\u539f\u56fe\u7684\u5750\u6807\u503c anchors , valid_flags = model . rpn_head . generator . generate_pyramid_anchors ( imagemeta ) \u5bf9\u4e8e1216x1216\u7684\u56fe\u50cf\u751f\u6210\u7684anchor\u7684\u6570\u91cf\u4e3a\uff1a # anchors.shape\uff1a #304*304*3+152*152*3+76*76*3+38*38*3+19*19*3=369303 TensorShape ([ 369303 , 4 ]) anchor\u7684\u53d6\u503c\u4e3a\uff1a < tf . Tensor : shape = ( 369303 , 4 ), dtype = float32 , numpy = array ([[ - 22.627417 , - 11.313708 , 22.627417 , 11.313708 ], [ - 16. , - 16. , 16. , 16. ], [ - 11.313708 , - 22.627417 , 11.313708 , 22.627417 ], ... , [ 789.9613 , 970.98065 , 1514.0387 , 1333.0193 ], [ 896. , 896. , 1408. , 1408. ], [ 970.98065 , 789.9613 , 1333.0193 , 1514.0387 ]], dtype = float32 ) > \u6211\u4eec\u5c06\u524d10000\u4e2aanchor\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a\uff1a # \u7ed8\u5236\u5728\u56fe\u50cf\u4e0a(\u5c06anchor\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a) visualize . draw_boxes ( rgd_image [ 0 ], boxes = anchors [: 10000 ,: 4 ]) plt . show ()","title":"2.2.1 anchors"},{"location":"objectdection/03.Faster-RCNN/#222-rpn","text":"\u4e00\u526fMxN\u5927\u5c0f\u7684\u77e9\u9635\u9001\u5165Faster RCNN\u7f51\u7edc\u540e\uff0c\u7ecf\u8fc7backbone\u7279\u5f81\u63d0\u53d6\u5230RPN\u7f51\u7edc\u53d8\u4e3aHxW\u5927\u5c0f\u7684\u7279\u5f81\u56fe\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u662fRPN\u8fdb\u884c\u5206\u7c7b\u7684\u7f51\u7edc\u7ed3\u6784\uff1a(k=9) \u5148\u505a\u4e00\u4e2a1x1\u7684\u5377\u79ef\uff0c\u5f97\u5230[batchsize,H,W,18]\u7684\u7279\u5f81\u56fe\uff0c\u7136\u540e\u8fdb\u884c\u53d8\u5f62,\u5c06\u7279\u5f81\u56fe\u8f6c\u6362\u4e3a[batchsize,9xH,W,2]\u7684\u7279\u5f81\u56fe\u540e\uff0c\u9001\u5165softmax\u4e2d\u8fdb\u884c\u5206\u7c7b\uff0c\u5f97\u5230\u5206\u7c7b\u7ed3\u679c\u540e\uff0c\u518d\u8fdb\u884creshape\u6700\u7ec8\u5f97\u5230[batchsize,H,W,18]\u5927\u5c0f\u7684\u7ed3\u679c,18\u8868\u793ak=9\u4e2aanchor\u662f\u5426\u5305\u542b\u76ee\u6807\u7684\u6982\u7387\u503c\u3002","title":"2.2.2 RPN\u5206\u7c7b"},{"location":"objectdection/03.Faster-RCNN/#223-rpn","text":"RPN\u56de\u5f52\u7684\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a(k=9) \u7ecf\u8fc7\u8be5\u5377\u79ef\u8f93\u51fa\u7279\u5f81\u56fe\u4e3a\u4e3a[1, H, W,4x9]\uff0c\u8fd9\u91cc\u76f8\u5f53\u4e8efeature maps\u6bcf\u4e2a\u70b9\u90fd\u67099\u4e2aanchors\uff0c\u6bcf\u4e2aanchors\u53c8\u90fd\u67094\u4e2a\u7528\u4e8e\u56de\u5f52\u7684: \u53d8\u6362\u91cf\u3002 \u8be5\u53d8\u6362\u91cf\u9884\u6d4b\u7684\u662fanchor\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u5e73\u79fb\u91cf\u548c\u5c3a\u5ea6\u56e0\u5b50\uff1a \u5229\u7528\u6e90\u7801\u6211\u4eec\u53ef\u4ee5\u83b7\u5f97\u5bf9anchors\u7684\u5206\u7c7b\u548c\u56de\u5f52\u7ed3\u679c\uff1a # RPN\u7f51\u7edc\u7684\u8f93\u5165:FPN\u7f51\u7edc\u83b7\u53d6\u7684\u7279\u5f81\u56fe rpn_feature_maps = [ P2 , P3 , P4 , P5 , P6 ] # RPN\u7f51\u7edc\u9884\u6d4b\uff0c\u8fd4\u56de\uff1alogits\u9001\u5165softmax\u4e4b\u524d\u7684\u5206\u6570\uff0c\u5305\u542b\u76ee\u6807\u7684\u6982\u7387\uff0c\u5bf9\u6846\u7684\u4fee\u6b63\u7ed3\u679c rpn_class_logits , rpn_probs , rpn_deltas = model . rpn_head ( rpn_feature_maps , training = False ) \u7ed3\u679c\u5206\u6790\uff1a # rpn_class_logits.shape,\u6bcf\u4e00\u4e2aanchor\u90fd\u8fdb\u884c\u4e86\u5206\u7c7b\u5206\u6790 TensorShape ([ 1 , 369303 , 2 ]) # rpn_probs.shape\uff1asoftmax\u8f93\u51fa\u7684\u6982\u7387\u503c TensorShape ([ 1 , 369303 , 2 ]) # rpn_deltas.shape \uff1a\u56de\u5f52\u7ed3\u679c TensorShape ([ 1 , 369303 , 4 ]) \u5176\u4e2d rpn_probs\u7684\u53d6\u503c\u4e3a\uff1a <tf.Tensor: shape=(1, 369303, 2), dtype=float32, numpy= array([[[9.94552910e-01, 5.44707105e-03], [9.97310877e-01, 2.68914248e-03], [9.95540321e-01, 4.45961533e-03], ..., [9.99888301e-01, 1.11637215e-04], [9.99961257e-01, 3.87872169e-05], [9.99820888e-01, 1.79159630e-04]]], dtype=float32)> \u6211\u4eec\u83b7\u53d6\u4e00\u4e9b\u5206\u7c7b\u7f6e\u4fe1\u5ea6\u8f83\u9ad8\u7684\u7ed3\u679c\uff0c\u5c06\u8fd9\u4e9banchor\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a\uff1a # \u83b7\u53d6\u5206\u7c7b\u7ed3\u679c\u4e2d\u5305\u542b\u76ee\u6807\u7684\u6982\u7387\u503c rpn_probs_tmp = rpn_probs [ 0 ,:, 1 ] # \u83b7\u53d6\u524d100\u4e2a\u8f83\u9ad8\u7684anchor limit = 100 ix = tf . nn . top_k ( rpn_probs_tmp , k = limit ) . indices [:: - 1 ] # \u83b7\u53d6\u5bf9\u5e94\u7684anchor\u7ed8\u5236\u56fe\u50cf\u4e0a\uff0c\u90a3\u8fd9\u4e9banchor\u5c31\u6709\u5f88\u5927\u6982\u7387\u751f\u6210\u5019\u9009\u533a\u57df visualize . draw_boxes ( rgd_image [ 0 ], tf . gather ( anchors , ix ) . numpy ())","title":"2.2.3 RPN\u56de\u5f52"},{"location":"objectdection/03.Faster-RCNN/#424-proposal","text":"Proposal\u5c42\u8d1f\u8d23\u7efc\u5408RPN\u7f51\u7edc\u5bf9anchors\u5206\u7c7b\u548c\u56de\u5f52\u7684\u7ed3\u679c\uff0c\u5229\u7528\u56de\u5f52\u7684\u7ed3\u679c\u5bf9\u5305\u542b\u76ee\u6807\u7684anchors\u8fdb\u884c\u4fee\u6b63\uff0c\u8ba1\u7b97\u51fa\u5019\u9009\u533a\u57df\uff0c\u9001\u5165\u540e\u7eedRoI Pooling\u5c42\u4e2d\u3002 Proposal\u5c42\u5904\u7406\u6d41\u7a0b\u5982\u4e0b\uff1a \u5229\u7528RPN\u7f51\u7edc\u56de\u5f52\u7684\u7ed3\u679c \u5bf9\u6240\u6709\u7684anchors\u8fdb\u884c\u4fee\u6b63\uff0c\u5f97\u5230\u4fee\u6b63\u540e\u7684\u68c0\u6d4b\u6846 \u6839\u636eRPN\u7f51\u7edc\u5206\u7c7b\u7684softmax\u8f93\u51fa\u7684\u6982\u7387\u503c\u7531\u5927\u5230\u5c0f\u5bf9\u68c0\u6d4b\u6846\u8fdb\u884c\u6392\u5e8f\uff0c\u63d0\u53d6\u524d6000\u4e2a\u7ed3\u679c\uff0c\u5373\u63d0\u53d6\u4fee\u6b63\u4f4d\u7f6e\u540e\u7684\u68c0\u6d4b\u6846 \u9650\u5b9a\u8d85\u51fa\u56fe\u50cf\u8fb9\u754c\u7684\u68c0\u6d4b\u6846\u4e3a\u56fe\u50cf\u8fb9\u754c\uff0c\u9632\u6b62\u540e\u7eedroi pooling\u65f6\u5019\u9009\u533a\u57df\u8d85\u51fa\u56fe\u50cf\u8fb9\u754c\u3002 \u5bf9\u5269\u4f59\u7684\u68c0\u6d4b\u6846\u8fdb\u884c\u975e\u6781\u5927\u503c\u6291\u5236NMS Proposal\u5c42\u7684\u8f93\u51fa\u662f\u5bf9\u5e94\u8f93\u5165\u7f51\u7edc\u56fe\u50cf\u5c3a\u5ea6\u7684\u5f52\u4e00\u5316\u540e\u7684\u5750\u6807\u503c[x1, y1, x2, y2]\u3002 \u5230\u6b64RPN\u7f51\u7edc\u7684\u5de5\u4f5c\u5c31\u7ed3\u675f\u4e86\u3002 Proposal\u5c42\u67093\u4e2a\u8f93\u5165\uff1aRPN\u5206\u7c7b\u548c\u56de\u5f52\u7ed3\u679c\uff0c\u4ee5\u53ca\u56fe\u50cf\u7684\u5143\u4fe1\u606f\u3002 # \u83b7\u53d6\u5019\u9009\u533a\u57df proposals_list = model . rpn_head . get_proposals ( rpn_probs , rpn_deltas , imagemeta ) \u7ed3\u679c\u4e3a\uff1a [ < tf . Tensor : shape = ( 1533 , 4 ), dtype = float32 , numpy = array ([[ 0.20729761 , 0.00852748 , 0.748096 , 0.46975034 ], [ 0.42213044 , 0.5887971 , 0.7810232 , 0.9806169 ], [ 0.40125194 , 0.4384725 , 0.48458642 , 0.47913405 ], ... , [ 0.25977597 , 0.435113 , 0.27290097 , 0.4483906 ], [ 0.38884488 , 0.41798416 , 0.41393432 , 0.4339822 ], [ 0.5885266 , 0.65331775 , 0.62330776 , 0.6913476 ]], dtype = float32 ) > ] \u5c06\u5176\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a # \u7ed8\u5236\u5728\u56fe\u50cf\u4e0a(\u5c06proposal\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a) visualize . draw_boxes ( rgd_image [ 0 ], boxes = proposals_list [ 0 ] . numpy ()[:,: 4 ] * 1216 ) plt . show ()","title":"4.2.4 Proposal\u5c42"},{"location":"objectdection/03.Faster-RCNN/#23-roipooling","text":"RoI Pooling\u5c42\u5219\u8d1f\u8d23\u6536\u96c6RPN\u7f51\u7edc\u751f\u6210\u7684\u5019\u9009\u533a\u57df\uff0c\u5e76\u5c06\u5176\u6620\u5c04\u5230\u7279\u5f81\u56fe\u4e2d\u5e76\u56fa\u5b9a\u7ef4\u5ea6\uff0c\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\u3002 RoI Pooling \u7684\u4f5c\u7528\u8fc7\u7a0b\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a RoIpooling\u4f7f\u7528\u6700\u5927\u6c60\u5316\u5c06\u4efb\u4f55\u6709\u6548\u7684RoI\u533a\u57df\u5185\u7684\u7279\u5f81\u8f6c\u6362\u6210\u5177\u6709pool_H\u00d7pool_W\u7684\u56fa\u5b9a\u7a7a\u95f4\u8303\u56f4\u7684\u5c0f\u7684\u7279\u5f81\u56fe\uff0c\u5176\u4e2dpool_H\u548cpool_W\u662f\u8d85\u53c2\u6570\uff0c\u6bd4\u5982\u8bbe\u7f6e\u4e3a7x7, \u5b83\u4eec\u72ec\u7acb\u4e8e\u4efb\u4f55\u7279\u5b9a\u7684RoI,\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5728\u5b9e\u73b0\u8fc7\u7a0b\u4e2d\uff0cFPN\u7f51\u7edc\u4ea7\u751f\u4e86\u591a\u4e2a\u5c3a\u5ea6\u7279\u5f81\u56fe\uff0c\u90a3\u5019\u9009\u533a\u57df\u8981\u6620\u5c04\u5230\u54ea\u4e2a\u7279\u5f81\u56fe\u4e2d\u5462\uff1f \u5728\u8fd9\u91cc\uff0c\u4e0d\u540c\u5c3a\u5ea6\u7684ROI\u4f7f\u7528\u4e0d\u540c\u7279\u5f81\u5c42\u4f5c\u4e3aROI pooling\u5c42\u7684\u8f93\u5165\uff0c\u5927\u5c3a\u5ea6ROI\u5c31\u7528\u540e\u9762\u4e00\u4e9b\u7684\u91d1\u5b57\u5854\u5c42\uff0c\u6bd4\u5982P5\uff1b\u5c0f\u5c3a\u5ea6ROI\u5c31\u7528\u524d\u9762\u4e00\u70b9\u7684\u7279\u5f81\u5c42\uff0c\u6bd4\u5982P3\uff0c\u6211\u4eec\u4f7f\u7528\u4e0b\u9762\u7684\u516c\u5f0f\u786e\u5b9aROI\u6240\u5728\u7684\u7279\u5f81\u5c42\uff1a \u5176\u4e2d\uff0c224\u662fImageNet\u7684\u6807\u51c6\u8f93\u5165\uff0ck0\u662f\u57fa\u51c6\u503c\uff0c\u8bbe\u7f6e\u4e3a4\uff0cw\u548ch\u662fROI\u533a\u57df\u7684\u957f\u548c\u5bbd\uff0c\u5047\u8bbeROI\u662f112x112\u7684\u5927\u5c0f\uff0c\u90a3\u4e48k = k0-1 = 4-1 = 3\uff0c\u610f\u5473\u7740\u8be5ROI\u5e94\u8be5\u4f7f\u7528P3\u7684\u7279\u5f81\u5c42\u3002k\u503c\u4f1a\u505a\u53d6\u6574\u5904\u7406\uff0c\u9632\u6b62\u7ed3\u679c\u4e0d\u662f\u6574\u6570\uff0c\u800c\u4e14\u4e3a\u4e86\u4fdd\u8bc1k\u503c\u57282-5\u4e4b\u95f4\uff0c\u8fd8\u4f1a\u505a\u622a\u65ad\u5904\u7406\u3002 # ROI Pooling\u5c42\u5b9e\u73b0:\u8f93\u5165\u662f\u5019\u9009\u533a\u57df\uff0c\u7279\u5f81\u56fe\uff0c\u56fe\u50cf\u7684\u5143\u4fe1\u606f pool_region_list = model . roi_align (( proposals_list , rcnn_feature_maps , imagemeta ), training = False ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a\u6bcf\u4e00\u4e2a\u5019\u9009\u533a\u57df\u90fd\u88ab\u56fa\u5b9a\u4e3a7x7\u5927\u5c0f [ < tf . Tensor : shape = ( 1533 , 7 , 7 , 256 ), dtype = float32 , numpy = array ([[[[ - 6.26428795e+00 , 3.55317879e+00 , 3.37260556e+00 , ... , 6.22574663e+00 , 3.75851846e+00 , - 2.49103808e+00 ], [ - 9.01443863e+00 , 7.67611027e-01 , 7.18744850e+00 , ... , 6.20492172e+00 , 4.09835625e+00 , 6.05924249e-01 ], [ - 7.43907213e+00 , - 3.76329374e+00 , 5.01457691e+00 , ... , 6.22656918e+00 , 1.19414163e+00 , 3.06410480e+00 ], ... , [ 1.39127302e+00 , - 1.71078873e+00 , 4.01916075e+00 , ... , 5.94641972e+00 , 3.63194764e-01 , 2.91014194e+00 ], [ - 5.21681070e+00 , 2.39917469e+00 , 2.49682212e+00 , ... , 5.92232943e+00 , 3.01222801e+00 , 1.63518691e+00 ], [ - 1.26697767e+00 , - 6.90211892e-01 , 4.50919747e-01 , ... , 1.97156405e+00 , - 1.07467103e+00 , 4.54943466e+00 ]]","title":"2.3 ROIPooling"},{"location":"objectdection/03.Faster-RCNN/#24","text":"\u8be5\u90e8\u5206\u5229\u7528\u83b7\u5f97\u7684\u5019\u9009\u533a\u57df\u7684\u7279\u5f81\u56fe\uff0c\u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u4e0esoftmax\u8ba1\u7b97\u6bcf\u4e2a\u5019\u9009\u533a\u57df\u5177\u4f53\u5c5e\u4e8e\u7684\u7c7b\u522b\uff08\u5982\u4eba\uff0c\u8f66\uff0c\u7535\u89c6\u7b49\uff09\uff0c\u8f93\u51fa\u6982\u7387\u503c\uff1b\u540c\u65f6\u518d\u6b21\u5229\u7528\u56de\u5f52\u65b9\u6cd5\u83b7\u5f97\u6bcf\u4e2a\u5019\u9009\u533a\u57df\u7684\u4f4d\u7f6e\u504f\u79fb\u91cf\uff0c\u7528\u4e8e\u56de\u5f52\u66f4\u52a0\u7cbe\u786e\u7684\u76ee\u6807\u68c0\u6d4b\u6846\u3002\u8be5\u90e8\u5206\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a \u4eceRoI Pooling\u5c42\u83b7\u53d6\u5230\u56fa\u5b9a\u5927\u5c0f\u7684\u7279\u5f81\u56fe\u540e\uff0c\u9001\u5165\u540e\u7eed\u7f51\u7edc\uff0c\u53ef\u4ee5\u770b\u5230\u505a\u4e86\u5982\u4e0b2\u4ef6\u4e8b\uff1a \u901a\u8fc7\u5168\u8fde\u63a5\u548csoftmax\u5bf9\u5019\u9009\u533a\u57df\u8fdb\u884c\u5206\u7c7b \u518d\u6b21\u5bf9\u5019\u9009\u533a\u57df\u8fdb\u884c\u56de\u5f52\u4fee\u6b63\uff0c\u83b7\u53d6\u66f4\u9ad8\u7cbe\u5ea6\u7684\u68c0\u6d4b\u6846 \u5b9e\u73b0\u6d41\u7a0b\u5982\u4e0b\uff1a \u9996\u5148\u83b7\u53d6\u7f51\u7edc\u5206\u7c7b\u548c\u56de\u5f52\u7684\u7ed3\u679c\uff1a # RCNN\u7f51\u7edc\u7684\u9884\u6d4b:\u8f93\u5165\u662fROIPooling\u5c42\u7684\u7279\u5f81\uff0c\u8f93\u51fa\uff1a\u7c7b\u522b\u7684score,\u7c7b\u522b\u7684\u6982\u7387\u503c\uff0c\u56de\u5f52\u7ed3\u679c rcnn_class_logits , rcnn_class_probs , rcnn_deltas_list = model . bbox_head ( pool_region_list , training = False \uff09 \u5229\u7528\u7ed3\u679c\u5bf9\u5019\u9009\u533a\u57df\u8fdb\u884c\u4fee\u6b63\uff1a # \u83b7\u53d6\u9884\u6d4b\u7ed3\u679c:\u8f93\u5165\uff1arcnn\u8fd4\u56de\u7684\u5206\u7c7b\u548c\u56de\u5f52\u7ed3\u679c\uff0c\u5019\u9009\u533a\u57df\uff0c\u56fe\u50cf\u5143\u4fe1\u606f\uff0c\u8f93\u51fa\uff1a\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c detection_list = model . bbox_head . get_bboxes ( rcnn_class_probs , rcnn_deltas_list , proposals_list , imagemeta ) \u7ed3\u679c\u4e3a\uff1a\u4e00\u5171\u68c0\u6d4b\u51fa17\u4e2a\u76ee\u6807\uff0c\u6bcf\u4e2a\u76ee\u6807\u53f3\u76ee\u6807\u4f4d\u7f6e\uff0c\u76ee\u6807\u7c7b\u522bid\uff0c\u76ee\u6807\u7c7b\u522b\u7f6e\u4fe1\u5ea66\u4e2a\u503c\u6784\u6210\u3002 [ < tf . Tensor : shape = ( 17 , 6 ), dtype = float32 , numpy = array ([[ 2.3262584e+02 , 2.1799168e+01 , 9.0194098e+02 , 5.4503723e+02 , 1.0000000e+00 , 9.9917287e-01 ], [ 1.4013255e+02 , 5.5109363e+02 , 3.8764392e+02 , 7.5518970e+02 , 1.0000000e+00 , 9.9226898e-01 ], [ 2.0952664e+02 , 7.8792090e+02 , 8.9771838e+02 , 1.2104146e+03 , 1.0000000e+00 , 9.9193186e-01 ], [ 2.0348978e+02 , 4.1579453e+02 , 3.3001547e+02 , 5.3761450e+02 , 1.0000000e+00 , 9.8929125e-01 ], [ 1.8087936e+02 , 7.9734338e+02 , 5.1281873e+02 , 1.0274907e+03 , 1.0000000e+00 , 9.8689401e-01 ], [ 1.7813437e+02 , 2.3680782e+00 , 5.0309012e+02 , 1.1671781e+02 , 1.0000000e+00 , 9.8671734e-01 ], [ 1.5557167e+02 , 6.2398212e+02 , 4.6821997e+02 , 8.8862134e+02 , 1.0000000e+00 , 9.8594207e-01 ], [ 1.6307811e+02 , 2.1531593e+02 , 3.3396735e+02 , 3.1797446e+02 , 1.0000000e+00 , 9.7716457e-01 ], [ 5.5404950e+02 , 7.0997412e+02 , 9.0215717e+02 , 1.0564817e+03 , 1.0000000e+00 , 9.7271395e-01 ], [ 3.5928052e+02 , 5.3055298e+02 , 4.3132263e+02 , 6.3369983e+02 , 4.6000000e+01 , 9.7136974e-01 ], [ 2.0050583e+02 , 9.7621101e+01 , 3.2383597e+02 , 2.6199030e+02 , 1.0000000e+00 , 9.6375221e-01 ], [ 2.9822769e+02 , 5.8259045e+02 , 3.4338364e+02 , 6.6165851e+02 , 4.6000000e+01 , 9.5854193e-01 ], [ 3.7460797e+02 , 2.8190384e+02 , 9.0596057e+02 , 1.0374227e+03 , 6.1000000e+01 , 9.2184818e-01 ], [ 5.3237848e+02 , 8.8739655e+02 , 6.0120386e+02 , 1.0191014e+03 , 4.6000000e+01 , 8.9205891e-01 ], [ 6.0350385e+02 , 9.9131537e+02 , 9.0866974e+02 , 1.1663280e+03 , 5.7000000e+01 , 8.5597926e-01 ], [ 3.3973947e+02 , 6.0475940e+02 , 3.7579034e+02 , 6.4243842e+02 , 4.5000000e+01 , 8.1343234e-01 ], [ 5.1774200e+02 , 4.7480432e+02 , 5.7942987e+02 , 5.0882794e+02 , 4.0000000e+01 , 7.8660023e-01 ]], dtype = float32 ) > ] \u53ef\u4ee5\u5c06\u5176\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a\uff1a # \u7ed8\u5236\u5728\u56fe\u50cf\u4e0a visualize . draw_boxes ( rgd_image [ 0 ], boxes = detection_list [ 0 ][:,: 4 ]) plt . show ( \uff09 \u5230\u8fd9\u6211\u4eec\u5c31\u5b8c\u6210\u4e86\u6574\u4e2a\u7f51\u7edc\u7684\u4ecb\u7ecd\u3002","title":"2.4 \u76ee\u6807\u5206\u7c7b\u4e0e\u56de\u5f52"},{"location":"objectdection/03.Faster-RCNN/#3-fasterrcnn","text":"Faster R-CNN\u7684\u8bad\u7ec3\u5206\u4e3a\u4e24\u90e8\u5206\uff0c\u5373RPN\u7f51\u7edc\u548c\u68c0\u6d4b\u7f51\u7edcfastRCNN\u7684\u8bad\u7ec3\uff1a \u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u5206\u4e3a\u56db\u6b65\uff1a \u7b2c\u4e00\u6b65\uff1aRPN\u7f51\u7edc\u7684\u8bad\u7ec3\uff0c\u4f7f\u7528ImageNet\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u521d\u59cb\u5316\uff0c\u5e76\u7aef\u5230\u7aef\u5fae\u8c03\u7528\u4e8e\u533a\u57df\u5efa\u8bae\u4efb\u52a1\u3002 \u7b2c\u4e8c\u6b65\uff1a\u5229\u7528\u7b2c\u4e00\u6b65\u7684RPN\u751f\u6210\u7684\u5efa\u8bae\u6846\uff0c\u7531Fast R-CNN\u8bad\u7ec3\u4e00\u4e2a\u5355\u72ec\u7684\u68c0\u6d4b\u7f51\u7edc\uff0c\u8fd9\u4e2a\u68c0\u6d4b\u7f51\u7edc\u540c\u6837\u662f\u7531ImageNet\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u521d\u59cb\u5316\u7684\uff0c\u8fd9\u65f6\u5019\u4e24\u4e2a\u7f51\u7edc\u8fd8\u6ca1\u6709\u5171\u4eab\u5377\u79ef\u5c42\u3002 \u7b2c\u4e09\u6b65\uff1a\u7528\u68c0\u6d4b\u7f51\u7edc\u521d\u59cb\u5316RPN\u8bad\u7ec3\uff0c\u4f46\u662f\u56fa\u5b9a\u5171\u4eab\u7684\u5377\u79ef\u5c42\uff0c\u5e76\u4e14\u53ea\u5fae\u8c03RPN\u72ec\u6709\u7684\u5c42\uff0c\u73b0\u5728\u4e24\u4e2a\u7f51\u7edc\u5171\u4eab\u5377\u79ef\u5c42\u4e86\u3002 \u7b2c\u56db\u6b65\uff1a\u4fdd\u6301\u5171\u4eab\u7684\u5377\u79ef\u5c42\u56fa\u5b9a\uff0c\u5fae\u8c03Fast R-CNN\u7684fc\u5c42\u3002\u8fd9\u6837\uff0c\u4e24\u4e2a\u7f51\u7edc\u5171\u4eab\u76f8\u540c\u7684\u5377\u79ef\u5c42\uff0c\u6784\u6210\u4e00\u4e2a\u7edf\u4e00\u7684\u7f51\u7edc\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u5206\u522b\u4ecb\u7ecd\u5404\u4e2a\u8bad\u7ec3\u6b65\u9aa4\uff1a","title":"3 FasterRCNN\u7684\u8bad\u7ec3"},{"location":"objectdection/03.Faster-RCNN/#31-rpn","text":"RPN\u7f51\u7edc\u7684\u4f5c\u7528\u4ece\u4f17\u591a\u7684anchors\u4e2d\u63d0\u53d6\u5305\u542b\u76ee\u6807\u7684\uff0c\u5e76\u4e14\u7ecf\u8fc7\u56de\u5f52\u8c03\u6574\u7684\u5019\u9009\u533a\u57df\u3002\u4e3a\u4e86\u8bad\u7ec3RPN\uff0c\u7ed9\u6bcf\u4e2aanchor\u5206\u914d\u662f\u5426\u5305\u542b\u76ee\u6807\u7684\u6807\u7b7e\uff0c\u4e5f\u5c31\u662f\u6b63\u8d1f\u6837\u672c\u7684\u6807\u8bb0\uff0c\u7136\u540e\u8fdb\u884c\u8bad\u7ec3\u3002","title":"3.1 RPN\u7f51\u7edc\u7684\u8bad\u7ec3"},{"location":"objectdection/03.Faster-RCNN/#311","text":"\u4e0e\u771f\u5b9e\u6846ground truth\uff08GT\uff09\u4ea4\u5e76\u6bd4IOU\u5927\u4e8e0.7\u7684anchor\u662f\u6b63\u6837\u672c\uff0c\u5373anchor\u4e2d\u5305\u542b\u76ee\u6807\uff0c\u76ee\u6807\u503c\u8bbe\u4e3a1 \u4e0e\u771f\u5b9e\u6846ground truth\uff08GT\uff09\u4ea4\u5e76\u6bd4IOU\u5c0f\u4e8e0.3\u7684anchor\u662f\u8d1f\u6837\u672c\uff0c\u5373anchor\u4e2d\u4e0d\u5305\u542b\u76ee\u6807\uff0c\u76ee\u6807\u503c\u8bbe\u4e3a-1 \u5176\u4ed6\u7684anchor\u820d\u5f03\uff0c\u4e0d\u53c2\u4e0e\u7f51\u7edc\u7684\u8bad\u7ec3\uff0c\u76ee\u6807\u503c\u8bbe\u4e3a0","title":"3.1.1\u6b63\u8d1f\u6837\u672c\u6807\u8bb0"},{"location":"objectdection/03.Faster-RCNN/#312-rpn","text":"RPN\u7f51\u7edc\u7684\u635f\u5931\u51fd\u6570\u662f\uff1a \u5176\u4e2d i i \u8868\u793aanchor\u7684\u7d22\u5f15 p_i p_i \u662f\u7b2ci\u4e2aanchor \u9884\u6d4b\u4e3a\u76ee\u6807\u7684\u53ef\u80fd\u6027\uff0c p_i^{*} p_i^{*} \u4e3aground-truth\u6807\u7b7e\u3002\u5982\u679c\u8fd9\u4e2aanchor\u662fpositive\u7684\uff0c\u5219ground-truth\u6807\u7b7e\u4e3a1\uff0c\u5426\u5219\u4e3a0\u3002\uff08\u5373\u5f53\u7b2ci\u4e2aanchor\u4e0eGT\u95f4IoU>0.7\uff0c\u8ba4\u4e3a\u662f\u8be5anchor\u662fpositive\uff0c\u6807\u7b7e\u4e3a1\uff1b\u53cd\u4e4bIoU<0.3\u65f6\uff0c\u8ba4\u4e3a\u662f\u8be5anchor\u662fnegative\uff0c\u6807\u7b7e\u4e3a0\uff09 t_i t_i \u8868\u793a\u8868\u793a\u6b63\u6837\u672canchor\u5230\u9884\u6d4b\u533a\u57dfbounding box\u76844\u4e2a\u53c2\u6570\u5316\u9884\u6d4b\u7ed3\u679c, t_i^{*} t_i^{*} \u662f\u8fd9\u4e2apositive anchor\u5bf9\u5e94\u7684ground-truth box\u7684\u504f\u79fb\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u9884\u6d4b\u503c\uff1a \u771f\u5b9e\u503c\uff1a \u5176\u4e2d\uff0cx\uff0cy\uff0cw\uff0ch\u8868\u793a\u7a97\u53e3\u4e2d\u5fc3\u5750\u6807\u548c\u7a97\u53e3\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff0c\u53d8\u91cfx\uff0c x_a \u548cx^{*} x_a \u548cx^{*} \u5206\u522b\u8868\u793a\u9884\u6d4b\u7a97\u53e3\u3001anchor\u7a97\u53e3\u548cGround Truth\u7684\u5750\u6807\uff08y\uff0cw\uff0ch\u540c\u7406\uff09 \u6574\u4e2aLoss\u5206\u4e3a\u4e24\u90e8\u5206\uff1a\u5206\u7c7b\u548c\u56de\u5f52\u7684\u635f\u5931 L_{cls} L_{cls} \u5206\u7c7b\u7684\u635f\u5931\uff08classification loss\uff09\uff0c\u662f\u4e00\u4e2a\u4e8c\u5206\u7c7b\u5668\u7684softmax loss\u3002 L_{reg} L_{reg} \u662f\u56de\u5f52\u635f\u5931\uff0c\u4e3a smooth(x) smooth(x) \u635f\u5931,\u5e76\u4e14\u53ea\u6709\u6b63\u6837\u672c\u624d\u53c2\u4e0e\u56de\u5f52\u635f\u5931\u8ba1\u7b97 N_{cls} N_{cls} \u548c N_{reg} N_{reg} \u5206\u522b\u7528\u6765\u6807\u51c6\u5316\u5206\u7c7b\u635f\u5931\u9879 L_{cls} L_{cls} \u548c\u56de\u5f52\u635f\u5931\u9879 L_{reg} L_{reg} \uff0c\u9ed8\u8ba4\u7528batch size\u8bbe\u7f6e N_{cls} N_{cls} \uff0c\u7528anchor\u4f4d\u7f6e\u6570\u76ee~2000\u521d\u59cb\u5316 N_{reg} N_{reg} N_{cls} N_{cls} \u548c N_{reg} N_{reg} \u76f8\u5dee\u8fc7\u5927\uff0c\u7528\u53c2\u6570\u03bb\u6765\u5e73\u8861\u4e24\u8005\uff0c\u4e00\u822c\u53d6\u503c\u4e3a N_{reg} N_{reg} \u548c N_{cls} N_{cls} \u7684\u6bd4\u503c10\u5373\u53ef\u3002","title":"3.1.2 RPN\u7f51\u7edc\u7684\u635f\u5931\u51fd\u6570"},{"location":"objectdection/03.Faster-RCNN/#313","text":"\u5728\u8bad\u7ec3\u65f6\u6bcf\u6b21\u8fed\u4ee3\u7684\u6b63\u8d1f\u6837\u672c\u662f\u7531\u4e00\u5e45\u56fe\u50cf\u7684\u6b63\u8d1f\u6837\u672c\u7ec4\u6210\u7684\uff1a \u968f\u673a\u91c7\u6837256\u4e2aanchor\uff0c\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u5176\u4e2d\u91c7\u6837\u7684\u6b63\u8d1fanchor\u7684\u6bd4\u4f8b\u662f1:1\u3002 \u901a\u8fc7\u4ece\u96f6\u5747\u503c\u6807\u51c6\u5dee\u4e3a0.01\u7684\u9ad8\u65af\u5206\u5e03\u4e2d\u83b7\u53d6\u7684\u6743\u91cd\u6765\u968f\u673a\u521d\u59cb\u5316\u6240\u6709\u65b0\u5c42\uff08\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5c42\u5176\u540e\u7684\u5c42\uff09\uff0c\u6240\u6709\u5176\u4ed6\u5c42\uff08\u5373\u5171\u4eab\u7684\u5377\u79ef\u5c42\uff09\u662f\u901a\u8fc7\u5bf9ImageNet\u5206\u7c7b\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u6765\u521d\u59cb\u5316\u7684 \u91c7\u7528\u5e26\u52a8\u91cf\u7684\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3","title":"3.1.3 \u8bad\u7ec3\u8fc7\u7a0b"},{"location":"objectdection/03.Faster-RCNN/#314","text":"","title":"3.1.4 \u5b9e\u73b0"},{"location":"objectdection/03.Faster-RCNN/#1_1","text":"\u5c06\u4ea7\u751f\u7684369303\u4e2aanchor\u4e0e\u76ee\u6807\u771f\u5b9e\u503c\u7684\u8ba1\u7b97\u4ea4\u5e76\u6bd4\u8bbe\u7f6e\u6b63\u8d1f\u6837\u672c\uff1a # \u83b7\u53d6\u5bf9\u5e94\u7684\u76ee\u6807\u503c\uff1a\u8f93\u5165\uff1a\u8981\u8bbe\u7f6e\u6b63\u8d1f\u6837\u672c\u7684anchors\uff0canchor\u5728\u6709\u6548\u533a\u57df\u7684\u6807\u8bc6\uff0c\u6837\u672c\u6807\u8bb0\u7684bbox\u53ca\u7c7b\u522blabel\uff1b\u8f93\u51fa\uff1arpn\u7684\u5206\u7c7b\u76ee\u6807\u503c\uff0cRPN\u7684\u56de\u5f52\u76ee\u6807\u503c rpn_target_matchs , rpn_target_deltas = model . rpn_head . anchor_target . build_targets ( anchors , valid_flags , bbox , label ) \u6240\u6709\u7684anchor\u90fd\u8bbe\u7f6e\u4e86\u5206\u7c7b\u7684\u76ee\u6807\u503c\uff0c\u56de\u5f52\u7684\u76ee\u6807\u503c\u53ea\u6709\u6b63\u8d1f\u6837\u672c\u8bbe\u7f6e\u4e86\u76ee\u6807\u503c\uff0c\u4e00\u5171\u6709369303\u4e2aAnchor\uff0c\u53c2\u4e0e\u8bad\u7ec3\u7684\u6709256\u4e2aanchor\u3002 # rpn_target_matchs.shape TensorShape ([ 1 , 369303 ]) # rpn_target_deltas.shape TensorShape ([ 1 , 256 , 4 ]) \u83b7\u53d6\u6b63\u6837\u672c\uff1a\u6b63\u6837\u672c\u662f\u5305\u542b\u76ee\u6807\u7684anchor\uff0c\u5176\u76ee\u6807\u503c\u8bbe\u4e3a1\uff0c\u6b63\u6837\u672c\u7684\u4e2a\u6570\u662f29\u4e2a # \u5c5e\u4e8e\u6b63\u6837\u672c\u7684anchors\uff0c\u4e0eGT\u4ea4\u5e76\u6bd4\u8f83\u5927\u7684anchor,\u76ee\u6807\u503c\u8bbe\u4e3a1 positive_anchors = tf . gather ( anchors , tf . where ( tf . equal ( rpn_target_matchs , 1 ))[:, 1 ]) # \u6b63\u6837\u672c\u7684\u4e2a\u6570\uff1a\u4e00\u5171\u4f7f\u752829\u4e2a\u5c5e\u4e8e\u6b63\u6837\u672c\u7684anchor TensorShape ([ 29 , 4 ]) \u6211\u4eec\u5c06\u8fd9\u4e9b\u6b63\u6837\u672c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a\uff1a\u53ef\u4ee5\u770b\u51fa\u8fd9\u4e9banchor\u4e0e\u76ee\u6807\u8fd8\u662f\u975e\u5e38\u63a5\u8fd1\u7684 \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u770b\u4e0b\u8d1f\u6837\u672c\u7684\u7ed3\u679c\uff0c\u8d1f\u6837\u672c\u7684\u76ee\u6807\u503c\u662f-1\uff0c\u8d1f\u6837\u672c\u7684\u4e2a\u6570\u662f227\uff0c\u4e0e29\u4e2a\u6b63\u6837\u672c\u4e00\u5171\u662f256\u4e2aanchor\u53c2\u4e0e\u7f51\u7edc\u8bad\u7ec3\uff0c\u5176\u4f59\u7684\u4e0d\u53c2\u4e0e\u7f51\u7edc\u8bad\u7ec3\u3002 # \u8d1f\u6837\u672c negtivate_anchors = tf . gather ( anchors , tf . where ( tf . equal ( rpn_target_matchs , - 1 ))[:, 1 ]) # negtivate_anchors.shape TensorShape ([ 227 , 4 ]) \u540c\u6837\u6211\u4eec\u4e5f\u5c06\u8d1f\u6837\u672c\u5c55\u793a\u5728\u56fe\u50cf\u4e0a\uff0c\u4ece\u56fe\u50cf\u53ef\u4ee5\u770b\u51fa\u8fd9\u4e9b\u8d1f\u6837\u672c\u7684anchor\u4e0e\u76ee\u6807\u5dee\u8ddd\u8fd8\u662f\u5f88\u5927\u7684\u3002","title":"1\u3001\u6b63\u8d1f\u6837\u672c\u8bbe\u7f6e"},{"location":"objectdection/03.Faster-RCNN/#2_1","text":"\u635f\u5931\u51fd\u6570\u8ba1\u7b97\u662f\u5c06\u7f51\u7edc\u9884\u6d4b\u7ed3\u679c\u548c\u771f\u5b9e\u503c\u8fdb\u884c\u6bd4\u8f83\uff0c\u83b7\u53d6\u4e24\u8005\u4e4b\u95f4\u7684\u5dee\u522b\u3002\u635f\u5931\u51fd\u6570\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff1a\u5206\u7c7b\u548c\u56de\u5f52 # RPN\u7f51\u7edc\u7684\u635f\u5931\u51fd\u6570 # \u8f93\u5165\uff1arpn\u7684\u5206\u7c7b\u7ed3\u679crpn_class_logits\uff0crpn\u7684\u56de\u5f52\u7ed3\u679c\uff0cbbox\u6807\u6ce8\u6846\uff0clabel\u662f\u76ee\u6807\u7d2f\u5457\uff0cimagemera\u56fe\u50cf\u5143\u4fe1\u606f # \u8f93\u51fa\uff1a\u5206\u7c7b\u635f\u5931\u548c\u56de\u5f52\u635f\u5931 rpn_class_loss , rpn_bbox_loss = model . rpn_head . loss ( rpn_class_logits , rpn_deltas , bbox , label , imagemeta ) # \u5206\u7c7b\u635f\u5931\uff1arpn_bbox_loss < tf . Tensor : shape = (), dtype = float32 , numpy = 0.20614956 > # \u56de\u5f52\u635f\u5931\uff1arpn_class_loss < tf . Tensor : shape = (), dtype = float32 , numpy = 0.034301624 > \u63a5\u4e0b\u6765\u6211\u4eec\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u5c31\u53ef\u4ee5\u4e86","title":"2\u3001\u635f\u5931\u51fd\u6570"},{"location":"objectdection/03.Faster-RCNN/#32-fastrcnn","text":"\u4f7f\u7528RPN\u7f51\u7edc\u6536\u96c6\u5230\u7684\u5019\u9009\u533a\u57df\u548cimageNet\u9884\u8bad\u7ec3\u7684\u5377\u79ef\u7f51\u7edc\u63d0\u53d6\u7684\u7279\u5f81\u5bf9\u68c0\u6d4b\u7684FastRCNN\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u3002","title":"3.2 FastRCNN\u7f51\u7edc\u7684\u8bad\u7ec3"},{"location":"objectdection/03.Faster-RCNN/#321","text":"\u5728FastRCNN\u7f51\u7edc\u8bad\u7ec3\u65f6\uff1a \u9996\u5148\u5c06\u4e0e\u771f\u5b9e\u6846ground truth\uff08GT\uff09\u4ea4\u5e76\u6bd4IOU\u5927\u4e8e0.5\u7684\u5019\u9009\u533a\u57df\u8bbe\u4e3a\u6b63\u6837\u672c\uff0c\u7c7b\u522b\u7684\u76ee\u6807\u503c\u662fGT\u7684\u7c7b\u522b \u5c06\u4e0e\u771f\u5b9e\u6846ground truth\uff08GT\uff09\u4ea4\u5e76\u6bd4IOU\u5c0f\u4e8e0.5\u7684\u5019\u9009\u533a\u57df\u8bbe\u4e3a\u8d1f\u6837\u672c\uff0c\u7c7b\u522b\u7684\u76ee\u6807\u503c\u662f0","title":"3.2.1 \u6b63\u8d1f\u6837\u672c\u6807\u8bb0"},{"location":"objectdection/03.Faster-RCNN/#312-fastrcnn","text":"FastRCNN\u7684\u8f93\u51fa\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff1a\u4e00\u90e8\u5206\u662fsoftmax\u5c42\u8fdb\u884c\u5206\u7c7b\uff0c\u8f93\u51fa\u7c7b\u522b\u6709K\u4e2a\u7c7b\u522b\u52a0\u4e0a\u201d\u80cc\u666f\u201d\u7c7b\uff0c\u53e6\u4e00\u90e8\u5206\u662f\u56de\u5f52bounding box regressor\u3002\u4e5f\u5c31\u662f\uff1a \u4e00\u90e8\u5206\u8f93\u51fa\u5728K+1\u4e2a\u7c7b\u522b\u4e0a\u7684\u79bb\u6563\u6982\u7387\u5206\u5e03\uff08\u6bcf\u4e2a\u5019\u9009\u533a\u57df\uff09\uff0c p=(p0,p1,...,pk) p=(p0,p1,...,pk) \u3002\u901a\u5e38\uff0c\u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u7684K+1\u4e2a\u8f93\u51fa\u4e0a\u7684Softmax\u6765\u8ba1\u7b97p\u3002 \u53e6\u4e00\u90e8\u5206\u8f93\u51fa\u5bf9\u4e8e\u7531K\u4e2a\u7c7b\u522b\u4e2d\u7684\u6bcf\u4e00\u4e2a\u68c0\u6d4b\u6846\u56de\u5f52\u504f\u79fb\uff0c t^{k}=(t_{x}^{k},t_{y}^{k},t_{w}^{k},t_{h}^{k}) t^{k}=(t_{x}^{k},t_{y}^{k},t_{w}^{k},t_{h}^{k}) \u3002\u5176\u4e2d t_k t_k \u6307\u5b9a\u76f8\u5bf9\u4e8e\u5019\u9009\u6846\u7684\u5c3a\u5ea6\u4e0d\u53d8\u8f6c\u6362\u548c\u5bf9\u6570\u7a7a\u95f4\u9ad8\u5ea6/\u5bbd\u5ea6\u79fb\u4f4d\uff0c\u4e0e\u5728RPN\u7f51\u7edc\u4e2d\u662f\u4e00\u6837\u7684\u3002 \u6bcf\u4e2a\u8bad\u7ec3\u7684\u5019\u9009\u533a\u57df\u7528 \u5206\u7c7b\u76ee\u6807\u503cu\u548c\u68c0\u6d4b\u6846\u56de\u5f52\u76ee\u6807\u503cv\u6807\u8bb0 \u3002\u80cc\u666f\u6837\u672c\u7528u=0\u6765\u8868\u793a\uff0c\u5bf9\u6bcf\u4e2a\u6807\u8bb0\u7684\u5019\u9009\u533a\u57df\u4f7f\u7528\u591a\u4efb\u52a1\u635f\u5931L\u4ee5\u8054\u5408\u8bad\u7ec3\u5206\u7c7b\u548c\u68c0\u6d4b\u6846\u56de\u5f52\uff1a \u5176\u4e2d L_{cls}(p, u) = -\\log p_u L_{cls}(p, u) = -\\log p_u \uff0c\u8868\u793a\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u7b2c\u4e8c\u4e2a\u635f\u5931 L_{loc} L_{loc} \uff0c\u662f\u5b9a\u4e49\u76ee\u6807\u503c\u548c\u9884\u6d4b\u68c0\u6d4b\u6846\u7684\u56db\u5143\u7ec4\u4e4b\u95f4\u7684\u635f\u5931\u4f7f\u7528smoothL1\u635f\u5931\u8ba1\u7b97\uff0c\u540c\u6837\u662f\u53ea\u6709\u6b63\u6837\u672c\uff08\u975e\u80cc\u666f\uff09\u7684\u5019\u9009\u533a\u57df\u624d\u8ba1\u7b97\u56de\u5f52\u635f\u5931\uff0c\u53c2\u6570\u03bb\u8bbe\u4e3a1\u3002","title":"3.1.2  FastRCNN\u7684\u635f\u5931\u51fd\u6570"},{"location":"objectdection/03.Faster-RCNN/#323","text":"FastRCNN\u7684\u8bad\u7ec3\u83b7\u53d6\u6bcf\u5f20\u56fe\u7247\u4e2d\u7684\u6b63\u8d1f\u6837\u672c\uff1a \u5bf9\u6240\u6709\u6b63\u6837\u672c\u6839\u636eIOU\u503c\u8fdb\u884c\u6392\u5e8f\uff0c\u6bcf\u5f20\u56fe\u7247\u53d6\u524d256\u4e2a\u533a\u57df\uff0c\u5c06\u8fd9\u4e9b\u533a\u57df\u7684\u5750\u6807\u4fdd\u5b58\u4e0b\u6765\uff0c\u4f5c\u4e3a\u8be5\u56fe\u7247\u7684\u8bad\u7ec3\u6837\u672c \u7528\u4e8eSoftmax\u5206\u7c7b\u548c\u68c0\u6d4b\u6846\u56de\u5f52\u7684\u5168\u8fde\u63a5\u5c42\u7684\u6743\u91cd\u5206\u522b\u4f7f\u7528\u5177\u6709\u65b9\u5dee0.01\u548c0.001\u7684\u96f6\u5747\u503c\u9ad8\u65af\u5206\u5e03\u521d\u59cb\u5316\uff0c\u504f\u7f6e\u521d\u59cb\u5316\u4e3a0\uff0c\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4f7f\u7528ImageNet\u7684\u9884\u8bad\u7ec3\u7f51\u7edc \u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u8fdb\u884c\u4f18\u5316","title":"3.2.3.\u8bad\u7ec3\u8fc7\u7a0b"},{"location":"objectdection/03.Faster-RCNN/#324","text":"","title":"3.2.4 \u5b9e\u73b0"},{"location":"objectdection/03.Faster-RCNN/#1_2","text":"\u5c06proposal\u5c42\u4ea7\u751f\u7684\u5019\u9009\u533a\u57df\u4e0e\u76ee\u6807\u771f\u5b9e\u503c\u7684\u8ba1\u7b97\u4ea4\u5e76\u6bd4\u8bbe\u7f6e\u6b63\u8d1f\u6837\u672c\uff1a # fastRCNN\u7684\u6b63\u8d1f\u6837\u672c\u8bbe\u7f6e # \u8f93\u5165\uff1aRPN\u7f51\u7edc\u751f\u6210\u7684\u5019\u9009\u533a\u57df\uff0cbbox\u662f\u6807\u8bb0\u6846\uff0clabel\u662f\u76ee\u6807\u7c7b\u522b # \u8f93\u51fa\uff1a\u53c2\u4e0e\u8bad\u7ec3\u7684\u5019\u9009\u533a\u57dfrois_list,\u5019\u9009\u533a\u57df\u5206\u7c7b\u7684\u76ee\u6807\u503crcnn_target_matchs_list\uff0c\u56de\u5f52\u7684\u76ee\u6807\u503crcnn_target_deltas_list rois_list , rcnn_target_matchs_list , rcnn_target_deltas_list = \\ model . bbox_target . build_targets ( proposals_list , bbox , label , imagemeta ) \u83b7\u53d6\u6b63\u6837\u672c\uff1a\u6b63\u6837\u672c\u662f\u8d1f\u8d23\u76ee\u6807\u68c0\u6d4b\u7684\u5019\u9009\u533a\u57df\uff0c\u5176\u76ee\u6807\u503c\u4e0d\u662f0\uff0c\u6b63\u6837\u672c\u7684\u4e2a\u6570\u662f64\u4e2a # \u83b7\u53d6\u6b63\u6837\u672c\uff1a positive_proposal = tf . gather ( rois_list [ 0 ], tf . where ( tf . not_equal ( rcnn_target_matchs_list , 0 ))[:, 1 ]) # positive_proposal.shape TensorShape ([ 64 , 4 ]) \u5c06\u5176\u5c55\u793a\u5728\u56fe\u50cf\u4e0a\uff1a\u53ef\u4ee5\u8fd9\u4e9b\u6846\u8ddf\u771f\u5b9e\u503c\u662f\u975e\u5e38\u63a5\u8fd1\u7684 # \u663e\u793a visualize . draw_boxes ( rgd_image [ 0 ], positive_proposal . numpy () * 1216 ) plt . show () \u540c\u6837\u6211\u4eec\u4e5f\u53ef\u4ee5\u83b7\u53d6\u8d1f\u6837\u672c\uff08\u80cc\u666f\uff09\uff0c\u5e76\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a\uff1a # \u8d1f\u6837\u672c negtivate_proposal = tf . gather ( rois_list [ 0 ], tf . where ( tf . equal ( rcnn_target_matchs_list , 0 ))[:, 1 ]) # negtivate_proposal.shape TensorShape ([ 192 , 4 ]) # \u663e\u793a visualize . draw_boxes ( rgd_image [ 0 ], negtivate_proposal . numpy () * 1216 ) plt . show ()","title":"1\u3001\u6b63\u8d1f\u6837\u672c\u8bbe\u7f6e"},{"location":"objectdection/03.Faster-RCNN/#2_2","text":"\u635f\u5931\u51fd\u6570\u8ba1\u7b97\u662f\u5c06\u7f51\u7edc\u9884\u6d4b\u7ed3\u679c\u548c\u771f\u5b9e\u503c\u8fdb\u884c\u6bd4\u8f83\uff0c\u83b7\u53d6\u4e24\u8005\u4e4b\u95f4\u7684\u5dee\u522b\u3002\u5728\u8fd9\u91cc\u6211\u4eec\u9700\u8981\u5c06\u53c2\u4e0e\u7f51\u7edc\u8bad\u7ec3\u7684\u5019\u9009\u533a\u57df\u8fdb\u884cROIPooling\u540e\u9001\u5165\u7f51\u7edc\u4e2d\u8bad\u7ec3\u3002\u635f\u5931\u51fd\u6570\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff1a\u5206\u7c7b\u548c\u56de\u5f52\uff1a # \u5c06\u53c2\u4e0e\u7f51\u7edc\u8bad\u7ec3\u7684\u5019\u9009\u533a\u57dfrois_list\u9001\u5165\u5230ROIpooling\u5c42\u4e2d\u8fdb\u884c\u7ef4\u5ea6\u56fa\u5b9a pooled_regions_list = model . roi_align ( ( rois_list , rcnn_feature_maps , imagemeta ), training = True \uff09 # \u9001\u5165\u7f51\u7edc\u4e2d\u8fdb\u884c\u9884\u6d4b\uff0c\u5f97\u5230\u9884\u6d4b\u7ed3\u679c rcnn_class_logits_list , rcnn_probs_list , rcnn_deltas_list = \\ model . bbox_head ( pooled_regions_list , training = True ) # \u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff1a\u5206\u7c7b\u548c\u56de\u5f52 # \u8f93\u5165\uff1a\u7f51\u7edc\u7684\u9884\u6d4b\u7ed3\u679c\u548c\u76ee\u6807\u503c rcnn_class_loss , rcnn_bbox_loss = model . bbox_head . loss ( rcnn_class_logits_list , rcnn_deltas_list , rcnn_target_matchs_list , rcnn_target_deltas_list ) # \u5206\u7c7b\u635f\u5931rcnn_class_loss < tf . Tensor : shape = (), dtype = float32 , numpy = 0.56958425 > # \u56de\u5f52\u635f\u5931rcnn_bbox_loss < tf . Tensor : shape = (), dtype = float32 , numpy = 0.28708345 > \u63a5\u4e0b\u6765\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u8fdb\u884c\u9884\u6d4b\u5373\u53ef","title":"2\u3001\u635f\u5931\u51fd\u6570"},{"location":"objectdection/03.Faster-RCNN/#33","text":"\u7528fastRCNN\u68c0\u6d4b\u7f51\u7edc\u521d\u59cb\u5316RPN\u8bad\u7ec3\uff0c\u4f46\u662f\u56fa\u5b9a\u5171\u4eab\u7684\u5377\u79ef\u5c42\uff0c\u5e76\u4e14\u53ea\u5fae\u8c03RPN\u72ec\u6709\u7684\u5c42\uff0c\u73b0\u5728\u4e24\u4e2a\u7f51\u7edc\u5171\u4eab\u5377\u79ef\u5c42\u4e86\uff0c\u63a5\u4e0b\u6765\u4fdd\u6301\u5171\u4eab\u7684\u5377\u79ef\u5c42\u56fa\u5b9a\uff0c\u5fae\u8c03Fast R-CNN\u7684fc\u5c42\u3002\u8fd9\u6837\uff0cRPN\u7f51\u7edc\u548cFast R-CNN\u7f51\u7edc\u5171\u4eab\u76f8\u540c\u7684\u5377\u79ef\u5c42\uff0c\u6784\u6210\u4e00\u4e2a\u7edf\u4e00\u7684\u7f51\u7edc\u3002 Faster R-CNN\u8fd8\u6709\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u8bad\u7ec3\u65b9\u5f0f\uff0c\u53ef\u4ee5\u4e00\u6b21\u5b8c\u6210\u8bad\u7ec3\uff0c\u5c06RPN loss\u4e0eFast RCNN loss\u76f8\u52a0\uff0c\u7136\u540e\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\uff0c\u66f4\u65b0\u53c2\u6570\u3002","title":"3.3 \u5171\u4eab\u5377\u79ef\u8bad\u7ec3"},{"location":"objectdection/03.Faster-RCNN/#4","text":"\u524d\u9762\u6211\u4eec\u5df2\u7ecf\u4ecb\u7ecd\u4e86\u7f51\u7edc\u6a21\u578b\u67b6\u6784\u548c\u9884\u6d4b\u7ed3\u679c\uff0c\u5728\u7f51\u7edc\u9884\u6d4b\u524d\u6211\u4eec\u9700\u8981\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\uff0c\u63a5\u4e0b\u6765\u4f7f\u7528\u7aef\u5230\u7aef\u7684\u65b9\u5f0f\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u57fa\u672c\u6b65\u9aa4\u662f\uff1a 1\u3001\u52a0\u8f7d\u6570\u636e\u96c6\uff1a\u6211\u4eec\u5728\u8fd9\u91cc\u4f7f\u7528VOC\u6570\u636e\u96c6\uff0c\u6240\u4ee5\u9700\u8981\u52a0\u8f7dVOC\u6570\u636e\u96c6 2\u3001\u6a21\u578b\u5b9e\u4f8b\u5316\uff1a\u52a0\u8f7dfaster RCNN\u6a21\u578b 3\u3001\u6a21\u578b\u8bad\u7ec3\uff1a\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u5bf9\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3 \u5b8c\u6210\u7f51\u7edc\u7684\u8bad\u7ec3\u3002\u9996\u5148\u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305\uff1a # \u6570\u636e\u96c6\u52a0\u8f7d from detection.datasets import pascal_voc # \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6 import tensorflow as tf import numpy as np # \u7ed8\u56fe from matplotlib import pyplot as plt # \u8981\u8bad\u7ec3\u7684\u6a21\u578b from detection.models.detectors import faster_rcnn","title":"4 \u7aef\u5230\u7aef\u8bad\u7ec3"},{"location":"objectdection/03.Faster-RCNN/#41","text":"# \u52a0\u8f7d\u6570\u636e\u96c6 train_dataset = pascal_voc . pascal_voc ( 'train' ) # \u6570\u636e\u7684\u7c7b\u522b\uff1a train_dataset.classes [ 'background' , 'person' , 'aeroplane' , 'bicycle' , 'bird' , 'boat' , 'bottle' , 'bus' , 'car' , 'cat' , 'chair' , 'cow' , 'diningtable' , 'dog' , 'horse' , 'motorbike' , 'pottedplant' , 'sheep' , 'sofa' , 'train' , 'tvmonitor' ] # \u6570\u636e\u7c7b\u522b\u6570\u91cf\uff1a21 num_classes = len ( train_dataset . classes )","title":"4.1 \u6570\u636e\u52a0\u8f7d"},{"location":"objectdection/03.Faster-RCNN/#42","text":"# \u6307\u5b9a\u6570\u636e\u96c6\u4e2d\u7c7b\u522b\u4e2a\u6570 model = faster_rcnn . FasterRCNN ( num_classes = num_classes )","title":"4.2. \u6a21\u578b\u5b9e\u4f8b\u5316"},{"location":"objectdection/03.Faster-RCNN/#43","text":"\u6a21\u578b\u8bad\u7ec3\u4e5f\u5c31\u662f\u8981\u4f7f\u7528\u635f\u5931\u51fd\u6570\uff0c\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\uff0c\u5229\u7528\u4f18\u5316\u5668\u8fdb\u884c\u53c2\u6570\u66f4\u65b0\uff0c\u8bad\u7ec3\u7684\u6d41\u7a0b\u662f\uff1a 1\u3001\u6307\u5b9a\u4f18\u5316\u5668\uff1a\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u52a0\u52a8\u91cf\u7684SGD\u65b9\u6cd5 2\u3001\u8bbe\u7f6eepoch\uff0c\u8fdb\u884c\u904d\u5386\u83b7\u53d6batch\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\u8fdb\u884c\u9884\u6d4b 3\u3001\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u66f4\u65b0\u53c2\u6570\uff0c\u6211\u4eec\u4f7f\u7528tf.GradientTape\u5b9e\u73b0\uff1a \u5b9a\u4e49\u4e0a\u4e0b\u6587\u73af\u5883\uff1atf.GradientTape \u8ba1\u7b97\u635f\u5931\u51fd\u6570loss \u4f7f\u7528 tape.gradient(loss,model.trainable_variables) \u81ea\u52a8\u8ba1\u7b97\u68af\u5ea6\uff0closs\u662f\u635f\u5931\u7ed3\u679c\uff0ctrainable_variables\u4e3a\u6240\u6709\u9700\u8981\u8bad\u7ec3\u7684\u53d8\u91cf\u3002 \u4f7f\u7528 optimizer.apply_gradients(zip(grads,model.trainable_variables)) \u81ea\u52a8\u66f4\u65b0\u6a21\u578b\u53c2\u6570\uff0czip(grads, trainable_variables)\u5c06\u68af\u5ea6\u548c\u53c2\u6570\u5173\u8054\u8d77\u6765\uff0c\u7136\u540eapply_gradients\u4f1a\u81ea\u52a8\u7684\u5229\u7528\u68af\u5ea6\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u6309\u7167\u8fd9\u4e2a\u6d41\u7a0b\u5b8c\u6210\u6a21\u578b\u8bad\u7ec3\u3002 # 1.\u5b9a\u4e49\u4f18\u5316\u5668 optimizer = tf . keras . optimizers . SGD ( 1e-3 , momentum = 0.9 , nesterov = True ) # \u6a21\u578b\u4f18\u5316 loss_his = [] # 2.\u8bbe\u7f6eepoch\uff0c\u8fdb\u884c\u904d\u5386\u83b7\u53d6batch\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\u8fdb\u884c\u9884\u6d4b for epoch in range ( 7 ): # \u83b7\u53d6\u7d22\u5f15 indices = np . arange ( train_dataset . num_gtlabels ) # \u6253\u4e71 np . random . shuffle ( indices ) # \u8fed\u4ee3\u6b21\u6570 iter = np . round ( train_dataset . num_gtlabels / train_dataset . batch_size ) . astype ( np . uint8 ) for idx in range ( iter ): # \u83b7\u53d6batch\u6570\u636e\u7d22\u5f15 idx = indices [ idx ] # \u83b7\u53d6batch_size batch_image , batch_metas , batch_bboxes , batch_label = train_dataset [ idx ] # 3.\u6a21\u578b\u8bad\u7ec3\uff0c\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u66f4\u65b0\u53c2\u6570 # 3.1 \u5b9a\u4e49\u4f5c\u7528\u57df with tf . GradientTape () as tape : # 3.2 \u8ba1\u7b97\u635f\u5931\u51fd\u6570 rpn_class_loss , rpn_bbox_loss , rcnn_class_loss , rcnn_bbox_loss = model (( batch_image , batch_metas , batch_bboxes , batch_label ), training = True ) # \u603b\u635f\u5931 loss = rpn_class_loss + rpn_bbox_loss + rcnn_class_loss + rcnn_bbox_loss # 3.3 \u8ba1\u7b97\u68af\u5ea6 grads = tape . gradient ( loss , model . trainable_variables ) # 3.4 \u66f4\u65b0\u53c2\u6570\u503c optimizer . apply_gradients ( zip ( grads , model . trainable_variables )) print ( \"epoch: %d ,batch: %d ,loss: %f \" % ( epoch + 1 , idx , loss )) loss_his . append ( loss ) \u7ed3\u679c\u4e3a\uff1a epoch \uff1a 1 , loss \uff1a 147.117371 epoch \uff1a 2 , loss \uff1a 72.580498 epoch \uff1a 3 , loss \uff1a 79.347351 epoch \uff1a 4 , loss \uff1a 41.220577 epoch \uff1a 5 , loss \uff1a 5.238140 epoch \uff1a 6 , loss \uff1a 2.924250 epoch \uff1a 7 , loss \uff1a 5.287500 \u635f\u5931\u51fd\u6570\u7684\u53d8\u6362\u5982\u4e0b\u56fe\u6240\u793a\uff1a # \u7ed8\u5236\u635f\u5931\u51fd\u6570\u53d8\u5316\u7684\u66f2\u7ebf plt . plot ( range ( len ( loss_his )),[ loss . numpy () for loss in loss_his ]) plt . grid () \u5f53\u6211\u4eec\u8bad\u7ec3\u597d\u6a21\u578b\u540e\uff0c\u5c31\u53ef\u4ee5\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u4e86\uff0c\u4e5f\u5c31\u662f\u672c\u8282\u5f00\u5934\u7ed9\u5927\u5bb6\u4ecb\u7ecd\u7684\u5185\u5bb9\u3002 \u603b\u7ed3 \u719f\u6089FasterRCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u5229\u7528CNN\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5229\u7528RPN\u751f\u6210\u5019\u9009\u533a\u57df\uff0c\u6700\u540e\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52 \u77e5\u9053anchor\u7684\u601d\u60f3 anchor\u6280\u672f\u5c06\u68c0\u6d4b\u95ee\u9898\u8f6c\u6362\u4e3a**\"\u8fd9\u4e2a\u56fa\u5b9a\u53c2\u8003\u6846\u4e2d\u6709\u6ca1\u6709\u76ee\u6807\uff0c\u76ee\u6807\u6846\u504f\u79bb\u53c2\u8003\u6846\u591a\u8fdc\"**\uff0c\u4e0d\u518d\u9700\u8981\u591a\u5c3a\u5ea6\u904d\u5386\u6ed1\u7a97 \u638c\u63e1RPN\u7f51\u7edc\u662f\u5982\u4f55\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u751f\u6210\u7684 \u901a\u8fc7softmax\u5224\u65adanchors\u5c5e\u4e8epositive\u6216\u8005negative\uff0c\u518d\u5229\u7528bounding box regression\u4fee\u6b63anchors\u83b7\u5f97\u7cbe\u786e\u7684proposals \u638c\u63e1ROIPooling\u7684\u4f7f\u7528\u65b9\u6cd5 RoIpooling\u4f7f\u7528\u6700\u5927\u6c60\u5316\u5c06\u4efb\u4f55\u6709\u6548\u7684RoI\u533a\u57df\u5185\u7684\u7279\u5f81\u8f6c\u6362\u6210\u5177\u6709H\u00d7W\u7684\u56fa\u5b9a\u7a7a\u95f4\u8303\u56f4\u7684\u5c0ffeature map \u77e5\u9053fasterRCNN\u7684\u8bad\u7ec3\u65b9\u6cd5 \u5206\u6b65\u8bad\u7ec3\uff1aRPN\u7f51\u7edc\uff0cfastrcnn\u8bad\u7ec3\uff0c\u5171\u4eab\u7f51\u7edc\u8bad\u7ec3\uff0c\u7aef\u5230\u7aef\u7684\u7f51\u7edc\u8bad\u7ec3","title":"4.3 \u6a21\u578b\u8bad\u7ec3"},{"location":"objectdection/03.RCNN-demo/","text":"4.3 Faster RCNN\u6848\u4f8b \u00b6 \u5b66\u4e60\u76ee\u6807 \u4e86\u89e3VOC\u6570\u636e\u96c6\u7684\u5e94\u7528 \u7406\u89e3fasterRCNN\u6a21\u578b\u7684\u6784\u6210 \u80fd\u591f\u5229\u7528fasterRCNN\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b 1. VOC\u6570\u636e\u96c6\u7b80\u4ecb \u00b6 Pascal VOC\u6570\u636e\u96c6\u4f5c\u4e3a\u57fa\u51c6\u6570\u636e\uff0c\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u5e38\u88ab\u4f7f\u7528\u5230\uff0c\u5f88\u591a\u4f18\u79c0\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\u6bd4\u5982\u5206\u7c7b\uff0c\u5b9a\u4f4d\uff0c\u68c0\u6d4b\uff0c\u5206\u5272\uff0c\u52a8\u4f5c\u8bc6\u522b\u7b49\u6a21\u578b\u90fd\u662f\u57fa\u4e8ePASCAL VOC\u6311\u6218\u8d5b\u53ca\u5176\u6570\u636e\u96c6\u4e0a\u63a8\u51fa\u7684\uff0c\u5c24\u5176\u662f\u4e00\u4e9b\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\uff08\u6bd4\u5982RCNN\u7cfb\u5217\uff0c\u4ee5\u53ca\u540e\u9762\u8981\u4ecb\u7ecd\u7684YOLO\uff0cSSD\u7b49\uff09\u3002 1.1 \u6570\u636e\u60c5\u51b5 \u00b6 \u5e38\u7528\u7684\u7248\u672c\u67092007\u548c2012\u4e24\u4e2a\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528VOC2007\u4f5c\u4e3a\u6848\u4f8b\u5b9e\u73b0\u7684\u6570\u636e\uff0c\u8be5\u6570\u636e\u96c6\u603b\u5171\u6709\u56db\u5927\u7c7b\uff0c20\u4e2a\u5c0f\u7c7b\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4ece2007\u5e74\u5f00\u59cb\uff0cPASCAL VOC\u6bcf\u5e74\u7684\u6570\u636e\u96c6\u90fd\u662f\u8fd9\u4e2a\u5c42\u7ea7\u7ed3\u6784 \u603b\u5171\u56db\u4e2a\u5927\u7c7b\uff1avehicle,household,animal,person \u603b\u517120\u4e2a\u5c0f\u7c7b\uff0c\u9884\u6d4b\u7684\u65f6\u5019\u662f\u53ea\u8f93\u51fa\u56fe\u4e2d\u9ed1\u8272\u7c97\u4f53\u7684\u7c7b\u522b \u7ec4\u7ec7\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a Annotations \u8fdb\u884c detection \u4efb\u52a1\u65f6\u7684\u6807\u7b7e\u6587\u4ef6\uff0cxml \u5f62\u5f0f\uff0c\u6587\u4ef6\u540d\u4e0e\u56fe\u7247\u540d\u4e00\u4e00\u5bf9\u5e94 ImageSets \u5305\u542b\u4e09\u4e2a\u5b50\u6587\u4ef6\u5939 Layout\u3001Main\u3001Segmentation\uff0c\u5176\u4e2d Main \u5b58\u653e\u7684\u662f\u5206\u7c7b\u548c\u68c0\u6d4b\u7684\u6570\u636e\u96c6\u5206\u5272\u6587\u4ef6 JPEGImages \u5b58\u653e .jpg \u683c\u5f0f\u7684\u56fe\u7247\u6587\u4ef6 SegmentationClass \u5b58\u653e\u6309\u7167 class \u5206\u5272\u7684\u56fe\u7247 SegmentationObject \u5b58\u653e\u6309\u7167 object \u5206\u5272\u7684\u56fe\u7247 \u6211\u4eec\u4f7f\u7528\u7684\u5c31\u662fAnnotations\u548cJPEGImages\u4e24\u90e8\u5206\u5185\u5bb9\uff0c\u53e6\u5916\u6211\u4eec\u901a\u8fc7Main\u6587\u4ef6\u5939\u4e0b\u7684\u6587\u672c\u6587\u4ef6\u83b7\u53d6\u5bf9\u5e94\u7684\u8bad\u7ec3\u96c6\u53ca\u9a8c\u8bc1\u96c6\u6570\u636e\uff0c\u5185\u5bb9\u5982\u4e0b\u6240\u793a\uff1a train.txt \u5199\u7740\u7528\u4e8e\u8bad\u7ec3\u7684\u56fe\u7247\u540d\u79f0\uff0c \u5171 2501 \u4e2a val.txt \u5199\u7740\u7528\u4e8e\u9a8c\u8bc1\u7684\u56fe\u7247\u540d\u79f0\uff0c\u5171 2510 \u4e2a trainval.txt train\u4e0eval\u7684\u5408\u96c6\u3002\u5171 5011 \u4e2a 1.2 \u6807\u6ce8\u4fe1\u606f \u00b6 \u6570\u636e\u96c6\u7684\u6807\u6ce8\u6709\u4e13\u95e8\u7684\u6807\u6ce8\u56e2\u961f\uff0c\u5e76\u9075\u4ece\u7edf\u4e00\u7684\u6807\u6ce8\u6807\u51c6\uff0c\u6807\u6ce8\u4fe1\u606f\u662f\u7528 xml \u6587\u4ef6\u7ec4\u7ec7\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6807\u6ce8\u4fe1\u606f\u5982\u4e0b\u6240\u793a\uff1a <annotation> <!--\u6570\u636e\u96c6\u7248\u672c\u4f4d\u7f6e--> <folder> VOC2007 </folder> <!--\u6587\u4ef6\u540d--> <filename> 000001.jpg </filename> <!--\u6587\u4ef6\u6765\u6e90--> <source> <database> The VOC2007 Database </database> <annotation> PASCAL VOC2007 </annotation> <image> flickr </image> <flickrid> 341012865 </flickrid> </source> <!--\u62e5\u6709\u8005--> <owner> <flickrid> Fried Camels </flickrid> <name> Jinky the Fruit Bat </name> </owner> <!--\u56fe\u7247\u5927\u5c0f--> <size> <width> 353 </width> <height> 500 </height> <depth> 3 </depth> </size> <!--\u662f\u5426\u5206\u5272--> <segmented> 0 </segmented> <!--\u4e00\u4e2a\u76ee\u6807\uff0c\u91cc\u9762\u7684\u5185\u5bb9\u662f\u76ee\u6807\u7684\u76f8\u5173\u4fe1\u606f--> <object> <!--object\u540d\u79f0\uff0c20\u4e2a\u7c7b\u522b--> <name> dog </name> <!--\u62cd\u6444\u89d2\u5ea6\uff1afront, rear, left, right\u3002\u3002--> <pose> Left </pose> <!--\u76ee\u6807\u662f\u5426\u88ab\u622a\u65ad\uff0c\u6216\u8005\u88ab\u906e\u6321\uff08\u8d85\u8fc715%\uff09--> <truncated> 1 </truncated> <!--\u68c0\u6d4b\u96be\u6613\u7a0b\u5ea6--> <difficult> 0 </difficult> <!--bounding box \u7684\u5de6\u4e0a\u89d2\u70b9\u548c\u53f3\u4e0b\u89d2\u70b9\u7684\u5750\u6807\u503c--> <bndbox> <xmin> 48 </xmin> <ymin> 240 </ymin> <xmax> 195 </xmax> <ymax> 371 </ymax> </bndbox> </object> <!--\u4e00\u4e2a\u76ee\u6807\uff0c\u91cc\u9762\u7684\u5185\u5bb9\u662f\u76ee\u6807\u7684\u76f8\u5173\u4fe1\u606f--> <object> <name> person </name> <pose> Left </pose> <!--\u76ee\u6807\u662f\u5426\u88ab\u622a\u65ad\uff0c\u6216\u8005\u88ab\u906e\u6321\uff08\u8d85\u8fc715%\uff09--> <truncated> 1 </truncated> <difficult> 0 </difficult> <bndbox> <xmin> 8 </xmin> <ymin> 12 </ymin> <xmax> 352 </xmax> <ymax> 498 </ymax> </bndbox> </object> </annotation> 2 \u6570\u636e\u96c6\u89e3\u6790 \u00b6 \u8be5\u6570\u636e\u96c6\u7684\u89e3\u6790\u5728fasterRCNN/detection/datasets/pascal_voc.py\u4e2d: \u63a5\u4e0b\u6765\u6211\u4eec\u5206\u6790\u6574\u4e2a\u7684\u5b9e\u73b0\u8fc7\u7a0b\uff1a 2.1 \u6307\u5b9a\u6570\u636e\u96c6 \u00b6 \u6839\u636e\u6307\u5b9a\u7684\u6570\u636e\u96c6\uff0c\u83b7\u53d6\u5bf9\u5e94\u7684\u6587\u4ef6\u4fe1\u606f\uff0c\u8fdb\u884c\u5904\u7406,\u5176\u4e2dmain\u4e2dtxt\u4e2d\u7684\u5185\u5bb9\u5982\u4e0b\u6240\u793a: \u56e0\u6b64\u6211\u4eec\u6839\u636etxt\u4e2d\u7684\u5185\u5bb9\u52a0\u8f7d\u5bf9\u5e94\u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1\u96c6: def load_labels ( self ): # \u6839\u636e\u6807\u7b7e\u4fe1\u606f\u52a0\u8f7d\u76f8\u5e94\u7684\u6570\u636e if self . phase == 'train' : txtname = os . path . join ( self . data_path , 'ImageSets' , 'Main' , 'trainval.txt' ) else : txtname = os . path . join ( self . data_path , 'ImageSets' , 'Main' , 'val.txt' ) # \u83b7\u53d6\u56fe\u50cf\u7684\u7d22\u5f15 with open ( txtname , 'r' ) as f : self . image_index = [ x . strip () for x in f . readlines ()] self . num_image = len ( self . image_index ) # \u56fe\u50cf\u5bf9\u5e94\u7684\u7d22\u5f15\u653e\u5230\u5217\u8868gt_labels\u4e2d gt_labels = [] # \u904d\u5386\u6bcf\u4e00\u4efd\u56fe\u50cf\u83b7\u53d6\u6807\u6ce8\u4fe1\u606f for index in self . image_index : # \u83b7\u53d6\u6807\u6ce8\u4fe1\u606f\uff0c\u5305\u62ecobjet box\u5750\u6807\u4fe1\u606f \u4ee5\u53ca\u7c7b\u522b\u4fe1\u606f gt_label = self . load_pascal_annotation ( index ) # \u6dfb\u52a0\u5230\u5217\u8868\u4e2d gt_labels . append ( gt_label ) # \u5c06\u6807\u6ce8\u4fe1\u606f\u8d4b\u503c\u7ed9\u5c5e\u6027\uff1aself.gt_labels self . gt_labels = gt_labels 2.2\u56fe\u50cf\u8bfb\u53d6 \u00b6 \u5229\u7528OpenCV\u8bfb\u53d6\u56fe\u50cf\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u901a\u9053\u7684\u8f6c\u6362\uff1a def image_read ( self , imname ): # opencv \u4e2d\u9ed8\u8ba4\u56fe\u7247\u8272\u5f69\u683c\u5f0f\u4e3aBGR image = cv2 . imread ( imname ) # \u5c06\u56fe\u7247\u8f6c\u6210RGB\u683c\u5f0f image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) . astype ( np . float32 ) return image 2.3 \u6807\u51c6\u4fe1\u606f\u7684\u8bfb\u53d6 \u00b6 \u6807\u6ce8\u4fe1\u606f\u7684\u8bfb\u53d6\u4e3b\u8981\u662f\u6839\u636e\u56fe\u50cf\u7684\u6587\u4ef6\u540d\u83b7\u53d6\u7d22\u5f15\u540e\uff0c\u627e\u5230\u5bf9\u5e94\u7684XML\u6587\u4ef6\uff0c\u8bfb\u53d6\u5176\u4e2d\u7684\u5185\u5bb9\uff0c\u5f97\u5230\u56fe\u50cf\u7684\u6807\u6ce8\u4fe1\u606f\u3002 def load_pascal_annotation ( self , index ): \"\"\" \u5728PASCAL VOC\u7684XML\u6587\u4ef6\u83b7\u53d6\u8fb9\u6846\u4fe1\u606f\u548c\u7c7b\u522b\u4fe1\u606f \"\"\" # \u83b7\u53d6XML\u6587\u4ef6\u7684\u5730\u5740 filename = os . path . join ( self . data_path , 'Annotations' , index + '.xml' ) # \u5c06XML\u4e2d\u7684\u5185\u5bb9\u83b7\u53d6\u51fa\u6765 tree = ET . parse ( filename ) # \u83b7\u53d6\u8282\u70b9\u56fe\u50cf\u7684size image_size = tree . find ( 'size' ) # \u5c06\u56fe\u50cf\u7684size\u4fe1\u606f\u5b58\u653e\u5230sizeinfo\u4e2d size_info = np . zeros (( 2 ,), dtype = np . float32 ) # \u5bbd size_info [ 0 ] = float ( image_size . find ( 'width' ) . text ) # \u9ad8 size_info [ 1 ] = float ( image_size . find ( 'height' ) . text ) # \u627e\u5230\u6240\u6709\u7684object\u8282\u70b9 objs = tree . findall ( 'object' ) # object\u7684\u6570\u91cf num_objs = len ( objs ) # boxes \u5750\u6807 (num_objs,4) boxes = np . zeros (( num_objs , 4 ), dtype = np . float32 ) # class \u7684\u6570\u91cfnum_objs\u4e2a\uff0c\u6bcf\u4e2a\u76ee\u6807\u4e00\u4e2a\u7c7b\u522b gt_classes = np . zeros (( num_objs ), dtype = np . int32 ) # \u904d\u5386\u6240\u6709\u7684\u76ee\u6807 for ix , obj in enumerate ( objs ): # \u627e\u5230bndbox\u8282\u70b9 bbox = obj . find ( 'bndbox' ) # \u83b7\u53d6\u5750\u6807\u6846\u7684\u4f4d\u7f6e\u4fe1\u606f x1 = float ( bbox . find ( 'xmin' ) . text ) - 1 y1 = float ( bbox . find ( 'ymin' ) . text ) - 1 x2 = float ( bbox . find ( 'xmax' ) . text ) - 1 y2 = float ( bbox . find ( 'ymax' ) . text ) - 1 # \u5c06\u4f4d\u7f6e\u4fe1\u606f\u5b58\u50a8\u5728bbox\u4e2d\uff0c\u6ce8\u610fboxes\u662f\u4e00\u4e2anp\u7c7b\u7684\u77e9\u9635 \u5927\u5c0f\u4e3a[num_objs,4] boxes [ ix , :] = [ y1 , x1 , y2 , x2 ] # \u627e\u5230class\u5bf9\u5e94\u7684\u7c7b\u522b\u4fe1\u606f cls = self . class_to_ind [ obj . find ( 'name' ) . text . lower () . strip ()] # \u5c06class\u4fe1\u606f\u5b58\u5165gt_classses\u4e2d\uff0c\u6ce8\u610fgt_classes\u4e5f\u662f\u4e00\u4e2anp\u7c7b\u7684\u77e9\u9635 \u5927\u5c0f\u4e3a[num_objs] \u662fint\u503c \u5bf9\u5e94\u4e8ename gt_classes [ ix ] = cls # \u83b7\u53d6\u56fe\u50cf\u7684\u5b58\u50a8\u8def\u5f84 imname = os . path . join ( self . data_path , 'JPEGImages' , index + '.jpg' ) # \u8fd4\u56de\u7ed3\u679c return { 'boxes' : boxes , 'gt_classs' : gt_classes , 'imname' : imname , 'image_size' : size_info , 'image_index' : index } 2.4 \u56fe\u50cf\u7684\u5927\u5c0f\u5904\u7406 \u00b6 \u5728\u5c06\u56fe\u50cf\u9001\u5165\u5230\u7f51\u7edc\u4e2d\u65f6\uff0c\u6211\u4eec\u9700\u8981\u5c06\u5176\u8fdb\u884c\u5927\u5c0f\u7684\u8c03\u6574\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u4e3a\u4e86\u4fdd\u8bc1\u957f\u5bbd\u6bd4\uff0c\u4f7f\u6700\u957f\u8fb9resize\u4e3a1024\uff0c\u77ed\u8fb9\u8fdb\u884cpad: def prep_im_for_blob ( self , im , pixel_means , target_size , max_size ): \"\u5bf9\u8f93\u5165\u7684\u56fe\u50cf\u8fdb\u884c\u5904\u7406\" im = im . astype ( np . float32 , copy = False ) # \u51cf\u53bb\u5747\u503c im -= pixel_means # \u56fe\u50cf\u7684\u5927\u5c0f im_shape = im . shape # \u6700\u77ed\u8fb9 im_size_min = np . min ( im_shape [ 0 : 2 ]) # \u6700\u957f\u8fb9 im_size_max = np . max ( im_shape [ 0 : 2 ]) # \u77ed\u8fb9\u53d8\u6362\u5230800\u7684\u6bd4\u4f8b im_scale = float ( target_size ) / float ( im_size_min ) # 600/\u6700\u77ed\u8fb9 # \u82e5\u957f\u8fb9\u4ee5\u4e0a\u8ff0\u6bd4\u4f8b\u53d8\u6362\u540e\u5927\u4e8e1024\uff0c\u5219\u4fee\u6b63\u53d8\u6362\u6bd4\u4f8b if np . round ( im_scale * im_size_max ) > max_size : im_scale = float ( max_size ) / float ( im_size_max ) # \u6839\u636e\u53d8\u6362\u6bd4\u4f8b\u5bf9\u56fe\u50cf\u8fdb\u884cresize im = cv2 . resize ( im , None , None , fx = im_scale , fy = im_scale , interpolation = cv2 . INTER_LINEAR ) shape = ( 1024 , 1024 , im . shape [ - 1 ]) pad = np . zeros ( shape , dtype = im . dtype ) pad [: im . shape [ 0 ], : im . shape [ 1 ], ... ] = im # \u8fd4\u56deim \u548c im_scale return pad , im_scale , im . shape 2.5 \u6784\u5efa\u6570\u636e\u8bfb\u53d6\u7684\u7c7b \u00b6 \u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528tf.keras.utils.Sequence\u6765\u5b8c\u6210\u6570\u636e\u7684\u8bfb\u53d6\uff0c\u7ee7\u627fSequence\u7c7b\u5fc5\u987b\u91cd\u8f7d\u4e09\u4e2a\u79c1\u6709\u65b9\u6cd5__init__\u3001 len__\u548c__getitem \uff0c\u4e3b\u8981\u662f__getitem__\u3002 \u0015__init__\u662f\u6784\u9020\u65b9\u6cd5\uff0c\u7528\u4e8e\u521d\u59cb\u5316\u6570\u636e\u7684\u3002 __len__\u7528\u4e8e\u8ba1\u7b97\u6837\u672c\u6570\u636e\u957f\u5ea6\u3002 __getitem__\u7528\u4e8e\u751f\u6210\u6574\u4e2abatch\u7684\u6570\u636e\uff0c\u9001\u5165\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5176\u8f93\u51fa\u683c\u5f0f\u662f\u5143\u7ec4\u3002__getitem__\u76f8\u5f53\u4e8e\u751f\u6210\u5668\u7684\u4f5c\u7528\u3002 Sequence \u662f\u8fdb\u884c\u591a\u5904\u7406\u7684\u66f4\u5b89\u5168\u65b9\u6cd5\u3002\u8fd9\u79cd\u7ed3\u6784\u4fdd\u8bc1\u4e86\u7f51\u7edc\u5728\u6bcf\u4e2a\u65f6\u95f4\u6bb5\u7684\u6bcf\u4e2a\u6837\u672c\u4e0a\u53ea\u4f1a\u8bad\u7ec3\u4e00\u6b21\u3002 \u4f8b\u5982\uff1a class CIFAR10Sequence ( Sequence ): # \u5b9a\u4e49\u4e00\u4e2a\u7c7b\u7ee7\u627f\u81eaSequence # _init_\u65b9\u6cd5\u8fdb\u884c\u521d\u59cb\u5316\u6570\u636e\uff0c\u6307\u5b9a\u76f8\u5e94\u7684\u5c5e\u6027\u5373\u53ef def __init__ ( self , x_set , y_set , batch_size ): # \u6570\u636e\u96c6 self . x , self . y = x_set , y_set # batch\u7684\u5927\u5c0f self . batch_size = batch_size # \u5b9a\u4e49\u4e00\u4e2aepoch\u4e2d\u7684\u8fed\u4ee3\u6b21\u6570 def __len__ ( self ): return math . ceil ( len ( self . x ) / self . batch_size ) # \u83b7\u53d6\u4e00\u4e2a\u6279\u6b21\u6570\u636e def __getitem__ ( self , idx ): # \u83b7\u53d6\u4e00\u4e2a\u6279\u6b21\u7684\u7279\u5f81\u503c\u6570\u636e batch_x = self . x [ idx * self . batch_size :( idx + 1 ) * self . batch_size ] # \u83b7\u53d6\u4e00\u4e2a\u6279\u6b21\u7684\u76ee\u6807\u503c\u6570\u636e batch_y = self . y [ idx * self . batch_size :( idx + 1 ) * self . batch_size ] # \u8fd4\u56de\u7ed3\u679c return np . array ([ resize ( imread ( file_name )) for file_name in batch_x ]), np . array ( batch_y ) \u90a3\u5728VOC\u6570\u636e\u96c6\u7684\u8bfb\u53d6\u4e2d\u6211\u4eec\u4e5f\u7c7b\u4f3c\u7684\u8fdb\u884c\u5904\u7406\uff1a class pascal_voc ( keras . utils . Sequence ): def __init__ ( self , phase ): # pascal_voc 2007\u6570\u636e\u7684\u5b58\u50a8\u8def\u5f84 self . data_path = os . path . join ( '../VOCdevkit' , 'VOC2007' ) # batch_size self . batch_size = 1 # \u56fe\u7247\u7684\u6700\u5c0f\u5c3a\u5bf8 self . target_size = 800 # \u56fe\u7247\u7684\u6700\u5927\u5c3a\u5bf8 self . max_size = 1024 # \u8f93\u5165\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf\u5c3a\u5bf8 self . scale = ( 1024 , 1024 ) # \u7c7b\u522b\u4fe1\u606f ['background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus'....] self . classes = [ 'background' , 'aeroplane' , 'bicycle' , 'bird' , 'boat' , 'bottle' , 'bus' , 'car' , 'cat' , 'chair' , 'cow' , 'diningtable' , 'dog' , 'horse' , 'motorbike' , 'person' , 'pottedplant' , 'sheep' , 'sofa' , 'train' , 'tvmonitor' ] # \u6784\u5efa\u76ee\u6807\u7c7b\u522b\u7684\u5b57\u5178{'background': 0, 'aeroplane': 1, \"bicycle\": 2....} self . class_to_ind = dict ( zip ( self . classes , range ( len ( self . classes )))) # \u50cf\u7d20RGB\u7684\u5747\u503c self . pixel_means = np . array ([[[ 122.7717 , 115.9465 , 102.9801 ]]]) # \u7528\u6765\u6307\u660e\u83b7\u53d6\u8bad\u7ec3\u96c6\u6216\u8005\u662f\u9a8c\u8bc1\u96c6\u6570\u636e self . phase = phase # \u83b7\u53d6\u56fe\u50cf\u6570\u91cf\uff0c\u5e76\u52a0\u8f7d\u76f8\u5e94\u7684\u6807\u7b7e self . load_labels () # \u76ee\u6807\u603b\u6570\u91cf self . num_gtlabels = len ( self . gt_labels ) self . img_transform = transforms . ImageTransform ( self . scale , self . pixel_means , [ 1. , 1. , 1. ], 'fixed' ) self . bbox_transform = transforms . BboxTransform () self . flip_ratio = 0.5 def __len__ ( self ): # \u8fd4\u56de\u8fed\u4ee3\u6b21\u6570 return np . round ( self . num_image / self . batch_size ) def __getitem__ ( self , idx ): # \u83b7\u53d6\u5f53\u524dbatch\u7684\u8d77\u59cb\u7d22\u5f15\u503c i = idx * self . batch_size batch_images = [] batch_imgmeta = [] batch_box = [] bacth_labels = [] for c in range ( self . batch_size ): # \u83b7\u53d6\u76f8\u5e94\u7684\u56fe\u50cf imname = self . gt_labels [ i + c ][ 'imname' ] # \u8bfb\u53d6\u56fe\u50cf image = self . image_read ( imname ) # \u83b7\u53d6\u539f\u59cb\u56fe\u50cf\u7684\u5c3a\u5bf8 ori_shape = image . shape # \u8fdb\u884c\u5c3a\u5ea6\u8c03\u6574\u540e\u7684\u56fe\u50cf\u53ca\u8c03\u6574\u7684\u5c3a\u5ea6 image , image_scale , image_shape = self . prep_im_for_blob ( image , self . pixel_means , self . target_size , self . max_size ) # \u83b7\u53d6\u5c3a\u5ea6\u53d8\u6362\u540e\u56fe\u50cf\u7684\u5c3a\u5bf8 pad_shape = image . shape # \u5c06gt_boxlabel\u4e0escale\u76f8\u4e58\u83b7\u53d6\u56fe\u50cf\u8c03\u6574\u540e\u7684\u6807\u6ce8\u6846\u7684\u5927\u5c0f\uff1aboxes.shape=[num_obj,4] bboxes = self . gt_labels [ i + c ][ 'boxes' ] * image_scale # \u83b7\u53d6\u5bf9\u5e94\u7684\u7c7b\u522b\u4fe1\u606f labels = self . gt_labels [ i + c ][ 'gt_classs' ] # print(labels) # \u56fe\u50cf\u7684\u57fa\u672c\u4fe1\u606f img_meta_dict = dict ({ 'ori_shape' : ori_shape , 'img_shape' : image_shape , 'pad_shape' : pad_shape , 'scale_factor' : image_scale }) # \u5c06\u5b57\u5178\u8f6c\u6362\u4e3a\u5217\u8868\u7684\u5f62\u5f0f image_meta = self . compose_image_meta ( img_meta_dict ) # print(image_meta) batch_images . append ( image ) bacth_labels . append ( labels ) batch_imgmeta . append ( image_meta ) batch_box . append ( bboxes ) # \u5c06\u56fe\u50cf\u8f6c\u6362\u6210tensorflow\u8f93\u5165\u7684\u5f62\u5f0f:\u3010batch_size,H,W,C\u3011 batch_images = np . reshape ( batch_images , ( self . batch_size , image . shape [ 0 ], image . shape [ 1 ], 3 )) # \u56fe\u50cf\u5143\u4fe1\u606f batch_imgmeta = np . reshape ( batch_imgmeta ,( self . batch_size , 11 )) # \u6807\u6ce8\u6846\u4fe1\u606f batch_box = np . reshape ( batch_box ,( self . batch_size , bboxes . shape [ 0 ], 4 )) # \u6807\u6ce8\u7c7b\u522b\u4fe1\u606f bacth_labels = np . reshape ( bacth_labels ,(( self . batch_size , labels . shape [ 0 ]))) # \u8fd4\u56de\u7ed3\u679c\uff1a\u5c3a\u5ea6\u53d8\u6362\u540e\u7684\u56fe\u50cf\uff0c\u56fe\u50cf\u5143\u4fe1\u606f\uff0c\u76ee\u6807\u6846\u4f4d\u7f6e\uff0c\u76ee\u6807\u7c7b\u522b return batch_images , batch_imgmeta , batch_box , bacth_labels 2.6 \u6570\u636e\u89e3\u6790\u7c7b\u6f14\u793a \u00b6 \u6211\u4eec\u5229\u7528\u4e0a\u8ff0\u7684\u6570\u636e\u89e3\u6790\u65b9\u6cd5\u6765\u5bf9VOC\u6570\u636e\u96c6\u8fdb\u884c\u89e3\u6790\uff1a \u5bfc\u5165\u6240\u9700\u7684\u5de5\u5177\u5305 # \u5bfc\u5165\u6570\u636e\u96c6 VOC data from detection.datasets import pascal_voc from detection.datasets.utils import get_original_image import numpy as np # \u56fe\u50cf\u5c55\u793a from matplotlib import pyplot as plt \u83b7\u53d6\u56fe\u50cf\u5e76\u8bbe\u7f6e\u56fe\u50cf\u7684\u5747\u503c\u4e0e\u65b9\u5dee # \u5b9e\u4f8b\u5316 pascal = pascal_voc . pascal_voc ( 'train' ) # \u83b7\u53d6\u56fe\u50cf image , image_meta , bboxes , labels = pascal [ 8 ] # \u56fe\u50cf\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee img_mean = ( 122.7717 , 115.9465 , 102.9801 ) img_std = ( 1. , 1. , 1. ) \u539f\u56fe\u50cf\u5c55\u793a # \u83b7\u53d6\u539f\u56fe\u50cf ori_img = get_original_image ( image [ 0 ], image_meta [ 0 ], img_mean ) . astype ( np . uint8 ) # \u56fe\u50cf\u5c55\u793a plt . imshow ( ori_img ) plt . show () \u0015\u9001\u5165\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf\u8fdb\u884c\u4e86resize\u548cpasding # \u9001\u5165\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf rgb_img = np . round ( image + img_mean ) . astype ( np . uint8 ) plt . imshow ( rgb_img [ 0 ]) plt . show () \u5c06\u6807\u6ce8\u4fe1\u606f\u663e\u793a\u51fa\u6765 # \u663e\u793a\u56fe\u50cf\uff0c\u53ca\u5bf9\u5e94\u7684\u6807\u7b7e\u503c import visualize visualize . display_instances ( rgb_img [ 0 ], bboxes [ 0 ], labels [ 0 ], pascal . classes ) 3.\u6a21\u578b\u8bad\u7ec3 \u00b6 \u63a5\u4e0b\u6765\u6211\u4eec\u5229\u7528\u5df2\u642d\u5efa\u597d\u7684\u7f51\u7edc\u548c\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\uff1a \u5b9a\u4e49tf.GradientTape\u7684\u4f5c\u7528\u57df\uff0c\u8ba1\u7b97\u635f\u5931\u503c \u4f7f\u7528 tape.gradient(ys, xs) \u81ea\u52a8\u8ba1\u7b97\u68af\u5ea6 \u4f7f\u7528 optimizer.apply_gradients(grads_and_vars) \u81ea\u52a8\u66f4\u65b0\u6a21\u578b\u53c2\u6570 \u5b8c\u6210\u7f51\u7edc\u7684\u8bad\u7ec3\u3002\u6211\u4eec\u6765\u770b\u4e0b\u5b9e\u73b0\u6d41\u7a0b\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 from detection.datasets import pascal_voc import tensorflow as tf import numpy as np from matplotlib import pyplot as plt from detection.models.detectors import faster_rcnn \u52a0\u8f7d\u6570\u636e\u83b7\u53d6\u6570\u636e\u7c7b\u522b # \u52a0\u8f7d\u6570\u636e\u96c6 train_dataset = pascal_voc . pascal_voc ( 'train' ) # \u6570\u636e\u7c7b\u522b num_classes = len ( train_dataset . classes ) \u6a21\u578b\u52a0\u8f7d model = faster_rcnn . FasterRCNN ( num_classes = num_classes ) \u5b9a\u4e49\u4f18\u5316\u5668 # \u4f18\u5316\u5668 optimizer = tf . keras . optimizers . SGD ( 1e-3 , momentum = 0.9 , nesterov = True ) \u6a21\u578b\u8bad\u7ec3 # \u6a21\u578b\u4f18\u5316 loss_his = [] for epoch in range ( 10 ): # \u83b7\u53d6\u6837\u672c\u7684index indices = np . arange ( train_dataset . num_gtlabels ) # \u6253\u4e71 np . random . shuffle ( indices ) # \u8fed\u4ee3\u6b21\u6570 iter = np . round ( train_dataset . num_gtlabels / train_dataset . batch_size ) . astype ( np . uint8 ) # \u6bcf\u4e00\u6b21\u8fed\u4ee3 for idx in range ( iter ): # \u83b7\u53d6\u67d0\u4e00\u4e2abacth idx = indices [ idx ] # \u83b7\u53d6\u5f53\u524dbatch\u7684\u7ed3\u679c batch_imgs , batch_metas , batch_bboxes , batch_labels = train_dataset [ idx ] # \u5b9a\u4e49\u4f5c\u7528\u57df with tf . GradientTape () as tape : # \u5c06\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\u8ba1\u7b97\u635f\u5931 rpn_class_loss , rpn_bbox_loss , rcnn_class_loss , rcnn_bbox_loss = \\ model (( batch_imgs , batch_metas , batch_bboxes , batch_labels ), training = True ) # \u6c42\u603b\u635f\u5931 loss = rpn_class_loss + rpn_bbox_loss + rcnn_class_loss + rcnn_bbox_loss # \u8ba1\u7b97\u68af\u5ea6\u503c grads = tape . gradient ( loss , model . trainable_variables ) # \u66f4\u65b0\u53c2\u6570\u503c optimizer . apply_gradients ( zip ( grads , model . trainable_variables )) # \u6253\u5370\u635f\u5931\u7ed3\u679c print ( \"epoch\uff1a %d , loss\uff1a %f \" % ( epoch + 1 , loss )) loss_his . append ( loss ) # \u6bcf\u4e00\u6b21\u8fed\u4ee3\u4e2d\u53ea\u8fd0\u884c\u4e00\u4e2a\u56fe\u50cf continue # \u6bcf\u4e00\u4e2aepoch\u4e2d\u53ea\u8fd0\u884c\u4e00\u6b21\u8fed\u4ee3 continue \u7ed3\u679c\u4e3a\uff1a epoch \uff1a 1 , loss \uff1a 147.117371 epoch \uff1a 2 , loss \uff1a 72.580498 epoch \uff1a 3 , loss \uff1a 79.347351 epoch \uff1a 4 , loss \uff1a 41.220577 epoch \uff1a 5 , loss \uff1a 5.238140 epoch \uff1a 6 , loss \uff1a 2.924250 epoch \uff1a 7 , loss \uff1a 5.287500 \u635f\u5931\u51fd\u6570\u7684\u53d8\u6362\u5982\u4e0b\u56fe\u6240\u793a\uff1a # \u7ed8\u5236\u635f\u5931\u51fd\u6570\u53d8\u5316\u7684\u66f2\u7ebf plt . plot ( range ( len ( loss_his )),[ loss . numpy () for loss in loss_his ]) plt . grid () 4.\u6a21\u578b\u6d4b\u8bd5 \u00b6 \u5728\u8fd9\u91cc\u6211\u4eec\u9996\u5148\u52a0\u8f7d\u6a21\u578b\uff0c\u6211\u4eec\u6765\u770b\u4e0bRPN\u7f51\u7edc\u548cfastRCNN\u7f51\u7edc\u7684\u8f93\u51fa\u3002 \u5bfc\u5165\u5de5\u5177\u5305 # \u5bfc\u5165\u6570\u636e\u96c6 VOC data from detection.datasets import pascal_voc import numpy as np # \u56fe\u50cf\u5c55\u793a from matplotlib import pyplot as plt # \u663e\u793a\u56fe\u50cf\uff0c\u53ca\u5bf9\u5e94\u7684\u6807\u7b7e\u503c import visualize # \u6a21\u578b\u52a0\u8f7d from detection.models.detectors import faster_rcnn import tensorflow as tf from detection.core.bbox import transforms from detection.datasets.utils import get_original_image 4.1 \u6570\u636e\u548c\u6a21\u578b\u52a0\u8f7d \u00b6 \u9996\u5148\u52a0\u8f7d\u8981\u8fdb\u884c\u9884\u6d4b\u7684\u6570\u636e\u548c\u8bad\u7ec3\u597d\u7684\u6a21\u578b: \u6570\u636e\u96c6\u52a0\u8f7d # \u6570\u636e\u96c6\u52a0\u8f7d # \u5b9e\u4f8b\u5316 pascal = pascal_voc . pascal_voc ( 'train' ) # \u83b7\u53d6\u56fe\u50cf image , image_meta , bboxes , labels = pascal [ 8 ] # \u56fe\u50cf\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee img_mean = ( 122.7717 , 115.9465 , 102.9801 ) img_std = ( 1. , 1. , 1. ) # \u83b7\u53d6\u56fe\u50cf\uff0c\u663e\u793a rgb_img = np . round ( image + img_mean ) . astype ( np . uint8 ) plt . imshow ( rgb_img [ 0 ]) plt . show () \u6a21\u578b\u52a0\u8f7d # \u52a0\u8f7d\u6a21\u578b\uff1a\u6a21\u578b\u8bad\u7ec3\u662f\u5728COCO\u6570\u636e\u96c6\u4e2d\u8fdb\u884c\u7684\uff0c # coco\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f classes = [ 'bg' , 'person' , 'bicycle' , 'car' , 'motorcycle' , 'airplane' , 'bus' , 'train' , 'truck' , 'boat' , 'traffic light' , 'fire hydrant' , 'stop sign' , 'parking meter' , 'bench' , 'bird' , 'cat' , 'dog' , 'horse' , 'sheep' , 'cow' , 'elephant' , 'bear' , 'zebra' , 'giraffe' , 'backpack' , 'umbrella' , 'handbag' , 'tie' , 'suitcase' , 'frisbee' , 'skis' , 'snowboard' , 'sports ball' , 'kite' , 'baseball bat' , 'baseball glove' , 'skateboard' , 'surfboard' , 'tennis racket' , 'bottle' , 'wine glass' , 'cup' , 'fork' , 'knife' , 'spoon' , 'bowl' , 'banana' , 'apple' , 'sandwich' , 'orange' , 'broccoli' , 'carrot' , 'hot dog' , 'pizza' , 'donut' , 'cake' , 'chair' , 'couch' , 'potted plant' , 'bed' , 'dining table' , 'toilet' , 'tv' , 'laptop' , 'mouse' , 'remote' , 'keyboard' , 'cell phone' , 'microwave' , 'oven' , 'toaster' , 'sink' , 'refrigerator' , 'book' , 'clock' , 'vase' , 'scissors' , 'teddy bear' , 'hair drier' , 'toothbrush' ] # \u6a21\u578b\u52a0\u8f7d model = faster_rcnn . FasterRCNN ( num_classes = len ( classes )) # \u5c06\u6570\u636e\u9001\u5165\u5230\u7f51\u7edc\u4e2d _ = model (( image , image_meta , bboxes , labels ), training = True ) # \u52a0\u8f7d\u5df2\u8bad\u7ec3\u597d\u7684\u6743\u91cd model . load_weights ( 'weights/faster_rcnn.h5' ) \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u6765\u770b\u4e0bRPN\u7f51\u7edc\u548cfastRCNN\u7684\u8f93\u51fa\u3002 4.2 RPN\u7f51\u7edc \u00b6 4.2.1 RPN\u7684\u76ee\u6807\u503c \u00b6 \u83b7\u53d6\u56fe\u50cf\u7684anchor,\u5e76\u5339\u914d\u76ee\u6807\u503c # \u6839\u636e\u56fe\u50cf\u4fe1\u606f\u4ea7\u751fanchor anchors , valid_flags = model . rpn_head . generator . generate_pyramid_anchors ( image_meta ) # \u5e76\u8bbe\u7f6eanchor\u5bf9\u5e94\u7684\u76ee\u6807\u503c rpn_target_matchs , rpn_target_deltas = model . rpn_head . anchor_target . build_targets ( anchors , valid_flags , bboxes , labels ) \u83b7\u53d6\u6b63\u8d1f\u6837\u672c\uff0c\u53ca\u6b63\u6837\u672c\u7684\u56de\u5f52\u503c # \u83b7\u53d6\u6b63\u6837\u672c positive_anchors = tf . gather ( anchors , tf . where ( tf . equal ( rpn_target_matchs , 1 ))[:, 1 ]) # \u83b7\u53d6\u8d1f\u6837\u672c negative_anchors = tf . gather ( anchors , tf . where ( tf . equal ( rpn_target_matchs , - 1 ))[:, 1 ]) # \u83b7\u53d6\u975e\u6b63\u975e\u8d1f\u6837\u672c neutral_anchors = tf . gather ( anchors , tf . where ( tf . equal ( rpn_target_matchs , 0 ))[:, 1 ]) # \u83b7\u53d6\u6b63\u6837\u672c\u7684\u56de\u5f52\u503c positive_target_deltas = rpn_target_deltas [ 0 , : tf . where ( tf . equal ( rpn_target_matchs , 1 )) . shape [ 0 ]] # \u83b7\u53d6anchor\u4fee\u6b63\u7684\u76ee\u6807\u503c refined_anchors = transforms . delta2bbox ( positive_anchors , positive_target_deltas , ( 0. , 0. , 0. , 0. ), ( 0.1 , 0.1 , 0.2 , 0.2 )) \u6b63\u8d1f\u6837\u672c\u7684\u7ed3\u679c # \u6b63\u8d1f\u6837\u672c\u7684\u4e2a\u6570 print ( 'rpn_target_matchs: \\t ' , rpn_target_matchs [ 0 ] . shape . as_list ()) print ( 'rpn_target_deltas: \\t ' , rpn_target_deltas [ 0 ] . shape . as_list ()) print ( 'positive_anchors: \\t ' , positive_anchors . shape . as_list ()) print ( 'negative_anchors: \\t ' , negative_anchors . shape . as_list ()) print ( 'neutral_anchors: \\t ' , neutral_anchors . shape . as_list ()) print ( 'refined_anchors: \\t ' , refined_anchors . shape . as_list () rpn_target_matchs : [ 261888 ] rpn_target_deltas : [ 256 , 4 ] positive_anchors : [ 4 , 4 ] negative_anchors : [ 252 , 4 ] neutral_anchors : [ 261632 , 4 ] refined_anchors : [ 4 , 4 ] \u5c06\u6b63\u6837\u672c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a # \u5c06\u6b63\u6837\u672c\u7684anchor\u663e\u793a\u5728\u56fe\u50cf\u4e0a visualize . draw_boxes ( rgb_img [ 0 ], boxes = positive_anchors . numpy (), refined_boxes = refined_anchors . numpy ()) plt . show () 4.2.2 RPN\u7684\u9884\u6d4b\u7ed3\u679c \u00b6 \u5c06\u56fe\u50cf\u9001\u5165\u7f51\u7edc\u4e2d\u83b7\u53d6\u9884\u6d4b\u7ed3\u679c # \u4e0d\u53ef\u8bad\u7ec3 training = False # \u83b7\u53d6backbone\u63d0\u53d6\u7684\u7279\u5f81\u7ed3\u679c C2 , C3 , C4 , C5 = model . backbone ( image , training = training ) # \u83b7\u53d6fcn\u7684\u7279\u5f81\u7ed3\u679c P2 , P3 , P4 , P5 , P6 = model . neck ([ C2 , C3 , C4 , C5 ], training = training ) \u83b7\u53d6\u9001\u5165\u5230RPN\u7f51\u7edc\u4e2d\u7684\u7279\u5f81\u56fe\uff0c\u5e76\u9001\u5165RPN\u7f51\u7edc\u4e2d # \u83b7\u53d6\u7279\u5f81\u56fe rpn_feature_maps = [ P2 , P3 , P4 , P5 , P6 ] # \u83b7\u53d6RPN\u7684\u9884\u6d4b\u7ed3\u679c:\u5206\u7c7b\u548c\u56de\u5f52\u7ed3\u679c rpn_class_logits , rpn_probs , rpn_deltas = model . rpn_head ( rpn_feature_maps , training = training ) \u5c06\u7f6e\u4fe1\u5ea6\u8f83\u9ad8\u7684anchor\u663e\u793a\u5728\u56fe\u50cf\u4e0a # [batch_size, num_anchors, (bg prob, fg prob)] rpn\u7684\u5206\u7c7b\u7ed3\u679c\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u53bb\u7b2c\u4e00\u4e2abatch,\u6240\u6709anchor\u524d\u666f\u7684\u6982\u7387 rpn_probs_tmp = rpn_probs [ 0 , :, 1 ] # \u5c06\u7f6e\u4fe1\u5ea6top100\u7684\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a limit = 100 ix = tf . nn . top_k ( rpn_probs_tmp , k = limit ) . indices [:: - 1 ] # \u7ed8\u5236\u5728\u56fe\u50cf\u4e0a visualize . draw_boxes ( rgb_img [ 0 ], boxes = tf . gather ( anchors , ix ) . numpy ()) \u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a 4.3 fastRCNN\u7f51\u7edc \u00b6 \u5c06RPN\u7684\u7ed3\u679c\u9001\u5165\u5230\u540e\u7eed\u7f51\u7edc\u4e2d\uff0c\u8fdb\u884c\u68c0\u6d4b\uff1a \u0015\u83b7\u53d6\u5019\u9009\u533a\u57df # \u5019\u9009\u533a\u57df proposals_list = model . rpn_head . get_proposals ( rpn_probs , rpn_deltas , image_meta ) \u8fdb\u884cROIPooling rois_list = proposals_list # roipooling pooled_regions_list = model . roi_align ( ( rois_list , rcnn_feature_maps , image_meta ), training = training ) \u9884\u6d4b # \u8fdb\u884c\u9884\u6d4b rcnn_class_logits_list , rcnn_probs_list , rcnn_deltas_list = \\ model . bbox_head ( pooled_regions_list , training = training ) \u83b7\u53d6\u9884\u6d4b\u7ed3\u679c # \u83b7\u53d6\u9884\u6d4b\u7ed3\u679c detections_list = model . bbox_head . get_bboxes ( rcnn_probs_list , rcnn_deltas_list , rois_list , image_meta ) \u83b7\u53d6\u9884\u6d4b\u7ed3\u679c\u7684\u5750\u6807\uff0c\u5e76\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a # \u83b7\u5f97\u5750\u6807\u503c tmp = detections_list [ 0 ][:, : 4 ] # \u5c06\u68c0\u6d4b\u68c0\u6d4b\u7684\u6846\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a visualize . draw_boxes ( rgb_img [ 0 ], boxes = tmp . numpy ()) 4.4 \u76ee\u6807\u68c0\u6d4b \u00b6 \u4e0a\u8ff0\u6211\u4eec\u662f\u5206\u6b65\u8fdb\u884c\u9884\u6d4b\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u76f4\u63a5\u5728\u539f\u56fe\u50cf\u4e0a\u8fdb\u884c\u9884\u6d4b\uff1a # \u83b7\u53d6\u539f\u56fe\u50cf ori_img = get_original_image ( image [ 0 ], image_meta [ 0 ], img_mean ) # \u83b7\u53d6\u5019\u9009\u533a\u57df proposals = model . simple_test_rpn ( image [ 0 ], image_meta [ 0 ]) # \u68c0\u6d4b\u7ed3\u679c res = model . simple_test_bboxes ( image [ 0 ], image_meta [ 0 ], proposals ) # \u5c06\u68c0\u6d4b\u7ed3\u679c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a visualize . display_instances ( ori_img , res [ 'rois' ], res [ 'class_ids' ], classes , scores = res [ 'scores' ]) \u6700\u7ec8\u7684\u68c0\u6d4b\u7ed3\u679c\u4e3a\uff1a \u603b\u7ed3 \u4e86\u89e3VOC\u6570\u636e\u96c6\u7684\u5e94\u7528\u7406\u89e3 Pascal VOC\u6570\u636e\u96c6\u4f5c\u4e3a\u57fa\u51c6\u6570\u636e\uff0c\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u5e38\u88ab\u4f7f\u7528\u5230 fasterRCNN\u6a21\u578b\u7684\u6784\u6210 \u4e3b\u8981\u6709RPN\u7f51\u7edc\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u7684\u751f\u6210\uff0c\u7136\u540e\u4f7f\u7528fastRCNN\u7f51\u7edc\u8fdb\u884c\u9884\u6d4b \u80fd\u591f\u5229\u7528fasterRCNN\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b","title":"4.3 Faster RCNN\u6848\u4f8b"},{"location":"objectdection/03.RCNN-demo/#43-faster-rcnn","text":"\u5b66\u4e60\u76ee\u6807 \u4e86\u89e3VOC\u6570\u636e\u96c6\u7684\u5e94\u7528 \u7406\u89e3fasterRCNN\u6a21\u578b\u7684\u6784\u6210 \u80fd\u591f\u5229\u7528fasterRCNN\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b","title":"4.3 Faster RCNN\u6848\u4f8b"},{"location":"objectdection/03.RCNN-demo/#1-voc","text":"Pascal VOC\u6570\u636e\u96c6\u4f5c\u4e3a\u57fa\u51c6\u6570\u636e\uff0c\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u5e38\u88ab\u4f7f\u7528\u5230\uff0c\u5f88\u591a\u4f18\u79c0\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\u6bd4\u5982\u5206\u7c7b\uff0c\u5b9a\u4f4d\uff0c\u68c0\u6d4b\uff0c\u5206\u5272\uff0c\u52a8\u4f5c\u8bc6\u522b\u7b49\u6a21\u578b\u90fd\u662f\u57fa\u4e8ePASCAL VOC\u6311\u6218\u8d5b\u53ca\u5176\u6570\u636e\u96c6\u4e0a\u63a8\u51fa\u7684\uff0c\u5c24\u5176\u662f\u4e00\u4e9b\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\uff08\u6bd4\u5982RCNN\u7cfb\u5217\uff0c\u4ee5\u53ca\u540e\u9762\u8981\u4ecb\u7ecd\u7684YOLO\uff0cSSD\u7b49\uff09\u3002","title":"1. VOC\u6570\u636e\u96c6\u7b80\u4ecb"},{"location":"objectdection/03.RCNN-demo/#11","text":"\u5e38\u7528\u7684\u7248\u672c\u67092007\u548c2012\u4e24\u4e2a\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528VOC2007\u4f5c\u4e3a\u6848\u4f8b\u5b9e\u73b0\u7684\u6570\u636e\uff0c\u8be5\u6570\u636e\u96c6\u603b\u5171\u6709\u56db\u5927\u7c7b\uff0c20\u4e2a\u5c0f\u7c7b\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4ece2007\u5e74\u5f00\u59cb\uff0cPASCAL VOC\u6bcf\u5e74\u7684\u6570\u636e\u96c6\u90fd\u662f\u8fd9\u4e2a\u5c42\u7ea7\u7ed3\u6784 \u603b\u5171\u56db\u4e2a\u5927\u7c7b\uff1avehicle,household,animal,person \u603b\u517120\u4e2a\u5c0f\u7c7b\uff0c\u9884\u6d4b\u7684\u65f6\u5019\u662f\u53ea\u8f93\u51fa\u56fe\u4e2d\u9ed1\u8272\u7c97\u4f53\u7684\u7c7b\u522b \u7ec4\u7ec7\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a Annotations \u8fdb\u884c detection \u4efb\u52a1\u65f6\u7684\u6807\u7b7e\u6587\u4ef6\uff0cxml \u5f62\u5f0f\uff0c\u6587\u4ef6\u540d\u4e0e\u56fe\u7247\u540d\u4e00\u4e00\u5bf9\u5e94 ImageSets \u5305\u542b\u4e09\u4e2a\u5b50\u6587\u4ef6\u5939 Layout\u3001Main\u3001Segmentation\uff0c\u5176\u4e2d Main \u5b58\u653e\u7684\u662f\u5206\u7c7b\u548c\u68c0\u6d4b\u7684\u6570\u636e\u96c6\u5206\u5272\u6587\u4ef6 JPEGImages \u5b58\u653e .jpg \u683c\u5f0f\u7684\u56fe\u7247\u6587\u4ef6 SegmentationClass \u5b58\u653e\u6309\u7167 class \u5206\u5272\u7684\u56fe\u7247 SegmentationObject \u5b58\u653e\u6309\u7167 object \u5206\u5272\u7684\u56fe\u7247 \u6211\u4eec\u4f7f\u7528\u7684\u5c31\u662fAnnotations\u548cJPEGImages\u4e24\u90e8\u5206\u5185\u5bb9\uff0c\u53e6\u5916\u6211\u4eec\u901a\u8fc7Main\u6587\u4ef6\u5939\u4e0b\u7684\u6587\u672c\u6587\u4ef6\u83b7\u53d6\u5bf9\u5e94\u7684\u8bad\u7ec3\u96c6\u53ca\u9a8c\u8bc1\u96c6\u6570\u636e\uff0c\u5185\u5bb9\u5982\u4e0b\u6240\u793a\uff1a train.txt \u5199\u7740\u7528\u4e8e\u8bad\u7ec3\u7684\u56fe\u7247\u540d\u79f0\uff0c \u5171 2501 \u4e2a val.txt \u5199\u7740\u7528\u4e8e\u9a8c\u8bc1\u7684\u56fe\u7247\u540d\u79f0\uff0c\u5171 2510 \u4e2a trainval.txt train\u4e0eval\u7684\u5408\u96c6\u3002\u5171 5011 \u4e2a","title":"1.1 \u6570\u636e\u60c5\u51b5"},{"location":"objectdection/03.RCNN-demo/#12","text":"\u6570\u636e\u96c6\u7684\u6807\u6ce8\u6709\u4e13\u95e8\u7684\u6807\u6ce8\u56e2\u961f\uff0c\u5e76\u9075\u4ece\u7edf\u4e00\u7684\u6807\u6ce8\u6807\u51c6\uff0c\u6807\u6ce8\u4fe1\u606f\u662f\u7528 xml \u6587\u4ef6\u7ec4\u7ec7\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6807\u6ce8\u4fe1\u606f\u5982\u4e0b\u6240\u793a\uff1a <annotation> <!--\u6570\u636e\u96c6\u7248\u672c\u4f4d\u7f6e--> <folder> VOC2007 </folder> <!--\u6587\u4ef6\u540d--> <filename> 000001.jpg </filename> <!--\u6587\u4ef6\u6765\u6e90--> <source> <database> The VOC2007 Database </database> <annotation> PASCAL VOC2007 </annotation> <image> flickr </image> <flickrid> 341012865 </flickrid> </source> <!--\u62e5\u6709\u8005--> <owner> <flickrid> Fried Camels </flickrid> <name> Jinky the Fruit Bat </name> </owner> <!--\u56fe\u7247\u5927\u5c0f--> <size> <width> 353 </width> <height> 500 </height> <depth> 3 </depth> </size> <!--\u662f\u5426\u5206\u5272--> <segmented> 0 </segmented> <!--\u4e00\u4e2a\u76ee\u6807\uff0c\u91cc\u9762\u7684\u5185\u5bb9\u662f\u76ee\u6807\u7684\u76f8\u5173\u4fe1\u606f--> <object> <!--object\u540d\u79f0\uff0c20\u4e2a\u7c7b\u522b--> <name> dog </name> <!--\u62cd\u6444\u89d2\u5ea6\uff1afront, rear, left, right\u3002\u3002--> <pose> Left </pose> <!--\u76ee\u6807\u662f\u5426\u88ab\u622a\u65ad\uff0c\u6216\u8005\u88ab\u906e\u6321\uff08\u8d85\u8fc715%\uff09--> <truncated> 1 </truncated> <!--\u68c0\u6d4b\u96be\u6613\u7a0b\u5ea6--> <difficult> 0 </difficult> <!--bounding box \u7684\u5de6\u4e0a\u89d2\u70b9\u548c\u53f3\u4e0b\u89d2\u70b9\u7684\u5750\u6807\u503c--> <bndbox> <xmin> 48 </xmin> <ymin> 240 </ymin> <xmax> 195 </xmax> <ymax> 371 </ymax> </bndbox> </object> <!--\u4e00\u4e2a\u76ee\u6807\uff0c\u91cc\u9762\u7684\u5185\u5bb9\u662f\u76ee\u6807\u7684\u76f8\u5173\u4fe1\u606f--> <object> <name> person </name> <pose> Left </pose> <!--\u76ee\u6807\u662f\u5426\u88ab\u622a\u65ad\uff0c\u6216\u8005\u88ab\u906e\u6321\uff08\u8d85\u8fc715%\uff09--> <truncated> 1 </truncated> <difficult> 0 </difficult> <bndbox> <xmin> 8 </xmin> <ymin> 12 </ymin> <xmax> 352 </xmax> <ymax> 498 </ymax> </bndbox> </object> </annotation>","title":"1.2 \u6807\u6ce8\u4fe1\u606f"},{"location":"objectdection/03.RCNN-demo/#2","text":"\u8be5\u6570\u636e\u96c6\u7684\u89e3\u6790\u5728fasterRCNN/detection/datasets/pascal_voc.py\u4e2d: \u63a5\u4e0b\u6765\u6211\u4eec\u5206\u6790\u6574\u4e2a\u7684\u5b9e\u73b0\u8fc7\u7a0b\uff1a","title":"2 \u6570\u636e\u96c6\u89e3\u6790"},{"location":"objectdection/03.RCNN-demo/#21","text":"\u6839\u636e\u6307\u5b9a\u7684\u6570\u636e\u96c6\uff0c\u83b7\u53d6\u5bf9\u5e94\u7684\u6587\u4ef6\u4fe1\u606f\uff0c\u8fdb\u884c\u5904\u7406,\u5176\u4e2dmain\u4e2dtxt\u4e2d\u7684\u5185\u5bb9\u5982\u4e0b\u6240\u793a: \u56e0\u6b64\u6211\u4eec\u6839\u636etxt\u4e2d\u7684\u5185\u5bb9\u52a0\u8f7d\u5bf9\u5e94\u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1\u96c6: def load_labels ( self ): # \u6839\u636e\u6807\u7b7e\u4fe1\u606f\u52a0\u8f7d\u76f8\u5e94\u7684\u6570\u636e if self . phase == 'train' : txtname = os . path . join ( self . data_path , 'ImageSets' , 'Main' , 'trainval.txt' ) else : txtname = os . path . join ( self . data_path , 'ImageSets' , 'Main' , 'val.txt' ) # \u83b7\u53d6\u56fe\u50cf\u7684\u7d22\u5f15 with open ( txtname , 'r' ) as f : self . image_index = [ x . strip () for x in f . readlines ()] self . num_image = len ( self . image_index ) # \u56fe\u50cf\u5bf9\u5e94\u7684\u7d22\u5f15\u653e\u5230\u5217\u8868gt_labels\u4e2d gt_labels = [] # \u904d\u5386\u6bcf\u4e00\u4efd\u56fe\u50cf\u83b7\u53d6\u6807\u6ce8\u4fe1\u606f for index in self . image_index : # \u83b7\u53d6\u6807\u6ce8\u4fe1\u606f\uff0c\u5305\u62ecobjet box\u5750\u6807\u4fe1\u606f \u4ee5\u53ca\u7c7b\u522b\u4fe1\u606f gt_label = self . load_pascal_annotation ( index ) # \u6dfb\u52a0\u5230\u5217\u8868\u4e2d gt_labels . append ( gt_label ) # \u5c06\u6807\u6ce8\u4fe1\u606f\u8d4b\u503c\u7ed9\u5c5e\u6027\uff1aself.gt_labels self . gt_labels = gt_labels","title":"2.1 \u6307\u5b9a\u6570\u636e\u96c6"},{"location":"objectdection/03.RCNN-demo/#22","text":"\u5229\u7528OpenCV\u8bfb\u53d6\u56fe\u50cf\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u901a\u9053\u7684\u8f6c\u6362\uff1a def image_read ( self , imname ): # opencv \u4e2d\u9ed8\u8ba4\u56fe\u7247\u8272\u5f69\u683c\u5f0f\u4e3aBGR image = cv2 . imread ( imname ) # \u5c06\u56fe\u7247\u8f6c\u6210RGB\u683c\u5f0f image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) . astype ( np . float32 ) return image","title":"2.2\u56fe\u50cf\u8bfb\u53d6"},{"location":"objectdection/03.RCNN-demo/#23","text":"\u6807\u6ce8\u4fe1\u606f\u7684\u8bfb\u53d6\u4e3b\u8981\u662f\u6839\u636e\u56fe\u50cf\u7684\u6587\u4ef6\u540d\u83b7\u53d6\u7d22\u5f15\u540e\uff0c\u627e\u5230\u5bf9\u5e94\u7684XML\u6587\u4ef6\uff0c\u8bfb\u53d6\u5176\u4e2d\u7684\u5185\u5bb9\uff0c\u5f97\u5230\u56fe\u50cf\u7684\u6807\u6ce8\u4fe1\u606f\u3002 def load_pascal_annotation ( self , index ): \"\"\" \u5728PASCAL VOC\u7684XML\u6587\u4ef6\u83b7\u53d6\u8fb9\u6846\u4fe1\u606f\u548c\u7c7b\u522b\u4fe1\u606f \"\"\" # \u83b7\u53d6XML\u6587\u4ef6\u7684\u5730\u5740 filename = os . path . join ( self . data_path , 'Annotations' , index + '.xml' ) # \u5c06XML\u4e2d\u7684\u5185\u5bb9\u83b7\u53d6\u51fa\u6765 tree = ET . parse ( filename ) # \u83b7\u53d6\u8282\u70b9\u56fe\u50cf\u7684size image_size = tree . find ( 'size' ) # \u5c06\u56fe\u50cf\u7684size\u4fe1\u606f\u5b58\u653e\u5230sizeinfo\u4e2d size_info = np . zeros (( 2 ,), dtype = np . float32 ) # \u5bbd size_info [ 0 ] = float ( image_size . find ( 'width' ) . text ) # \u9ad8 size_info [ 1 ] = float ( image_size . find ( 'height' ) . text ) # \u627e\u5230\u6240\u6709\u7684object\u8282\u70b9 objs = tree . findall ( 'object' ) # object\u7684\u6570\u91cf num_objs = len ( objs ) # boxes \u5750\u6807 (num_objs,4) boxes = np . zeros (( num_objs , 4 ), dtype = np . float32 ) # class \u7684\u6570\u91cfnum_objs\u4e2a\uff0c\u6bcf\u4e2a\u76ee\u6807\u4e00\u4e2a\u7c7b\u522b gt_classes = np . zeros (( num_objs ), dtype = np . int32 ) # \u904d\u5386\u6240\u6709\u7684\u76ee\u6807 for ix , obj in enumerate ( objs ): # \u627e\u5230bndbox\u8282\u70b9 bbox = obj . find ( 'bndbox' ) # \u83b7\u53d6\u5750\u6807\u6846\u7684\u4f4d\u7f6e\u4fe1\u606f x1 = float ( bbox . find ( 'xmin' ) . text ) - 1 y1 = float ( bbox . find ( 'ymin' ) . text ) - 1 x2 = float ( bbox . find ( 'xmax' ) . text ) - 1 y2 = float ( bbox . find ( 'ymax' ) . text ) - 1 # \u5c06\u4f4d\u7f6e\u4fe1\u606f\u5b58\u50a8\u5728bbox\u4e2d\uff0c\u6ce8\u610fboxes\u662f\u4e00\u4e2anp\u7c7b\u7684\u77e9\u9635 \u5927\u5c0f\u4e3a[num_objs,4] boxes [ ix , :] = [ y1 , x1 , y2 , x2 ] # \u627e\u5230class\u5bf9\u5e94\u7684\u7c7b\u522b\u4fe1\u606f cls = self . class_to_ind [ obj . find ( 'name' ) . text . lower () . strip ()] # \u5c06class\u4fe1\u606f\u5b58\u5165gt_classses\u4e2d\uff0c\u6ce8\u610fgt_classes\u4e5f\u662f\u4e00\u4e2anp\u7c7b\u7684\u77e9\u9635 \u5927\u5c0f\u4e3a[num_objs] \u662fint\u503c \u5bf9\u5e94\u4e8ename gt_classes [ ix ] = cls # \u83b7\u53d6\u56fe\u50cf\u7684\u5b58\u50a8\u8def\u5f84 imname = os . path . join ( self . data_path , 'JPEGImages' , index + '.jpg' ) # \u8fd4\u56de\u7ed3\u679c return { 'boxes' : boxes , 'gt_classs' : gt_classes , 'imname' : imname , 'image_size' : size_info , 'image_index' : index }","title":"2.3 \u6807\u51c6\u4fe1\u606f\u7684\u8bfb\u53d6"},{"location":"objectdection/03.RCNN-demo/#24","text":"\u5728\u5c06\u56fe\u50cf\u9001\u5165\u5230\u7f51\u7edc\u4e2d\u65f6\uff0c\u6211\u4eec\u9700\u8981\u5c06\u5176\u8fdb\u884c\u5927\u5c0f\u7684\u8c03\u6574\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u4e3a\u4e86\u4fdd\u8bc1\u957f\u5bbd\u6bd4\uff0c\u4f7f\u6700\u957f\u8fb9resize\u4e3a1024\uff0c\u77ed\u8fb9\u8fdb\u884cpad: def prep_im_for_blob ( self , im , pixel_means , target_size , max_size ): \"\u5bf9\u8f93\u5165\u7684\u56fe\u50cf\u8fdb\u884c\u5904\u7406\" im = im . astype ( np . float32 , copy = False ) # \u51cf\u53bb\u5747\u503c im -= pixel_means # \u56fe\u50cf\u7684\u5927\u5c0f im_shape = im . shape # \u6700\u77ed\u8fb9 im_size_min = np . min ( im_shape [ 0 : 2 ]) # \u6700\u957f\u8fb9 im_size_max = np . max ( im_shape [ 0 : 2 ]) # \u77ed\u8fb9\u53d8\u6362\u5230800\u7684\u6bd4\u4f8b im_scale = float ( target_size ) / float ( im_size_min ) # 600/\u6700\u77ed\u8fb9 # \u82e5\u957f\u8fb9\u4ee5\u4e0a\u8ff0\u6bd4\u4f8b\u53d8\u6362\u540e\u5927\u4e8e1024\uff0c\u5219\u4fee\u6b63\u53d8\u6362\u6bd4\u4f8b if np . round ( im_scale * im_size_max ) > max_size : im_scale = float ( max_size ) / float ( im_size_max ) # \u6839\u636e\u53d8\u6362\u6bd4\u4f8b\u5bf9\u56fe\u50cf\u8fdb\u884cresize im = cv2 . resize ( im , None , None , fx = im_scale , fy = im_scale , interpolation = cv2 . INTER_LINEAR ) shape = ( 1024 , 1024 , im . shape [ - 1 ]) pad = np . zeros ( shape , dtype = im . dtype ) pad [: im . shape [ 0 ], : im . shape [ 1 ], ... ] = im # \u8fd4\u56deim \u548c im_scale return pad , im_scale , im . shape","title":"2.4 \u56fe\u50cf\u7684\u5927\u5c0f\u5904\u7406"},{"location":"objectdection/03.RCNN-demo/#25","text":"\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528tf.keras.utils.Sequence\u6765\u5b8c\u6210\u6570\u636e\u7684\u8bfb\u53d6\uff0c\u7ee7\u627fSequence\u7c7b\u5fc5\u987b\u91cd\u8f7d\u4e09\u4e2a\u79c1\u6709\u65b9\u6cd5__init__\u3001 len__\u548c__getitem \uff0c\u4e3b\u8981\u662f__getitem__\u3002 \u0015__init__\u662f\u6784\u9020\u65b9\u6cd5\uff0c\u7528\u4e8e\u521d\u59cb\u5316\u6570\u636e\u7684\u3002 __len__\u7528\u4e8e\u8ba1\u7b97\u6837\u672c\u6570\u636e\u957f\u5ea6\u3002 __getitem__\u7528\u4e8e\u751f\u6210\u6574\u4e2abatch\u7684\u6570\u636e\uff0c\u9001\u5165\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5176\u8f93\u51fa\u683c\u5f0f\u662f\u5143\u7ec4\u3002__getitem__\u76f8\u5f53\u4e8e\u751f\u6210\u5668\u7684\u4f5c\u7528\u3002 Sequence \u662f\u8fdb\u884c\u591a\u5904\u7406\u7684\u66f4\u5b89\u5168\u65b9\u6cd5\u3002\u8fd9\u79cd\u7ed3\u6784\u4fdd\u8bc1\u4e86\u7f51\u7edc\u5728\u6bcf\u4e2a\u65f6\u95f4\u6bb5\u7684\u6bcf\u4e2a\u6837\u672c\u4e0a\u53ea\u4f1a\u8bad\u7ec3\u4e00\u6b21\u3002 \u4f8b\u5982\uff1a class CIFAR10Sequence ( Sequence ): # \u5b9a\u4e49\u4e00\u4e2a\u7c7b\u7ee7\u627f\u81eaSequence # _init_\u65b9\u6cd5\u8fdb\u884c\u521d\u59cb\u5316\u6570\u636e\uff0c\u6307\u5b9a\u76f8\u5e94\u7684\u5c5e\u6027\u5373\u53ef def __init__ ( self , x_set , y_set , batch_size ): # \u6570\u636e\u96c6 self . x , self . y = x_set , y_set # batch\u7684\u5927\u5c0f self . batch_size = batch_size # \u5b9a\u4e49\u4e00\u4e2aepoch\u4e2d\u7684\u8fed\u4ee3\u6b21\u6570 def __len__ ( self ): return math . ceil ( len ( self . x ) / self . batch_size ) # \u83b7\u53d6\u4e00\u4e2a\u6279\u6b21\u6570\u636e def __getitem__ ( self , idx ): # \u83b7\u53d6\u4e00\u4e2a\u6279\u6b21\u7684\u7279\u5f81\u503c\u6570\u636e batch_x = self . x [ idx * self . batch_size :( idx + 1 ) * self . batch_size ] # \u83b7\u53d6\u4e00\u4e2a\u6279\u6b21\u7684\u76ee\u6807\u503c\u6570\u636e batch_y = self . y [ idx * self . batch_size :( idx + 1 ) * self . batch_size ] # \u8fd4\u56de\u7ed3\u679c return np . array ([ resize ( imread ( file_name )) for file_name in batch_x ]), np . array ( batch_y ) \u90a3\u5728VOC\u6570\u636e\u96c6\u7684\u8bfb\u53d6\u4e2d\u6211\u4eec\u4e5f\u7c7b\u4f3c\u7684\u8fdb\u884c\u5904\u7406\uff1a class pascal_voc ( keras . utils . Sequence ): def __init__ ( self , phase ): # pascal_voc 2007\u6570\u636e\u7684\u5b58\u50a8\u8def\u5f84 self . data_path = os . path . join ( '../VOCdevkit' , 'VOC2007' ) # batch_size self . batch_size = 1 # \u56fe\u7247\u7684\u6700\u5c0f\u5c3a\u5bf8 self . target_size = 800 # \u56fe\u7247\u7684\u6700\u5927\u5c3a\u5bf8 self . max_size = 1024 # \u8f93\u5165\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf\u5c3a\u5bf8 self . scale = ( 1024 , 1024 ) # \u7c7b\u522b\u4fe1\u606f ['background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus'....] self . classes = [ 'background' , 'aeroplane' , 'bicycle' , 'bird' , 'boat' , 'bottle' , 'bus' , 'car' , 'cat' , 'chair' , 'cow' , 'diningtable' , 'dog' , 'horse' , 'motorbike' , 'person' , 'pottedplant' , 'sheep' , 'sofa' , 'train' , 'tvmonitor' ] # \u6784\u5efa\u76ee\u6807\u7c7b\u522b\u7684\u5b57\u5178{'background': 0, 'aeroplane': 1, \"bicycle\": 2....} self . class_to_ind = dict ( zip ( self . classes , range ( len ( self . classes )))) # \u50cf\u7d20RGB\u7684\u5747\u503c self . pixel_means = np . array ([[[ 122.7717 , 115.9465 , 102.9801 ]]]) # \u7528\u6765\u6307\u660e\u83b7\u53d6\u8bad\u7ec3\u96c6\u6216\u8005\u662f\u9a8c\u8bc1\u96c6\u6570\u636e self . phase = phase # \u83b7\u53d6\u56fe\u50cf\u6570\u91cf\uff0c\u5e76\u52a0\u8f7d\u76f8\u5e94\u7684\u6807\u7b7e self . load_labels () # \u76ee\u6807\u603b\u6570\u91cf self . num_gtlabels = len ( self . gt_labels ) self . img_transform = transforms . ImageTransform ( self . scale , self . pixel_means , [ 1. , 1. , 1. ], 'fixed' ) self . bbox_transform = transforms . BboxTransform () self . flip_ratio = 0.5 def __len__ ( self ): # \u8fd4\u56de\u8fed\u4ee3\u6b21\u6570 return np . round ( self . num_image / self . batch_size ) def __getitem__ ( self , idx ): # \u83b7\u53d6\u5f53\u524dbatch\u7684\u8d77\u59cb\u7d22\u5f15\u503c i = idx * self . batch_size batch_images = [] batch_imgmeta = [] batch_box = [] bacth_labels = [] for c in range ( self . batch_size ): # \u83b7\u53d6\u76f8\u5e94\u7684\u56fe\u50cf imname = self . gt_labels [ i + c ][ 'imname' ] # \u8bfb\u53d6\u56fe\u50cf image = self . image_read ( imname ) # \u83b7\u53d6\u539f\u59cb\u56fe\u50cf\u7684\u5c3a\u5bf8 ori_shape = image . shape # \u8fdb\u884c\u5c3a\u5ea6\u8c03\u6574\u540e\u7684\u56fe\u50cf\u53ca\u8c03\u6574\u7684\u5c3a\u5ea6 image , image_scale , image_shape = self . prep_im_for_blob ( image , self . pixel_means , self . target_size , self . max_size ) # \u83b7\u53d6\u5c3a\u5ea6\u53d8\u6362\u540e\u56fe\u50cf\u7684\u5c3a\u5bf8 pad_shape = image . shape # \u5c06gt_boxlabel\u4e0escale\u76f8\u4e58\u83b7\u53d6\u56fe\u50cf\u8c03\u6574\u540e\u7684\u6807\u6ce8\u6846\u7684\u5927\u5c0f\uff1aboxes.shape=[num_obj,4] bboxes = self . gt_labels [ i + c ][ 'boxes' ] * image_scale # \u83b7\u53d6\u5bf9\u5e94\u7684\u7c7b\u522b\u4fe1\u606f labels = self . gt_labels [ i + c ][ 'gt_classs' ] # print(labels) # \u56fe\u50cf\u7684\u57fa\u672c\u4fe1\u606f img_meta_dict = dict ({ 'ori_shape' : ori_shape , 'img_shape' : image_shape , 'pad_shape' : pad_shape , 'scale_factor' : image_scale }) # \u5c06\u5b57\u5178\u8f6c\u6362\u4e3a\u5217\u8868\u7684\u5f62\u5f0f image_meta = self . compose_image_meta ( img_meta_dict ) # print(image_meta) batch_images . append ( image ) bacth_labels . append ( labels ) batch_imgmeta . append ( image_meta ) batch_box . append ( bboxes ) # \u5c06\u56fe\u50cf\u8f6c\u6362\u6210tensorflow\u8f93\u5165\u7684\u5f62\u5f0f:\u3010batch_size,H,W,C\u3011 batch_images = np . reshape ( batch_images , ( self . batch_size , image . shape [ 0 ], image . shape [ 1 ], 3 )) # \u56fe\u50cf\u5143\u4fe1\u606f batch_imgmeta = np . reshape ( batch_imgmeta ,( self . batch_size , 11 )) # \u6807\u6ce8\u6846\u4fe1\u606f batch_box = np . reshape ( batch_box ,( self . batch_size , bboxes . shape [ 0 ], 4 )) # \u6807\u6ce8\u7c7b\u522b\u4fe1\u606f bacth_labels = np . reshape ( bacth_labels ,(( self . batch_size , labels . shape [ 0 ]))) # \u8fd4\u56de\u7ed3\u679c\uff1a\u5c3a\u5ea6\u53d8\u6362\u540e\u7684\u56fe\u50cf\uff0c\u56fe\u50cf\u5143\u4fe1\u606f\uff0c\u76ee\u6807\u6846\u4f4d\u7f6e\uff0c\u76ee\u6807\u7c7b\u522b return batch_images , batch_imgmeta , batch_box , bacth_labels","title":"2.5 \u6784\u5efa\u6570\u636e\u8bfb\u53d6\u7684\u7c7b"},{"location":"objectdection/03.RCNN-demo/#26","text":"\u6211\u4eec\u5229\u7528\u4e0a\u8ff0\u7684\u6570\u636e\u89e3\u6790\u65b9\u6cd5\u6765\u5bf9VOC\u6570\u636e\u96c6\u8fdb\u884c\u89e3\u6790\uff1a \u5bfc\u5165\u6240\u9700\u7684\u5de5\u5177\u5305 # \u5bfc\u5165\u6570\u636e\u96c6 VOC data from detection.datasets import pascal_voc from detection.datasets.utils import get_original_image import numpy as np # \u56fe\u50cf\u5c55\u793a from matplotlib import pyplot as plt \u83b7\u53d6\u56fe\u50cf\u5e76\u8bbe\u7f6e\u56fe\u50cf\u7684\u5747\u503c\u4e0e\u65b9\u5dee # \u5b9e\u4f8b\u5316 pascal = pascal_voc . pascal_voc ( 'train' ) # \u83b7\u53d6\u56fe\u50cf image , image_meta , bboxes , labels = pascal [ 8 ] # \u56fe\u50cf\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee img_mean = ( 122.7717 , 115.9465 , 102.9801 ) img_std = ( 1. , 1. , 1. ) \u539f\u56fe\u50cf\u5c55\u793a # \u83b7\u53d6\u539f\u56fe\u50cf ori_img = get_original_image ( image [ 0 ], image_meta [ 0 ], img_mean ) . astype ( np . uint8 ) # \u56fe\u50cf\u5c55\u793a plt . imshow ( ori_img ) plt . show () \u0015\u9001\u5165\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf\u8fdb\u884c\u4e86resize\u548cpasding # \u9001\u5165\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf rgb_img = np . round ( image + img_mean ) . astype ( np . uint8 ) plt . imshow ( rgb_img [ 0 ]) plt . show () \u5c06\u6807\u6ce8\u4fe1\u606f\u663e\u793a\u51fa\u6765 # \u663e\u793a\u56fe\u50cf\uff0c\u53ca\u5bf9\u5e94\u7684\u6807\u7b7e\u503c import visualize visualize . display_instances ( rgb_img [ 0 ], bboxes [ 0 ], labels [ 0 ], pascal . classes )","title":"2.6 \u6570\u636e\u89e3\u6790\u7c7b\u6f14\u793a"},{"location":"objectdection/03.RCNN-demo/#3","text":"\u63a5\u4e0b\u6765\u6211\u4eec\u5229\u7528\u5df2\u642d\u5efa\u597d\u7684\u7f51\u7edc\u548c\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\uff1a \u5b9a\u4e49tf.GradientTape\u7684\u4f5c\u7528\u57df\uff0c\u8ba1\u7b97\u635f\u5931\u503c \u4f7f\u7528 tape.gradient(ys, xs) \u81ea\u52a8\u8ba1\u7b97\u68af\u5ea6 \u4f7f\u7528 optimizer.apply_gradients(grads_and_vars) \u81ea\u52a8\u66f4\u65b0\u6a21\u578b\u53c2\u6570 \u5b8c\u6210\u7f51\u7edc\u7684\u8bad\u7ec3\u3002\u6211\u4eec\u6765\u770b\u4e0b\u5b9e\u73b0\u6d41\u7a0b\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 from detection.datasets import pascal_voc import tensorflow as tf import numpy as np from matplotlib import pyplot as plt from detection.models.detectors import faster_rcnn \u52a0\u8f7d\u6570\u636e\u83b7\u53d6\u6570\u636e\u7c7b\u522b # \u52a0\u8f7d\u6570\u636e\u96c6 train_dataset = pascal_voc . pascal_voc ( 'train' ) # \u6570\u636e\u7c7b\u522b num_classes = len ( train_dataset . classes ) \u6a21\u578b\u52a0\u8f7d model = faster_rcnn . FasterRCNN ( num_classes = num_classes ) \u5b9a\u4e49\u4f18\u5316\u5668 # \u4f18\u5316\u5668 optimizer = tf . keras . optimizers . SGD ( 1e-3 , momentum = 0.9 , nesterov = True ) \u6a21\u578b\u8bad\u7ec3 # \u6a21\u578b\u4f18\u5316 loss_his = [] for epoch in range ( 10 ): # \u83b7\u53d6\u6837\u672c\u7684index indices = np . arange ( train_dataset . num_gtlabels ) # \u6253\u4e71 np . random . shuffle ( indices ) # \u8fed\u4ee3\u6b21\u6570 iter = np . round ( train_dataset . num_gtlabels / train_dataset . batch_size ) . astype ( np . uint8 ) # \u6bcf\u4e00\u6b21\u8fed\u4ee3 for idx in range ( iter ): # \u83b7\u53d6\u67d0\u4e00\u4e2abacth idx = indices [ idx ] # \u83b7\u53d6\u5f53\u524dbatch\u7684\u7ed3\u679c batch_imgs , batch_metas , batch_bboxes , batch_labels = train_dataset [ idx ] # \u5b9a\u4e49\u4f5c\u7528\u57df with tf . GradientTape () as tape : # \u5c06\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\u8ba1\u7b97\u635f\u5931 rpn_class_loss , rpn_bbox_loss , rcnn_class_loss , rcnn_bbox_loss = \\ model (( batch_imgs , batch_metas , batch_bboxes , batch_labels ), training = True ) # \u6c42\u603b\u635f\u5931 loss = rpn_class_loss + rpn_bbox_loss + rcnn_class_loss + rcnn_bbox_loss # \u8ba1\u7b97\u68af\u5ea6\u503c grads = tape . gradient ( loss , model . trainable_variables ) # \u66f4\u65b0\u53c2\u6570\u503c optimizer . apply_gradients ( zip ( grads , model . trainable_variables )) # \u6253\u5370\u635f\u5931\u7ed3\u679c print ( \"epoch\uff1a %d , loss\uff1a %f \" % ( epoch + 1 , loss )) loss_his . append ( loss ) # \u6bcf\u4e00\u6b21\u8fed\u4ee3\u4e2d\u53ea\u8fd0\u884c\u4e00\u4e2a\u56fe\u50cf continue # \u6bcf\u4e00\u4e2aepoch\u4e2d\u53ea\u8fd0\u884c\u4e00\u6b21\u8fed\u4ee3 continue \u7ed3\u679c\u4e3a\uff1a epoch \uff1a 1 , loss \uff1a 147.117371 epoch \uff1a 2 , loss \uff1a 72.580498 epoch \uff1a 3 , loss \uff1a 79.347351 epoch \uff1a 4 , loss \uff1a 41.220577 epoch \uff1a 5 , loss \uff1a 5.238140 epoch \uff1a 6 , loss \uff1a 2.924250 epoch \uff1a 7 , loss \uff1a 5.287500 \u635f\u5931\u51fd\u6570\u7684\u53d8\u6362\u5982\u4e0b\u56fe\u6240\u793a\uff1a # \u7ed8\u5236\u635f\u5931\u51fd\u6570\u53d8\u5316\u7684\u66f2\u7ebf plt . plot ( range ( len ( loss_his )),[ loss . numpy () for loss in loss_his ]) plt . grid ()","title":"3.\u6a21\u578b\u8bad\u7ec3"},{"location":"objectdection/03.RCNN-demo/#4","text":"\u5728\u8fd9\u91cc\u6211\u4eec\u9996\u5148\u52a0\u8f7d\u6a21\u578b\uff0c\u6211\u4eec\u6765\u770b\u4e0bRPN\u7f51\u7edc\u548cfastRCNN\u7f51\u7edc\u7684\u8f93\u51fa\u3002 \u5bfc\u5165\u5de5\u5177\u5305 # \u5bfc\u5165\u6570\u636e\u96c6 VOC data from detection.datasets import pascal_voc import numpy as np # \u56fe\u50cf\u5c55\u793a from matplotlib import pyplot as plt # \u663e\u793a\u56fe\u50cf\uff0c\u53ca\u5bf9\u5e94\u7684\u6807\u7b7e\u503c import visualize # \u6a21\u578b\u52a0\u8f7d from detection.models.detectors import faster_rcnn import tensorflow as tf from detection.core.bbox import transforms from detection.datasets.utils import get_original_image","title":"4.\u6a21\u578b\u6d4b\u8bd5"},{"location":"objectdection/03.RCNN-demo/#41","text":"\u9996\u5148\u52a0\u8f7d\u8981\u8fdb\u884c\u9884\u6d4b\u7684\u6570\u636e\u548c\u8bad\u7ec3\u597d\u7684\u6a21\u578b: \u6570\u636e\u96c6\u52a0\u8f7d # \u6570\u636e\u96c6\u52a0\u8f7d # \u5b9e\u4f8b\u5316 pascal = pascal_voc . pascal_voc ( 'train' ) # \u83b7\u53d6\u56fe\u50cf image , image_meta , bboxes , labels = pascal [ 8 ] # \u56fe\u50cf\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee img_mean = ( 122.7717 , 115.9465 , 102.9801 ) img_std = ( 1. , 1. , 1. ) # \u83b7\u53d6\u56fe\u50cf\uff0c\u663e\u793a rgb_img = np . round ( image + img_mean ) . astype ( np . uint8 ) plt . imshow ( rgb_img [ 0 ]) plt . show () \u6a21\u578b\u52a0\u8f7d # \u52a0\u8f7d\u6a21\u578b\uff1a\u6a21\u578b\u8bad\u7ec3\u662f\u5728COCO\u6570\u636e\u96c6\u4e2d\u8fdb\u884c\u7684\uff0c # coco\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f classes = [ 'bg' , 'person' , 'bicycle' , 'car' , 'motorcycle' , 'airplane' , 'bus' , 'train' , 'truck' , 'boat' , 'traffic light' , 'fire hydrant' , 'stop sign' , 'parking meter' , 'bench' , 'bird' , 'cat' , 'dog' , 'horse' , 'sheep' , 'cow' , 'elephant' , 'bear' , 'zebra' , 'giraffe' , 'backpack' , 'umbrella' , 'handbag' , 'tie' , 'suitcase' , 'frisbee' , 'skis' , 'snowboard' , 'sports ball' , 'kite' , 'baseball bat' , 'baseball glove' , 'skateboard' , 'surfboard' , 'tennis racket' , 'bottle' , 'wine glass' , 'cup' , 'fork' , 'knife' , 'spoon' , 'bowl' , 'banana' , 'apple' , 'sandwich' , 'orange' , 'broccoli' , 'carrot' , 'hot dog' , 'pizza' , 'donut' , 'cake' , 'chair' , 'couch' , 'potted plant' , 'bed' , 'dining table' , 'toilet' , 'tv' , 'laptop' , 'mouse' , 'remote' , 'keyboard' , 'cell phone' , 'microwave' , 'oven' , 'toaster' , 'sink' , 'refrigerator' , 'book' , 'clock' , 'vase' , 'scissors' , 'teddy bear' , 'hair drier' , 'toothbrush' ] # \u6a21\u578b\u52a0\u8f7d model = faster_rcnn . FasterRCNN ( num_classes = len ( classes )) # \u5c06\u6570\u636e\u9001\u5165\u5230\u7f51\u7edc\u4e2d _ = model (( image , image_meta , bboxes , labels ), training = True ) # \u52a0\u8f7d\u5df2\u8bad\u7ec3\u597d\u7684\u6743\u91cd model . load_weights ( 'weights/faster_rcnn.h5' ) \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u6765\u770b\u4e0bRPN\u7f51\u7edc\u548cfastRCNN\u7684\u8f93\u51fa\u3002","title":"4.1 \u6570\u636e\u548c\u6a21\u578b\u52a0\u8f7d"},{"location":"objectdection/03.RCNN-demo/#42-rpn","text":"","title":"4.2 RPN\u7f51\u7edc"},{"location":"objectdection/03.RCNN-demo/#421-rpn","text":"\u83b7\u53d6\u56fe\u50cf\u7684anchor,\u5e76\u5339\u914d\u76ee\u6807\u503c # \u6839\u636e\u56fe\u50cf\u4fe1\u606f\u4ea7\u751fanchor anchors , valid_flags = model . rpn_head . generator . generate_pyramid_anchors ( image_meta ) # \u5e76\u8bbe\u7f6eanchor\u5bf9\u5e94\u7684\u76ee\u6807\u503c rpn_target_matchs , rpn_target_deltas = model . rpn_head . anchor_target . build_targets ( anchors , valid_flags , bboxes , labels ) \u83b7\u53d6\u6b63\u8d1f\u6837\u672c\uff0c\u53ca\u6b63\u6837\u672c\u7684\u56de\u5f52\u503c # \u83b7\u53d6\u6b63\u6837\u672c positive_anchors = tf . gather ( anchors , tf . where ( tf . equal ( rpn_target_matchs , 1 ))[:, 1 ]) # \u83b7\u53d6\u8d1f\u6837\u672c negative_anchors = tf . gather ( anchors , tf . where ( tf . equal ( rpn_target_matchs , - 1 ))[:, 1 ]) # \u83b7\u53d6\u975e\u6b63\u975e\u8d1f\u6837\u672c neutral_anchors = tf . gather ( anchors , tf . where ( tf . equal ( rpn_target_matchs , 0 ))[:, 1 ]) # \u83b7\u53d6\u6b63\u6837\u672c\u7684\u56de\u5f52\u503c positive_target_deltas = rpn_target_deltas [ 0 , : tf . where ( tf . equal ( rpn_target_matchs , 1 )) . shape [ 0 ]] # \u83b7\u53d6anchor\u4fee\u6b63\u7684\u76ee\u6807\u503c refined_anchors = transforms . delta2bbox ( positive_anchors , positive_target_deltas , ( 0. , 0. , 0. , 0. ), ( 0.1 , 0.1 , 0.2 , 0.2 )) \u6b63\u8d1f\u6837\u672c\u7684\u7ed3\u679c # \u6b63\u8d1f\u6837\u672c\u7684\u4e2a\u6570 print ( 'rpn_target_matchs: \\t ' , rpn_target_matchs [ 0 ] . shape . as_list ()) print ( 'rpn_target_deltas: \\t ' , rpn_target_deltas [ 0 ] . shape . as_list ()) print ( 'positive_anchors: \\t ' , positive_anchors . shape . as_list ()) print ( 'negative_anchors: \\t ' , negative_anchors . shape . as_list ()) print ( 'neutral_anchors: \\t ' , neutral_anchors . shape . as_list ()) print ( 'refined_anchors: \\t ' , refined_anchors . shape . as_list () rpn_target_matchs : [ 261888 ] rpn_target_deltas : [ 256 , 4 ] positive_anchors : [ 4 , 4 ] negative_anchors : [ 252 , 4 ] neutral_anchors : [ 261632 , 4 ] refined_anchors : [ 4 , 4 ] \u5c06\u6b63\u6837\u672c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a # \u5c06\u6b63\u6837\u672c\u7684anchor\u663e\u793a\u5728\u56fe\u50cf\u4e0a visualize . draw_boxes ( rgb_img [ 0 ], boxes = positive_anchors . numpy (), refined_boxes = refined_anchors . numpy ()) plt . show ()","title":"4.2.1 RPN\u7684\u76ee\u6807\u503c"},{"location":"objectdection/03.RCNN-demo/#422-rpn","text":"\u5c06\u56fe\u50cf\u9001\u5165\u7f51\u7edc\u4e2d\u83b7\u53d6\u9884\u6d4b\u7ed3\u679c # \u4e0d\u53ef\u8bad\u7ec3 training = False # \u83b7\u53d6backbone\u63d0\u53d6\u7684\u7279\u5f81\u7ed3\u679c C2 , C3 , C4 , C5 = model . backbone ( image , training = training ) # \u83b7\u53d6fcn\u7684\u7279\u5f81\u7ed3\u679c P2 , P3 , P4 , P5 , P6 = model . neck ([ C2 , C3 , C4 , C5 ], training = training ) \u83b7\u53d6\u9001\u5165\u5230RPN\u7f51\u7edc\u4e2d\u7684\u7279\u5f81\u56fe\uff0c\u5e76\u9001\u5165RPN\u7f51\u7edc\u4e2d # \u83b7\u53d6\u7279\u5f81\u56fe rpn_feature_maps = [ P2 , P3 , P4 , P5 , P6 ] # \u83b7\u53d6RPN\u7684\u9884\u6d4b\u7ed3\u679c:\u5206\u7c7b\u548c\u56de\u5f52\u7ed3\u679c rpn_class_logits , rpn_probs , rpn_deltas = model . rpn_head ( rpn_feature_maps , training = training ) \u5c06\u7f6e\u4fe1\u5ea6\u8f83\u9ad8\u7684anchor\u663e\u793a\u5728\u56fe\u50cf\u4e0a # [batch_size, num_anchors, (bg prob, fg prob)] rpn\u7684\u5206\u7c7b\u7ed3\u679c\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u53bb\u7b2c\u4e00\u4e2abatch,\u6240\u6709anchor\u524d\u666f\u7684\u6982\u7387 rpn_probs_tmp = rpn_probs [ 0 , :, 1 ] # \u5c06\u7f6e\u4fe1\u5ea6top100\u7684\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a limit = 100 ix = tf . nn . top_k ( rpn_probs_tmp , k = limit ) . indices [:: - 1 ] # \u7ed8\u5236\u5728\u56fe\u50cf\u4e0a visualize . draw_boxes ( rgb_img [ 0 ], boxes = tf . gather ( anchors , ix ) . numpy ()) \u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a","title":"4.2.2 RPN\u7684\u9884\u6d4b\u7ed3\u679c"},{"location":"objectdection/03.RCNN-demo/#43-fastrcnn","text":"\u5c06RPN\u7684\u7ed3\u679c\u9001\u5165\u5230\u540e\u7eed\u7f51\u7edc\u4e2d\uff0c\u8fdb\u884c\u68c0\u6d4b\uff1a \u0015\u83b7\u53d6\u5019\u9009\u533a\u57df # \u5019\u9009\u533a\u57df proposals_list = model . rpn_head . get_proposals ( rpn_probs , rpn_deltas , image_meta ) \u8fdb\u884cROIPooling rois_list = proposals_list # roipooling pooled_regions_list = model . roi_align ( ( rois_list , rcnn_feature_maps , image_meta ), training = training ) \u9884\u6d4b # \u8fdb\u884c\u9884\u6d4b rcnn_class_logits_list , rcnn_probs_list , rcnn_deltas_list = \\ model . bbox_head ( pooled_regions_list , training = training ) \u83b7\u53d6\u9884\u6d4b\u7ed3\u679c # \u83b7\u53d6\u9884\u6d4b\u7ed3\u679c detections_list = model . bbox_head . get_bboxes ( rcnn_probs_list , rcnn_deltas_list , rois_list , image_meta ) \u83b7\u53d6\u9884\u6d4b\u7ed3\u679c\u7684\u5750\u6807\uff0c\u5e76\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a # \u83b7\u5f97\u5750\u6807\u503c tmp = detections_list [ 0 ][:, : 4 ] # \u5c06\u68c0\u6d4b\u68c0\u6d4b\u7684\u6846\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a visualize . draw_boxes ( rgb_img [ 0 ], boxes = tmp . numpy ())","title":"4.3 fastRCNN\u7f51\u7edc"},{"location":"objectdection/03.RCNN-demo/#44","text":"\u4e0a\u8ff0\u6211\u4eec\u662f\u5206\u6b65\u8fdb\u884c\u9884\u6d4b\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u76f4\u63a5\u5728\u539f\u56fe\u50cf\u4e0a\u8fdb\u884c\u9884\u6d4b\uff1a # \u83b7\u53d6\u539f\u56fe\u50cf ori_img = get_original_image ( image [ 0 ], image_meta [ 0 ], img_mean ) # \u83b7\u53d6\u5019\u9009\u533a\u57df proposals = model . simple_test_rpn ( image [ 0 ], image_meta [ 0 ]) # \u68c0\u6d4b\u7ed3\u679c res = model . simple_test_bboxes ( image [ 0 ], image_meta [ 0 ], proposals ) # \u5c06\u68c0\u6d4b\u7ed3\u679c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a visualize . display_instances ( ori_img , res [ 'rois' ], res [ 'class_ids' ], classes , scores = res [ 'scores' ]) \u6700\u7ec8\u7684\u68c0\u6d4b\u7ed3\u679c\u4e3a\uff1a \u603b\u7ed3 \u4e86\u89e3VOC\u6570\u636e\u96c6\u7684\u5e94\u7528\u7406\u89e3 Pascal VOC\u6570\u636e\u96c6\u4f5c\u4e3a\u57fa\u51c6\u6570\u636e\uff0c\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u5e38\u88ab\u4f7f\u7528\u5230 fasterRCNN\u6a21\u578b\u7684\u6784\u6210 \u4e3b\u8981\u6709RPN\u7f51\u7edc\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u7684\u751f\u6210\uff0c\u7136\u540e\u4f7f\u7528fastRCNN\u7f51\u7edc\u8fdb\u884c\u9884\u6d4b \u80fd\u591f\u5229\u7528fasterRCNN\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b","title":"4.4 \u76ee\u6807\u68c0\u6d4b"},{"location":"objectdection/04.yolo/","text":"4.4.yolo\u7cfb\u5217 \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053yolo\u7f51\u7edc\u67b6\u6784\uff0c\u7406\u89e3\u5176\u8f93\u5165\u8f93\u51fa \u77e5\u9053yolo\u6a21\u578b\u7684\u8bad\u7ec3\u6837\u672c\u6784\u5efa\u7684\u65b9\u6cd5 \u7406\u89e3yolo\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570 \u77e5\u9053yoloV2\u6a21\u578b\u7684\u6539\u8fdb\u65b9\u6cd5 \u77e5\u9053yoloV3\u7684\u591a\u5c3a\u5ea6\u68c0\u6d4b\u65b9\u6cd5 \u77e5\u9053yoloV3\u6a21\u578b\u7684\u7f51\u7edc\u7ed3\u6784\u53ca\u7f51\u7edc\u8f93\u51fa \u4e86\u89e3yoloV3\u6a21\u578b\u5148\u9a8c\u6846\u8bbe\u8ba1\u7684\u65b9\u6cd5 \u77e5\u9053yoloV3\u6a21\u578b\u4e3a\u4ec0\u4e48\u9002\u7528\u4e8e\u591a\u6807\u7b7e\u7684\u76ee\u6807\u5206\u7c7b \u4e86\u89e3yoloV4\u6a21\u578b YOLO\u7cfb\u5217\u7b97\u6cd5\u662f\u4e00\u7c7b\u5178\u578b\u7684one-stage\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\uff0c\u5176\u5229\u7528anchor box\u5c06\u5206\u7c7b\u4e0e\u76ee\u6807\u5b9a\u4f4d\u7684\u56de\u5f52\u95ee\u9898\u7ed3\u5408\u8d77\u6765\uff0c\u4ece\u800c\u505a\u5230\u4e86\u9ad8\u6548\u3001\u7075\u6d3b\u548c\u6cdb\u5316\u6027\u80fd\u597d\uff0c\u6240\u4ee5\u5728\u5de5\u4e1a\u754c\u4e5f\u5341\u5206\u53d7\u6b22\u8fce\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u4ecb\u7ecdYOLO \u7cfb\u5217\u7b97\u6cd5\u3002 1.yolo\u7b97\u6cd5 \u00b6 Yolo\u7b97\u6cd5\u91c7\u7528\u4e00\u4e2a\u5355\u72ec\u7684CNN\u6a21\u578b\u5b9e\u73b0end-to-end\u7684\u76ee\u6807\u68c0\u6d4b\uff0c\u6838\u5fc3\u601d\u60f3\u5c31\u662f\u5229\u7528\u6574\u5f20\u56fe\u4f5c\u4e3a\u7f51\u7edc\u7684\u8f93\u5165\uff0c\u76f4\u63a5\u5728\u8f93\u51fa\u5c42\u56de\u5f52 bounding box\uff08\u8fb9\u754c\u6846\uff09 \u7684\u4f4d\u7f6e\u53ca\u5176\u6240\u5c5e\u7684\u7c7b\u522b\uff0c\u6574\u4e2a\u7cfb\u7edf\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u9996\u5148\u5c06\u8f93\u5165\u56fe\u7247resize\u5230448x448\uff0c\u7136\u540e\u9001\u5165CNN\u7f51\u7edc\uff0c\u6700\u540e\u5904\u7406\u7f51\u7edc\u9884\u6d4b\u7ed3\u679c\u5f97\u5230\u68c0\u6d4b\u7684\u76ee\u6807\u3002\u76f8\u6bd4R-CNN\u7b97\u6cd5\uff0c\u5176\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u5176\u901f\u5ea6\u66f4\u5feb\u3002 1.1 Yolo\u7b97\u6cd5\u601d\u60f3 \u00b6 \u5728\u4ecb\u7ecdYolo\u7b97\u6cd5\u4e4b\u524d\uff0c\u6211\u4eec\u56de\u5fc6\u4e0bRCNN\u6a21\u578b\uff0cRCNN\u6a21\u578b\u63d0\u51fa\u4e86\u5019\u9009\u533a(Region Proposals)\u7684\u65b9\u6cd5\uff0c\u5148\u4ece\u56fe\u7247\u4e2d\u641c\u7d22\u51fa\u4e00\u4e9b\u53ef\u80fd\u5b58\u5728\u5bf9\u8c61\u7684\u5019\u9009\u533a\uff08Selective Search\uff09\uff0c\u5927\u69822000\u4e2a\u5de6\u53f3\uff0c\u7136\u540e\u5bf9\u6bcf\u4e2a\u5019\u9009\u533a\u8fdb\u884c\u5bf9\u8c61\u8bc6\u522b\uff0c\u4f46\u5904\u7406\u901f\u5ea6\u8f83\u6162\u3002 Yolo\u610f\u601d\u662fYou Only Look Once\uff0c\u5b83\u5e76\u6ca1\u6709\u771f\u6b63\u7684\u53bb\u6389\u5019\u9009\u533a\u57df\uff0c\u800c\u662f\u521b\u9020\u6027\u7684\u5c06\u5019\u9009\u533a\u548c\u76ee\u6807\u5206\u7c7b\u5408\u4e8c\u4e3a\u4e00\uff0c\u770b\u4e00\u773c\u56fe\u7247\u5c31\u80fd\u77e5\u9053\u6709\u54ea\u4e9b\u5bf9\u8c61\u4ee5\u53ca\u5b83\u4eec\u7684\u4f4d\u7f6e\u3002 Yolo\u6a21\u578b\u91c7\u7528\u9884\u5b9a\u4e49\u9884\u6d4b\u533a\u57df\u7684\u65b9\u6cd5\u6765\u5b8c\u6210\u76ee\u6807\u68c0\u6d4b\uff0c\u5177\u4f53\u800c\u8a00\u662f\u5c06\u539f\u59cb\u56fe\u50cf\u5212\u5206\u4e3a 7x7=49 \u4e2a\u7f51\u683c\uff08grid\uff09\uff0c\u6bcf\u4e2a\u7f51\u683c\u5141\u8bb8\u9884\u6d4b\u51fa2\u4e2a\u8fb9\u6846\uff08bounding box\uff0c\u5305\u542b\u67d0\u4e2a\u5bf9\u8c61\u7684\u77e9\u5f62\u6846\uff09\uff0c\u603b\u5171 49x2=98 \u4e2abounding box\u3002\u6211\u4eec\u5c06\u5176\u7406\u89e3\u4e3a98\u4e2a\u9884\u6d4b\u533a\uff0c\u5f88\u7c97\u7565\u7684\u8986\u76d6\u4e86\u56fe\u7247\u7684\u6574\u4e2a\u533a\u57df\uff0c\u5c31\u5728\u8fd998\u4e2a\u9884\u6d4b\u533a\u4e2d\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u3002 \u53ea\u8981\u5f97\u5230\u8fd998\u4e2a\u533a\u57df\u7684\u76ee\u6807\u5206\u7c7b\u548c\u56de\u5f52\u7ed3\u679c\uff0c\u518d\u8fdb\u884cNMS\u5c31\u53ef\u4ee5\u5f97\u5230\u6700\u7ec8\u7684\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c\u3002\u90a3\u5177\u4f53\u8981\u600e\u6837\u5b9e\u73b0\u5462\uff1f 1.2 Yolo\u7684\u7f51\u7edc\u7ed3\u6784 \u00b6 YOLO\u7684\u7ed3\u6784\u975e\u5e38\u7b80\u5355\uff0c\u5c31\u662f\u5355\u7eaf\u7684\u5377\u79ef\u3001\u6c60\u5316\u6700\u540e\u52a0\u4e86\u4e24\u5c42\u5168\u8fde\u63a5\uff0c\u4ece\u7f51\u7edc\u7ed3\u6784\u4e0a\u770b\uff0c\u4e0e\u524d\u9762\u4ecb\u7ecd\u7684CNN\u5206\u7c7b\u7f51\u7edc\u6ca1\u6709\u672c\u8d28\u7684\u533a\u522b\uff0c\u6700\u5927\u7684\u5dee\u5f02\u662f\u8f93\u51fa\u5c42\u7528\u7ebf\u6027\u51fd\u6570\u505a\u6fc0\u6d3b\u51fd\u6570\uff0c\u56e0\u4e3a\u9700\u8981\u9884\u6d4bbounding box\u7684\u4f4d\u7f6e\uff08\u6570\u503c\u578b\uff09\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5bf9\u8c61\u7684\u6982\u7387\u3002\u6240\u4ee5\u7c97\u7565\u6765\u8bf4\uff0cYOLO\u7684\u6574\u4e2a\u7ed3\u6784\u5c31\u662f\u8f93\u5165\u56fe\u7247\u7ecf\u8fc7\u795e\u7ecf\u7f51\u7edc\u7684\u53d8\u6362\u5f97\u5230\u4e00\u4e2a\u8f93\u51fa\u7684\u5f20\u91cf\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7f51\u7edc\u7ed3\u6784\u6bd4\u8f83\u7b80\u5355\uff0c\u91cd\u70b9\u662f\u6211\u4eec\u8981\u7406\u89e3\u7f51\u7edc\u8f93\u5165\u4e0e\u8f93\u51fa\u4e4b\u95f4\u7684\u5173\u7cfb\u3002 1.2.1 \u7f51\u7edc\u8f93\u5165 \u00b6 \u7f51\u7edc\u7684\u8f93\u5165\u662f\u539f\u59cb\u56fe\u50cf\uff0c\u552f\u4e00\u7684\u8981\u6c42\u662f\u7f29\u653e\u5230448x448\u7684\u5927\u5c0f\u3002\u4e3b\u8981\u662f\u56e0\u4e3aYolo\u7684\u7f51\u7edc\u4e2d\uff0c\u5377\u79ef\u5c42\u6700\u540e\u63a5\u4e86\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u5168\u8fde\u63a5\u5c42\u662f\u8981\u6c42\u56fa\u5b9a\u5927\u5c0f\u7684\u5411\u91cf\u4f5c\u4e3a\u8f93\u5165\uff0c\u6240\u4ee5Yolo\u7684\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u56fa\u5b9a\u4e3a448x448\u3002 1.2.2 \u7f51\u7edc\u8f93\u51fa \u00b6 \u7f51\u7edc\u7684\u8f93\u51fa\u5c31\u662f\u4e00\u4e2a7x7x30 \u7684\u5f20\u91cf\uff08tensor\uff09\u3002\u90a3\u8fd9\u4e2a\u8f93\u51fa\u7ed3\u679c\u6211\u4eec\u8981\u600e\u4e48\u7406\u89e3\u90a3\uff1f 1.7x7\u7f51\u683c \u00b6 \u6839\u636eYOLO\u7684\u8bbe\u8ba1\uff0c\u8f93\u5165\u56fe\u50cf\u88ab\u5212\u5206\u4e3a 7x7 \u7684\u7f51\u683c\uff08grid\uff09\uff0c\u8f93\u51fa\u5f20\u91cf\u4e2d\u7684 7x7 \u5c31\u5bf9\u5e94\u7740\u8f93\u5165\u56fe\u50cf\u7684 7x7 \u7f51\u683c\u3002\u6216\u8005\u6211\u4eec\u628a 7x7x30 \u7684\u5f20\u91cf\u770b\u4f5c 7x7=49\u4e2a30\u7ef4\u7684\u5411\u91cf\uff0c\u4e5f\u5c31\u662f\u8f93\u5165\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e2a\u7f51\u683c\u5bf9\u5e94\u8f93\u51fa\u4e00\u4e2a30\u7ef4\u7684\u5411\u91cf\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u6bd4\u5982\u8f93\u5165\u56fe\u50cf\u5de6\u4e0a\u89d2\u7684\u7f51\u683c\u5bf9\u5e94\u5230\u8f93\u51fa\u5f20\u91cf\u4e2d\u5de6\u4e0a\u89d2\u7684\u5411\u91cf\u3002 2.30\u7ef4\u5411\u91cf \u00b6 30\u7ef4\u7684\u5411\u91cf\u5305\u542b\uff1a2\u4e2abbox\u7684\u4f4d\u7f6e\u548c\u7f6e\u4fe1\u5ea6\u4ee5\u53ca\u8be5\u7f51\u683c\u5c5e\u4e8e20\u4e2a\u7c7b\u522b\u7684\u6982\u7387 2\u4e2abounding box\u7684\u4f4d\u7f6e \u6bcf\u4e2abounding box\u9700\u89814\u4e2a\u6570\u503c\u6765\u8868\u793a\u5176\u4f4d\u7f6e\uff0c(Center_x,Center_y,width,height)\uff0c\u5373(bounding box\u7684\u4e2d\u5fc3\u70b9\u7684x\u5750\u6807\uff0cy\u5750\u6807\uff0cbounding box\u7684\u5bbd\u5ea6\uff0c\u9ad8\u5ea6)\uff0c2\u4e2abounding box\u5171\u9700\u89818\u4e2a\u6570\u503c\u6765\u8868\u793a\u5176\u4f4d\u7f6e\u3002 2\u4e2abounding box\u7684\u7f6e\u4fe1\u5ea6 bounding box\u7684\u7f6e\u4fe1\u5ea6 = \u8be5bounding box\u5185\u5b58\u5728\u5bf9\u8c61\u7684\u6982\u7387 * \u8be5bounding box\u4e0e\u8be5\u5bf9\u8c61\u5b9e\u9645bounding box\u7684IOU\uff0c\u7528\u516c\u5f0f\u8868\u793a\u5c31\u662f\uff1a Pr(Object)\u662fbounding box\u5185\u5b58\u5728\u5bf9\u8c61\u7684\u6982\u7387 20\u4e2a\u5bf9\u8c61\u5206\u7c7b\u7684\u6982\u7387 Yolo\u652f\u6301\u8bc6\u522b20\u79cd\u4e0d\u540c\u7684\u5bf9\u8c61\uff08\u4eba\u3001\u9e1f\u3001\u732b\u3001\u6c7d\u8f66\u3001\u6905\u5b50\u7b49\uff09\uff0c\u6240\u4ee5\u8fd9\u91cc\u670920\u4e2a\u503c\u8868\u793a\u8be5\u7f51\u683c\u4f4d\u7f6e\u5b58\u5728\u4efb\u4e00\u79cd\u5bf9\u8c61\u7684\u6982\u7387. 1.3Yolo\u6a21\u578b\u7684\u8bad\u7ec3 \u00b6 \u5728\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u65f6\uff0c\u6211\u4eec\u9700\u8981\u6784\u9020\u8bad\u7ec3\u6837\u672c\u548c\u8bbe\u8ba1\u635f\u5931\u51fd\u6570\uff0c\u624d\u80fd\u5229\u7528\u68af\u5ea6\u4e0b\u964d\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u3002 1.3.1\u8bad\u7ec3\u6837\u672c\u7684\u6784\u5efa \u00b6 \u5c06\u4e00\u5e45\u56fe\u7247\u8f93\u5165\u5230yolo\u6a21\u578b\u4e2d\uff0c\u5bf9\u5e94\u7684\u8f93\u51fa\u662f\u4e00\u4e2a7x7x30\u5f20\u91cf\uff0c\u6784\u5efa\u6807\u7b7elabel\u65f6\u5bf9\u4e8e\u539f\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e00\u4e2a\u7f51\u683cgrid\u90fd\u9700\u8981\u6784\u5efa\u4e00\u4e2a30\u7ef4\u7684\u5411\u91cf\u3002\u5bf9\u7167\u4e0b\u56fe\u6211\u4eec\u6765\u6784\u5efa\u76ee\u6807\u5411\u91cf\uff1a 20\u4e2a\u5bf9\u8c61\u5206\u7c7b\u7684\u6982\u7387 \u5bf9\u4e8e\u8f93\u5165\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e2a\u5bf9\u8c61\uff0c\u5148\u627e\u5230\u5176\u4e2d\u5fc3\u70b9\u3002\u6bd4\u5982\u4e0a\u56fe\u4e2d\u81ea\u884c\u8f66\uff0c\u5176\u4e2d\u5fc3\u70b9\u5728\u9ec4\u8272\u5706\u70b9\u4f4d\u7f6e\uff0c\u4e2d\u5fc3\u70b9\u843d\u5728\u9ec4\u8272\u7f51\u683c\u5185\uff0c\u6240\u4ee5\u8fd9\u4e2a\u9ec4\u8272\u7f51\u683c\u5bf9\u5e94\u768430\u7ef4\u5411\u91cf\u4e2d\uff0c\u81ea\u884c\u8f66\u7684\u6982\u7387\u662f1\uff0c\u5176\u5b83\u5bf9\u8c61\u7684\u6982\u7387\u662f0\u3002\u6240\u6709\u5176\u5b8348\u4e2a\u7f51\u683c\u768430\u7ef4\u5411\u91cf\u4e2d\uff0c\u8be5\u81ea\u884c\u8f66\u7684\u6982\u7387\u90fd\u662f0\u3002\u8fd9\u5c31\u662f\u6240\u8c13\u7684\"\u4e2d\u5fc3\u70b9\u6240\u5728\u7684\u7f51\u683c\u5bf9\u9884\u6d4b\u8be5\u5bf9\u8c61\u8d1f\u8d23\"\u3002\u72d7\u548c\u6c7d\u8f66\u7684\u5206\u7c7b\u6982\u7387\u4e5f\u662f\u540c\u6837\u7684\u65b9\u6cd5\u586b\u5199 2\u4e2abounding box\u7684\u4f4d\u7f6e \u8bad\u7ec3\u6837\u672c\u7684bbox\u4f4d\u7f6e\u5e94\u8be5\u586b\u5199\u5bf9\u8c61\u771f\u5b9e\u7684\u4f4d\u7f6ebbox\uff0c\u4f46\u4e00\u4e2a\u5bf9\u8c61\u5bf9\u5e94\u4e862\u4e2abounding box\uff0c\u8be5\u586b\u54ea\u4e00\u4e2a\u5462\uff1f\u9700\u8981\u6839\u636e\u7f51\u7edc\u8f93\u51fa\u7684bbox\u4e0e\u5bf9\u8c61\u5b9e\u9645bbox\u7684IOU\u6765\u9009\u62e9\uff0c\u6240\u4ee5\u8981\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u52a8\u6001\u51b3\u5b9a\u5230\u5e95\u586b\u54ea\u4e00\u4e2abbox\u3002 2\u4e2abounding box\u7684\u7f6e\u4fe1\u5ea6 \u9884\u6d4b\u7f6e\u4fe1\u5ea6\u7684\u516c\u5f0f\u4e3a\uff1a IOU_{pred}^{truth} IOU_{pred}^{truth} \u5229\u7528\u7f51\u7edc\u8f93\u51fa\u76842\u4e2abounding box\u4e0e\u5bf9\u8c61\u771f\u5b9ebounding box\u8ba1\u7b97\u51fa\u6765\u3002\u7136\u540e\u770b\u8fd92\u4e2abounding box\u7684IOU\uff0c\u54ea\u4e2a\u6bd4\u8f83\u5927\uff0c\u5c31\u7531\u54ea\u4e2abounding box\u6765\u8d1f\u8d23\u9884\u6d4b\u8be5\u5bf9\u8c61\u662f\u5426\u5b58\u5728\uff0c\u5373\u8be5bounding box\u7684Pr(Object)=1\uff0c\u540c\u65f6\u5bf9\u8c61\u771f\u5b9ebounding box\u7684\u4f4d\u7f6e\u4e5f\u5c31\u586b\u5165\u8be5bounding box\u3002\u53e6\u4e00\u4e2a\u4e0d\u8d1f\u8d23\u9884\u6d4b\u7684bounding box\u7684Pr(Object)=0\u3002 \u4e0a\u56fe\u4e2d\u81ea\u884c\u8f66\u6240\u5728\u7684grid\u5bf9\u5e94\u7684\u7ed3\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff1a 1.3.2 \u635f\u5931\u51fd\u6570 \u00b6 \u635f\u5931\u5c31\u662f\u7f51\u7edc\u5b9e\u9645\u8f93\u51fa\u503c\u4e0e\u6837\u672c\u6807\u7b7e\u503c\u4e4b\u95f4\u7684\u504f\u5dee\uff1a yolo\u7ed9\u51fa\u7684\u635f\u5931\u51fd\u6570\uff1a \u6ce8\uff1a\u5176\u4e2d 1_{i}^{obj} 1_{i}^{obj} \u8868\u793a\u76ee\u6807\u662f\u5426\u51fa\u73b0\u5728\u7f51\u683c\u5355\u5143i\u4e2d\uff0c 1_{ij}^{obj} 1_{ij}^{obj} \u8868\u793a\u5355\u5143\u683ci\u4e2d\u7684\u7b2cj\u4e2a\u8fb9\u754c\u6846\u9884\u6d4b\u5668\u8d1f\u8d23\u8be5\u9884\u6d4b\uff0cYOLO\u8bbe\u7f6e \\lambda_{coord} = 5 \\lambda_{coord} = 5 \u6765\u8c03\u9ad8\u4f4d\u7f6e\u8bef\u5dee\u7684\u6743\u91cd\uff0c \\lambda_{noobj} = 0.5 \\lambda_{noobj} = 0.5 \u5373\u8c03\u4f4e\u4e0d\u5b58\u5728\u5bf9\u8c61\u7684bounding box\u7684\u7f6e\u4fe1\u5ea6\u8bef\u5dee\u7684\u6743\u91cd\u3002 1.3.3 \u6a21\u578b\u8bad\u7ec3 \u00b6 Yolo\u5148\u4f7f\u7528ImageNet\u6570\u636e\u96c6\u5bf9\u524d20\u5c42\u5377\u79ef\u7f51\u7edc\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u4f7f\u7528\u5b8c\u6574\u7684\u7f51\u7edc\uff0c\u5728PASCAL VOC\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5bf9\u8c61\u8bc6\u522b\u548c\u5b9a\u4f4d\u7684\u8bad\u7ec3\u3002 Yolo\u7684\u6700\u540e\u4e00\u5c42\u91c7\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff0c\u5176\u5b83\u5c42\u90fd\u662fLeaky ReLU\u3002\u8bad\u7ec3\u4e2d\u91c7\u7528\u4e86drop out\u548c\u6570\u636e\u589e\u5f3a\uff08data augmentation\uff09\u6765\u9632\u6b62\u8fc7\u62df\u5408. 1.4 \u6a21\u578b\u9884\u6d4b \u00b6 \u5c06\u56fe\u7247resize\u6210448x448\u7684\u5927\u5c0f\uff0c\u9001\u5165\u5230yolo\u7f51\u7edc\u4e2d\uff0c\u8f93\u51fa\u4e00\u4e2a 7x7x30 \u7684\u5f20\u91cf\uff08tensor\uff09\u6765\u8868\u793a\u56fe\u7247\u4e2d\u6240\u6709\u7f51\u683c\u5305\u542b\u7684\u5bf9\u8c61\uff08\u6982\u7387\uff09\u4ee5\u53ca\u8be5\u5bf9\u8c61\u53ef\u80fd\u76842\u4e2a\u4f4d\u7f6e\uff08bounding box\uff09\u548c\u53ef\u4fe1\u7a0b\u5ea6\uff08\u7f6e\u4fe1\u5ea6\uff09\u3002\u5728\u91c7\u7528NMS\uff08Non-maximal suppression\uff0c\u975e\u6781\u5927\u503c\u6291\u5236\uff09\u7b97\u6cd5\u9009\u51fa\u6700\u6709\u53ef\u80fd\u662f\u76ee\u6807\u7684\u7ed3\u679c\u3002 1.5 yolo\u603b\u7ed3 \u00b6 \u4f18\u70b9 \u901f\u5ea6\u975e\u5e38\u5feb\uff0c\u5904\u7406\u901f\u5ea6\u53ef\u4ee5\u8fbe\u523045fps\uff0c\u5176\u5feb\u901f\u7248\u672c\uff08\u7f51\u7edc\u8f83\u5c0f\uff09\u751a\u81f3\u53ef\u4ee5\u8fbe\u5230155fps\u3002 \u8bad\u7ec3\u548c\u9884\u6d4b\u53ef\u4ee5\u7aef\u5230\u7aef\u7684\u8fdb\u884c\uff0c\u975e\u5e38\u7b80\u4fbf\u3002 \u7f3a\u70b9 \u51c6\u786e\u7387\u4f1a\u6253\u6298\u6263 \u5bf9\u4e8e\u5c0f\u76ee\u6807\u548c\u9760\u7684\u5f88\u8fd1\u7684\u76ee\u6807\u68c0\u6d4b\u6548\u679c\u5e76\u4e0d\u597d 2.yoloV2 \u00b6 YOLOv2\u76f8\u5bf9v1\u7248\u672c\uff0c\u5728\u7ee7\u7eed\u4fdd\u6301\u5904\u7406\u901f\u5ea6\u7684\u57fa\u7840\u4e0a\uff0c\u4ece\u9884\u6d4b\u66f4\u51c6\u786e\uff08Better\uff09\uff0c\u901f\u5ea6\u66f4\u5feb\uff08Faster\uff09\uff0c\u8bc6\u522b\u5bf9\u8c61\u66f4\u591a\uff08Stronger\uff09\u8fd9\u4e09\u4e2a\u65b9\u9762\u8fdb\u884c\u4e86\u6539\u8fdb\u3002\u5176\u4e2d\u8bc6\u522b\u66f4\u591a\u5bf9\u8c61\u4e5f\u5c31\u662f\u6269\u5c55\u5230\u80fd\u591f\u68c0\u6d4b9000\u79cd\u4e0d\u540c\u5bf9\u8c61\uff0c\u79f0\u4e4b\u4e3aYOLO9000\u3002 \u4e0b\u9762\u6211\u4eec\u770b\u4e0byoloV2\u7684\u90fd\u505a\u4e86\u54ea\u4e9b\u6539\u8fdb\uff1f 2.1 \u9884\u6d4b\u66f4\u51c6\u786e\uff08better\uff09 \u00b6 2.1.1 batch normalization \u00b6 \u6279\u6807\u51c6\u5316\u6709\u52a9\u4e8e\u89e3\u51b3\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u7684\u68af\u5ea6\u6d88\u5931\u548c\u68af\u5ea6\u7206\u70b8\u95ee\u9898\uff0c\u964d\u4f4e\u5bf9\u4e00\u4e9b\u8d85\u53c2\u6570\u7684\u654f\u611f\u6027\uff0c\u5e76\u4e14\u6bcf\u4e2abatch\u5206\u522b\u8fdb\u884c\u5f52\u4e00\u5316\u7684\u65f6\u5019\uff0c\u8d77\u5230\u4e86\u4e00\u5b9a\u7684\u6b63\u5219\u5316\u6548\u679c\uff0c\u4ece\u800c\u80fd\u591f\u83b7\u5f97\u66f4\u597d\u7684\u6536\u655b\u901f\u5ea6\u548c\u6536\u655b\u6548\u679c\u3002\u5728yoloV2\u4e2d\u5377\u79ef\u540e\u5168\u90e8\u52a0\u5165Batch Normalization\uff0c\u7f51\u7edc\u4f1a\u63d0\u53472%\u7684mAP\u3002 2.1.2 \u4f7f\u7528\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5fae\u8c03\u5206\u7c7b\u6a21\u578b \u00b6 YOLO v1\u4f7f\u7528ImageNet\u7684\u56fe\u50cf\u5206\u7c7b\u6837\u672c\u91c7\u7528 224x224 \u4f5c\u4e3a\u8f93\u5165\uff0c\u6765\u8bad\u7ec3CNN\u5377\u79ef\u5c42\u3002\u7136\u540e\u5728\u8bad\u7ec3\u5bf9\u8c61\u68c0\u6d4b\u65f6\uff0c\u68c0\u6d4b\u7528\u7684\u56fe\u50cf\u6837\u672c\u91c7\u7528\u66f4\u9ad8\u5206\u8fa8\u7387\u7684 448x448 \u7684\u56fe\u50cf\u4f5c\u4e3a\u8f93\u5165\u3002\u4f46\u8fd9\u6837\u5207\u6362\u5bf9\u6a21\u578b\u6027\u80fd\u6709\u4e00\u5b9a\u5f71\u54cd\u3002 YOLOV2\u5728\u91c7\u7528 224x224 \u56fe\u50cf\u8fdb\u884c\u5206\u7c7b\u6a21\u578b\u9884\u8bad\u7ec3\u540e\uff0c\u518d\u91c7\u7528 448x448 \u7684\u9ad8\u5206\u8fa8\u7387\u6837\u672c\u5bf9\u5206\u7c7b\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0810\u4e2aepoch\uff09\uff0c\u4f7f\u7f51\u7edc\u7279\u5f81\u9010\u6e10\u9002\u5e94 448x448 \u7684\u5206\u8fa8\u7387\u3002\u7136\u540e\u518d\u4f7f\u7528 448x448 \u7684\u68c0\u6d4b\u6837\u672c\u8fdb\u884c\u8bad\u7ec3\uff0c\u7f13\u89e3\u4e86\u5206\u8fa8\u7387\u7a81\u7136\u5207\u6362\u9020\u6210\u7684\u5f71\u54cd\u3002 \u4f7f\u7528\u8be5\u6280\u5de7\u540e\u7f51\u7edc\u7684mAP\u63d0\u5347\u4e86\u7ea64%\u3002 2.1.3 \u91c7\u7528Anchor Boxes \u00b6 YOLO1\u5e76\u6ca1\u6709\u91c7\u7528\u5148\u9a8c\u6846\uff0c\u5e76\u4e14\u6bcf\u4e2agrid\u53ea\u9884\u6d4b\u4e24\u4e2abounding box\uff0c\u6574\u4e2a\u56fe\u50cf98\u4e2a\u3002YOLO2\u5982\u679c\u6bcf\u4e2agrid\u91c7\u75285\u4e2a\u5148\u9a8c\u6846\uff0c\u603b\u5171\u670913x13x5=845\u4e2a\u5148\u9a8c\u6846\u3002\u901a\u8fc7\u5f15\u5165anchor boxes\uff0c\u4f7f\u5f97\u9884\u6d4b\u7684box\u6570\u91cf\u66f4\u591a\uff0813x13xn\uff09\u3002 2.2.4 \u805a\u7c7b\u63d0\u53d6anchor\u5c3a\u5ea6 \u00b6 Faster-rcnn\u9009\u62e9\u7684anchor\u6bd4\u4f8b\u90fd\u662f\u624b\u52a8\u6307\u5b9a\u7684\uff0c\u4f46\u662f\u4e0d\u4e00\u5b9a\u5b8c\u5168\u9002\u5408\u6570\u636e\u96c6\u3002YOLO2\u5c1d\u8bd5\u7edf\u8ba1\u51fa\u66f4\u7b26\u5408\u6837\u672c\u4e2d\u5bf9\u8c61\u5c3a\u5bf8\u7684\u5148\u9a8c\u6846\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u51cf\u5c11\u7f51\u7edc\u5fae\u8c03\u5148\u9a8c\u6846\u5230\u5b9e\u9645\u4f4d\u7f6e\u7684\u96be\u5ea6\u3002YOLO2\u7684\u505a\u6cd5\u662f\u5bf9\u8bad\u7ec3\u96c6\u4e2d\u6807\u6ce8\u7684\u8fb9\u6846\u8fdb\u884c\u805a\u7c7b\u5206\u6790\uff0c\u4ee5\u5bfb\u627e\u5c3d\u53ef\u80fd\u5339\u914d\u6837\u672c\u7684\u8fb9\u6846\u5c3a\u5bf8\u3002 YoloV2\u9009\u62e9\u4e86\u805a\u7c7b\u7684\u4e94\u79cd\u5c3a\u5bf8\u6700\u4e3aanchor box\u3002 2.1.5 \u8fb9\u6846\u4f4d\u7f6e\u7684\u9884\u6d4b \u00b6 Yolov2\u4e2d\u5c06\u8fb9\u6846\u7684\u7ed3\u679c\u7ea6\u675f\u5728\u7279\u5b9a\u7684\u7f51\u683c\u4e2d\uff1a \u5176\u4e2d\uff0c b_x,b_y,b_w,b_h b_x,b_y,b_w,b_h \u662f\u9884\u6d4b\u8fb9\u6846\u7684\u4e2d\u5fc3\u548c\u5bbd\u9ad8\u3002 Pr(object)\u2217IOU(b,object) Pr(object)\u2217IOU(b,object) \u662f\u9884\u6d4b\u8fb9\u6846\u7684\u7f6e\u4fe1\u5ea6\uff0cYOLO1\u662f\u76f4\u63a5\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u7684\u503c\uff0c\u8fd9\u91cc\u5bf9\u9884\u6d4b\u53c2\u6570 t_o t_o \u8fdb\u884c\u03c3\u53d8\u6362\u540e\u4f5c\u4e3a\u7f6e\u4fe1\u5ea6\u7684\u503c\u3002 c_x,c_y c_x,c_y \u662f\u5f53\u524d\u7f51\u683c\u5de6\u4e0a\u89d2\u5230\u56fe\u50cf\u5de6\u4e0a\u89d2\u7684\u8ddd\u79bb\uff0c\u8981\u5148\u5c06\u7f51\u683c\u5927\u5c0f\u5f52\u4e00\u5316\uff0c\u5373\u4ee4\u4e00\u4e2a\u7f51\u683c\u7684\u5bbd=1\uff0c\u9ad8=1\u3002 p_w,p_h p_w,p_h \u662f\u5148\u9a8c\u6846\u7684\u5bbd\u548c\u9ad8\u3002 \u03c3\u662fsigmoid\u51fd\u6570\u3002 t_x,t_y,t_w,t_h,t_o t_x,t_y,t_w,t_h,t_o \u662f\u8981\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u5206\u522b\u7528\u4e8e\u9884\u6d4b\u8fb9\u6846\u7684\u4e2d\u5fc3\u548c\u5bbd\u9ad8\uff0c\u4ee5\u53ca\u7f6e\u4fe1\u5ea6\u3002 \u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7531\u4e8e\u03c3\u51fd\u6570\u5c06 t_x,t_y t_x,t_y \u7ea6\u675f\u5728(0,1)\u8303\u56f4\u5185\uff0c\u9884\u6d4b\u8fb9\u6846\u7684\u84dd\u8272\u4e2d\u5fc3\u70b9\u88ab\u7ea6\u675f\u5728\u84dd\u8272\u80cc\u666f\u7684\u7f51\u683c\u5185\u3002\u7ea6\u675f\u8fb9\u6846\u4f4d\u7f6e\u4f7f\u5f97\u6a21\u578b\u66f4\u5bb9\u6613\u5b66\u4e60\uff0c\u4e14\u9884\u6d4b\u66f4\u4e3a\u7a33\u5b9a\u3002 \u5047\u8bbe\u7f51\u7edc\u9884\u6d4b\u503c\u4e3a\uff1a anchor\u6846\u4e3a\uff1a \u5219\u76ee\u6807\u5728\u7279\u5f81\u56fe\u4e2d\u7684\u4f4d\u7f6e\uff1a \u5728\u539f\u56fe\u50cf\u4e2d\u7684\u4f4d\u7f6e\uff1a 2.1.6 \u7ec6\u7c92\u5ea6\u7279\u5f81\u878d\u5408 \u00b6 \u56fe\u50cf\u4e2d\u5bf9\u8c61\u4f1a\u6709\u5927\u6709\u5c0f\uff0c\u8f93\u5165\u56fe\u50cf\u7ecf\u8fc7\u591a\u5c42\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\uff0c\u6700\u540e\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u4e2d\uff0c\u8f83\u5c0f\u7684\u5bf9\u8c61\u53ef\u80fd\u7279\u5f81\u5df2\u7ecf\u4e0d\u660e\u663e\u751a\u81f3\u88ab\u5ffd\u7565\u6389\u4e86\u3002\u4e3a\u4e86\u66f4\u597d\u7684\u68c0\u6d4b\u51fa\u4e00\u4e9b\u6bd4\u8f83\u5c0f\u7684\u5bf9\u8c61\uff0c\u6700\u540e\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u9700\u8981\u4fdd\u7559\u4e00\u4e9b\u66f4\u7ec6\u8282\u7684\u4fe1\u606f\u3002 YOLO2\u5f15\u5165\u4e00\u79cd\u79f0\u4e3apassthrough\u5c42\u7684\u65b9\u6cd5\u5728\u7279\u5f81\u56fe\u4e2d\u4fdd\u7559\u4e00\u4e9b\u7ec6\u8282\u4fe1\u606f\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5c31\u662f\u5728\u6700\u540e\u4e00\u4e2apooling\u4e4b\u524d\uff0c\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u662f26x26x512\uff0c\u5c06\u51761\u62c64\uff0c\u76f4\u63a5\u4f20\u9012\uff08passthrough\uff09\u5230pooling\u540e\uff08\u5e76\u4e14\u53c8\u7ecf\u8fc7\u4e00\u7ec4\u5377\u79ef\uff09\u7684\u7279\u5f81\u56fe\uff0c\u4e24\u8005\u53e0\u52a0\u5230\u4e00\u8d77\u4f5c\u4e3a\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u3002 \u5177\u4f53\u7684\u62c6\u5206\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a 2.1.7 \u591a\u5c3a\u5ea6\u8bad\u7ec3 \u00b6 YOLO2\u4e2d\u6ca1\u6709\u5168\u8fde\u63a5\u5c42\uff0c\u53ef\u4ee5\u8f93\u5165\u4efb\u4f55\u5c3a\u5bf8\u7684\u56fe\u50cf\u3002\u56e0\u4e3a\u6574\u4e2a\u7f51\u7edc\u4e0b\u91c7\u6837\u500d\u6570\u662f32\uff0c\u91c7\u7528\u4e86{320,352,...,608}\u7b4910\u79cd\u8f93\u5165\u56fe\u50cf\u7684\u5c3a\u5bf8\uff0c\u8fd9\u4e9b\u5c3a\u5bf8\u7684\u8f93\u5165\u56fe\u50cf\u5bf9\u5e94\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u5bbd\u548c\u9ad8\u662f{10,11,...19}\u3002\u8bad\u7ec3\u65f6\u6bcf10\u4e2abatch\u5c31\u968f\u673a\u66f4\u6362\u4e00\u79cd\u5c3a\u5bf8\uff0c\u4f7f\u7f51\u7edc\u80fd\u591f\u9002\u5e94\u5404\u79cd\u5927\u5c0f\u7684\u5bf9\u8c61\u68c0\u6d4b\u3002 2.2 \u901f\u5ea6\u66f4\u5feb\uff08Faster\uff09 \u00b6 yoloV2\u63d0\u51fa\u4e86Darknet-19\uff08\u670919\u4e2a\u5377\u79ef\u5c42\u548c5\u4e2aMaxPooling\u5c42\uff09\u7f51\u7edc\u7ed3\u6784\u4f5c\u4e3a\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u3002DarkNet-19\u6bd4VGG-16\u5c0f\u4e00\u4e9b\uff0c\u7cbe\u5ea6\u4e0d\u5f31\u4e8eVGG-16\uff0c\u4f46\u6d6e\u70b9\u8fd0\u7b97\u91cf\u51cf\u5c11\u5230\u7ea6\u2155\uff0c\u4ee5\u4fdd\u8bc1\u66f4\u5feb\u7684\u8fd0\u7b97\u901f\u5ea6\u3002 yoloV2\u7684\u7f51\u7edc\u4e2d\u53ea\u6709\u5377\u79ef+pooling\uff0c\u4ece416x416x3 \u53d8\u6362\u5230 13x13x5x25\u3002\u589e\u52a0\u4e86batch normalization\uff0c\u589e\u52a0\u4e86\u4e00\u4e2apassthrough\u5c42\uff0c\u53bb\u6389\u4e86\u5168\u8fde\u63a5\u5c42\uff0c\u4ee5\u53ca\u91c7\u7528\u4e865\u4e2a\u5148\u9a8c\u6846,\u7f51\u7edc\u7684\u8f93\u51fa\u5982\u4e0b\u56fe\u6240\u793a\uff1a 2.3 \u8bc6\u522b\u5bf9\u8c61\u66f4\u591a \u00b6 VOC\u6570\u636e\u96c6\u53ef\u4ee5\u68c0\u6d4b20\u79cd\u5bf9\u8c61\uff0c\u4f46\u5b9e\u9645\u4e0a\u5bf9\u8c61\u7684\u79cd\u7c7b\u975e\u5e38\u591a\uff0c\u53ea\u662f\u7f3a\u5c11\u76f8\u5e94\u7684\u7528\u4e8e\u5bf9\u8c61\u68c0\u6d4b\u7684\u8bad\u7ec3\u6837\u672c\u3002YOLO2\u5c1d\u8bd5\u5229\u7528ImageNet\u975e\u5e38\u5927\u91cf\u7684\u5206\u7c7b\u6837\u672c\uff0c\u8054\u5408COCO\u7684\u5bf9\u8c61\u68c0\u6d4b\u6570\u636e\u96c6\u4e00\u8d77\u8bad\u7ec3\uff0c\u4f7f\u5f97YOLO2\u5373\u4f7f\u6ca1\u6709\u5b66\u8fc7\u5f88\u591a\u5bf9\u8c61\u7684\u68c0\u6d4b\u6837\u672c\uff0c\u4e5f\u80fd\u68c0\u6d4b\u51fa\u8fd9\u4e9b\u5bf9\u8c61\u3002 3.yoloV3 \u00b6 yoloV3\u4ee5V1\uff0cV2\u4e3a\u57fa\u7840\u8fdb\u884c\u7684\u6539\u8fdb\uff0c\u4e3b\u8981\u6709\uff1a\u5229\u7528\u591a\u5c3a\u5ea6\u7279\u5f81\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff1b\u5148\u9a8c\u6846\u66f4\u4e30\u5bcc\uff1b\u8c03\u6574\u4e86\u7f51\u7edc\u7ed3\u6784\uff1b\u5bf9\u8c61\u5206\u7c7b\u4f7f\u7528logistic\u4ee3\u66ff\u4e86softmax,\u66f4\u9002\u7528\u4e8e\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1\u3002 3.1\u7b97\u6cd5\u7b80\u4ecb \u00b6 YOLOv3\u662fYOLO (You Only Look Once)\u7cfb\u5217\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\u7684\u7b2c\u4e09\u7248\uff0c\u76f8\u6bd4\u4e4b\u524d\u7684\u7b97\u6cd5\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u5c0f\u76ee\u6807\uff0c\u7cbe\u5ea6\u6709\u663e\u8457\u63d0\u5347\u3002 yoloV3\u7684\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u5e45\u8f93\u5165\u56fe\u50cf\uff0cYOLOv3\u4f1a\u9884\u6d4b\u4e09\u4e2a\u4e0d\u540c\u5c3a\u5ea6\u7684\u8f93\u51fa\uff0c\u76ee\u7684\u662f\u68c0\u6d4b\u51fa\u4e0d\u540c\u5927\u5c0f\u7684\u76ee\u6807\u3002 3.2\u591a\u5c3a\u5ea6\u68c0\u6d4b \u00b6 \u901a\u5e38\u4e00\u5e45\u56fe\u50cf\u5305\u542b\u5404\u79cd\u4e0d\u540c\u7684\u7269\u4f53\uff0c\u5e76\u4e14\u6709\u5927\u6709\u5c0f\u3002\u6bd4\u8f83\u7406\u60f3\u7684\u662f\u4e00\u6b21\u5c31\u53ef\u4ee5\u5c06\u6240\u6709\u5927\u5c0f\u7684\u7269\u4f53\u540c\u65f6\u68c0\u6d4b\u51fa\u6765\u3002\u56e0\u6b64\uff0c\u7f51\u7edc\u5fc5\u987b\u5177\u5907\u80fd\u591f\u201c\u770b\u5230\u201d\u4e0d\u540c\u5927\u5c0f\u7684\u7269\u4f53\u7684\u80fd\u529b\u3002\u56e0\u4e3a\u7f51\u7edc\u8d8a\u6df1\uff0c\u7279\u5f81\u56fe\u5c31\u4f1a\u8d8a\u5c0f\uff0c\u6240\u4ee5\u7f51\u7edc\u8d8a\u6df1\u5c0f\u7684\u7269\u4f53\u4e5f\u5c31\u8d8a\u96be\u68c0\u6d4b\u51fa\u6765\u3002 \u5728\u5b9e\u9645\u7684feature map\u4e2d\uff0c\u968f\u7740\u7f51\u7edc\u6df1\u5ea6\u7684\u52a0\u6df1\uff0c\u6d45\u5c42\u7684feature map\u4e2d\u4e3b\u8981\u5305\u542b\u4f4e\u7ea7\u7684\u4fe1\u606f\uff08\u7269\u4f53\u8fb9\u7f18\uff0c\u989c\u8272\uff0c\u521d\u7ea7\u4f4d\u7f6e\u4fe1\u606f\u7b49\uff09\uff0c\u6df1\u5c42\u7684feature map\u4e2d\u5305\u542b\u9ad8\u7b49\u4fe1\u606f\uff08\u4f8b\u5982\u7269\u4f53\u7684\u8bed\u4e49\u4fe1\u606f\uff1a\u72d7\uff0c\u732b\uff0c\u6c7d\u8f66\u7b49\u7b49\uff09\u3002\u56e0\u6b64\u5728\u4e0d\u540c\u7ea7\u522b\u7684feature map\u5bf9\u5e94\u4e0d\u540c\u7684scale\uff0c\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u5728\u4e0d\u540c\u7ea7\u522b\u7684\u7279\u5f81\u56fe\u4e2d\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u3002\u5982\u4e0b\u56fe\u5c55\u793a\u4e86\u591a\u79cdscale\u53d8\u6362\u7684\u7ecf\u5178\u65b9\u6cd5\u3002 (a) \u8fd9\u79cd\u65b9\u6cd5\u9996\u5148\u5efa\u7acb\u56fe\u50cf\u91d1\u5b57\u5854\uff0c\u4e0d\u540c\u5c3a\u5ea6\u7684\u91d1\u5b57\u5854\u56fe\u50cf\u88ab\u8f93\u5165\u5230\u5bf9\u5e94\u7684\u7f51\u7edc\u5f53\u4e2d\uff0c\u7528\u4e8e\u4e0d\u540cscale\u7269\u4f53\u7684\u68c0\u6d4b\u3002\u4f46\u8fd9\u6837\u505a\u7684\u7ed3\u679c\u5c31\u662f\u6bcf\u4e2a\u7ea7\u522b\u7684\u91d1\u5b57\u5854\u90fd\u9700\u8981\u8fdb\u884c\u4e00\u6b21\u5904\u7406\uff0c\u901f\u5ea6\u5f88\u6162\u3002 (b) \u68c0\u6d4b\u53ea\u5728\u6700\u540e\u4e00\u5c42feature map\u9636\u6bb5\u8fdb\u884c\uff0c\u8fd9\u4e2a\u7ed3\u6784\u65e0\u6cd5\u68c0\u6d4b\u4e0d\u540c\u5927\u5c0f\u7684\u7269\u4f53 \u00a9 \u5bf9\u4e0d\u540c\u6df1\u5ea6\u7684feature map\u5206\u522b\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u3002SSD\u4e2d\u91c7\u7528\u7684\u4fbf\u662f\u8fd9\u6837\u7684\u7ed3\u6784\u3002\u8fd9\u6837\u5c0f\u7684\u7269\u4f53\u4f1a\u5728\u6d45\u5c42\u7684feature map\u4e2d\u88ab\u68c0\u6d4b\u51fa\u6765\uff0c\u800c\u5927\u7684\u7269\u4f53\u4f1a\u5728\u6df1\u5c42\u7684feature map\u88ab\u68c0\u6d4b\u51fa\u6765\uff0c\u4ece\u800c\u8fbe\u5230\u5bf9\u5e94\u4e0d\u540cscale\u7684\u7269\u4f53\u7684\u76ee\u7684\uff0c\u7f3a\u70b9\u662f\u6bcf\u4e00\u4e2afeature map\u83b7\u5f97\u7684\u4fe1\u606f\u4ec5\u6765\u6e90\u4e8e\u4e4b\u524d\u7684\u5c42\uff0c\u4e4b\u540e\u7684\u5c42\u7684\u7279\u5f81\u4fe1\u606f\u65e0\u6cd5\u83b7\u53d6\u5e76\u52a0\u4ee5\u5229\u7528\u3002 (d) \u4e0e\u00a9\u5f88\u63a5\u8fd1\uff0c\u4f46\u4e0d\u540c\u7684\u662f\uff0c\u5f53\u524d\u5c42\u7684feature map\u4f1a\u5bf9\u672a\u6765\u5c42\u7684feature map\u8fdb\u884c\u4e0a\u91c7\u6837\uff0c\u5e76\u52a0\u4ee5\u5229\u7528\u3002\u56e0\u4e3a\u6709\u4e86\u8fd9\u6837\u4e00\u4e2a\u7ed3\u6784\uff0c\u5f53\u524d\u7684feature map\u5c31\u53ef\u4ee5\u83b7\u5f97\u201c\u672a\u6765\u201d\u5c42\u7684\u4fe1\u606f\uff0c\u8fd9\u6837\u7684\u8bdd\u4f4e\u9636\u7279\u5f81\u4e0e\u9ad8\u9636\u7279\u5f81\u5c31\u6709\u673a\u878d\u5408\u8d77\u6765\u4e86\uff0c\u63d0\u5347\u68c0\u6d4b\u7cbe\u5ea6\u3002\u5728YOLOv3\u4e2d\uff0c\u5c31\u662f\u91c7\u7528\u8fd9\u79cd\u65b9\u5f0f\u6765\u5b9e\u73b0\u76ee\u6807\u591a\u5c3a\u5ea6\u7684\u53d8\u6362\u7684\u3002 3.3\u7f51\u7edc\u6a21\u578b\u7ed3\u6784 \u00b6 \u5728\u57fa\u672c\u7684\u56fe\u50cf\u7279\u5f81\u63d0\u53d6\u65b9\u9762\uff0cYOLO3\u91c7\u7528\u4e86Darknet-53\u7684\u7f51\u7edc\u7ed3\u6784\uff08\u542b\u670953\u4e2a\u5377\u79ef\u5c42\uff09\uff0c\u5b83\u501f\u9274\u4e86\u6b8b\u5dee\u7f51\u7edcResNet\u7684\u505a\u6cd5\uff0c\u5728\u5c42\u4e4b\u95f4\u8bbe\u7f6e\u4e86shortcut\uff0c\u6765\u89e3\u51b3\u6df1\u5c42\u7f51\u7edc\u68af\u5ea6\u7684\u95ee\u9898\uff0cshortcut\u5982\u4e0b\u56fe\u6240\u793a\uff1a\u5305\u542b\u4e24\u4e2a\u5377\u79ef\u5c42\u548c\u4e00\u4e2ashortcut connections\u3002 yoloV3\u7684\u6a21\u578b\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a\u6574\u4e2av3\u7ed3\u6784\u91cc\u9762\uff0c\u6ca1\u6709\u6c60\u5316\u5c42\u548c\u5168\u8fde\u63a5\u5c42\uff0c\u7f51\u7edc\u7684\u4e0b\u91c7\u6837\u662f\u901a\u8fc7\u8bbe\u7f6e\u5377\u79ef\u7684stride\u4e3a2\u6765\u8fbe\u5230\u7684\uff0c\u6bcf\u5f53\u901a\u8fc7\u8fd9\u4e2a\u5377\u79ef\u5c42\u4e4b\u540e\u56fe\u50cf\u7684\u5c3a\u5bf8\u5c31\u4f1a\u51cf\u5c0f\u5230\u4e00\u534a\u3002 ![ \u4e0b\u9762\u6211\u4eec\u770b\u4e0b\u7f51\u7edc\u7ed3\u6784\uff1a \u57fa\u672c\u7ec4\u4ef6\uff1a\u84dd\u8272\u65b9\u6846\u5185\u90e8\u5206 1\u3001CBL\uff1aYolov3\u7f51\u7edc\u7ed3\u6784\u4e2d\u7684\u6700\u5c0f\u7ec4\u4ef6\uff0c\u7531Conv+Bn+Leaky_relu\u6fc0\u6d3b\u51fd\u6570\u4e09\u8005\u7ec4\u6210\u3002 2\u3001Res unit\uff1a\u501f\u9274Resnet\u7f51\u7edc\u4e2d\u7684\u6b8b\u5dee\u7ed3\u6784\uff0c\u8ba9\u7f51\u7edc\u53ef\u4ee5\u6784\u5efa\u7684\u66f4\u6df1\u3002 3\u3001ResX\uff1a\u7531\u4e00\u4e2aCBL\u548cX\u4e2a\u6b8b\u5dee\u7ec4\u4ef6\u6784\u6210\uff0c\u662fYolov3\u4e2d\u7684\u5927\u7ec4\u4ef6\u3002\u6bcf\u4e2aRes\u6a21\u5757\u524d\u9762\u7684CBL\u90fd\u8d77\u5230\u4e0b\u91c7\u6837\u7684\u4f5c\u7528\uff0c\u56e0\u6b64\u7ecf\u8fc75\u6b21Res\u6a21\u5757\u540e\uff0c\u5f97\u5230\u7684\u7279\u5f81\u56fe\u662f416->208->104->52->26->13\u5927\u5c0f\u3002 \u5176\u4ed6\u57fa\u7840\u64cd\u4f5c\uff1a 1\u3001Concat\uff1a\u5f20\u91cf\u62fc\u63a5\uff0c\u4f1a\u6269\u5145\u4e24\u4e2a\u5f20\u91cf\u7684\u7ef4\u5ea6\uff0c\u4f8b\u598226\u00d726\u00d7256\u548c26\u00d726\u00d7512\u4e24\u4e2a\u5f20\u91cf\u62fc\u63a5\uff0c\u7ed3\u679c\u662f26\u00d726\u00d7768\u3002 2\u3001Add\uff1a\u5f20\u91cf\u76f8\u52a0\uff0c\u5f20\u91cf\u76f4\u63a5\u76f8\u52a0\uff0c\u4e0d\u4f1a\u6269\u5145\u7ef4\u5ea6\uff0c\u4f8b\u5982104\u00d7104\u00d7128\u548c104\u00d7104\u00d7128\u76f8\u52a0\uff0c\u7ed3\u679c\u8fd8\u662f104\u00d7104\u00d7128\u3002 Backbone\u4e2d\u5377\u79ef\u5c42\u7684\u6570\u91cf\uff1a \u6bcf\u4e2aResX\u4e2d\u5305\u542b1+2\u00d7X\u4e2a\u5377\u79ef\u5c42\uff0c\u56e0\u6b64\u6574\u4e2a\u4e3b\u5e72\u7f51\u7edcBackbone\u4e2d\u4e00\u5171\u5305\u542b1+\uff081+2\u00d71\uff09+\uff081+2\u00d72\uff09+\uff081+2\u00d78\uff09+\uff081+2\u00d78\uff09+\uff081+2\u00d74\uff09=52\uff0c\u518d\u52a0\u4e0a\u4e00\u4e2aFC\u5168\u8fde\u63a5\u5c42\uff0c\u5373\u53ef\u4ee5\u7ec4\u6210\u4e00\u4e2aDarknet53\u5206\u7c7b\u7f51\u7edc\u3002\u4e0d\u8fc7\u5728\u76ee\u6807\u68c0\u6d4bYolov3\u4e2d\uff0c\u53bb\u6389FC\u5c42\uff0c\u4ecd\u7136\u628aYolov3\u7684\u4e3b\u5e72\u7f51\u7edc\u53eb\u505aDarknet53\u7ed3\u6784\u3002 3.4\u5148\u9a8c\u6846 \u00b6 yoloV3\u91c7\u7528K-means\u805a\u7c7b\u5f97\u5230\u5148\u9a8c\u6846\u7684\u5c3a\u5bf8\uff0c\u4e3a\u6bcf\u79cd\u5c3a\u5ea6\u8bbe\u5b9a3\u79cd\u5148\u9a8c\u6846\uff0c\u603b\u5171\u805a\u7c7b\u51fa9\u79cd\u5c3a\u5bf8\u7684\u5148\u9a8c\u6846\u3002 \u5728COCO\u6570\u636e\u96c6\u8fd99\u4e2a\u5148\u9a8c\u6846\u662f\uff1a(10x13)\uff0c(16x30)\uff0c(33x23)\uff0c(30x61)\uff0c(62x45)\uff0c(59x119)\uff0c(116x90)\uff0c(156x198)\uff0c(373x326)\u3002\u5728\u6700\u5c0f\u7684(13x13)\u7279\u5f81\u56fe\u4e0a\uff08\u6709\u6700\u5927\u7684\u611f\u53d7\u91ce\uff09\u5e94\u7528\u8f83\u5927\u7684\u5148\u9a8c\u6846(116x90)\uff0c(156x198)\uff0c(373x326)\uff0c\u9002\u5408\u68c0\u6d4b\u8f83\u5927\u7684\u5bf9\u8c61\u3002\u4e2d\u7b49\u7684(26x26)\u7279\u5f81\u56fe\u4e0a\uff08\u4e2d\u7b49\u611f\u53d7\u91ce\uff09\u5e94\u7528\u4e2d\u7b49\u7684\u5148\u9a8c\u6846(30x61)\uff0c(62x45)\uff0c(59x119)\uff0c\u9002\u5408\u68c0\u6d4b\u4e2d\u7b49\u5927\u5c0f\u7684\u5bf9\u8c61\u3002\u8f83\u5927\u7684(52x52)\u7279\u5f81\u56fe\u4e0a\uff08\u8f83\u5c0f\u7684\u611f\u53d7\u91ce\uff09\u5e94\u7528,\u5176\u4e2d\u8f83\u5c0f\u7684\u5148\u9a8c\u6846(10x13)\uff0c(16x30)\uff0c(33x23)\uff0c\u9002\u5408\u68c0\u6d4b\u8f83\u5c0f\u7684\u5bf9\u8c61\u3002 \u76f4\u89c2\u4e0a\u611f\u53d79\u79cd\u5148\u9a8c\u6846\u7684\u5c3a\u5bf8\uff0c\u4e0b\u56fe\u4e2d\u84dd\u8272\u6846\u4e3a\u805a\u7c7b\u5f97\u5230\u7684\u5148\u9a8c\u6846\u3002\u9ec4\u8272\u6846\u5f0fground truth\uff0c\u7ea2\u6846\u662f\u5bf9\u8c61\u4e2d\u5fc3\u70b9\u6240\u5728\u7684\u7f51\u683c\u3002 3.5 logistic\u56de\u5f52 \u00b6 \u9884\u6d4b\u5bf9\u8c61\u7c7b\u522b\u65f6\u4e0d\u4f7f\u7528softmax\uff0c\u800c\u662f\u88ab\u66ff\u6362\u4e3a\u4e00\u4e2a1x1\u7684\u5377\u79ef\u5c42+logistic\u6fc0\u6d3b\u51fd\u6570\u7684\u7ed3\u6784\u3002\u4f7f\u7528softmax\u5c42\u7684\u65f6\u5019\u5176\u5b9e\u5df2\u7ecf\u5047\u8bbe\u6bcf\u4e2a\u8f93\u51fa\u4ec5\u5bf9\u5e94\u67d0\u4e00\u4e2a\u5355\u4e2a\u7684class\uff0c\u4f46\u662f\u5728\u67d0\u4e9bclass\u5b58\u5728\u91cd\u53e0\u60c5\u51b5\uff08\u4f8b\u5982woman\u548cperson\uff09\u7684\u6570\u636e\u96c6\u4e2d\uff0c\u4f7f\u7528softmax\u5c31\u4e0d\u80fd\u4f7f\u7f51\u7edc\u5bf9\u6570\u636e\u8fdb\u884c\u5f88\u597d\u7684\u9884\u6d4b\u3002 3.6 yoloV3\u6a21\u578b\u7684\u8f93\u5165\u4e0e\u8f93\u51fa \u00b6 YoloV3\u7684\u8f93\u5165\u8f93\u51fa\u5f62\u5f0f\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8f93\u5165416\u00d7416\u00d73\u7684\u56fe\u50cf\uff0c\u901a\u8fc7darknet\u7f51\u7edc\u5f97\u5230\u4e09\u79cd\u4e0d\u540c\u5c3a\u5ea6\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u6bcf\u4e2a\u5c3a\u5ea6\u90fd\u5bf9\u5e94N\u4e2a\u901a\u9053\uff0c\u5305\u542b\u7740\u9884\u6d4b\u7684\u4fe1\u606f\uff1b \u6bcf\u4e2a\u7f51\u683c\u6bcf\u4e2a\u5c3a\u5bf8\u7684anchors\u7684\u9884\u6d4b\u7ed3\u679c\u3002 YOLOv3\u5171\u670913\u00d713\u00d73 + 26\u00d726\u00d73 + 52\u00d752\u00d73\u4e2a\u9884\u6d4b \u3002\u6bcf\u4e2a\u9884\u6d4b\u5bf9\u5e9485\u7ef4\uff0c\u5206\u522b\u662f4\uff08\u5750\u6807\u503c\uff09\u30011\uff08\u7f6e\u4fe1\u5ea6\u5206\u6570\uff09\u300180\uff08coco\u7c7b\u522b\u6982\u7387\uff09\u3002 4.yoloV4[\u4e86\u89e3] \u00b6 YOLO\u4e4b\u7236\u57282020\u5e74\u521d\u5ba3\u5e03\u9000\u51faCV\u754c\uff0cYOLOv4 \u7684\u4f5c\u8005\u5e76\u4e0d\u662fYOLO\u7cfb\u5217 \u7684\u539f\u4f5c\u8005\u3002YOLO V4\u662fYOLO\u7cfb\u5217\u4e00\u4e2a\u91cd\u5927\u7684\u66f4\u65b0\uff0c\u5176\u5728COCO\u6570\u636e\u96c6\u4e0a\u7684\u5e73\u5747\u7cbe\u5ea6(AP)\u548c\u5e27\u7387\u7cbe\u5ea6(FPS)\u5206\u522b\u63d0\u9ad8\u4e8610% \u548c12%\uff0c\u5e76\u5f97\u5230\u4e86Joseph Redmon\u7684\u5b98\u65b9\u8ba4\u53ef\uff0c\u88ab\u8ba4\u4e3a\u662f\u5f53\u524d\u6700\u5f3a\u7684\u5b9e\u65f6\u5bf9\u8c61\u68c0\u6d4b\u6a21\u578b\u4e4b\u4e00\u3002 yoloV4\u603b\u7ed3\u4e86\u5927\u90e8\u5206\u68c0\u6d4b\u6280\u5de7\uff0c\u7136\u540e\u7ecf\u8fc7\u7b5b\u9009\uff0c\u6392\u5217\u7ec4\u5408\uff0c\u6328\u4e2a\u5b9e\u9a8c\uff08ablation study\uff09\u54ea\u4e9b\u65b9\u6cd5\u6709\u6548\uff0c\u603b\u4f53\u6765\u8bf4\uff0cYolov4\u5e76\u6ca1\u6709\u521b\u9020\u65b0\u7684\u6539\u8fdb\uff0c\u800c\u662f\u4f7f\u7528\u4e86\u5927\u91cf\u7684\u76ee\u6807\u68c0\u6d4b\u7684\u6280\u5de7\u3002\u5728\u8fd9\u91cc\u6211\u4eec\u4e3b\u8981\u7ed9\u5927\u5bb6\u770b\u4e0b\u5b83\u7684\u7f51\u7edc\u67b6\u6784\uff1a Yolov4\u7684\u7ed3\u6784\u56fe\u548cYolov3\u662f\u76f8\u4f3c\u7684\uff0c\u4e0d\u8fc7\u4f7f\u7528\u5404\u79cd\u65b0\u7684\u7b97\u6cd5\u601d\u60f3\u5bf9\u5404\u4e2a\u5b50\u7ed3\u6784\u90fd\u8fdb\u884c\u4e86\u6539\u8fdb\u3002 \u5148\u6574\u7406\u4e0bYolov4\u7684\u7ed3\u6784\u7ec4\u4ef6 \u57fa\u672c\u7ec4\u4ef6\uff1a CBM\uff1aYolov4\u7f51\u7edc\u7ed3\u6784\u4e2d\u7684\u6700\u5c0f\u7ec4\u4ef6\uff0c\u7531Conv+Bn+Mish\u6fc0\u6d3b\u51fd\u6570\u4e09\u8005\u7ec4\u6210\u3002 CBL\uff1a\u7531Conv+Bn+Leaky_relu\u6fc0\u6d3b\u51fd\u6570\u4e09\u8005\u7ec4\u6210\u3002 Res unit\uff1a\u501f\u9274Resnet\u7f51\u7edc\u4e2d\u7684\u6b8b\u5dee\u7ed3\u6784\uff0c\u8ba9\u7f51\u7edc\u53ef\u4ee5\u6784\u5efa\u7684\u66f4\u6df1\u3002 CSPX\uff1a\u7531\u4e09\u4e2a\u5377\u79ef\u5c42\u548cX\u4e2aRes unint\u6a21\u5757Concate\u7ec4\u6210\u3002 SPP\uff1a\u91c7\u75281\u00d71\uff0c5\u00d75\uff0c9\u00d79\uff0c13\u00d713\u7684\u6700\u5927\u6c60\u5316\u7684\u65b9\u5f0f\uff0c\u8fdb\u884c\u591a\u5c3a\u5ea6\u878d\u5408\u3002 \u5176\u4ed6\u57fa\u7840\u64cd\u4f5c\uff1a Concat\uff1a\u5f20\u91cf\u62fc\u63a5\uff0c\u7ef4\u5ea6\u4f1a\u6269\u5145\uff0c\u548cYolov3\u4e2d\u7684\u89e3\u91ca\u4e00\u6837\uff0c\u5bf9\u5e94\u4e8ecfg\u6587\u4ef6\u4e2d\u7684route\u64cd\u4f5c\u3002 Add\uff1a\u5f20\u91cf\u76f8\u52a0\uff0c\u4e0d\u4f1a\u6269\u5145\u7ef4\u5ea6\uff0c\u5bf9\u5e94\u4e8ecfg\u6587\u4ef6\u4e2d\u7684shortcut\u64cd\u4f5c\u3002 Backbone\u4e2d\u5377\u79ef\u5c42\u7684\u6570\u91cf\uff1a \u6bcf\u4e2aCSPX\u4e2d\u5305\u542b3+2\u00d7X\u4e2a\u5377\u79ef\u5c42\uff0c\u56e0\u6b64\u6574\u4e2a\u4e3b\u5e72\u7f51\u7edcBackbone\u4e2d\u4e00\u5171\u5305\u542b2+\uff083+2\u00d71\uff09+2+\uff083+2\u00d72\uff09+2+\uff083+2\u00d78\uff09+2+\uff083+2\u00d78\uff09+2+\uff083+2\u00d74\uff09+1=72\u3002 \u6ce8\u610f\uff1a \u7f51\u7edc\u7684\u8f93\u5165\u5927\u5c0f\u4e0d\u662f\u56fa\u5b9a\u7684\uff0c\u5728yoloV3\u4e2d\u8f93\u5165\u9ed8\u8ba4\u662f416\u00d7416\uff0c\u5728yoloV4\u4e2d\u9ed8\u8ba4\u662f608\u00d7608\uff0c\u5728\u5b9e\u9645\u9879\u76ee\u4e2d\u4e5f\u53ef\u4ee5\u6839\u636e\u9700\u8981\u4fee\u6539\uff0c\u6bd4\u5982320\u00d7320\uff0c\u4e00\u822c\u662f32\u7684\u500d\u6570\u3002 \u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u548c\u6700\u540e\u7684\u4e09\u4e2a\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u4e5f\u662f\u5bf9\u5e94\u7684\uff0c\u6bd4\u5982416\u00d7416\u7684\u8f93\u5165\uff0c\u6700\u540e\u7684\u4e09\u4e2a\u7279\u5f81\u56fe\u5927\u5c0f\u662f13\u00d713\uff0c26\u00d726\uff0c52\u00d752\uff0c \u5982\u679c\u662f608\u00d7608\uff0c\u6700\u540e\u7684\u4e09\u4e2a\u7279\u5f81\u56fe\u5927\u5c0f\u5219\u662f19\u00d719\uff0c38\u00d738\uff0c76\u00d776\u3002 \u603b\u7ed3 \u77e5\u9053yolo\u7f51\u7edc\u67b6\u6784\uff0c\u7406\u89e3\u5176\u8f93\u5165\u8f93\u51fa YOLO\u7684\u6574\u4e2a\u7ed3\u6784\u5c31\u662f\u8f93\u5165\u56fe\u7247\u7ecf\u8fc7\u795e\u7ecf\u7f51\u7edc\u7684\u53d8\u6362\u5f97\u5230\u4e00\u4e2a\u8f93\u51fa\u7684\u5f20\u91cf \u77e5\u9053yolo\u6a21\u578b\u7684\u8bad\u7ec3\u6837\u672c\u6784\u5efa\u7684\u65b9\u6cd5 \u5bf9\u4e8e\u539f\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e00\u4e2a\u7f51\u683cgrid\u90fd\u9700\u8981\u6784\u5efa\u4e00\u4e2a30\u7ef4\u7684\u5411\u91cf\uff1a\u5206\u7c7b\uff0c\u7f6e\u4fe1\u5ea6\uff0c\u56de\u5f52\u7684\u76ee\u6807\u503c \u7406\u89e3yolo\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570 \u635f\u5931\u51fd\u6570\u5206\u4e3a3\u90e8\u5206\uff1a\u5206\u7c7b\u635f\u5931\uff0c\u56de\u5f52\u635f\u5931\uff0c\u7f6e\u4fe1\u5ea6\u635f\u5931 \u77e5\u9053yoloV2\u6a21\u578b\u7684\u6539\u8fdb\u65b9\u6cd5 \u4f7f\u7528\u4e86BN\u5c42\uff0c\u9ad8\u5206\u8fa8\u7387\u8bad\u7ec3\uff0c\u91c7\u7528Anchorbox\uff0c\u805a\u7c7b\u5f97\u5230anchorbox\u7684\u5c3a\u5bf8\uff0c\u6539\u8fdb\u8fb9\u754c\u6846\u9884\u6d4b\u7684\u65b9\u6cd5\uff0c\u7279\u5f81\u878d\u5408\uff0c\u591a\u5c3a\u5ea6\u8bad\u7ec3\uff0c\u7f51\u7edc\u6a21\u578b\u4f7f\u7528darknet19\uff0c\u5229\u7528imagenet\u6570\u636e\u96c6\u8bc6\u522b\u66f4\u591a\u7684\u76ee\u6807 yoloV3\u7684\u591a\u5c3a\u5ea6\u68c0\u6d4b\u65b9\u6cd5 \u5728YOLOv3\u4e2d\u91c7\u7528FPN\u7ed3\u6784\u6765\u63d0\u9ad8\u5bf9\u5e94\u591a\u5c3a\u5ea6\u76ee\u6807\u68c0\u6d4b\u7684\u7cbe\u5ea6\uff0c\u5f53\u524d\u7684feature map\u5229\u7528\u201c\u672a\u6765\u201d\u5c42\u7684\u4fe1\u606f\uff0c\u5c06\u4f4e\u9636\u7279\u5f81\u4e0e\u9ad8\u9636\u7279\u5f81\u8fdb\u884c\u878d\u5408\uff0c\u63d0\u5347\u68c0\u6d4b\u7cbe\u5ea6\u3002 yoloV3\u6a21\u578b\u7684\u7f51\u7edc\u7ed3\u6784 \u4ee5darknet-53\u4e3a\u57fa\u7840\uff0c\u501f\u9274resnet\u7684\u601d\u60f3\uff0c\u5728\u7f51\u7edc\u4e2d\u52a0\u5165\u4e86\u6b8b\u5dee\u6a21\u5757\uff0c\u5229\u4e8e\u89e3\u51b3\u6df1\u5c42\u6b21\u7f51\u7edc\u7684\u68af\u5ea6\u95ee\u9898 \u6574\u4e2av3\u7ed3\u6784\u91cc\u9762\uff0c\u6ca1\u6709\u6c60\u5316\u5c42\u548c\u5168\u8fde\u63a5\u5c42\uff0c\u53ea\u6709\u5377\u79ef\u5c42 \u7f51\u7edc\u7684\u4e0b\u91c7\u6837\u662f\u901a\u8fc7\u8bbe\u7f6e\u5377\u79ef\u7684stride\u4e3a2\u6765\u8fbe\u5230\u7684 yoloV3\u6a21\u578b\u5148\u9a8c\u6846\u8bbe\u8ba1\u7684\u65b9\u6cd5 \u91c7\u7528K-means\u805a\u7c7b\u5f97\u5230\u5148\u9a8c\u6846\u7684\u5c3a\u5bf8\uff0c\u4e3a\u6bcf\u79cd\u5c3a\u5ea6\u8bbe\u5b9a3\u79cd\u5148\u9a8c\u6846\uff0c\u603b\u5171\u805a\u7c7b\u51fa9\u79cd\u5c3a\u5bf8\u7684\u5148\u9a8c\u6846\u3002 yoloV3\u6a21\u578b\u4e3a\u4ec0\u4e48\u9002\u7528\u4e8e\u591a\u6807\u7b7e\u7684\u76ee\u6807\u5206\u7c7b \u9884\u6d4b\u5bf9\u8c61\u7c7b\u522b\u65f6\u4e0d\u4f7f\u7528softmax\uff0c\u800c\u662f\u4f7f\u7528logistic\u7684\u8f93\u51fa\u8fdb\u884c\u9884\u6d4b yoloV3\u6a21\u578b\u7684\u8f93\u5165\u8f93\u51fa \u5bf9\u4e8e416\u00d7416\u00d73\u7684\u8f93\u5165\u56fe\u50cf\uff0c\u5728\u6bcf\u4e2a\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u7684\u6bcf\u4e2a\u7f51\u683c\u8bbe\u7f6e3\u4e2a\u5148\u9a8c\u6846\uff0c\u603b\u5171\u6709 13\u00d713\u00d73 + 26\u00d726\u00d73 + 52\u00d752\u00d73 = 10647 \u4e2a\u9884\u6d4b\u3002\u6bcf\u4e00\u4e2a\u9884\u6d4b\u662f\u4e00\u4e2a(4+1+80)=85\u7ef4\u5411\u91cf\uff0c\u8fd9\u4e2a85\u7ef4\u5411\u91cf\u5305\u542b\u8fb9\u6846\u5750\u6807\uff084\u4e2a\u6570\u503c\uff09\uff0c\u8fb9\u6846\u7f6e\u4fe1\u5ea6\uff081\u4e2a\u6570\u503c\uff09\uff0c\u5bf9\u8c61\u7c7b\u522b\u7684\u6982\u7387\uff08\u5bf9\u4e8eCOCO\u6570\u636e\u96c6\uff0c\u670980\u79cd\u5bf9\u8c61\uff09\u3002","title":"YOLO\u7cfb\u5217\u7b97\u6cd5"},{"location":"objectdection/04.yolo/#44yolo","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053yolo\u7f51\u7edc\u67b6\u6784\uff0c\u7406\u89e3\u5176\u8f93\u5165\u8f93\u51fa \u77e5\u9053yolo\u6a21\u578b\u7684\u8bad\u7ec3\u6837\u672c\u6784\u5efa\u7684\u65b9\u6cd5 \u7406\u89e3yolo\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570 \u77e5\u9053yoloV2\u6a21\u578b\u7684\u6539\u8fdb\u65b9\u6cd5 \u77e5\u9053yoloV3\u7684\u591a\u5c3a\u5ea6\u68c0\u6d4b\u65b9\u6cd5 \u77e5\u9053yoloV3\u6a21\u578b\u7684\u7f51\u7edc\u7ed3\u6784\u53ca\u7f51\u7edc\u8f93\u51fa \u4e86\u89e3yoloV3\u6a21\u578b\u5148\u9a8c\u6846\u8bbe\u8ba1\u7684\u65b9\u6cd5 \u77e5\u9053yoloV3\u6a21\u578b\u4e3a\u4ec0\u4e48\u9002\u7528\u4e8e\u591a\u6807\u7b7e\u7684\u76ee\u6807\u5206\u7c7b \u4e86\u89e3yoloV4\u6a21\u578b YOLO\u7cfb\u5217\u7b97\u6cd5\u662f\u4e00\u7c7b\u5178\u578b\u7684one-stage\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\uff0c\u5176\u5229\u7528anchor box\u5c06\u5206\u7c7b\u4e0e\u76ee\u6807\u5b9a\u4f4d\u7684\u56de\u5f52\u95ee\u9898\u7ed3\u5408\u8d77\u6765\uff0c\u4ece\u800c\u505a\u5230\u4e86\u9ad8\u6548\u3001\u7075\u6d3b\u548c\u6cdb\u5316\u6027\u80fd\u597d\uff0c\u6240\u4ee5\u5728\u5de5\u4e1a\u754c\u4e5f\u5341\u5206\u53d7\u6b22\u8fce\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u4ecb\u7ecdYOLO \u7cfb\u5217\u7b97\u6cd5\u3002","title":"4.4.yolo\u7cfb\u5217"},{"location":"objectdection/04.yolo/#1yolo","text":"Yolo\u7b97\u6cd5\u91c7\u7528\u4e00\u4e2a\u5355\u72ec\u7684CNN\u6a21\u578b\u5b9e\u73b0end-to-end\u7684\u76ee\u6807\u68c0\u6d4b\uff0c\u6838\u5fc3\u601d\u60f3\u5c31\u662f\u5229\u7528\u6574\u5f20\u56fe\u4f5c\u4e3a\u7f51\u7edc\u7684\u8f93\u5165\uff0c\u76f4\u63a5\u5728\u8f93\u51fa\u5c42\u56de\u5f52 bounding box\uff08\u8fb9\u754c\u6846\uff09 \u7684\u4f4d\u7f6e\u53ca\u5176\u6240\u5c5e\u7684\u7c7b\u522b\uff0c\u6574\u4e2a\u7cfb\u7edf\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u9996\u5148\u5c06\u8f93\u5165\u56fe\u7247resize\u5230448x448\uff0c\u7136\u540e\u9001\u5165CNN\u7f51\u7edc\uff0c\u6700\u540e\u5904\u7406\u7f51\u7edc\u9884\u6d4b\u7ed3\u679c\u5f97\u5230\u68c0\u6d4b\u7684\u76ee\u6807\u3002\u76f8\u6bd4R-CNN\u7b97\u6cd5\uff0c\u5176\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u5176\u901f\u5ea6\u66f4\u5feb\u3002","title":"1.yolo\u7b97\u6cd5"},{"location":"objectdection/04.yolo/#11-yolo","text":"\u5728\u4ecb\u7ecdYolo\u7b97\u6cd5\u4e4b\u524d\uff0c\u6211\u4eec\u56de\u5fc6\u4e0bRCNN\u6a21\u578b\uff0cRCNN\u6a21\u578b\u63d0\u51fa\u4e86\u5019\u9009\u533a(Region Proposals)\u7684\u65b9\u6cd5\uff0c\u5148\u4ece\u56fe\u7247\u4e2d\u641c\u7d22\u51fa\u4e00\u4e9b\u53ef\u80fd\u5b58\u5728\u5bf9\u8c61\u7684\u5019\u9009\u533a\uff08Selective Search\uff09\uff0c\u5927\u69822000\u4e2a\u5de6\u53f3\uff0c\u7136\u540e\u5bf9\u6bcf\u4e2a\u5019\u9009\u533a\u8fdb\u884c\u5bf9\u8c61\u8bc6\u522b\uff0c\u4f46\u5904\u7406\u901f\u5ea6\u8f83\u6162\u3002 Yolo\u610f\u601d\u662fYou Only Look Once\uff0c\u5b83\u5e76\u6ca1\u6709\u771f\u6b63\u7684\u53bb\u6389\u5019\u9009\u533a\u57df\uff0c\u800c\u662f\u521b\u9020\u6027\u7684\u5c06\u5019\u9009\u533a\u548c\u76ee\u6807\u5206\u7c7b\u5408\u4e8c\u4e3a\u4e00\uff0c\u770b\u4e00\u773c\u56fe\u7247\u5c31\u80fd\u77e5\u9053\u6709\u54ea\u4e9b\u5bf9\u8c61\u4ee5\u53ca\u5b83\u4eec\u7684\u4f4d\u7f6e\u3002 Yolo\u6a21\u578b\u91c7\u7528\u9884\u5b9a\u4e49\u9884\u6d4b\u533a\u57df\u7684\u65b9\u6cd5\u6765\u5b8c\u6210\u76ee\u6807\u68c0\u6d4b\uff0c\u5177\u4f53\u800c\u8a00\u662f\u5c06\u539f\u59cb\u56fe\u50cf\u5212\u5206\u4e3a 7x7=49 \u4e2a\u7f51\u683c\uff08grid\uff09\uff0c\u6bcf\u4e2a\u7f51\u683c\u5141\u8bb8\u9884\u6d4b\u51fa2\u4e2a\u8fb9\u6846\uff08bounding box\uff0c\u5305\u542b\u67d0\u4e2a\u5bf9\u8c61\u7684\u77e9\u5f62\u6846\uff09\uff0c\u603b\u5171 49x2=98 \u4e2abounding box\u3002\u6211\u4eec\u5c06\u5176\u7406\u89e3\u4e3a98\u4e2a\u9884\u6d4b\u533a\uff0c\u5f88\u7c97\u7565\u7684\u8986\u76d6\u4e86\u56fe\u7247\u7684\u6574\u4e2a\u533a\u57df\uff0c\u5c31\u5728\u8fd998\u4e2a\u9884\u6d4b\u533a\u4e2d\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u3002 \u53ea\u8981\u5f97\u5230\u8fd998\u4e2a\u533a\u57df\u7684\u76ee\u6807\u5206\u7c7b\u548c\u56de\u5f52\u7ed3\u679c\uff0c\u518d\u8fdb\u884cNMS\u5c31\u53ef\u4ee5\u5f97\u5230\u6700\u7ec8\u7684\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c\u3002\u90a3\u5177\u4f53\u8981\u600e\u6837\u5b9e\u73b0\u5462\uff1f","title":"1.1 Yolo\u7b97\u6cd5\u601d\u60f3"},{"location":"objectdection/04.yolo/#12-yolo","text":"YOLO\u7684\u7ed3\u6784\u975e\u5e38\u7b80\u5355\uff0c\u5c31\u662f\u5355\u7eaf\u7684\u5377\u79ef\u3001\u6c60\u5316\u6700\u540e\u52a0\u4e86\u4e24\u5c42\u5168\u8fde\u63a5\uff0c\u4ece\u7f51\u7edc\u7ed3\u6784\u4e0a\u770b\uff0c\u4e0e\u524d\u9762\u4ecb\u7ecd\u7684CNN\u5206\u7c7b\u7f51\u7edc\u6ca1\u6709\u672c\u8d28\u7684\u533a\u522b\uff0c\u6700\u5927\u7684\u5dee\u5f02\u662f\u8f93\u51fa\u5c42\u7528\u7ebf\u6027\u51fd\u6570\u505a\u6fc0\u6d3b\u51fd\u6570\uff0c\u56e0\u4e3a\u9700\u8981\u9884\u6d4bbounding box\u7684\u4f4d\u7f6e\uff08\u6570\u503c\u578b\uff09\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5bf9\u8c61\u7684\u6982\u7387\u3002\u6240\u4ee5\u7c97\u7565\u6765\u8bf4\uff0cYOLO\u7684\u6574\u4e2a\u7ed3\u6784\u5c31\u662f\u8f93\u5165\u56fe\u7247\u7ecf\u8fc7\u795e\u7ecf\u7f51\u7edc\u7684\u53d8\u6362\u5f97\u5230\u4e00\u4e2a\u8f93\u51fa\u7684\u5f20\u91cf\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7f51\u7edc\u7ed3\u6784\u6bd4\u8f83\u7b80\u5355\uff0c\u91cd\u70b9\u662f\u6211\u4eec\u8981\u7406\u89e3\u7f51\u7edc\u8f93\u5165\u4e0e\u8f93\u51fa\u4e4b\u95f4\u7684\u5173\u7cfb\u3002","title":"1.2 Yolo\u7684\u7f51\u7edc\u7ed3\u6784"},{"location":"objectdection/04.yolo/#121","text":"\u7f51\u7edc\u7684\u8f93\u5165\u662f\u539f\u59cb\u56fe\u50cf\uff0c\u552f\u4e00\u7684\u8981\u6c42\u662f\u7f29\u653e\u5230448x448\u7684\u5927\u5c0f\u3002\u4e3b\u8981\u662f\u56e0\u4e3aYolo\u7684\u7f51\u7edc\u4e2d\uff0c\u5377\u79ef\u5c42\u6700\u540e\u63a5\u4e86\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u5168\u8fde\u63a5\u5c42\u662f\u8981\u6c42\u56fa\u5b9a\u5927\u5c0f\u7684\u5411\u91cf\u4f5c\u4e3a\u8f93\u5165\uff0c\u6240\u4ee5Yolo\u7684\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u56fa\u5b9a\u4e3a448x448\u3002","title":"1.2.1 \u7f51\u7edc\u8f93\u5165"},{"location":"objectdection/04.yolo/#122","text":"\u7f51\u7edc\u7684\u8f93\u51fa\u5c31\u662f\u4e00\u4e2a7x7x30 \u7684\u5f20\u91cf\uff08tensor\uff09\u3002\u90a3\u8fd9\u4e2a\u8f93\u51fa\u7ed3\u679c\u6211\u4eec\u8981\u600e\u4e48\u7406\u89e3\u90a3\uff1f","title":"1.2.2 \u7f51\u7edc\u8f93\u51fa"},{"location":"objectdection/04.yolo/#17x7","text":"\u6839\u636eYOLO\u7684\u8bbe\u8ba1\uff0c\u8f93\u5165\u56fe\u50cf\u88ab\u5212\u5206\u4e3a 7x7 \u7684\u7f51\u683c\uff08grid\uff09\uff0c\u8f93\u51fa\u5f20\u91cf\u4e2d\u7684 7x7 \u5c31\u5bf9\u5e94\u7740\u8f93\u5165\u56fe\u50cf\u7684 7x7 \u7f51\u683c\u3002\u6216\u8005\u6211\u4eec\u628a 7x7x30 \u7684\u5f20\u91cf\u770b\u4f5c 7x7=49\u4e2a30\u7ef4\u7684\u5411\u91cf\uff0c\u4e5f\u5c31\u662f\u8f93\u5165\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e2a\u7f51\u683c\u5bf9\u5e94\u8f93\u51fa\u4e00\u4e2a30\u7ef4\u7684\u5411\u91cf\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u6bd4\u5982\u8f93\u5165\u56fe\u50cf\u5de6\u4e0a\u89d2\u7684\u7f51\u683c\u5bf9\u5e94\u5230\u8f93\u51fa\u5f20\u91cf\u4e2d\u5de6\u4e0a\u89d2\u7684\u5411\u91cf\u3002","title":"1.7x7\u7f51\u683c"},{"location":"objectdection/04.yolo/#230","text":"30\u7ef4\u7684\u5411\u91cf\u5305\u542b\uff1a2\u4e2abbox\u7684\u4f4d\u7f6e\u548c\u7f6e\u4fe1\u5ea6\u4ee5\u53ca\u8be5\u7f51\u683c\u5c5e\u4e8e20\u4e2a\u7c7b\u522b\u7684\u6982\u7387 2\u4e2abounding box\u7684\u4f4d\u7f6e \u6bcf\u4e2abounding box\u9700\u89814\u4e2a\u6570\u503c\u6765\u8868\u793a\u5176\u4f4d\u7f6e\uff0c(Center_x,Center_y,width,height)\uff0c\u5373(bounding box\u7684\u4e2d\u5fc3\u70b9\u7684x\u5750\u6807\uff0cy\u5750\u6807\uff0cbounding box\u7684\u5bbd\u5ea6\uff0c\u9ad8\u5ea6)\uff0c2\u4e2abounding box\u5171\u9700\u89818\u4e2a\u6570\u503c\u6765\u8868\u793a\u5176\u4f4d\u7f6e\u3002 2\u4e2abounding box\u7684\u7f6e\u4fe1\u5ea6 bounding box\u7684\u7f6e\u4fe1\u5ea6 = \u8be5bounding box\u5185\u5b58\u5728\u5bf9\u8c61\u7684\u6982\u7387 * \u8be5bounding box\u4e0e\u8be5\u5bf9\u8c61\u5b9e\u9645bounding box\u7684IOU\uff0c\u7528\u516c\u5f0f\u8868\u793a\u5c31\u662f\uff1a Pr(Object)\u662fbounding box\u5185\u5b58\u5728\u5bf9\u8c61\u7684\u6982\u7387 20\u4e2a\u5bf9\u8c61\u5206\u7c7b\u7684\u6982\u7387 Yolo\u652f\u6301\u8bc6\u522b20\u79cd\u4e0d\u540c\u7684\u5bf9\u8c61\uff08\u4eba\u3001\u9e1f\u3001\u732b\u3001\u6c7d\u8f66\u3001\u6905\u5b50\u7b49\uff09\uff0c\u6240\u4ee5\u8fd9\u91cc\u670920\u4e2a\u503c\u8868\u793a\u8be5\u7f51\u683c\u4f4d\u7f6e\u5b58\u5728\u4efb\u4e00\u79cd\u5bf9\u8c61\u7684\u6982\u7387.","title":"2.30\u7ef4\u5411\u91cf"},{"location":"objectdection/04.yolo/#13yolo","text":"\u5728\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u65f6\uff0c\u6211\u4eec\u9700\u8981\u6784\u9020\u8bad\u7ec3\u6837\u672c\u548c\u8bbe\u8ba1\u635f\u5931\u51fd\u6570\uff0c\u624d\u80fd\u5229\u7528\u68af\u5ea6\u4e0b\u964d\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u3002","title":"1.3Yolo\u6a21\u578b\u7684\u8bad\u7ec3"},{"location":"objectdection/04.yolo/#131","text":"\u5c06\u4e00\u5e45\u56fe\u7247\u8f93\u5165\u5230yolo\u6a21\u578b\u4e2d\uff0c\u5bf9\u5e94\u7684\u8f93\u51fa\u662f\u4e00\u4e2a7x7x30\u5f20\u91cf\uff0c\u6784\u5efa\u6807\u7b7elabel\u65f6\u5bf9\u4e8e\u539f\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e00\u4e2a\u7f51\u683cgrid\u90fd\u9700\u8981\u6784\u5efa\u4e00\u4e2a30\u7ef4\u7684\u5411\u91cf\u3002\u5bf9\u7167\u4e0b\u56fe\u6211\u4eec\u6765\u6784\u5efa\u76ee\u6807\u5411\u91cf\uff1a 20\u4e2a\u5bf9\u8c61\u5206\u7c7b\u7684\u6982\u7387 \u5bf9\u4e8e\u8f93\u5165\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e2a\u5bf9\u8c61\uff0c\u5148\u627e\u5230\u5176\u4e2d\u5fc3\u70b9\u3002\u6bd4\u5982\u4e0a\u56fe\u4e2d\u81ea\u884c\u8f66\uff0c\u5176\u4e2d\u5fc3\u70b9\u5728\u9ec4\u8272\u5706\u70b9\u4f4d\u7f6e\uff0c\u4e2d\u5fc3\u70b9\u843d\u5728\u9ec4\u8272\u7f51\u683c\u5185\uff0c\u6240\u4ee5\u8fd9\u4e2a\u9ec4\u8272\u7f51\u683c\u5bf9\u5e94\u768430\u7ef4\u5411\u91cf\u4e2d\uff0c\u81ea\u884c\u8f66\u7684\u6982\u7387\u662f1\uff0c\u5176\u5b83\u5bf9\u8c61\u7684\u6982\u7387\u662f0\u3002\u6240\u6709\u5176\u5b8348\u4e2a\u7f51\u683c\u768430\u7ef4\u5411\u91cf\u4e2d\uff0c\u8be5\u81ea\u884c\u8f66\u7684\u6982\u7387\u90fd\u662f0\u3002\u8fd9\u5c31\u662f\u6240\u8c13\u7684\"\u4e2d\u5fc3\u70b9\u6240\u5728\u7684\u7f51\u683c\u5bf9\u9884\u6d4b\u8be5\u5bf9\u8c61\u8d1f\u8d23\"\u3002\u72d7\u548c\u6c7d\u8f66\u7684\u5206\u7c7b\u6982\u7387\u4e5f\u662f\u540c\u6837\u7684\u65b9\u6cd5\u586b\u5199 2\u4e2abounding box\u7684\u4f4d\u7f6e \u8bad\u7ec3\u6837\u672c\u7684bbox\u4f4d\u7f6e\u5e94\u8be5\u586b\u5199\u5bf9\u8c61\u771f\u5b9e\u7684\u4f4d\u7f6ebbox\uff0c\u4f46\u4e00\u4e2a\u5bf9\u8c61\u5bf9\u5e94\u4e862\u4e2abounding box\uff0c\u8be5\u586b\u54ea\u4e00\u4e2a\u5462\uff1f\u9700\u8981\u6839\u636e\u7f51\u7edc\u8f93\u51fa\u7684bbox\u4e0e\u5bf9\u8c61\u5b9e\u9645bbox\u7684IOU\u6765\u9009\u62e9\uff0c\u6240\u4ee5\u8981\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u52a8\u6001\u51b3\u5b9a\u5230\u5e95\u586b\u54ea\u4e00\u4e2abbox\u3002 2\u4e2abounding box\u7684\u7f6e\u4fe1\u5ea6 \u9884\u6d4b\u7f6e\u4fe1\u5ea6\u7684\u516c\u5f0f\u4e3a\uff1a IOU_{pred}^{truth} IOU_{pred}^{truth} \u5229\u7528\u7f51\u7edc\u8f93\u51fa\u76842\u4e2abounding box\u4e0e\u5bf9\u8c61\u771f\u5b9ebounding box\u8ba1\u7b97\u51fa\u6765\u3002\u7136\u540e\u770b\u8fd92\u4e2abounding box\u7684IOU\uff0c\u54ea\u4e2a\u6bd4\u8f83\u5927\uff0c\u5c31\u7531\u54ea\u4e2abounding box\u6765\u8d1f\u8d23\u9884\u6d4b\u8be5\u5bf9\u8c61\u662f\u5426\u5b58\u5728\uff0c\u5373\u8be5bounding box\u7684Pr(Object)=1\uff0c\u540c\u65f6\u5bf9\u8c61\u771f\u5b9ebounding box\u7684\u4f4d\u7f6e\u4e5f\u5c31\u586b\u5165\u8be5bounding box\u3002\u53e6\u4e00\u4e2a\u4e0d\u8d1f\u8d23\u9884\u6d4b\u7684bounding box\u7684Pr(Object)=0\u3002 \u4e0a\u56fe\u4e2d\u81ea\u884c\u8f66\u6240\u5728\u7684grid\u5bf9\u5e94\u7684\u7ed3\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff1a","title":"1.3.1\u8bad\u7ec3\u6837\u672c\u7684\u6784\u5efa"},{"location":"objectdection/04.yolo/#132","text":"\u635f\u5931\u5c31\u662f\u7f51\u7edc\u5b9e\u9645\u8f93\u51fa\u503c\u4e0e\u6837\u672c\u6807\u7b7e\u503c\u4e4b\u95f4\u7684\u504f\u5dee\uff1a yolo\u7ed9\u51fa\u7684\u635f\u5931\u51fd\u6570\uff1a \u6ce8\uff1a\u5176\u4e2d 1_{i}^{obj} 1_{i}^{obj} \u8868\u793a\u76ee\u6807\u662f\u5426\u51fa\u73b0\u5728\u7f51\u683c\u5355\u5143i\u4e2d\uff0c 1_{ij}^{obj} 1_{ij}^{obj} \u8868\u793a\u5355\u5143\u683ci\u4e2d\u7684\u7b2cj\u4e2a\u8fb9\u754c\u6846\u9884\u6d4b\u5668\u8d1f\u8d23\u8be5\u9884\u6d4b\uff0cYOLO\u8bbe\u7f6e \\lambda_{coord} = 5 \\lambda_{coord} = 5 \u6765\u8c03\u9ad8\u4f4d\u7f6e\u8bef\u5dee\u7684\u6743\u91cd\uff0c \\lambda_{noobj} = 0.5 \\lambda_{noobj} = 0.5 \u5373\u8c03\u4f4e\u4e0d\u5b58\u5728\u5bf9\u8c61\u7684bounding box\u7684\u7f6e\u4fe1\u5ea6\u8bef\u5dee\u7684\u6743\u91cd\u3002","title":"1.3.2 \u635f\u5931\u51fd\u6570"},{"location":"objectdection/04.yolo/#133","text":"Yolo\u5148\u4f7f\u7528ImageNet\u6570\u636e\u96c6\u5bf9\u524d20\u5c42\u5377\u79ef\u7f51\u7edc\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u4f7f\u7528\u5b8c\u6574\u7684\u7f51\u7edc\uff0c\u5728PASCAL VOC\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5bf9\u8c61\u8bc6\u522b\u548c\u5b9a\u4f4d\u7684\u8bad\u7ec3\u3002 Yolo\u7684\u6700\u540e\u4e00\u5c42\u91c7\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff0c\u5176\u5b83\u5c42\u90fd\u662fLeaky ReLU\u3002\u8bad\u7ec3\u4e2d\u91c7\u7528\u4e86drop out\u548c\u6570\u636e\u589e\u5f3a\uff08data augmentation\uff09\u6765\u9632\u6b62\u8fc7\u62df\u5408.","title":"1.3.3 \u6a21\u578b\u8bad\u7ec3"},{"location":"objectdection/04.yolo/#14","text":"\u5c06\u56fe\u7247resize\u6210448x448\u7684\u5927\u5c0f\uff0c\u9001\u5165\u5230yolo\u7f51\u7edc\u4e2d\uff0c\u8f93\u51fa\u4e00\u4e2a 7x7x30 \u7684\u5f20\u91cf\uff08tensor\uff09\u6765\u8868\u793a\u56fe\u7247\u4e2d\u6240\u6709\u7f51\u683c\u5305\u542b\u7684\u5bf9\u8c61\uff08\u6982\u7387\uff09\u4ee5\u53ca\u8be5\u5bf9\u8c61\u53ef\u80fd\u76842\u4e2a\u4f4d\u7f6e\uff08bounding box\uff09\u548c\u53ef\u4fe1\u7a0b\u5ea6\uff08\u7f6e\u4fe1\u5ea6\uff09\u3002\u5728\u91c7\u7528NMS\uff08Non-maximal suppression\uff0c\u975e\u6781\u5927\u503c\u6291\u5236\uff09\u7b97\u6cd5\u9009\u51fa\u6700\u6709\u53ef\u80fd\u662f\u76ee\u6807\u7684\u7ed3\u679c\u3002","title":"1.4 \u6a21\u578b\u9884\u6d4b"},{"location":"objectdection/04.yolo/#15-yolo","text":"\u4f18\u70b9 \u901f\u5ea6\u975e\u5e38\u5feb\uff0c\u5904\u7406\u901f\u5ea6\u53ef\u4ee5\u8fbe\u523045fps\uff0c\u5176\u5feb\u901f\u7248\u672c\uff08\u7f51\u7edc\u8f83\u5c0f\uff09\u751a\u81f3\u53ef\u4ee5\u8fbe\u5230155fps\u3002 \u8bad\u7ec3\u548c\u9884\u6d4b\u53ef\u4ee5\u7aef\u5230\u7aef\u7684\u8fdb\u884c\uff0c\u975e\u5e38\u7b80\u4fbf\u3002 \u7f3a\u70b9 \u51c6\u786e\u7387\u4f1a\u6253\u6298\u6263 \u5bf9\u4e8e\u5c0f\u76ee\u6807\u548c\u9760\u7684\u5f88\u8fd1\u7684\u76ee\u6807\u68c0\u6d4b\u6548\u679c\u5e76\u4e0d\u597d","title":"1.5 yolo\u603b\u7ed3"},{"location":"objectdection/04.yolo/#2yolov2","text":"YOLOv2\u76f8\u5bf9v1\u7248\u672c\uff0c\u5728\u7ee7\u7eed\u4fdd\u6301\u5904\u7406\u901f\u5ea6\u7684\u57fa\u7840\u4e0a\uff0c\u4ece\u9884\u6d4b\u66f4\u51c6\u786e\uff08Better\uff09\uff0c\u901f\u5ea6\u66f4\u5feb\uff08Faster\uff09\uff0c\u8bc6\u522b\u5bf9\u8c61\u66f4\u591a\uff08Stronger\uff09\u8fd9\u4e09\u4e2a\u65b9\u9762\u8fdb\u884c\u4e86\u6539\u8fdb\u3002\u5176\u4e2d\u8bc6\u522b\u66f4\u591a\u5bf9\u8c61\u4e5f\u5c31\u662f\u6269\u5c55\u5230\u80fd\u591f\u68c0\u6d4b9000\u79cd\u4e0d\u540c\u5bf9\u8c61\uff0c\u79f0\u4e4b\u4e3aYOLO9000\u3002 \u4e0b\u9762\u6211\u4eec\u770b\u4e0byoloV2\u7684\u90fd\u505a\u4e86\u54ea\u4e9b\u6539\u8fdb\uff1f","title":"2.yoloV2"},{"location":"objectdection/04.yolo/#21-better","text":"","title":"2.1 \u9884\u6d4b\u66f4\u51c6\u786e\uff08better\uff09"},{"location":"objectdection/04.yolo/#211-batch-normalization","text":"\u6279\u6807\u51c6\u5316\u6709\u52a9\u4e8e\u89e3\u51b3\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u7684\u68af\u5ea6\u6d88\u5931\u548c\u68af\u5ea6\u7206\u70b8\u95ee\u9898\uff0c\u964d\u4f4e\u5bf9\u4e00\u4e9b\u8d85\u53c2\u6570\u7684\u654f\u611f\u6027\uff0c\u5e76\u4e14\u6bcf\u4e2abatch\u5206\u522b\u8fdb\u884c\u5f52\u4e00\u5316\u7684\u65f6\u5019\uff0c\u8d77\u5230\u4e86\u4e00\u5b9a\u7684\u6b63\u5219\u5316\u6548\u679c\uff0c\u4ece\u800c\u80fd\u591f\u83b7\u5f97\u66f4\u597d\u7684\u6536\u655b\u901f\u5ea6\u548c\u6536\u655b\u6548\u679c\u3002\u5728yoloV2\u4e2d\u5377\u79ef\u540e\u5168\u90e8\u52a0\u5165Batch Normalization\uff0c\u7f51\u7edc\u4f1a\u63d0\u53472%\u7684mAP\u3002","title":"2.1.1 batch normalization"},{"location":"objectdection/04.yolo/#212","text":"YOLO v1\u4f7f\u7528ImageNet\u7684\u56fe\u50cf\u5206\u7c7b\u6837\u672c\u91c7\u7528 224x224 \u4f5c\u4e3a\u8f93\u5165\uff0c\u6765\u8bad\u7ec3CNN\u5377\u79ef\u5c42\u3002\u7136\u540e\u5728\u8bad\u7ec3\u5bf9\u8c61\u68c0\u6d4b\u65f6\uff0c\u68c0\u6d4b\u7528\u7684\u56fe\u50cf\u6837\u672c\u91c7\u7528\u66f4\u9ad8\u5206\u8fa8\u7387\u7684 448x448 \u7684\u56fe\u50cf\u4f5c\u4e3a\u8f93\u5165\u3002\u4f46\u8fd9\u6837\u5207\u6362\u5bf9\u6a21\u578b\u6027\u80fd\u6709\u4e00\u5b9a\u5f71\u54cd\u3002 YOLOV2\u5728\u91c7\u7528 224x224 \u56fe\u50cf\u8fdb\u884c\u5206\u7c7b\u6a21\u578b\u9884\u8bad\u7ec3\u540e\uff0c\u518d\u91c7\u7528 448x448 \u7684\u9ad8\u5206\u8fa8\u7387\u6837\u672c\u5bf9\u5206\u7c7b\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0810\u4e2aepoch\uff09\uff0c\u4f7f\u7f51\u7edc\u7279\u5f81\u9010\u6e10\u9002\u5e94 448x448 \u7684\u5206\u8fa8\u7387\u3002\u7136\u540e\u518d\u4f7f\u7528 448x448 \u7684\u68c0\u6d4b\u6837\u672c\u8fdb\u884c\u8bad\u7ec3\uff0c\u7f13\u89e3\u4e86\u5206\u8fa8\u7387\u7a81\u7136\u5207\u6362\u9020\u6210\u7684\u5f71\u54cd\u3002 \u4f7f\u7528\u8be5\u6280\u5de7\u540e\u7f51\u7edc\u7684mAP\u63d0\u5347\u4e86\u7ea64%\u3002","title":"2.1.2 \u4f7f\u7528\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5fae\u8c03\u5206\u7c7b\u6a21\u578b"},{"location":"objectdection/04.yolo/#213-anchor-boxes","text":"YOLO1\u5e76\u6ca1\u6709\u91c7\u7528\u5148\u9a8c\u6846\uff0c\u5e76\u4e14\u6bcf\u4e2agrid\u53ea\u9884\u6d4b\u4e24\u4e2abounding box\uff0c\u6574\u4e2a\u56fe\u50cf98\u4e2a\u3002YOLO2\u5982\u679c\u6bcf\u4e2agrid\u91c7\u75285\u4e2a\u5148\u9a8c\u6846\uff0c\u603b\u5171\u670913x13x5=845\u4e2a\u5148\u9a8c\u6846\u3002\u901a\u8fc7\u5f15\u5165anchor boxes\uff0c\u4f7f\u5f97\u9884\u6d4b\u7684box\u6570\u91cf\u66f4\u591a\uff0813x13xn\uff09\u3002","title":"2.1.3 \u91c7\u7528Anchor Boxes"},{"location":"objectdection/04.yolo/#224-anchor","text":"Faster-rcnn\u9009\u62e9\u7684anchor\u6bd4\u4f8b\u90fd\u662f\u624b\u52a8\u6307\u5b9a\u7684\uff0c\u4f46\u662f\u4e0d\u4e00\u5b9a\u5b8c\u5168\u9002\u5408\u6570\u636e\u96c6\u3002YOLO2\u5c1d\u8bd5\u7edf\u8ba1\u51fa\u66f4\u7b26\u5408\u6837\u672c\u4e2d\u5bf9\u8c61\u5c3a\u5bf8\u7684\u5148\u9a8c\u6846\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u51cf\u5c11\u7f51\u7edc\u5fae\u8c03\u5148\u9a8c\u6846\u5230\u5b9e\u9645\u4f4d\u7f6e\u7684\u96be\u5ea6\u3002YOLO2\u7684\u505a\u6cd5\u662f\u5bf9\u8bad\u7ec3\u96c6\u4e2d\u6807\u6ce8\u7684\u8fb9\u6846\u8fdb\u884c\u805a\u7c7b\u5206\u6790\uff0c\u4ee5\u5bfb\u627e\u5c3d\u53ef\u80fd\u5339\u914d\u6837\u672c\u7684\u8fb9\u6846\u5c3a\u5bf8\u3002 YoloV2\u9009\u62e9\u4e86\u805a\u7c7b\u7684\u4e94\u79cd\u5c3a\u5bf8\u6700\u4e3aanchor box\u3002","title":"2.2.4 \u805a\u7c7b\u63d0\u53d6anchor\u5c3a\u5ea6"},{"location":"objectdection/04.yolo/#215","text":"Yolov2\u4e2d\u5c06\u8fb9\u6846\u7684\u7ed3\u679c\u7ea6\u675f\u5728\u7279\u5b9a\u7684\u7f51\u683c\u4e2d\uff1a \u5176\u4e2d\uff0c b_x,b_y,b_w,b_h b_x,b_y,b_w,b_h \u662f\u9884\u6d4b\u8fb9\u6846\u7684\u4e2d\u5fc3\u548c\u5bbd\u9ad8\u3002 Pr(object)\u2217IOU(b,object) Pr(object)\u2217IOU(b,object) \u662f\u9884\u6d4b\u8fb9\u6846\u7684\u7f6e\u4fe1\u5ea6\uff0cYOLO1\u662f\u76f4\u63a5\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u7684\u503c\uff0c\u8fd9\u91cc\u5bf9\u9884\u6d4b\u53c2\u6570 t_o t_o \u8fdb\u884c\u03c3\u53d8\u6362\u540e\u4f5c\u4e3a\u7f6e\u4fe1\u5ea6\u7684\u503c\u3002 c_x,c_y c_x,c_y \u662f\u5f53\u524d\u7f51\u683c\u5de6\u4e0a\u89d2\u5230\u56fe\u50cf\u5de6\u4e0a\u89d2\u7684\u8ddd\u79bb\uff0c\u8981\u5148\u5c06\u7f51\u683c\u5927\u5c0f\u5f52\u4e00\u5316\uff0c\u5373\u4ee4\u4e00\u4e2a\u7f51\u683c\u7684\u5bbd=1\uff0c\u9ad8=1\u3002 p_w,p_h p_w,p_h \u662f\u5148\u9a8c\u6846\u7684\u5bbd\u548c\u9ad8\u3002 \u03c3\u662fsigmoid\u51fd\u6570\u3002 t_x,t_y,t_w,t_h,t_o t_x,t_y,t_w,t_h,t_o \u662f\u8981\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u5206\u522b\u7528\u4e8e\u9884\u6d4b\u8fb9\u6846\u7684\u4e2d\u5fc3\u548c\u5bbd\u9ad8\uff0c\u4ee5\u53ca\u7f6e\u4fe1\u5ea6\u3002 \u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7531\u4e8e\u03c3\u51fd\u6570\u5c06 t_x,t_y t_x,t_y \u7ea6\u675f\u5728(0,1)\u8303\u56f4\u5185\uff0c\u9884\u6d4b\u8fb9\u6846\u7684\u84dd\u8272\u4e2d\u5fc3\u70b9\u88ab\u7ea6\u675f\u5728\u84dd\u8272\u80cc\u666f\u7684\u7f51\u683c\u5185\u3002\u7ea6\u675f\u8fb9\u6846\u4f4d\u7f6e\u4f7f\u5f97\u6a21\u578b\u66f4\u5bb9\u6613\u5b66\u4e60\uff0c\u4e14\u9884\u6d4b\u66f4\u4e3a\u7a33\u5b9a\u3002 \u5047\u8bbe\u7f51\u7edc\u9884\u6d4b\u503c\u4e3a\uff1a anchor\u6846\u4e3a\uff1a \u5219\u76ee\u6807\u5728\u7279\u5f81\u56fe\u4e2d\u7684\u4f4d\u7f6e\uff1a \u5728\u539f\u56fe\u50cf\u4e2d\u7684\u4f4d\u7f6e\uff1a","title":"2.1.5 \u8fb9\u6846\u4f4d\u7f6e\u7684\u9884\u6d4b"},{"location":"objectdection/04.yolo/#216","text":"\u56fe\u50cf\u4e2d\u5bf9\u8c61\u4f1a\u6709\u5927\u6709\u5c0f\uff0c\u8f93\u5165\u56fe\u50cf\u7ecf\u8fc7\u591a\u5c42\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\uff0c\u6700\u540e\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u4e2d\uff0c\u8f83\u5c0f\u7684\u5bf9\u8c61\u53ef\u80fd\u7279\u5f81\u5df2\u7ecf\u4e0d\u660e\u663e\u751a\u81f3\u88ab\u5ffd\u7565\u6389\u4e86\u3002\u4e3a\u4e86\u66f4\u597d\u7684\u68c0\u6d4b\u51fa\u4e00\u4e9b\u6bd4\u8f83\u5c0f\u7684\u5bf9\u8c61\uff0c\u6700\u540e\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u9700\u8981\u4fdd\u7559\u4e00\u4e9b\u66f4\u7ec6\u8282\u7684\u4fe1\u606f\u3002 YOLO2\u5f15\u5165\u4e00\u79cd\u79f0\u4e3apassthrough\u5c42\u7684\u65b9\u6cd5\u5728\u7279\u5f81\u56fe\u4e2d\u4fdd\u7559\u4e00\u4e9b\u7ec6\u8282\u4fe1\u606f\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5c31\u662f\u5728\u6700\u540e\u4e00\u4e2apooling\u4e4b\u524d\uff0c\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u662f26x26x512\uff0c\u5c06\u51761\u62c64\uff0c\u76f4\u63a5\u4f20\u9012\uff08passthrough\uff09\u5230pooling\u540e\uff08\u5e76\u4e14\u53c8\u7ecf\u8fc7\u4e00\u7ec4\u5377\u79ef\uff09\u7684\u7279\u5f81\u56fe\uff0c\u4e24\u8005\u53e0\u52a0\u5230\u4e00\u8d77\u4f5c\u4e3a\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u3002 \u5177\u4f53\u7684\u62c6\u5206\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a","title":"2.1.6 \u7ec6\u7c92\u5ea6\u7279\u5f81\u878d\u5408"},{"location":"objectdection/04.yolo/#217","text":"YOLO2\u4e2d\u6ca1\u6709\u5168\u8fde\u63a5\u5c42\uff0c\u53ef\u4ee5\u8f93\u5165\u4efb\u4f55\u5c3a\u5bf8\u7684\u56fe\u50cf\u3002\u56e0\u4e3a\u6574\u4e2a\u7f51\u7edc\u4e0b\u91c7\u6837\u500d\u6570\u662f32\uff0c\u91c7\u7528\u4e86{320,352,...,608}\u7b4910\u79cd\u8f93\u5165\u56fe\u50cf\u7684\u5c3a\u5bf8\uff0c\u8fd9\u4e9b\u5c3a\u5bf8\u7684\u8f93\u5165\u56fe\u50cf\u5bf9\u5e94\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u5bbd\u548c\u9ad8\u662f{10,11,...19}\u3002\u8bad\u7ec3\u65f6\u6bcf10\u4e2abatch\u5c31\u968f\u673a\u66f4\u6362\u4e00\u79cd\u5c3a\u5bf8\uff0c\u4f7f\u7f51\u7edc\u80fd\u591f\u9002\u5e94\u5404\u79cd\u5927\u5c0f\u7684\u5bf9\u8c61\u68c0\u6d4b\u3002","title":"2.1.7 \u591a\u5c3a\u5ea6\u8bad\u7ec3"},{"location":"objectdection/04.yolo/#22-faster","text":"yoloV2\u63d0\u51fa\u4e86Darknet-19\uff08\u670919\u4e2a\u5377\u79ef\u5c42\u548c5\u4e2aMaxPooling\u5c42\uff09\u7f51\u7edc\u7ed3\u6784\u4f5c\u4e3a\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u3002DarkNet-19\u6bd4VGG-16\u5c0f\u4e00\u4e9b\uff0c\u7cbe\u5ea6\u4e0d\u5f31\u4e8eVGG-16\uff0c\u4f46\u6d6e\u70b9\u8fd0\u7b97\u91cf\u51cf\u5c11\u5230\u7ea6\u2155\uff0c\u4ee5\u4fdd\u8bc1\u66f4\u5feb\u7684\u8fd0\u7b97\u901f\u5ea6\u3002 yoloV2\u7684\u7f51\u7edc\u4e2d\u53ea\u6709\u5377\u79ef+pooling\uff0c\u4ece416x416x3 \u53d8\u6362\u5230 13x13x5x25\u3002\u589e\u52a0\u4e86batch normalization\uff0c\u589e\u52a0\u4e86\u4e00\u4e2apassthrough\u5c42\uff0c\u53bb\u6389\u4e86\u5168\u8fde\u63a5\u5c42\uff0c\u4ee5\u53ca\u91c7\u7528\u4e865\u4e2a\u5148\u9a8c\u6846,\u7f51\u7edc\u7684\u8f93\u51fa\u5982\u4e0b\u56fe\u6240\u793a\uff1a","title":"2.2 \u901f\u5ea6\u66f4\u5feb\uff08Faster\uff09"},{"location":"objectdection/04.yolo/#23","text":"VOC\u6570\u636e\u96c6\u53ef\u4ee5\u68c0\u6d4b20\u79cd\u5bf9\u8c61\uff0c\u4f46\u5b9e\u9645\u4e0a\u5bf9\u8c61\u7684\u79cd\u7c7b\u975e\u5e38\u591a\uff0c\u53ea\u662f\u7f3a\u5c11\u76f8\u5e94\u7684\u7528\u4e8e\u5bf9\u8c61\u68c0\u6d4b\u7684\u8bad\u7ec3\u6837\u672c\u3002YOLO2\u5c1d\u8bd5\u5229\u7528ImageNet\u975e\u5e38\u5927\u91cf\u7684\u5206\u7c7b\u6837\u672c\uff0c\u8054\u5408COCO\u7684\u5bf9\u8c61\u68c0\u6d4b\u6570\u636e\u96c6\u4e00\u8d77\u8bad\u7ec3\uff0c\u4f7f\u5f97YOLO2\u5373\u4f7f\u6ca1\u6709\u5b66\u8fc7\u5f88\u591a\u5bf9\u8c61\u7684\u68c0\u6d4b\u6837\u672c\uff0c\u4e5f\u80fd\u68c0\u6d4b\u51fa\u8fd9\u4e9b\u5bf9\u8c61\u3002","title":"2.3 \u8bc6\u522b\u5bf9\u8c61\u66f4\u591a"},{"location":"objectdection/04.yolo/#3yolov3","text":"yoloV3\u4ee5V1\uff0cV2\u4e3a\u57fa\u7840\u8fdb\u884c\u7684\u6539\u8fdb\uff0c\u4e3b\u8981\u6709\uff1a\u5229\u7528\u591a\u5c3a\u5ea6\u7279\u5f81\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff1b\u5148\u9a8c\u6846\u66f4\u4e30\u5bcc\uff1b\u8c03\u6574\u4e86\u7f51\u7edc\u7ed3\u6784\uff1b\u5bf9\u8c61\u5206\u7c7b\u4f7f\u7528logistic\u4ee3\u66ff\u4e86softmax,\u66f4\u9002\u7528\u4e8e\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1\u3002","title":"3.yoloV3"},{"location":"objectdection/04.yolo/#31","text":"YOLOv3\u662fYOLO (You Only Look Once)\u7cfb\u5217\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\u7684\u7b2c\u4e09\u7248\uff0c\u76f8\u6bd4\u4e4b\u524d\u7684\u7b97\u6cd5\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u5c0f\u76ee\u6807\uff0c\u7cbe\u5ea6\u6709\u663e\u8457\u63d0\u5347\u3002 yoloV3\u7684\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u5e45\u8f93\u5165\u56fe\u50cf\uff0cYOLOv3\u4f1a\u9884\u6d4b\u4e09\u4e2a\u4e0d\u540c\u5c3a\u5ea6\u7684\u8f93\u51fa\uff0c\u76ee\u7684\u662f\u68c0\u6d4b\u51fa\u4e0d\u540c\u5927\u5c0f\u7684\u76ee\u6807\u3002","title":"3.1\u7b97\u6cd5\u7b80\u4ecb"},{"location":"objectdection/04.yolo/#32","text":"\u901a\u5e38\u4e00\u5e45\u56fe\u50cf\u5305\u542b\u5404\u79cd\u4e0d\u540c\u7684\u7269\u4f53\uff0c\u5e76\u4e14\u6709\u5927\u6709\u5c0f\u3002\u6bd4\u8f83\u7406\u60f3\u7684\u662f\u4e00\u6b21\u5c31\u53ef\u4ee5\u5c06\u6240\u6709\u5927\u5c0f\u7684\u7269\u4f53\u540c\u65f6\u68c0\u6d4b\u51fa\u6765\u3002\u56e0\u6b64\uff0c\u7f51\u7edc\u5fc5\u987b\u5177\u5907\u80fd\u591f\u201c\u770b\u5230\u201d\u4e0d\u540c\u5927\u5c0f\u7684\u7269\u4f53\u7684\u80fd\u529b\u3002\u56e0\u4e3a\u7f51\u7edc\u8d8a\u6df1\uff0c\u7279\u5f81\u56fe\u5c31\u4f1a\u8d8a\u5c0f\uff0c\u6240\u4ee5\u7f51\u7edc\u8d8a\u6df1\u5c0f\u7684\u7269\u4f53\u4e5f\u5c31\u8d8a\u96be\u68c0\u6d4b\u51fa\u6765\u3002 \u5728\u5b9e\u9645\u7684feature map\u4e2d\uff0c\u968f\u7740\u7f51\u7edc\u6df1\u5ea6\u7684\u52a0\u6df1\uff0c\u6d45\u5c42\u7684feature map\u4e2d\u4e3b\u8981\u5305\u542b\u4f4e\u7ea7\u7684\u4fe1\u606f\uff08\u7269\u4f53\u8fb9\u7f18\uff0c\u989c\u8272\uff0c\u521d\u7ea7\u4f4d\u7f6e\u4fe1\u606f\u7b49\uff09\uff0c\u6df1\u5c42\u7684feature map\u4e2d\u5305\u542b\u9ad8\u7b49\u4fe1\u606f\uff08\u4f8b\u5982\u7269\u4f53\u7684\u8bed\u4e49\u4fe1\u606f\uff1a\u72d7\uff0c\u732b\uff0c\u6c7d\u8f66\u7b49\u7b49\uff09\u3002\u56e0\u6b64\u5728\u4e0d\u540c\u7ea7\u522b\u7684feature map\u5bf9\u5e94\u4e0d\u540c\u7684scale\uff0c\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u5728\u4e0d\u540c\u7ea7\u522b\u7684\u7279\u5f81\u56fe\u4e2d\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u3002\u5982\u4e0b\u56fe\u5c55\u793a\u4e86\u591a\u79cdscale\u53d8\u6362\u7684\u7ecf\u5178\u65b9\u6cd5\u3002 (a) \u8fd9\u79cd\u65b9\u6cd5\u9996\u5148\u5efa\u7acb\u56fe\u50cf\u91d1\u5b57\u5854\uff0c\u4e0d\u540c\u5c3a\u5ea6\u7684\u91d1\u5b57\u5854\u56fe\u50cf\u88ab\u8f93\u5165\u5230\u5bf9\u5e94\u7684\u7f51\u7edc\u5f53\u4e2d\uff0c\u7528\u4e8e\u4e0d\u540cscale\u7269\u4f53\u7684\u68c0\u6d4b\u3002\u4f46\u8fd9\u6837\u505a\u7684\u7ed3\u679c\u5c31\u662f\u6bcf\u4e2a\u7ea7\u522b\u7684\u91d1\u5b57\u5854\u90fd\u9700\u8981\u8fdb\u884c\u4e00\u6b21\u5904\u7406\uff0c\u901f\u5ea6\u5f88\u6162\u3002 (b) \u68c0\u6d4b\u53ea\u5728\u6700\u540e\u4e00\u5c42feature map\u9636\u6bb5\u8fdb\u884c\uff0c\u8fd9\u4e2a\u7ed3\u6784\u65e0\u6cd5\u68c0\u6d4b\u4e0d\u540c\u5927\u5c0f\u7684\u7269\u4f53 \u00a9 \u5bf9\u4e0d\u540c\u6df1\u5ea6\u7684feature map\u5206\u522b\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u3002SSD\u4e2d\u91c7\u7528\u7684\u4fbf\u662f\u8fd9\u6837\u7684\u7ed3\u6784\u3002\u8fd9\u6837\u5c0f\u7684\u7269\u4f53\u4f1a\u5728\u6d45\u5c42\u7684feature map\u4e2d\u88ab\u68c0\u6d4b\u51fa\u6765\uff0c\u800c\u5927\u7684\u7269\u4f53\u4f1a\u5728\u6df1\u5c42\u7684feature map\u88ab\u68c0\u6d4b\u51fa\u6765\uff0c\u4ece\u800c\u8fbe\u5230\u5bf9\u5e94\u4e0d\u540cscale\u7684\u7269\u4f53\u7684\u76ee\u7684\uff0c\u7f3a\u70b9\u662f\u6bcf\u4e00\u4e2afeature map\u83b7\u5f97\u7684\u4fe1\u606f\u4ec5\u6765\u6e90\u4e8e\u4e4b\u524d\u7684\u5c42\uff0c\u4e4b\u540e\u7684\u5c42\u7684\u7279\u5f81\u4fe1\u606f\u65e0\u6cd5\u83b7\u53d6\u5e76\u52a0\u4ee5\u5229\u7528\u3002 (d) \u4e0e\u00a9\u5f88\u63a5\u8fd1\uff0c\u4f46\u4e0d\u540c\u7684\u662f\uff0c\u5f53\u524d\u5c42\u7684feature map\u4f1a\u5bf9\u672a\u6765\u5c42\u7684feature map\u8fdb\u884c\u4e0a\u91c7\u6837\uff0c\u5e76\u52a0\u4ee5\u5229\u7528\u3002\u56e0\u4e3a\u6709\u4e86\u8fd9\u6837\u4e00\u4e2a\u7ed3\u6784\uff0c\u5f53\u524d\u7684feature map\u5c31\u53ef\u4ee5\u83b7\u5f97\u201c\u672a\u6765\u201d\u5c42\u7684\u4fe1\u606f\uff0c\u8fd9\u6837\u7684\u8bdd\u4f4e\u9636\u7279\u5f81\u4e0e\u9ad8\u9636\u7279\u5f81\u5c31\u6709\u673a\u878d\u5408\u8d77\u6765\u4e86\uff0c\u63d0\u5347\u68c0\u6d4b\u7cbe\u5ea6\u3002\u5728YOLOv3\u4e2d\uff0c\u5c31\u662f\u91c7\u7528\u8fd9\u79cd\u65b9\u5f0f\u6765\u5b9e\u73b0\u76ee\u6807\u591a\u5c3a\u5ea6\u7684\u53d8\u6362\u7684\u3002","title":"3.2\u591a\u5c3a\u5ea6\u68c0\u6d4b"},{"location":"objectdection/04.yolo/#33","text":"\u5728\u57fa\u672c\u7684\u56fe\u50cf\u7279\u5f81\u63d0\u53d6\u65b9\u9762\uff0cYOLO3\u91c7\u7528\u4e86Darknet-53\u7684\u7f51\u7edc\u7ed3\u6784\uff08\u542b\u670953\u4e2a\u5377\u79ef\u5c42\uff09\uff0c\u5b83\u501f\u9274\u4e86\u6b8b\u5dee\u7f51\u7edcResNet\u7684\u505a\u6cd5\uff0c\u5728\u5c42\u4e4b\u95f4\u8bbe\u7f6e\u4e86shortcut\uff0c\u6765\u89e3\u51b3\u6df1\u5c42\u7f51\u7edc\u68af\u5ea6\u7684\u95ee\u9898\uff0cshortcut\u5982\u4e0b\u56fe\u6240\u793a\uff1a\u5305\u542b\u4e24\u4e2a\u5377\u79ef\u5c42\u548c\u4e00\u4e2ashortcut connections\u3002 yoloV3\u7684\u6a21\u578b\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a\u6574\u4e2av3\u7ed3\u6784\u91cc\u9762\uff0c\u6ca1\u6709\u6c60\u5316\u5c42\u548c\u5168\u8fde\u63a5\u5c42\uff0c\u7f51\u7edc\u7684\u4e0b\u91c7\u6837\u662f\u901a\u8fc7\u8bbe\u7f6e\u5377\u79ef\u7684stride\u4e3a2\u6765\u8fbe\u5230\u7684\uff0c\u6bcf\u5f53\u901a\u8fc7\u8fd9\u4e2a\u5377\u79ef\u5c42\u4e4b\u540e\u56fe\u50cf\u7684\u5c3a\u5bf8\u5c31\u4f1a\u51cf\u5c0f\u5230\u4e00\u534a\u3002 ![ \u4e0b\u9762\u6211\u4eec\u770b\u4e0b\u7f51\u7edc\u7ed3\u6784\uff1a \u57fa\u672c\u7ec4\u4ef6\uff1a\u84dd\u8272\u65b9\u6846\u5185\u90e8\u5206 1\u3001CBL\uff1aYolov3\u7f51\u7edc\u7ed3\u6784\u4e2d\u7684\u6700\u5c0f\u7ec4\u4ef6\uff0c\u7531Conv+Bn+Leaky_relu\u6fc0\u6d3b\u51fd\u6570\u4e09\u8005\u7ec4\u6210\u3002 2\u3001Res unit\uff1a\u501f\u9274Resnet\u7f51\u7edc\u4e2d\u7684\u6b8b\u5dee\u7ed3\u6784\uff0c\u8ba9\u7f51\u7edc\u53ef\u4ee5\u6784\u5efa\u7684\u66f4\u6df1\u3002 3\u3001ResX\uff1a\u7531\u4e00\u4e2aCBL\u548cX\u4e2a\u6b8b\u5dee\u7ec4\u4ef6\u6784\u6210\uff0c\u662fYolov3\u4e2d\u7684\u5927\u7ec4\u4ef6\u3002\u6bcf\u4e2aRes\u6a21\u5757\u524d\u9762\u7684CBL\u90fd\u8d77\u5230\u4e0b\u91c7\u6837\u7684\u4f5c\u7528\uff0c\u56e0\u6b64\u7ecf\u8fc75\u6b21Res\u6a21\u5757\u540e\uff0c\u5f97\u5230\u7684\u7279\u5f81\u56fe\u662f416->208->104->52->26->13\u5927\u5c0f\u3002 \u5176\u4ed6\u57fa\u7840\u64cd\u4f5c\uff1a 1\u3001Concat\uff1a\u5f20\u91cf\u62fc\u63a5\uff0c\u4f1a\u6269\u5145\u4e24\u4e2a\u5f20\u91cf\u7684\u7ef4\u5ea6\uff0c\u4f8b\u598226\u00d726\u00d7256\u548c26\u00d726\u00d7512\u4e24\u4e2a\u5f20\u91cf\u62fc\u63a5\uff0c\u7ed3\u679c\u662f26\u00d726\u00d7768\u3002 2\u3001Add\uff1a\u5f20\u91cf\u76f8\u52a0\uff0c\u5f20\u91cf\u76f4\u63a5\u76f8\u52a0\uff0c\u4e0d\u4f1a\u6269\u5145\u7ef4\u5ea6\uff0c\u4f8b\u5982104\u00d7104\u00d7128\u548c104\u00d7104\u00d7128\u76f8\u52a0\uff0c\u7ed3\u679c\u8fd8\u662f104\u00d7104\u00d7128\u3002 Backbone\u4e2d\u5377\u79ef\u5c42\u7684\u6570\u91cf\uff1a \u6bcf\u4e2aResX\u4e2d\u5305\u542b1+2\u00d7X\u4e2a\u5377\u79ef\u5c42\uff0c\u56e0\u6b64\u6574\u4e2a\u4e3b\u5e72\u7f51\u7edcBackbone\u4e2d\u4e00\u5171\u5305\u542b1+\uff081+2\u00d71\uff09+\uff081+2\u00d72\uff09+\uff081+2\u00d78\uff09+\uff081+2\u00d78\uff09+\uff081+2\u00d74\uff09=52\uff0c\u518d\u52a0\u4e0a\u4e00\u4e2aFC\u5168\u8fde\u63a5\u5c42\uff0c\u5373\u53ef\u4ee5\u7ec4\u6210\u4e00\u4e2aDarknet53\u5206\u7c7b\u7f51\u7edc\u3002\u4e0d\u8fc7\u5728\u76ee\u6807\u68c0\u6d4bYolov3\u4e2d\uff0c\u53bb\u6389FC\u5c42\uff0c\u4ecd\u7136\u628aYolov3\u7684\u4e3b\u5e72\u7f51\u7edc\u53eb\u505aDarknet53\u7ed3\u6784\u3002","title":"3.3\u7f51\u7edc\u6a21\u578b\u7ed3\u6784"},{"location":"objectdection/04.yolo/#34","text":"yoloV3\u91c7\u7528K-means\u805a\u7c7b\u5f97\u5230\u5148\u9a8c\u6846\u7684\u5c3a\u5bf8\uff0c\u4e3a\u6bcf\u79cd\u5c3a\u5ea6\u8bbe\u5b9a3\u79cd\u5148\u9a8c\u6846\uff0c\u603b\u5171\u805a\u7c7b\u51fa9\u79cd\u5c3a\u5bf8\u7684\u5148\u9a8c\u6846\u3002 \u5728COCO\u6570\u636e\u96c6\u8fd99\u4e2a\u5148\u9a8c\u6846\u662f\uff1a(10x13)\uff0c(16x30)\uff0c(33x23)\uff0c(30x61)\uff0c(62x45)\uff0c(59x119)\uff0c(116x90)\uff0c(156x198)\uff0c(373x326)\u3002\u5728\u6700\u5c0f\u7684(13x13)\u7279\u5f81\u56fe\u4e0a\uff08\u6709\u6700\u5927\u7684\u611f\u53d7\u91ce\uff09\u5e94\u7528\u8f83\u5927\u7684\u5148\u9a8c\u6846(116x90)\uff0c(156x198)\uff0c(373x326)\uff0c\u9002\u5408\u68c0\u6d4b\u8f83\u5927\u7684\u5bf9\u8c61\u3002\u4e2d\u7b49\u7684(26x26)\u7279\u5f81\u56fe\u4e0a\uff08\u4e2d\u7b49\u611f\u53d7\u91ce\uff09\u5e94\u7528\u4e2d\u7b49\u7684\u5148\u9a8c\u6846(30x61)\uff0c(62x45)\uff0c(59x119)\uff0c\u9002\u5408\u68c0\u6d4b\u4e2d\u7b49\u5927\u5c0f\u7684\u5bf9\u8c61\u3002\u8f83\u5927\u7684(52x52)\u7279\u5f81\u56fe\u4e0a\uff08\u8f83\u5c0f\u7684\u611f\u53d7\u91ce\uff09\u5e94\u7528,\u5176\u4e2d\u8f83\u5c0f\u7684\u5148\u9a8c\u6846(10x13)\uff0c(16x30)\uff0c(33x23)\uff0c\u9002\u5408\u68c0\u6d4b\u8f83\u5c0f\u7684\u5bf9\u8c61\u3002 \u76f4\u89c2\u4e0a\u611f\u53d79\u79cd\u5148\u9a8c\u6846\u7684\u5c3a\u5bf8\uff0c\u4e0b\u56fe\u4e2d\u84dd\u8272\u6846\u4e3a\u805a\u7c7b\u5f97\u5230\u7684\u5148\u9a8c\u6846\u3002\u9ec4\u8272\u6846\u5f0fground truth\uff0c\u7ea2\u6846\u662f\u5bf9\u8c61\u4e2d\u5fc3\u70b9\u6240\u5728\u7684\u7f51\u683c\u3002","title":"3.4\u5148\u9a8c\u6846"},{"location":"objectdection/04.yolo/#35-logistic","text":"\u9884\u6d4b\u5bf9\u8c61\u7c7b\u522b\u65f6\u4e0d\u4f7f\u7528softmax\uff0c\u800c\u662f\u88ab\u66ff\u6362\u4e3a\u4e00\u4e2a1x1\u7684\u5377\u79ef\u5c42+logistic\u6fc0\u6d3b\u51fd\u6570\u7684\u7ed3\u6784\u3002\u4f7f\u7528softmax\u5c42\u7684\u65f6\u5019\u5176\u5b9e\u5df2\u7ecf\u5047\u8bbe\u6bcf\u4e2a\u8f93\u51fa\u4ec5\u5bf9\u5e94\u67d0\u4e00\u4e2a\u5355\u4e2a\u7684class\uff0c\u4f46\u662f\u5728\u67d0\u4e9bclass\u5b58\u5728\u91cd\u53e0\u60c5\u51b5\uff08\u4f8b\u5982woman\u548cperson\uff09\u7684\u6570\u636e\u96c6\u4e2d\uff0c\u4f7f\u7528softmax\u5c31\u4e0d\u80fd\u4f7f\u7f51\u7edc\u5bf9\u6570\u636e\u8fdb\u884c\u5f88\u597d\u7684\u9884\u6d4b\u3002","title":"3.5 logistic\u56de\u5f52"},{"location":"objectdection/04.yolo/#36-yolov3","text":"YoloV3\u7684\u8f93\u5165\u8f93\u51fa\u5f62\u5f0f\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8f93\u5165416\u00d7416\u00d73\u7684\u56fe\u50cf\uff0c\u901a\u8fc7darknet\u7f51\u7edc\u5f97\u5230\u4e09\u79cd\u4e0d\u540c\u5c3a\u5ea6\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u6bcf\u4e2a\u5c3a\u5ea6\u90fd\u5bf9\u5e94N\u4e2a\u901a\u9053\uff0c\u5305\u542b\u7740\u9884\u6d4b\u7684\u4fe1\u606f\uff1b \u6bcf\u4e2a\u7f51\u683c\u6bcf\u4e2a\u5c3a\u5bf8\u7684anchors\u7684\u9884\u6d4b\u7ed3\u679c\u3002 YOLOv3\u5171\u670913\u00d713\u00d73 + 26\u00d726\u00d73 + 52\u00d752\u00d73\u4e2a\u9884\u6d4b \u3002\u6bcf\u4e2a\u9884\u6d4b\u5bf9\u5e9485\u7ef4\uff0c\u5206\u522b\u662f4\uff08\u5750\u6807\u503c\uff09\u30011\uff08\u7f6e\u4fe1\u5ea6\u5206\u6570\uff09\u300180\uff08coco\u7c7b\u522b\u6982\u7387\uff09\u3002","title":"3.6 yoloV3\u6a21\u578b\u7684\u8f93\u5165\u4e0e\u8f93\u51fa"},{"location":"objectdection/04.yolo/#4yolov4","text":"YOLO\u4e4b\u7236\u57282020\u5e74\u521d\u5ba3\u5e03\u9000\u51faCV\u754c\uff0cYOLOv4 \u7684\u4f5c\u8005\u5e76\u4e0d\u662fYOLO\u7cfb\u5217 \u7684\u539f\u4f5c\u8005\u3002YOLO V4\u662fYOLO\u7cfb\u5217\u4e00\u4e2a\u91cd\u5927\u7684\u66f4\u65b0\uff0c\u5176\u5728COCO\u6570\u636e\u96c6\u4e0a\u7684\u5e73\u5747\u7cbe\u5ea6(AP)\u548c\u5e27\u7387\u7cbe\u5ea6(FPS)\u5206\u522b\u63d0\u9ad8\u4e8610% \u548c12%\uff0c\u5e76\u5f97\u5230\u4e86Joseph Redmon\u7684\u5b98\u65b9\u8ba4\u53ef\uff0c\u88ab\u8ba4\u4e3a\u662f\u5f53\u524d\u6700\u5f3a\u7684\u5b9e\u65f6\u5bf9\u8c61\u68c0\u6d4b\u6a21\u578b\u4e4b\u4e00\u3002 yoloV4\u603b\u7ed3\u4e86\u5927\u90e8\u5206\u68c0\u6d4b\u6280\u5de7\uff0c\u7136\u540e\u7ecf\u8fc7\u7b5b\u9009\uff0c\u6392\u5217\u7ec4\u5408\uff0c\u6328\u4e2a\u5b9e\u9a8c\uff08ablation study\uff09\u54ea\u4e9b\u65b9\u6cd5\u6709\u6548\uff0c\u603b\u4f53\u6765\u8bf4\uff0cYolov4\u5e76\u6ca1\u6709\u521b\u9020\u65b0\u7684\u6539\u8fdb\uff0c\u800c\u662f\u4f7f\u7528\u4e86\u5927\u91cf\u7684\u76ee\u6807\u68c0\u6d4b\u7684\u6280\u5de7\u3002\u5728\u8fd9\u91cc\u6211\u4eec\u4e3b\u8981\u7ed9\u5927\u5bb6\u770b\u4e0b\u5b83\u7684\u7f51\u7edc\u67b6\u6784\uff1a Yolov4\u7684\u7ed3\u6784\u56fe\u548cYolov3\u662f\u76f8\u4f3c\u7684\uff0c\u4e0d\u8fc7\u4f7f\u7528\u5404\u79cd\u65b0\u7684\u7b97\u6cd5\u601d\u60f3\u5bf9\u5404\u4e2a\u5b50\u7ed3\u6784\u90fd\u8fdb\u884c\u4e86\u6539\u8fdb\u3002 \u5148\u6574\u7406\u4e0bYolov4\u7684\u7ed3\u6784\u7ec4\u4ef6 \u57fa\u672c\u7ec4\u4ef6\uff1a CBM\uff1aYolov4\u7f51\u7edc\u7ed3\u6784\u4e2d\u7684\u6700\u5c0f\u7ec4\u4ef6\uff0c\u7531Conv+Bn+Mish\u6fc0\u6d3b\u51fd\u6570\u4e09\u8005\u7ec4\u6210\u3002 CBL\uff1a\u7531Conv+Bn+Leaky_relu\u6fc0\u6d3b\u51fd\u6570\u4e09\u8005\u7ec4\u6210\u3002 Res unit\uff1a\u501f\u9274Resnet\u7f51\u7edc\u4e2d\u7684\u6b8b\u5dee\u7ed3\u6784\uff0c\u8ba9\u7f51\u7edc\u53ef\u4ee5\u6784\u5efa\u7684\u66f4\u6df1\u3002 CSPX\uff1a\u7531\u4e09\u4e2a\u5377\u79ef\u5c42\u548cX\u4e2aRes unint\u6a21\u5757Concate\u7ec4\u6210\u3002 SPP\uff1a\u91c7\u75281\u00d71\uff0c5\u00d75\uff0c9\u00d79\uff0c13\u00d713\u7684\u6700\u5927\u6c60\u5316\u7684\u65b9\u5f0f\uff0c\u8fdb\u884c\u591a\u5c3a\u5ea6\u878d\u5408\u3002 \u5176\u4ed6\u57fa\u7840\u64cd\u4f5c\uff1a Concat\uff1a\u5f20\u91cf\u62fc\u63a5\uff0c\u7ef4\u5ea6\u4f1a\u6269\u5145\uff0c\u548cYolov3\u4e2d\u7684\u89e3\u91ca\u4e00\u6837\uff0c\u5bf9\u5e94\u4e8ecfg\u6587\u4ef6\u4e2d\u7684route\u64cd\u4f5c\u3002 Add\uff1a\u5f20\u91cf\u76f8\u52a0\uff0c\u4e0d\u4f1a\u6269\u5145\u7ef4\u5ea6\uff0c\u5bf9\u5e94\u4e8ecfg\u6587\u4ef6\u4e2d\u7684shortcut\u64cd\u4f5c\u3002 Backbone\u4e2d\u5377\u79ef\u5c42\u7684\u6570\u91cf\uff1a \u6bcf\u4e2aCSPX\u4e2d\u5305\u542b3+2\u00d7X\u4e2a\u5377\u79ef\u5c42\uff0c\u56e0\u6b64\u6574\u4e2a\u4e3b\u5e72\u7f51\u7edcBackbone\u4e2d\u4e00\u5171\u5305\u542b2+\uff083+2\u00d71\uff09+2+\uff083+2\u00d72\uff09+2+\uff083+2\u00d78\uff09+2+\uff083+2\u00d78\uff09+2+\uff083+2\u00d74\uff09+1=72\u3002 \u6ce8\u610f\uff1a \u7f51\u7edc\u7684\u8f93\u5165\u5927\u5c0f\u4e0d\u662f\u56fa\u5b9a\u7684\uff0c\u5728yoloV3\u4e2d\u8f93\u5165\u9ed8\u8ba4\u662f416\u00d7416\uff0c\u5728yoloV4\u4e2d\u9ed8\u8ba4\u662f608\u00d7608\uff0c\u5728\u5b9e\u9645\u9879\u76ee\u4e2d\u4e5f\u53ef\u4ee5\u6839\u636e\u9700\u8981\u4fee\u6539\uff0c\u6bd4\u5982320\u00d7320\uff0c\u4e00\u822c\u662f32\u7684\u500d\u6570\u3002 \u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u548c\u6700\u540e\u7684\u4e09\u4e2a\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u4e5f\u662f\u5bf9\u5e94\u7684\uff0c\u6bd4\u5982416\u00d7416\u7684\u8f93\u5165\uff0c\u6700\u540e\u7684\u4e09\u4e2a\u7279\u5f81\u56fe\u5927\u5c0f\u662f13\u00d713\uff0c26\u00d726\uff0c52\u00d752\uff0c \u5982\u679c\u662f608\u00d7608\uff0c\u6700\u540e\u7684\u4e09\u4e2a\u7279\u5f81\u56fe\u5927\u5c0f\u5219\u662f19\u00d719\uff0c38\u00d738\uff0c76\u00d776\u3002 \u603b\u7ed3 \u77e5\u9053yolo\u7f51\u7edc\u67b6\u6784\uff0c\u7406\u89e3\u5176\u8f93\u5165\u8f93\u51fa YOLO\u7684\u6574\u4e2a\u7ed3\u6784\u5c31\u662f\u8f93\u5165\u56fe\u7247\u7ecf\u8fc7\u795e\u7ecf\u7f51\u7edc\u7684\u53d8\u6362\u5f97\u5230\u4e00\u4e2a\u8f93\u51fa\u7684\u5f20\u91cf \u77e5\u9053yolo\u6a21\u578b\u7684\u8bad\u7ec3\u6837\u672c\u6784\u5efa\u7684\u65b9\u6cd5 \u5bf9\u4e8e\u539f\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e00\u4e2a\u7f51\u683cgrid\u90fd\u9700\u8981\u6784\u5efa\u4e00\u4e2a30\u7ef4\u7684\u5411\u91cf\uff1a\u5206\u7c7b\uff0c\u7f6e\u4fe1\u5ea6\uff0c\u56de\u5f52\u7684\u76ee\u6807\u503c \u7406\u89e3yolo\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570 \u635f\u5931\u51fd\u6570\u5206\u4e3a3\u90e8\u5206\uff1a\u5206\u7c7b\u635f\u5931\uff0c\u56de\u5f52\u635f\u5931\uff0c\u7f6e\u4fe1\u5ea6\u635f\u5931 \u77e5\u9053yoloV2\u6a21\u578b\u7684\u6539\u8fdb\u65b9\u6cd5 \u4f7f\u7528\u4e86BN\u5c42\uff0c\u9ad8\u5206\u8fa8\u7387\u8bad\u7ec3\uff0c\u91c7\u7528Anchorbox\uff0c\u805a\u7c7b\u5f97\u5230anchorbox\u7684\u5c3a\u5bf8\uff0c\u6539\u8fdb\u8fb9\u754c\u6846\u9884\u6d4b\u7684\u65b9\u6cd5\uff0c\u7279\u5f81\u878d\u5408\uff0c\u591a\u5c3a\u5ea6\u8bad\u7ec3\uff0c\u7f51\u7edc\u6a21\u578b\u4f7f\u7528darknet19\uff0c\u5229\u7528imagenet\u6570\u636e\u96c6\u8bc6\u522b\u66f4\u591a\u7684\u76ee\u6807 yoloV3\u7684\u591a\u5c3a\u5ea6\u68c0\u6d4b\u65b9\u6cd5 \u5728YOLOv3\u4e2d\u91c7\u7528FPN\u7ed3\u6784\u6765\u63d0\u9ad8\u5bf9\u5e94\u591a\u5c3a\u5ea6\u76ee\u6807\u68c0\u6d4b\u7684\u7cbe\u5ea6\uff0c\u5f53\u524d\u7684feature map\u5229\u7528\u201c\u672a\u6765\u201d\u5c42\u7684\u4fe1\u606f\uff0c\u5c06\u4f4e\u9636\u7279\u5f81\u4e0e\u9ad8\u9636\u7279\u5f81\u8fdb\u884c\u878d\u5408\uff0c\u63d0\u5347\u68c0\u6d4b\u7cbe\u5ea6\u3002 yoloV3\u6a21\u578b\u7684\u7f51\u7edc\u7ed3\u6784 \u4ee5darknet-53\u4e3a\u57fa\u7840\uff0c\u501f\u9274resnet\u7684\u601d\u60f3\uff0c\u5728\u7f51\u7edc\u4e2d\u52a0\u5165\u4e86\u6b8b\u5dee\u6a21\u5757\uff0c\u5229\u4e8e\u89e3\u51b3\u6df1\u5c42\u6b21\u7f51\u7edc\u7684\u68af\u5ea6\u95ee\u9898 \u6574\u4e2av3\u7ed3\u6784\u91cc\u9762\uff0c\u6ca1\u6709\u6c60\u5316\u5c42\u548c\u5168\u8fde\u63a5\u5c42\uff0c\u53ea\u6709\u5377\u79ef\u5c42 \u7f51\u7edc\u7684\u4e0b\u91c7\u6837\u662f\u901a\u8fc7\u8bbe\u7f6e\u5377\u79ef\u7684stride\u4e3a2\u6765\u8fbe\u5230\u7684 yoloV3\u6a21\u578b\u5148\u9a8c\u6846\u8bbe\u8ba1\u7684\u65b9\u6cd5 \u91c7\u7528K-means\u805a\u7c7b\u5f97\u5230\u5148\u9a8c\u6846\u7684\u5c3a\u5bf8\uff0c\u4e3a\u6bcf\u79cd\u5c3a\u5ea6\u8bbe\u5b9a3\u79cd\u5148\u9a8c\u6846\uff0c\u603b\u5171\u805a\u7c7b\u51fa9\u79cd\u5c3a\u5bf8\u7684\u5148\u9a8c\u6846\u3002 yoloV3\u6a21\u578b\u4e3a\u4ec0\u4e48\u9002\u7528\u4e8e\u591a\u6807\u7b7e\u7684\u76ee\u6807\u5206\u7c7b \u9884\u6d4b\u5bf9\u8c61\u7c7b\u522b\u65f6\u4e0d\u4f7f\u7528softmax\uff0c\u800c\u662f\u4f7f\u7528logistic\u7684\u8f93\u51fa\u8fdb\u884c\u9884\u6d4b yoloV3\u6a21\u578b\u7684\u8f93\u5165\u8f93\u51fa \u5bf9\u4e8e416\u00d7416\u00d73\u7684\u8f93\u5165\u56fe\u50cf\uff0c\u5728\u6bcf\u4e2a\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u7684\u6bcf\u4e2a\u7f51\u683c\u8bbe\u7f6e3\u4e2a\u5148\u9a8c\u6846\uff0c\u603b\u5171\u6709 13\u00d713\u00d73 + 26\u00d726\u00d73 + 52\u00d752\u00d73 = 10647 \u4e2a\u9884\u6d4b\u3002\u6bcf\u4e00\u4e2a\u9884\u6d4b\u662f\u4e00\u4e2a(4+1+80)=85\u7ef4\u5411\u91cf\uff0c\u8fd9\u4e2a85\u7ef4\u5411\u91cf\u5305\u542b\u8fb9\u6846\u5750\u6807\uff084\u4e2a\u6570\u503c\uff09\uff0c\u8fb9\u6846\u7f6e\u4fe1\u5ea6\uff081\u4e2a\u6570\u503c\uff09\uff0c\u5bf9\u8c61\u7c7b\u522b\u7684\u6982\u7387\uff08\u5bf9\u4e8eCOCO\u6570\u636e\u96c6\uff0c\u670980\u79cd\u5bf9\u8c61\uff09\u3002","title":"4.yoloV4[\u4e86\u89e3]"},{"location":"objectdection/05.yolo-demo/","text":"4.5 YoloV3 \u6848\u4f8b \u00b6 \u5b66\u4e60\u76ee\u6807 \u719f\u6089TFRecord\u6587\u4ef6\u7684\u4f7f\u7528\u65b9\u6cd5 \u77e5\u9053YoloV3\u6a21\u578b\u7ed3\u6784\u53ca\u6784\u5efa\u65b9\u6cd5 \u77e5\u9053\u6570\u636e\u5904\u7406\u65b9\u6cd5 \u80fd\u591f\u5229\u7528yoloV3\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b 1.TFrecord\u6587\u4ef6 \u00b6 \u8be5\u6848\u4f8b\u4e2d\u6211\u4eec\u4f9d\u7136\u4f7f\u7528VOC\u6570\u636e\u96c6\u6765\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff0c\u4e0d\u540c\u7684\u662f\u6211\u4eec\u8981\u5229\u7528tfrecord\u6587\u4ef6\u6765\u5b58\u50a8\u548c\u8bfb\u53d6\u6570\u636e\uff0c\u9996\u5148\u6765\u770b\u4e00\u4e0btfrecord\u6587\u4ef6\u7684\u76f8\u5173\u5185\u5bb9\u3002 \u4e3a\u4ec0\u4e48\u8981\u4f7f\u7528tfrecord\u6587\u4ef6\uff1f TFRecord\u662fGoogle\u5b98\u65b9\u63a8\u8350\u4f7f\u7528\u7684\u6570\u636e\u683c\u5f0f\u5316\u5b58\u50a8\u5de5\u5177\uff0c\u4e3aTensorFlow\u91cf\u8eab\u6253\u9020\u7684\u3002 TFRecord\u89c4\u8303\u4e86\u6570\u636e\u7684\u8bfb\u5199\u65b9\u5f0f\uff0c\u6570\u636e\u8bfb\u53d6\u548c\u5904\u7406\u7684\u6548\u7387\u90fd\u4f1a\u5f97\u5230\u663e\u8457\u7684\u63d0\u9ad8\u3002 1.1 \u4ec0\u4e48\u662fTFrecord\u6587\u4ef6 \u00b6 TFRecord \u662fGoogle\u5b98\u65b9\u63a8\u8350\u7684\u4e00\u79cd\u6570\u636e\u683c\u5f0f\uff0c\u662fGoogle\u4e13\u95e8\u4e3aTensorFlow\u8bbe\u8ba1\u7684\u4e00\u79cd\u6570\u636e\u683c\u5f0f\uff0c\u5229\u7528\u8fd9\u79cd\u65b9\u5f0f\u5b58\u50a8\u6570\u636e\u53ef\u4ee5\u4f7f\u5176\u4e0e\u7f51\u7edc\u67b6\u6784\u66f4\u9002\u914d\u3002TFRecord\u662f\u4e00\u79cd\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u5176\u80fd\u66f4\u597d\u7684\u5229\u7528\u5185\u5b58\uff0c\u4e0ecsv,hdf5\u6587\u4ef6\u662f\u7c7b\u4f3c\u7684\u3002 TFRecord\u7684\u6587\u4ef6\u7684\u5185\u5bb9\u5982\u4e0b\u56fe\u6240\u793a\uff1a TFRecord\u5185\u90e8\u5305\u542b\u591a\u4e2atf.train.Example\uff0c\u4e00\u822c\u6765\u8bf4\u5bf9\u5e94\u4e00\u4e2a\u56fe\u50cf\u6570\u636e\uff0c\u5728\u4e00\u4e2aExample\u6d88\u606f\u4f53\u4e2d\u5305\u542b\u4e86\u4e00\u7cfb\u5217\u7684tf.train.feature\u5c5e\u6027\uff0c\u800c \u6bcf\u4e00\u4e2afeature\u662f\u4e00\u4e2akey-value\u7684\u952e\u503c\u5bf9\uff0c\u5176\u4e2d\uff0ckey \u662fstring\u7c7b\u578b\uff0c\u800cvalue \u7684\u53d6\u503c\u6709\u4e09\u79cd\uff1a tf.train.bytes_list: \u53ef\u4ee5\u5b58\u50a8string \u548cbyte\u4e24\u79cd\u6570\u636e\u7c7b\u578b\u3002\u56fe\u50cf\u6570\u636e\u4f7f\u7528\u8fd9\u79cd\u65b9\u5f0f\u5b58\u50a8\u5373\u53ef\u3002 tf.train.float_list: \u53ef\u4ee5\u5b58\u50a8float(float32)\u4e0edouble(float64) \u4e24\u79cd\u6570\u636e\u7c7b\u578b \u3002 tf.train.int64_list: \u53ef\u4ee5\u5b58\u50a8\uff1abool, enum, int32, uint32, int64, uint64 \u3002 TFRecord \u5e76\u975e\u662fTensorFlow\u552f\u4e00\u652f\u6301\u7684\u6570\u636e\u683c\u5f0f\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528CSV\u6216\u6587\u672c\u7b49\u5176\u4ed6\u683c\u5f0f\uff0c\u4f46\u662f\u5bf9\u4e8eTensorFlow\u6765\u8bf4\uff0cTFRecord \u662f\u6700\u53cb\u597d\u7684\uff0c\u6700\u65b9\u4fbf\u7684\uff0c\u800c\u4e14tensorflow\u4e5f\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684API\u5e2e\u52a9\u6211\u4eec\u8f7b\u677e\u7684\u521b\u5efa\u548c\u83b7\u53d6TFRecord\u6587\u4ef6\u3002 1.2 \u5c06\u6570\u636e\u8f6c\u6362\u4e3aTFRecord\u6587\u4ef6 \u00b6 \u5bf9\u4e8e\u4e2d\u5927\u6570\u636e\u96c6\u6765\u8bf4\uff0cGoogle\u5b98\u65b9\u63a8\u8350\u5148\u5c06\u6570\u636e\u96c6\u8f6c\u5316\u4e3aTFRecord\u6570\u636e, \u8fd9\u6837\u53ef\u52a0\u5feb\u5728\u6570\u636e\u8bfb\u53d6, \u9884\u5904\u7406\u4e2d\u7684\u901f\u5ea6\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u5c31\u5c06VOC\u6570\u636e\u96c6\u8f6c\u6362\u4e3aRecords\u683c\u5f0f\uff0c\u5728\u8fd9\u91cc\u9996\u5148\u8bfb\u53d6\u6807\u6ce8XML\u6587\u4ef6\uff0c\u5e76\u627e\u5230\u5bf9\u5e94\u7684\u56fe\u50cf\u6570\u636e\uff0c\u6700\u540e\u5c06\u6570\u636e\u5199\u5165TFRecords\u6587\u4ef6\u4e2d\u3002 1.2.1 \u8bfb\u53d6\u6807\u6ce8\u4fe1\u606f \u00b6 VOC\u6570\u636e\u96c6\u7684\u6807\u6ce8\u4fe1\u606f\u5b58\u50a8\u5728xml\u6587\u4ef6\u4e2d\uff0c\u5728VOC2007\u7684\u6570\u636e\u4e2d\u4e3b\u8981\u83b7\u53d6fIlename\uff0cwidth\uff0cheight\uff0c\u548cobject\uff08\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\uff09\u4e0b\u7684name\uff08\u76ee\u6807\u540d\u79f0\uff09\u548cbndbox\uff08\u6846\u7684\u4f4d\u7f6e\uff09\u3002\u5177\u4f53\u5927\u5bb6\u53ef\u4ee5\u770b\u4e0b\u5728FasterRCNN\u4e2d\u7684\u4ecb\u7ecd\uff0c\u4ee3\u7801\u5982\u4e0b\u6240\u793a\uff1a import xml.dom.minidom as xdom # VOC\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f voc_classes = { 'none' : 0 , 'aeroplane' : 1 , 'bicycle' : 2 , 'bird' : 3 , 'boat' : 4 , 'bottle' : 5 , 'bus' : 6 , 'car' : 7 , 'cat' : 8 , 'chair' : 9 , 'cow' : 10 , 'diningtable' : 11 , 'dog' : 12 , 'horse' : 13 , 'motorbike' : 14 , 'person' : 15 , 'pottedplant' : 16 , 'sheep' : 17 , 'sofa' : 18 , 'train' : 19 , 'tvmonitor' : 20 , } # \u8bfb\u53d6XML\u6587\u4ef6\u4e2d\u7684\u4fe1\u606f def Prase_Singel_xml ( xml_path ): DOMTree = xdom . parse ( xml_path ) RootNode = DOMTree . documentElement #\u83b7\u53d6XML\u6587\u4ef6\u5bf9\u5e94\u7684\u56fe\u50cf image_name = RootNode . getElementsByTagName ( \"filename\" )[ 0 ] . childNodes [ 0 ] . data #\u83b7\u53d6\u56fe\u50cf\u5bbd\u548c\u9ad8 size = RootNode . getElementsByTagName ( \"size\" ) image_height = int ( size [ 0 ] . getElementsByTagName ( \"height\" )[ 0 ] . childNodes [ 0 ] . data ) image_width = int ( size [ 0 ] . getElementsByTagName ( \"width\" )[ 0 ] . childNodes [ 0 ] . data ) #\u83b7\u53d6\u56fe\u50cf\u4e2d\u76ee\u6807\u5bf9\u8c61 all_obj = RootNode . getElementsByTagName ( \"object\" ) bndbox_lable_dic = [] # \u904d\u5386\u6240\u6709\u7684\u5bf9\u8c61 for one_obj in all_obj : # \u83b7\u53d6\u76ee\u6807\u7684\u6807\u6ce8\u4fe1\u606f obj_name = one_obj . getElementsByTagName ( \"name\" )[ 0 ] . childNodes [ 0 ] . data # \u83b7\u53d6\u5bf9\u5e94\u7684label\u503c obj_label = voc_classes [ obj_name ] # \u83b7\u53d6bbox bndbox = one_obj . getElementsByTagName ( \"bndbox\" ) # \u83b7\u53d6\u76ee\u6807\u7684\u5de6\u4e0a\u53f3\u4e0b\u7684\u4f4d\u7f6e xmin = int ( bndbox [ 0 ] . getElementsByTagName ( \"xmin\" )[ 0 ] . childNodes [ 0 ] . data ) ymin = int ( bndbox [ 0 ] . getElementsByTagName ( \"ymin\" )[ 0 ] . childNodes [ 0 ] . data ) xmax = int ( bndbox [ 0 ] . getElementsByTagName ( \"xmax\" )[ 0 ] . childNodes [ 0 ] . data ) ymax = int ( bndbox [ 0 ] . getElementsByTagName ( \"ymax\" )[ 0 ] . childNodes [ 0 ] . data ) # \u5c06\u76ee\u6807\u6846\u548c\u7c7b\u522b\u7ec4\u5408\u5728\u4e00\u8d77 bndbox_lable_dic . append ([ xmin , ymin , xmax , ymax , obj_label ]) # \u8fd4\u56de\u76f8\u5e94\u7684\u4fe1\u606f return image_name , image_width , image_height , bndbox_lable_dic \u63a5\u4e0b\u6765\u6211\u4eec\u8bfb\u53d6\u4e00\u4e2aXML\u6587\u4ef6\u770b\u4e0b\u6548\u679c\uff1a # \u5c55\u793a\u6548\u679c print ( Prase_Singel_xml ( 'VOCdevkit/VOC2007/Annotations/000007.xml' )) \u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a ( '000007.jpg' , 500 , 333 , [[ 141 , 50 , 500 , 330 , 7 ]]) \u4ece\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u5bf9\u5e94\u7684\u56fe\u50cf\u662f000007.jpg\uff0c\u56fe\u50cf\u7684\u5bbd\u9ad8\u662f500, 333\uff0c\u56fe\u50cf\u4e2d\u53ea\u5305\u542b\u4e00\u4e2a\u76ee\u6807\uff0c\u4f4d\u7f6e\u662f141, 50, 500, 330\uff0c\u7c7b\u522b\u662f7 car. 1.2.2 \u5c06\u6570\u636e\u5199\u5165TFRecord\u6587\u4ef6\u4e2d \u00b6 \u5728\u5c06\u6570\u636e\u5199\u5165\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528tf.io.TFRecordWriter\u6765\u5b8c\u6210\uff0c\u4e3b\u8981\u6b65\u9aa4\u662f\uff1a 1\u3001\u4f7f\u7528tf.io.TFRecordWriter\u6253\u5f00TFRecords\u6587\u4ef6 2\u3001\u4f7f\u7528tf.train.Int64List\uff0ctf.train.BytesList\u6216tf.train.FloatList\u5bf9\u6570\u636e\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362 3\u3001\u5c06\u7c7b\u578b\u8f6c\u6362\u540e\u7684\u6570\u636e\u4f20\u5165tf.train.Feature\u521b\u5efa\u7684\u7279\u5f81\u4e2d 4\u3001\u5c06\u7279\u5f81\u4f20\u5165tf.train.Example\u521b\u5efa\u7684example\u4e2d 5\u3001\u4f7f\u7528example.SerializeToString()\u5c06example\u5e8f\u5217\u5316\u4e3a\u5b57\u7b26\u4e32 6\u3001\u4f7f\u7528writer.write\u5c06\u5e8f\u5217\u5316\u540e\u7684example\u5199\u5165TFRecords\u6587\u4ef6 7\u3001\u6700\u540e\u4f7f\u7528writer.close\uff08\uff09\u5173\u95ed\u6587\u4ef6 import tensorflow as tf import glob import os # \u6307\u660exml\u6587\u4ef6\uff0ctfrecord\u6587\u4ef6\u548c\u56fe\u50cf\u7684\u4f4d\u7f6e def write_to_tfrecord ( all_xml_path , tfrecord_path , voc_img_path ): # 1\u3001\u4f7f\u7528tf.io.TFRecordWriter\u6253\u5f00TFRecords\u6587\u4ef6 writer = tf . io . TFRecordWriter ( tfrecord_path ) # \u904d\u5386\u6240\u6709\u7684XML\u6587\u4ef6 for i , single_xml_path in enumerate ( all_xml_path ): # \u8bfb\u53d6xml\u6587\u4ef6\u4e2d\u7684\u5185\u5bb9 image_name , image_width , image_height , bndbox_lable_dic = Prase_Singel_xml ( single_xml_path ) # \u83b7\u53d6\u56fe\u50cf\u7684\u8def\u5f84 sigle_img_path = os . path . join ( voc_img_path , image_name ) # \u8bfb\u53d6\u56fe\u50cf image_data = open ( sigle_img_path , 'rb' ) . read () xmin = [] ymin = [] xmax = [] ymax = [] obj_label = [] # \u904d\u5386box\u548clabel\u4fe1\u606f\uff0c\u5e76\u8bb0\u5f55\u4e0b\u6765 for j in range ( len ( bndbox_lable_dic )): xmin . append ( bndbox_lable_dic [ j ][ 0 ]) ymin . append ( bndbox_lable_dic [ j ][ 1 ]) xmax . append ( bndbox_lable_dic [ j ][ 2 ]) ymax . append ( bndbox_lable_dic [ j ][ 3 ]) obj_label . append ( bndbox_lable_dic [ j ][ 4 ]) # \u521b\u5efa\u7279\u5f81\uff1a\u56fe\u50cf\uff0csize,box\u548clabel # 2\u3001\u4f7f\u7528tf.train.Int64List\uff0ctf.train.BytesList\u6216tf.train.FloatList\u5bf9\u6570\u636e\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362 # 3\u3001\u5c06\u7c7b\u578b\u8f6c\u6362\u540e\u7684\u6570\u636e\u4f20\u5165tf.train.Feature\u521b\u5efa\u7684\u7279\u5f81\u4e2d feature = { 'image' : tf . train . Feature ( bytes_list = tf . train . BytesList ( value = [ image_data ])), 'width' : tf . train . Feature ( float_list = tf . train . FloatList ( value = [ image_width ])), 'height' : tf . train . Feature ( float_list = tf . train . FloatList ( value = [ image_height ])), 'xmin' : tf . train . Feature ( float_list = tf . train . FloatList ( value = xmin )), 'ymin' : tf . train . Feature ( float_list = tf . train . FloatList ( value = ymin )), 'xmax' : tf . train . Feature ( float_list = tf . train . FloatList ( value = xmax )), 'ymax' : tf . train . Feature ( float_list = tf . train . FloatList ( value = ymax )), 'label' : tf . train . Feature ( int64_list = tf . train . Int64List ( value = obj_label )) } # 4\u3001\u5c06\u7279\u5f81\u4f20\u5165tf.train.Example\u521b\u5efa\u7684example\u4e2d example = tf . train . Example ( features = tf . train . Features ( feature = feature )) # \u5c06example\u5199\u5165\u5230tfrecord\u6587\u4ef6\u4e2d # 5\u3001\u4f7f\u7528example.SerializeToString()\u5c06example\u5e8f\u5217\u5316\u4e3a\u5b57\u7b26\u4e32 # 6\u3001\u4f7f\u7528writer.write\u5c06\u5e8f\u5217\u5316\u540e\u7684example\u5199\u5165TFRecords\u6587\u4ef6 writer . write ( example . SerializeToString ()) # \u6700\u540e\u4f7f\u7528writer.close\uff08\uff09\u5173\u95ed\u6587\u4ef6 writer . close () print ( '\u7b2c {} \u5f20\u56fe\u7247\u5199\u5165\u5b8c\u6bd5' . format ( i )) \u63a5\u4e0b\u6765\u8c03\u7528\u4e0a\u8ff0\u65b9\u6cd5\u5c06VOC\u6570\u636e\u5199\u5165\u5230TFRecord\u6587\u4ef6\u4e2d\uff1a # \u83b7\u53d6\u6240\u6709\u7684xml\u6587\u4ef6 all_xml_path = glob . glob ( 'VOCdevkit/VOC2007/Annotations/*.xml' ) # \u6307\u5b9atfrecords\u6587\u4ef6\u7684\u8def\u5f84 tfrecord_path = 'voc_2007.tfrecords' # \u6307\u5b9a\u56fe\u50cf\u6240\u5728\u7684\u8def\u5f84 voc_img_path = 'VOCdevkit/VOC2007/JPEGImages' # \u5c06\u4fe1\u606f\u5199\u5165\u5230tfrecord\u6587\u4ef6\u4e2d write_to_tfrecord ( all_xml_path , tfrecord_path , voc_img_path ) \u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a 1.3 \u8bfb\u53d6TFRecord\u6587\u4ef6 \u00b6 VOC\u6570\u636e\u96c6\u5df2\u7ecf\u88ab\u5199\u5165\u5230TFRecord\u6587\u4ef6\u4e2d\u4e86\uff0c\u90a3\u6211\u4eec\u5c31\u8981\u4eceTFrecord\u6587\u4ef6\u4e2d\u5c06\u6570\u636e\u8bfb\u53d6\u51fa\u6765\u3002\u53ea\u9700\u8981\u7b80\u5355\u7684\u4f7f\u7528 tf.data.TFRecordDataset \u5c31\u80fd\u591f\u8f7b\u677e\u7684\u8bfb\u53d6\u6570\u636e\u3002 \u4f7f\u7528tf.data.TFRecordDataset\u6765\u83b7\u53d6TFRecord\u6587\u4ef6\u4e2d\u7684\u6570\u636e \u5b9a\u4e49\u7279\u5f81\u7684\u63cf\u8ff0\u65b9\u6cd5\uff0c\u4e0e\u5199\u5165\u65f6\u662f\u5bf9\u5e94\u7684 \u4f7f\u7528tf.io.parse_single_example\u5c06\u4e00\u4e2aexample\u8f6c\u6362\u4e3a\u539f\u59cb\u6570\u636e \u4f7f\u7528\u529f\u80fdmap\u65b9\u6cd5\u5bf9\u6240\u6709\u6570\u636e\u8fdb\u884c\u5904\u7406\u83b7\u53d6\u6700\u7ec8\u7684\u7ed3\u679c\uff08map\u65b9\u6cd5\u7a0d\u540e\u4ecb\u7ecd\uff09 import tensorflow as tf import os import numpy as np import matplotlib.pyplot as plt from matplotlib.patches import Rectangle # \u83b7\u53d6tfreocrd\u4e2d\u7684\u6240\u6709\u6570\u636e raw_datasets = tf . data . TFRecordDataset ( 'voc_2007.tfrecords' ) # \u5b9a\u4e49\u7279\u5f81\u7684\u63cf\u8ff0\u65b9\u6cd5\uff1a\u56fe\u50cf\uff0cbox\u548clabel,\u6ce8\u610f\uff1a\u8981\u548c\u5199\u5165\u65f6\u662f\u4e00\u4e00\u5bf9\u5e94\u7684 feature_description = { 'image' : tf . io . FixedLenFeature ([], tf . string ), 'width' : tf . io . FixedLenFeature ([], tf . float32 ), 'height' : tf . io . FixedLenFeature ([], tf . float32 ), 'xmin' : tf . io . VarLenFeature ( tf . float32 ), 'ymin' : tf . io . VarLenFeature ( tf . float32 ), 'xmax' : tf . io . VarLenFeature ( tf . float32 ), 'ymax' : tf . io . VarLenFeature ( tf . float32 ), 'label' : tf . io . VarLenFeature ( tf . int64 ), } # \u5c06tfrecord\u4e2d\u7684\u6570\u636e\u8f6c\u6362\u4e3a\u539f\u59cb\u56fe\u50cf\u548c\u6807\u6ce8\u4fe1\u606f\uff08\u53ea\u80fd\u5bf9\u4e00\u4e2a\u6570\u636e\u8fdb\u884c\u5904\u7406\uff09 def parse_example ( example_string ): # \u5c06tfreocord\u6587\u4ef6\u4e2d\u7684\u4e00\u4e2aexample\u6620\u5c04\u56de\u539f\u59cb\u6570\u636e feature_dict = tf . io . parse_single_example ( example_string , feature_description ) # \u83b7\u53d6\u56fe\u50cf\u6570\u636e image_data = tf . io . decode_jpeg ( feature_dict [ 'image' ]) # \u83b7\u53d6box boxes = tf . stack ([ tf . sparse . to_dense ( feature_dict [ 'xmin' ]), tf . sparse . to_dense ( feature_dict [ 'ymin' ]), tf . sparse . to_dense ( feature_dict [ 'xmax' ]), tf . sparse . to_dense ( feature_dict [ 'ymax' ])], axis = 1 ) # \u83b7\u53d6\u6807\u6ce8\u4fe1\u606f boxes_category = tf . sparse . to_dense ( feature_dict [ 'label' ]) # \u8fd4\u56de\u7ed3\u679c return image_data , feature_dict [ 'width' ], feature_dict [ 'height' ], boxes , boxes_category # \u5229\u7528map\u65b9\u6cd5\u8c03\u7528parse_example\u65b9\u6cd5\u5bf9\u6240\u6709\u6570\u636e\u8fdb\u884c\u5904\u7406\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u7ecf\u8fc7 raw_datasets = raw_datasets . map ( parse_example ) \u6211\u4eec\u5c06\u4eceTFRecord\u6587\u4ef6\u4e2d\u8bfb\u53d6\u7684\u6570\u636e\u5c55\u793a\u51fa\u6765\uff1a # \u5c06VOC_class\u5b57\u5178\u7684key\u548cvalue\u8fdb\u884c\u7ffb\u8f6c new_voc_class = { v : k for k , v in voc_classes . items ()} # \u5c06tfrecord\u4e2d\u7684\u56fe\u50cf\u8fdb\u884c\u5c55\u793a plt . figure ( figsize = ( 15 , 10 )) # \u521d\u59cb\u5316\uff1a\u7b2c\u51e0\u4e2a\u56fe\u50cf i = 0 # \u4eceraw_datasets\u4e2d\u9009\u53d63\u4e2a\u6837\u672c\uff0c\u83b7\u53d6\u56fe\u50cf\uff0c\u5927\u5c0f\uff0c\u6846\u7684\u6807\u6ce8\u4fe1\u606f\u548c\u7c7b\u522b\u4fe1\u606f for image , width , height , boxes , boxes_category in raw_datasets . take ( 3 ): # \u8fdb\u884c\u7ed8\u56fe plt . subplot ( 1 , 3 , i + 1 ) # \u7ed8\u5236\u56fe\u50cf plt . imshow ( image ) # \u83b7\u53d6\u5750\u6807\u533a\u57df ax = plt . gca () # \u904d\u5386\u6240\u6709\u7684\u6846 for j in range ( boxes . shape [ 0 ]): # \u7ed8\u5236\u6846 rect = Rectangle (( boxes [ j , 0 ], boxes [ j , 1 ]), boxes [ j , 2 ] - boxes [ j , 0 ], boxes [ j , 3 ] - boxes [ j , 1 ], color = 'r' , fill = False ) # \u5c06\u6846\u663e\u793a\u5728\u56fe\u50cf\u4e0a ax . add_patch ( rect ) # \u663e\u793a\u6807\u6ce8\u4fe1\u606f # \u83b7\u53d6\u6807\u6ce8\u4fe1\u606f\u7684id label_id = boxes_category [ j ] # \u83b7\u53d6\u6807\u51c6\u4fe1\u606f label = new_voc_class . get ( label_id . numpy ()) # \u5c06\u6807\u6ce8\u4fe1\u606f\u6dfb\u52a0\u5728\u56fe\u50cf\u4e0a ax . text ( boxes [ j , 0 ], boxes [ j , 1 ] + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) # \u4e0b\u4e00\u4e2a\u7ed3\u679c i += 1 # \u663e\u793a\u56fe\u50cf plt . show () \u7ed3\u679c\u4e3a\uff1a 1.4 \u6570\u636e\u5904\u7406\u7684Pipeline \u00b6 \u4f7f\u7528\u6570\u636e\u5904\u7406\u7684tf.data.Dataset\u6a21\u5757\u4e2dpipline\u673a\u5236\uff0c\u53ef\u5b9e\u73b0CPU\u591a\u7ebf\u7a0b\u5904\u7406\u8f93\u5165\u7684\u6570\u636e\uff0c\u5982\u8bfb\u53d6\u56fe\u7247\u548c\u56fe\u7247\u7684\u4e00\u4e9b\u7684\u9884\u5904\u7406\uff0c\u8fd9\u6837GPU\u53ef\u4ee5\u4e13\u6ce8\u4e8e\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u800cCPU\u53bb\u51c6\u5907\u6570\u636e\u3002 Dataset\u652f\u6301\u4e00\u7c7b\u7279\u6b8a\u7684\u64cd\u4f5c\uff1aTransformation\u3002\u4e00\u4e2aDataset\u901a\u8fc7Transformation\u53d8\u6210\u4e00\u4e2a\u65b0\u7684Dataset\u3002\u901a\u5e38\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7Transformation\u5b8c\u6210\u6570\u636e\u53d8\u6362\uff0c\u6253\u4e71\uff0c\u7ec4\u6210batch\uff0c\u751f\u6210epoch\u7b49\u4e00\u7cfb\u5217\u64cd\u4f5c\u3002\u5e38\u7528\u7684Transformation\u6709\uff1amap\u3001batch\u3001shuffle\u548crepeat\u3002\u89e3\u6790tfrecord\u6587\u4ef6\u5f97\u5230\u7684\u6570\u636e\u90fd\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e9b\u65b9\u6cd5\uff0c\u4f8b\u5982\u6211\u4eec\u524d\u9762\u4f7f\u7528\u7684\uff1a # \u5229\u7528map\u65b9\u6cd5\u8c03\u7528parse_example\u65b9\u6cd5\u5bf9\u6240\u6709\u6570\u636e\u8fdb\u884c\u5904\u7406\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u7ecf\u8fc7 raw_datasets = raw_datasets . map ( parse_example ) \u4e0b\u9762\u6211\u4eec\u5206\u522b\u4ecb\u7ecd\uff1a 1.4.1 map \u00b6 \u4f7f\u7528 tf.data.Dataset.map\uff0c\u6211\u4eec\u53ef\u4ee5\u5f88\u65b9\u4fbf\u5730\u5bf9\u6570\u636e\u96c6\u4e2d\u7684\u5404\u4e2a\u5143\u7d20\u8fdb\u884c\u9884\u5904\u7406\u3002\u56e0\u4e3a\u8f93\u5165\u5143\u7d20\u4e4b\u95f4\u65f6\u72ec\u7acb\u7684\uff0c\u6240\u4ee5\u53ef\u4ee5\u5728\u591a\u4e2a CPU \u6838\u5fc3\u4e0a\u5e76\u884c\u5730\u8fdb\u884c\u9884\u5904\u7406\u3002map \u53d8\u6362\u63d0\u4f9b\u4e86\u4e00\u4e2a num_parallel_calls\u53c2\u6570\u53bb\u6307\u5b9a\u5e76\u884c\u7684\u7ea7\u522b\u3002 dataset = dataset . map ( map_func = parse_fn , num_parallel_calls = FLAGS . num_parallel_calls ) 1.4.2 repeat \u00b6 repeat\u7684\u529f\u80fd\u5c31\u662f\u5c06\u6574\u4e2a\u5e8f\u5217\u91cd\u590d\u591a\u6b21\uff0c\u4e3b\u8981\u7528\u6765\u5904\u7406\u673a\u5668\u5b66\u4e60\u4e2d\u7684epoch\uff0c\u5047\u8bbe\u539f\u5148\u7684\u6570\u636e\u662f\u4e00\u4e2aepoch\uff0c\u4f7f\u7528repeat(5)\u5c31\u53ef\u4ee5\u5c06\u4e4b\u53d8\u62105\u4e2aepoch\u7684\u6570\u636e\u3002 1.4.3 prefetch \u00b6 tf.data.Dataset.prefetch \u63d0\u4f9b\u89e3\u8026\u4e86 \u6570\u636e\u4ea7\u751f\u7684\u65f6\u95f4 \u548c \u6570\u636e\u6d88\u8017\u7684\u65f6\u95f4\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5728\u6570\u636e\u88ab\u8bf7\u6c42\u524d\uff0c\u5c31\u4ece dataset \u4e2d\u9884\u52a0\u8f7d\u4e00\u4e9b\u6570\u636e\uff0c\u4ece\u800c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\u3002prefech(n) \u4e00\u822c\u4f5c\u4e3a\u6700\u540e\u4e00\u4e2a transformation\uff0c\u5176\u4e2d n \u4e3a batch_size\u3002 prefetch \u7684\u4f7f\u7528\u65b9\u6cd5\u5982\u4e0b\uff1a # \u6700\u540e\u4e00\u4e2a\u53d8\u6362 dataset = dataset . prefetch ( buffer_size = FLAGS . prefetch_buffer_size ) return dataset \u53e6\u5916\u8fd8\u53ef\u4f7f\u7528bacth\u65b9\u6cd5\u7ec4\u6210\u6279\u6b21\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\uff0c\u4e5f\u53ef\u4f7f\u7528shuffle\u65b9\u6cd5\u5bf9\u6570\u636e\u6253\u4e71\u3002 1.5. \u6570\u636e\u5904\u7406 \u00b6 yoloV3\u6a21\u578b\u7684\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u662f32\u7684\u500d\u6570\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u5bf9\u56fe\u50cf\u8fdb\u884c\u5904\u7406\u3002\u5728\u8fd9\u91cc\u6211\u4eec\u5c06\u56fe\u50cf\u7684\u5c3a\u5ea6\u8c03\u6574\u4e3a416x416\u7684\u5927\u5c0f\uff0c\u4e3a\u4e86\u4fdd\u6301\u957f\u5bbd\u6bd4\uff0c\u6211\u5c06\u56db\u5468\u4e3a0\u7684\u50cf\u7d20\u4ee5\u7070\u5ea6\u503c128\u8fdb\u884c\u586b\u5145\u3002 def preprocess ( image , bbox , input_shape = ( 416 , 416 )): # \u589e\u52a0batch\u7ef4 image = tf . expand_dims ( image , axis = 0 ) # \u83b7\u53d6\u56fe\u50cf\u7684\u9ad8\u5bbd[height, width] img_shape = image . shape [ 1 : 3 ] # \u5c06\u56fe\u50cf\u8fdb\u884c\u8c03\u6574\uff0c\u63d2\u503c\u65b9\u6cd5\u662f\u53cc\u4e09\u6b21\u63d2\u503c\uff0c\u4fdd\u7559\u957f\u5bbd\u6bd4 resize_image = tf . image . resize ( image , input_shape , method = tf . image . ResizeMethod . BICUBIC , preserve_aspect_ratio = True ) # \u83b7\u53d6\u56fe\u50cf\u7684\u5bbd\u9ad8[height,width] resize_shape = resize_image . shape [ 1 : 3 ] # \u56fe\u50cf\u4e0a\u65b9\u7684\u586b\u5145\u5927\u5c0f top_pad = ( input_shape [ 0 ] - resize_shape [ 0 ]) // 2 # \u56fe\u50cf\u4e0b\u65b9\u7684\u586b\u5145\u5927\u5c0f bottom_pad = input_shape [ 0 ] - resize_shape [ 0 ] - top_pad # \u56fe\u50cf\u5de6\u65b9\u7684\u586b\u5145\u5927\u5c0f left_pad = ( input_shape [ 1 ] - resize_shape [ 1 ]) // 2 # \u56fe\u50cf\u53f3\u65b9\u7684\u586b\u5145\u5927\u5c0f right_pad = input_shape [ 1 ] - resize_shape [ 1 ] - left_pad # \u5c06\u56fe\u50cf\u5468\u56f4\u586b\u5145128 resize_image = tf . pad ( resize_image , [[ 0 , 0 ], [ top_pad , bottom_pad ], [ left_pad , right_pad ], [ 0 , 0 ]], constant_values = 128 ) # \u7c7b\u578b\u8f6c\u5316 image_data = tf . cast ( resize_image , tf . float32 ) / 255. # \u5bf9\u6807\u6ce8\u6846\u8fdb\u884c\u8c03\u6574\uff1a\u8fdb\u884c\u5c3a\u5ea6\u548c\u5e73\u79fb\u8c03\u6574 # \u5c3a\u5ea6\u53d8\u6362 bbox = bbox * tf . convert_to_tensor ( [ resize_shape [ 1 ], resize_shape [ 0 ], resize_shape [ 1 ], resize_shape [ 0 ]], dtype = tf . float32 ) # \u9664\u4ee5\u539f\u56fe\u50cf\u5927\u5c0f bbox = bbox / tf . convert_to_tensor ( [ img_shape [ 1 ], img_shape [ 0 ], img_shape [ 1 ], img_shape [ 0 ]], dtype = tf . float32 ) # \u5e73\u79fb,\u83b7\u53d6\u6700\u7ec8\u7684\u7ed3\u679c bbox = bbox + tf . convert_to_tensor ( [ left_pad , top_pad , left_pad , top_pad ], dtype = tf . float32 ) # \u8fd4\u56de return image_data , bbox \u7ecf\u8fc7\u56fe\u50cf\u5904\u7406\u7684\u9001\u5165\u5230\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf\u7ed3\u679c\u4e3a: # \u5c06VOC_class\u5b57\u5178\u7684key\u548cvalue\u8fdb\u884c\u7ffb\u8f6c new_voc_class = { v : k for k , v in voc_classes . items ()} # \u5c06tfrecord\u4e2d\u7684\u56fe\u50cf\u8fdb\u884c\u5c55\u793a plt . figure ( figsize = ( 15 , 10 )) i = 0 # \u4eceraw_datasets\u4e2d\u9009\u53d63\u4e2a\u6837\u672c\uff0c\u83b7\u53d6\u56fe\u50cf\uff0c\u5927\u5c0f\uff0c\u6846\u7684\u6807\u6ce8\u4fe1\u606f\u548c\u7c7b\u522b\u4fe1\u606f for image , width , height , boxes , boxes_category in raw_datasets . take ( 3 ): # \u56fe\u50cf\u5904\u7406 image , boxes = preprocess ( image , boxes ) # \u8fdb\u884c\u7ed8\u56fe plt . subplot ( 1 , 3 , i + 1 ) # \u7ed8\u5236\u56fe\u50cf plt . imshow ( image [ 0 ]) # \u83b7\u53d6\u5750\u6807\u533a\u57df ax = plt . gca () # \u904d\u5386\u6240\u6709\u7684\u6846 for j in range ( boxes . shape [ 0 ]): # \u7ed8\u5236\u6846 rect = Rectangle (( boxes [ j , 0 ], boxes [ j , 1 ]), boxes [ j , 2 ] - boxes [ j , 0 ], boxes [ j , 3 ] - boxes [ j , 1 ], color = 'r' , fill = False ) # \u5c06\u6846\u663e\u793a\u5728\u56fe\u50cf\u4e0a ax . add_patch ( rect ) # \u663e\u793a\u6807\u6ce8\u4fe1\u606f # \u83b7\u53d6\u6807\u6ce8\u4fe1\u606f\u7684id label_id = boxes_category [ j ] # \u83b7\u53d6\u6807\u51c6\u4fe1\u606f label = new_voc_class . get ( label_id . numpy ()) # \u5c06\u6807\u6ce8\u4fe1\u606f\u6dfb\u52a0\u5728\u56fe\u50cf\u4e0a ax . text ( boxes [ j , 0 ], boxes [ j , 1 ] + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) # \u4e0b\u4e00\u4e2a\u7ed3\u679c i += 1 # \u663e\u793a\u56fe\u50cf plt . show () \u6548\u679c\u5982\u4e0b\u56fe\u6240\u793a: 2.\u6a21\u578b\u6784\u5efa \u00b6 yoloV3\u7684\u6a21\u578b\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a\u6574\u4e2av3\u7ed3\u6784\u91cc\u9762\uff0c\u6ca1\u6709\u6c60\u5316\u5c42\u548c\u5168\u8fde\u63a5\u5c42\uff0c\u7f51\u7edc\u7684\u4e0b\u91c7\u6837\u662f\u901a\u8fc7\u8bbe\u7f6e\u5377\u79ef\u7684stride\u4e3a2\u6765\u8fbe\u5230\u7684\uff0c\u6bcf\u5f53\u901a\u8fc7\u8fd9\u4e2a\u5377\u79ef\u5c42\u4e4b\u540e\u56fe\u50cf\u7684\u5c3a\u5bf8\u5c31\u4f1a\u51cf\u5c0f\u5230\u4e00\u534a\u3002 2.1 \u57fa\u672c\u7ec4\u4ef6 \u00b6 \u57fa\u672c\u7ec4\u4ef6\u6307\u84dd\u8272\u65b9\u6846\u5185\u90e8\u5206\uff1a 2.1.1 CBL \u00b6 Yolov3\u7f51\u7edc\u7ed3\u6784\u4e2d\u7684\u6700\u5c0f\u7ec4\u4ef6\uff0c\u7531Conv+Bn+Leaky_relu\u6fc0\u6d3b\u51fd\u6570\u4e09\u8005\u7ec4\u6210\uff0c \u6e90\u7801\u5b9e\u73b0\u5982\u4e0b\uff1a def ConvBlock ( input_shape , filters , kernel_size , strides = ( 1 , 1 ), padding = None ): # padding\u6839\u636e\u6b65\u957f\u7684\u5927\u5c0f\u8fdb\u884c\u4fee\u6539 padding = 'valid' if strides == ( 2 , 2 ) else 'same' # \u8f93\u5165 inputs = tf . keras . Input ( shape = input_shape ) # \u5377\u79ef\u5c42\uff1a\u52a0\u5165L2\u6b63\u5219\u5316\u7684\u5377\u79ef\u5c42 conv = tf . keras . layers . Conv2D ( filters , kernel_size = kernel_size , strides = strides , padding = padding , kernel_regularizer = tf . keras . regularizers . l2 ( l = 5e-4 ))( inputs ) # BN \u5c42 bn = tf . keras . layers . BatchNormalization ()( conv ) # \u6fc0\u6d3b\u51fd\u6570 relu = tf . keras . layers . LeakyReLU ( alpha = 0.1 )( bn ) # \u6a21\u578b\u6784\u5efa return tf . keras . Model ( inputs = inputs , outputs = relu ) 2.1.2 ResX \u00b6 \u6b8b\u5dee\u7ec4\u4ef6\u501f\u9274Resnet\u7f51\u7edc\u4e2d\u7684\u6b8b\u5dee\u7ed3\u6784\uff0c\u8ba9\u7f51\u7edc\u53ef\u4ee5\u6784\u5efa\u7684\u66f4\u6df1,ResX\u7531\u4e00\u4e2aCBL\u548cX\u4e2a\u6b8b\u5dee\u7ec4\u4ef6\u6784\u6210\uff0c\u662fYolov3\u4e2d\u7684\u5927\u7ec4\u4ef6\u3002\u6bcf\u4e2aRes\u6a21\u5757\u524d\u9762\u7684CBL\u90fd\u8d77\u5230\u4e0b\u91c7\u6837\u7684\u4f5c\u7528\u3002 def ResBlock ( input_shape , filters , blocks ): # \u6307\u5b9a\u8f93\u5165 inputs = tf . keras . Input ( shape = input_shape ) # \u5bf9\u8f93\u5165\u8fdb\u884cpad pad = tf . keras . layers . ZeroPadding2D ( padding = (( 1 , 0 ), ( 1 , 0 )))( inputs ) # \u5377\u79ef\u6b65\u957f\u4e3a2 results = ConvBlock ( pad . shape [ 1 :], filters = filters , kernel_size = ( 3 , 3 ), strides = ( 2 , 2 ))( pad ) # \u6784\u5efa\u6b8b\u5dee\u5355\u5143 for i in range ( blocks ): # \u5377\u79ef results_conv = ConvBlock ( results . shape [ 1 :], filters = filters // 2 , kernel_size = ( 1 , 1 ))( results ) # \u5377\u79ef results_conv = ConvBlock ( results_conv . shape [ 1 :], filters = filters , kernel_size = ( 3 , 3 ))( results_conv ) # \u878d\u548c results = tf . keras . layers . Add ()([ results_conv , results ]) # \u8fd4\u56de\u6a21\u578b return tf . keras . Model ( inputs = inputs , outputs = results ) 2.2 BackBone \u00b6 BackBone\u662fDarkNet53\u6784\u6210,\u7528\u6765\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u4e3b\u8981\u662fResX\u6a21\u5757\u3002 def Body ( input_shape ): # \u6a21\u578b\u8f93\u5165 inputs = tf . keras . Input ( shape = input_shape ) # \u5377\u79ef\u7ed3\u679c(batch, 416, 416, 32) cb = ConvBlock ( inputs . shape [ 1 :], filters = 32 , kernel_size = ( 3 , 3 ))( inputs ) # \u6b8b\u5dee\u6a21\u5757 (batch, 208, 208, 64) rb1 = ResBlock ( cb . shape [ 1 :], filters = 64 , blocks = 1 )( cb ) # (batch, 104, 104, 128) rb2 = ResBlock ( rb1 . shape [ 1 :], filters = 128 , blocks = 2 )( rb1 ) # (batch, 52, 52, 256) rb3 = ResBlock ( rb2 . shape [ 1 :], filters = 256 , blocks = 8 )( rb2 ) # (batch, 26, 26, 512) rb4 = ResBlock ( rb3 . shape [ 1 :], filters = 512 , blocks = 8 )( rb3 ) # (batch, 13, 13, 1024) rb5 = ResBlock ( rb4 . shape [ 1 :], filters = 1024 , blocks = 4 )( rb4 ) return tf . keras . Model ( inputs = inputs , outputs = ( rb5 , rb4 , rb3 )) 2.3 \u8f93\u51fa\u90e8\u5206 \u00b6 \u8f93\u51fa\u662f3\u4e2a\u5c3a\u5ea6\u8f93\u51fa\u7684CBL\u4e32\u8054\u7ed3\u6784\uff1a def Output ( input_shape , input_filters , output_filters ): # \u8f93\u5165\u6570\u636e inputs = tf . keras . Input ( shape = input_shape ) # \u8f93\u51fa\u8fde\u7eed\u7684\u516d\u4e2a\u6a21\u5757 cb1 = ConvBlock ( inputs . shape [ 1 :], filters = input_filters , kernel_size = ( 1 , 1 ))( inputs ) cb2 = ConvBlock ( cb1 . shape [ 1 :], filters = input_filters * 2 , kernel_size = ( 3 , 3 ))( cb1 ) cb3 = ConvBlock ( cb2 . shape [ 1 :], filters = input_filters , kernel_size = ( 1 , 1 ))( cb2 ) cb4 = ConvBlock ( cb3 . shape [ 1 :], filters = input_filters * 2 , kernel_size = ( 3 , 3 ))( cb3 ) cb5 = ConvBlock ( cb4 . shape [ 1 :], filters = input_filters , kernel_size = ( 1 , 1 ))( cb4 ) cb6 = ConvBlock ( cb5 . shape [ 1 :], filters = input_filters * 2 , kernel_size = ( 3 , 3 ))( cb5 ) # \u6700\u540e\u7684\u7b2c\u4e03\u4e2a\u5377\u79ef\u5757 cb7 = ConvBlock ( cb6 . shape [ 1 :], filters = output_filters , kernel_size = ( 1 , 1 ))( cb6 ) return tf . keras . Model ( inputs = inputs , outputs = ( cb5 , cb7 )) 2.4 V3\u6a21\u578b\u6784\u5efa \u00b6 \u5c06\u6a21\u578b\u7684backbone\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u878d\u5408\u540e\u9001\u5165\u5230output\u6a21\u5757\uff0c\u6784\u5efa\u6574\u4e2ayoloV3\u6a21\u578b\u3002 def YOLOv3 ( input_shape , class_num = 80 ): # anchor\u6570\u76ee anchor_num = 3 # \u8f93\u5165\u6570\u636e inputs = tf . keras . Input ( shape = input_shape ) # \u83b7\u53d6backbone\u8f93\u51fa\u76843\u4e2a\u7279\u5f81\u56fe large , middle , small = Body ( inputs . shape [ 1 :])( inputs ) # \u8f83\u5927\u76ee\u6807\u7684\u68c0\u6d4b x1 , y1 = Output ( large . shape [ 1 :], 512 , anchor_num * ( class_num + 5 ))( large ) # reshape\u6210\u6700\u7ec8\u7684\u6570\u636e\u7ed3\u679c y1 = tf . keras . layers . Reshape ( ( input_shape [ 0 ] // 32 , input_shape [ 1 ] // 32 , 3 , 5 + class_num ))( y1 ) # \u4e2d\u7b49\u76ee\u6807\u7684\u68c0\u6d4b cb1 = ConvBlock ( x1 . shape [ 1 :], filters = 256 , kernel_size = ( 1 , 1 ))( x1 ) # \u4e0a\u91c7\u6837 us1 = tf . keras . layers . UpSampling2D ( 2 )( cb1 ) # \u62fc\u63a5 cat1 = tf . keras . layers . Concatenate ()([ us1 , middle ]) # \u8ba1\u7b97\u8f93\u51fa\u7ed3\u679c x2 , y2 = Output ( cat1 . shape [ 1 :], 256 , anchor_num * ( class_num + 5 ))( cat1 ) # reshape\u6210\u6700\u7ec8\u7684\u6570\u636e\u7ed3\u679c y2 = tf . keras . layers . Reshape ( ( input_shape [ 0 ] // 16 , input_shape [ 1 ] // 16 , 3 , 5 + class_num ))( y2 ) # \u8f83\u5c0f\u76ee\u6807\u68c0\u6d4b cb2 = ConvBlock ( x2 . shape [ 1 :], filters = 128 , kernel_size = ( 1 , 1 ))( x2 ) # \u4e0a\u91c7\u6837 us2 = tf . keras . layers . UpSampling2D ( 2 )( cb2 ) # \u62fc\u63a5 cat2 = tf . keras . layers . Concatenate ()([ us2 , small ]) # \u8ba1\u7b97\u8f93\u51fa\u7ed3\u679c x3 , y3 = Output ( cat2 . shape [ 1 :], 128 , anchor_num * ( class_num + 5 ))( cat2 ) # reshape\u6210\u6700\u7ec8\u7684\u6570\u636e\u7ed3\u679c y3 = tf . keras . layers . Reshape ( ( input_shape [ 0 ] // 8 , input_shape [ 1 ] // 8 , 3 , 5 + class_num ))( y3 ) # \u8fd4\u56de\u7ed3\u679c return tf . keras . Model ( inputs = inputs , outputs = ( y1 , y2 , y3 )) 2.5 \u8f93\u51fa\u7ed3\u679c\u5904\u7406 \u00b6 \u7f51\u7edc\u7684\u8f93\u51fa\u7ed3\u679c\u662f\uff1a \u5750\u6807\u662f\u5bf9anchor\u7684\u4fee\u6b63\uff0c\u5c06\u5176\u8f6c\u6362\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u5bbd\u9ad8\u7684\u5f62\u5f0f\uff0c\u5728\u9884\u6d4b\u8fc7\u7a0b\u548c\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u65f6\u4f7f\u7528\u3002 V3\u7f51\u7edc\u8f93\u51fa\u7684\u7ed3\u679c\u4e3a$ t_x,t_y,t_w,t_h$ \u4e0e\u8fb9\u6846\u8868\u793a b_x,b_y,b_w,b_h b_x,b_y,b_w,b_h \u4e4b\u95f4\u7684\u5173\u7cfb\u662f\uff1a c_x,c_y c_x,c_y \u662f\u5f53\u524d\u7f51\u683c\u5de6\u4e0a\u89d2\u5230\u56fe\u50cf\u5de6\u4e0a\u89d2\u7684\u8ddd\u79bb\uff0c p_w,p_h p_w,p_h \u662f\u5148\u9a8c\u6846\u7684\u5bbd\u548c\u9ad8\u3002\u6839\u636e\u4e0a\u8ff0\u5173\u7cfb\u5bf9\u7f51\u7edc\u7684\u8f93\u51fa\u8fdb\u884c\u4fee\u6b63\u3002 \u53e6\u5916\u5bf9\u4e8e\u5206\u7c7b\u7684\u8f93\u51fa\u7ed3\u679c\u5e94\u9001\u5165\u5230Sigmoid\u6fc0\u6d3b\u51fd\u6570\u4e2d\u8fdb\u884c\u5904\u7406\u3002 \u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u4e86\u4e00\u4e2a\u5e38\u89c1\u7684\u65b9\u6cd5\uff0c\u5b83\u7684\u4f5c\u7528\u662f\u628a\u4efb\u610f\u7684\u8868\u8fbe\u5f0ffunction\u4f5c\u4e3a\u4e00\u4e2a\u201cLayer\u201d\u5bf9\u8c61: keras . layers . Lambda ( function , output_shape = None , mask = None , arguments = None ) \u53c2\u6570\uff1a function\uff1a\u9700\u8981\u5c01\u88c5\u7684\u51fd\u6570\u3002 output_shape: \u9884\u671f\u7684\u51fd\u6570\u8f93\u51fa\u5c3a\u5bf8\u3002 arguments: \u53ef\u9009\u7684\u9700\u8981\u4f20\u9012\u7ed9\u51fd\u6570\u7684\u5173\u952e\u5b57\u53c2\u6570 \u8f6c\u6362\u8fc7\u7a0b\u5982\u4e0b\uff1a # \u5c06\u7f51\u7edc\u7684\u8f93\u51fa\u7ed3\u679c\u8f6c\u6362\u4e3abbox\u7684\u5750\u6807\u53ca\u5bbd\u9ad8 def OutputParser ( input_shape , img_shape , anchors ): # feats/input_shape\u7684\u610f\u4e49\uff1a[batch,height,width,anchor_num,(1(delta x) + 1(delta y) + 1(width scale) + 1(height scale) + 1(object mask) + class_num(class probability))] feats = tf . keras . Input ( input_shape ) # \u83b7\u53d6\u7f51\u683cgrid\u7684\u5de6\u4e0a\u89d2x,y\u5750\u6807\uff0c\u5bf9\u5e94\u7740cx,cy # \u83b7\u53d6\u884cy\u7684\u5750\u6807 # 1.\u4f7f\u7528tf.shape\u83b7\u53d6feats\u7684\u9ad8 # 2.\u4f7f\u7528tf.cast\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362\uff0c\u8f6c\u6362\u4e3afloat32\u7c7b\u578b # 3.\u4f7f\u7528tf.range\u521b\u5efa\u6570\u5b57\u5e8f\u5217 # 4.\u4f7f\u7528tf.reshape\u8fdb\u884c\u5f62\u72b6\u8f6c\u6362\u4e3a(height,1,1,1) # 5.\u4f7f\u7528tf.tile\u5bf9\u4e0a\u8ff0\u7ed3\u679c\u6309\u7167\u5217\u6570x\u8fdb\u884c\u5e73\u94fa # 6.\u4f7f\u7528tf.keras.layers.Lambda\u8f6c\u6362\u6210\u5c42 grid_y = tf . keras . layers . Lambda ( lambda x : tf . tile ( tf . reshape ( tf . range ( tf . cast ( tf . shape ( x )[ 1 ], dtype = tf . float32 ), dtype = tf . float32 ), ( - 1 , 1 , 1 , 1 )), ( 1 , tf . shape ( x )[ 2 ], 1 , 1 )))( feats ) # \u83b7\u53d6\u5217x\u7684\u5750\u6807 # 1.\u4f7f\u7528tf.shape\u83b7\u53d6feats\u7684\u5bbd # 2.\u4f7f\u7528tf.cast\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362\uff0c\u8f6c\u6362\u4e3afloat32\u7c7b\u578b # 3.\u4f7f\u7528tf.range\u521b\u5efa\u6570\u5b57\u5e8f\u5217 # 4.\u4f7f\u7528tf.reshape\u8fdb\u884c\u5f62\u72b6\u8f6c\u6362\u4e3a(1,width,1,1) # 5.\u4f7f\u7528tf.tile\u5bf9\u4e0a\u8ff0\u7ed3\u679c\u6309\u7167\u884c\u6570y\u8fdb\u884c\u5e73\u94fa # 6.\u4f7f\u7528tf.keras.layers.Lambda\u8f6c\u6362\u6210\u5c42 grid_x = tf . keras . layers . Lambda ( lambda x : tf . tile ( tf . reshape ( tf . range ( tf . cast ( tf . shape ( x )[ 2 ], dtype = tf . float32 ), dtype = tf . float32 ), ( 1 , - 1 , 1 , 1 )), ( tf . shape ( x )[ 1 ], 1 , 1 , 1 )))( feats ) # \u6784\u5efagrid\u7684\u7f51\u683c\u8868\u793a # grid.shape = (grid h, grid w, 1, 2) grid = tf . keras . layers . Concatenate ( axis =- 1 )([ grid_x , grid_y ]) # \u83b7\u53d6\u6bcf\u4e00\u4e2a\u68c0\u6d4b\u7ed3\u679c\u4e2d\u5fc3\u70b9\u5750\u6807:\u5c06\u9884\u6d4b\u7ed3\u679c\u8f6c\u6362\u4e3a\u4e2d\u5fc3\u70b9\u5750\u6807 # box_xy = (delta x, delta y) + (priorbox upper left x,priorbox upper left y) / (feature map.width, feature map.height) # box_xy.shape = (batch, grid h, grid w, anchor_num, 2) box_xy = tf . keras . layers . Lambda ( lambda x : ( tf . math . sigmoid ( x [ 0 ][ ... , 0 : 2 ]) + x [ 1 ]) / tf . cast ( [ tf . shape ( x [ 1 ])[ 1 ], tf . shape ( x [ 1 ])[ 0 ]], dtype = tf . float32 ))([ feats , grid ]) # box_wh.shape = (batch, grid h, grid w, anchor_num, 2) # \u83b7\u53d6\u68c0\u6d4b\u7ed3\u679c\u7684\u5bbd\u9ad8 # box_wh = (width scale, height scale) * (anchor width, anchor height) / (image.width, image.height) box_wh = tf . keras . layers . Lambda ( lambda x , y , z : tf . math . exp ( x [ ... , 2 : 4 ]) * y / tf . cast ( [ z [ 1 ], z [ 0 ]], dtype = tf . float32 ), arguments = { 'y' : anchors , 'z' : img_shape })( feats ) # \u83b7\u53d6\u67d0\u4e00\u4e2aanchor\u4e2d\u5305\u542b\u76ee\u6807\u7684\u6982\u7387 box_confidence = tf . keras . layers . Lambda ( lambda x : tf . math . sigmoid ( x [ ... , 4 ]))( feats ) # \u83b7\u53d6\u67d0\u4e00\u4e2aanchor\u5c5e\u4e8e\u67d0\u4e00\u4e2a\u7c7b\u522b\u7684\u6982\u7387 box_class_probs = tf . keras . layers . Lambda ( lambda x : tf . math . sigmoid ( x [ ... , 5 :]))( feats ) # \u8fd4\u56de\u8f93\u51fa\u7ed3\u679c return tf . keras . Model ( inputs = feats , outputs = ( box_xy , box_wh , box_confidence , box_class_probs )) 3.\u6a21\u578b\u8bad\u7ec3 \u00b6 3.1\u635f\u5931\u51fd\u6570\u7684\u8ba1\u7b97 \u00b6 YoloV3\u7684\u635f\u5931\u51fd\u6570\u5206\u4e3a\u4e09\u90e8\u5206\uff1a box\u7684\u635f\u5931\uff1a \u53ea\u6709\u8d1f\u8d23\u68c0\u6d4b\u7684gridcell\u4e2d\u7684anchor\u624d\u4f1a\u8ba1\u5165\u635f\u5931,\u5bf9x,y,w,h\u5206\u522b\u6c42\u5747\u65b9\u8bef\u5dee \u7f6e\u4fe1\u5ea6\u7684\u635f\u5931 \u7f6e\u4fe1\u5ea6\u7684\u635f\u5931\u662f\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u6240\u6709\u7684box\u90fd\u8ba1\u5165\u635f\u5931\u8ba1\u7b97 \u5206\u7c7b\u7684\u635f\u5931\uff1a \u5206\u7c7b\u7684\u635f\u5931\u662f\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u53ea\u6709\u8d1f\u8d23\u68c0\u6d4b\u76ee\u6807\u7684\u624d\u8ba1\u7b97\u635f\u5931 def Loss ( img_shape , class_num = 80 ): # anchor\u7684\u5c3a\u5ea6\uff1a\u5206\u522b\u68c0\u6d4b\u5c0f\uff0c\u4e2d\uff0c\u5927\u7684\u76ee\u6807 anchors = { 2 : [[ 10 , 13 ], [ 16 , 30 ], [ 33 , 23 ]], 1 : [[ 30 , 61 ], [ 62 , 45 ], [ 59 , 119 ]], 0 : [[ 116 , 90 ], [ 156 , 198 ], [ 373 , 326 ]]} # \u6784\u5efa\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u7684\u6570\u7ec4 input_shapes = [ ( img_shape [ 0 ] // 32 , img_shape [ 1 ] // 32 , 3 , 5 + class_num ), ( img_shape [ 0 ] // 16 , img_shape [ 1 ] // 16 , 3 , 5 + class_num ), ( img_shape [ 0 ] // 8 , img_shape [ 1 ] // 8 , 3 , 5 + class_num ) ] # \u7f51\u7edc\u7684\u8f93\u51fa\u503c inputs = [ tf . keras . Input ( input_shape ) for input_shape in input_shapes ] # \u76ee\u6807\u503c labels = [ tf . keras . Input ( input_shape ) for input_shape in input_shapes ] losses = list () # \u904d\u5386\u4e09\u4e2a\u5c3a\u5ea6\u7684\u8f93\u51fa for l in range ( 3 ): # \u83b7\u53d6\u5f53\u524d\u5c3a\u5ea6\u7684\u5f62\u72b6 input_shape_of_this_layer = input_shapes [ l ] # \u83b7\u53d6\u5f53\u524d\u5c3a\u5ea6\u7684anchor anchors_of_this_layer = anchors [ l ] # \u83b7\u53d6\u7f51\u7edc\u8f93\u51fa input_of_this_layer = inputs [ l ] # \u83b7\u53d6\u5bf9\u5e94\u7684\u76ee\u6807\u503c label_of_this_layer = labels [ l ] # YOLOV3\u6a21\u578b\u8f93\u51fa\u7684\u7ed3\u679c\uff1a\u4e2d\u5fc3\u70b9\u5750\u6807\uff0c\u5bbd\u9ad8\uff0c\u7f6e\u4fe1\u5ea6 pred_xy , pred_wh , pred_box_confidence , pred_class = OutputParser ( input_shape_of_this_layer , img_shape , anchors_of_this_layer )( input_of_this_layer ) # \u9884\u6d4b\u6846 pred_box = tf . keras . layers . Concatenate ()([ pred_xy , pred_wh ]) # \u771f\u5b9e\u503c true_box = tf . keras . layers . Lambda ( lambda x : x [ ... , 0 : 4 ])( label_of_this_layer ) true_box_confidence = tf . keras . layers . Lambda ( lambda x : x [ ... , 4 ])( label_of_this_layer ) true_class = tf . keras . layers . Lambda ( lambda x : x [ ... , 5 :])( label_of_this_layer ) # \u83b7\u53d6box\u7684\u7f6e\u4fe1\u5ea6 object_mask = tf . keras . layers . Lambda ( lambda x : tf . cast ( x , dtype = tf . bool ))( true_box_confidence ) # \u8ba1\u7b97MSE\u635f\u5931\uff1a\u53ea\u6709\u6b63\u6837\u672c\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97 pos_loss = tf . keras . layers . Lambda ( lambda x : tf . math . reduce_sum ( tf . keras . losses . MSE ( tf . boolean_mask ( x [ 0 ], x [ 2 ]), tf . boolean_mask ( x [ 1 ], x [ 2 ]) )) )([ true_box , pred_box , object_mask ]) # \u7f6e\u4fe1\u5ea6\u7684\u635f\u5931\uff1a\u4ea4\u53c9\u71b5\u635f\u5931 confidence_loss = tf . keras . layers . Lambda ( lambda x : # \u6b63\u6837\u672c\u7684\u635f\u5931 tf . keras . losses . BinaryCrossentropy ( from_logits = False )( tf . boolean_mask ( x [ 0 ], x [ 2 ]), tf . boolean_mask ( x [ 1 ], x [ 2 ]) ) + # \u8d1f\u6837\u672c\u7684\u635f\u5931 100 * tf . keras . losses . BinaryCrossentropy ( from_logits = False )( tf . boolean_mask ( x [ 0 ], tf . math . logical_not ( x [ 2 ])), tf . boolean_mask ( x [ 1 ], tf . math . logical_not ( x [ 2 ])) ) )([ true_box_confidence , pred_box_confidence , object_mask ]) # \u5206\u7c7b\u635f\u5931\uff1a\u53ea\u6709\u6b63\u6837\u672c\u8ba1\u7b97\u635f\u5931 class_loss = tf . keras . layers . Lambda ( lambda x : tf . keras . losses . BinaryCrossentropy ( from_logits = False )( tf . boolean_mask ( x [ 0 ], x [ 2 ]), tf . boolean_mask ( x [ 1 ], x [ 2 ]) ) )([ true_class , pred_class , object_mask ]) # \u635f\u5931\u7ed3\u679c loss = tf . keras . layers . Lambda ( lambda x : tf . math . add_n ( x ))( [ pos_loss , confidence_loss , class_loss ]) losses . append ( loss ) # \u8ba1\u7b97\u635f\u5931\u503c loss = tf . keras . layers . Lambda ( lambda x : tf . math . add_n ( x ))( losses ) return tf . keras . Model ( inputs = ( * inputs , * labels ), outputs = loss ) 3.2 \u6b63\u8d1f\u6837\u672c\u7684\u8bbe\u5b9a \u00b6 \u5728\u4e0a\u8ff0\u7684loss\u8ba1\u7b97\u4e2d\uff0c\u8d1f\u8d23\u8fdb\u884c\u76ee\u6807\u9884\u6d4b\u7684anchor\u5c31\u662f\u6b63\u6837\u672c\uff0c\u800c\u4e0d\u8d1f\u8d23\u8fdb\u884c\u76ee\u6807\u9884\u6d4b\u7684\u5c31\u662f\u8d1f\u6837\u672c\uff0c\u4e5f\u5c31\u662f\u80cc\u666f\uff0c\u90a3\u5728\u8fd9\u91cc\u6211\u4eec\u662f\u5982\u4f55\u8bbe\u7f6e\u6b63\u8d1f\u6837\u672c\u7684\u5462\uff1f\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6b63\u6837\u672c \uff1a\u9996\u5148\u8ba1\u7b97\u76ee\u6807\u4e2d\u5fc3\u70b9\u843d\u5728\u54ea\u4e2agrid\u4e0a\uff0c\u7136\u540e\u8ba1\u7b97\u8fd9\u4e2agrid\u5bf9\u5e94\u76843\u4e2a\u5148\u9a8c\u6846\uff08anchor\uff09\u548c\u76ee\u6807\u771f\u5b9e\u4f4d\u7f6e\u7684IOU\u503c\uff0c\u53d6IOU\u503c\u6700\u5927\u7684\u5148\u9a8c\u6846\u548c\u76ee\u6807\u5339\u914d\u3002\u90a3\u4e48\u8be5anchor \u5c31\u8d1f\u8d23\u9884\u6d4b\u8fd9\u4e2a\u76ee\u6807\uff0c\u90a3\u8fd9\u4e2aanchor\u5c31\u4f5c\u4e3a\u6b63\u6837\u672c\uff0c\u5c06\u5176\u7f6e\u4fe1\u5ea6\u8bbe\u4e3a1\uff0c\u5176\u4ed6\u7684\u76ee\u6807\u503c\u6839\u636e\u6807\u6ce8\u4fe1\u606f\u8bbe\u7f6e\u3002 \u8d1f\u6837\u672c \uff1a\u6240\u6709\u4e0d\u662f\u6b63\u6837\u672c\u7684anchor\u90fd\u662f\u8d1f\u6837\u672c\uff0c\u5c06\u5176\u7f6e\u4fe1\u5ea6\u8bbe\u4e3a0\uff0c\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\uff0c\u5176\u5b83\u7684\u503c\u4e0d\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\uff0c\u9ed8\u8ba4\u4e3a0\u3002 \u5728\u5b9e\u73b0\u7684\u65f6\u5019\uff0c\u4e3a\u4e86\u63d0\u9ad8\u8ba1\u7b97\u901f\u5ea6\u505a\u4e86\u4f18\u5316\uff0c\u5728\u8ba1\u7b97\u662f\u5426\u4e3a\u6b63\u6837\u672c\u65f6\uff0c\u6211\u4eec\u8ba4\u4e3aanchor\u548c\u76ee\u6807\u7684\u4e2d\u5fc3\u70b9\u662f\u76f8\u540c\u7684\uff0c\u76f4\u63a5\u5229\u7528anchor\u548c\u76ee\u6807box\u7684\u5bbd\u9ad8\u8ba1\u7b97\u4ea4\u5e76\u6bd4\uff0c\u786e\u5b9a\u6b63\u6837\u672c\u3002\u5b9e\u73b0\u5982\u4e0b\uff1a \u5b9a\u4e49anchor: YOLOv3_anchors = np . array ([[ 10 , 13 ], [ 16 , 30 ], [ 33 , 23 ], [ 30 , 61 ], [ 62 , 45 ], [ 59 , 119 ], [ 116 , 90 ], [ 156 , 198 ], [ 373 , 326 ]], dtype = np . int32 ) \u5b9a\u4e49\u65b9\u6cd5\u8ba1\u7b97anchor\u5bf9\u5e94\u7684\u76ee\u6807\u503c\uff0c\u786e\u5b9a\u6b63\u8d1f\u6837\u672c\uff1a def bbox_to_tensor ( bbox , label , input_shape = ( 416 , 416 ), anchors = YOLOv3_anchors , num_classes = 80 ): # bbox\uff1a\u771f\u5b9e\u503c\u5750\u6807\u8868\u793a\u4e3a(xmin,ymin,xmax,ymax)\uff0c\u662f\u76f8\u5bf9\u5750\u6807 # label\uff1a \u6bcf\u4e2abbox\u7684\u7c7b\u522b # anchors = (9,2) # \u8fd4\u56de\uff1aanchor\u5bf9\u5e94\u7684\u771f\u5b9e\u503c,\u5373\u6b63\u8d1f\u6837\u672c\u7684\u6807\u8bb0\u7ed3\u679c \u83b7\u53d6\u5c3a\u5ea6\u4e2a\u6570\u548cbox\u7684\u7edd\u5bf9\u5750\u6807 # \u83b7\u53d6\u6709\u51e0\u4e2a\u5c3a\u5ea6\u7684\u8f93\u51fa\uff0c\u6bcf\u4e2a\u5c3a\u5ea6\u5bf9\u5e943\u4e2aanchor:3 num_layers = anchors . shape [ 0 ] // 3 # anchor\u5bf9\u5e94\u7684\u7279\u5f81\u56fe\u63a9\u7801\uff1a\u7b2c\u4e00\u4e2a\u7279\u5f81\u56fe\u5bf9\u5e94\u7b2c6\uff0c7\uff0c8\u4e2aanchor... anchor_mask = tf . cond ( tf . equal ( num_layers , 3 ), lambda : tf . constant ( [[ 6 , 7 , 8 ], [ 3 , 4 , 5 ], [ 0 , 1 , 2 ]]), lambda : tf . constant ([[ 3 , 4 , 5 ], [ 1 , 2 , 3 ]])) # bbox\u7684\u76f8\u5bf9\u4e2d\u5fc3\u70b9\u5750\u6807 true_boxes_xy = ( bbox [ ... , 0 : 2 ] + bbox [ ... , 2 : 4 ]) / 2. # bbox\u7684\u76f8\u5bf9\u5bbd\u9ad8 true_boxes_wh = tf . math . abs ( bbox [ ... , 2 : 4 ] - bbox [ ... , 0 : 2 ]) # bbox\u7684\u7ed3\u679c:\u5c06\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u5bbd\u9ad8\u62fc\u63a5\u5728\u4e00\u8d77 true_boxes = tf . concat ([ true_boxes_xy , true_boxes_wh ], axis =- 1 ) # bbox\u7684\u7edd\u5bf9\u5750\u6807\u548c\u7edd\u5bf9\u5bbd\u9ad8 boxes_xy = true_boxes [ ... , 0 : 2 ] * input_shape boxes_wh = true_boxes [ ... , 2 : 4 ] * input_shape \u521b\u5efa\u4e00\u4e2a\u4e0e\u7f51\u7edc\u8f93\u51fa\u5927\u5c0f\u76f8\u540c\u7684\u5168\u96f6\u6570\u7ec4\uff0c\u7528\u6765\u8bbe\u7f6e\u771f\u5b9e\u503c # \u751f\u6210\u4e0eyoloV3\u8f93\u51fa\u7ed3\u679c\u76f8\u540c\u5927\u5c0f\u7684\u51680\u6570\u7ec4\uff1ay_true.shape[layer] = (height, width, anchor num, 5 + class num) y_true = tuple (( np . zeros ( shape = ( input_shape [ 0 ] // { 0 : 32 , 1 : 16 , 2 : 8 }[ l ], input_shape [ 1 ] // { 0 : 32 , 1 : 16 , 2 : 8 }[ l ], tf . shape ( anchor_mask [ l , ... ])[ 0 ], 5 + num_classes ), dtype = np . float32 ) for l in range ( num_layers ))) \u8ba1\u7b97anchor\u7684\u4f4d\u7f6e\u4fe1\u606f # \u6269\u5c55\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u7528\u6765\u5b58\u653eanchor\u7684\u7d22\u5f15 anchors = tf . expand_dims ( tf . convert_to_tensor ( anchors , dtype = tf . float32 ), 0 ) # \u7528\u4e8e\u8ba1\u7b97\u4ea4\u5e76\u6bd4 # \u4ee5anchor\u4e2d\u5fc3\u4e3a\u539f\u70b9\uff0c\u8ba1\u7b97\u53f3\u4e0b\u89d2\u5750\u6807 anchor_maxes = anchors / 2. # \u4ee5anchor\u4e2d\u5fc3\u4e3a\u539f\u70b9\uff0c\u8ba1\u7b97\u5de6\u4e0a\u89d2\u5750\u6807 anchor_mins = - anchor_maxes \u5bf9\u76ee\u6807\u8fdb\u884c\u7b5b\u9009\uff0c\u53ea\u6709\u5bbd\u5ea6\u5927\u4e8e0\u7684\u8ba4\u4e3a\u662f\u771f\u6b63\u7684\u76ee\u6807 # \u521b\u5efa\u4e00\u4e2amask,\u6307\u660e\u76ee\u6807\u662f\u5426\u5b58\u5728\uff0c\u5bbd\u5ea6\u5927\u4e8e0\u7684\u8ba4\u4e3a\u662f\u771f\u5b9e\u7684\u76ee\u6807 valid_mask = tf . greater ( boxes_wh [ ... , 0 ], 0 \uff09 # \u83b7\u53d6\u771f\u5b9e\u7684\u76ee\u6807\u7684\u5bbd\u9ad8 wh = tf . boolean_mask ( boxes_wh , valid_mask ) # \u83b7\u53d6\u771f\u5b9e\u76ee\u6807\u7684box\uff1avalid_true_boxes.shape = (valid box num, 4) valid_true_boxes = tf . boolean_mask ( boxes , valid_mask ) # \u83b7\u53d6\u771f\u5b9e\u76ee\u6807\u7684\u6807\u7b7e\u503c\uff1avalid_label.shape = (valid box num) valid_label = tf . boolean_mask ( label , valid_mask ) \u83b7\u53d6\u4e0e\u76ee\u6807\u4ea4\u5e76\u6700\u5927\u7684anchor,\u90a3\u8fd9\u4e9banchor\u5373\u4e3a\u6b63\u6837\u672c # \u5f53\u56fe\u50cf\u4e2d\u5b58\u5728\u76ee\u6807\u65f6\uff0c\u8ba1\u7b97\u4e0e\u76ee\u6807\u4ea4\u5e76\u6bd4\u6700\u5927\u7684anchor\u4f5c\u4e3a\u6b63\u6837\u672c\uff0c\u5e76\u8bbe\u7f6e\u6807\u8bb0\u7ed3\u679c if wh . shape [ 0 ] > 0 : # \u6269\u5c55\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u7528\u6765\u5b58\u653e\u5bf9\u5e94\u7684anchor\uff1awh.shape = (valid box num, 1, 2) wh = tf . expand_dims ( wh , - 2 ) # \u4ee5box\u7684\u4e2d\u5fc3\u70b9\u4e3a\u539f\u70b9\uff1a\u8ba1\u7b97\u53f3\u4e0b\u89d2\u5750\u6807\uff1amax of width, height, box_maxes.shape = (valid box num, 1, 2) box_maxes = wh / 2 # \u4ee5box\u7684\u4e2d\u5fc3\u70b9\u4e3a\u539f\u70b9\uff1a\u8ba1\u7b97\u5de6\u4e0a\u89d2\u5750\u6807\uff1amin of width, height, box_mins.shape = (valid box num, 1, 2) box_mins = - box_maxes # \u8ba1\u7b97box\u4e0eanchor\u4ea4\u7684\u5de6\u4e0a\u89d2\u5750\u6807\uff1aintersect_mins.shape = (valid box num, anchor num(9), 2) intersect_mins = tf . math . maximum ( box_mins , anchor_mins ) # \u8ba1\u7b97box\u4e0eanchor\u4ea4\u7684\u53f3\u4e0b\u89d2\u5750\u6807\uff1aintersect_maxes.shape = (valid box num, anchor num(9), 2) intersect_maxes = tf . math . minimum ( box_maxes , anchor_maxes ) # \u8ba1\u7b97\u4ea4\u96c6\u7684\u5bbd\u9ad8\uff1aintersect_wh.shape = (valid box num, anchor num(9), 2) intersect_wh = tf . math . maximum ( intersect_maxes - intersect_mins , 0. ) # \u8ba1\u7b97\u4ea4\u96c6\u7684\u9762\u79ef\uff1aintersect_area.shape = (valid box num, anchor num(9)) intersect_area = intersect_wh [ ... , 0 ] * intersect_wh [ ... , 1 ] # \u8ba1\u7b97box\u7684\u9762\u79ef\uff1abox_area.shape = (valid box_num, 1) box_area = wh [ ... , 0 ] * wh [ ... , 1 ] # \u8ba1\u7b97anchor\u7684\u9762\u79ef\uff1aanchor_area.shape = (1, anchor num(9)) anchor_area = anchors [ ... , 0 ] * anchors [ ... , 1 ] # \u8ba1\u7b97\u4ea4\u5e76\u6bd4\uff1aiou.shape = (valid box num, anchor num(9)) iou = intersect_area / ( box_area + anchor_area - intersect_area ) # \u8ba1\u7b97\u4e0ebox\u4ea4\u5e76\u6bd4\u6700\u5927\u7684anchor,\u5c06\u5176\u4f5c\u4e3a\u6b63\u6837\u672c\uff1abest_anchor.shape = (valid box num) best_anchor = tf . math . argmax ( iou , axis =- 1 , output_type = tf . int32 ) \u904d\u5386\u5339\u914d\u6210\u529f\u7684anchor(\u6b63\u6837\u672c)\uff0c\u8bbe\u7f6e\u76ee\u6807\u503c # \u904d\u5386\u4e0ebox\u5339\u914d\u6210\u529f\u7684anchor for t in range ( tf . shape ( best_anchor )[ 0 ]): # \u83b7\u53d6\u7b2ct\u4e2aanchor n = best_anchor [ t ] # \u83b7\u53d6anchor\u7684\u4f4d\u7f6e pos = tf . where ( tf . equal ( anchor_mask , n )) # \u83b7\u53d6\u5c3a\u5ea6\u503c\uff1a0\uff0c1\uff0c2 l = pos [ 0 ][ 0 ] # \u83b7\u53d6\u5bf9\u5e94\u7684anchor\u7d22\u5f15 k = pos [ 0 ][ 1 ] # \u83b7\u53d6anchor\u5bf9\u5e94\u7684grid cell\u7684\u5217\u6570\uff0c\u9650\u5236\u57280\u5230\u6700\u5927\u503c\u4e4b\u95f4 i = int ( tf . clip_by_value ( valid_true_boxes [ t , 1 ] * y_true [ l ] . shape [ 0 ], clip_value_min = 0 , clip_value_max = y_true [ l ] . shape [ 0 ] - 1 )) # \u83b7\u53d6anchor\u5bf9\u5e94\u7684grid cell\u7684\u884c\u6570\uff0c\u9650\u5236\u57280\u5230\u6700\u5927\u503c\u4e4b\u95f4 j = int ( tf . clip_by_value ( valid_true_boxes [ t , 0 ] * y_true [ l ] . shape [ 1 ], clip_value_min = 0 , clip_value_max = y_true [ l ] . shape [ 1 ] - 1 )) # \u83b7\u53d6anchor\u7684\u7c7b\u522b c = valid_label [ t ] # box\u7684\u4f4d\u7f6e:(x,y,width,height) y_true [ l ][ i , j , k , 0 : 4 ] = valid_true_boxes [ t , 0 : 4 ] # \u5339\u914d\u4e0a\u7684\u90fd\u5305\u542b\u76ee\u6807\uff0c\u7f6e\u4fe1\u5ea6\u8bbe\u4e3a1 y_true [ l ][ i , j , k , 4 ] = 1 # \u7c7b\u522b\u4fe1\u606f y_true [ l ][ i , j , k , 5 + c ] = 1 \u8fd4\u56de\u7ed3\u679c # \u8fd4\u56de3\u4e2a\u5c3a\u5ea6\u5bf9\u5e94\u7684\u771f\u5b9e\u503c return ( tf . convert_to_tensor ( y_true [ 0 ]), tf . convert_to_tensor ( y_true [ 1 ]), tf . convert_to_tensor ( y_true [ 2 ])) 3.3 \u6a21\u578b\u8bad\u7ec3 \u00b6 \u63a5\u4e0b\u6765\u6211\u4eec\u5229\u7528\u5df2\u642d\u5efa\u597d\u7684\u7f51\u7edc\u548c\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a 3.3.1 \u83b7\u53d6\u6570\u636e\u96c6 \u00b6 \u9996\u5148\u4eceTFRecord\u6587\u4ef6\u4e2d\u83b7\u53d6\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u6570\u636e\u5904\u7406\uff0c\u5f97\u5230\u5bf9\u5e94\u7684\u76ee\u6807\u503c\uff0c\u8fd9\u4e9b\u901a\u8fc7map\u65b9\u6cd5\u6765\u5b9e\u73b0 1.\u5b9a\u4e49\u65b9\u6cd5\u8fdb\u884c\u6570\u636e\u5904\u7406\u548c\u83b7\u53d6\u76ee\u6807\u503c def map_function_impl ( image , bbox , label ): # \u56fe\u50cf\u5c3a\u5ea6\u8c03\u6574 image , bbox = preprocess ( image , bbox , random = True ) # \u83b7\u53d6\u5bf9\u5e94\u7684\u76ee\u6807\u503c label1 , label2 , label3 = bbox_to_tensor ( bbox , label ) # \u8fd4\u56de\u7ed3\u679c return image , label1 , label2 , label3 2.\u4f7f\u7528py_function\u6765\u63d0\u9ad8\u6027\u80fd def map_function ( image , width , height , boxes , boxes_category ): # \u5bf9\u6570\u636e\u8fdb\u884c\u5904\u7406\uff0c\u83b7\u53d6\u56fe\u50cf\u53ca\u76ee\u6807\u503c\uff1a\u63d0\u5347\u6027\u80fd image , label1 , label2 , label3 = tf . py_function ( map_function_impl , inp = [ image , boxes , boxes_category ], Tout = [ tf . float32 , tf . float32 , tf . float32 , tf . float32 ]) # \u5bf9\u56fe\u50cf\u548c\u76ee\u6807\u503c\u8fdb\u884c\u5c3a\u5ea6\u8c03\u6574 image = tf . reshape ( image , ( 416 , 416 , 3 )) label1 = tf . reshape ( label1 , ( 13 , 13 , 3 , 85 )) label2 = tf . reshape ( label2 , ( 26 , 26 , 3 , 85 )) label3 = tf . reshape ( label3 , ( 52 , 52 , 3 , 85 )) # \u8fd4\u56de\u7ed3\u679c return image , ( label1 , label2 , label3 ) 3.\u4f7f\u7528map\u65b9\u6cd5\u5bf9\u4eceTFRcords\u4e2d\u8bfb\u53d6\u7684\u6570\u636e\u8fdb\u884c\u5904\u7406 # \u4eceTFRecord\u6587\u4ef6\u4e2d\u83b7\u53d6\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u5904\u7406 batch_size = 10 trainset = raw_datasets . map ( map_function ) . shuffle ( batch_size ) . batch ( batch_size ) . prefetch ( tf . data . experimental . AUTOTUNE ) 3.3.2 \u6a21\u578b\u8bad\u7ec3 \u00b6 \u6a21\u578b\u521d\u59cb\u5316\uff1a yolov3 = YOLOv3 (( 416 , 416 , 3 ,), 20 ) yolov3_loss = Loss (( 416 , 416 , 3 ), 20 ) \u5b9a\u4e49\u4f18\u5316\u65b9\u6cd5\uff1a # \u5b9a\u4e49\u4f18\u5316\u65b9\u6cd5 optimizer = tf . keras . optimizers . Adam ( 1e-4 ) \u63a5\u4e0b\u6765\u8fdb\u884c\u7f51\u7edc\u8bad\u7ec3\uff0c\u8fd9\u91cc\u4f7f\u7528\uff1a 1.\u5b9a\u4e49tf.GradientTape\u7684\u4f5c\u7528\u57df\uff0c\u8ba1\u7b97\u635f\u5931\u503c 2.\u4f7f\u7528 tape.gradient(ys, xs)\u81ea\u52a8\u8ba1\u7b97\u68af\u5ea6 3.\u4f7f\u7528 optimizer.apply_gradients(grads_and_vars)\u81ea\u52a8\u66f4\u65b0\u6a21\u578b\u53c2\u6570 \u5b8c\u6210\u7f51\u7edc\u8bad\u7ec3\uff0c\u5e76\u4fdd\u5b58\u8bad\u7ec3\u7ed3\u679c # \u904d\u5386\u56fe\u50cf\u548c\u76ee\u6807\u503c\uff0c\u8fdb\u884c\u66f4\u65b0 for images , labels in trainset : # \u5b9a\u4e49\u4f5c\u7528\u57df with tf . GradientTape () as tape : # \u5c06\u56fe\u50cf\u9001\u5165\u7f51\u7edc\u4e2d outputs = yolov3 ( images ) # \u8ba1\u7b97\u635f\u5931\u51fd\u6570 loss = yolov3_loss ([ * outputs , * labels ]) # \u8ba1\u7b97\u68af\u5ea6 grads = tape . gradient ( loss , yolov3 . trainable_variables ) try : # \u8fdb\u884c\u68af\u5ea6\u68c0\u67e5 grads_check = [ tf . debugging . check_numerics ( grad , 'the grad is not correct! cancel gradient apply!' ) for grad in grads ] with tf . control_dependencies ( grads_check ): # \u68af\u5ea6\u66f4\u65b0 optimizer . apply_gradients ( zip ( grads , yolov3 . trainable_variables )) except BaseException as e : print ( e . message ) # \u4fdd\u5b58\u6a21\u578b\u8bad\u7ec3\u7ed3\u679c yolov3 . save ( 'yolov3.h5' ) 4.\u6a21\u578b\u9884\u6d4b \u00b6 \u6211\u4eec\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u9884\u6d4b,\u5728\u8fd9\u91cc\u6211\u4eec\u901a\u8fc7yoloV3\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\uff0c\u9884\u6d4b\u4e4b\u540e\u8f6c\u6362\u4e3a\u7edd\u5bf9\u5750\u6807\u540e\uff0c\u83b7\u53d6\u591a\u4e2a\u5c3a\u5ea6\u7684\u9884\u6d4b\u7ed3\u679c\u62fc\u63a5\u5728\u4e00\u8d77\uff0c\u4f7f\u7528NMS\u8fdb\u884c\u68c0\u6d4b\u6846\u7684\u7b5b\u9009\u3002 \u9996\u5148\u5b9a\u4e49\u9884\u6d4b\u7c7b\uff1a # \u5b9a\u4e49\u9884\u6d4b\u7c7b class Predictor ( object ): \u6307\u660eanchor\u7684\u5927\u5c0f\uff1a # anchorbox\u7684\u5927\u5c0f anchors = { 2 : [[ 10 , 13 ], [ 16 , 30 ], [ 33 , 23 ]], 1 : [[ 30 , 61 ], [ 62 , 45 ], [ 59 , 119 ]], 0 : [[ 116 , 90 ], [ 156 , 198 ], [ 373 , 326 ]]} 4.1 \u521d\u59cb\u5316 \u00b6 \u8fdb\u884c\u6a21\u578b\u521d\u59cb\u5316 # \u521d\u59cb\u5316 def __init__ ( self , input_shape = ( 416 , 416 , 3 ), class_num = 80 , yolov3 = None ): # \u8f93\u5165\u5927\u5c0f self . input_shape = input_shape # \u6a21\u578b\u521d\u59cb\u5316 self . yolov3 = tf . keras . models . load_model ( 'yolov3.h5' , compile = False ) # \u5c06\u7ed3\u679c\u8f6c\u6362\u4e3a\u5750\u6807\u503c self . parsers = [ OutputParser ( tuple ( self . yolov3 . outputs [ l ] . shape [ 1 :]), self . input_shape , self . anchors [ l ]) for l in range ( 3 )] 4.2 \u9884\u6d4b\u65b9\u6cd5\u5b9e\u73b0 \u00b6 \u5728\u8fd9\u91cc\u52a0\u5165NMS\u65b9\u6cd5\uff1a 4.2.1 \u83b7\u53d6\u7f51\u7edc\u7684\u9884\u6d4b\u7ed3\u679c \u00b6 def predict ( self , image , conf_thres = 0.5 , nms_thres = 0.5 ): # conf_thres\uff1a\u7f6e\u4fe1\u5ea6\u7684\u9608\u503c\uff0cNMS\u4e2d\u4ea4\u5e76\u6bd4\u7684\u9608\u503c # \u589e\u52a0\u4e00\u7ef4batch images = tf . expand_dims ( image , axis = 0 ) # \u56fe\u50cf\u53d8\u5f62 resize_images = tf . image . resize ( images , self . input_shape [: 2 ], method = tf . image . ResizeMethod . BICUBIC , preserve_aspect_ratio = True ) # \u56fe\u50cf\u53d8\u5f62\u540e\u7684\u5927\u5c0f resize_shape = resize_images . shape [ 1 : 3 ] # \u56fe\u50cf\u5728\u4e0a\u4e0b\u5de6\u53f3\u586b\u5145\u7684\u5927\u5c0f top_pad = ( self . input_shape [ 0 ] - resize_shape [ 0 ]) // 2 bottom_pad = self . input_shape [ 0 ] - resize_shape [ 0 ] - top_pad left_pad = ( self . input_shape [ 1 ] - resize_shape [ 1 ]) // 2 right_pad = self . input_shape [ 1 ] - resize_shape [ 1 ] - left_pad # \u586b\u5145\u4e3a128 resize_images = tf . pad ( resize_images , [[ 0 , 0 ], [ top_pad , bottom_pad ], [ left_pad , right_pad ], [ 0 , 0 ]], constant_values = 128 ) # \u6807\u51c6\u5dee deviation = tf . constant ([ left_pad / self . input_shape [ 1 ], top_pad / self . input_shape [ 0 ], 0 , 0 ], dtype = tf . float32 ) # \u5c3a\u5ea6\u7684\u53d8\u6362 scale = tf . constant ([ self . input_shape [ 1 ] / resize_shape [ 1 ], self . input_shape [ 0 ] / resize_shape [ 0 ], self . input_shape [ 1 ] / resize_shape [ 1 ], self . input_shape [ 0 ] / resize_shape [ 0 ] ], dtype = tf . float32 ) # \u7c7b\u578b\u8f6c\u6362 images_data = tf . cast ( resize_images , tf . float32 ) / 255. # \u8f93\u51fa\u7ed3\u679c outputs = self . yolov3 ( images_data ) 4.2.2 \u7ed3\u679c\u7ec4\u5408 \u00b6 \u904d\u5386\u6bcf\u4e2a\u5c3a\u5ea6\u7684\u7ed3\u679c\uff0c\u8fdb\u884c\u62fc\u63a5 # \u76ee\u6807\u503c whole_targets = tf . zeros (( 0 , 6 ), dtype = tf . float32 ) # \u904d\u5386\u6bcf\u4e00\u4e2a\u5c3a\u5ea6 for i in range ( 3 ): # \u83b7\u53d6\u9884\u6d4b\u7684\u4f4d\u7f6e\u3001\u7f6e\u4fe1\u5ea6\u548c\u5206\u7c7b\u7ed3\u679c pred_xy , pred_wh , pred_box_confidence , pred_class = self . parsers [ i ]( outputs [ i ]) # \u83b7\u53d6\u76ee\u6807\u6846\u7684\u4f4d\u7f6e pred_box = tf . keras . layers . Concatenate ( axis =- 1 )([ pred_xy , pred_wh ]) #\u76ee\u6807\u6846\u7684\u7f6e\u4fe1\u5ea6\u5927\u4e8e\u9608\u503c\u7684\u90e8\u5206\uff1atarget_mask.shape = (h, w, anchor num) target_mask = tf . greater ( pred_box_confidence , conf_thres ) # \u83b7\u53d6\u5927\u4e8e\u9608\u503c\u7684\u90e8\u5206\u7684\u7f6e\u4fe1\u5ea6\uff1apred_box_confidence = (pred target num, 1) pred_box_confidence = tf . boolean_mask ( pred_box_confidence , target_mask ) # \u5728\u6700\u540e\u589e\u52a0\u4e00\u7ef4 pred_box_confidence = tf . expand_dims ( pred_box_confidence , axis =- 1 ) # \u83b7\u53d6\u5bf9\u5e94\u7684\u76ee\u6807\u6846\u68c0\u6d4b\u7ed3\u679c pred_box.shape = (pred target num, 4) pred_box = tf . boolean_mask ( pred_box , target_mask ) # \u5f52\u4e00\u5316\u5904\u7406 pred_box = ( pred_box - deviation ) * scale * \\ [ image . shape [ 1 ], image . shape [ 0 ], image . shape [ 1 ], image . shape [ 0 ]] # \u5206\u7c7b\u7ed3\u679c\uff1apred_class.shape = (pred target num, 1) pred_class = tf . boolean_mask ( pred_class , target_mask ) # \u83b7\u53d6\u6bcf\u4e2a\u7c7b\u522b\u6700\u5927\u7684\u7d22\u5f15 pred_class = tf . math . argmax ( pred_class , axis =- 1 ) # \u7c7b\u578b\u8f6c\u6362 pred_class = tf . cast ( tf . expand_dims ( pred_class , axis =- 1 ), dtype = tf . float32 ) # \u5c06\u9884\u6d4b\u7ed3\u679c\u62fc\u63a5\u5728\u4e00\u8d77 targets,sgaoe = (pred target num, 6) targets = tf . keras . layers . Concatenate ( axis =- 1 )([ pred_box , pred_box_confidence , pred_class ]) # \u5c06\u591a\u4e2a\u5c3a\u5ea6\u7684\u7ed3\u679c\u62fc\u63a5\u5728\u4e00\u8d77 whole_targets = tf . keras . layers . Concatenate ( axis = 0 )([ whole_targets , targets ]) 4.2.3 NMS \u00b6 \u8fdb\u884cNMS\u5f97\u5230\u6700\u7ec8\u7684\u9884\u6d4b\u7ed3\u679c # \u8fdb\u884cNMS,\u6392\u5e8f\u4ee5\u7f6e\u4fe1\u5ea6\u6392\u5e8f,\u4ece\u5927\u5230\u5c0f\u6392\u5e8f descend_idx = tf . argsort ( whole_targets [ ... , 4 ], direction = 'DESCENDING' ) i = 0 # \u904d\u5386 while i < descend_idx . shape [ 0 ]: # \u83b7\u53d6\u7d22\u5f15\u503c idx = descend_idx [ i ] # \u5de6\u4e0a\u89d2\u5750\u6807 cur_upper_left = whole_targets [ idx , 0 : 2 ] - whole_targets [ idx , 2 : 4 ] / 2 # \u53f3\u4e0b\u89d2\u5750\u6807 cur_down_right = cur_upper_left + whole_targets [ idx , 2 : 4 ] # \u5bbd\u9ad8 wh = whole_targets [ idx , 2 : 4 ] # \u83b7\u53d6\u9762\u79ef area = wh [ ... , 0 ] * wh [ ... , 1 ] # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u7d22\u5f15 following_idx = descend_idx [ i + 1 :] # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846 following_targets = tf . gather ( whole_targets , following_idx ) # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u5de6\u4e0a\u89d2\u5750\u6807 following_upper_left = following_targets [ ... , 0 : 2 ] - following_targets [ ... , 2 : 4 ] / 2 # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u53f3\u4e0b\u89d2\u5750\u6807 following_down_right = following_upper_left + following_targets [ ... , 2 : 4 ] # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u5bbd\u9ad8 following_wh = following_targets [ ... , 2 : 4 ] # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u9762\u79ef following_area = following_wh [ ... , 0 ] * following_wh [ ... , 1 ] # \u8ba1\u7b97\u4ea4\u5e76\u6bd4 # \u8ba1\u7b97\u4ea4\u7684\u5de6\u4e0a\u89d2\u5750\u6807 max_upper_left = tf . math . maximum ( cur_upper_left , following_upper_left ) # \u8ba1\u7b97\u4ea4\u7684\u53f3\u4e0b\u89d2\u5750\u6807 min_down_right = tf . math . minimum ( cur_down_right , following_down_right ) # \u4ea4\u7684\u5bbd\u9ad8 intersect_wh = min_down_right - max_upper_left # \u5c06\u5bbd\u9ad8\u5927\u4e8e0\uff0c\u4fdd\u6301\u4e0d\u53d8\uff0c\u5c0f\u4e8e0\u7684\u7f6e\u4e3a0 intersect_wh = tf . where ( tf . math . greater ( intersect_wh , 0 ), intersect_wh , tf . zeros_like ( intersect_wh )) # \u8ba1\u7b97\u4ea4\u7684\u9762\u79ef intersect_area = intersect_wh [ ... , 0 ] * intersect_wh [ ... , 1 ] # \u8ba1\u7b97\u4ea4\u5e76\u6bd4 overlap = intersect_area / ( area + following_area - intersect_area ) # \u83b7\u53d6\u5c0f\u4e8eNMS\u9608\u503c\u7684\u4fdd\u7559\uff0c\u5176\u4ed6\u7684\u820d\u5f03 indices = tf . where ( tf . less ( overlap , nms_thres )) # \u8fdb\u884c\u5207\u7247\uff0c\u4fdd\u7559\u7ed3\u679c following_idx = tf . gather_nd ( following_idx , indices ) # \u5c06\u5176\u6dfb\u52a0\u5230descend\u4e2d\u5373\u53ef descend_idx = tf . concat ([ descend_idx [: i + 1 ], following_idx ], axis = 0 ) i += 1 # \u83b7\u53d6\u6700\u7ec8\u7684\u7ed3\u679c whole_targets = tf . gather ( whole_targets , descend_idx ) # \u5de6\u4e0a\u89d2\u5750\u6807 upper_left = ( whole_targets [ ... , 0 : 2 ] - whole_targets [ ... , 2 : 4 ] / 2 ) # \u53f3\u4e0b\u89d2\u5750\u6807 down_right = ( upper_left + whole_targets [ ... , 2 : 4 ]) # \u83b7\u53d6\u68c0\u6d4b\u7ed3\u679c boundings = tf . keras . layers . Concatenate ( axis =- 1 )([ upper_left , down_right , whole_targets [ ... , 4 :]]) return boundings 4.3 \u9884\u6d4b\u7ed3\u679c \u00b6 \u6a21\u578b\u7684\u9884\u6d4b\u6548\u679c\uff1a import cv2 import numpy as np import matplotlib.pyplot as plt # \u56fe\u50cf\u8bfb\u53d6 img = cv2 . imread ( \"image.jpg\" ) # \u5b9e\u4f8b\u5316 predictor = Predictor () # \u83b7\u53d6\u7ed3\u679c boundings = predictor . predict ( img ) # \u663e\u793a\u56fe\u50cf plt . imshow ( img [:, :, :: - 1 ]) # \u83b7\u53d6\u5750\u6807\u533a\u57df ax = plt . gca () # \u52a0\u8f7d\u6a21\u578b\uff1a\u6a21\u578b\u8bad\u7ec3\u662f\u5728COCO\u6570\u636e\u96c6\u4e2d\u8fdb\u884c\u7684\uff0c # coco\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f classes = [ 'person' , 'bicycle' , 'car' , 'motorcycle' , 'airplane' , 'bus' , 'train' , 'truck' , 'boat' , 'traffic light' , 'fire hydrant' , 'stop sign' , 'parking meter' , 'bench' , 'bird' , 'cat' , 'dog' , 'horse' , 'sheep' , 'cow' , 'elephant' , 'bear' , 'zebra' , 'giraffe' , 'backpack' , 'umbrella' , 'handbag' , 'tie' , 'suitcase' , 'frisbee' , 'skis' , 'snowboard' , 'sports ball' , 'kite' , 'baseball bat' , 'baseball glove' , 'skateboard' , 'surfboard' , 'tennis racket' , 'bottle' , 'wine glass' , 'cup' , 'fork' , 'knife' , 'spoon' , 'bowl' , 'banana' , 'apple' , 'sandwich' , 'orange' , 'broccoli' , 'carrot' , 'hot dog' , 'pizza' , 'donut' , 'cake' , 'chair' , 'couch' , 'potted plant' , 'bed' , 'dining table' , 'toilet' , 'tv' , 'laptop' , 'mouse' , 'remote' , 'keyboard' , 'cell phone' , 'microwave' , 'oven' , 'toaster' , 'sink' , 'refrigerator' , 'book' , 'clock' , 'vase' , 'scissors' , 'teddy bear' , 'hair drier' , 'toothbrush' ] for bounding in boundings : # \u7ed8\u5236\u6846 rect = Rectangle (( bounding [ 0 ] . numpy (), bounding [ 1 ] . numpy ()), bounding [ 2 ] . numpy ( ) - bounding [ 0 ] . numpy (), bounding [ 3 ] . numpy () - bounding [ 1 ] . numpy (), color = 'r' , fill = False ) # \u5c06\u6846\u663e\u793a\u5728\u56fe\u50cf\u4e0a ax . add_patch ( rect ) # \u663e\u793a\u7c7b\u522b\u4fe1\u606f # \u83b7\u53d6\u7c7b\u522b\u4fe1\u606f\u7684id label_id = bounding [ 5 ] . numpy () . astype ( 'int32' ) # \u83b7\u53d6\u7c7b\u522b label = classes [ label_id ] # \u5c06\u6807\u6ce8\u4fe1\u606f\u6dfb\u52a0\u5728\u56fe\u50cf\u4e0a ax . text ( bounding [ 0 ] . numpy (), bounding [ 1 ] . numpy () + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) # \u4e0b\u4e00\u4e2a\u7ed3\u679c # \u663e\u793a\u56fe\u50cf plt . show () \u9884\u6d4b\u7ed3\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u603b\u7ed3 \u719f\u6089TFRecord\u6587\u4ef6\u7684\u4f7f\u7528\u65b9\u6cd5 TFRecord\u662fGoogle\u5b98\u65b9\u63a8\u8350\u4f7f\u7528\u7684\u6570\u636e\u683c\u5f0f\u5316\u5b58\u50a8\u5de5\u5177\uff0c\u4e3aTensorFlow\u91cf\u8eab\u6253\u9020\u7684\u3002TFRecord\u5185\u90e8\u5305\u542b\u591a\u4e2atf.train.Example\uff0c\u4e00\u822c\u6765\u8bf4\u5bf9\u5e94\u4e00\u4e2a\u56fe\u50cf\u6570\u636e\uff0c\u5728\u4e00\u4e2aExample\u6d88\u606f\u4f53\u4e2d\u5305\u542b\u4e86\u4e00\u7cfb\u5217\u7684tf.train.feature\u5c5e\u6027\uff0c\u800c \u6bcf\u4e00\u4e2afeature\u662f\u4e00\u4e2akey-value\u7684\u952e\u503c\u5bf9\u3002 \u77e5\u9053YoloV3\u6a21\u578b\u7ed3\u6784\u53ca\u6784\u5efa\u65b9\u6cd5 \u57fa\u672c\u7ec4\u4ef6\u7684\u6784\u5efa\uff0cbackbone\uff0coutput, yoloV3, \u8f93\u51fa\u503c\u7684\u8f6c\u6362 \u77e5\u9053\u6570\u636e\u5904\u7406\u65b9\u6cd5 \u77e5\u9053\u5bf9\u56fe\u50cf\u8fdb\u884cresize,\u4fdd\u6301\u5bbd\u9ad8\u6bd4\uff0c\u8fdb\u884cpad\u7684\u65b9\u6cd5 \u80fd\u591f\u5229\u7528yoloV3\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b \u77e5\u9053\u635f\u5931\u51fd\u6570\uff0c\u6b63\u8d1f\u6837\u672c\u8bbe\u7f6e\uff0c\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u9884\u6d4b\u7684\u8fc7\u7a0b\u3002","title":"4.5 YoloV3 \u6848\u4f8b"},{"location":"objectdection/05.yolo-demo/#45-yolov3","text":"\u5b66\u4e60\u76ee\u6807 \u719f\u6089TFRecord\u6587\u4ef6\u7684\u4f7f\u7528\u65b9\u6cd5 \u77e5\u9053YoloV3\u6a21\u578b\u7ed3\u6784\u53ca\u6784\u5efa\u65b9\u6cd5 \u77e5\u9053\u6570\u636e\u5904\u7406\u65b9\u6cd5 \u80fd\u591f\u5229\u7528yoloV3\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b","title":"4.5 YoloV3 \u6848\u4f8b"},{"location":"objectdection/05.yolo-demo/#1tfrecord","text":"\u8be5\u6848\u4f8b\u4e2d\u6211\u4eec\u4f9d\u7136\u4f7f\u7528VOC\u6570\u636e\u96c6\u6765\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff0c\u4e0d\u540c\u7684\u662f\u6211\u4eec\u8981\u5229\u7528tfrecord\u6587\u4ef6\u6765\u5b58\u50a8\u548c\u8bfb\u53d6\u6570\u636e\uff0c\u9996\u5148\u6765\u770b\u4e00\u4e0btfrecord\u6587\u4ef6\u7684\u76f8\u5173\u5185\u5bb9\u3002 \u4e3a\u4ec0\u4e48\u8981\u4f7f\u7528tfrecord\u6587\u4ef6\uff1f TFRecord\u662fGoogle\u5b98\u65b9\u63a8\u8350\u4f7f\u7528\u7684\u6570\u636e\u683c\u5f0f\u5316\u5b58\u50a8\u5de5\u5177\uff0c\u4e3aTensorFlow\u91cf\u8eab\u6253\u9020\u7684\u3002 TFRecord\u89c4\u8303\u4e86\u6570\u636e\u7684\u8bfb\u5199\u65b9\u5f0f\uff0c\u6570\u636e\u8bfb\u53d6\u548c\u5904\u7406\u7684\u6548\u7387\u90fd\u4f1a\u5f97\u5230\u663e\u8457\u7684\u63d0\u9ad8\u3002","title":"1.TFrecord\u6587\u4ef6"},{"location":"objectdection/05.yolo-demo/#11-tfrecord","text":"TFRecord \u662fGoogle\u5b98\u65b9\u63a8\u8350\u7684\u4e00\u79cd\u6570\u636e\u683c\u5f0f\uff0c\u662fGoogle\u4e13\u95e8\u4e3aTensorFlow\u8bbe\u8ba1\u7684\u4e00\u79cd\u6570\u636e\u683c\u5f0f\uff0c\u5229\u7528\u8fd9\u79cd\u65b9\u5f0f\u5b58\u50a8\u6570\u636e\u53ef\u4ee5\u4f7f\u5176\u4e0e\u7f51\u7edc\u67b6\u6784\u66f4\u9002\u914d\u3002TFRecord\u662f\u4e00\u79cd\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u5176\u80fd\u66f4\u597d\u7684\u5229\u7528\u5185\u5b58\uff0c\u4e0ecsv,hdf5\u6587\u4ef6\u662f\u7c7b\u4f3c\u7684\u3002 TFRecord\u7684\u6587\u4ef6\u7684\u5185\u5bb9\u5982\u4e0b\u56fe\u6240\u793a\uff1a TFRecord\u5185\u90e8\u5305\u542b\u591a\u4e2atf.train.Example\uff0c\u4e00\u822c\u6765\u8bf4\u5bf9\u5e94\u4e00\u4e2a\u56fe\u50cf\u6570\u636e\uff0c\u5728\u4e00\u4e2aExample\u6d88\u606f\u4f53\u4e2d\u5305\u542b\u4e86\u4e00\u7cfb\u5217\u7684tf.train.feature\u5c5e\u6027\uff0c\u800c \u6bcf\u4e00\u4e2afeature\u662f\u4e00\u4e2akey-value\u7684\u952e\u503c\u5bf9\uff0c\u5176\u4e2d\uff0ckey \u662fstring\u7c7b\u578b\uff0c\u800cvalue \u7684\u53d6\u503c\u6709\u4e09\u79cd\uff1a tf.train.bytes_list: \u53ef\u4ee5\u5b58\u50a8string \u548cbyte\u4e24\u79cd\u6570\u636e\u7c7b\u578b\u3002\u56fe\u50cf\u6570\u636e\u4f7f\u7528\u8fd9\u79cd\u65b9\u5f0f\u5b58\u50a8\u5373\u53ef\u3002 tf.train.float_list: \u53ef\u4ee5\u5b58\u50a8float(float32)\u4e0edouble(float64) \u4e24\u79cd\u6570\u636e\u7c7b\u578b \u3002 tf.train.int64_list: \u53ef\u4ee5\u5b58\u50a8\uff1abool, enum, int32, uint32, int64, uint64 \u3002 TFRecord \u5e76\u975e\u662fTensorFlow\u552f\u4e00\u652f\u6301\u7684\u6570\u636e\u683c\u5f0f\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528CSV\u6216\u6587\u672c\u7b49\u5176\u4ed6\u683c\u5f0f\uff0c\u4f46\u662f\u5bf9\u4e8eTensorFlow\u6765\u8bf4\uff0cTFRecord \u662f\u6700\u53cb\u597d\u7684\uff0c\u6700\u65b9\u4fbf\u7684\uff0c\u800c\u4e14tensorflow\u4e5f\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684API\u5e2e\u52a9\u6211\u4eec\u8f7b\u677e\u7684\u521b\u5efa\u548c\u83b7\u53d6TFRecord\u6587\u4ef6\u3002","title":"1.1 \u4ec0\u4e48\u662fTFrecord\u6587\u4ef6"},{"location":"objectdection/05.yolo-demo/#12-tfrecord","text":"\u5bf9\u4e8e\u4e2d\u5927\u6570\u636e\u96c6\u6765\u8bf4\uff0cGoogle\u5b98\u65b9\u63a8\u8350\u5148\u5c06\u6570\u636e\u96c6\u8f6c\u5316\u4e3aTFRecord\u6570\u636e, \u8fd9\u6837\u53ef\u52a0\u5feb\u5728\u6570\u636e\u8bfb\u53d6, \u9884\u5904\u7406\u4e2d\u7684\u901f\u5ea6\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u5c31\u5c06VOC\u6570\u636e\u96c6\u8f6c\u6362\u4e3aRecords\u683c\u5f0f\uff0c\u5728\u8fd9\u91cc\u9996\u5148\u8bfb\u53d6\u6807\u6ce8XML\u6587\u4ef6\uff0c\u5e76\u627e\u5230\u5bf9\u5e94\u7684\u56fe\u50cf\u6570\u636e\uff0c\u6700\u540e\u5c06\u6570\u636e\u5199\u5165TFRecords\u6587\u4ef6\u4e2d\u3002","title":"1.2 \u5c06\u6570\u636e\u8f6c\u6362\u4e3aTFRecord\u6587\u4ef6"},{"location":"objectdection/05.yolo-demo/#121","text":"VOC\u6570\u636e\u96c6\u7684\u6807\u6ce8\u4fe1\u606f\u5b58\u50a8\u5728xml\u6587\u4ef6\u4e2d\uff0c\u5728VOC2007\u7684\u6570\u636e\u4e2d\u4e3b\u8981\u83b7\u53d6fIlename\uff0cwidth\uff0cheight\uff0c\u548cobject\uff08\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\uff09\u4e0b\u7684name\uff08\u76ee\u6807\u540d\u79f0\uff09\u548cbndbox\uff08\u6846\u7684\u4f4d\u7f6e\uff09\u3002\u5177\u4f53\u5927\u5bb6\u53ef\u4ee5\u770b\u4e0b\u5728FasterRCNN\u4e2d\u7684\u4ecb\u7ecd\uff0c\u4ee3\u7801\u5982\u4e0b\u6240\u793a\uff1a import xml.dom.minidom as xdom # VOC\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f voc_classes = { 'none' : 0 , 'aeroplane' : 1 , 'bicycle' : 2 , 'bird' : 3 , 'boat' : 4 , 'bottle' : 5 , 'bus' : 6 , 'car' : 7 , 'cat' : 8 , 'chair' : 9 , 'cow' : 10 , 'diningtable' : 11 , 'dog' : 12 , 'horse' : 13 , 'motorbike' : 14 , 'person' : 15 , 'pottedplant' : 16 , 'sheep' : 17 , 'sofa' : 18 , 'train' : 19 , 'tvmonitor' : 20 , } # \u8bfb\u53d6XML\u6587\u4ef6\u4e2d\u7684\u4fe1\u606f def Prase_Singel_xml ( xml_path ): DOMTree = xdom . parse ( xml_path ) RootNode = DOMTree . documentElement #\u83b7\u53d6XML\u6587\u4ef6\u5bf9\u5e94\u7684\u56fe\u50cf image_name = RootNode . getElementsByTagName ( \"filename\" )[ 0 ] . childNodes [ 0 ] . data #\u83b7\u53d6\u56fe\u50cf\u5bbd\u548c\u9ad8 size = RootNode . getElementsByTagName ( \"size\" ) image_height = int ( size [ 0 ] . getElementsByTagName ( \"height\" )[ 0 ] . childNodes [ 0 ] . data ) image_width = int ( size [ 0 ] . getElementsByTagName ( \"width\" )[ 0 ] . childNodes [ 0 ] . data ) #\u83b7\u53d6\u56fe\u50cf\u4e2d\u76ee\u6807\u5bf9\u8c61 all_obj = RootNode . getElementsByTagName ( \"object\" ) bndbox_lable_dic = [] # \u904d\u5386\u6240\u6709\u7684\u5bf9\u8c61 for one_obj in all_obj : # \u83b7\u53d6\u76ee\u6807\u7684\u6807\u6ce8\u4fe1\u606f obj_name = one_obj . getElementsByTagName ( \"name\" )[ 0 ] . childNodes [ 0 ] . data # \u83b7\u53d6\u5bf9\u5e94\u7684label\u503c obj_label = voc_classes [ obj_name ] # \u83b7\u53d6bbox bndbox = one_obj . getElementsByTagName ( \"bndbox\" ) # \u83b7\u53d6\u76ee\u6807\u7684\u5de6\u4e0a\u53f3\u4e0b\u7684\u4f4d\u7f6e xmin = int ( bndbox [ 0 ] . getElementsByTagName ( \"xmin\" )[ 0 ] . childNodes [ 0 ] . data ) ymin = int ( bndbox [ 0 ] . getElementsByTagName ( \"ymin\" )[ 0 ] . childNodes [ 0 ] . data ) xmax = int ( bndbox [ 0 ] . getElementsByTagName ( \"xmax\" )[ 0 ] . childNodes [ 0 ] . data ) ymax = int ( bndbox [ 0 ] . getElementsByTagName ( \"ymax\" )[ 0 ] . childNodes [ 0 ] . data ) # \u5c06\u76ee\u6807\u6846\u548c\u7c7b\u522b\u7ec4\u5408\u5728\u4e00\u8d77 bndbox_lable_dic . append ([ xmin , ymin , xmax , ymax , obj_label ]) # \u8fd4\u56de\u76f8\u5e94\u7684\u4fe1\u606f return image_name , image_width , image_height , bndbox_lable_dic \u63a5\u4e0b\u6765\u6211\u4eec\u8bfb\u53d6\u4e00\u4e2aXML\u6587\u4ef6\u770b\u4e0b\u6548\u679c\uff1a # \u5c55\u793a\u6548\u679c print ( Prase_Singel_xml ( 'VOCdevkit/VOC2007/Annotations/000007.xml' )) \u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a ( '000007.jpg' , 500 , 333 , [[ 141 , 50 , 500 , 330 , 7 ]]) \u4ece\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u5bf9\u5e94\u7684\u56fe\u50cf\u662f000007.jpg\uff0c\u56fe\u50cf\u7684\u5bbd\u9ad8\u662f500, 333\uff0c\u56fe\u50cf\u4e2d\u53ea\u5305\u542b\u4e00\u4e2a\u76ee\u6807\uff0c\u4f4d\u7f6e\u662f141, 50, 500, 330\uff0c\u7c7b\u522b\u662f7 car.","title":"1.2.1 \u8bfb\u53d6\u6807\u6ce8\u4fe1\u606f"},{"location":"objectdection/05.yolo-demo/#122-tfrecord","text":"\u5728\u5c06\u6570\u636e\u5199\u5165\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528tf.io.TFRecordWriter\u6765\u5b8c\u6210\uff0c\u4e3b\u8981\u6b65\u9aa4\u662f\uff1a 1\u3001\u4f7f\u7528tf.io.TFRecordWriter\u6253\u5f00TFRecords\u6587\u4ef6 2\u3001\u4f7f\u7528tf.train.Int64List\uff0ctf.train.BytesList\u6216tf.train.FloatList\u5bf9\u6570\u636e\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362 3\u3001\u5c06\u7c7b\u578b\u8f6c\u6362\u540e\u7684\u6570\u636e\u4f20\u5165tf.train.Feature\u521b\u5efa\u7684\u7279\u5f81\u4e2d 4\u3001\u5c06\u7279\u5f81\u4f20\u5165tf.train.Example\u521b\u5efa\u7684example\u4e2d 5\u3001\u4f7f\u7528example.SerializeToString()\u5c06example\u5e8f\u5217\u5316\u4e3a\u5b57\u7b26\u4e32 6\u3001\u4f7f\u7528writer.write\u5c06\u5e8f\u5217\u5316\u540e\u7684example\u5199\u5165TFRecords\u6587\u4ef6 7\u3001\u6700\u540e\u4f7f\u7528writer.close\uff08\uff09\u5173\u95ed\u6587\u4ef6 import tensorflow as tf import glob import os # \u6307\u660exml\u6587\u4ef6\uff0ctfrecord\u6587\u4ef6\u548c\u56fe\u50cf\u7684\u4f4d\u7f6e def write_to_tfrecord ( all_xml_path , tfrecord_path , voc_img_path ): # 1\u3001\u4f7f\u7528tf.io.TFRecordWriter\u6253\u5f00TFRecords\u6587\u4ef6 writer = tf . io . TFRecordWriter ( tfrecord_path ) # \u904d\u5386\u6240\u6709\u7684XML\u6587\u4ef6 for i , single_xml_path in enumerate ( all_xml_path ): # \u8bfb\u53d6xml\u6587\u4ef6\u4e2d\u7684\u5185\u5bb9 image_name , image_width , image_height , bndbox_lable_dic = Prase_Singel_xml ( single_xml_path ) # \u83b7\u53d6\u56fe\u50cf\u7684\u8def\u5f84 sigle_img_path = os . path . join ( voc_img_path , image_name ) # \u8bfb\u53d6\u56fe\u50cf image_data = open ( sigle_img_path , 'rb' ) . read () xmin = [] ymin = [] xmax = [] ymax = [] obj_label = [] # \u904d\u5386box\u548clabel\u4fe1\u606f\uff0c\u5e76\u8bb0\u5f55\u4e0b\u6765 for j in range ( len ( bndbox_lable_dic )): xmin . append ( bndbox_lable_dic [ j ][ 0 ]) ymin . append ( bndbox_lable_dic [ j ][ 1 ]) xmax . append ( bndbox_lable_dic [ j ][ 2 ]) ymax . append ( bndbox_lable_dic [ j ][ 3 ]) obj_label . append ( bndbox_lable_dic [ j ][ 4 ]) # \u521b\u5efa\u7279\u5f81\uff1a\u56fe\u50cf\uff0csize,box\u548clabel # 2\u3001\u4f7f\u7528tf.train.Int64List\uff0ctf.train.BytesList\u6216tf.train.FloatList\u5bf9\u6570\u636e\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362 # 3\u3001\u5c06\u7c7b\u578b\u8f6c\u6362\u540e\u7684\u6570\u636e\u4f20\u5165tf.train.Feature\u521b\u5efa\u7684\u7279\u5f81\u4e2d feature = { 'image' : tf . train . Feature ( bytes_list = tf . train . BytesList ( value = [ image_data ])), 'width' : tf . train . Feature ( float_list = tf . train . FloatList ( value = [ image_width ])), 'height' : tf . train . Feature ( float_list = tf . train . FloatList ( value = [ image_height ])), 'xmin' : tf . train . Feature ( float_list = tf . train . FloatList ( value = xmin )), 'ymin' : tf . train . Feature ( float_list = tf . train . FloatList ( value = ymin )), 'xmax' : tf . train . Feature ( float_list = tf . train . FloatList ( value = xmax )), 'ymax' : tf . train . Feature ( float_list = tf . train . FloatList ( value = ymax )), 'label' : tf . train . Feature ( int64_list = tf . train . Int64List ( value = obj_label )) } # 4\u3001\u5c06\u7279\u5f81\u4f20\u5165tf.train.Example\u521b\u5efa\u7684example\u4e2d example = tf . train . Example ( features = tf . train . Features ( feature = feature )) # \u5c06example\u5199\u5165\u5230tfrecord\u6587\u4ef6\u4e2d # 5\u3001\u4f7f\u7528example.SerializeToString()\u5c06example\u5e8f\u5217\u5316\u4e3a\u5b57\u7b26\u4e32 # 6\u3001\u4f7f\u7528writer.write\u5c06\u5e8f\u5217\u5316\u540e\u7684example\u5199\u5165TFRecords\u6587\u4ef6 writer . write ( example . SerializeToString ()) # \u6700\u540e\u4f7f\u7528writer.close\uff08\uff09\u5173\u95ed\u6587\u4ef6 writer . close () print ( '\u7b2c {} \u5f20\u56fe\u7247\u5199\u5165\u5b8c\u6bd5' . format ( i )) \u63a5\u4e0b\u6765\u8c03\u7528\u4e0a\u8ff0\u65b9\u6cd5\u5c06VOC\u6570\u636e\u5199\u5165\u5230TFRecord\u6587\u4ef6\u4e2d\uff1a # \u83b7\u53d6\u6240\u6709\u7684xml\u6587\u4ef6 all_xml_path = glob . glob ( 'VOCdevkit/VOC2007/Annotations/*.xml' ) # \u6307\u5b9atfrecords\u6587\u4ef6\u7684\u8def\u5f84 tfrecord_path = 'voc_2007.tfrecords' # \u6307\u5b9a\u56fe\u50cf\u6240\u5728\u7684\u8def\u5f84 voc_img_path = 'VOCdevkit/VOC2007/JPEGImages' # \u5c06\u4fe1\u606f\u5199\u5165\u5230tfrecord\u6587\u4ef6\u4e2d write_to_tfrecord ( all_xml_path , tfrecord_path , voc_img_path ) \u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a","title":"1.2.2 \u5c06\u6570\u636e\u5199\u5165TFRecord\u6587\u4ef6\u4e2d"},{"location":"objectdection/05.yolo-demo/#13-tfrecord","text":"VOC\u6570\u636e\u96c6\u5df2\u7ecf\u88ab\u5199\u5165\u5230TFRecord\u6587\u4ef6\u4e2d\u4e86\uff0c\u90a3\u6211\u4eec\u5c31\u8981\u4eceTFrecord\u6587\u4ef6\u4e2d\u5c06\u6570\u636e\u8bfb\u53d6\u51fa\u6765\u3002\u53ea\u9700\u8981\u7b80\u5355\u7684\u4f7f\u7528 tf.data.TFRecordDataset \u5c31\u80fd\u591f\u8f7b\u677e\u7684\u8bfb\u53d6\u6570\u636e\u3002 \u4f7f\u7528tf.data.TFRecordDataset\u6765\u83b7\u53d6TFRecord\u6587\u4ef6\u4e2d\u7684\u6570\u636e \u5b9a\u4e49\u7279\u5f81\u7684\u63cf\u8ff0\u65b9\u6cd5\uff0c\u4e0e\u5199\u5165\u65f6\u662f\u5bf9\u5e94\u7684 \u4f7f\u7528tf.io.parse_single_example\u5c06\u4e00\u4e2aexample\u8f6c\u6362\u4e3a\u539f\u59cb\u6570\u636e \u4f7f\u7528\u529f\u80fdmap\u65b9\u6cd5\u5bf9\u6240\u6709\u6570\u636e\u8fdb\u884c\u5904\u7406\u83b7\u53d6\u6700\u7ec8\u7684\u7ed3\u679c\uff08map\u65b9\u6cd5\u7a0d\u540e\u4ecb\u7ecd\uff09 import tensorflow as tf import os import numpy as np import matplotlib.pyplot as plt from matplotlib.patches import Rectangle # \u83b7\u53d6tfreocrd\u4e2d\u7684\u6240\u6709\u6570\u636e raw_datasets = tf . data . TFRecordDataset ( 'voc_2007.tfrecords' ) # \u5b9a\u4e49\u7279\u5f81\u7684\u63cf\u8ff0\u65b9\u6cd5\uff1a\u56fe\u50cf\uff0cbox\u548clabel,\u6ce8\u610f\uff1a\u8981\u548c\u5199\u5165\u65f6\u662f\u4e00\u4e00\u5bf9\u5e94\u7684 feature_description = { 'image' : tf . io . FixedLenFeature ([], tf . string ), 'width' : tf . io . FixedLenFeature ([], tf . float32 ), 'height' : tf . io . FixedLenFeature ([], tf . float32 ), 'xmin' : tf . io . VarLenFeature ( tf . float32 ), 'ymin' : tf . io . VarLenFeature ( tf . float32 ), 'xmax' : tf . io . VarLenFeature ( tf . float32 ), 'ymax' : tf . io . VarLenFeature ( tf . float32 ), 'label' : tf . io . VarLenFeature ( tf . int64 ), } # \u5c06tfrecord\u4e2d\u7684\u6570\u636e\u8f6c\u6362\u4e3a\u539f\u59cb\u56fe\u50cf\u548c\u6807\u6ce8\u4fe1\u606f\uff08\u53ea\u80fd\u5bf9\u4e00\u4e2a\u6570\u636e\u8fdb\u884c\u5904\u7406\uff09 def parse_example ( example_string ): # \u5c06tfreocord\u6587\u4ef6\u4e2d\u7684\u4e00\u4e2aexample\u6620\u5c04\u56de\u539f\u59cb\u6570\u636e feature_dict = tf . io . parse_single_example ( example_string , feature_description ) # \u83b7\u53d6\u56fe\u50cf\u6570\u636e image_data = tf . io . decode_jpeg ( feature_dict [ 'image' ]) # \u83b7\u53d6box boxes = tf . stack ([ tf . sparse . to_dense ( feature_dict [ 'xmin' ]), tf . sparse . to_dense ( feature_dict [ 'ymin' ]), tf . sparse . to_dense ( feature_dict [ 'xmax' ]), tf . sparse . to_dense ( feature_dict [ 'ymax' ])], axis = 1 ) # \u83b7\u53d6\u6807\u6ce8\u4fe1\u606f boxes_category = tf . sparse . to_dense ( feature_dict [ 'label' ]) # \u8fd4\u56de\u7ed3\u679c return image_data , feature_dict [ 'width' ], feature_dict [ 'height' ], boxes , boxes_category # \u5229\u7528map\u65b9\u6cd5\u8c03\u7528parse_example\u65b9\u6cd5\u5bf9\u6240\u6709\u6570\u636e\u8fdb\u884c\u5904\u7406\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u7ecf\u8fc7 raw_datasets = raw_datasets . map ( parse_example ) \u6211\u4eec\u5c06\u4eceTFRecord\u6587\u4ef6\u4e2d\u8bfb\u53d6\u7684\u6570\u636e\u5c55\u793a\u51fa\u6765\uff1a # \u5c06VOC_class\u5b57\u5178\u7684key\u548cvalue\u8fdb\u884c\u7ffb\u8f6c new_voc_class = { v : k for k , v in voc_classes . items ()} # \u5c06tfrecord\u4e2d\u7684\u56fe\u50cf\u8fdb\u884c\u5c55\u793a plt . figure ( figsize = ( 15 , 10 )) # \u521d\u59cb\u5316\uff1a\u7b2c\u51e0\u4e2a\u56fe\u50cf i = 0 # \u4eceraw_datasets\u4e2d\u9009\u53d63\u4e2a\u6837\u672c\uff0c\u83b7\u53d6\u56fe\u50cf\uff0c\u5927\u5c0f\uff0c\u6846\u7684\u6807\u6ce8\u4fe1\u606f\u548c\u7c7b\u522b\u4fe1\u606f for image , width , height , boxes , boxes_category in raw_datasets . take ( 3 ): # \u8fdb\u884c\u7ed8\u56fe plt . subplot ( 1 , 3 , i + 1 ) # \u7ed8\u5236\u56fe\u50cf plt . imshow ( image ) # \u83b7\u53d6\u5750\u6807\u533a\u57df ax = plt . gca () # \u904d\u5386\u6240\u6709\u7684\u6846 for j in range ( boxes . shape [ 0 ]): # \u7ed8\u5236\u6846 rect = Rectangle (( boxes [ j , 0 ], boxes [ j , 1 ]), boxes [ j , 2 ] - boxes [ j , 0 ], boxes [ j , 3 ] - boxes [ j , 1 ], color = 'r' , fill = False ) # \u5c06\u6846\u663e\u793a\u5728\u56fe\u50cf\u4e0a ax . add_patch ( rect ) # \u663e\u793a\u6807\u6ce8\u4fe1\u606f # \u83b7\u53d6\u6807\u6ce8\u4fe1\u606f\u7684id label_id = boxes_category [ j ] # \u83b7\u53d6\u6807\u51c6\u4fe1\u606f label = new_voc_class . get ( label_id . numpy ()) # \u5c06\u6807\u6ce8\u4fe1\u606f\u6dfb\u52a0\u5728\u56fe\u50cf\u4e0a ax . text ( boxes [ j , 0 ], boxes [ j , 1 ] + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) # \u4e0b\u4e00\u4e2a\u7ed3\u679c i += 1 # \u663e\u793a\u56fe\u50cf plt . show () \u7ed3\u679c\u4e3a\uff1a","title":"1.3 \u8bfb\u53d6TFRecord\u6587\u4ef6"},{"location":"objectdection/05.yolo-demo/#14-pipeline","text":"\u4f7f\u7528\u6570\u636e\u5904\u7406\u7684tf.data.Dataset\u6a21\u5757\u4e2dpipline\u673a\u5236\uff0c\u53ef\u5b9e\u73b0CPU\u591a\u7ebf\u7a0b\u5904\u7406\u8f93\u5165\u7684\u6570\u636e\uff0c\u5982\u8bfb\u53d6\u56fe\u7247\u548c\u56fe\u7247\u7684\u4e00\u4e9b\u7684\u9884\u5904\u7406\uff0c\u8fd9\u6837GPU\u53ef\u4ee5\u4e13\u6ce8\u4e8e\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u800cCPU\u53bb\u51c6\u5907\u6570\u636e\u3002 Dataset\u652f\u6301\u4e00\u7c7b\u7279\u6b8a\u7684\u64cd\u4f5c\uff1aTransformation\u3002\u4e00\u4e2aDataset\u901a\u8fc7Transformation\u53d8\u6210\u4e00\u4e2a\u65b0\u7684Dataset\u3002\u901a\u5e38\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7Transformation\u5b8c\u6210\u6570\u636e\u53d8\u6362\uff0c\u6253\u4e71\uff0c\u7ec4\u6210batch\uff0c\u751f\u6210epoch\u7b49\u4e00\u7cfb\u5217\u64cd\u4f5c\u3002\u5e38\u7528\u7684Transformation\u6709\uff1amap\u3001batch\u3001shuffle\u548crepeat\u3002\u89e3\u6790tfrecord\u6587\u4ef6\u5f97\u5230\u7684\u6570\u636e\u90fd\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e9b\u65b9\u6cd5\uff0c\u4f8b\u5982\u6211\u4eec\u524d\u9762\u4f7f\u7528\u7684\uff1a # \u5229\u7528map\u65b9\u6cd5\u8c03\u7528parse_example\u65b9\u6cd5\u5bf9\u6240\u6709\u6570\u636e\u8fdb\u884c\u5904\u7406\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u7ecf\u8fc7 raw_datasets = raw_datasets . map ( parse_example ) \u4e0b\u9762\u6211\u4eec\u5206\u522b\u4ecb\u7ecd\uff1a","title":"1.4 \u6570\u636e\u5904\u7406\u7684Pipeline"},{"location":"objectdection/05.yolo-demo/#141-map","text":"\u4f7f\u7528 tf.data.Dataset.map\uff0c\u6211\u4eec\u53ef\u4ee5\u5f88\u65b9\u4fbf\u5730\u5bf9\u6570\u636e\u96c6\u4e2d\u7684\u5404\u4e2a\u5143\u7d20\u8fdb\u884c\u9884\u5904\u7406\u3002\u56e0\u4e3a\u8f93\u5165\u5143\u7d20\u4e4b\u95f4\u65f6\u72ec\u7acb\u7684\uff0c\u6240\u4ee5\u53ef\u4ee5\u5728\u591a\u4e2a CPU \u6838\u5fc3\u4e0a\u5e76\u884c\u5730\u8fdb\u884c\u9884\u5904\u7406\u3002map \u53d8\u6362\u63d0\u4f9b\u4e86\u4e00\u4e2a num_parallel_calls\u53c2\u6570\u53bb\u6307\u5b9a\u5e76\u884c\u7684\u7ea7\u522b\u3002 dataset = dataset . map ( map_func = parse_fn , num_parallel_calls = FLAGS . num_parallel_calls )","title":"1.4.1 map"},{"location":"objectdection/05.yolo-demo/#142-repeat","text":"repeat\u7684\u529f\u80fd\u5c31\u662f\u5c06\u6574\u4e2a\u5e8f\u5217\u91cd\u590d\u591a\u6b21\uff0c\u4e3b\u8981\u7528\u6765\u5904\u7406\u673a\u5668\u5b66\u4e60\u4e2d\u7684epoch\uff0c\u5047\u8bbe\u539f\u5148\u7684\u6570\u636e\u662f\u4e00\u4e2aepoch\uff0c\u4f7f\u7528repeat(5)\u5c31\u53ef\u4ee5\u5c06\u4e4b\u53d8\u62105\u4e2aepoch\u7684\u6570\u636e\u3002","title":"1.4.2 repeat"},{"location":"objectdection/05.yolo-demo/#143-prefetch","text":"tf.data.Dataset.prefetch \u63d0\u4f9b\u89e3\u8026\u4e86 \u6570\u636e\u4ea7\u751f\u7684\u65f6\u95f4 \u548c \u6570\u636e\u6d88\u8017\u7684\u65f6\u95f4\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5728\u6570\u636e\u88ab\u8bf7\u6c42\u524d\uff0c\u5c31\u4ece dataset \u4e2d\u9884\u52a0\u8f7d\u4e00\u4e9b\u6570\u636e\uff0c\u4ece\u800c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\u3002prefech(n) \u4e00\u822c\u4f5c\u4e3a\u6700\u540e\u4e00\u4e2a transformation\uff0c\u5176\u4e2d n \u4e3a batch_size\u3002 prefetch \u7684\u4f7f\u7528\u65b9\u6cd5\u5982\u4e0b\uff1a # \u6700\u540e\u4e00\u4e2a\u53d8\u6362 dataset = dataset . prefetch ( buffer_size = FLAGS . prefetch_buffer_size ) return dataset \u53e6\u5916\u8fd8\u53ef\u4f7f\u7528bacth\u65b9\u6cd5\u7ec4\u6210\u6279\u6b21\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\uff0c\u4e5f\u53ef\u4f7f\u7528shuffle\u65b9\u6cd5\u5bf9\u6570\u636e\u6253\u4e71\u3002","title":"1.4.3 prefetch"},{"location":"objectdection/05.yolo-demo/#15","text":"yoloV3\u6a21\u578b\u7684\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u662f32\u7684\u500d\u6570\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u5bf9\u56fe\u50cf\u8fdb\u884c\u5904\u7406\u3002\u5728\u8fd9\u91cc\u6211\u4eec\u5c06\u56fe\u50cf\u7684\u5c3a\u5ea6\u8c03\u6574\u4e3a416x416\u7684\u5927\u5c0f\uff0c\u4e3a\u4e86\u4fdd\u6301\u957f\u5bbd\u6bd4\uff0c\u6211\u5c06\u56db\u5468\u4e3a0\u7684\u50cf\u7d20\u4ee5\u7070\u5ea6\u503c128\u8fdb\u884c\u586b\u5145\u3002 def preprocess ( image , bbox , input_shape = ( 416 , 416 )): # \u589e\u52a0batch\u7ef4 image = tf . expand_dims ( image , axis = 0 ) # \u83b7\u53d6\u56fe\u50cf\u7684\u9ad8\u5bbd[height, width] img_shape = image . shape [ 1 : 3 ] # \u5c06\u56fe\u50cf\u8fdb\u884c\u8c03\u6574\uff0c\u63d2\u503c\u65b9\u6cd5\u662f\u53cc\u4e09\u6b21\u63d2\u503c\uff0c\u4fdd\u7559\u957f\u5bbd\u6bd4 resize_image = tf . image . resize ( image , input_shape , method = tf . image . ResizeMethod . BICUBIC , preserve_aspect_ratio = True ) # \u83b7\u53d6\u56fe\u50cf\u7684\u5bbd\u9ad8[height,width] resize_shape = resize_image . shape [ 1 : 3 ] # \u56fe\u50cf\u4e0a\u65b9\u7684\u586b\u5145\u5927\u5c0f top_pad = ( input_shape [ 0 ] - resize_shape [ 0 ]) // 2 # \u56fe\u50cf\u4e0b\u65b9\u7684\u586b\u5145\u5927\u5c0f bottom_pad = input_shape [ 0 ] - resize_shape [ 0 ] - top_pad # \u56fe\u50cf\u5de6\u65b9\u7684\u586b\u5145\u5927\u5c0f left_pad = ( input_shape [ 1 ] - resize_shape [ 1 ]) // 2 # \u56fe\u50cf\u53f3\u65b9\u7684\u586b\u5145\u5927\u5c0f right_pad = input_shape [ 1 ] - resize_shape [ 1 ] - left_pad # \u5c06\u56fe\u50cf\u5468\u56f4\u586b\u5145128 resize_image = tf . pad ( resize_image , [[ 0 , 0 ], [ top_pad , bottom_pad ], [ left_pad , right_pad ], [ 0 , 0 ]], constant_values = 128 ) # \u7c7b\u578b\u8f6c\u5316 image_data = tf . cast ( resize_image , tf . float32 ) / 255. # \u5bf9\u6807\u6ce8\u6846\u8fdb\u884c\u8c03\u6574\uff1a\u8fdb\u884c\u5c3a\u5ea6\u548c\u5e73\u79fb\u8c03\u6574 # \u5c3a\u5ea6\u53d8\u6362 bbox = bbox * tf . convert_to_tensor ( [ resize_shape [ 1 ], resize_shape [ 0 ], resize_shape [ 1 ], resize_shape [ 0 ]], dtype = tf . float32 ) # \u9664\u4ee5\u539f\u56fe\u50cf\u5927\u5c0f bbox = bbox / tf . convert_to_tensor ( [ img_shape [ 1 ], img_shape [ 0 ], img_shape [ 1 ], img_shape [ 0 ]], dtype = tf . float32 ) # \u5e73\u79fb,\u83b7\u53d6\u6700\u7ec8\u7684\u7ed3\u679c bbox = bbox + tf . convert_to_tensor ( [ left_pad , top_pad , left_pad , top_pad ], dtype = tf . float32 ) # \u8fd4\u56de return image_data , bbox \u7ecf\u8fc7\u56fe\u50cf\u5904\u7406\u7684\u9001\u5165\u5230\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf\u7ed3\u679c\u4e3a: # \u5c06VOC_class\u5b57\u5178\u7684key\u548cvalue\u8fdb\u884c\u7ffb\u8f6c new_voc_class = { v : k for k , v in voc_classes . items ()} # \u5c06tfrecord\u4e2d\u7684\u56fe\u50cf\u8fdb\u884c\u5c55\u793a plt . figure ( figsize = ( 15 , 10 )) i = 0 # \u4eceraw_datasets\u4e2d\u9009\u53d63\u4e2a\u6837\u672c\uff0c\u83b7\u53d6\u56fe\u50cf\uff0c\u5927\u5c0f\uff0c\u6846\u7684\u6807\u6ce8\u4fe1\u606f\u548c\u7c7b\u522b\u4fe1\u606f for image , width , height , boxes , boxes_category in raw_datasets . take ( 3 ): # \u56fe\u50cf\u5904\u7406 image , boxes = preprocess ( image , boxes ) # \u8fdb\u884c\u7ed8\u56fe plt . subplot ( 1 , 3 , i + 1 ) # \u7ed8\u5236\u56fe\u50cf plt . imshow ( image [ 0 ]) # \u83b7\u53d6\u5750\u6807\u533a\u57df ax = plt . gca () # \u904d\u5386\u6240\u6709\u7684\u6846 for j in range ( boxes . shape [ 0 ]): # \u7ed8\u5236\u6846 rect = Rectangle (( boxes [ j , 0 ], boxes [ j , 1 ]), boxes [ j , 2 ] - boxes [ j , 0 ], boxes [ j , 3 ] - boxes [ j , 1 ], color = 'r' , fill = False ) # \u5c06\u6846\u663e\u793a\u5728\u56fe\u50cf\u4e0a ax . add_patch ( rect ) # \u663e\u793a\u6807\u6ce8\u4fe1\u606f # \u83b7\u53d6\u6807\u6ce8\u4fe1\u606f\u7684id label_id = boxes_category [ j ] # \u83b7\u53d6\u6807\u51c6\u4fe1\u606f label = new_voc_class . get ( label_id . numpy ()) # \u5c06\u6807\u6ce8\u4fe1\u606f\u6dfb\u52a0\u5728\u56fe\u50cf\u4e0a ax . text ( boxes [ j , 0 ], boxes [ j , 1 ] + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) # \u4e0b\u4e00\u4e2a\u7ed3\u679c i += 1 # \u663e\u793a\u56fe\u50cf plt . show () \u6548\u679c\u5982\u4e0b\u56fe\u6240\u793a:","title":"1.5. \u6570\u636e\u5904\u7406"},{"location":"objectdection/05.yolo-demo/#2","text":"yoloV3\u7684\u6a21\u578b\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a\u6574\u4e2av3\u7ed3\u6784\u91cc\u9762\uff0c\u6ca1\u6709\u6c60\u5316\u5c42\u548c\u5168\u8fde\u63a5\u5c42\uff0c\u7f51\u7edc\u7684\u4e0b\u91c7\u6837\u662f\u901a\u8fc7\u8bbe\u7f6e\u5377\u79ef\u7684stride\u4e3a2\u6765\u8fbe\u5230\u7684\uff0c\u6bcf\u5f53\u901a\u8fc7\u8fd9\u4e2a\u5377\u79ef\u5c42\u4e4b\u540e\u56fe\u50cf\u7684\u5c3a\u5bf8\u5c31\u4f1a\u51cf\u5c0f\u5230\u4e00\u534a\u3002","title":"2.\u6a21\u578b\u6784\u5efa"},{"location":"objectdection/05.yolo-demo/#21","text":"\u57fa\u672c\u7ec4\u4ef6\u6307\u84dd\u8272\u65b9\u6846\u5185\u90e8\u5206\uff1a","title":"2.1 \u57fa\u672c\u7ec4\u4ef6"},{"location":"objectdection/05.yolo-demo/#211-cbl","text":"Yolov3\u7f51\u7edc\u7ed3\u6784\u4e2d\u7684\u6700\u5c0f\u7ec4\u4ef6\uff0c\u7531Conv+Bn+Leaky_relu\u6fc0\u6d3b\u51fd\u6570\u4e09\u8005\u7ec4\u6210\uff0c \u6e90\u7801\u5b9e\u73b0\u5982\u4e0b\uff1a def ConvBlock ( input_shape , filters , kernel_size , strides = ( 1 , 1 ), padding = None ): # padding\u6839\u636e\u6b65\u957f\u7684\u5927\u5c0f\u8fdb\u884c\u4fee\u6539 padding = 'valid' if strides == ( 2 , 2 ) else 'same' # \u8f93\u5165 inputs = tf . keras . Input ( shape = input_shape ) # \u5377\u79ef\u5c42\uff1a\u52a0\u5165L2\u6b63\u5219\u5316\u7684\u5377\u79ef\u5c42 conv = tf . keras . layers . Conv2D ( filters , kernel_size = kernel_size , strides = strides , padding = padding , kernel_regularizer = tf . keras . regularizers . l2 ( l = 5e-4 ))( inputs ) # BN \u5c42 bn = tf . keras . layers . BatchNormalization ()( conv ) # \u6fc0\u6d3b\u51fd\u6570 relu = tf . keras . layers . LeakyReLU ( alpha = 0.1 )( bn ) # \u6a21\u578b\u6784\u5efa return tf . keras . Model ( inputs = inputs , outputs = relu )","title":"2.1.1 CBL"},{"location":"objectdection/05.yolo-demo/#212-resx","text":"\u6b8b\u5dee\u7ec4\u4ef6\u501f\u9274Resnet\u7f51\u7edc\u4e2d\u7684\u6b8b\u5dee\u7ed3\u6784\uff0c\u8ba9\u7f51\u7edc\u53ef\u4ee5\u6784\u5efa\u7684\u66f4\u6df1,ResX\u7531\u4e00\u4e2aCBL\u548cX\u4e2a\u6b8b\u5dee\u7ec4\u4ef6\u6784\u6210\uff0c\u662fYolov3\u4e2d\u7684\u5927\u7ec4\u4ef6\u3002\u6bcf\u4e2aRes\u6a21\u5757\u524d\u9762\u7684CBL\u90fd\u8d77\u5230\u4e0b\u91c7\u6837\u7684\u4f5c\u7528\u3002 def ResBlock ( input_shape , filters , blocks ): # \u6307\u5b9a\u8f93\u5165 inputs = tf . keras . Input ( shape = input_shape ) # \u5bf9\u8f93\u5165\u8fdb\u884cpad pad = tf . keras . layers . ZeroPadding2D ( padding = (( 1 , 0 ), ( 1 , 0 )))( inputs ) # \u5377\u79ef\u6b65\u957f\u4e3a2 results = ConvBlock ( pad . shape [ 1 :], filters = filters , kernel_size = ( 3 , 3 ), strides = ( 2 , 2 ))( pad ) # \u6784\u5efa\u6b8b\u5dee\u5355\u5143 for i in range ( blocks ): # \u5377\u79ef results_conv = ConvBlock ( results . shape [ 1 :], filters = filters // 2 , kernel_size = ( 1 , 1 ))( results ) # \u5377\u79ef results_conv = ConvBlock ( results_conv . shape [ 1 :], filters = filters , kernel_size = ( 3 , 3 ))( results_conv ) # \u878d\u548c results = tf . keras . layers . Add ()([ results_conv , results ]) # \u8fd4\u56de\u6a21\u578b return tf . keras . Model ( inputs = inputs , outputs = results )","title":"2.1.2 ResX"},{"location":"objectdection/05.yolo-demo/#22-backbone","text":"BackBone\u662fDarkNet53\u6784\u6210,\u7528\u6765\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u4e3b\u8981\u662fResX\u6a21\u5757\u3002 def Body ( input_shape ): # \u6a21\u578b\u8f93\u5165 inputs = tf . keras . Input ( shape = input_shape ) # \u5377\u79ef\u7ed3\u679c(batch, 416, 416, 32) cb = ConvBlock ( inputs . shape [ 1 :], filters = 32 , kernel_size = ( 3 , 3 ))( inputs ) # \u6b8b\u5dee\u6a21\u5757 (batch, 208, 208, 64) rb1 = ResBlock ( cb . shape [ 1 :], filters = 64 , blocks = 1 )( cb ) # (batch, 104, 104, 128) rb2 = ResBlock ( rb1 . shape [ 1 :], filters = 128 , blocks = 2 )( rb1 ) # (batch, 52, 52, 256) rb3 = ResBlock ( rb2 . shape [ 1 :], filters = 256 , blocks = 8 )( rb2 ) # (batch, 26, 26, 512) rb4 = ResBlock ( rb3 . shape [ 1 :], filters = 512 , blocks = 8 )( rb3 ) # (batch, 13, 13, 1024) rb5 = ResBlock ( rb4 . shape [ 1 :], filters = 1024 , blocks = 4 )( rb4 ) return tf . keras . Model ( inputs = inputs , outputs = ( rb5 , rb4 , rb3 ))","title":"2.2 BackBone"},{"location":"objectdection/05.yolo-demo/#23","text":"\u8f93\u51fa\u662f3\u4e2a\u5c3a\u5ea6\u8f93\u51fa\u7684CBL\u4e32\u8054\u7ed3\u6784\uff1a def Output ( input_shape , input_filters , output_filters ): # \u8f93\u5165\u6570\u636e inputs = tf . keras . Input ( shape = input_shape ) # \u8f93\u51fa\u8fde\u7eed\u7684\u516d\u4e2a\u6a21\u5757 cb1 = ConvBlock ( inputs . shape [ 1 :], filters = input_filters , kernel_size = ( 1 , 1 ))( inputs ) cb2 = ConvBlock ( cb1 . shape [ 1 :], filters = input_filters * 2 , kernel_size = ( 3 , 3 ))( cb1 ) cb3 = ConvBlock ( cb2 . shape [ 1 :], filters = input_filters , kernel_size = ( 1 , 1 ))( cb2 ) cb4 = ConvBlock ( cb3 . shape [ 1 :], filters = input_filters * 2 , kernel_size = ( 3 , 3 ))( cb3 ) cb5 = ConvBlock ( cb4 . shape [ 1 :], filters = input_filters , kernel_size = ( 1 , 1 ))( cb4 ) cb6 = ConvBlock ( cb5 . shape [ 1 :], filters = input_filters * 2 , kernel_size = ( 3 , 3 ))( cb5 ) # \u6700\u540e\u7684\u7b2c\u4e03\u4e2a\u5377\u79ef\u5757 cb7 = ConvBlock ( cb6 . shape [ 1 :], filters = output_filters , kernel_size = ( 1 , 1 ))( cb6 ) return tf . keras . Model ( inputs = inputs , outputs = ( cb5 , cb7 ))","title":"2.3 \u8f93\u51fa\u90e8\u5206"},{"location":"objectdection/05.yolo-demo/#24-v3","text":"\u5c06\u6a21\u578b\u7684backbone\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u878d\u5408\u540e\u9001\u5165\u5230output\u6a21\u5757\uff0c\u6784\u5efa\u6574\u4e2ayoloV3\u6a21\u578b\u3002 def YOLOv3 ( input_shape , class_num = 80 ): # anchor\u6570\u76ee anchor_num = 3 # \u8f93\u5165\u6570\u636e inputs = tf . keras . Input ( shape = input_shape ) # \u83b7\u53d6backbone\u8f93\u51fa\u76843\u4e2a\u7279\u5f81\u56fe large , middle , small = Body ( inputs . shape [ 1 :])( inputs ) # \u8f83\u5927\u76ee\u6807\u7684\u68c0\u6d4b x1 , y1 = Output ( large . shape [ 1 :], 512 , anchor_num * ( class_num + 5 ))( large ) # reshape\u6210\u6700\u7ec8\u7684\u6570\u636e\u7ed3\u679c y1 = tf . keras . layers . Reshape ( ( input_shape [ 0 ] // 32 , input_shape [ 1 ] // 32 , 3 , 5 + class_num ))( y1 ) # \u4e2d\u7b49\u76ee\u6807\u7684\u68c0\u6d4b cb1 = ConvBlock ( x1 . shape [ 1 :], filters = 256 , kernel_size = ( 1 , 1 ))( x1 ) # \u4e0a\u91c7\u6837 us1 = tf . keras . layers . UpSampling2D ( 2 )( cb1 ) # \u62fc\u63a5 cat1 = tf . keras . layers . Concatenate ()([ us1 , middle ]) # \u8ba1\u7b97\u8f93\u51fa\u7ed3\u679c x2 , y2 = Output ( cat1 . shape [ 1 :], 256 , anchor_num * ( class_num + 5 ))( cat1 ) # reshape\u6210\u6700\u7ec8\u7684\u6570\u636e\u7ed3\u679c y2 = tf . keras . layers . Reshape ( ( input_shape [ 0 ] // 16 , input_shape [ 1 ] // 16 , 3 , 5 + class_num ))( y2 ) # \u8f83\u5c0f\u76ee\u6807\u68c0\u6d4b cb2 = ConvBlock ( x2 . shape [ 1 :], filters = 128 , kernel_size = ( 1 , 1 ))( x2 ) # \u4e0a\u91c7\u6837 us2 = tf . keras . layers . UpSampling2D ( 2 )( cb2 ) # \u62fc\u63a5 cat2 = tf . keras . layers . Concatenate ()([ us2 , small ]) # \u8ba1\u7b97\u8f93\u51fa\u7ed3\u679c x3 , y3 = Output ( cat2 . shape [ 1 :], 128 , anchor_num * ( class_num + 5 ))( cat2 ) # reshape\u6210\u6700\u7ec8\u7684\u6570\u636e\u7ed3\u679c y3 = tf . keras . layers . Reshape ( ( input_shape [ 0 ] // 8 , input_shape [ 1 ] // 8 , 3 , 5 + class_num ))( y3 ) # \u8fd4\u56de\u7ed3\u679c return tf . keras . Model ( inputs = inputs , outputs = ( y1 , y2 , y3 ))","title":"2.4 V3\u6a21\u578b\u6784\u5efa"},{"location":"objectdection/05.yolo-demo/#25","text":"\u7f51\u7edc\u7684\u8f93\u51fa\u7ed3\u679c\u662f\uff1a \u5750\u6807\u662f\u5bf9anchor\u7684\u4fee\u6b63\uff0c\u5c06\u5176\u8f6c\u6362\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u5bbd\u9ad8\u7684\u5f62\u5f0f\uff0c\u5728\u9884\u6d4b\u8fc7\u7a0b\u548c\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u65f6\u4f7f\u7528\u3002 V3\u7f51\u7edc\u8f93\u51fa\u7684\u7ed3\u679c\u4e3a$ t_x,t_y,t_w,t_h$ \u4e0e\u8fb9\u6846\u8868\u793a b_x,b_y,b_w,b_h b_x,b_y,b_w,b_h \u4e4b\u95f4\u7684\u5173\u7cfb\u662f\uff1a c_x,c_y c_x,c_y \u662f\u5f53\u524d\u7f51\u683c\u5de6\u4e0a\u89d2\u5230\u56fe\u50cf\u5de6\u4e0a\u89d2\u7684\u8ddd\u79bb\uff0c p_w,p_h p_w,p_h \u662f\u5148\u9a8c\u6846\u7684\u5bbd\u548c\u9ad8\u3002\u6839\u636e\u4e0a\u8ff0\u5173\u7cfb\u5bf9\u7f51\u7edc\u7684\u8f93\u51fa\u8fdb\u884c\u4fee\u6b63\u3002 \u53e6\u5916\u5bf9\u4e8e\u5206\u7c7b\u7684\u8f93\u51fa\u7ed3\u679c\u5e94\u9001\u5165\u5230Sigmoid\u6fc0\u6d3b\u51fd\u6570\u4e2d\u8fdb\u884c\u5904\u7406\u3002 \u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u4e86\u4e00\u4e2a\u5e38\u89c1\u7684\u65b9\u6cd5\uff0c\u5b83\u7684\u4f5c\u7528\u662f\u628a\u4efb\u610f\u7684\u8868\u8fbe\u5f0ffunction\u4f5c\u4e3a\u4e00\u4e2a\u201cLayer\u201d\u5bf9\u8c61: keras . layers . Lambda ( function , output_shape = None , mask = None , arguments = None ) \u53c2\u6570\uff1a function\uff1a\u9700\u8981\u5c01\u88c5\u7684\u51fd\u6570\u3002 output_shape: \u9884\u671f\u7684\u51fd\u6570\u8f93\u51fa\u5c3a\u5bf8\u3002 arguments: \u53ef\u9009\u7684\u9700\u8981\u4f20\u9012\u7ed9\u51fd\u6570\u7684\u5173\u952e\u5b57\u53c2\u6570 \u8f6c\u6362\u8fc7\u7a0b\u5982\u4e0b\uff1a # \u5c06\u7f51\u7edc\u7684\u8f93\u51fa\u7ed3\u679c\u8f6c\u6362\u4e3abbox\u7684\u5750\u6807\u53ca\u5bbd\u9ad8 def OutputParser ( input_shape , img_shape , anchors ): # feats/input_shape\u7684\u610f\u4e49\uff1a[batch,height,width,anchor_num,(1(delta x) + 1(delta y) + 1(width scale) + 1(height scale) + 1(object mask) + class_num(class probability))] feats = tf . keras . Input ( input_shape ) # \u83b7\u53d6\u7f51\u683cgrid\u7684\u5de6\u4e0a\u89d2x,y\u5750\u6807\uff0c\u5bf9\u5e94\u7740cx,cy # \u83b7\u53d6\u884cy\u7684\u5750\u6807 # 1.\u4f7f\u7528tf.shape\u83b7\u53d6feats\u7684\u9ad8 # 2.\u4f7f\u7528tf.cast\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362\uff0c\u8f6c\u6362\u4e3afloat32\u7c7b\u578b # 3.\u4f7f\u7528tf.range\u521b\u5efa\u6570\u5b57\u5e8f\u5217 # 4.\u4f7f\u7528tf.reshape\u8fdb\u884c\u5f62\u72b6\u8f6c\u6362\u4e3a(height,1,1,1) # 5.\u4f7f\u7528tf.tile\u5bf9\u4e0a\u8ff0\u7ed3\u679c\u6309\u7167\u5217\u6570x\u8fdb\u884c\u5e73\u94fa # 6.\u4f7f\u7528tf.keras.layers.Lambda\u8f6c\u6362\u6210\u5c42 grid_y = tf . keras . layers . Lambda ( lambda x : tf . tile ( tf . reshape ( tf . range ( tf . cast ( tf . shape ( x )[ 1 ], dtype = tf . float32 ), dtype = tf . float32 ), ( - 1 , 1 , 1 , 1 )), ( 1 , tf . shape ( x )[ 2 ], 1 , 1 )))( feats ) # \u83b7\u53d6\u5217x\u7684\u5750\u6807 # 1.\u4f7f\u7528tf.shape\u83b7\u53d6feats\u7684\u5bbd # 2.\u4f7f\u7528tf.cast\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362\uff0c\u8f6c\u6362\u4e3afloat32\u7c7b\u578b # 3.\u4f7f\u7528tf.range\u521b\u5efa\u6570\u5b57\u5e8f\u5217 # 4.\u4f7f\u7528tf.reshape\u8fdb\u884c\u5f62\u72b6\u8f6c\u6362\u4e3a(1,width,1,1) # 5.\u4f7f\u7528tf.tile\u5bf9\u4e0a\u8ff0\u7ed3\u679c\u6309\u7167\u884c\u6570y\u8fdb\u884c\u5e73\u94fa # 6.\u4f7f\u7528tf.keras.layers.Lambda\u8f6c\u6362\u6210\u5c42 grid_x = tf . keras . layers . Lambda ( lambda x : tf . tile ( tf . reshape ( tf . range ( tf . cast ( tf . shape ( x )[ 2 ], dtype = tf . float32 ), dtype = tf . float32 ), ( 1 , - 1 , 1 , 1 )), ( tf . shape ( x )[ 1 ], 1 , 1 , 1 )))( feats ) # \u6784\u5efagrid\u7684\u7f51\u683c\u8868\u793a # grid.shape = (grid h, grid w, 1, 2) grid = tf . keras . layers . Concatenate ( axis =- 1 )([ grid_x , grid_y ]) # \u83b7\u53d6\u6bcf\u4e00\u4e2a\u68c0\u6d4b\u7ed3\u679c\u4e2d\u5fc3\u70b9\u5750\u6807:\u5c06\u9884\u6d4b\u7ed3\u679c\u8f6c\u6362\u4e3a\u4e2d\u5fc3\u70b9\u5750\u6807 # box_xy = (delta x, delta y) + (priorbox upper left x,priorbox upper left y) / (feature map.width, feature map.height) # box_xy.shape = (batch, grid h, grid w, anchor_num, 2) box_xy = tf . keras . layers . Lambda ( lambda x : ( tf . math . sigmoid ( x [ 0 ][ ... , 0 : 2 ]) + x [ 1 ]) / tf . cast ( [ tf . shape ( x [ 1 ])[ 1 ], tf . shape ( x [ 1 ])[ 0 ]], dtype = tf . float32 ))([ feats , grid ]) # box_wh.shape = (batch, grid h, grid w, anchor_num, 2) # \u83b7\u53d6\u68c0\u6d4b\u7ed3\u679c\u7684\u5bbd\u9ad8 # box_wh = (width scale, height scale) * (anchor width, anchor height) / (image.width, image.height) box_wh = tf . keras . layers . Lambda ( lambda x , y , z : tf . math . exp ( x [ ... , 2 : 4 ]) * y / tf . cast ( [ z [ 1 ], z [ 0 ]], dtype = tf . float32 ), arguments = { 'y' : anchors , 'z' : img_shape })( feats ) # \u83b7\u53d6\u67d0\u4e00\u4e2aanchor\u4e2d\u5305\u542b\u76ee\u6807\u7684\u6982\u7387 box_confidence = tf . keras . layers . Lambda ( lambda x : tf . math . sigmoid ( x [ ... , 4 ]))( feats ) # \u83b7\u53d6\u67d0\u4e00\u4e2aanchor\u5c5e\u4e8e\u67d0\u4e00\u4e2a\u7c7b\u522b\u7684\u6982\u7387 box_class_probs = tf . keras . layers . Lambda ( lambda x : tf . math . sigmoid ( x [ ... , 5 :]))( feats ) # \u8fd4\u56de\u8f93\u51fa\u7ed3\u679c return tf . keras . Model ( inputs = feats , outputs = ( box_xy , box_wh , box_confidence , box_class_probs ))","title":"2.5 \u8f93\u51fa\u7ed3\u679c\u5904\u7406"},{"location":"objectdection/05.yolo-demo/#3","text":"","title":"3.\u6a21\u578b\u8bad\u7ec3"},{"location":"objectdection/05.yolo-demo/#31","text":"YoloV3\u7684\u635f\u5931\u51fd\u6570\u5206\u4e3a\u4e09\u90e8\u5206\uff1a box\u7684\u635f\u5931\uff1a \u53ea\u6709\u8d1f\u8d23\u68c0\u6d4b\u7684gridcell\u4e2d\u7684anchor\u624d\u4f1a\u8ba1\u5165\u635f\u5931,\u5bf9x,y,w,h\u5206\u522b\u6c42\u5747\u65b9\u8bef\u5dee \u7f6e\u4fe1\u5ea6\u7684\u635f\u5931 \u7f6e\u4fe1\u5ea6\u7684\u635f\u5931\u662f\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u6240\u6709\u7684box\u90fd\u8ba1\u5165\u635f\u5931\u8ba1\u7b97 \u5206\u7c7b\u7684\u635f\u5931\uff1a \u5206\u7c7b\u7684\u635f\u5931\u662f\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u53ea\u6709\u8d1f\u8d23\u68c0\u6d4b\u76ee\u6807\u7684\u624d\u8ba1\u7b97\u635f\u5931 def Loss ( img_shape , class_num = 80 ): # anchor\u7684\u5c3a\u5ea6\uff1a\u5206\u522b\u68c0\u6d4b\u5c0f\uff0c\u4e2d\uff0c\u5927\u7684\u76ee\u6807 anchors = { 2 : [[ 10 , 13 ], [ 16 , 30 ], [ 33 , 23 ]], 1 : [[ 30 , 61 ], [ 62 , 45 ], [ 59 , 119 ]], 0 : [[ 116 , 90 ], [ 156 , 198 ], [ 373 , 326 ]]} # \u6784\u5efa\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u7684\u6570\u7ec4 input_shapes = [ ( img_shape [ 0 ] // 32 , img_shape [ 1 ] // 32 , 3 , 5 + class_num ), ( img_shape [ 0 ] // 16 , img_shape [ 1 ] // 16 , 3 , 5 + class_num ), ( img_shape [ 0 ] // 8 , img_shape [ 1 ] // 8 , 3 , 5 + class_num ) ] # \u7f51\u7edc\u7684\u8f93\u51fa\u503c inputs = [ tf . keras . Input ( input_shape ) for input_shape in input_shapes ] # \u76ee\u6807\u503c labels = [ tf . keras . Input ( input_shape ) for input_shape in input_shapes ] losses = list () # \u904d\u5386\u4e09\u4e2a\u5c3a\u5ea6\u7684\u8f93\u51fa for l in range ( 3 ): # \u83b7\u53d6\u5f53\u524d\u5c3a\u5ea6\u7684\u5f62\u72b6 input_shape_of_this_layer = input_shapes [ l ] # \u83b7\u53d6\u5f53\u524d\u5c3a\u5ea6\u7684anchor anchors_of_this_layer = anchors [ l ] # \u83b7\u53d6\u7f51\u7edc\u8f93\u51fa input_of_this_layer = inputs [ l ] # \u83b7\u53d6\u5bf9\u5e94\u7684\u76ee\u6807\u503c label_of_this_layer = labels [ l ] # YOLOV3\u6a21\u578b\u8f93\u51fa\u7684\u7ed3\u679c\uff1a\u4e2d\u5fc3\u70b9\u5750\u6807\uff0c\u5bbd\u9ad8\uff0c\u7f6e\u4fe1\u5ea6 pred_xy , pred_wh , pred_box_confidence , pred_class = OutputParser ( input_shape_of_this_layer , img_shape , anchors_of_this_layer )( input_of_this_layer ) # \u9884\u6d4b\u6846 pred_box = tf . keras . layers . Concatenate ()([ pred_xy , pred_wh ]) # \u771f\u5b9e\u503c true_box = tf . keras . layers . Lambda ( lambda x : x [ ... , 0 : 4 ])( label_of_this_layer ) true_box_confidence = tf . keras . layers . Lambda ( lambda x : x [ ... , 4 ])( label_of_this_layer ) true_class = tf . keras . layers . Lambda ( lambda x : x [ ... , 5 :])( label_of_this_layer ) # \u83b7\u53d6box\u7684\u7f6e\u4fe1\u5ea6 object_mask = tf . keras . layers . Lambda ( lambda x : tf . cast ( x , dtype = tf . bool ))( true_box_confidence ) # \u8ba1\u7b97MSE\u635f\u5931\uff1a\u53ea\u6709\u6b63\u6837\u672c\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97 pos_loss = tf . keras . layers . Lambda ( lambda x : tf . math . reduce_sum ( tf . keras . losses . MSE ( tf . boolean_mask ( x [ 0 ], x [ 2 ]), tf . boolean_mask ( x [ 1 ], x [ 2 ]) )) )([ true_box , pred_box , object_mask ]) # \u7f6e\u4fe1\u5ea6\u7684\u635f\u5931\uff1a\u4ea4\u53c9\u71b5\u635f\u5931 confidence_loss = tf . keras . layers . Lambda ( lambda x : # \u6b63\u6837\u672c\u7684\u635f\u5931 tf . keras . losses . BinaryCrossentropy ( from_logits = False )( tf . boolean_mask ( x [ 0 ], x [ 2 ]), tf . boolean_mask ( x [ 1 ], x [ 2 ]) ) + # \u8d1f\u6837\u672c\u7684\u635f\u5931 100 * tf . keras . losses . BinaryCrossentropy ( from_logits = False )( tf . boolean_mask ( x [ 0 ], tf . math . logical_not ( x [ 2 ])), tf . boolean_mask ( x [ 1 ], tf . math . logical_not ( x [ 2 ])) ) )([ true_box_confidence , pred_box_confidence , object_mask ]) # \u5206\u7c7b\u635f\u5931\uff1a\u53ea\u6709\u6b63\u6837\u672c\u8ba1\u7b97\u635f\u5931 class_loss = tf . keras . layers . Lambda ( lambda x : tf . keras . losses . BinaryCrossentropy ( from_logits = False )( tf . boolean_mask ( x [ 0 ], x [ 2 ]), tf . boolean_mask ( x [ 1 ], x [ 2 ]) ) )([ true_class , pred_class , object_mask ]) # \u635f\u5931\u7ed3\u679c loss = tf . keras . layers . Lambda ( lambda x : tf . math . add_n ( x ))( [ pos_loss , confidence_loss , class_loss ]) losses . append ( loss ) # \u8ba1\u7b97\u635f\u5931\u503c loss = tf . keras . layers . Lambda ( lambda x : tf . math . add_n ( x ))( losses ) return tf . keras . Model ( inputs = ( * inputs , * labels ), outputs = loss )","title":"3.1\u635f\u5931\u51fd\u6570\u7684\u8ba1\u7b97"},{"location":"objectdection/05.yolo-demo/#32","text":"\u5728\u4e0a\u8ff0\u7684loss\u8ba1\u7b97\u4e2d\uff0c\u8d1f\u8d23\u8fdb\u884c\u76ee\u6807\u9884\u6d4b\u7684anchor\u5c31\u662f\u6b63\u6837\u672c\uff0c\u800c\u4e0d\u8d1f\u8d23\u8fdb\u884c\u76ee\u6807\u9884\u6d4b\u7684\u5c31\u662f\u8d1f\u6837\u672c\uff0c\u4e5f\u5c31\u662f\u80cc\u666f\uff0c\u90a3\u5728\u8fd9\u91cc\u6211\u4eec\u662f\u5982\u4f55\u8bbe\u7f6e\u6b63\u8d1f\u6837\u672c\u7684\u5462\uff1f\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6b63\u6837\u672c \uff1a\u9996\u5148\u8ba1\u7b97\u76ee\u6807\u4e2d\u5fc3\u70b9\u843d\u5728\u54ea\u4e2agrid\u4e0a\uff0c\u7136\u540e\u8ba1\u7b97\u8fd9\u4e2agrid\u5bf9\u5e94\u76843\u4e2a\u5148\u9a8c\u6846\uff08anchor\uff09\u548c\u76ee\u6807\u771f\u5b9e\u4f4d\u7f6e\u7684IOU\u503c\uff0c\u53d6IOU\u503c\u6700\u5927\u7684\u5148\u9a8c\u6846\u548c\u76ee\u6807\u5339\u914d\u3002\u90a3\u4e48\u8be5anchor \u5c31\u8d1f\u8d23\u9884\u6d4b\u8fd9\u4e2a\u76ee\u6807\uff0c\u90a3\u8fd9\u4e2aanchor\u5c31\u4f5c\u4e3a\u6b63\u6837\u672c\uff0c\u5c06\u5176\u7f6e\u4fe1\u5ea6\u8bbe\u4e3a1\uff0c\u5176\u4ed6\u7684\u76ee\u6807\u503c\u6839\u636e\u6807\u6ce8\u4fe1\u606f\u8bbe\u7f6e\u3002 \u8d1f\u6837\u672c \uff1a\u6240\u6709\u4e0d\u662f\u6b63\u6837\u672c\u7684anchor\u90fd\u662f\u8d1f\u6837\u672c\uff0c\u5c06\u5176\u7f6e\u4fe1\u5ea6\u8bbe\u4e3a0\uff0c\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\uff0c\u5176\u5b83\u7684\u503c\u4e0d\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\uff0c\u9ed8\u8ba4\u4e3a0\u3002 \u5728\u5b9e\u73b0\u7684\u65f6\u5019\uff0c\u4e3a\u4e86\u63d0\u9ad8\u8ba1\u7b97\u901f\u5ea6\u505a\u4e86\u4f18\u5316\uff0c\u5728\u8ba1\u7b97\u662f\u5426\u4e3a\u6b63\u6837\u672c\u65f6\uff0c\u6211\u4eec\u8ba4\u4e3aanchor\u548c\u76ee\u6807\u7684\u4e2d\u5fc3\u70b9\u662f\u76f8\u540c\u7684\uff0c\u76f4\u63a5\u5229\u7528anchor\u548c\u76ee\u6807box\u7684\u5bbd\u9ad8\u8ba1\u7b97\u4ea4\u5e76\u6bd4\uff0c\u786e\u5b9a\u6b63\u6837\u672c\u3002\u5b9e\u73b0\u5982\u4e0b\uff1a \u5b9a\u4e49anchor: YOLOv3_anchors = np . array ([[ 10 , 13 ], [ 16 , 30 ], [ 33 , 23 ], [ 30 , 61 ], [ 62 , 45 ], [ 59 , 119 ], [ 116 , 90 ], [ 156 , 198 ], [ 373 , 326 ]], dtype = np . int32 ) \u5b9a\u4e49\u65b9\u6cd5\u8ba1\u7b97anchor\u5bf9\u5e94\u7684\u76ee\u6807\u503c\uff0c\u786e\u5b9a\u6b63\u8d1f\u6837\u672c\uff1a def bbox_to_tensor ( bbox , label , input_shape = ( 416 , 416 ), anchors = YOLOv3_anchors , num_classes = 80 ): # bbox\uff1a\u771f\u5b9e\u503c\u5750\u6807\u8868\u793a\u4e3a(xmin,ymin,xmax,ymax)\uff0c\u662f\u76f8\u5bf9\u5750\u6807 # label\uff1a \u6bcf\u4e2abbox\u7684\u7c7b\u522b # anchors = (9,2) # \u8fd4\u56de\uff1aanchor\u5bf9\u5e94\u7684\u771f\u5b9e\u503c,\u5373\u6b63\u8d1f\u6837\u672c\u7684\u6807\u8bb0\u7ed3\u679c \u83b7\u53d6\u5c3a\u5ea6\u4e2a\u6570\u548cbox\u7684\u7edd\u5bf9\u5750\u6807 # \u83b7\u53d6\u6709\u51e0\u4e2a\u5c3a\u5ea6\u7684\u8f93\u51fa\uff0c\u6bcf\u4e2a\u5c3a\u5ea6\u5bf9\u5e943\u4e2aanchor:3 num_layers = anchors . shape [ 0 ] // 3 # anchor\u5bf9\u5e94\u7684\u7279\u5f81\u56fe\u63a9\u7801\uff1a\u7b2c\u4e00\u4e2a\u7279\u5f81\u56fe\u5bf9\u5e94\u7b2c6\uff0c7\uff0c8\u4e2aanchor... anchor_mask = tf . cond ( tf . equal ( num_layers , 3 ), lambda : tf . constant ( [[ 6 , 7 , 8 ], [ 3 , 4 , 5 ], [ 0 , 1 , 2 ]]), lambda : tf . constant ([[ 3 , 4 , 5 ], [ 1 , 2 , 3 ]])) # bbox\u7684\u76f8\u5bf9\u4e2d\u5fc3\u70b9\u5750\u6807 true_boxes_xy = ( bbox [ ... , 0 : 2 ] + bbox [ ... , 2 : 4 ]) / 2. # bbox\u7684\u76f8\u5bf9\u5bbd\u9ad8 true_boxes_wh = tf . math . abs ( bbox [ ... , 2 : 4 ] - bbox [ ... , 0 : 2 ]) # bbox\u7684\u7ed3\u679c:\u5c06\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u5bbd\u9ad8\u62fc\u63a5\u5728\u4e00\u8d77 true_boxes = tf . concat ([ true_boxes_xy , true_boxes_wh ], axis =- 1 ) # bbox\u7684\u7edd\u5bf9\u5750\u6807\u548c\u7edd\u5bf9\u5bbd\u9ad8 boxes_xy = true_boxes [ ... , 0 : 2 ] * input_shape boxes_wh = true_boxes [ ... , 2 : 4 ] * input_shape \u521b\u5efa\u4e00\u4e2a\u4e0e\u7f51\u7edc\u8f93\u51fa\u5927\u5c0f\u76f8\u540c\u7684\u5168\u96f6\u6570\u7ec4\uff0c\u7528\u6765\u8bbe\u7f6e\u771f\u5b9e\u503c # \u751f\u6210\u4e0eyoloV3\u8f93\u51fa\u7ed3\u679c\u76f8\u540c\u5927\u5c0f\u7684\u51680\u6570\u7ec4\uff1ay_true.shape[layer] = (height, width, anchor num, 5 + class num) y_true = tuple (( np . zeros ( shape = ( input_shape [ 0 ] // { 0 : 32 , 1 : 16 , 2 : 8 }[ l ], input_shape [ 1 ] // { 0 : 32 , 1 : 16 , 2 : 8 }[ l ], tf . shape ( anchor_mask [ l , ... ])[ 0 ], 5 + num_classes ), dtype = np . float32 ) for l in range ( num_layers ))) \u8ba1\u7b97anchor\u7684\u4f4d\u7f6e\u4fe1\u606f # \u6269\u5c55\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u7528\u6765\u5b58\u653eanchor\u7684\u7d22\u5f15 anchors = tf . expand_dims ( tf . convert_to_tensor ( anchors , dtype = tf . float32 ), 0 ) # \u7528\u4e8e\u8ba1\u7b97\u4ea4\u5e76\u6bd4 # \u4ee5anchor\u4e2d\u5fc3\u4e3a\u539f\u70b9\uff0c\u8ba1\u7b97\u53f3\u4e0b\u89d2\u5750\u6807 anchor_maxes = anchors / 2. # \u4ee5anchor\u4e2d\u5fc3\u4e3a\u539f\u70b9\uff0c\u8ba1\u7b97\u5de6\u4e0a\u89d2\u5750\u6807 anchor_mins = - anchor_maxes \u5bf9\u76ee\u6807\u8fdb\u884c\u7b5b\u9009\uff0c\u53ea\u6709\u5bbd\u5ea6\u5927\u4e8e0\u7684\u8ba4\u4e3a\u662f\u771f\u6b63\u7684\u76ee\u6807 # \u521b\u5efa\u4e00\u4e2amask,\u6307\u660e\u76ee\u6807\u662f\u5426\u5b58\u5728\uff0c\u5bbd\u5ea6\u5927\u4e8e0\u7684\u8ba4\u4e3a\u662f\u771f\u5b9e\u7684\u76ee\u6807 valid_mask = tf . greater ( boxes_wh [ ... , 0 ], 0 \uff09 # \u83b7\u53d6\u771f\u5b9e\u7684\u76ee\u6807\u7684\u5bbd\u9ad8 wh = tf . boolean_mask ( boxes_wh , valid_mask ) # \u83b7\u53d6\u771f\u5b9e\u76ee\u6807\u7684box\uff1avalid_true_boxes.shape = (valid box num, 4) valid_true_boxes = tf . boolean_mask ( boxes , valid_mask ) # \u83b7\u53d6\u771f\u5b9e\u76ee\u6807\u7684\u6807\u7b7e\u503c\uff1avalid_label.shape = (valid box num) valid_label = tf . boolean_mask ( label , valid_mask ) \u83b7\u53d6\u4e0e\u76ee\u6807\u4ea4\u5e76\u6700\u5927\u7684anchor,\u90a3\u8fd9\u4e9banchor\u5373\u4e3a\u6b63\u6837\u672c # \u5f53\u56fe\u50cf\u4e2d\u5b58\u5728\u76ee\u6807\u65f6\uff0c\u8ba1\u7b97\u4e0e\u76ee\u6807\u4ea4\u5e76\u6bd4\u6700\u5927\u7684anchor\u4f5c\u4e3a\u6b63\u6837\u672c\uff0c\u5e76\u8bbe\u7f6e\u6807\u8bb0\u7ed3\u679c if wh . shape [ 0 ] > 0 : # \u6269\u5c55\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u7528\u6765\u5b58\u653e\u5bf9\u5e94\u7684anchor\uff1awh.shape = (valid box num, 1, 2) wh = tf . expand_dims ( wh , - 2 ) # \u4ee5box\u7684\u4e2d\u5fc3\u70b9\u4e3a\u539f\u70b9\uff1a\u8ba1\u7b97\u53f3\u4e0b\u89d2\u5750\u6807\uff1amax of width, height, box_maxes.shape = (valid box num, 1, 2) box_maxes = wh / 2 # \u4ee5box\u7684\u4e2d\u5fc3\u70b9\u4e3a\u539f\u70b9\uff1a\u8ba1\u7b97\u5de6\u4e0a\u89d2\u5750\u6807\uff1amin of width, height, box_mins.shape = (valid box num, 1, 2) box_mins = - box_maxes # \u8ba1\u7b97box\u4e0eanchor\u4ea4\u7684\u5de6\u4e0a\u89d2\u5750\u6807\uff1aintersect_mins.shape = (valid box num, anchor num(9), 2) intersect_mins = tf . math . maximum ( box_mins , anchor_mins ) # \u8ba1\u7b97box\u4e0eanchor\u4ea4\u7684\u53f3\u4e0b\u89d2\u5750\u6807\uff1aintersect_maxes.shape = (valid box num, anchor num(9), 2) intersect_maxes = tf . math . minimum ( box_maxes , anchor_maxes ) # \u8ba1\u7b97\u4ea4\u96c6\u7684\u5bbd\u9ad8\uff1aintersect_wh.shape = (valid box num, anchor num(9), 2) intersect_wh = tf . math . maximum ( intersect_maxes - intersect_mins , 0. ) # \u8ba1\u7b97\u4ea4\u96c6\u7684\u9762\u79ef\uff1aintersect_area.shape = (valid box num, anchor num(9)) intersect_area = intersect_wh [ ... , 0 ] * intersect_wh [ ... , 1 ] # \u8ba1\u7b97box\u7684\u9762\u79ef\uff1abox_area.shape = (valid box_num, 1) box_area = wh [ ... , 0 ] * wh [ ... , 1 ] # \u8ba1\u7b97anchor\u7684\u9762\u79ef\uff1aanchor_area.shape = (1, anchor num(9)) anchor_area = anchors [ ... , 0 ] * anchors [ ... , 1 ] # \u8ba1\u7b97\u4ea4\u5e76\u6bd4\uff1aiou.shape = (valid box num, anchor num(9)) iou = intersect_area / ( box_area + anchor_area - intersect_area ) # \u8ba1\u7b97\u4e0ebox\u4ea4\u5e76\u6bd4\u6700\u5927\u7684anchor,\u5c06\u5176\u4f5c\u4e3a\u6b63\u6837\u672c\uff1abest_anchor.shape = (valid box num) best_anchor = tf . math . argmax ( iou , axis =- 1 , output_type = tf . int32 ) \u904d\u5386\u5339\u914d\u6210\u529f\u7684anchor(\u6b63\u6837\u672c)\uff0c\u8bbe\u7f6e\u76ee\u6807\u503c # \u904d\u5386\u4e0ebox\u5339\u914d\u6210\u529f\u7684anchor for t in range ( tf . shape ( best_anchor )[ 0 ]): # \u83b7\u53d6\u7b2ct\u4e2aanchor n = best_anchor [ t ] # \u83b7\u53d6anchor\u7684\u4f4d\u7f6e pos = tf . where ( tf . equal ( anchor_mask , n )) # \u83b7\u53d6\u5c3a\u5ea6\u503c\uff1a0\uff0c1\uff0c2 l = pos [ 0 ][ 0 ] # \u83b7\u53d6\u5bf9\u5e94\u7684anchor\u7d22\u5f15 k = pos [ 0 ][ 1 ] # \u83b7\u53d6anchor\u5bf9\u5e94\u7684grid cell\u7684\u5217\u6570\uff0c\u9650\u5236\u57280\u5230\u6700\u5927\u503c\u4e4b\u95f4 i = int ( tf . clip_by_value ( valid_true_boxes [ t , 1 ] * y_true [ l ] . shape [ 0 ], clip_value_min = 0 , clip_value_max = y_true [ l ] . shape [ 0 ] - 1 )) # \u83b7\u53d6anchor\u5bf9\u5e94\u7684grid cell\u7684\u884c\u6570\uff0c\u9650\u5236\u57280\u5230\u6700\u5927\u503c\u4e4b\u95f4 j = int ( tf . clip_by_value ( valid_true_boxes [ t , 0 ] * y_true [ l ] . shape [ 1 ], clip_value_min = 0 , clip_value_max = y_true [ l ] . shape [ 1 ] - 1 )) # \u83b7\u53d6anchor\u7684\u7c7b\u522b c = valid_label [ t ] # box\u7684\u4f4d\u7f6e:(x,y,width,height) y_true [ l ][ i , j , k , 0 : 4 ] = valid_true_boxes [ t , 0 : 4 ] # \u5339\u914d\u4e0a\u7684\u90fd\u5305\u542b\u76ee\u6807\uff0c\u7f6e\u4fe1\u5ea6\u8bbe\u4e3a1 y_true [ l ][ i , j , k , 4 ] = 1 # \u7c7b\u522b\u4fe1\u606f y_true [ l ][ i , j , k , 5 + c ] = 1 \u8fd4\u56de\u7ed3\u679c # \u8fd4\u56de3\u4e2a\u5c3a\u5ea6\u5bf9\u5e94\u7684\u771f\u5b9e\u503c return ( tf . convert_to_tensor ( y_true [ 0 ]), tf . convert_to_tensor ( y_true [ 1 ]), tf . convert_to_tensor ( y_true [ 2 ]))","title":"3.2 \u6b63\u8d1f\u6837\u672c\u7684\u8bbe\u5b9a"},{"location":"objectdection/05.yolo-demo/#33","text":"\u63a5\u4e0b\u6765\u6211\u4eec\u5229\u7528\u5df2\u642d\u5efa\u597d\u7684\u7f51\u7edc\u548c\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a","title":"3.3 \u6a21\u578b\u8bad\u7ec3"},{"location":"objectdection/05.yolo-demo/#331","text":"\u9996\u5148\u4eceTFRecord\u6587\u4ef6\u4e2d\u83b7\u53d6\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u6570\u636e\u5904\u7406\uff0c\u5f97\u5230\u5bf9\u5e94\u7684\u76ee\u6807\u503c\uff0c\u8fd9\u4e9b\u901a\u8fc7map\u65b9\u6cd5\u6765\u5b9e\u73b0 1.\u5b9a\u4e49\u65b9\u6cd5\u8fdb\u884c\u6570\u636e\u5904\u7406\u548c\u83b7\u53d6\u76ee\u6807\u503c def map_function_impl ( image , bbox , label ): # \u56fe\u50cf\u5c3a\u5ea6\u8c03\u6574 image , bbox = preprocess ( image , bbox , random = True ) # \u83b7\u53d6\u5bf9\u5e94\u7684\u76ee\u6807\u503c label1 , label2 , label3 = bbox_to_tensor ( bbox , label ) # \u8fd4\u56de\u7ed3\u679c return image , label1 , label2 , label3 2.\u4f7f\u7528py_function\u6765\u63d0\u9ad8\u6027\u80fd def map_function ( image , width , height , boxes , boxes_category ): # \u5bf9\u6570\u636e\u8fdb\u884c\u5904\u7406\uff0c\u83b7\u53d6\u56fe\u50cf\u53ca\u76ee\u6807\u503c\uff1a\u63d0\u5347\u6027\u80fd image , label1 , label2 , label3 = tf . py_function ( map_function_impl , inp = [ image , boxes , boxes_category ], Tout = [ tf . float32 , tf . float32 , tf . float32 , tf . float32 ]) # \u5bf9\u56fe\u50cf\u548c\u76ee\u6807\u503c\u8fdb\u884c\u5c3a\u5ea6\u8c03\u6574 image = tf . reshape ( image , ( 416 , 416 , 3 )) label1 = tf . reshape ( label1 , ( 13 , 13 , 3 , 85 )) label2 = tf . reshape ( label2 , ( 26 , 26 , 3 , 85 )) label3 = tf . reshape ( label3 , ( 52 , 52 , 3 , 85 )) # \u8fd4\u56de\u7ed3\u679c return image , ( label1 , label2 , label3 ) 3.\u4f7f\u7528map\u65b9\u6cd5\u5bf9\u4eceTFRcords\u4e2d\u8bfb\u53d6\u7684\u6570\u636e\u8fdb\u884c\u5904\u7406 # \u4eceTFRecord\u6587\u4ef6\u4e2d\u83b7\u53d6\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u5904\u7406 batch_size = 10 trainset = raw_datasets . map ( map_function ) . shuffle ( batch_size ) . batch ( batch_size ) . prefetch ( tf . data . experimental . AUTOTUNE )","title":"3.3.1 \u83b7\u53d6\u6570\u636e\u96c6"},{"location":"objectdection/05.yolo-demo/#332","text":"\u6a21\u578b\u521d\u59cb\u5316\uff1a yolov3 = YOLOv3 (( 416 , 416 , 3 ,), 20 ) yolov3_loss = Loss (( 416 , 416 , 3 ), 20 ) \u5b9a\u4e49\u4f18\u5316\u65b9\u6cd5\uff1a # \u5b9a\u4e49\u4f18\u5316\u65b9\u6cd5 optimizer = tf . keras . optimizers . Adam ( 1e-4 ) \u63a5\u4e0b\u6765\u8fdb\u884c\u7f51\u7edc\u8bad\u7ec3\uff0c\u8fd9\u91cc\u4f7f\u7528\uff1a 1.\u5b9a\u4e49tf.GradientTape\u7684\u4f5c\u7528\u57df\uff0c\u8ba1\u7b97\u635f\u5931\u503c 2.\u4f7f\u7528 tape.gradient(ys, xs)\u81ea\u52a8\u8ba1\u7b97\u68af\u5ea6 3.\u4f7f\u7528 optimizer.apply_gradients(grads_and_vars)\u81ea\u52a8\u66f4\u65b0\u6a21\u578b\u53c2\u6570 \u5b8c\u6210\u7f51\u7edc\u8bad\u7ec3\uff0c\u5e76\u4fdd\u5b58\u8bad\u7ec3\u7ed3\u679c # \u904d\u5386\u56fe\u50cf\u548c\u76ee\u6807\u503c\uff0c\u8fdb\u884c\u66f4\u65b0 for images , labels in trainset : # \u5b9a\u4e49\u4f5c\u7528\u57df with tf . GradientTape () as tape : # \u5c06\u56fe\u50cf\u9001\u5165\u7f51\u7edc\u4e2d outputs = yolov3 ( images ) # \u8ba1\u7b97\u635f\u5931\u51fd\u6570 loss = yolov3_loss ([ * outputs , * labels ]) # \u8ba1\u7b97\u68af\u5ea6 grads = tape . gradient ( loss , yolov3 . trainable_variables ) try : # \u8fdb\u884c\u68af\u5ea6\u68c0\u67e5 grads_check = [ tf . debugging . check_numerics ( grad , 'the grad is not correct! cancel gradient apply!' ) for grad in grads ] with tf . control_dependencies ( grads_check ): # \u68af\u5ea6\u66f4\u65b0 optimizer . apply_gradients ( zip ( grads , yolov3 . trainable_variables )) except BaseException as e : print ( e . message ) # \u4fdd\u5b58\u6a21\u578b\u8bad\u7ec3\u7ed3\u679c yolov3 . save ( 'yolov3.h5' )","title":"3.3.2 \u6a21\u578b\u8bad\u7ec3"},{"location":"objectdection/05.yolo-demo/#4","text":"\u6211\u4eec\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u9884\u6d4b,\u5728\u8fd9\u91cc\u6211\u4eec\u901a\u8fc7yoloV3\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\uff0c\u9884\u6d4b\u4e4b\u540e\u8f6c\u6362\u4e3a\u7edd\u5bf9\u5750\u6807\u540e\uff0c\u83b7\u53d6\u591a\u4e2a\u5c3a\u5ea6\u7684\u9884\u6d4b\u7ed3\u679c\u62fc\u63a5\u5728\u4e00\u8d77\uff0c\u4f7f\u7528NMS\u8fdb\u884c\u68c0\u6d4b\u6846\u7684\u7b5b\u9009\u3002 \u9996\u5148\u5b9a\u4e49\u9884\u6d4b\u7c7b\uff1a # \u5b9a\u4e49\u9884\u6d4b\u7c7b class Predictor ( object ): \u6307\u660eanchor\u7684\u5927\u5c0f\uff1a # anchorbox\u7684\u5927\u5c0f anchors = { 2 : [[ 10 , 13 ], [ 16 , 30 ], [ 33 , 23 ]], 1 : [[ 30 , 61 ], [ 62 , 45 ], [ 59 , 119 ]], 0 : [[ 116 , 90 ], [ 156 , 198 ], [ 373 , 326 ]]}","title":"4.\u6a21\u578b\u9884\u6d4b"},{"location":"objectdection/05.yolo-demo/#41","text":"\u8fdb\u884c\u6a21\u578b\u521d\u59cb\u5316 # \u521d\u59cb\u5316 def __init__ ( self , input_shape = ( 416 , 416 , 3 ), class_num = 80 , yolov3 = None ): # \u8f93\u5165\u5927\u5c0f self . input_shape = input_shape # \u6a21\u578b\u521d\u59cb\u5316 self . yolov3 = tf . keras . models . load_model ( 'yolov3.h5' , compile = False ) # \u5c06\u7ed3\u679c\u8f6c\u6362\u4e3a\u5750\u6807\u503c self . parsers = [ OutputParser ( tuple ( self . yolov3 . outputs [ l ] . shape [ 1 :]), self . input_shape , self . anchors [ l ]) for l in range ( 3 )]","title":"4.1 \u521d\u59cb\u5316"},{"location":"objectdection/05.yolo-demo/#42","text":"\u5728\u8fd9\u91cc\u52a0\u5165NMS\u65b9\u6cd5\uff1a","title":"4.2 \u9884\u6d4b\u65b9\u6cd5\u5b9e\u73b0"},{"location":"objectdection/05.yolo-demo/#421","text":"def predict ( self , image , conf_thres = 0.5 , nms_thres = 0.5 ): # conf_thres\uff1a\u7f6e\u4fe1\u5ea6\u7684\u9608\u503c\uff0cNMS\u4e2d\u4ea4\u5e76\u6bd4\u7684\u9608\u503c # \u589e\u52a0\u4e00\u7ef4batch images = tf . expand_dims ( image , axis = 0 ) # \u56fe\u50cf\u53d8\u5f62 resize_images = tf . image . resize ( images , self . input_shape [: 2 ], method = tf . image . ResizeMethod . BICUBIC , preserve_aspect_ratio = True ) # \u56fe\u50cf\u53d8\u5f62\u540e\u7684\u5927\u5c0f resize_shape = resize_images . shape [ 1 : 3 ] # \u56fe\u50cf\u5728\u4e0a\u4e0b\u5de6\u53f3\u586b\u5145\u7684\u5927\u5c0f top_pad = ( self . input_shape [ 0 ] - resize_shape [ 0 ]) // 2 bottom_pad = self . input_shape [ 0 ] - resize_shape [ 0 ] - top_pad left_pad = ( self . input_shape [ 1 ] - resize_shape [ 1 ]) // 2 right_pad = self . input_shape [ 1 ] - resize_shape [ 1 ] - left_pad # \u586b\u5145\u4e3a128 resize_images = tf . pad ( resize_images , [[ 0 , 0 ], [ top_pad , bottom_pad ], [ left_pad , right_pad ], [ 0 , 0 ]], constant_values = 128 ) # \u6807\u51c6\u5dee deviation = tf . constant ([ left_pad / self . input_shape [ 1 ], top_pad / self . input_shape [ 0 ], 0 , 0 ], dtype = tf . float32 ) # \u5c3a\u5ea6\u7684\u53d8\u6362 scale = tf . constant ([ self . input_shape [ 1 ] / resize_shape [ 1 ], self . input_shape [ 0 ] / resize_shape [ 0 ], self . input_shape [ 1 ] / resize_shape [ 1 ], self . input_shape [ 0 ] / resize_shape [ 0 ] ], dtype = tf . float32 ) # \u7c7b\u578b\u8f6c\u6362 images_data = tf . cast ( resize_images , tf . float32 ) / 255. # \u8f93\u51fa\u7ed3\u679c outputs = self . yolov3 ( images_data )","title":"4.2.1 \u83b7\u53d6\u7f51\u7edc\u7684\u9884\u6d4b\u7ed3\u679c"},{"location":"objectdection/05.yolo-demo/#422","text":"\u904d\u5386\u6bcf\u4e2a\u5c3a\u5ea6\u7684\u7ed3\u679c\uff0c\u8fdb\u884c\u62fc\u63a5 # \u76ee\u6807\u503c whole_targets = tf . zeros (( 0 , 6 ), dtype = tf . float32 ) # \u904d\u5386\u6bcf\u4e00\u4e2a\u5c3a\u5ea6 for i in range ( 3 ): # \u83b7\u53d6\u9884\u6d4b\u7684\u4f4d\u7f6e\u3001\u7f6e\u4fe1\u5ea6\u548c\u5206\u7c7b\u7ed3\u679c pred_xy , pred_wh , pred_box_confidence , pred_class = self . parsers [ i ]( outputs [ i ]) # \u83b7\u53d6\u76ee\u6807\u6846\u7684\u4f4d\u7f6e pred_box = tf . keras . layers . Concatenate ( axis =- 1 )([ pred_xy , pred_wh ]) #\u76ee\u6807\u6846\u7684\u7f6e\u4fe1\u5ea6\u5927\u4e8e\u9608\u503c\u7684\u90e8\u5206\uff1atarget_mask.shape = (h, w, anchor num) target_mask = tf . greater ( pred_box_confidence , conf_thres ) # \u83b7\u53d6\u5927\u4e8e\u9608\u503c\u7684\u90e8\u5206\u7684\u7f6e\u4fe1\u5ea6\uff1apred_box_confidence = (pred target num, 1) pred_box_confidence = tf . boolean_mask ( pred_box_confidence , target_mask ) # \u5728\u6700\u540e\u589e\u52a0\u4e00\u7ef4 pred_box_confidence = tf . expand_dims ( pred_box_confidence , axis =- 1 ) # \u83b7\u53d6\u5bf9\u5e94\u7684\u76ee\u6807\u6846\u68c0\u6d4b\u7ed3\u679c pred_box.shape = (pred target num, 4) pred_box = tf . boolean_mask ( pred_box , target_mask ) # \u5f52\u4e00\u5316\u5904\u7406 pred_box = ( pred_box - deviation ) * scale * \\ [ image . shape [ 1 ], image . shape [ 0 ], image . shape [ 1 ], image . shape [ 0 ]] # \u5206\u7c7b\u7ed3\u679c\uff1apred_class.shape = (pred target num, 1) pred_class = tf . boolean_mask ( pred_class , target_mask ) # \u83b7\u53d6\u6bcf\u4e2a\u7c7b\u522b\u6700\u5927\u7684\u7d22\u5f15 pred_class = tf . math . argmax ( pred_class , axis =- 1 ) # \u7c7b\u578b\u8f6c\u6362 pred_class = tf . cast ( tf . expand_dims ( pred_class , axis =- 1 ), dtype = tf . float32 ) # \u5c06\u9884\u6d4b\u7ed3\u679c\u62fc\u63a5\u5728\u4e00\u8d77 targets,sgaoe = (pred target num, 6) targets = tf . keras . layers . Concatenate ( axis =- 1 )([ pred_box , pred_box_confidence , pred_class ]) # \u5c06\u591a\u4e2a\u5c3a\u5ea6\u7684\u7ed3\u679c\u62fc\u63a5\u5728\u4e00\u8d77 whole_targets = tf . keras . layers . Concatenate ( axis = 0 )([ whole_targets , targets ])","title":"4.2.2 \u7ed3\u679c\u7ec4\u5408"},{"location":"objectdection/05.yolo-demo/#423-nms","text":"\u8fdb\u884cNMS\u5f97\u5230\u6700\u7ec8\u7684\u9884\u6d4b\u7ed3\u679c # \u8fdb\u884cNMS,\u6392\u5e8f\u4ee5\u7f6e\u4fe1\u5ea6\u6392\u5e8f,\u4ece\u5927\u5230\u5c0f\u6392\u5e8f descend_idx = tf . argsort ( whole_targets [ ... , 4 ], direction = 'DESCENDING' ) i = 0 # \u904d\u5386 while i < descend_idx . shape [ 0 ]: # \u83b7\u53d6\u7d22\u5f15\u503c idx = descend_idx [ i ] # \u5de6\u4e0a\u89d2\u5750\u6807 cur_upper_left = whole_targets [ idx , 0 : 2 ] - whole_targets [ idx , 2 : 4 ] / 2 # \u53f3\u4e0b\u89d2\u5750\u6807 cur_down_right = cur_upper_left + whole_targets [ idx , 2 : 4 ] # \u5bbd\u9ad8 wh = whole_targets [ idx , 2 : 4 ] # \u83b7\u53d6\u9762\u79ef area = wh [ ... , 0 ] * wh [ ... , 1 ] # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u7d22\u5f15 following_idx = descend_idx [ i + 1 :] # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846 following_targets = tf . gather ( whole_targets , following_idx ) # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u5de6\u4e0a\u89d2\u5750\u6807 following_upper_left = following_targets [ ... , 0 : 2 ] - following_targets [ ... , 2 : 4 ] / 2 # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u53f3\u4e0b\u89d2\u5750\u6807 following_down_right = following_upper_left + following_targets [ ... , 2 : 4 ] # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u5bbd\u9ad8 following_wh = following_targets [ ... , 2 : 4 ] # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u9762\u79ef following_area = following_wh [ ... , 0 ] * following_wh [ ... , 1 ] # \u8ba1\u7b97\u4ea4\u5e76\u6bd4 # \u8ba1\u7b97\u4ea4\u7684\u5de6\u4e0a\u89d2\u5750\u6807 max_upper_left = tf . math . maximum ( cur_upper_left , following_upper_left ) # \u8ba1\u7b97\u4ea4\u7684\u53f3\u4e0b\u89d2\u5750\u6807 min_down_right = tf . math . minimum ( cur_down_right , following_down_right ) # \u4ea4\u7684\u5bbd\u9ad8 intersect_wh = min_down_right - max_upper_left # \u5c06\u5bbd\u9ad8\u5927\u4e8e0\uff0c\u4fdd\u6301\u4e0d\u53d8\uff0c\u5c0f\u4e8e0\u7684\u7f6e\u4e3a0 intersect_wh = tf . where ( tf . math . greater ( intersect_wh , 0 ), intersect_wh , tf . zeros_like ( intersect_wh )) # \u8ba1\u7b97\u4ea4\u7684\u9762\u79ef intersect_area = intersect_wh [ ... , 0 ] * intersect_wh [ ... , 1 ] # \u8ba1\u7b97\u4ea4\u5e76\u6bd4 overlap = intersect_area / ( area + following_area - intersect_area ) # \u83b7\u53d6\u5c0f\u4e8eNMS\u9608\u503c\u7684\u4fdd\u7559\uff0c\u5176\u4ed6\u7684\u820d\u5f03 indices = tf . where ( tf . less ( overlap , nms_thres )) # \u8fdb\u884c\u5207\u7247\uff0c\u4fdd\u7559\u7ed3\u679c following_idx = tf . gather_nd ( following_idx , indices ) # \u5c06\u5176\u6dfb\u52a0\u5230descend\u4e2d\u5373\u53ef descend_idx = tf . concat ([ descend_idx [: i + 1 ], following_idx ], axis = 0 ) i += 1 # \u83b7\u53d6\u6700\u7ec8\u7684\u7ed3\u679c whole_targets = tf . gather ( whole_targets , descend_idx ) # \u5de6\u4e0a\u89d2\u5750\u6807 upper_left = ( whole_targets [ ... , 0 : 2 ] - whole_targets [ ... , 2 : 4 ] / 2 ) # \u53f3\u4e0b\u89d2\u5750\u6807 down_right = ( upper_left + whole_targets [ ... , 2 : 4 ]) # \u83b7\u53d6\u68c0\u6d4b\u7ed3\u679c boundings = tf . keras . layers . Concatenate ( axis =- 1 )([ upper_left , down_right , whole_targets [ ... , 4 :]]) return boundings","title":"4.2.3 NMS"},{"location":"objectdection/05.yolo-demo/#43","text":"\u6a21\u578b\u7684\u9884\u6d4b\u6548\u679c\uff1a import cv2 import numpy as np import matplotlib.pyplot as plt # \u56fe\u50cf\u8bfb\u53d6 img = cv2 . imread ( \"image.jpg\" ) # \u5b9e\u4f8b\u5316 predictor = Predictor () # \u83b7\u53d6\u7ed3\u679c boundings = predictor . predict ( img ) # \u663e\u793a\u56fe\u50cf plt . imshow ( img [:, :, :: - 1 ]) # \u83b7\u53d6\u5750\u6807\u533a\u57df ax = plt . gca () # \u52a0\u8f7d\u6a21\u578b\uff1a\u6a21\u578b\u8bad\u7ec3\u662f\u5728COCO\u6570\u636e\u96c6\u4e2d\u8fdb\u884c\u7684\uff0c # coco\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f classes = [ 'person' , 'bicycle' , 'car' , 'motorcycle' , 'airplane' , 'bus' , 'train' , 'truck' , 'boat' , 'traffic light' , 'fire hydrant' , 'stop sign' , 'parking meter' , 'bench' , 'bird' , 'cat' , 'dog' , 'horse' , 'sheep' , 'cow' , 'elephant' , 'bear' , 'zebra' , 'giraffe' , 'backpack' , 'umbrella' , 'handbag' , 'tie' , 'suitcase' , 'frisbee' , 'skis' , 'snowboard' , 'sports ball' , 'kite' , 'baseball bat' , 'baseball glove' , 'skateboard' , 'surfboard' , 'tennis racket' , 'bottle' , 'wine glass' , 'cup' , 'fork' , 'knife' , 'spoon' , 'bowl' , 'banana' , 'apple' , 'sandwich' , 'orange' , 'broccoli' , 'carrot' , 'hot dog' , 'pizza' , 'donut' , 'cake' , 'chair' , 'couch' , 'potted plant' , 'bed' , 'dining table' , 'toilet' , 'tv' , 'laptop' , 'mouse' , 'remote' , 'keyboard' , 'cell phone' , 'microwave' , 'oven' , 'toaster' , 'sink' , 'refrigerator' , 'book' , 'clock' , 'vase' , 'scissors' , 'teddy bear' , 'hair drier' , 'toothbrush' ] for bounding in boundings : # \u7ed8\u5236\u6846 rect = Rectangle (( bounding [ 0 ] . numpy (), bounding [ 1 ] . numpy ()), bounding [ 2 ] . numpy ( ) - bounding [ 0 ] . numpy (), bounding [ 3 ] . numpy () - bounding [ 1 ] . numpy (), color = 'r' , fill = False ) # \u5c06\u6846\u663e\u793a\u5728\u56fe\u50cf\u4e0a ax . add_patch ( rect ) # \u663e\u793a\u7c7b\u522b\u4fe1\u606f # \u83b7\u53d6\u7c7b\u522b\u4fe1\u606f\u7684id label_id = bounding [ 5 ] . numpy () . astype ( 'int32' ) # \u83b7\u53d6\u7c7b\u522b label = classes [ label_id ] # \u5c06\u6807\u6ce8\u4fe1\u606f\u6dfb\u52a0\u5728\u56fe\u50cf\u4e0a ax . text ( bounding [ 0 ] . numpy (), bounding [ 1 ] . numpy () + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) # \u4e0b\u4e00\u4e2a\u7ed3\u679c # \u663e\u793a\u56fe\u50cf plt . show () \u9884\u6d4b\u7ed3\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u603b\u7ed3 \u719f\u6089TFRecord\u6587\u4ef6\u7684\u4f7f\u7528\u65b9\u6cd5 TFRecord\u662fGoogle\u5b98\u65b9\u63a8\u8350\u4f7f\u7528\u7684\u6570\u636e\u683c\u5f0f\u5316\u5b58\u50a8\u5de5\u5177\uff0c\u4e3aTensorFlow\u91cf\u8eab\u6253\u9020\u7684\u3002TFRecord\u5185\u90e8\u5305\u542b\u591a\u4e2atf.train.Example\uff0c\u4e00\u822c\u6765\u8bf4\u5bf9\u5e94\u4e00\u4e2a\u56fe\u50cf\u6570\u636e\uff0c\u5728\u4e00\u4e2aExample\u6d88\u606f\u4f53\u4e2d\u5305\u542b\u4e86\u4e00\u7cfb\u5217\u7684tf.train.feature\u5c5e\u6027\uff0c\u800c \u6bcf\u4e00\u4e2afeature\u662f\u4e00\u4e2akey-value\u7684\u952e\u503c\u5bf9\u3002 \u77e5\u9053YoloV3\u6a21\u578b\u7ed3\u6784\u53ca\u6784\u5efa\u65b9\u6cd5 \u57fa\u672c\u7ec4\u4ef6\u7684\u6784\u5efa\uff0cbackbone\uff0coutput, yoloV3, \u8f93\u51fa\u503c\u7684\u8f6c\u6362 \u77e5\u9053\u6570\u636e\u5904\u7406\u65b9\u6cd5 \u77e5\u9053\u5bf9\u56fe\u50cf\u8fdb\u884cresize,\u4fdd\u6301\u5bbd\u9ad8\u6bd4\uff0c\u8fdb\u884cpad\u7684\u65b9\u6cd5 \u80fd\u591f\u5229\u7528yoloV3\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b \u77e5\u9053\u635f\u5931\u51fd\u6570\uff0c\u6b63\u8d1f\u6837\u672c\u8bbe\u7f6e\uff0c\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u9884\u6d4b\u7684\u8fc7\u7a0b\u3002","title":"4.3 \u9884\u6d4b\u7ed3\u679c"},{"location":"objectdection/05.yoloV3-demo/","text":"4.5 YoloV3 \u6848\u4f8b \u00b6 \u5b66\u4e60\u76ee\u6807 \u719f\u6089TFRecord\u6587\u4ef6\u7684\u4f7f\u7528\u65b9\u6cd5 \u77e5\u9053YoloV3\u6a21\u578b\u7ed3\u6784\u53ca\u6784\u5efa\u65b9\u6cd5 \u77e5\u9053\u6570\u636e\u5904\u7406\u65b9\u6cd5 \u80fd\u591f\u5229\u7528yoloV3\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b 1.\u6570\u636e\u83b7\u53d6 \u00b6 \u6839\u636e\u8981\u5b9e\u73b0\u7684\u4e1a\u52a1\u573a\u666f\uff0c\u9700\u8981\u6536\u96c6\u5927\u91cf\u7684\u56fe\u50cf\u6570\u636e\uff0c\u4e00\u822c\u6765\u8bf4\u5305\u542b\u4e24\u5927\u6765\u6e90\uff0c\u4e00\u90e8\u5206\u662f\u7f51\u7edc\u6570\u636e\uff0c\u53ef\u4ee5\u662f\u5f00\u6e90\u6570\u636e\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u767e\u5ea6\u3001Google\u56fe\u7247\u722c\u866b\u5f97\u5230\uff0c\u53e6\u4e00\u90e8\u5206\u662f\u7528\u6237\u573a\u666f\u7684\u89c6\u9891\u5f55\u50cf\uff0c\u8fd9\u4e00\u90e8\u5206\u7684\u6570\u636e\u91cf\u4f1a\u66f4\u5927\u3002\u5bf9\u4e8e\u5f00\u6e90\u6570\u636e\u6211\u4eec\u4e0d\u9700\u8981\u8fdb\u884c\u6807\u6ce8\uff0c\u800c\u722c\u53d6\u7684\u6570\u636e\u548c\u89c6\u9891\u5f55\u50cf\u9700\u8981\u8fdb\u884c\u6807\u6ce8\uff0c\u8fd9\u65f6\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u5f00\u6e90\u5de5\u5177labelImg\u8fdb\u884c\u6807\u6ce8\uff0c\u8be5\u8f6f\u4ef6\u622a\u56fe\u5982\u4e0b\uff1a \u5177\u4f53\u7684\u64cd\u4f5c\uff1a labelImage\u4f7f\u7528\u65b9\u6cd5 \u6570\u636e\u6807\u6ce8\u5b8c\u6210\u540e\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u4f7f\u7528\u5176\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u5728\u63a5\u4e0b\u6765\u7684\u8bfe\u7a0b\u4e2d\u6211\u4eec\u5c31\u4f7f\u7528\u6807\u6ce8\u597d\u7684\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u6a21\u578b\u9884\u6d4b\u3002\u4f7f\u7528\u7684\u5de5\u7a0b\u5982\u4e0b\u6240\u793a\uff1a \u4e3b\u8981\u5185\u5bb9\u662f\uff1a 1.config\u4e2d\u662f\u7f51\u7edc\u7684\u914d\u7f6e\u4fe1\u606f\uff1aanchors,\u7c7b\u522b\u4fe1\u606f 2.core\u4e2d\u662f\u635f\u5931\u51fd\u6570\u8ba1\u7b97\uff0c\u7f51\u7edc\u9884\u6d4b\u7684\u5185\u5bb9 3.dateset\u4e2d\u662f\u5bf9\u6570\u636e\u7684\u5904\u7406 4.model\u662f\u5bf9\u6a21\u578b\u7684\u6784\u5efa 5.utils\u662f\u4e00\u4e9b\u8f85\u52a9\u6587\u4ef6\uff0c\u5305\u62ecanchor,\u7c7b\u522b\u4fe1\u606f\u7684\u83b7\u53d6\u7b49 6.weights\u4e2d\u4fdd\u5b58\u4e86\u4e00\u4e2a\u4f7f\u7528coco\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u9884\u8bad\u7ec3\u6a21\u578b 2.TFrecord\u6587\u4ef6 \u00b6 \u8be5\u6848\u4f8b\u4e2d\u6211\u4eec\u4f9d\u7136\u4f7f\u7528VOC\u6570\u636e\u96c6\u6765\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff0c\u4e0d\u540c\u7684\u662f\u6211\u4eec\u8981\u5229\u7528tfrecord\u6587\u4ef6\u6765\u5b58\u50a8\u548c\u8bfb\u53d6\u6570\u636e\uff0c\u9996\u5148\u6765\u770b\u4e00\u4e0btfrecord\u6587\u4ef6\u7684\u76f8\u5173\u5185\u5bb9\u3002 \u4e3a\u4ec0\u4e48\u8981\u4f7f\u7528tfrecord\u6587\u4ef6\uff1f TFRecord\u662fGoogle\u5b98\u65b9\u63a8\u8350\u4f7f\u7528\u7684\u6570\u636e\u683c\u5f0f\u5316\u5b58\u50a8\u5de5\u5177\uff0c\u4e3aTensorFlow\u91cf\u8eab\u6253\u9020\u7684\u3002 TFRecord\u89c4\u8303\u4e86\u6570\u636e\u7684\u8bfb\u5199\u65b9\u5f0f\uff0c\u6570\u636e\u8bfb\u53d6\u548c\u5904\u7406\u7684\u6548\u7387\u90fd\u4f1a\u5f97\u5230\u663e\u8457\u7684\u63d0\u9ad8\u3002 2.1 \u4ec0\u4e48\u662fTFrecord\u6587\u4ef6 \u00b6 TFRecord \u662fGoogle\u5b98\u65b9\u63a8\u8350\u7684\u4e00\u79cd\u6570\u636e\u683c\u5f0f\uff0c\u662fGoogle\u4e13\u95e8\u4e3aTensorFlow\u8bbe\u8ba1\u7684\u4e00\u79cd\u6570\u636e\u683c\u5f0f\uff0c\u5229\u7528\u8fd9\u79cd\u65b9\u5f0f\u5b58\u50a8\u6570\u636e\u53ef\u4ee5\u4f7f\u5176\u4e0e\u7f51\u7edc\u67b6\u6784\u66f4\u9002\u914d\u3002TFRecord\u662f\u4e00\u79cd\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u5176\u80fd\u66f4\u597d\u7684\u5229\u7528\u5185\u5b58\uff0c\u4e0ecsv,hdf5\u6587\u4ef6\u662f\u7c7b\u4f3c\u7684\u3002 TFRecord\u7684\u6587\u4ef6\u7684\u5185\u5bb9\u5982\u4e0b\u56fe\u6240\u793a\uff1a TFRecord\u5185\u90e8\u5305\u542b\u591a\u4e2atf.train.Example\uff0c\u4e00\u822c\u6765\u8bf4\u5bf9\u5e94\u4e00\u4e2a\u56fe\u50cf\u6570\u636e\uff0c\u5728\u4e00\u4e2aExample\u6d88\u606f\u4f53\u4e2d\u5305\u542b\u4e86\u4e00\u7cfb\u5217\u7684tf.train.feature\u5c5e\u6027\uff0c\u800c \u6bcf\u4e00\u4e2afeature\u662f\u4e00\u4e2akey-value\u7684\u952e\u503c\u5bf9,key\u662f\u7279\u5f81\u540d\u79f0\uff0cvalue\u662f\u7279\u5f81\u503c\u3002 TFRecord \u5e76\u975e\u662fTensorFlow\u552f\u4e00\u652f\u6301\u7684\u6570\u636e\u683c\u5f0f\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528CSV\u6216\u6587\u672c\u7b49\u5176\u4ed6\u683c\u5f0f\uff0c\u4f46\u662f\u5bf9\u4e8eTensorFlow\u6765\u8bf4\uff0cTFRecord \u662f\u6700\u53cb\u597d\u7684\uff0c\u6700\u65b9\u4fbf\u7684\uff0c\u800c\u4e14tensorflow\u4e5f\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684API\u5e2e\u52a9\u6211\u4eec\u8f7b\u677e\u7684\u521b\u5efa\u548c\u83b7\u53d6TFRecord\u6587\u4ef6\u3002 2.2 \u5c06\u6570\u636e\u8f6c\u6362\u4e3aTFRecord\u6587\u4ef6 \u00b6 \u5bf9\u4e8e\u4e2d\u5927\u6570\u636e\u96c6\u6765\u8bf4\uff0cGoogle\u5b98\u65b9\u63a8\u8350\u5148\u5c06\u6570\u636e\u96c6\u8f6c\u5316\u4e3aTFRecord\u6570\u636e, \u8fd9\u6837\u53ef\u52a0\u5feb\u5728\u6570\u636e\u8bfb\u53d6, \u9884\u5904\u7406\u4e2d\u7684\u901f\u5ea6\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u5c31\u5c06VOC\u6570\u636e\u96c6\u8f6c\u6362\u4e3aRecords\u683c\u5f0f\uff0c\u5c06\u6570\u636e\u5199\u5165TFRecords\u6587\u4ef6\u4e2d,\u76f4\u63a5\u4f7f\u7528write_to_tfrecord\u5373\u53ef\u5b9e\u73b0\uff0c\u9996\u5148\u5bfc\u5165\u5de5\u5177\u5305\uff1a from dataset.vocdata_tfrecord import load_labels , write_to_tfrecord import os \u5c06\u6570\u636e\u5199\u5165tfrecord\u4e2d\u7684\u6d41\u7a0b\u662f\uff1a \u6307\u5b9a\u8981\u5199\u5165\u7684\u6570\u636e\u96c6\u8def\u5f84 \u83b7\u53d6\u6240\u6709\u7684XML\u6807\u6ce8\u6587\u4ef6 \u6307\u5b9atfrecord\u7684\u5b58\u50a8\u4f4d\u7f6e \u83b7\u53d6\u56fe\u50cf\u7684\u8def\u5f84 \u5c06\u6570\u636e\u5199\u5165\u5230tfrecord\u6587\u4ef6\u4e2d \u5b9e\u73b0\u5982\u4e0b\uff1a # \u6307\u5b9a\u8981\u5199\u5165\u7684\u6570\u636e\u96c6\u8def\u5f84 data_path = '/Users/yaoxiaoying/Desktop/yoloV3-tf2/dataset/VOCdevkit/VOC2007' # \u83b7\u53d6\u6240\u6709\u7684XML\u6807\u6ce8\u6587\u4ef6 all_xml = load_labels ( data_path , 'train' ) # \u6307\u5b9atfrecord\u7684\u5b58\u50a8\u4f4d\u7f6e tfrecord_path = 'voc_train.tfrecords' # \u83b7\u53d6\u56fe\u50cf\u7684\u8def\u5f84 voc_img_path = os . path . join ( data_path , 'JPEGImages' ) # \u5c06\u6570\u636e\u5199\u5165\u5230tfrecord\u6587\u4ef6\u4e2d write_to_tfrecord ( all_xml , tfrecord_path , voc_img_path ) \u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a 2.3 \u8bfb\u53d6TFRecord\u6587\u4ef6 \u00b6 VOC\u6570\u636e\u96c6\u5df2\u7ecf\u88ab\u5199\u5165\u5230TFRecord\u6587\u4ef6\u4e2d\u4e86\uff0c\u90a3\u6211\u4eec\u5c31\u8981\u4eceTFrecord\u6587\u4ef6\u4e2d\u5c06\u6570\u636e\u8bfb\u53d6\u51fa\u6765\u3002\u53ea\u4f7f\u7528 getdata\u5c31\u80fd\u591f\u8f7b\u677e\u7684\u8bfb\u53d6\u6570\u636e\u3002 \u5bfc\u5165\u5de5\u5177\u5305\uff1a # \u8bfb\u53d6tfrecords\u6587\u4ef6\u6240\u9700\u7684\u5de5\u5177\u5305 from dataset.get_tfdata import getdata # \u7ed8\u56fe import matplotlib.pyplot as plt from matplotlib.patches import Rectangle \u63a5\u4e0b\u6765\u4f7f\u7528getdata\u5c31\u53ef\u4ee5\u83b7\u53d6\u6587\u4ef6\u4e2d\u7684\u6240\u6709\u6570\u636e\uff1a # \u6307\u5b9atfrecord\u6587\u4ef6\u7684\u4f4d\u7f6e\uff0c\u83b7\u53d6tfrecord\u6587\u4ef6\u4e2d\u7684\u6570\u636e datasets = getdata ( \"dataset/voc_val.tfrecords\" ) \u6211\u4eec\u5c06\u4eceTFRecord\u6587\u4ef6\u4e2d\u8bfb\u53d6\u7684\u6570\u636e\u5c55\u793a\u51fa\u6765\uff1a from matplotlib.patches import Rectangle # \u6570\u636e\u7c7b\u522b from utils.config_utils import read_class_names classes = read_class_names ( \"config/classname\" ) # \u5c06tfrecord\u4e2d\u7684\u56fe\u50cf\u8fdb\u884c\u5c55\u793a plt . figure ( figsize = ( 15 , 10 )) # \u521d\u59cb\u5316\uff1a\u7b2c\u51e0\u4e2a\u56fe\u50cf i = 0 # \u4ecedatasets\u4e2d\u9009\u53d63\u4e2a\u6837\u672c\uff0c\u83b7\u53d6\u56fe\u50cf\uff0c\u5927\u5c0f\uff0c\u6846\u7684\u6807\u6ce8\u4fe1\u606f\u548c\u7c7b\u522b\u4fe1\u606f for image , width , height , boxes , boxes_category in datasets . take ( 3 ): # \u8fdb\u884c\u7ed8\u56fe plt . subplot ( 1 , 3 , i + 1 ) # \u7ed8\u5236\u56fe\u50cf plt . imshow ( image ) # \u83b7\u53d6\u5750\u6807\u533a\u57df ax = plt . gca () # \u904d\u5386\u6240\u6709\u7684\u6846 for j in range ( boxes . shape [ 0 ]): # \u7ed8\u5236\u6846 rect = Rectangle (( boxes [ j , 0 ], boxes [ j , 1 ]), boxes [ j , 2 ] - boxes [ j , 0 ], boxes [ j , 3 ] - boxes [ j , 1 ], color = 'r' , fill = False ) # \u5c06\u6846\u663e\u793a\u5728\u56fe\u50cf\u4e0a ax . add_patch ( rect ) # \u663e\u793a\u6807\u6ce8\u4fe1\u606f # \u83b7\u53d6\u6807\u6ce8\u4fe1\u606f\u7684id label_id = boxes_category [ j ] # \u83b7\u53d6\u6807\u51c6\u4fe1\u606f label = classes . get ( label_id . numpy ()) # \u5c06\u6807\u6ce8\u4fe1\u606f\u6dfb\u52a0\u5728\u56fe\u50cf\u4e0a ax . text ( boxes [ j , 0 ], boxes [ j , 1 ] + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) # \u4e0b\u4e00\u4e2a\u7ed3\u679c i += 1 # \u663e\u793a\u56fe\u50cf plt . show () \u7ed3\u679c\u4e3a\uff1a 2.4. \u6570\u636e\u5904\u7406 \u00b6 yoloV3\u6a21\u578b\u7684\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u662f32\u7684\u500d\u6570\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u5bf9\u56fe\u50cf\u8fdb\u884c\u5904\u7406\u3002\u5728\u8fd9\u91cc\u6211\u4eec\u5c06\u56fe\u50cf\u7684\u5c3a\u5ea6\u8c03\u6574\u4e3a416x416\u7684\u5927\u5c0f\uff0c\u4e3a\u4e86\u4fdd\u6301\u957f\u5bbd\u6bd4\uff0c\u6211\u5c06\u56db\u5468\u4e3a0\u7684\u50cf\u7d20\u4ee5\u7070\u5ea6\u503c128\u8fdb\u884c\u586b\u5145\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5b9e\u73b0\u8be5\u529f\u80fd\u4f7f\u7528dataset.preprocess\u6765\u5b8c\u6210\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u8f93\u5165\uff1a\u539f\u56fe\u50cf\u53ca\u56fe\u50cf\u4e0a\u7684\u6807\u51c6\u6846 # \u8f93\u51fa\uff1a\u5c06\u5c3a\u5ea6\u8c03\u6574\u540e\u7684\u56fe\u50cf\uff0c\u53ca\u76f8\u5e94\u7684\u76ee\u6807\u6846 image , bbox = preprocess ( oriimage , oribbox , input_shape = ( 416 , 416 )) \u6211\u4eec\u5bf9\u8bfb\u53d6\u7684\u6570\u636e\u8fdb\u884c\u5904\u7406\u5e76\u7ed8\u5236\u7ed3\u679c\uff1a # 1.\u5bfc\u5165\u5de5\u5177\u5305\uff0c from dataset.preprocess import preprocess as ppro # 2.\u521b\u5efa\u753b\u5e03 plt . figure ( figsize = ( 15 , 10 )) # 3.\u83b7\u53d6\u6570\u636e\u904d\u5386 i = 0 for image , width , height , boxes , boxes_category in datasets . take ( 3 ): # 4.\u8fdb\u884c\u6570\u636e\u5904\u7406 image , boxes = preprocess ( image , boxes ) # 5.\u5212\u5206\u4e0d\u540c\u7684\u5750\u6807\u8f74subplot() plt . subplot ( 1 , 3 , i + 1 ) # 6.\u663e\u793a\u56fe\u50cf\uff1aplt.imshow() plt . imshow ( image [ 0 ]) # 7.\u663e\u793abox,\u904d\u5386\u6240\u6709\u7684bbox,rectange\u8fdb\u884c\u7ed8\u5236 ax = plt . gca () for j in range ( boxes . shape [ 0 ]): rect = Rectangle (( boxes [ j , 0 ], boxes [ j , 1 ]), boxes [ j , 2 ] - boxes [ j , 0 ], boxes [ j , 3 ] - boxes [ j , 1 ], color = 'r' , fill = False ) ax . add_patch ( rect ) # 8.\u663e\u793a\u7c7b\u522b label_id = boxes_category [ j ] label = classes . get ( label_id . numpy ()) ax . text ( boxes [ j , 0 ], boxes [ j , 1 ] + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) i += 1 plt . show () 3.\u6a21\u578b\u6784\u5efa \u00b6 yoloV3\u7684\u6a21\u578b\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a\u6574\u4e2av3\u7ed3\u6784\u91cc\u9762\uff0c\u6ca1\u6709\u6c60\u5316\u5c42\u548c\u5168\u8fde\u63a5\u5c42\uff0c\u7f51\u7edc\u7684\u4e0b\u91c7\u6837\u662f\u901a\u8fc7\u8bbe\u7f6e\u5377\u79ef\u7684stride\u4e3a2\u6765\u8fbe\u5230\u7684\uff0c\u6bcf\u5f53\u901a\u8fc7\u8fd9\u4e2a\u5377\u79ef\u5c42\u4e4b\u540e\u56fe\u50cf\u7684\u5c3a\u5bf8\u5c31\u4f1a\u51cf\u5c0f\u5230\u4e00\u534a\u3002 \u5728\u6784\u5efa\u7f51\u7edc\u65f6\uff0c\u4f7f\u7528model.yoloV3\u6765\u8fdb\u884c\u6784\u5efa\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 from model.yoloV3 import YOLOv3 # \u6a21\u578b\u5b9e\u4f8b\u5316\uff1a\u6307\u5b9a\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\uff0c\u548c\u7c7b\u522b\u6570 yolov3 = YOLOv3 (( 416 , 416 , 3 ), 80 ) # \u83b7\u53d6\u6a21\u578b\u67b6\u6784 yolov3 . summary () \u90a3\u5230\u8fd9\u91cc\u6a21\u578b\u5c31\u6784\u5efa\u597d\u4e86\u3002 4.\u6a21\u578b\u8bad\u7ec3 \u00b6 4.1\u635f\u5931\u51fd\u6570\u7684\u8ba1\u7b97 \u00b6 YoloV3\u7684\u635f\u5931\u51fd\u6570\u5206\u4e3a\u4e09\u90e8\u5206\uff1a box\u7684\u635f\u5931\uff1a \u53ea\u6709\u8d1f\u8d23\u68c0\u6d4b\u7684gridcell\u4e2d\u7684anchor\u624d\u4f1a\u8ba1\u5165\u635f\u5931,\u5bf9x,y,w,h\u5206\u522b\u6c42\u5747\u65b9\u8bef\u5dee \u7f6e\u4fe1\u5ea6\u7684\u635f\u5931 \u7f6e\u4fe1\u5ea6\u7684\u635f\u5931\u662f\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u6240\u6709\u7684box\u90fd\u8ba1\u5165\u635f\u5931\u8ba1\u7b97 \u5206\u7c7b\u7684\u635f\u5931\uff1a \u5206\u7c7b\u7684\u635f\u5931\u662f\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u53ea\u6709\u8d1f\u8d23\u68c0\u6d4b\u76ee\u6807\u7684\u624d\u8ba1\u7b97\u635f\u5931 \u5728\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u65f6\u4f7f\u7528core.loss\u6765\u5b8c\u6210\uff1a # \u5bfc\u5165\u6240\u9700\u7684\u5de5\u5177\u5305 from core.loss import Loss # \u5b9e\u4f8b\u5316 yolov3_loss = Loss (( 416 , 416 , 3 ), 80 ) \u6211\u4eec\u6765\u770b\u4e0b\u635f\u5931\u7684\u8f93\u5165\u8f93\u51fa\uff1a # \u635f\u5931\u8f93\u5165 yolov3_loss . inputs # \u635f\u5931\u8f93\u51fa yolov3_loss . outputs \u8f93\u51fa\u7684\u7ed3\u679c\u5c31\u662f\u7f51\u7edc\u7684\u635f\u5931\u503c\uff0c\u662f\u4e00\u4e2a\u6807\u91cf\uff0c\u4f7f\u7528\u5b83\u5c31\u53ef\u4ee5\u6765\u5b8c\u6210\u7f51\u7edc\u7684\u8bad\u7ec3\u3002 4.2 \u6b63\u8d1f\u6837\u672c\u7684\u8bbe\u5b9a \u00b6 \u5728\u4e0a\u8ff0\u7684loss\u8ba1\u7b97\u4e2d\uff0c\u8d1f\u8d23\u8fdb\u884c\u76ee\u6807\u9884\u6d4b\u7684anchor\u5c31\u662f\u6b63\u6837\u672c\uff0c\u800c\u4e0d\u8d1f\u8d23\u8fdb\u884c\u76ee\u6807\u9884\u6d4b\u7684\u5c31\u662f\u8d1f\u6837\u672c\uff0c\u4e5f\u5c31\u662f\u80cc\u666f\uff0c\u90a3\u5728\u8fd9\u91cc\u6211\u4eec\u662f\u5982\u4f55\u8bbe\u7f6e\u6b63\u8d1f\u6837\u672c\u7684\u5462\uff1f\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6b63\u6837\u672c \uff1a\u9996\u5148\u8ba1\u7b97\u76ee\u6807\u4e2d\u5fc3\u70b9\u843d\u5728\u54ea\u4e2agrid\u4e0a\uff0c\u7136\u540e\u8ba1\u7b97\u8fd9\u4e2agrid\u5bf9\u5e94\u76843\u4e2a\u5148\u9a8c\u6846\uff08anchor\uff09\u548c\u76ee\u6807\u771f\u5b9e\u4f4d\u7f6e\u7684IOU\u503c\uff0c\u53d6IOU\u503c\u6700\u5927\u7684\u5148\u9a8c\u6846\u548c\u76ee\u6807\u5339\u914d\u3002\u90a3\u4e48\u8be5anchor \u5c31\u8d1f\u8d23\u9884\u6d4b\u8fd9\u4e2a\u76ee\u6807\uff0c\u90a3\u8fd9\u4e2aanchor\u5c31\u4f5c\u4e3a\u6b63\u6837\u672c\uff0c\u5c06\u5176\u7f6e\u4fe1\u5ea6\u8bbe\u4e3a1\uff0c\u5176\u4ed6\u7684\u76ee\u6807\u503c\u6839\u636e\u6807\u6ce8\u4fe1\u606f\u8bbe\u7f6e\u3002 \u8d1f\u6837\u672c \uff1a\u6240\u6709\u4e0d\u662f\u6b63\u6837\u672c\u7684anchor\u90fd\u662f\u8d1f\u6837\u672c\uff0c\u5c06\u5176\u7f6e\u4fe1\u5ea6\u8bbe\u4e3a0\uff0c\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\uff0c\u5176\u5b83\u7684\u503c\u4e0d\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\uff0c\u9ed8\u8ba4\u4e3a0\u3002 \u5bf9\u4e8e\u6bcf\u4e00\u4e2aanchor\u6211\u4eec\u90fd\u89814+1+80\u7ef4\u7684\u76ee\u6807\u503c\uff0c\u5176\u4e2d\u524d4\u7ef4\u662f\u5750\u6807\u503c\uff0c\u6b63\u6837\u672c\u662fGT\u7684bbox\u6846\u7684\u503c\uff0c\u7b2c5\u7ef4\u662f\u7f6e\u4fe1\u5ea6\uff0c\u6b63\u6837\u672c\u8bbe\u7f6e\u4e3a1\uff0c\u8d1f\u6837\u672c\u8bbe\u7f6e\u4e3a0\uff0c\u6700\u540e\u768480\u662f\u7c7b\u522b\u6570\uff0c\u6b63\u6837\u672c\u5bf9\u5e94\u7684\u7c7b\u522b\u8bbe\u7f6e\u4e3a1\uff0c\u5176\u4f59\u4e3a0\uff0c\u82e5\u4f7f\u7528voc\u6570\u636e\u96c6\u7c7b\u522b\u6570\u662f20 \u3002 \u53ef\u4ee5\u901a\u8fc7bbox_to_target\u6765\u5b8c\u6210\u6837\u672c\u7684\u8bbe\u7f6e\uff0c\u83b7\u53d6\u56fe\u50cf\u53ca\u5176\u6807\u6ce8\u4fe1\u606f\uff0c\u83b7\u53d6\u76ee\u6807\u503c\uff0c\u5982\u4e0b\uff1a # \u5bfc\u5165\u76ee\u6807\u503c\u8bbe\u7f6e\u6240\u9700\u65b9\u6cd5 from core.bbox_target import bbox_to_target # \u83b7\u53d6\u56fe\u50cf\u53ca\u5176\u6807\u6ce8\u4fe1\u606f for image , width , height , boxes , labels in datasets . take ( 1 ): # \u83b7\u53d6anchor\u7684\u76ee\u6807\u503c\uff0clabel1\u662f13*13\u7684\u76ee\u6807\u503c\uff0clabel2\u662f26*26\u7684\u76ee\u6807\u503c\uff0clabel3\u662f52*52\u7684\u76ee\u6807\u503c\uff0c label1 , label2 , label3 = bbox_to_target ( bbox = boxes , label = labels , num_classes = 20 ) \u6b63\u6837\u672c\u7684anchor\u7684\u7f6e\u4fe1\u5ea6\u4e3a1\uff0c\u6240\u4ee5\u6211\u4eec\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u4e3a1\u6765\u83b7\u53d6\u6b63\u6837\u672c\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # label1[...,0:4]\u5750\u6807\u503c\uff0clabel1[...,4]\u7f6e\u4fe1\u5ea6\uff0clabel1[...,5:]\u7c7b\u522b\u5206\u6570 index = tf . where ( tf . equal ( label1 [ ... , 4 ], 1 )) # index.numpy(),\u8bf4\u660e\u7d22\u5f15\u4e3a12 12 0 \u4e2a\u50cf\u7d20\u4e2dAnchor\u662f\u6b63\u6837\u672c array ([[ 12 , 12 , 0 ]]) \u5b83\u5bf9\u5e94\u7684\u5750\u6807\u503c\u662f\uff1a # label1[12, 12,0,0:4].numpy() array ([ 209. , 318. , 88. , 108. ], dtype = float32 ) \u5206\u7c7b\u7684\u76ee\u6807\u503c\u662f\uff1a # label1[12,12,0,5:].numpy() array ([ 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ], dtype = float32 ) \u6211\u4eec\u5c06\u76ee\u6807\u503c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a\uff1a import matplotlib.pyplot as plt from matplotlib.patches import Rectangle # 1.\u83b7\u53d6\u7c7b\u522b\u4fe1\u606f from utils.config_utils import read_class_names classes = read_class_names ( 'config/classname' ) # 2.\u521b\u5efa\u753b\u5e03 plt . figure ( figsize = ( 15 , 10 )) # 3.\u83b7\u53d6\u6570\u636e\u904d\u5386 for image , width , height , boxes , boxes_category in datasets . take ( 1 ): # 4.\u663e\u793a\u56fe\u50cf\uff1aplt.imshow() plt . imshow ( image ) # 5.\u663e\u793abox,\u904d\u5386\u6240\u6709\u7684bbox,rectange\u8fdb\u884c\u7ed8\u5236 ax = plt . gca () for j in range ( boxes . shape [ 0 ]): rect = Rectangle (( boxes [ j , 0 ], boxes [ j , 1 ]), boxes [ j , 2 ] - boxes [ j , 0 ], boxes [ j , 3 ] - boxes [ j , 1 ], color = 'r' , fill = False ) ax . add_patch ( rect ) # 6.\u663e\u793a\u7c7b\u522b label_id = boxes_category [ j ] label = classes . get ( label_id . numpy ()) ax . text ( boxes [ j , 0 ], boxes [ j , 1 ] + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) # 7.\u7ed8\u5236\u6b63\u6837\u672c\u7684anchor\u7684\u76ee\u6807\u503c anchor = label1 [ 12 , 12 , 0 , 0 : 4 ] . numpy () rect2 = Rectangle (( anchor [ 0 ] - anchor [ 2 ] / 2 , anchor [ 1 ] - anchor [ 3 ] / 2 ), anchor [ 2 ], anchor [ 3 ], color = 'g' , fill = False ) ax . add_patch ( rect2 ) plt . show () 4.3 \u6a21\u578b\u8bad\u7ec3 \u00b6 \u524d\u9762\u6211\u4eec\u5df2\u7ecf\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u7f51\u7edc\u6a21\u578b\u67b6\u6784\uff0c\u5728\u7f51\u7edc\u9884\u6d4b\u524d\u6211\u4eec\u9700\u8981\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\uff0c\u63a5\u4e0b\u6765\u4f7f\u7528\u7aef\u5230\u7aef\u7684\u65b9\u5f0f\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u57fa\u672c\u6b65\u9aa4\u662f\uff1a 1\u3001\u52a0\u8f7d\u6570\u636e\u96c6\uff1a\u6211\u4eec\u5728\u8fd9\u91cc\u4f7f\u7528VOC\u6570\u636e\u96c6\uff0c\u6240\u4ee5\u9700\u8981\u4eceTFrecord\u6587\u4ef6\u4e2d\u52a0\u8f7dVOC\u6570\u636e\u96c6 2\u3001\u6a21\u578b\u5b9e\u4f8b\u5316\uff1a\u52a0\u8f7dyoloV3\u6a21\u578b\u548c\u635f\u5931\u51fd\u6570\u7684\u5b9e\u73b0 3\u3001\u6a21\u578b\u8bad\u7ec3\uff1a\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u5bf9\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3 4.3.1 \u83b7\u53d6\u6570\u636e\u96c6 \u00b6 \u6211\u4eec\u4ecetfrecords\u6587\u4ef6\u4e2d\u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e: # \u5bfc\u5165 from dataset.preprocess import dataset # \u8bbe\u7f6ebatch_size batch_size = 1 # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e\uff0c\u5e76\u6307\u5b9abatchsize,\u8fd4\u56de\u8bad\u7ec3\u96c6\u6570\u636e trainset = dataset ( \"dataset/voc_train.tfrecords\" , batch_size ) 4.3.2 \u52a0\u8f7d\u6a21\u578b \u00b6 \u5c06\u5728yoloV3\u6a21\u578b\u548c\u635f\u5931\u51fd\u6570\u7684\u8ba1\u7b97\u8fdb\u884c\u5b9e\u4f8b\u5316\uff1a # V3\u6a21\u578b\u7684\u5b9e\u4f8b\u5316\uff0c\u6307\u5b9a\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\uff0c\u5373\u76ee\u6807\u68c0\u6d4b\u7684\u7c7b\u522b\u4e2a\u6570 yolov3 = YOLOv3 (( 416 , 416 , 3 ,), 20 ) yolov3_loss = Loss (( 416 , 416 , 3 ), 20 ) 4.3.3 \u6a21\u578b\u8bad\u7ec3 \u00b6 \u6a21\u578b\u8bad\u7ec3\u4e5f\u5c31\u662f\u8981\u4f7f\u7528\u635f\u5931\u51fd\u6570\uff0c\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\uff0c\u5229\u7528\u4f18\u5316\u5668\u8fdb\u884c\u53c2\u6570\u66f4\u65b0\uff0c\u8bad\u7ec3\u7684\u6d41\u7a0b\u662f\uff1a 1\u3001\u6307\u5b9a\u4f18\u5316\u5668\uff1a\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u52a0\u52a8\u91cf\u7684SGD\u65b9\u6cd5 2\u3001\u8bbe\u7f6eepoch\uff0c\u8fdb\u884c\u904d\u5386\u83b7\u53d6batch\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\u8fdb\u884c\u9884\u6d4b 3\u3001\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u66f4\u65b0\u53c2\u6570\uff0c\u6211\u4eec\u4f7f\u7528tf.GradientTape\u5b9e\u73b0\uff1a \u5b9a\u4e49\u4e0a\u4e0b\u6587\u73af\u5883\uff1atf.GradientTape \u8ba1\u7b97\u635f\u5931\u51fd\u6570loss \u4f7f\u7528 tape.gradient(loss,model.trainable_variables) \u81ea\u52a8\u8ba1\u7b97\u68af\u5ea6\uff0closs\u662f\u635f\u5931\u7ed3\u679c\uff0ctrainable_variables\u4e3a\u6240\u6709\u9700\u8981\u8bad\u7ec3\u7684\u53d8\u91cf\u3002 \u4f7f\u7528 optimizer.apply_gradients(zip(grads,model.trainable_variables)) \u81ea\u52a8\u66f4\u65b0\u6a21\u578b\u53c2\u6570\uff0czip(grads, trainable_variables)\u5c06\u68af\u5ea6\u548c\u53c2\u6570\u5173\u8054\u8d77\u6765\uff0c\u7136\u540eapply_gradients\u4f1a\u81ea\u52a8\u7684\u5229\u7528\u68af\u5ea6\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u6309\u7167\u8fd9\u4e2a\u6d41\u7a0b\u5b8c\u6210\u6a21\u578b\u8bad\u7ec3\uff0c\u5e76\u4fdd\u5b58\u6a21\u578b\u8bad\u7ec3\u7ed3\u679c\u3002 # 1\u3001\u5b9a\u4e49\u4f18\u5316\u65b9\u6cd5 optimizer = tf . keras . optimizers . SGD ( 0.1 , 0.9 ) # 2.\u8bbe\u7f6eepoch\uff0c\u83b7\u53d6batch\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\u8fdb\u884c\u9884\u6d4b for epoch in range ( 300 ): loss_history = [] # \u904d\u5386\u6bcf\u4e00\u4e2abatch\u7684\u56fe\u50cf\u548c\u76ee\u6807\u503c\uff0c\u8fdb\u884c\u66f4\u65b0 for ( batch , inputs ) in enumerate ( trainset ): images , labels = inputs # 3.\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u66f4\u65b0\u53c2\u6570 # 3.1 \u5b9a\u4e49\u4e0a\u4e0b\u6587\u73af\u5883 with tf . GradientTape () as tape : # 3.2 \u5c06\u56fe\u50cf\u9001\u5165\u7f51\u7edc\u4e2d outputs = yolov3 ( images ) # 3.3 \u8ba1\u7b97\u635f\u5931\u51fd\u6570 loss = yolov3_loss ([ * outputs , * labels ]) # 3.4 \u8ba1\u7b97\u68af\u5ea6 grads = tape . gradient ( loss , yolov3 . trainable_variables ) # 3.5 \u68af\u5ea6\u66f4\u65b0 optimizer . apply_gradients ( zip ( grads , yolov3 . trainable_variables )) # 3.6 \u6253\u5370\u4fe1\u606f info = 'epoch: %d , batch: %d ,loss: %f ' % ( epoch , batch , np . mean ( loss_history )) print ( info ) loss_history . append ( loss . numpy ()) yolov3 . save ( 'yolov3.h5' ) \u635f\u5931\u51fd\u6570\u7684\u53d8\u5316\u4e3a\uff1a epoch: 0, batch: 0 ,loss: 701318.312500 epoch: 0, batch: 1 ,loss: 765384.625000 epoch: 0, batch: 2 ,loss: 747363.000000 epoch: 0, batch: 3 ,loss: 708547.187500 epoch: 0, batch: 4 ,loss: 699261.500000 epoch: 0, batch: 5 ,loss: 727906.812500 epoch: 0, batch: 6 ,loss: 696439.875000 epoch: 0, batch: 7 ,loss: 669801.500000 epoch: 0, batch: 8 ,loss: 669526.875000 \u5f53\u6211\u4eec\u8bad\u7ec3\u597d\u6a21\u578b\u540e\uff0c\u5c31\u53ef\u4ee5\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u4e86\u3002 5.\u6a21\u578b\u9884\u6d4b \u00b6 \u6211\u4eec\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u9884\u6d4b,\u5728\u8fd9\u91cc\u6211\u4eec\u901a\u8fc7yoloV3\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\uff0c\u5e76\u5c06\u9884\u6d4b\u7ed3\u679c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a\u3002\u9996\u5148\u5bfc\u5165\u5de5\u5177\u5305\uff0c\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u662f\u4f7f\u7528coco\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u7684\uff0c\u6240\u4ee5\u6307\u5b9a\u76f8\u5e94\u7684\u7c7b\u522b\u4fe1\u606f\uff1a # \u8bfb\u53d6\u56fe\u50cf\uff0c\u7ed8\u56fe\u7684\u5de5\u5177\u5305 import cv2 import matplotlib.pyplot as plt from matplotlib.patches import Rectangle # yoloV3\u7684\u9884\u6d4b\u5668 from core.predicter import Predictor # coco\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f classes = [ 'person' , 'bicycle' , 'car' , 'motorcycle' , 'airplane' , 'bus' , 'train' , 'truck' , 'boat' , 'traffic light' , 'fire hydrant' , 'stop sign' , 'parking meter' , 'bench' , 'bird' , 'cat' , 'dog' , 'horse' , 'sheep' , 'cow' , 'elephant' , 'bear' , 'zebra' , 'giraffe' , 'backpack' , 'umbrella' , 'handbag' , 'tie' , 'suitcase' , 'frisbee' , 'skis' , 'snowboard' , 'sports ball' , 'kite' , 'baseball bat' , 'baseball glove' , 'skateboard' , 'surfboard' , 'tennis racket' , 'bottle' , 'wine glass' , 'cup' , 'fork' , 'knife' , 'spoon' , 'bowl' , 'banana' , 'apple' , 'sandwich' , 'orange' , 'broccoli' , 'carrot' , 'hot dog' , 'pizza' , 'donut' , 'cake' , 'chair' , 'couch' , 'potted plant' , 'bed' , 'dining table' , 'toilet' , 'tv' , 'laptop' , 'mouse' , 'remote' , 'keyboard' , 'cell phone' , 'microwave' , 'oven' , 'toaster' , 'sink' , 'refrigerator' , 'book' , 'clock' , 'vase' , 'scissors' , 'teddy bear' , 'hair drier' , 'toothbrush' ] \u6574\u4e2a\u6d41\u7a0b\u662f\uff1a 1.\u8bfb\u53d6\u8981\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u7684\u56fe\u50cf 2.\u5b9e\u4f8b\u5316yoloV3\u7684\u9884\u6d4b\u5668\uff0c\u5e76\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u3002 3.\u5229\u7528\u9884\u6d4b\u5668\u5bf9\u56fe\u7247\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b 4.\u5c06\u68c0\u6d4b\u7ed3\u679c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a \u5b9e\u73b0\u5982\u4e0b\uff1a # 1. \u56fe\u50cf\u8bfb\u53d6 img = cv2 . imread ( \"image.jpg\" ) # 2.\u5b9e\u4f8b\u5316\uff0c\u5e76\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b predictor = Predictor ( class_num = 80 , yolov3 = \"weights/yolov3.h5\" ) # 3.\u83b7\u53d6\u68c0\u6d4b\u7ed3\u679c boundings = predictor . predict ( img ) # 4.\u5c06\u68c0\u6d4b\u7ed3\u679c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a # 4.1 \u663e\u793a\u56fe\u50cf plt . imshow ( img [:, :, :: - 1 ]) # \u83b7\u53d6\u5750\u6807\u533a\u57df ax = plt . gca () # 4.2 \u904d\u5386\u68c0\u6d4b\u6846\uff0c\u5c06\u68c0\u6d4b\u6846\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a for bounding in boundings : # \u7ed8\u5236\u6846 rect = Rectangle (( bounding [ 0 ] . numpy (), bounding [ 1 ] . numpy ()), bounding [ 2 ] . numpy ( ) - bounding [ 0 ] . numpy (), bounding [ 3 ] . numpy () - bounding [ 1 ] . numpy (), color = 'r' , fill = False ) # \u5c06\u6846\u663e\u793a\u5728\u56fe\u50cf\u4e0a ax . add_patch ( rect ) # \u663e\u793a\u7c7b\u522b\u4fe1\u606f # \u83b7\u53d6\u7c7b\u522b\u4fe1\u606f\u7684id label_id = bounding [ 5 ] . numpy () . astype ( 'int32' ) # \u83b7\u53d6\u7c7b\u522b label = classes [ label_id ] # \u5c06\u6807\u6ce8\u4fe1\u606f\u6dfb\u52a0\u5728\u56fe\u50cf\u4e0a ax . text ( bounding [ 0 ] . numpy (), bounding [ 1 ] . numpy () + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) # \u663e\u793a\u56fe\u50cf plt . show () \u9884\u6d4b\u7ed3\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u603b\u7ed3 \u719f\u6089TFRecord\u6587\u4ef6\u7684\u4f7f\u7528\u65b9\u6cd5 TFRecord\u662fGoogle\u5b98\u65b9\u63a8\u8350\u4f7f\u7528\u7684\u6570\u636e\u683c\u5f0f\u5316\u5b58\u50a8\u5de5\u5177\uff0c\u4e3aTensorFlow\u91cf\u8eab\u6253\u9020\u7684\u3002TFRecord\u5185\u90e8\u5305\u542b\u591a\u4e2atf.train.Example\uff0c\u4e00\u822c\u6765\u8bf4\u5bf9\u5e94\u4e00\u4e2a\u56fe\u50cf\u6570\u636e\uff0c\u5728\u4e00\u4e2aExample\u6d88\u606f\u4f53\u4e2d\u5305\u542b\u4e86\u4e00\u7cfb\u5217\u7684tf.train.feature\u5c5e\u6027\uff0c\u800c \u6bcf\u4e00\u4e2afeature\u662f\u4e00\u4e2akey-value\u7684\u952e\u503c\u5bf9\u3002 \u77e5\u9053YoloV3\u6a21\u578b\u7ed3\u6784\u53ca\u6784\u5efa\u65b9\u6cd5 \u57fa\u672c\u7ec4\u4ef6\u7684\u6784\u5efa\uff0cbackbone\uff0coutput, yoloV3, \u8f93\u51fa\u503c\u7684\u8f6c\u6362 \u77e5\u9053\u6570\u636e\u5904\u7406\u65b9\u6cd5 \u77e5\u9053\u5bf9\u56fe\u50cf\u8fdb\u884cresize,\u4fdd\u6301\u5bbd\u9ad8\u6bd4\uff0c\u8fdb\u884cpad\u7684\u65b9\u6cd5 \u80fd\u591f\u5229\u7528yoloV3\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b \u77e5\u9053\u635f\u5931\u51fd\u6570\uff0c\u6b63\u8d1f\u6837\u672c\u8bbe\u7f6e\uff0c\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u9884\u6d4b\u7684\u8fc7\u7a0b\u3002","title":"YOLOV3\u6848\u4f8b"},{"location":"objectdection/05.yoloV3-demo/#45-yolov3","text":"\u5b66\u4e60\u76ee\u6807 \u719f\u6089TFRecord\u6587\u4ef6\u7684\u4f7f\u7528\u65b9\u6cd5 \u77e5\u9053YoloV3\u6a21\u578b\u7ed3\u6784\u53ca\u6784\u5efa\u65b9\u6cd5 \u77e5\u9053\u6570\u636e\u5904\u7406\u65b9\u6cd5 \u80fd\u591f\u5229\u7528yoloV3\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b","title":"4.5 YoloV3 \u6848\u4f8b"},{"location":"objectdection/05.yoloV3-demo/#1","text":"\u6839\u636e\u8981\u5b9e\u73b0\u7684\u4e1a\u52a1\u573a\u666f\uff0c\u9700\u8981\u6536\u96c6\u5927\u91cf\u7684\u56fe\u50cf\u6570\u636e\uff0c\u4e00\u822c\u6765\u8bf4\u5305\u542b\u4e24\u5927\u6765\u6e90\uff0c\u4e00\u90e8\u5206\u662f\u7f51\u7edc\u6570\u636e\uff0c\u53ef\u4ee5\u662f\u5f00\u6e90\u6570\u636e\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u767e\u5ea6\u3001Google\u56fe\u7247\u722c\u866b\u5f97\u5230\uff0c\u53e6\u4e00\u90e8\u5206\u662f\u7528\u6237\u573a\u666f\u7684\u89c6\u9891\u5f55\u50cf\uff0c\u8fd9\u4e00\u90e8\u5206\u7684\u6570\u636e\u91cf\u4f1a\u66f4\u5927\u3002\u5bf9\u4e8e\u5f00\u6e90\u6570\u636e\u6211\u4eec\u4e0d\u9700\u8981\u8fdb\u884c\u6807\u6ce8\uff0c\u800c\u722c\u53d6\u7684\u6570\u636e\u548c\u89c6\u9891\u5f55\u50cf\u9700\u8981\u8fdb\u884c\u6807\u6ce8\uff0c\u8fd9\u65f6\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u5f00\u6e90\u5de5\u5177labelImg\u8fdb\u884c\u6807\u6ce8\uff0c\u8be5\u8f6f\u4ef6\u622a\u56fe\u5982\u4e0b\uff1a \u5177\u4f53\u7684\u64cd\u4f5c\uff1a labelImage\u4f7f\u7528\u65b9\u6cd5 \u6570\u636e\u6807\u6ce8\u5b8c\u6210\u540e\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u4f7f\u7528\u5176\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u5728\u63a5\u4e0b\u6765\u7684\u8bfe\u7a0b\u4e2d\u6211\u4eec\u5c31\u4f7f\u7528\u6807\u6ce8\u597d\u7684\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u6a21\u578b\u9884\u6d4b\u3002\u4f7f\u7528\u7684\u5de5\u7a0b\u5982\u4e0b\u6240\u793a\uff1a \u4e3b\u8981\u5185\u5bb9\u662f\uff1a 1.config\u4e2d\u662f\u7f51\u7edc\u7684\u914d\u7f6e\u4fe1\u606f\uff1aanchors,\u7c7b\u522b\u4fe1\u606f 2.core\u4e2d\u662f\u635f\u5931\u51fd\u6570\u8ba1\u7b97\uff0c\u7f51\u7edc\u9884\u6d4b\u7684\u5185\u5bb9 3.dateset\u4e2d\u662f\u5bf9\u6570\u636e\u7684\u5904\u7406 4.model\u662f\u5bf9\u6a21\u578b\u7684\u6784\u5efa 5.utils\u662f\u4e00\u4e9b\u8f85\u52a9\u6587\u4ef6\uff0c\u5305\u62ecanchor,\u7c7b\u522b\u4fe1\u606f\u7684\u83b7\u53d6\u7b49 6.weights\u4e2d\u4fdd\u5b58\u4e86\u4e00\u4e2a\u4f7f\u7528coco\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u9884\u8bad\u7ec3\u6a21\u578b","title":"1.\u6570\u636e\u83b7\u53d6"},{"location":"objectdection/05.yoloV3-demo/#2tfrecord","text":"\u8be5\u6848\u4f8b\u4e2d\u6211\u4eec\u4f9d\u7136\u4f7f\u7528VOC\u6570\u636e\u96c6\u6765\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff0c\u4e0d\u540c\u7684\u662f\u6211\u4eec\u8981\u5229\u7528tfrecord\u6587\u4ef6\u6765\u5b58\u50a8\u548c\u8bfb\u53d6\u6570\u636e\uff0c\u9996\u5148\u6765\u770b\u4e00\u4e0btfrecord\u6587\u4ef6\u7684\u76f8\u5173\u5185\u5bb9\u3002 \u4e3a\u4ec0\u4e48\u8981\u4f7f\u7528tfrecord\u6587\u4ef6\uff1f TFRecord\u662fGoogle\u5b98\u65b9\u63a8\u8350\u4f7f\u7528\u7684\u6570\u636e\u683c\u5f0f\u5316\u5b58\u50a8\u5de5\u5177\uff0c\u4e3aTensorFlow\u91cf\u8eab\u6253\u9020\u7684\u3002 TFRecord\u89c4\u8303\u4e86\u6570\u636e\u7684\u8bfb\u5199\u65b9\u5f0f\uff0c\u6570\u636e\u8bfb\u53d6\u548c\u5904\u7406\u7684\u6548\u7387\u90fd\u4f1a\u5f97\u5230\u663e\u8457\u7684\u63d0\u9ad8\u3002","title":"2.TFrecord\u6587\u4ef6"},{"location":"objectdection/05.yoloV3-demo/#21-tfrecord","text":"TFRecord \u662fGoogle\u5b98\u65b9\u63a8\u8350\u7684\u4e00\u79cd\u6570\u636e\u683c\u5f0f\uff0c\u662fGoogle\u4e13\u95e8\u4e3aTensorFlow\u8bbe\u8ba1\u7684\u4e00\u79cd\u6570\u636e\u683c\u5f0f\uff0c\u5229\u7528\u8fd9\u79cd\u65b9\u5f0f\u5b58\u50a8\u6570\u636e\u53ef\u4ee5\u4f7f\u5176\u4e0e\u7f51\u7edc\u67b6\u6784\u66f4\u9002\u914d\u3002TFRecord\u662f\u4e00\u79cd\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u5176\u80fd\u66f4\u597d\u7684\u5229\u7528\u5185\u5b58\uff0c\u4e0ecsv,hdf5\u6587\u4ef6\u662f\u7c7b\u4f3c\u7684\u3002 TFRecord\u7684\u6587\u4ef6\u7684\u5185\u5bb9\u5982\u4e0b\u56fe\u6240\u793a\uff1a TFRecord\u5185\u90e8\u5305\u542b\u591a\u4e2atf.train.Example\uff0c\u4e00\u822c\u6765\u8bf4\u5bf9\u5e94\u4e00\u4e2a\u56fe\u50cf\u6570\u636e\uff0c\u5728\u4e00\u4e2aExample\u6d88\u606f\u4f53\u4e2d\u5305\u542b\u4e86\u4e00\u7cfb\u5217\u7684tf.train.feature\u5c5e\u6027\uff0c\u800c \u6bcf\u4e00\u4e2afeature\u662f\u4e00\u4e2akey-value\u7684\u952e\u503c\u5bf9,key\u662f\u7279\u5f81\u540d\u79f0\uff0cvalue\u662f\u7279\u5f81\u503c\u3002 TFRecord \u5e76\u975e\u662fTensorFlow\u552f\u4e00\u652f\u6301\u7684\u6570\u636e\u683c\u5f0f\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528CSV\u6216\u6587\u672c\u7b49\u5176\u4ed6\u683c\u5f0f\uff0c\u4f46\u662f\u5bf9\u4e8eTensorFlow\u6765\u8bf4\uff0cTFRecord \u662f\u6700\u53cb\u597d\u7684\uff0c\u6700\u65b9\u4fbf\u7684\uff0c\u800c\u4e14tensorflow\u4e5f\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684API\u5e2e\u52a9\u6211\u4eec\u8f7b\u677e\u7684\u521b\u5efa\u548c\u83b7\u53d6TFRecord\u6587\u4ef6\u3002","title":"2.1 \u4ec0\u4e48\u662fTFrecord\u6587\u4ef6"},{"location":"objectdection/05.yoloV3-demo/#22-tfrecord","text":"\u5bf9\u4e8e\u4e2d\u5927\u6570\u636e\u96c6\u6765\u8bf4\uff0cGoogle\u5b98\u65b9\u63a8\u8350\u5148\u5c06\u6570\u636e\u96c6\u8f6c\u5316\u4e3aTFRecord\u6570\u636e, \u8fd9\u6837\u53ef\u52a0\u5feb\u5728\u6570\u636e\u8bfb\u53d6, \u9884\u5904\u7406\u4e2d\u7684\u901f\u5ea6\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u5c31\u5c06VOC\u6570\u636e\u96c6\u8f6c\u6362\u4e3aRecords\u683c\u5f0f\uff0c\u5c06\u6570\u636e\u5199\u5165TFRecords\u6587\u4ef6\u4e2d,\u76f4\u63a5\u4f7f\u7528write_to_tfrecord\u5373\u53ef\u5b9e\u73b0\uff0c\u9996\u5148\u5bfc\u5165\u5de5\u5177\u5305\uff1a from dataset.vocdata_tfrecord import load_labels , write_to_tfrecord import os \u5c06\u6570\u636e\u5199\u5165tfrecord\u4e2d\u7684\u6d41\u7a0b\u662f\uff1a \u6307\u5b9a\u8981\u5199\u5165\u7684\u6570\u636e\u96c6\u8def\u5f84 \u83b7\u53d6\u6240\u6709\u7684XML\u6807\u6ce8\u6587\u4ef6 \u6307\u5b9atfrecord\u7684\u5b58\u50a8\u4f4d\u7f6e \u83b7\u53d6\u56fe\u50cf\u7684\u8def\u5f84 \u5c06\u6570\u636e\u5199\u5165\u5230tfrecord\u6587\u4ef6\u4e2d \u5b9e\u73b0\u5982\u4e0b\uff1a # \u6307\u5b9a\u8981\u5199\u5165\u7684\u6570\u636e\u96c6\u8def\u5f84 data_path = '/Users/yaoxiaoying/Desktop/yoloV3-tf2/dataset/VOCdevkit/VOC2007' # \u83b7\u53d6\u6240\u6709\u7684XML\u6807\u6ce8\u6587\u4ef6 all_xml = load_labels ( data_path , 'train' ) # \u6307\u5b9atfrecord\u7684\u5b58\u50a8\u4f4d\u7f6e tfrecord_path = 'voc_train.tfrecords' # \u83b7\u53d6\u56fe\u50cf\u7684\u8def\u5f84 voc_img_path = os . path . join ( data_path , 'JPEGImages' ) # \u5c06\u6570\u636e\u5199\u5165\u5230tfrecord\u6587\u4ef6\u4e2d write_to_tfrecord ( all_xml , tfrecord_path , voc_img_path ) \u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a","title":"2.2 \u5c06\u6570\u636e\u8f6c\u6362\u4e3aTFRecord\u6587\u4ef6"},{"location":"objectdection/05.yoloV3-demo/#23-tfrecord","text":"VOC\u6570\u636e\u96c6\u5df2\u7ecf\u88ab\u5199\u5165\u5230TFRecord\u6587\u4ef6\u4e2d\u4e86\uff0c\u90a3\u6211\u4eec\u5c31\u8981\u4eceTFrecord\u6587\u4ef6\u4e2d\u5c06\u6570\u636e\u8bfb\u53d6\u51fa\u6765\u3002\u53ea\u4f7f\u7528 getdata\u5c31\u80fd\u591f\u8f7b\u677e\u7684\u8bfb\u53d6\u6570\u636e\u3002 \u5bfc\u5165\u5de5\u5177\u5305\uff1a # \u8bfb\u53d6tfrecords\u6587\u4ef6\u6240\u9700\u7684\u5de5\u5177\u5305 from dataset.get_tfdata import getdata # \u7ed8\u56fe import matplotlib.pyplot as plt from matplotlib.patches import Rectangle \u63a5\u4e0b\u6765\u4f7f\u7528getdata\u5c31\u53ef\u4ee5\u83b7\u53d6\u6587\u4ef6\u4e2d\u7684\u6240\u6709\u6570\u636e\uff1a # \u6307\u5b9atfrecord\u6587\u4ef6\u7684\u4f4d\u7f6e\uff0c\u83b7\u53d6tfrecord\u6587\u4ef6\u4e2d\u7684\u6570\u636e datasets = getdata ( \"dataset/voc_val.tfrecords\" ) \u6211\u4eec\u5c06\u4eceTFRecord\u6587\u4ef6\u4e2d\u8bfb\u53d6\u7684\u6570\u636e\u5c55\u793a\u51fa\u6765\uff1a from matplotlib.patches import Rectangle # \u6570\u636e\u7c7b\u522b from utils.config_utils import read_class_names classes = read_class_names ( \"config/classname\" ) # \u5c06tfrecord\u4e2d\u7684\u56fe\u50cf\u8fdb\u884c\u5c55\u793a plt . figure ( figsize = ( 15 , 10 )) # \u521d\u59cb\u5316\uff1a\u7b2c\u51e0\u4e2a\u56fe\u50cf i = 0 # \u4ecedatasets\u4e2d\u9009\u53d63\u4e2a\u6837\u672c\uff0c\u83b7\u53d6\u56fe\u50cf\uff0c\u5927\u5c0f\uff0c\u6846\u7684\u6807\u6ce8\u4fe1\u606f\u548c\u7c7b\u522b\u4fe1\u606f for image , width , height , boxes , boxes_category in datasets . take ( 3 ): # \u8fdb\u884c\u7ed8\u56fe plt . subplot ( 1 , 3 , i + 1 ) # \u7ed8\u5236\u56fe\u50cf plt . imshow ( image ) # \u83b7\u53d6\u5750\u6807\u533a\u57df ax = plt . gca () # \u904d\u5386\u6240\u6709\u7684\u6846 for j in range ( boxes . shape [ 0 ]): # \u7ed8\u5236\u6846 rect = Rectangle (( boxes [ j , 0 ], boxes [ j , 1 ]), boxes [ j , 2 ] - boxes [ j , 0 ], boxes [ j , 3 ] - boxes [ j , 1 ], color = 'r' , fill = False ) # \u5c06\u6846\u663e\u793a\u5728\u56fe\u50cf\u4e0a ax . add_patch ( rect ) # \u663e\u793a\u6807\u6ce8\u4fe1\u606f # \u83b7\u53d6\u6807\u6ce8\u4fe1\u606f\u7684id label_id = boxes_category [ j ] # \u83b7\u53d6\u6807\u51c6\u4fe1\u606f label = classes . get ( label_id . numpy ()) # \u5c06\u6807\u6ce8\u4fe1\u606f\u6dfb\u52a0\u5728\u56fe\u50cf\u4e0a ax . text ( boxes [ j , 0 ], boxes [ j , 1 ] + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) # \u4e0b\u4e00\u4e2a\u7ed3\u679c i += 1 # \u663e\u793a\u56fe\u50cf plt . show () \u7ed3\u679c\u4e3a\uff1a","title":"2.3 \u8bfb\u53d6TFRecord\u6587\u4ef6"},{"location":"objectdection/05.yoloV3-demo/#24","text":"yoloV3\u6a21\u578b\u7684\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u662f32\u7684\u500d\u6570\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u5bf9\u56fe\u50cf\u8fdb\u884c\u5904\u7406\u3002\u5728\u8fd9\u91cc\u6211\u4eec\u5c06\u56fe\u50cf\u7684\u5c3a\u5ea6\u8c03\u6574\u4e3a416x416\u7684\u5927\u5c0f\uff0c\u4e3a\u4e86\u4fdd\u6301\u957f\u5bbd\u6bd4\uff0c\u6211\u5c06\u56db\u5468\u4e3a0\u7684\u50cf\u7d20\u4ee5\u7070\u5ea6\u503c128\u8fdb\u884c\u586b\u5145\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5b9e\u73b0\u8be5\u529f\u80fd\u4f7f\u7528dataset.preprocess\u6765\u5b8c\u6210\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u8f93\u5165\uff1a\u539f\u56fe\u50cf\u53ca\u56fe\u50cf\u4e0a\u7684\u6807\u51c6\u6846 # \u8f93\u51fa\uff1a\u5c06\u5c3a\u5ea6\u8c03\u6574\u540e\u7684\u56fe\u50cf\uff0c\u53ca\u76f8\u5e94\u7684\u76ee\u6807\u6846 image , bbox = preprocess ( oriimage , oribbox , input_shape = ( 416 , 416 )) \u6211\u4eec\u5bf9\u8bfb\u53d6\u7684\u6570\u636e\u8fdb\u884c\u5904\u7406\u5e76\u7ed8\u5236\u7ed3\u679c\uff1a # 1.\u5bfc\u5165\u5de5\u5177\u5305\uff0c from dataset.preprocess import preprocess as ppro # 2.\u521b\u5efa\u753b\u5e03 plt . figure ( figsize = ( 15 , 10 )) # 3.\u83b7\u53d6\u6570\u636e\u904d\u5386 i = 0 for image , width , height , boxes , boxes_category in datasets . take ( 3 ): # 4.\u8fdb\u884c\u6570\u636e\u5904\u7406 image , boxes = preprocess ( image , boxes ) # 5.\u5212\u5206\u4e0d\u540c\u7684\u5750\u6807\u8f74subplot() plt . subplot ( 1 , 3 , i + 1 ) # 6.\u663e\u793a\u56fe\u50cf\uff1aplt.imshow() plt . imshow ( image [ 0 ]) # 7.\u663e\u793abox,\u904d\u5386\u6240\u6709\u7684bbox,rectange\u8fdb\u884c\u7ed8\u5236 ax = plt . gca () for j in range ( boxes . shape [ 0 ]): rect = Rectangle (( boxes [ j , 0 ], boxes [ j , 1 ]), boxes [ j , 2 ] - boxes [ j , 0 ], boxes [ j , 3 ] - boxes [ j , 1 ], color = 'r' , fill = False ) ax . add_patch ( rect ) # 8.\u663e\u793a\u7c7b\u522b label_id = boxes_category [ j ] label = classes . get ( label_id . numpy ()) ax . text ( boxes [ j , 0 ], boxes [ j , 1 ] + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) i += 1 plt . show ()","title":"2.4. \u6570\u636e\u5904\u7406"},{"location":"objectdection/05.yoloV3-demo/#3","text":"yoloV3\u7684\u6a21\u578b\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a\u6574\u4e2av3\u7ed3\u6784\u91cc\u9762\uff0c\u6ca1\u6709\u6c60\u5316\u5c42\u548c\u5168\u8fde\u63a5\u5c42\uff0c\u7f51\u7edc\u7684\u4e0b\u91c7\u6837\u662f\u901a\u8fc7\u8bbe\u7f6e\u5377\u79ef\u7684stride\u4e3a2\u6765\u8fbe\u5230\u7684\uff0c\u6bcf\u5f53\u901a\u8fc7\u8fd9\u4e2a\u5377\u79ef\u5c42\u4e4b\u540e\u56fe\u50cf\u7684\u5c3a\u5bf8\u5c31\u4f1a\u51cf\u5c0f\u5230\u4e00\u534a\u3002 \u5728\u6784\u5efa\u7f51\u7edc\u65f6\uff0c\u4f7f\u7528model.yoloV3\u6765\u8fdb\u884c\u6784\u5efa\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 from model.yoloV3 import YOLOv3 # \u6a21\u578b\u5b9e\u4f8b\u5316\uff1a\u6307\u5b9a\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\uff0c\u548c\u7c7b\u522b\u6570 yolov3 = YOLOv3 (( 416 , 416 , 3 ), 80 ) # \u83b7\u53d6\u6a21\u578b\u67b6\u6784 yolov3 . summary () \u90a3\u5230\u8fd9\u91cc\u6a21\u578b\u5c31\u6784\u5efa\u597d\u4e86\u3002","title":"3.\u6a21\u578b\u6784\u5efa"},{"location":"objectdection/05.yoloV3-demo/#4","text":"","title":"4.\u6a21\u578b\u8bad\u7ec3"},{"location":"objectdection/05.yoloV3-demo/#41","text":"YoloV3\u7684\u635f\u5931\u51fd\u6570\u5206\u4e3a\u4e09\u90e8\u5206\uff1a box\u7684\u635f\u5931\uff1a \u53ea\u6709\u8d1f\u8d23\u68c0\u6d4b\u7684gridcell\u4e2d\u7684anchor\u624d\u4f1a\u8ba1\u5165\u635f\u5931,\u5bf9x,y,w,h\u5206\u522b\u6c42\u5747\u65b9\u8bef\u5dee \u7f6e\u4fe1\u5ea6\u7684\u635f\u5931 \u7f6e\u4fe1\u5ea6\u7684\u635f\u5931\u662f\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u6240\u6709\u7684box\u90fd\u8ba1\u5165\u635f\u5931\u8ba1\u7b97 \u5206\u7c7b\u7684\u635f\u5931\uff1a \u5206\u7c7b\u7684\u635f\u5931\u662f\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u53ea\u6709\u8d1f\u8d23\u68c0\u6d4b\u76ee\u6807\u7684\u624d\u8ba1\u7b97\u635f\u5931 \u5728\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u65f6\u4f7f\u7528core.loss\u6765\u5b8c\u6210\uff1a # \u5bfc\u5165\u6240\u9700\u7684\u5de5\u5177\u5305 from core.loss import Loss # \u5b9e\u4f8b\u5316 yolov3_loss = Loss (( 416 , 416 , 3 ), 80 ) \u6211\u4eec\u6765\u770b\u4e0b\u635f\u5931\u7684\u8f93\u5165\u8f93\u51fa\uff1a # \u635f\u5931\u8f93\u5165 yolov3_loss . inputs # \u635f\u5931\u8f93\u51fa yolov3_loss . outputs \u8f93\u51fa\u7684\u7ed3\u679c\u5c31\u662f\u7f51\u7edc\u7684\u635f\u5931\u503c\uff0c\u662f\u4e00\u4e2a\u6807\u91cf\uff0c\u4f7f\u7528\u5b83\u5c31\u53ef\u4ee5\u6765\u5b8c\u6210\u7f51\u7edc\u7684\u8bad\u7ec3\u3002","title":"4.1\u635f\u5931\u51fd\u6570\u7684\u8ba1\u7b97"},{"location":"objectdection/05.yoloV3-demo/#42","text":"\u5728\u4e0a\u8ff0\u7684loss\u8ba1\u7b97\u4e2d\uff0c\u8d1f\u8d23\u8fdb\u884c\u76ee\u6807\u9884\u6d4b\u7684anchor\u5c31\u662f\u6b63\u6837\u672c\uff0c\u800c\u4e0d\u8d1f\u8d23\u8fdb\u884c\u76ee\u6807\u9884\u6d4b\u7684\u5c31\u662f\u8d1f\u6837\u672c\uff0c\u4e5f\u5c31\u662f\u80cc\u666f\uff0c\u90a3\u5728\u8fd9\u91cc\u6211\u4eec\u662f\u5982\u4f55\u8bbe\u7f6e\u6b63\u8d1f\u6837\u672c\u7684\u5462\uff1f\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6b63\u6837\u672c \uff1a\u9996\u5148\u8ba1\u7b97\u76ee\u6807\u4e2d\u5fc3\u70b9\u843d\u5728\u54ea\u4e2agrid\u4e0a\uff0c\u7136\u540e\u8ba1\u7b97\u8fd9\u4e2agrid\u5bf9\u5e94\u76843\u4e2a\u5148\u9a8c\u6846\uff08anchor\uff09\u548c\u76ee\u6807\u771f\u5b9e\u4f4d\u7f6e\u7684IOU\u503c\uff0c\u53d6IOU\u503c\u6700\u5927\u7684\u5148\u9a8c\u6846\u548c\u76ee\u6807\u5339\u914d\u3002\u90a3\u4e48\u8be5anchor \u5c31\u8d1f\u8d23\u9884\u6d4b\u8fd9\u4e2a\u76ee\u6807\uff0c\u90a3\u8fd9\u4e2aanchor\u5c31\u4f5c\u4e3a\u6b63\u6837\u672c\uff0c\u5c06\u5176\u7f6e\u4fe1\u5ea6\u8bbe\u4e3a1\uff0c\u5176\u4ed6\u7684\u76ee\u6807\u503c\u6839\u636e\u6807\u6ce8\u4fe1\u606f\u8bbe\u7f6e\u3002 \u8d1f\u6837\u672c \uff1a\u6240\u6709\u4e0d\u662f\u6b63\u6837\u672c\u7684anchor\u90fd\u662f\u8d1f\u6837\u672c\uff0c\u5c06\u5176\u7f6e\u4fe1\u5ea6\u8bbe\u4e3a0\uff0c\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\uff0c\u5176\u5b83\u7684\u503c\u4e0d\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\uff0c\u9ed8\u8ba4\u4e3a0\u3002 \u5bf9\u4e8e\u6bcf\u4e00\u4e2aanchor\u6211\u4eec\u90fd\u89814+1+80\u7ef4\u7684\u76ee\u6807\u503c\uff0c\u5176\u4e2d\u524d4\u7ef4\u662f\u5750\u6807\u503c\uff0c\u6b63\u6837\u672c\u662fGT\u7684bbox\u6846\u7684\u503c\uff0c\u7b2c5\u7ef4\u662f\u7f6e\u4fe1\u5ea6\uff0c\u6b63\u6837\u672c\u8bbe\u7f6e\u4e3a1\uff0c\u8d1f\u6837\u672c\u8bbe\u7f6e\u4e3a0\uff0c\u6700\u540e\u768480\u662f\u7c7b\u522b\u6570\uff0c\u6b63\u6837\u672c\u5bf9\u5e94\u7684\u7c7b\u522b\u8bbe\u7f6e\u4e3a1\uff0c\u5176\u4f59\u4e3a0\uff0c\u82e5\u4f7f\u7528voc\u6570\u636e\u96c6\u7c7b\u522b\u6570\u662f20 \u3002 \u53ef\u4ee5\u901a\u8fc7bbox_to_target\u6765\u5b8c\u6210\u6837\u672c\u7684\u8bbe\u7f6e\uff0c\u83b7\u53d6\u56fe\u50cf\u53ca\u5176\u6807\u6ce8\u4fe1\u606f\uff0c\u83b7\u53d6\u76ee\u6807\u503c\uff0c\u5982\u4e0b\uff1a # \u5bfc\u5165\u76ee\u6807\u503c\u8bbe\u7f6e\u6240\u9700\u65b9\u6cd5 from core.bbox_target import bbox_to_target # \u83b7\u53d6\u56fe\u50cf\u53ca\u5176\u6807\u6ce8\u4fe1\u606f for image , width , height , boxes , labels in datasets . take ( 1 ): # \u83b7\u53d6anchor\u7684\u76ee\u6807\u503c\uff0clabel1\u662f13*13\u7684\u76ee\u6807\u503c\uff0clabel2\u662f26*26\u7684\u76ee\u6807\u503c\uff0clabel3\u662f52*52\u7684\u76ee\u6807\u503c\uff0c label1 , label2 , label3 = bbox_to_target ( bbox = boxes , label = labels , num_classes = 20 ) \u6b63\u6837\u672c\u7684anchor\u7684\u7f6e\u4fe1\u5ea6\u4e3a1\uff0c\u6240\u4ee5\u6211\u4eec\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u4e3a1\u6765\u83b7\u53d6\u6b63\u6837\u672c\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # label1[...,0:4]\u5750\u6807\u503c\uff0clabel1[...,4]\u7f6e\u4fe1\u5ea6\uff0clabel1[...,5:]\u7c7b\u522b\u5206\u6570 index = tf . where ( tf . equal ( label1 [ ... , 4 ], 1 )) # index.numpy(),\u8bf4\u660e\u7d22\u5f15\u4e3a12 12 0 \u4e2a\u50cf\u7d20\u4e2dAnchor\u662f\u6b63\u6837\u672c array ([[ 12 , 12 , 0 ]]) \u5b83\u5bf9\u5e94\u7684\u5750\u6807\u503c\u662f\uff1a # label1[12, 12,0,0:4].numpy() array ([ 209. , 318. , 88. , 108. ], dtype = float32 ) \u5206\u7c7b\u7684\u76ee\u6807\u503c\u662f\uff1a # label1[12,12,0,5:].numpy() array ([ 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ], dtype = float32 ) \u6211\u4eec\u5c06\u76ee\u6807\u503c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a\uff1a import matplotlib.pyplot as plt from matplotlib.patches import Rectangle # 1.\u83b7\u53d6\u7c7b\u522b\u4fe1\u606f from utils.config_utils import read_class_names classes = read_class_names ( 'config/classname' ) # 2.\u521b\u5efa\u753b\u5e03 plt . figure ( figsize = ( 15 , 10 )) # 3.\u83b7\u53d6\u6570\u636e\u904d\u5386 for image , width , height , boxes , boxes_category in datasets . take ( 1 ): # 4.\u663e\u793a\u56fe\u50cf\uff1aplt.imshow() plt . imshow ( image ) # 5.\u663e\u793abox,\u904d\u5386\u6240\u6709\u7684bbox,rectange\u8fdb\u884c\u7ed8\u5236 ax = plt . gca () for j in range ( boxes . shape [ 0 ]): rect = Rectangle (( boxes [ j , 0 ], boxes [ j , 1 ]), boxes [ j , 2 ] - boxes [ j , 0 ], boxes [ j , 3 ] - boxes [ j , 1 ], color = 'r' , fill = False ) ax . add_patch ( rect ) # 6.\u663e\u793a\u7c7b\u522b label_id = boxes_category [ j ] label = classes . get ( label_id . numpy ()) ax . text ( boxes [ j , 0 ], boxes [ j , 1 ] + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) # 7.\u7ed8\u5236\u6b63\u6837\u672c\u7684anchor\u7684\u76ee\u6807\u503c anchor = label1 [ 12 , 12 , 0 , 0 : 4 ] . numpy () rect2 = Rectangle (( anchor [ 0 ] - anchor [ 2 ] / 2 , anchor [ 1 ] - anchor [ 3 ] / 2 ), anchor [ 2 ], anchor [ 3 ], color = 'g' , fill = False ) ax . add_patch ( rect2 ) plt . show ()","title":"4.2 \u6b63\u8d1f\u6837\u672c\u7684\u8bbe\u5b9a"},{"location":"objectdection/05.yoloV3-demo/#43","text":"\u524d\u9762\u6211\u4eec\u5df2\u7ecf\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u7f51\u7edc\u6a21\u578b\u67b6\u6784\uff0c\u5728\u7f51\u7edc\u9884\u6d4b\u524d\u6211\u4eec\u9700\u8981\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\uff0c\u63a5\u4e0b\u6765\u4f7f\u7528\u7aef\u5230\u7aef\u7684\u65b9\u5f0f\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u57fa\u672c\u6b65\u9aa4\u662f\uff1a 1\u3001\u52a0\u8f7d\u6570\u636e\u96c6\uff1a\u6211\u4eec\u5728\u8fd9\u91cc\u4f7f\u7528VOC\u6570\u636e\u96c6\uff0c\u6240\u4ee5\u9700\u8981\u4eceTFrecord\u6587\u4ef6\u4e2d\u52a0\u8f7dVOC\u6570\u636e\u96c6 2\u3001\u6a21\u578b\u5b9e\u4f8b\u5316\uff1a\u52a0\u8f7dyoloV3\u6a21\u578b\u548c\u635f\u5931\u51fd\u6570\u7684\u5b9e\u73b0 3\u3001\u6a21\u578b\u8bad\u7ec3\uff1a\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u5bf9\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3","title":"4.3 \u6a21\u578b\u8bad\u7ec3"},{"location":"objectdection/05.yoloV3-demo/#431","text":"\u6211\u4eec\u4ecetfrecords\u6587\u4ef6\u4e2d\u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e: # \u5bfc\u5165 from dataset.preprocess import dataset # \u8bbe\u7f6ebatch_size batch_size = 1 # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e\uff0c\u5e76\u6307\u5b9abatchsize,\u8fd4\u56de\u8bad\u7ec3\u96c6\u6570\u636e trainset = dataset ( \"dataset/voc_train.tfrecords\" , batch_size )","title":"4.3.1 \u83b7\u53d6\u6570\u636e\u96c6"},{"location":"objectdection/05.yoloV3-demo/#432","text":"\u5c06\u5728yoloV3\u6a21\u578b\u548c\u635f\u5931\u51fd\u6570\u7684\u8ba1\u7b97\u8fdb\u884c\u5b9e\u4f8b\u5316\uff1a # V3\u6a21\u578b\u7684\u5b9e\u4f8b\u5316\uff0c\u6307\u5b9a\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\uff0c\u5373\u76ee\u6807\u68c0\u6d4b\u7684\u7c7b\u522b\u4e2a\u6570 yolov3 = YOLOv3 (( 416 , 416 , 3 ,), 20 ) yolov3_loss = Loss (( 416 , 416 , 3 ), 20 )","title":"4.3.2 \u52a0\u8f7d\u6a21\u578b"},{"location":"objectdection/05.yoloV3-demo/#433","text":"\u6a21\u578b\u8bad\u7ec3\u4e5f\u5c31\u662f\u8981\u4f7f\u7528\u635f\u5931\u51fd\u6570\uff0c\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\uff0c\u5229\u7528\u4f18\u5316\u5668\u8fdb\u884c\u53c2\u6570\u66f4\u65b0\uff0c\u8bad\u7ec3\u7684\u6d41\u7a0b\u662f\uff1a 1\u3001\u6307\u5b9a\u4f18\u5316\u5668\uff1a\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u52a0\u52a8\u91cf\u7684SGD\u65b9\u6cd5 2\u3001\u8bbe\u7f6eepoch\uff0c\u8fdb\u884c\u904d\u5386\u83b7\u53d6batch\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\u8fdb\u884c\u9884\u6d4b 3\u3001\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u66f4\u65b0\u53c2\u6570\uff0c\u6211\u4eec\u4f7f\u7528tf.GradientTape\u5b9e\u73b0\uff1a \u5b9a\u4e49\u4e0a\u4e0b\u6587\u73af\u5883\uff1atf.GradientTape \u8ba1\u7b97\u635f\u5931\u51fd\u6570loss \u4f7f\u7528 tape.gradient(loss,model.trainable_variables) \u81ea\u52a8\u8ba1\u7b97\u68af\u5ea6\uff0closs\u662f\u635f\u5931\u7ed3\u679c\uff0ctrainable_variables\u4e3a\u6240\u6709\u9700\u8981\u8bad\u7ec3\u7684\u53d8\u91cf\u3002 \u4f7f\u7528 optimizer.apply_gradients(zip(grads,model.trainable_variables)) \u81ea\u52a8\u66f4\u65b0\u6a21\u578b\u53c2\u6570\uff0czip(grads, trainable_variables)\u5c06\u68af\u5ea6\u548c\u53c2\u6570\u5173\u8054\u8d77\u6765\uff0c\u7136\u540eapply_gradients\u4f1a\u81ea\u52a8\u7684\u5229\u7528\u68af\u5ea6\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u6309\u7167\u8fd9\u4e2a\u6d41\u7a0b\u5b8c\u6210\u6a21\u578b\u8bad\u7ec3\uff0c\u5e76\u4fdd\u5b58\u6a21\u578b\u8bad\u7ec3\u7ed3\u679c\u3002 # 1\u3001\u5b9a\u4e49\u4f18\u5316\u65b9\u6cd5 optimizer = tf . keras . optimizers . SGD ( 0.1 , 0.9 ) # 2.\u8bbe\u7f6eepoch\uff0c\u83b7\u53d6batch\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\u8fdb\u884c\u9884\u6d4b for epoch in range ( 300 ): loss_history = [] # \u904d\u5386\u6bcf\u4e00\u4e2abatch\u7684\u56fe\u50cf\u548c\u76ee\u6807\u503c\uff0c\u8fdb\u884c\u66f4\u65b0 for ( batch , inputs ) in enumerate ( trainset ): images , labels = inputs # 3.\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u66f4\u65b0\u53c2\u6570 # 3.1 \u5b9a\u4e49\u4e0a\u4e0b\u6587\u73af\u5883 with tf . GradientTape () as tape : # 3.2 \u5c06\u56fe\u50cf\u9001\u5165\u7f51\u7edc\u4e2d outputs = yolov3 ( images ) # 3.3 \u8ba1\u7b97\u635f\u5931\u51fd\u6570 loss = yolov3_loss ([ * outputs , * labels ]) # 3.4 \u8ba1\u7b97\u68af\u5ea6 grads = tape . gradient ( loss , yolov3 . trainable_variables ) # 3.5 \u68af\u5ea6\u66f4\u65b0 optimizer . apply_gradients ( zip ( grads , yolov3 . trainable_variables )) # 3.6 \u6253\u5370\u4fe1\u606f info = 'epoch: %d , batch: %d ,loss: %f ' % ( epoch , batch , np . mean ( loss_history )) print ( info ) loss_history . append ( loss . numpy ()) yolov3 . save ( 'yolov3.h5' ) \u635f\u5931\u51fd\u6570\u7684\u53d8\u5316\u4e3a\uff1a epoch: 0, batch: 0 ,loss: 701318.312500 epoch: 0, batch: 1 ,loss: 765384.625000 epoch: 0, batch: 2 ,loss: 747363.000000 epoch: 0, batch: 3 ,loss: 708547.187500 epoch: 0, batch: 4 ,loss: 699261.500000 epoch: 0, batch: 5 ,loss: 727906.812500 epoch: 0, batch: 6 ,loss: 696439.875000 epoch: 0, batch: 7 ,loss: 669801.500000 epoch: 0, batch: 8 ,loss: 669526.875000 \u5f53\u6211\u4eec\u8bad\u7ec3\u597d\u6a21\u578b\u540e\uff0c\u5c31\u53ef\u4ee5\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u4e86\u3002","title":"4.3.3 \u6a21\u578b\u8bad\u7ec3"},{"location":"objectdection/05.yoloV3-demo/#5","text":"\u6211\u4eec\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u9884\u6d4b,\u5728\u8fd9\u91cc\u6211\u4eec\u901a\u8fc7yoloV3\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\uff0c\u5e76\u5c06\u9884\u6d4b\u7ed3\u679c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a\u3002\u9996\u5148\u5bfc\u5165\u5de5\u5177\u5305\uff0c\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u662f\u4f7f\u7528coco\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u7684\uff0c\u6240\u4ee5\u6307\u5b9a\u76f8\u5e94\u7684\u7c7b\u522b\u4fe1\u606f\uff1a # \u8bfb\u53d6\u56fe\u50cf\uff0c\u7ed8\u56fe\u7684\u5de5\u5177\u5305 import cv2 import matplotlib.pyplot as plt from matplotlib.patches import Rectangle # yoloV3\u7684\u9884\u6d4b\u5668 from core.predicter import Predictor # coco\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f classes = [ 'person' , 'bicycle' , 'car' , 'motorcycle' , 'airplane' , 'bus' , 'train' , 'truck' , 'boat' , 'traffic light' , 'fire hydrant' , 'stop sign' , 'parking meter' , 'bench' , 'bird' , 'cat' , 'dog' , 'horse' , 'sheep' , 'cow' , 'elephant' , 'bear' , 'zebra' , 'giraffe' , 'backpack' , 'umbrella' , 'handbag' , 'tie' , 'suitcase' , 'frisbee' , 'skis' , 'snowboard' , 'sports ball' , 'kite' , 'baseball bat' , 'baseball glove' , 'skateboard' , 'surfboard' , 'tennis racket' , 'bottle' , 'wine glass' , 'cup' , 'fork' , 'knife' , 'spoon' , 'bowl' , 'banana' , 'apple' , 'sandwich' , 'orange' , 'broccoli' , 'carrot' , 'hot dog' , 'pizza' , 'donut' , 'cake' , 'chair' , 'couch' , 'potted plant' , 'bed' , 'dining table' , 'toilet' , 'tv' , 'laptop' , 'mouse' , 'remote' , 'keyboard' , 'cell phone' , 'microwave' , 'oven' , 'toaster' , 'sink' , 'refrigerator' , 'book' , 'clock' , 'vase' , 'scissors' , 'teddy bear' , 'hair drier' , 'toothbrush' ] \u6574\u4e2a\u6d41\u7a0b\u662f\uff1a 1.\u8bfb\u53d6\u8981\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u7684\u56fe\u50cf 2.\u5b9e\u4f8b\u5316yoloV3\u7684\u9884\u6d4b\u5668\uff0c\u5e76\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u3002 3.\u5229\u7528\u9884\u6d4b\u5668\u5bf9\u56fe\u7247\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b 4.\u5c06\u68c0\u6d4b\u7ed3\u679c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a \u5b9e\u73b0\u5982\u4e0b\uff1a # 1. \u56fe\u50cf\u8bfb\u53d6 img = cv2 . imread ( \"image.jpg\" ) # 2.\u5b9e\u4f8b\u5316\uff0c\u5e76\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b predictor = Predictor ( class_num = 80 , yolov3 = \"weights/yolov3.h5\" ) # 3.\u83b7\u53d6\u68c0\u6d4b\u7ed3\u679c boundings = predictor . predict ( img ) # 4.\u5c06\u68c0\u6d4b\u7ed3\u679c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a # 4.1 \u663e\u793a\u56fe\u50cf plt . imshow ( img [:, :, :: - 1 ]) # \u83b7\u53d6\u5750\u6807\u533a\u57df ax = plt . gca () # 4.2 \u904d\u5386\u68c0\u6d4b\u6846\uff0c\u5c06\u68c0\u6d4b\u6846\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a for bounding in boundings : # \u7ed8\u5236\u6846 rect = Rectangle (( bounding [ 0 ] . numpy (), bounding [ 1 ] . numpy ()), bounding [ 2 ] . numpy ( ) - bounding [ 0 ] . numpy (), bounding [ 3 ] . numpy () - bounding [ 1 ] . numpy (), color = 'r' , fill = False ) # \u5c06\u6846\u663e\u793a\u5728\u56fe\u50cf\u4e0a ax . add_patch ( rect ) # \u663e\u793a\u7c7b\u522b\u4fe1\u606f # \u83b7\u53d6\u7c7b\u522b\u4fe1\u606f\u7684id label_id = bounding [ 5 ] . numpy () . astype ( 'int32' ) # \u83b7\u53d6\u7c7b\u522b label = classes [ label_id ] # \u5c06\u6807\u6ce8\u4fe1\u606f\u6dfb\u52a0\u5728\u56fe\u50cf\u4e0a ax . text ( bounding [ 0 ] . numpy (), bounding [ 1 ] . numpy () + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) # \u663e\u793a\u56fe\u50cf plt . show () \u9884\u6d4b\u7ed3\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u603b\u7ed3 \u719f\u6089TFRecord\u6587\u4ef6\u7684\u4f7f\u7528\u65b9\u6cd5 TFRecord\u662fGoogle\u5b98\u65b9\u63a8\u8350\u4f7f\u7528\u7684\u6570\u636e\u683c\u5f0f\u5316\u5b58\u50a8\u5de5\u5177\uff0c\u4e3aTensorFlow\u91cf\u8eab\u6253\u9020\u7684\u3002TFRecord\u5185\u90e8\u5305\u542b\u591a\u4e2atf.train.Example\uff0c\u4e00\u822c\u6765\u8bf4\u5bf9\u5e94\u4e00\u4e2a\u56fe\u50cf\u6570\u636e\uff0c\u5728\u4e00\u4e2aExample\u6d88\u606f\u4f53\u4e2d\u5305\u542b\u4e86\u4e00\u7cfb\u5217\u7684tf.train.feature\u5c5e\u6027\uff0c\u800c \u6bcf\u4e00\u4e2afeature\u662f\u4e00\u4e2akey-value\u7684\u952e\u503c\u5bf9\u3002 \u77e5\u9053YoloV3\u6a21\u578b\u7ed3\u6784\u53ca\u6784\u5efa\u65b9\u6cd5 \u57fa\u672c\u7ec4\u4ef6\u7684\u6784\u5efa\uff0cbackbone\uff0coutput, yoloV3, \u8f93\u51fa\u503c\u7684\u8f6c\u6362 \u77e5\u9053\u6570\u636e\u5904\u7406\u65b9\u6cd5 \u77e5\u9053\u5bf9\u56fe\u50cf\u8fdb\u884cresize,\u4fdd\u6301\u5bbd\u9ad8\u6bd4\uff0c\u8fdb\u884cpad\u7684\u65b9\u6cd5 \u80fd\u591f\u5229\u7528yoloV3\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b \u77e5\u9053\u635f\u5931\u51fd\u6570\uff0c\u6b63\u8d1f\u6837\u672c\u8bbe\u7f6e\uff0c\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u9884\u6d4b\u7684\u8fc7\u7a0b\u3002","title":"5.\u6a21\u578b\u9884\u6d4b"},{"location":"objectdection/06.ssd/","text":"4.6 SSD\u7b97\u6cd5 \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053SSD\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u7684\u7f51\u7edc \u77e5\u9053SSD\u4e2d\u5148\u9a8c\u6846\u7684\u751f\u6210\u65b9\u5f0f \u77e5\u9053SSD\u7684\u635f\u5931\u51fd\u6570\u7684\u8bbe\u8ba1 \u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e3b\u8981\u5206\u4e3a\u4e24\u7c7b\uff1a Two-stage\u65b9\u6cd5\uff1a\u5982R-CNN\u7cfb\u5217\u7b97\u6cd5\uff0c\u4e3b\u8981\u601d\u8def\u5c31\u662f\u901a\u8fc7Selective Search\u6216\u8005CNN\u7f51\u7edc\u4ea7\u751f\u4e00\u7cfb\u5217\u7684\u7a00\u758f\u77e9\u9635\u7684\u5019\u9009\u533a\u57df\uff0c\u7136\u540e\u5bf9\u8fd9\u4e9b\u5019\u9009\u533a\u57df\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0ctwo-stage\u7684\u65b9\u6cd5\u4f18\u52bf\u5728\u4e8e\u51c6\u786e\u7387\u5ea6\u9ad8\uff1b One-stage\u65b9\u6cd5\uff1a\u5982YOLO\u7cfb\u5217\u65b9\u6cd5\uff0c\u4e3b\u8981\u601d\u8def\u5c31\u662f\u5747\u5300\u5730\u5728\u56fe\u7247\u4e0a\u4e0d\u540c\u4f4d\u7f6e\u8fdb\u884c\u5bc6\u96c6\u91c7\u6837\uff0c\u91c7\u6837\u65f6\u4f7f\u7528\u4e0d\u540c\u5c3a\u5ea6\u548c\u957f\u5bbd\u6bd4box\uff0c\u7136\u540e\u5229\u7528CNN\u63d0\u53d6\u7279\u5f81\u540e\u76f4\u63a5\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u6574\u4e2a\u8fc7\u7a0b\u53ea\u9700\u8981\u4e00\u6b65\uff0c\u6240\u4ee5\u4f18\u52bf\u5728\u4e8e\u901f\u5ea6\u5feb\u3002\u6211\u4eec\u63a5\u4e0b\u6765\u4ecb\u7ecd\u7684SSD\u65b9\u6cd5\u4e5f\u662f\u5355\u9636\u6bb5\u7684\u7b97\u6cd5\u3002 SSD\u7b97\u6cd5\u7684\u5168\u540d\u662fSingle Shot MultiBox Detector\uff0cSingle shot\u6307\u660e\u4e86SSD\u7b97\u6cd5\u5c5e\u4e8eone-stage\u65b9\u6cd5\uff0cMultiBox\u6307\u660e\u4e86SSD\u662f\u591a\u6846\u9884\u6d4b\u3002\u5bf9\u4e8eFaster R-CNN\uff0c\u5148\u901a\u8fc7CNN\u5f97\u5230\u5019\u9009\u6846\uff0c\u7136\u540e\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u800cYOLO\u548cSSD\u53ef\u4ee5\u4e00\u6b65\u5b8c\u6210\u68c0\u6d4b\uff0cSSD\u7684\u7279\u70b9\u662f\uff1a SSD\u63d0\u53d6\u4e86\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u6765\u505a\u68c0\u6d4b\uff0c\u5927\u5c3a\u5ea6\u7279\u5f81\u56fe\u53ef\u4ee5\u7528\u6765\u68c0\u6d4b\u5c0f\u7269\u4f53\uff0c\u800c\u5c0f\u7279\u5f81\u56fe\u7528\u6765\u68c0\u6d4b\u5927\u7269\u4f53\uff1b SSD\u91c7\u7528\u4e86\u4e0d\u540c\u5c3a\u5ea6\u548c\u957f\u5bbd\u6bd4\u7684\u5148\u9a8c\u6846\uff0c\u5728faster r-cnn\u548cyoloV2,V3\u4e2d\u79f0\u4e3aAnchors\u3002 1\u3001 SSD\u7f51\u7edc\u7ed3\u6784 \u00b6 SSD\u662fYOLO V1\u51fa\u6765\u540e\uff0cYOLO V2\u51fa\u6765\u524d\u7684\u4e00\u6b3eOne-stage\u76ee\u6807\u68c0\u6d4b\u5668\u3002SSD\u7528\u5230\u4e86\u591a\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\uff0c\u5728\u4e4b\u540e\u7684YOLO V3\u7684darknet53\u4e2d\uff0c\u4e5f\u662f\u7528\u5230\u4e86\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u7684\u601d\u60f3\u3002\u8f83\u6d45\u5c42\u7684\u7279\u5f81\u56fe\u4e0a\uff0c\u6bcf\u4e2acell\u7684\u611f\u53d7\u91ce\u4e0d\u662f\u5f88\u5927\uff0c\u6240\u4ee5\u9002\u5408\u68c0\u6d4b\u8f83\u5c0f\u7684\u7269\u4f53\uff0c\u800c\u5728\u8f83\u6df1\u7684\u7279\u5f81\u56fe\u4e0a\uff0c\u6bcf\u4e2acell\u7684\u611f\u53d7\u91ce\u5c31\u6bd4\u8f83\u5927\u4e86\uff0c\u9002\u5408\u68c0\u6d4b\u8f83\u5927\u7684\u7269\u4f53\u3002 SSD\u91c7\u7528VGG16\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u7136\u540e\u5728VGG16\u7684\u57fa\u7840\u4e0a\u65b0\u589e\u4e86\u5377\u79ef\u5c42\u6765\u83b7\u5f97\u66f4\u591a\u7684\u7279\u5f81\u56fe\u4ee5\u7528\u4e8e\u68c0\u6d4b\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6574\u4e2a\u7279\u5f81\u56fe\u5206\u4e3a\u4e09\u90e8\u5206\uff1a backbone: VGGnet\u7528\u4e8e\u56fe\u7247\u7279\u5f81\u63d0\u53d6\u7684\u7f51\u7edc Extra: \u7528\u4e8e\u5f15\u51fa\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u7684\u7f51\u7edc Loc\u548ccls: \u7528\u4e8e\u6846\u4f4d\u7f6e\u56de\u5f52\u548c\u76ee\u6807\u5206\u7c7b\u7684\u7f51\u7edc 1.1 backbone \u00b6 \u7f51\u7edc\u91c7\u7528VGG16\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u4f7f\u7528imagenet\u6570\u636e\u8fdb\u884c\u9884\u8bad\u7ec3\u540e\uff0c\u5c06conv4-1\u524d\u4e00\u5c42\u7684maxpooling\u4e2d\u6c60\u5316\u6a21\u5f0fpadding\u6539\u4e3asame(\u56fe\u4e2d\u5bf9\u5e94pytorch\u4e2d\u7684ceil_mode),\u4f7f\u5f97\u8f93\u51fa\u4e3a38x38\uff0cConv4-3\u5c31\u662f\u591a\u5c3a\u5ea6\u7279\u5f81\u4e2d\u7684\u7b2c\u4e00\u4e2a38x38\u7684\u7279\u5f81\u56fe\uff0c\u56e0\u4e3a\u8be5\u5c42\u6bd4\u8f83\u9760\u524d\uff0c\u6240\u4ee5\u5728\u5176\u540e\u9762\u589e\u52a0\u4e86\u4e00\u4e2aL2 Normalization\u5c42\uff0c\u5bf9\u6bcf\u4e2a\u50cf\u7d20\u70b9\u5728channle\u7ef4\u5ea6\u505a\u5f52\u4e00\u5316\u3002VGG16\u6700\u540e\u7684\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42\u8f6c\u6362\u6210 3x3 \u5377\u79ef\u5c42 conv6\u548c \u5377\u79ef\u5c42conv7\uff0c\u540c\u65f6\u5c06\u6700\u540e\u7684\u6c60\u5316\u5c42\u7531\u539f\u6765\u7684stride=2\u7684 2x2 \u53d8\u6210stride=1\u7684 3x3\u7684\u6c60\u5316\u5c42\u3002 \u5176\u4e2dconv6\u4f7f\u7528\u7684Dilated Convolutions\uff0c\u53ef\u4ee5\u7ffb\u8bd1\u4e3a\u6269\u5f20\u5377\u79ef\u6216\u7a7a\u6d1e\u5377\u79ef\u3002\u4e0e\u666e\u901a\u7684\u5377\u79ef\u76f8\u6bd4\uff0c\u589e\u52a0\u4e86\u4e00\u4e2a\u6269\u5f20\u7387(dilation rate)\u53c2\u6570\uff0c\u4e3b\u8981\u7528\u6765\u8868\u793a\u6269\u5f20\u7684\u5927\u5c0f\u3002\u6269\u5f20\u5377\u79ef\u4e0e\u666e\u901a\u5377\u79ef\u7684\u76f8\u540c\u70b9\u5728\u4e8e\uff0c\u5377\u79ef\u6838\u7684\u5927\u5c0f\u662f\u4e00\u6837\u7684\uff0c\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u53c2\u6570\u6570\u91cf\u4e0d\u53d8\uff0c\u533a\u522b\u5728\u4e8e\u6269\u5f20\u5377\u79ef\u5177\u6709\u66f4\u5927\u7684\u611f\u53d7\u91ce\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a (a) \u666e\u901a\u5377\u79ef\uff0c1-dilated convolution\uff0c\u5377\u79ef\u6838\u7684\u611f\u53d7\u91ce\u4e3a 3 \\times 3 = 9 3 \\times 3 = 9 \u3002 (b) \u6269\u5f20\u5377\u79ef\uff0c2-dilated convolution\uff0c\u5377\u79ef\u6838\u7684\u611f\u53d7\u91ce\u4e3a 7 \\times 7 = 49 7 \\times 7 = 49 \u3002 \u00a9 \u6269\u5f20\u5377\u79ef\uff0c4-dilated convolution\uff0c\u5377\u79ef\u6838\u7684\u611f\u53d7\u91ce\u4e3a 15 \\times 15 = 225 15 \\times 15 = 225 \u3002 \u6269\u5f20\u5377\u79ef\u7684\u611f\u53d7\u91ce\u7684\u8ba1\u7b97\u65b9\u6cd5\u662f\uff1a \u5728tensorflow\u4e2d\u5b9e\u73b0\u4f7f\u7528\u7684\u662f\uff1a(\u4e0e\u666e\u901a\u5377\u79ef\u4e0d\u540c\u7684\u662f\u6307\u5b9adilation_rate\u5373\u53ef) layers.Conv2D(1024, 3, padding='same',dilation_rate=6, activation='relu'), \u4ece\u4e0a\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u5377\u79ef\u6838\u7684\u53c2\u6570\u4e2a\u6570\u4fdd\u6301\u4e0d\u53d8\uff0c\u611f\u53d7\u91ce\u7684\u5927\u5c0f\u968f\u7740\u201cdilation rate\u201d\u53c2\u6570\u7684\u589e\u52a0\u5448\u6307\u6570\u589e\u957f\u3002 1.2 extra\u90e8\u5206 \u00b6 \u4e3a\u4e86\u8fdb\u884c\u540e\u7eed\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u63d0\u53d6\uff0c\u5728Backbone\u540e\u9762\u6dfb\u52a0\u4e86\u5377\u79ef\u7f51\u7edc\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u65b0\u589e\u7684Conv8_2\uff0cConv9_2\uff0cConv10_2\uff0cConv11_2\u63d0\u53d6\u7528\u4e8e\u68c0\u6d4b\u7684\u7279\u5f81\u56fe\uff0c\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u5982\u4e0b\u8868\u6240\u793a\uff1a \u7ea2\u6846\u4e2d\u7684\u5185\u5bb9\u662f\u8fdb\u884c\u591a\u5c3a\u5ea6\u5206\u6790\u7684\u7279\u5f81\u56fe\uff0c\u5728\u52a0\u4e0abackbone\u90e8\u5206\u7684Conv4_3\u548cConv7\u83b7\u53d6\u7684\u7279\u5f81\u56fe\uff0c\u5171\u63d0\u53d6\u4e866\u4e2a\u7279\u5f81\u56fe\uff0c\u5176\u5927\u5c0f\u5206\u522b\u662f (38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)\uff0c\u6211\u4eec\u5c06\u5176\u9001\u5165\u5230loc\u548ccls\u4e2d\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u3002 1.3 loc\u548ccls \u00b6 \u5728backbone\u548c Extras \u5728\u63d0\u53d6\u76846\u4e2a\u7279\u5f81\u56fe\u7684\u57fa\u7840\u4e0a\uff0c\u8fdb\u884c\u4f4d\u7f6e\u4fe1\u606f\u548c\u5206\u7c7b\u4fe1\u606f\u7684\u63d0\u53d6\uff0c\u5176\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8be5\u90e8\u5206\u4e3b\u8981\u67093\u4e2a\u652f\u8def\u6784\u6210\uff0c PriorBox\u5c42\uff0c\u7528\u6765\u751f\u6210\u5148\u9a8c\u6846\uff0c\u4e5f\u5c31\u662f\u5728fasterRCNN\u4e2d\u7684anchorbox\uff0c\u5047\u8bbe\u5148\u9a8c\u6846\u79cd\u7c7b\u67093\u4e2a\uff08\u4e00\u4e2a\u5355\u5143\u4e0a\u67093\u4e2a\u5148\u9a8c\u6846\uff09\uff0c\u4e00\u5171\u4ea7\u751f5x5x3=75\u4e2a\u5148\u9a8c\u6846 Localization: \u91c7\u7528\u4e00\u6b21 3\\times3 3\\times3 \u5377\u79ef\u6765\u8fdb\u884c\u5b8c\u6210\uff0c\u6bcf\u4e2a\u5148\u9a8c\u6846\u6709\u56db\u4e2a\u5750\u6807\uff0c\u5171\u67095x5x3x4\u4e2a\u9884\u6d4b\u7ed3\u679c \u7c7b\u522b\u7f6e\u4fe1\u5ea6confdence\uff1a\u91c7\u7528\u4e00\u6b21 3\\times3 3\\times3 \u5377\u79ef\u6765\u8fdb\u884c\u5b8c\u6210\uff0c\u6bcf\u4e2a\u5148\u9a8c\u6846\u670921\u4e2a\u7c7b\u522b\u9884\u6d4b\u7ed3\u679c\uff08VOC\u6570\u636e\u96c6\uff09\uff0c\u5171\u67095x5x3x21\u4e2a\u9884\u6d4b\u7ed3\u679c \u6574\u4e2a\u8fc7\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a 1.3.1 PriorBox\u5c42\u5148\u9a8c\u6846\u7684\u751f\u6210\u65b9\u6cd5 \u00b6 \u5728\u8fd9\u91cc\u6211\u4eec\u7740\u91cd\u4ecb\u7ecdPriorBox\u5c42\u5148\u9a8c\u6846\u7684\u751f\u6210\u65b9\u6cd5\uff1a SSD\u4e00\u5171\u67096\u4e2a\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\uff0c\u6bcf\u4e2a\u7279\u5f81\u56fe\u4e0a\u8bbe\u7f6e\u7684\u5148\u9a8c\u6846\u6570\u91cf\u4e0d\u540c\u7684\uff08\u540c\u4e00\u4e2a\u7279\u5f81\u56fe\u4e0a\u6bcf\u4e2a\u5355\u5143\u8bbe\u7f6e\u7684\u5148\u9a8c\u6846\u662f\u76f8\u540c\u7684\uff0c\u8fd9\u91cc\u7684\u6570\u76ee\u6307\u7684\u662f\u4e00\u4e2a\u5355\u5143\u7684\u5148\u9a8c\u6846\u6570\u76ee\uff09\u3002 \u5148\u9a8c\u6846\u7684\u8bbe\u7f6e\uff1a\u5305\u62ec\u5c3a\u5ea6\uff08\u6216\u8005\u8bf4\u5927\u5c0f\uff09\u548c\u957f\u5bbd\u6bd4\u4e24\u4e2a\u65b9\u9762\u3002 \u5148\u9a8c\u6846\u7684\u5c3a\u5ea6 \u5148\u9a8c\u6846\u7684\u5c3a\u5ea6\u9075\u5b88\u4e00\u4e2a\u7ebf\u6027\u9012\u589e\u89c4\u5219\uff1a\u968f\u7740\u7279\u5f81\u56fe\u5927\u5c0f\u964d\u4f4e\uff0c\u5148\u9a8c\u6846\u5c3a\u5ea6\u7ebf\u6027\u589e\u52a0\uff0c\u6bcf\u4e2a\u5148\u9a8c\u6846\u7684\u5c3a\u5ea6\u6709\u4e0b\u5f0f\u51b3\u5b9a\uff1a s_k = s_{min} + \\frac{s_{max} - s_{min}}{m-1}(k-1), k\\in[1,m] s_k = s_{min} + \\frac{s_{max} - s_{min}}{m-1}(k-1), k\\in[1,m] \u5176\u4e2d\uff1a m m \u6307\u7684\u7279\u5f81\u56fe\u4e2a\u6570\uff0c\u8fd9\u91cc\u8bbe\u4e3a5 \uff0c\u56e0\u4e3a\u7b2c\u4e00\u5c42\uff08Conv4_3\u5c42\uff09\u662f\u5355\u72ec\u8bbe\u7f6e\u7684\u3002 s_k s_k \u8868\u793a\u5148\u9a8c\u6846\u5927\u5c0f\u76f8\u5bf9\u4e8e\u56fe\u7247\u7684\u6bd4\u4f8b\uff0c\u800c s_{min} s_{min} \u548c s_{max} s_{max} \u8868\u793a\u6bd4\u4f8b\u7684\u6700\u5c0f\u503c\u4e0e\u6700\u5927\u503c\uff0c\u53d6\u503c\u4e3a0.2\u548c0.9\u3002 1\u3001\u5bf9\u4e8e\u7b2c\u4e00\u4e2a\u7279\u5f81\u56fe\uff0c\u5176\u5148\u9a8c\u6846\u7684\u5c3a\u5ea6\u6bd4\u4f8b\u4e00\u822c\u8bbe\u7f6e\u4e3a s_{min}/2=0.1 s_{min}/2=0.1 \uff0c\u5c3a\u5ea6\u4e3a 300\\times 0.1=30 300\\times 0.1=30 \u3002 2\u3001\u5bf9\u4e8e\u540e\u9762\u7684\u7279\u5f81\u56fe\uff0c\u5148\u9a8c\u6846\u5c3a\u5ea6\u6309\u7167 s_k s_k \u7ebf\u6027\u589e\u52a0\uff0c\u589e\u957f\u6b65\u957f\u4e3a: \\lfloor\\frac{\\lfloor s_{max}\\rfloor - \\lfloor s_{min}\\rfloor}{m-1}\\rfloor=0.17 \\lfloor\\frac{\\lfloor s_{max}\\rfloor - \\lfloor s_{min}\\rfloor}{m-1}\\rfloor=0.17 3\u3001\u6839\u636e\u4e0a\u5f0f\uff0c\u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u51fa\u5404\u4e2a\u5c3a\u5ea6 s_k s_k \u7684\u53d6\u503c\u4e3a0.20, 0.37,0. 54, 0.71, 0.88 4\u3001\u7136\u540e\u518d\u4e58\u4ee5\u539f\u56fe\u7684\u5927\u5c0f300\uff0c\u518d\u7efc\u5408\u7b2c\u4e00\u4e2a\u7279\u5f81\u56fe\u7684\u5148\u9a8c\u6846\u5c3a\u5bf8\uff0c\u5219\u53ef\u5f97\u5404\u4e2a\u7279\u5f81\u56fe\u7684\u5148\u9a8c\u6846\u5c3a\u5bf8\u4e3a30,60,111, 162,213,264\u3002 \u5148\u9a8c\u6846\u7684\u957f\u5bbd\u6bd4 \u4e00\u822c\u9009\u53d6 a_r\\in {1,2,3,\\frac{1}{2},\\frac{1}{3}} a_r\\in {1,2,3,\\frac{1}{2},\\frac{1}{3}} \uff0c\u5bf9\u4e8e\u7279\u5b9a\u7684\u957f\u5bbd\u6bd4\uff0c\u6309\u5982\u4e0b\u516c\u5f0f\u8ba1\u7b97\u5148\u9a8c\u6846\u7684\u5bbd\u5ea6\u4e0e\u9ad8\u5ea6\uff08\u540e\u9762\u7684 s_k s_k \u5747\u6307\u7684\u662f\u5148\u9a8c\u6846\u5b9e\u9645\u5c3a\u5ea6\uff0c\u800c\u4e0d\u662f\u5c3a\u5ea6\u6bd4\u4f8b\uff09: w^a_{k}=s_k\\sqrt{a_r},\\space h^a_{k}=s_k/\\sqrt{a_r} w^a_{k}=s_k\\sqrt{a_r},\\space h^a_{k}=s_k/\\sqrt{a_r} \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u6bcf\u4e2a\u7279\u5f81\u56fe\u4f1a\u6709\u4e00\u4e2a a_r=1 a_r=1 \u4e14\u5c3a\u5ea6\u4e3a s_k s_k \u7684\u5148\u9a8c\u6846\uff0c\u9664\u6b64\u4e4b\u5916\uff0c\u8fd8\u4f1a\u8bbe\u7f6e\u4e00\u4e2a\u5c3a\u5ea6\u4e3a s'_{k}=\\sqrt{s_k s_{k+1}} s'_{k}=\\sqrt{s_k s_{k+1}} \u4e14 a_r=1 a_r=1 \u7684\u5148\u9a8c\u6846\uff0c\u8fd9\u6837\u6bcf\u4e2a\u7279\u5f81\u56fe\u90fd\u8bbe\u7f6e\u4e86\u4e24\u4e2a\u957f\u5bbd\u6bd4\u4e3a1\u4f46\u5927\u5c0f\u4e0d\u540c\u7684\u6b63\u65b9\u5f62\u5148\u9a8c\u6846\u3002 \u56e0\u6b64\uff0c\u6bcf\u4e2a\u7279\u5f81\u56fe\u4e00\u5171\u6709 6 \u4e2a\u5148\u9a8c\u6846 {1,2,3,\\frac{1}{2},\\frac{1}{3},1'} {1,2,3,\\frac{1}{2},\\frac{1}{3},1'} \uff0c\u4f46\u662f\u5728\u5b9e\u73b0\u65f6\uff0cConv4_3\uff0cConv10_2\u548cConv11_2\u5c42\u4ec5\u4f7f\u75284\u4e2a\u5148\u9a8c\u6846\uff0c\u5b83\u4eec\u4e0d\u4f7f\u7528\u957f\u5bbd\u6bd4\u4e3a 3,\\frac{1}{3} 3,\\frac{1}{3} \u7684\u5148\u9a8c\u6846\u3002 \u4ee4 n_k n_k \u4e3a\u8be5\u7279\u5f81\u56fe\u6240\u91c7\u7528\u7684\u5148\u9a8c\u6846\u6570\u76ee\uff0c\u90a3\u4e48\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u9700\u8981\u7684\u5377\u79ef\u6838\u6570\u91cf\u4e3a n_k n_k \uff0c\u800c\u8fb9\u754c\u6846\u4f4d\u7f6e\u9700\u8981\u7684\u5377\u79ef\u6838\u6570\u91cf\u4e3a n_k\\times 4 n_k\\times 4 \u3002\u7531\u4e8e\u6bcf\u4e2a\u5148\u9a8c\u6846\u90fd\u4f1a\u9884\u6d4b\u4e00\u4e2a\u8fb9\u754c\u6846\uff0c \u6240\u4ee5SSD\u4e00\u5171\u53ef\u4ee5\u9884\u6d4b 38\\times38\\times4+19\\times19\\times6+10\\times10\\times6+5\\times5\\times6+3\\times3\\times4+1\\times1\\times4=8732 38\\times38\\times4+19\\times19\\times6+10\\times10\\times6+5\\times5\\times6+3\\times3\\times4+1\\times1\\times4=8732 \u4e2a\u8fb9\u754c\u6846\uff0c\u5bf9\u4e8e\u4e00\u4e2a300x300\u7684\u56fe\u50cf\u5c31\u67098732\u4e2a\u9884\u6d4b\u7ed3\u679c\uff0c\u662f\u975e\u5e38\u7684\u591a\u7684\uff0c\u6240\u4ee5\u8bf4SSD\u672c\u8d28\u4e0a\u662f\u5bc6\u96c6\u91c7\u6837\u3002 1.3.2 loc\u7684\u9884\u6d4b\u7ed3\u679c \u00b6 \u7f51\u7edc\u9884\u6d4b\u8f93\u51fa\u7684\u8fb9\u754c\u6846\u4e0e\u771f\u5b9e\u7684\u8fb9\u754c\u6846\u4e4b\u95f4\u5b58\u5728\u8f6c\u6362\u5173\u7cfb\uff0c\u5177\u4f53\u5982\u4e0b\uff1a \u5148\u9a8c\u6846\u4f4d\u7f6e\uff1a l= (l^{cx}, l^{cy}, l^{w}, l^{h}) l= (l^{cx}, l^{cy}, l^{w}, l^{h}) \u771f\u5b9e\u6846\u7684\u4f4d\u7f6e\uff1a p = (p^{cx}, p^{cy}, p^{w}, p^{h}) p = (p^{cx}, p^{cy}, p^{w}, p^{h}) \u90a3\u4e48\u7f51\u7edc\u8f93\u51fa\u7ed3\u679c d d \u4e0e\u8fb9\u754c\u6846\u7684\u4f4d\u7f6e\u5b58\u5728\u5173\u7cfb\uff1a p^{cx} =l^{w}d^{cx} +l^{cx}, p^{cy} = l^{y}d^{cy} +l^{cy} p^{cx} =l^{w}d^{cx} +l^{cx}, p^{cy} = l^{y}d^{cy} +l^{cy} p^{w} = l^{w}exp(d^{w}), p^{h} = l^{h}exp(d^{h}) p^{w} = l^{w}exp(d^{w}), p^{h} = l^{h}exp(d^{h}) 2.\u6a21\u578b\u8bad\u7ec3 \u00b6 2.1 \u6b63\u8d1f\u6837\u672c\u6807\u8bb0 \u00b6 \u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u9996\u5148\u9700\u8981\u786e\u5b9a\u8bad\u7ec3\u56fe\u7247\u4e2d\u7684 ground truth \u4e0e\u54ea\u4e00\u4e2a\u5148\u9a8c\u6846\u6765\u8fdb\u884c\u5339\u914d\uff0c\u4e0e\u4e4b\u5339\u914d\u7684\u5148\u9a8c\u6846\u6240\u5bf9\u5e94\u7684\u8fb9\u754c\u6846\u5c06\u8d1f\u8d23\u9884\u6d4b\u5b83\u3002 SSD\u7684\u5148\u9a8c\u6846\u548cground truth\u5339\u914d\u539f\u5219\uff1a \u6b63\u6837\u672c 1\u3001\u5bf9\u4e8e\u56fe\u7247\u4e2d\u7684\u6bcf\u4e2agt\uff0c\u627e\u5230\u4e0e\u5176IOU\u6700\u5927\u7684\u5148\u9a8c\u6846\uff0c\u8be5\u5148\u9a8c\u6846\u4e0e\u5176\u5339\u914d\uff0c\u8fd9\u6837\u53ef\u4ee5\u4fdd\u8bc1\u6bcf\u4e2agt\u4e00\u5b9a\u4e0e\u67d0\u4e2a\u5148\u9a8c\u6846\u5339\u914d\u3002 2\u3001\u5bf9\u4e8e\u5269\u4f59\u672a\u5339\u914d\u7684\u5148\u9a8c\u6846\uff0c\u82e5\u67d0\u4e2agt\u7684IOU\u5927\u4e8e\u67d0\u4e2a\u9608\u503c(\u4e00\u822c0.5)\uff0c\u90a3\u4e48\u8be5\u5148\u9a8c\u6846\u4e0e\u8fd9\u4e2agt\u5339\u914d \u8d1f\u6837\u672c \u5176\u5b83\u7684\u5148\u9a8c\u6846\u6807\u8bb0\u4e3a\u8d1f\u6837\u672c \u6ce8\u610f\uff1a 1\u3001\u67d0\u4e2agt\u53ef\u4ee5\u548c\u591a\u4e2a\u5148\u9a8c\u6846\u5339\u914d\uff0c\u800c\u6bcf\u4e2a\u5148\u9a8c\u6846\u53ea\u80fd\u548c\u4e00\u4e2agt\u8fdb\u884c\u5339\u914d 2\u3001\u5982\u679c\u591a\u4e2agt\u548c\u67d0\u4e00\u4e2a\u5148\u9a8c\u6846\u7684IOU\u5747\u5927\u4e8e\u9608\u503c\uff0c\u90a3\u4e48\u5148\u9a8c\u6846\u53ea\u4e0eIOU\u6700\u5927\u7684\u90a3\u4e2a\u8fdb\u884c\u5339\u914d 2.2 \u635f\u5931\u51fd\u6570 \u00b6 SSD\u7684\u635f\u5931\u51fd\u6570\u662f\u4f4d\u7f6e\u635f\u5931\uff08 loc\uff09\u4e0e\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u635f\u5931\uff08conf\uff09\u7684\u52a0\u6743\u548c\uff1a L(x, c, l, g) = \\frac{1}{N}(L_{conf}(x,c) + \\alpha L_{loc}(x,l,g)) L(x, c, l, g) = \\frac{1}{N}(L_{conf}(x,c) + \\alpha L_{loc}(x,l,g)) \u5176\u4e2d N N \u662f\u5148\u9a8c\u6846\u7684\u6b63\u6837\u672c\u6570\u91cf\uff0c c c \u4e3a\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u503c\uff0c l l \u4e3a\u5148\u9a8c\u6846\u7684\u6240\u5bf9\u5e94\u8fb9\u754c\u6846\u7684\u4f4d\u7f6e\u9884\u6d4b\u503c\uff0c\u800c g g \u662fground truth\u7684\u4f4d\u7f6e\u53c2\u6570\uff0c\u6743\u91cd\u7cfb\u6570 \\alpha \\alpha \u8bbe\u7f6e\u4e3a1\u3002 \u4f4d\u7f6e\u635f\u5931\u51fd\u6570\uff1a \u9488\u5bf9\u6240\u6709\u7684\u6b63\u6837\u672c\uff0c\u91c7\u7528 Smooth L1 Loss\u635f\u5931 \u5206\u7c7b\u635f\u5931\u51fd\u6570 \u5bf9\u4e8e\u5206\u7c7b\u635f\u5931\uff0c\u4e0efasterRCNN\u4e00\u6837\u91c7\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u3002 2.3 \u56f0\u96be\u6837\u672c\u6316\u6398 \u00b6 \u56f0\u96be\u6837\u672c\u6316\u6398\u7684\u601d\u60f3\u662f\u4f7f\u7528\u7f51\u7edc\u5bf9\u6837\u672c\u8fdb\u884c\u5904\u7406\uff0c\u628a\u5176\u4e2d\u9884\u6d4b\u9519\u8bef\u7684\u8d1f\u6837\u672c(hard negative)\u653e\u5165\u8d1f\u6837\u672c\u96c6\u5408\u518d\u7ee7\u7eed\u8bad\u7ec3\u7f51\u7edc\u6a21\u578b\u3002 \u5728SSD\u4e2d\u5904\u7406\u65b9\u5f0f\u662f\uff1a \u4f7f\u75281\uff1a3\u7684\u6b63\u8d1f\u6837\u672c\u6bd4\u4f8b\u8bad\u7ec3\u7f51\u7edc\uff0c \u5bf9\u8f93\u5165\u7684\u9884\u6d4b\u7ed3\u679c\u6309\u7167\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u8fdb\u884c\u964d\u5e8f\u6392\u5e8f\uff0c\u53d6\u51fa\u524dk\u4e2a\u8d1f\u6837\u672c \u5c06\u8fd9k\u4e2a\u8d1f\u6837\u672c\u52a0\u5165\u4e0b\u6b21\u8fed\u4ee3\u7684\u8d1f\u6837\u672c\u4e2d\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u3002 3.\u6a21\u578b\u9884\u6d4b \u00b6 \u9884\u6d4b\u8fc7\u7a0b\u6bd4\u8f83\u7b80\u5355\uff0c \u4e3b\u8981\u6b65\u9aa4\u5982\u4e0b\uff1a \u5bf9\u4e8e\u6bcf\u4e2a\u9884\u6d4b\u6846\uff0c\u9996\u5148\u6839\u636e\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u786e\u5b9a\u5176\u7c7b\u522b\uff08\u7f6e\u4fe1\u5ea6\u6700\u5927\u8005\uff09\u4e0e\u7f6e\u4fe1\u5ea6\u503c\uff0c\u5e76\u8fc7\u6ee4\u6389\u5c5e\u4e8e\u80cc\u666f\u7684\u9884\u6d4b\u6846\u3002 \u7136\u540e\u6839\u636e\u7f6e\u4fe1\u5ea6\u9608\u503c\uff08\u59820.5\uff09\u8fc7\u6ee4\u6389\u9608\u503c\u8f83\u4f4e\u7684\u9884\u6d4b\u6846\u3002 \u5bf9\u4e8e\u7559\u4e0b\u7684\u9884\u6d4b\u6846\u8fdb\u884c\u89e3\u7801\uff0c\u6839\u636e\u5148\u9a8c\u6846\u5f97\u5230\u5176\u771f\u5b9e\u7684\u4f4d\u7f6e\u53c2\u6570\uff08\u89e3\u7801\u540e\u4e00\u822c\u8fd8\u9700\u8981\u505aclip\uff0c\u9632\u6b62\u9884\u6d4b\u6846\u4f4d\u7f6e\u8d85\u51fa\u56fe\u7247\uff09\u3002 \u89e3\u7801\u4e4b\u540e\uff0c\u4e00\u822c\u9700\u8981\u6839\u636e\u7f6e\u4fe1\u5ea6\u8fdb\u884c\u964d\u5e8f\u6392\u5217\uff0c\u7136\u540e\u4ec5\u4fdd\u7559top-k\uff08\u5982400\uff09\u4e2a\u9884\u6d4b\u6846\u3002 \u8fdb\u884cNMS\u7b97\u6cd5\uff0c\u8fc7\u6ee4\u6389\u90a3\u4e9b\u91cd\u53e0\u5ea6\u8f83\u5927\u7684\u9884\u6d4b\u6846\u3002 \u6700\u540e\u5269\u4f59\u7684\u9884\u6d4b\u6846\u5c31\u662f\u68c0\u6d4b\u7ed3\u679c\u4e86\u3002 \u603b\u7ed3 \u77e5\u9053SSD\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u7684\u7f51\u7edc SSD\u63d0\u53d6\u4e866\u4e2a\u4e0d\u540c\u7279\u5f81\u56fe\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b \u77e5\u9053SSD\u4e2d\u5148\u9a8c\u6846\u7684\u751f\u6210\u65b9\u5f0f SSD\u5728\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u4e0a\u751f\u6210\u7684\u5148\u9a8c\u6846\u7684\u5c3a\u5ea6\u548c\u957f\u5bbd\u6bd4\u662f\u4e0d\u4e00\u6837\u7684 \u77e5\u9053SSD\u7684\u635f\u5931\u51fd\u6570\u7684\u8bbe\u8ba1 \u5206\u7c7b\u548c\u56de\u5f52\u635f\u5931\u51fd\u6570\u7684\u52a0\u6743\u548c","title":"4.6 SSD\u7b97\u6cd5"},{"location":"objectdection/06.ssd/#46-ssd","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053SSD\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u7684\u7f51\u7edc \u77e5\u9053SSD\u4e2d\u5148\u9a8c\u6846\u7684\u751f\u6210\u65b9\u5f0f \u77e5\u9053SSD\u7684\u635f\u5931\u51fd\u6570\u7684\u8bbe\u8ba1 \u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e3b\u8981\u5206\u4e3a\u4e24\u7c7b\uff1a Two-stage\u65b9\u6cd5\uff1a\u5982R-CNN\u7cfb\u5217\u7b97\u6cd5\uff0c\u4e3b\u8981\u601d\u8def\u5c31\u662f\u901a\u8fc7Selective Search\u6216\u8005CNN\u7f51\u7edc\u4ea7\u751f\u4e00\u7cfb\u5217\u7684\u7a00\u758f\u77e9\u9635\u7684\u5019\u9009\u533a\u57df\uff0c\u7136\u540e\u5bf9\u8fd9\u4e9b\u5019\u9009\u533a\u57df\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0ctwo-stage\u7684\u65b9\u6cd5\u4f18\u52bf\u5728\u4e8e\u51c6\u786e\u7387\u5ea6\u9ad8\uff1b One-stage\u65b9\u6cd5\uff1a\u5982YOLO\u7cfb\u5217\u65b9\u6cd5\uff0c\u4e3b\u8981\u601d\u8def\u5c31\u662f\u5747\u5300\u5730\u5728\u56fe\u7247\u4e0a\u4e0d\u540c\u4f4d\u7f6e\u8fdb\u884c\u5bc6\u96c6\u91c7\u6837\uff0c\u91c7\u6837\u65f6\u4f7f\u7528\u4e0d\u540c\u5c3a\u5ea6\u548c\u957f\u5bbd\u6bd4box\uff0c\u7136\u540e\u5229\u7528CNN\u63d0\u53d6\u7279\u5f81\u540e\u76f4\u63a5\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u6574\u4e2a\u8fc7\u7a0b\u53ea\u9700\u8981\u4e00\u6b65\uff0c\u6240\u4ee5\u4f18\u52bf\u5728\u4e8e\u901f\u5ea6\u5feb\u3002\u6211\u4eec\u63a5\u4e0b\u6765\u4ecb\u7ecd\u7684SSD\u65b9\u6cd5\u4e5f\u662f\u5355\u9636\u6bb5\u7684\u7b97\u6cd5\u3002 SSD\u7b97\u6cd5\u7684\u5168\u540d\u662fSingle Shot MultiBox Detector\uff0cSingle shot\u6307\u660e\u4e86SSD\u7b97\u6cd5\u5c5e\u4e8eone-stage\u65b9\u6cd5\uff0cMultiBox\u6307\u660e\u4e86SSD\u662f\u591a\u6846\u9884\u6d4b\u3002\u5bf9\u4e8eFaster R-CNN\uff0c\u5148\u901a\u8fc7CNN\u5f97\u5230\u5019\u9009\u6846\uff0c\u7136\u540e\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u800cYOLO\u548cSSD\u53ef\u4ee5\u4e00\u6b65\u5b8c\u6210\u68c0\u6d4b\uff0cSSD\u7684\u7279\u70b9\u662f\uff1a SSD\u63d0\u53d6\u4e86\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u6765\u505a\u68c0\u6d4b\uff0c\u5927\u5c3a\u5ea6\u7279\u5f81\u56fe\u53ef\u4ee5\u7528\u6765\u68c0\u6d4b\u5c0f\u7269\u4f53\uff0c\u800c\u5c0f\u7279\u5f81\u56fe\u7528\u6765\u68c0\u6d4b\u5927\u7269\u4f53\uff1b SSD\u91c7\u7528\u4e86\u4e0d\u540c\u5c3a\u5ea6\u548c\u957f\u5bbd\u6bd4\u7684\u5148\u9a8c\u6846\uff0c\u5728faster r-cnn\u548cyoloV2,V3\u4e2d\u79f0\u4e3aAnchors\u3002","title":"4.6 SSD\u7b97\u6cd5"},{"location":"objectdection/06.ssd/#1-ssd","text":"SSD\u662fYOLO V1\u51fa\u6765\u540e\uff0cYOLO V2\u51fa\u6765\u524d\u7684\u4e00\u6b3eOne-stage\u76ee\u6807\u68c0\u6d4b\u5668\u3002SSD\u7528\u5230\u4e86\u591a\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\uff0c\u5728\u4e4b\u540e\u7684YOLO V3\u7684darknet53\u4e2d\uff0c\u4e5f\u662f\u7528\u5230\u4e86\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u7684\u601d\u60f3\u3002\u8f83\u6d45\u5c42\u7684\u7279\u5f81\u56fe\u4e0a\uff0c\u6bcf\u4e2acell\u7684\u611f\u53d7\u91ce\u4e0d\u662f\u5f88\u5927\uff0c\u6240\u4ee5\u9002\u5408\u68c0\u6d4b\u8f83\u5c0f\u7684\u7269\u4f53\uff0c\u800c\u5728\u8f83\u6df1\u7684\u7279\u5f81\u56fe\u4e0a\uff0c\u6bcf\u4e2acell\u7684\u611f\u53d7\u91ce\u5c31\u6bd4\u8f83\u5927\u4e86\uff0c\u9002\u5408\u68c0\u6d4b\u8f83\u5927\u7684\u7269\u4f53\u3002 SSD\u91c7\u7528VGG16\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u7136\u540e\u5728VGG16\u7684\u57fa\u7840\u4e0a\u65b0\u589e\u4e86\u5377\u79ef\u5c42\u6765\u83b7\u5f97\u66f4\u591a\u7684\u7279\u5f81\u56fe\u4ee5\u7528\u4e8e\u68c0\u6d4b\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6574\u4e2a\u7279\u5f81\u56fe\u5206\u4e3a\u4e09\u90e8\u5206\uff1a backbone: VGGnet\u7528\u4e8e\u56fe\u7247\u7279\u5f81\u63d0\u53d6\u7684\u7f51\u7edc Extra: \u7528\u4e8e\u5f15\u51fa\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u7684\u7f51\u7edc Loc\u548ccls: \u7528\u4e8e\u6846\u4f4d\u7f6e\u56de\u5f52\u548c\u76ee\u6807\u5206\u7c7b\u7684\u7f51\u7edc","title":"1\u3001 SSD\u7f51\u7edc\u7ed3\u6784"},{"location":"objectdection/06.ssd/#11-backbone","text":"\u7f51\u7edc\u91c7\u7528VGG16\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u4f7f\u7528imagenet\u6570\u636e\u8fdb\u884c\u9884\u8bad\u7ec3\u540e\uff0c\u5c06conv4-1\u524d\u4e00\u5c42\u7684maxpooling\u4e2d\u6c60\u5316\u6a21\u5f0fpadding\u6539\u4e3asame(\u56fe\u4e2d\u5bf9\u5e94pytorch\u4e2d\u7684ceil_mode),\u4f7f\u5f97\u8f93\u51fa\u4e3a38x38\uff0cConv4-3\u5c31\u662f\u591a\u5c3a\u5ea6\u7279\u5f81\u4e2d\u7684\u7b2c\u4e00\u4e2a38x38\u7684\u7279\u5f81\u56fe\uff0c\u56e0\u4e3a\u8be5\u5c42\u6bd4\u8f83\u9760\u524d\uff0c\u6240\u4ee5\u5728\u5176\u540e\u9762\u589e\u52a0\u4e86\u4e00\u4e2aL2 Normalization\u5c42\uff0c\u5bf9\u6bcf\u4e2a\u50cf\u7d20\u70b9\u5728channle\u7ef4\u5ea6\u505a\u5f52\u4e00\u5316\u3002VGG16\u6700\u540e\u7684\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42\u8f6c\u6362\u6210 3x3 \u5377\u79ef\u5c42 conv6\u548c \u5377\u79ef\u5c42conv7\uff0c\u540c\u65f6\u5c06\u6700\u540e\u7684\u6c60\u5316\u5c42\u7531\u539f\u6765\u7684stride=2\u7684 2x2 \u53d8\u6210stride=1\u7684 3x3\u7684\u6c60\u5316\u5c42\u3002 \u5176\u4e2dconv6\u4f7f\u7528\u7684Dilated Convolutions\uff0c\u53ef\u4ee5\u7ffb\u8bd1\u4e3a\u6269\u5f20\u5377\u79ef\u6216\u7a7a\u6d1e\u5377\u79ef\u3002\u4e0e\u666e\u901a\u7684\u5377\u79ef\u76f8\u6bd4\uff0c\u589e\u52a0\u4e86\u4e00\u4e2a\u6269\u5f20\u7387(dilation rate)\u53c2\u6570\uff0c\u4e3b\u8981\u7528\u6765\u8868\u793a\u6269\u5f20\u7684\u5927\u5c0f\u3002\u6269\u5f20\u5377\u79ef\u4e0e\u666e\u901a\u5377\u79ef\u7684\u76f8\u540c\u70b9\u5728\u4e8e\uff0c\u5377\u79ef\u6838\u7684\u5927\u5c0f\u662f\u4e00\u6837\u7684\uff0c\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u53c2\u6570\u6570\u91cf\u4e0d\u53d8\uff0c\u533a\u522b\u5728\u4e8e\u6269\u5f20\u5377\u79ef\u5177\u6709\u66f4\u5927\u7684\u611f\u53d7\u91ce\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a (a) \u666e\u901a\u5377\u79ef\uff0c1-dilated convolution\uff0c\u5377\u79ef\u6838\u7684\u611f\u53d7\u91ce\u4e3a 3 \\times 3 = 9 3 \\times 3 = 9 \u3002 (b) \u6269\u5f20\u5377\u79ef\uff0c2-dilated convolution\uff0c\u5377\u79ef\u6838\u7684\u611f\u53d7\u91ce\u4e3a 7 \\times 7 = 49 7 \\times 7 = 49 \u3002 \u00a9 \u6269\u5f20\u5377\u79ef\uff0c4-dilated convolution\uff0c\u5377\u79ef\u6838\u7684\u611f\u53d7\u91ce\u4e3a 15 \\times 15 = 225 15 \\times 15 = 225 \u3002 \u6269\u5f20\u5377\u79ef\u7684\u611f\u53d7\u91ce\u7684\u8ba1\u7b97\u65b9\u6cd5\u662f\uff1a \u5728tensorflow\u4e2d\u5b9e\u73b0\u4f7f\u7528\u7684\u662f\uff1a(\u4e0e\u666e\u901a\u5377\u79ef\u4e0d\u540c\u7684\u662f\u6307\u5b9adilation_rate\u5373\u53ef) layers.Conv2D(1024, 3, padding='same',dilation_rate=6, activation='relu'), \u4ece\u4e0a\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u5377\u79ef\u6838\u7684\u53c2\u6570\u4e2a\u6570\u4fdd\u6301\u4e0d\u53d8\uff0c\u611f\u53d7\u91ce\u7684\u5927\u5c0f\u968f\u7740\u201cdilation rate\u201d\u53c2\u6570\u7684\u589e\u52a0\u5448\u6307\u6570\u589e\u957f\u3002","title":"1.1 backbone"},{"location":"objectdection/06.ssd/#12-extra","text":"\u4e3a\u4e86\u8fdb\u884c\u540e\u7eed\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u63d0\u53d6\uff0c\u5728Backbone\u540e\u9762\u6dfb\u52a0\u4e86\u5377\u79ef\u7f51\u7edc\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u65b0\u589e\u7684Conv8_2\uff0cConv9_2\uff0cConv10_2\uff0cConv11_2\u63d0\u53d6\u7528\u4e8e\u68c0\u6d4b\u7684\u7279\u5f81\u56fe\uff0c\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u5982\u4e0b\u8868\u6240\u793a\uff1a \u7ea2\u6846\u4e2d\u7684\u5185\u5bb9\u662f\u8fdb\u884c\u591a\u5c3a\u5ea6\u5206\u6790\u7684\u7279\u5f81\u56fe\uff0c\u5728\u52a0\u4e0abackbone\u90e8\u5206\u7684Conv4_3\u548cConv7\u83b7\u53d6\u7684\u7279\u5f81\u56fe\uff0c\u5171\u63d0\u53d6\u4e866\u4e2a\u7279\u5f81\u56fe\uff0c\u5176\u5927\u5c0f\u5206\u522b\u662f (38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)\uff0c\u6211\u4eec\u5c06\u5176\u9001\u5165\u5230loc\u548ccls\u4e2d\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u3002","title":"1.2 extra\u90e8\u5206"},{"location":"objectdection/06.ssd/#13-loccls","text":"\u5728backbone\u548c Extras \u5728\u63d0\u53d6\u76846\u4e2a\u7279\u5f81\u56fe\u7684\u57fa\u7840\u4e0a\uff0c\u8fdb\u884c\u4f4d\u7f6e\u4fe1\u606f\u548c\u5206\u7c7b\u4fe1\u606f\u7684\u63d0\u53d6\uff0c\u5176\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8be5\u90e8\u5206\u4e3b\u8981\u67093\u4e2a\u652f\u8def\u6784\u6210\uff0c PriorBox\u5c42\uff0c\u7528\u6765\u751f\u6210\u5148\u9a8c\u6846\uff0c\u4e5f\u5c31\u662f\u5728fasterRCNN\u4e2d\u7684anchorbox\uff0c\u5047\u8bbe\u5148\u9a8c\u6846\u79cd\u7c7b\u67093\u4e2a\uff08\u4e00\u4e2a\u5355\u5143\u4e0a\u67093\u4e2a\u5148\u9a8c\u6846\uff09\uff0c\u4e00\u5171\u4ea7\u751f5x5x3=75\u4e2a\u5148\u9a8c\u6846 Localization: \u91c7\u7528\u4e00\u6b21 3\\times3 3\\times3 \u5377\u79ef\u6765\u8fdb\u884c\u5b8c\u6210\uff0c\u6bcf\u4e2a\u5148\u9a8c\u6846\u6709\u56db\u4e2a\u5750\u6807\uff0c\u5171\u67095x5x3x4\u4e2a\u9884\u6d4b\u7ed3\u679c \u7c7b\u522b\u7f6e\u4fe1\u5ea6confdence\uff1a\u91c7\u7528\u4e00\u6b21 3\\times3 3\\times3 \u5377\u79ef\u6765\u8fdb\u884c\u5b8c\u6210\uff0c\u6bcf\u4e2a\u5148\u9a8c\u6846\u670921\u4e2a\u7c7b\u522b\u9884\u6d4b\u7ed3\u679c\uff08VOC\u6570\u636e\u96c6\uff09\uff0c\u5171\u67095x5x3x21\u4e2a\u9884\u6d4b\u7ed3\u679c \u6574\u4e2a\u8fc7\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a","title":"1.3 loc\u548ccls"},{"location":"objectdection/06.ssd/#131-priorbox","text":"\u5728\u8fd9\u91cc\u6211\u4eec\u7740\u91cd\u4ecb\u7ecdPriorBox\u5c42\u5148\u9a8c\u6846\u7684\u751f\u6210\u65b9\u6cd5\uff1a SSD\u4e00\u5171\u67096\u4e2a\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\uff0c\u6bcf\u4e2a\u7279\u5f81\u56fe\u4e0a\u8bbe\u7f6e\u7684\u5148\u9a8c\u6846\u6570\u91cf\u4e0d\u540c\u7684\uff08\u540c\u4e00\u4e2a\u7279\u5f81\u56fe\u4e0a\u6bcf\u4e2a\u5355\u5143\u8bbe\u7f6e\u7684\u5148\u9a8c\u6846\u662f\u76f8\u540c\u7684\uff0c\u8fd9\u91cc\u7684\u6570\u76ee\u6307\u7684\u662f\u4e00\u4e2a\u5355\u5143\u7684\u5148\u9a8c\u6846\u6570\u76ee\uff09\u3002 \u5148\u9a8c\u6846\u7684\u8bbe\u7f6e\uff1a\u5305\u62ec\u5c3a\u5ea6\uff08\u6216\u8005\u8bf4\u5927\u5c0f\uff09\u548c\u957f\u5bbd\u6bd4\u4e24\u4e2a\u65b9\u9762\u3002 \u5148\u9a8c\u6846\u7684\u5c3a\u5ea6 \u5148\u9a8c\u6846\u7684\u5c3a\u5ea6\u9075\u5b88\u4e00\u4e2a\u7ebf\u6027\u9012\u589e\u89c4\u5219\uff1a\u968f\u7740\u7279\u5f81\u56fe\u5927\u5c0f\u964d\u4f4e\uff0c\u5148\u9a8c\u6846\u5c3a\u5ea6\u7ebf\u6027\u589e\u52a0\uff0c\u6bcf\u4e2a\u5148\u9a8c\u6846\u7684\u5c3a\u5ea6\u6709\u4e0b\u5f0f\u51b3\u5b9a\uff1a s_k = s_{min} + \\frac{s_{max} - s_{min}}{m-1}(k-1), k\\in[1,m] s_k = s_{min} + \\frac{s_{max} - s_{min}}{m-1}(k-1), k\\in[1,m] \u5176\u4e2d\uff1a m m \u6307\u7684\u7279\u5f81\u56fe\u4e2a\u6570\uff0c\u8fd9\u91cc\u8bbe\u4e3a5 \uff0c\u56e0\u4e3a\u7b2c\u4e00\u5c42\uff08Conv4_3\u5c42\uff09\u662f\u5355\u72ec\u8bbe\u7f6e\u7684\u3002 s_k s_k \u8868\u793a\u5148\u9a8c\u6846\u5927\u5c0f\u76f8\u5bf9\u4e8e\u56fe\u7247\u7684\u6bd4\u4f8b\uff0c\u800c s_{min} s_{min} \u548c s_{max} s_{max} \u8868\u793a\u6bd4\u4f8b\u7684\u6700\u5c0f\u503c\u4e0e\u6700\u5927\u503c\uff0c\u53d6\u503c\u4e3a0.2\u548c0.9\u3002 1\u3001\u5bf9\u4e8e\u7b2c\u4e00\u4e2a\u7279\u5f81\u56fe\uff0c\u5176\u5148\u9a8c\u6846\u7684\u5c3a\u5ea6\u6bd4\u4f8b\u4e00\u822c\u8bbe\u7f6e\u4e3a s_{min}/2=0.1 s_{min}/2=0.1 \uff0c\u5c3a\u5ea6\u4e3a 300\\times 0.1=30 300\\times 0.1=30 \u3002 2\u3001\u5bf9\u4e8e\u540e\u9762\u7684\u7279\u5f81\u56fe\uff0c\u5148\u9a8c\u6846\u5c3a\u5ea6\u6309\u7167 s_k s_k \u7ebf\u6027\u589e\u52a0\uff0c\u589e\u957f\u6b65\u957f\u4e3a: \\lfloor\\frac{\\lfloor s_{max}\\rfloor - \\lfloor s_{min}\\rfloor}{m-1}\\rfloor=0.17 \\lfloor\\frac{\\lfloor s_{max}\\rfloor - \\lfloor s_{min}\\rfloor}{m-1}\\rfloor=0.17 3\u3001\u6839\u636e\u4e0a\u5f0f\uff0c\u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u51fa\u5404\u4e2a\u5c3a\u5ea6 s_k s_k \u7684\u53d6\u503c\u4e3a0.20, 0.37,0. 54, 0.71, 0.88 4\u3001\u7136\u540e\u518d\u4e58\u4ee5\u539f\u56fe\u7684\u5927\u5c0f300\uff0c\u518d\u7efc\u5408\u7b2c\u4e00\u4e2a\u7279\u5f81\u56fe\u7684\u5148\u9a8c\u6846\u5c3a\u5bf8\uff0c\u5219\u53ef\u5f97\u5404\u4e2a\u7279\u5f81\u56fe\u7684\u5148\u9a8c\u6846\u5c3a\u5bf8\u4e3a30,60,111, 162,213,264\u3002 \u5148\u9a8c\u6846\u7684\u957f\u5bbd\u6bd4 \u4e00\u822c\u9009\u53d6 a_r\\in {1,2,3,\\frac{1}{2},\\frac{1}{3}} a_r\\in {1,2,3,\\frac{1}{2},\\frac{1}{3}} \uff0c\u5bf9\u4e8e\u7279\u5b9a\u7684\u957f\u5bbd\u6bd4\uff0c\u6309\u5982\u4e0b\u516c\u5f0f\u8ba1\u7b97\u5148\u9a8c\u6846\u7684\u5bbd\u5ea6\u4e0e\u9ad8\u5ea6\uff08\u540e\u9762\u7684 s_k s_k \u5747\u6307\u7684\u662f\u5148\u9a8c\u6846\u5b9e\u9645\u5c3a\u5ea6\uff0c\u800c\u4e0d\u662f\u5c3a\u5ea6\u6bd4\u4f8b\uff09: w^a_{k}=s_k\\sqrt{a_r},\\space h^a_{k}=s_k/\\sqrt{a_r} w^a_{k}=s_k\\sqrt{a_r},\\space h^a_{k}=s_k/\\sqrt{a_r} \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u6bcf\u4e2a\u7279\u5f81\u56fe\u4f1a\u6709\u4e00\u4e2a a_r=1 a_r=1 \u4e14\u5c3a\u5ea6\u4e3a s_k s_k \u7684\u5148\u9a8c\u6846\uff0c\u9664\u6b64\u4e4b\u5916\uff0c\u8fd8\u4f1a\u8bbe\u7f6e\u4e00\u4e2a\u5c3a\u5ea6\u4e3a s'_{k}=\\sqrt{s_k s_{k+1}} s'_{k}=\\sqrt{s_k s_{k+1}} \u4e14 a_r=1 a_r=1 \u7684\u5148\u9a8c\u6846\uff0c\u8fd9\u6837\u6bcf\u4e2a\u7279\u5f81\u56fe\u90fd\u8bbe\u7f6e\u4e86\u4e24\u4e2a\u957f\u5bbd\u6bd4\u4e3a1\u4f46\u5927\u5c0f\u4e0d\u540c\u7684\u6b63\u65b9\u5f62\u5148\u9a8c\u6846\u3002 \u56e0\u6b64\uff0c\u6bcf\u4e2a\u7279\u5f81\u56fe\u4e00\u5171\u6709 6 \u4e2a\u5148\u9a8c\u6846 {1,2,3,\\frac{1}{2},\\frac{1}{3},1'} {1,2,3,\\frac{1}{2},\\frac{1}{3},1'} \uff0c\u4f46\u662f\u5728\u5b9e\u73b0\u65f6\uff0cConv4_3\uff0cConv10_2\u548cConv11_2\u5c42\u4ec5\u4f7f\u75284\u4e2a\u5148\u9a8c\u6846\uff0c\u5b83\u4eec\u4e0d\u4f7f\u7528\u957f\u5bbd\u6bd4\u4e3a 3,\\frac{1}{3} 3,\\frac{1}{3} \u7684\u5148\u9a8c\u6846\u3002 \u4ee4 n_k n_k \u4e3a\u8be5\u7279\u5f81\u56fe\u6240\u91c7\u7528\u7684\u5148\u9a8c\u6846\u6570\u76ee\uff0c\u90a3\u4e48\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u9700\u8981\u7684\u5377\u79ef\u6838\u6570\u91cf\u4e3a n_k n_k \uff0c\u800c\u8fb9\u754c\u6846\u4f4d\u7f6e\u9700\u8981\u7684\u5377\u79ef\u6838\u6570\u91cf\u4e3a n_k\\times 4 n_k\\times 4 \u3002\u7531\u4e8e\u6bcf\u4e2a\u5148\u9a8c\u6846\u90fd\u4f1a\u9884\u6d4b\u4e00\u4e2a\u8fb9\u754c\u6846\uff0c \u6240\u4ee5SSD\u4e00\u5171\u53ef\u4ee5\u9884\u6d4b 38\\times38\\times4+19\\times19\\times6+10\\times10\\times6+5\\times5\\times6+3\\times3\\times4+1\\times1\\times4=8732 38\\times38\\times4+19\\times19\\times6+10\\times10\\times6+5\\times5\\times6+3\\times3\\times4+1\\times1\\times4=8732 \u4e2a\u8fb9\u754c\u6846\uff0c\u5bf9\u4e8e\u4e00\u4e2a300x300\u7684\u56fe\u50cf\u5c31\u67098732\u4e2a\u9884\u6d4b\u7ed3\u679c\uff0c\u662f\u975e\u5e38\u7684\u591a\u7684\uff0c\u6240\u4ee5\u8bf4SSD\u672c\u8d28\u4e0a\u662f\u5bc6\u96c6\u91c7\u6837\u3002","title":"1.3.1 PriorBox\u5c42\u5148\u9a8c\u6846\u7684\u751f\u6210\u65b9\u6cd5"},{"location":"objectdection/06.ssd/#132-loc","text":"\u7f51\u7edc\u9884\u6d4b\u8f93\u51fa\u7684\u8fb9\u754c\u6846\u4e0e\u771f\u5b9e\u7684\u8fb9\u754c\u6846\u4e4b\u95f4\u5b58\u5728\u8f6c\u6362\u5173\u7cfb\uff0c\u5177\u4f53\u5982\u4e0b\uff1a \u5148\u9a8c\u6846\u4f4d\u7f6e\uff1a l= (l^{cx}, l^{cy}, l^{w}, l^{h}) l= (l^{cx}, l^{cy}, l^{w}, l^{h}) \u771f\u5b9e\u6846\u7684\u4f4d\u7f6e\uff1a p = (p^{cx}, p^{cy}, p^{w}, p^{h}) p = (p^{cx}, p^{cy}, p^{w}, p^{h}) \u90a3\u4e48\u7f51\u7edc\u8f93\u51fa\u7ed3\u679c d d \u4e0e\u8fb9\u754c\u6846\u7684\u4f4d\u7f6e\u5b58\u5728\u5173\u7cfb\uff1a p^{cx} =l^{w}d^{cx} +l^{cx}, p^{cy} = l^{y}d^{cy} +l^{cy} p^{cx} =l^{w}d^{cx} +l^{cx}, p^{cy} = l^{y}d^{cy} +l^{cy} p^{w} = l^{w}exp(d^{w}), p^{h} = l^{h}exp(d^{h}) p^{w} = l^{w}exp(d^{w}), p^{h} = l^{h}exp(d^{h})","title":"1.3.2 loc\u7684\u9884\u6d4b\u7ed3\u679c"},{"location":"objectdection/06.ssd/#2","text":"","title":"2.\u6a21\u578b\u8bad\u7ec3"},{"location":"objectdection/06.ssd/#21","text":"\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u9996\u5148\u9700\u8981\u786e\u5b9a\u8bad\u7ec3\u56fe\u7247\u4e2d\u7684 ground truth \u4e0e\u54ea\u4e00\u4e2a\u5148\u9a8c\u6846\u6765\u8fdb\u884c\u5339\u914d\uff0c\u4e0e\u4e4b\u5339\u914d\u7684\u5148\u9a8c\u6846\u6240\u5bf9\u5e94\u7684\u8fb9\u754c\u6846\u5c06\u8d1f\u8d23\u9884\u6d4b\u5b83\u3002 SSD\u7684\u5148\u9a8c\u6846\u548cground truth\u5339\u914d\u539f\u5219\uff1a \u6b63\u6837\u672c 1\u3001\u5bf9\u4e8e\u56fe\u7247\u4e2d\u7684\u6bcf\u4e2agt\uff0c\u627e\u5230\u4e0e\u5176IOU\u6700\u5927\u7684\u5148\u9a8c\u6846\uff0c\u8be5\u5148\u9a8c\u6846\u4e0e\u5176\u5339\u914d\uff0c\u8fd9\u6837\u53ef\u4ee5\u4fdd\u8bc1\u6bcf\u4e2agt\u4e00\u5b9a\u4e0e\u67d0\u4e2a\u5148\u9a8c\u6846\u5339\u914d\u3002 2\u3001\u5bf9\u4e8e\u5269\u4f59\u672a\u5339\u914d\u7684\u5148\u9a8c\u6846\uff0c\u82e5\u67d0\u4e2agt\u7684IOU\u5927\u4e8e\u67d0\u4e2a\u9608\u503c(\u4e00\u822c0.5)\uff0c\u90a3\u4e48\u8be5\u5148\u9a8c\u6846\u4e0e\u8fd9\u4e2agt\u5339\u914d \u8d1f\u6837\u672c \u5176\u5b83\u7684\u5148\u9a8c\u6846\u6807\u8bb0\u4e3a\u8d1f\u6837\u672c \u6ce8\u610f\uff1a 1\u3001\u67d0\u4e2agt\u53ef\u4ee5\u548c\u591a\u4e2a\u5148\u9a8c\u6846\u5339\u914d\uff0c\u800c\u6bcf\u4e2a\u5148\u9a8c\u6846\u53ea\u80fd\u548c\u4e00\u4e2agt\u8fdb\u884c\u5339\u914d 2\u3001\u5982\u679c\u591a\u4e2agt\u548c\u67d0\u4e00\u4e2a\u5148\u9a8c\u6846\u7684IOU\u5747\u5927\u4e8e\u9608\u503c\uff0c\u90a3\u4e48\u5148\u9a8c\u6846\u53ea\u4e0eIOU\u6700\u5927\u7684\u90a3\u4e2a\u8fdb\u884c\u5339\u914d","title":"2.1 \u6b63\u8d1f\u6837\u672c\u6807\u8bb0"},{"location":"objectdection/06.ssd/#22","text":"SSD\u7684\u635f\u5931\u51fd\u6570\u662f\u4f4d\u7f6e\u635f\u5931\uff08 loc\uff09\u4e0e\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u635f\u5931\uff08conf\uff09\u7684\u52a0\u6743\u548c\uff1a L(x, c, l, g) = \\frac{1}{N}(L_{conf}(x,c) + \\alpha L_{loc}(x,l,g)) L(x, c, l, g) = \\frac{1}{N}(L_{conf}(x,c) + \\alpha L_{loc}(x,l,g)) \u5176\u4e2d N N \u662f\u5148\u9a8c\u6846\u7684\u6b63\u6837\u672c\u6570\u91cf\uff0c c c \u4e3a\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u503c\uff0c l l \u4e3a\u5148\u9a8c\u6846\u7684\u6240\u5bf9\u5e94\u8fb9\u754c\u6846\u7684\u4f4d\u7f6e\u9884\u6d4b\u503c\uff0c\u800c g g \u662fground truth\u7684\u4f4d\u7f6e\u53c2\u6570\uff0c\u6743\u91cd\u7cfb\u6570 \\alpha \\alpha \u8bbe\u7f6e\u4e3a1\u3002 \u4f4d\u7f6e\u635f\u5931\u51fd\u6570\uff1a \u9488\u5bf9\u6240\u6709\u7684\u6b63\u6837\u672c\uff0c\u91c7\u7528 Smooth L1 Loss\u635f\u5931 \u5206\u7c7b\u635f\u5931\u51fd\u6570 \u5bf9\u4e8e\u5206\u7c7b\u635f\u5931\uff0c\u4e0efasterRCNN\u4e00\u6837\u91c7\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u3002","title":"2.2 \u635f\u5931\u51fd\u6570"},{"location":"objectdection/06.ssd/#23","text":"\u56f0\u96be\u6837\u672c\u6316\u6398\u7684\u601d\u60f3\u662f\u4f7f\u7528\u7f51\u7edc\u5bf9\u6837\u672c\u8fdb\u884c\u5904\u7406\uff0c\u628a\u5176\u4e2d\u9884\u6d4b\u9519\u8bef\u7684\u8d1f\u6837\u672c(hard negative)\u653e\u5165\u8d1f\u6837\u672c\u96c6\u5408\u518d\u7ee7\u7eed\u8bad\u7ec3\u7f51\u7edc\u6a21\u578b\u3002 \u5728SSD\u4e2d\u5904\u7406\u65b9\u5f0f\u662f\uff1a \u4f7f\u75281\uff1a3\u7684\u6b63\u8d1f\u6837\u672c\u6bd4\u4f8b\u8bad\u7ec3\u7f51\u7edc\uff0c \u5bf9\u8f93\u5165\u7684\u9884\u6d4b\u7ed3\u679c\u6309\u7167\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u8fdb\u884c\u964d\u5e8f\u6392\u5e8f\uff0c\u53d6\u51fa\u524dk\u4e2a\u8d1f\u6837\u672c \u5c06\u8fd9k\u4e2a\u8d1f\u6837\u672c\u52a0\u5165\u4e0b\u6b21\u8fed\u4ee3\u7684\u8d1f\u6837\u672c\u4e2d\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u3002","title":"2.3 \u56f0\u96be\u6837\u672c\u6316\u6398"},{"location":"objectdection/06.ssd/#3","text":"\u9884\u6d4b\u8fc7\u7a0b\u6bd4\u8f83\u7b80\u5355\uff0c \u4e3b\u8981\u6b65\u9aa4\u5982\u4e0b\uff1a \u5bf9\u4e8e\u6bcf\u4e2a\u9884\u6d4b\u6846\uff0c\u9996\u5148\u6839\u636e\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u786e\u5b9a\u5176\u7c7b\u522b\uff08\u7f6e\u4fe1\u5ea6\u6700\u5927\u8005\uff09\u4e0e\u7f6e\u4fe1\u5ea6\u503c\uff0c\u5e76\u8fc7\u6ee4\u6389\u5c5e\u4e8e\u80cc\u666f\u7684\u9884\u6d4b\u6846\u3002 \u7136\u540e\u6839\u636e\u7f6e\u4fe1\u5ea6\u9608\u503c\uff08\u59820.5\uff09\u8fc7\u6ee4\u6389\u9608\u503c\u8f83\u4f4e\u7684\u9884\u6d4b\u6846\u3002 \u5bf9\u4e8e\u7559\u4e0b\u7684\u9884\u6d4b\u6846\u8fdb\u884c\u89e3\u7801\uff0c\u6839\u636e\u5148\u9a8c\u6846\u5f97\u5230\u5176\u771f\u5b9e\u7684\u4f4d\u7f6e\u53c2\u6570\uff08\u89e3\u7801\u540e\u4e00\u822c\u8fd8\u9700\u8981\u505aclip\uff0c\u9632\u6b62\u9884\u6d4b\u6846\u4f4d\u7f6e\u8d85\u51fa\u56fe\u7247\uff09\u3002 \u89e3\u7801\u4e4b\u540e\uff0c\u4e00\u822c\u9700\u8981\u6839\u636e\u7f6e\u4fe1\u5ea6\u8fdb\u884c\u964d\u5e8f\u6392\u5217\uff0c\u7136\u540e\u4ec5\u4fdd\u7559top-k\uff08\u5982400\uff09\u4e2a\u9884\u6d4b\u6846\u3002 \u8fdb\u884cNMS\u7b97\u6cd5\uff0c\u8fc7\u6ee4\u6389\u90a3\u4e9b\u91cd\u53e0\u5ea6\u8f83\u5927\u7684\u9884\u6d4b\u6846\u3002 \u6700\u540e\u5269\u4f59\u7684\u9884\u6d4b\u6846\u5c31\u662f\u68c0\u6d4b\u7ed3\u679c\u4e86\u3002 \u603b\u7ed3 \u77e5\u9053SSD\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u7684\u7f51\u7edc SSD\u63d0\u53d6\u4e866\u4e2a\u4e0d\u540c\u7279\u5f81\u56fe\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b \u77e5\u9053SSD\u4e2d\u5148\u9a8c\u6846\u7684\u751f\u6210\u65b9\u5f0f SSD\u5728\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u4e0a\u751f\u6210\u7684\u5148\u9a8c\u6846\u7684\u5c3a\u5ea6\u548c\u957f\u5bbd\u6bd4\u662f\u4e0d\u4e00\u6837\u7684 \u77e5\u9053SSD\u7684\u635f\u5931\u51fd\u6570\u7684\u8bbe\u8ba1 \u5206\u7c7b\u548c\u56de\u5f52\u635f\u5931\u51fd\u6570\u7684\u52a0\u6743\u548c","title":"3.\u6a21\u578b\u9884\u6d4b"},{"location":"tensorFlow/","text":"\u6df1\u5165\u6d45\u51faTensorFlow \u00b6 \u4e86\u89e3Tensorflow\u6846\u67b6\u7684\u7ec4\u6210\u3001\u63a5\u53e3 \u4e86\u89e3TensorFlow\u6846\u67b6\u7684\u5b89\u88c5 \u77e5\u9053tf.keras\u7684\u7279\u70b9\u548c\u4f7f\u7528 \u638c\u63e1TensorFlow\u57fa\u672c\u5f20\u91cf\u64cd\u4f5c \u638c\u63e1TensorFlow\u7684\u81ea\u52a8\u6c42\u5bfc\u673a\u5236 \u6a21\u578b\u7684\u6784\u5efa\uff1a `tf.keras.Model` \u548c `tf.keras.layers` \u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\uff1a `tf.keras.losses` \u6a21\u578b\u7684\u4f18\u5316\u5668\uff1a `tf.keras.optimizer` \u6a21\u578b\u7684\u8bc4\u4f30\uff1a `tf.keras.metrics` \u638c\u63e1keras pipline\u7684\u4f7f\u7528 \u638c\u63e1keras\u81ea\u5b9a\u4e49\u5c42\u3001\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4f30\u6307\u6807\u7684\u4f7f\u7528 \u638c\u63e1Checkpoint\u4f7f\u7528 \u638c\u63e1TensorBoard\u4f7f\u7528 \u638c\u63e1data\u6a21\u5757\u4f7f\u7528 \u638c\u63e1tf\u7684\u56fe\u6267\u884c\u6a21\u5f0f\u539f\u7406\u4e0e\u4f1a\u8bdd\u6a21\u5f0f\u7684\u533a\u522b \u638c\u63e1TensorFlow\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u63a5\u53e3\u4f7f\u7528 \u5e94\u7528Tensorflow\u5b8c\u6210\u5783\u573e\u5206\u7c7b\u7684\u8bad\u7ec3\u548c\u9884\u6d4b \u5e94\u7528\u5b8c\u6210\u5783\u573e\u5206\u7c7b\u7684\u8bad\u7ec3\u548c\u63a8\u7406","title":"\u6df1\u5165\u6d45\u51faTensorFlow"},{"location":"tensorFlow/#tensorflow","text":"\u4e86\u89e3Tensorflow\u6846\u67b6\u7684\u7ec4\u6210\u3001\u63a5\u53e3 \u4e86\u89e3TensorFlow\u6846\u67b6\u7684\u5b89\u88c5 \u77e5\u9053tf.keras\u7684\u7279\u70b9\u548c\u4f7f\u7528 \u638c\u63e1TensorFlow\u57fa\u672c\u5f20\u91cf\u64cd\u4f5c \u638c\u63e1TensorFlow\u7684\u81ea\u52a8\u6c42\u5bfc\u673a\u5236 \u6a21\u578b\u7684\u6784\u5efa\uff1a `tf.keras.Model` \u548c `tf.keras.layers` \u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\uff1a `tf.keras.losses` \u6a21\u578b\u7684\u4f18\u5316\u5668\uff1a `tf.keras.optimizer` \u6a21\u578b\u7684\u8bc4\u4f30\uff1a `tf.keras.metrics` \u638c\u63e1keras pipline\u7684\u4f7f\u7528 \u638c\u63e1keras\u81ea\u5b9a\u4e49\u5c42\u3001\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4f30\u6307\u6807\u7684\u4f7f\u7528 \u638c\u63e1Checkpoint\u4f7f\u7528 \u638c\u63e1TensorBoard\u4f7f\u7528 \u638c\u63e1data\u6a21\u5757\u4f7f\u7528 \u638c\u63e1tf\u7684\u56fe\u6267\u884c\u6a21\u5f0f\u539f\u7406\u4e0e\u4f1a\u8bdd\u6a21\u5f0f\u7684\u533a\u522b \u638c\u63e1TensorFlow\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u63a5\u53e3\u4f7f\u7528 \u5e94\u7528Tensorflow\u5b8c\u6210\u5783\u573e\u5206\u7c7b\u7684\u8bad\u7ec3\u548c\u9884\u6d4b \u5e94\u7528\u5b8c\u6210\u5783\u573e\u5206\u7c7b\u7684\u8bad\u7ec3\u548c\u63a8\u7406","title":"\u6df1\u5165\u6d45\u51faTensorFlow"},{"location":"tensorFlow/section1/","text":"\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-TensorFlow \u00b6 \u5b66\u4e60\u76ee\u6807 \u4e86\u89e3Tensorflow2.0\u6846\u67b6\u7684\u7528\u9014\u53ca\u6d41\u7a0b \u77e5\u9053tf2.0\u7684\u5f20\u91cf\u53ca\u5176\u64cd\u4f5c \u77e5\u9053tf.keras\u4e2d\u7684\u76f8\u5173\u6a21\u5757\u53ca\u5e38\u7528\u65b9\u6cd5 1.1 TensorFlow\u4ecb\u7ecd \u00b6 \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6TensorFlow\u4e00\u7ecf\u53d1\u5e03\uff0c\u5c31\u53d7\u5230\u4e86\u5e7f\u6cdb\u7684\u5173\u6ce8\uff0c\u5e76\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u97f3\u9891\u5904\u7406\u3001\u63a8\u8350\u7cfb\u7edf\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u573a\u666f\u4e0b\u90fd\u88ab\u5927\u9762\u79ef\u63a8\u5e7f\u4f7f\u7528\uff0c\u73b0\u5728\u5df2\u53d1\u5e032.3.0\u7248\u672c\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u6df1\u5165\u6d45\u51fa\u7684\u4ecb\u7ecdTensorflow\u7684\u76f8\u5173\u5e94\u7528\u3002 TensorFlow\u7684\u4f9d\u8d56\u89c6\u56fe\u5982\u4e0b\u6240\u793a\uff1a TF\u6258\u7ba1\u5728github\u5e73\u53f0\uff0c\u6709google groups\u548ccontributors\u5171\u540c\u7ef4\u62a4\u3002 TF\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u6df1\u5ea6\u5b66\u4e60\u76f8\u5173\u7684API\uff0c\u652f\u6301Python\u548cC/C++\u63a5\u53e3\u3002 TF\u63d0\u4f9b\u4e86\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177Tensorboard\uff0c\u65b9\u4fbf\u5206\u6790\u548c\u8c03\u6574\u6a21\u578b\u3002 TF\u652f\u6301Linux\u5e73\u53f0\uff0cWindows\u5e73\u53f0\uff0cMac\u5e73\u53f0\uff0c\u751a\u81f3\u624b\u673a\u79fb\u52a8\u8bbe\u5907\u7b49\u5404\u79cd\u5e73\u53f0\u3002 TensorFlow 2.0 \u5c06\u4e13\u6ce8\u4e8e\u7b80\u5355\u6027\u548c\u6613\u7528\u6027\uff0c\u5de5\u4f5c\u6d41\u7a0b\u5982\u4e0b\u6240\u793a\uff1a 1\u3001\u4f7f\u7528tf.data\u52a0\u8f7d\u6570\u636e\u3002 \u4f7f\u7528tf.data\u5b9e\u4f8b\u5316\u8bfb\u53d6\u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e 2\u3001\u6a21\u578b\u7684\u5efa\u7acb\u4e0e\u8c03\u8bd5\uff1a \u4f7f\u7528\u52a8\u6001\u56fe\u6a21\u5f0f Eager Execution \u548c\u8457\u540d\u7684\u795e\u7ecf\u7f51\u7edc\u9ad8\u5c42 API \u6846\u67b6 Keras\uff0c\u7ed3\u5408\u53ef\u89c6\u5316\u5de5\u5177 TensorBoard\uff0c\u7b80\u6613\u3001\u5feb\u901f\u5730\u5efa\u7acb\u548c\u8c03\u8bd5\u6a21\u578b\uff1b 3\u3001\u6a21\u578b\u7684\u8bad\u7ec3\uff1a \u652f\u6301 CPU / \u5355 GPU / \u5355\u673a\u591a\u5361 GPU / \u591a\u673a\u96c6\u7fa4 / TPU \u8bad\u7ec3\u6a21\u578b\uff0c\u5145\u5206\u5229\u7528\u6d77\u91cf\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u8fdb\u884c\u9ad8\u6548\u8bad\u7ec3\uff1b 4\u3001\u9884\u8bad\u7ec3\u6a21\u578b\u8c03\u7528\uff1a \u901a\u8fc7 TensorFlow Hub\uff0c\u53ef\u4ee5\u65b9\u4fbf\u5730\u8c03\u7528\u9884\u8bad\u7ec3\u5b8c\u6bd5\u7684\u5df2\u6709\u6210\u719f\u6a21\u578b\u3002 5\u3001\u6a21\u578b\u7684\u90e8\u7f72\uff1a \u901a\u8fc7 TensorFlow Serving\u3001TensorFlow Lite\u3001TensorFlow.js \u7b49\u7ec4\u4ef6\uff0c\u53ef\u4ee5\u5c06TensorFlow \u6a21\u578b\u90e8\u7f72\u5230\u670d\u52a1\u5668\u3001\u79fb\u52a8\u7aef\u3001\u5d4c\u5165\u5f0f\u7aef\u7b49\u591a\u79cd\u4f7f\u7528\u573a\u666f\uff1b 1.2 TensorFlow\u7684\u5b89\u88c5 \u00b6 \u5b89\u88c5 TensorFlow\u572864 \u4f4d\u7cfb\u7edf\u4e0a\u6d4b\u8bd5\u8fd9\u4e9b\u7cfb\u7edf\u652f\u6301 TensorFlow\uff1a Ubuntu 16.04 \u6216\u66f4\u9ad8\u7248\u672c Windows 7 \u6216\u66f4\u9ad8\u7248\u672c macOS 10.12.6 (Sierra) \u6216\u66f4\u9ad8\u7248\u672c\uff08\u4e0d\u652f\u6301 GPU\uff09 \u8fdb\u5165\u865a\u62df\u73af\u5883\u5f53\u4e2d\u518d\u5b89\u88c5\u3002\u63a8\u8350\u4f7f\u7528anoconda\u8fdb\u884c\u5b89\u88c5 1\u3001\u975eGPU\u7248\u672c\u5b89\u88c5 ubuntu\u5b89\u88c5 pip install tensorflow==2.3.0 -i https://pypi.tuna.tsinghua.edu.cn/simple 2\u3001GPU\u7248\u672c\u5b89\u88c5 pip install tensorflow-gpu==2.3.0 -i https://pypi.tuna.tsinghua.edu.cn/simple \u6ce8\uff1a\u5982\u679c\u9700\u8981\u4e0b\u8f7dGPU\u7248\u672c\u7684\uff08TensorFlow\u53ea\u63d0\u4f9bwindows\u548clinux\u7248\u672c\u7684\uff0c\u6ca1\u6709Macos\u7248\u672c\u7684\uff09\u3002 1.3 \u5f20\u91cf\u53ca\u5176\u64cd\u4f5c \u00b6 1.3.1 \u5f20\u91cfTensor \u00b6 \u5f20\u91cf\u662f\u4e00\u4e2a\u591a\u7ef4\u6570\u7ec4\u3002 \u4e0eNumPy ndarray\u5bf9\u8c61\u7c7b\u4f3c\uff0ctf.Tensor\u5bf9\u8c61\u4e5f\u5177\u6709\u6570\u636e\u7c7b\u578b\u548c\u5f62\u72b6\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6b64\u5916\uff0ctf.Tensors\u53ef\u4ee5\u4fdd\u7559\u5728GPU\u4e2d\u3002 TensorFlow\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u64cd\u4f5c\u5e93\uff08tf.add\uff0ctf.matmul\uff0ctf.linalg.inv\u7b49\uff09\uff0c\u5b83\u4eec\u4f7f\u7528\u548c\u751f\u6210tf.Tensor\u3002\u5728\u8fdb\u884c\u5f20\u91cf\u64cd\u4f5c\u4e4b\u524d\u5148\u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305\uff1a import tensorflow as tf import numpy as np 1.\u57fa\u672c\u65b9\u6cd5 \u00b6 \u9996\u5148\u8ba9\u6211\u4eec\u521b\u5efa\u57fa\u7840\u7684\u5f20\u91cf\uff1a # \u521b\u5efaint32\u7c7b\u578b\u76840\u7ef4\u5f20\u91cf\uff0c\u5373\u6807\u91cf rank_0_tensor = tf . constant ( 4 ) print ( rank_0_tensor ) # \u521b\u5efafloat32\u7c7b\u578b\u76841\u7ef4\u5f20\u91cf rank_1_tensor = tf . constant ([ 2.0 , 3.0 , 4.0 ]) print ( rank_1_tensor ) # \u521b\u5efafloat16\u7c7b\u578b\u7684\u4e8c\u7ef4\u5f20\u91cf rank_2_tensor = tf . constant ([[ 1 , 2 ], [ 3 , 4 ], [ 5 , 6 ]], dtype = tf . float16 ) print ( rank_2_tensor ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( 4 , shape = (), dtype = int32 ) tf . Tensor ([ 2. 3. 4. ], shape = ( 3 ,), dtype = float32 ) tf . Tensor ( [[ 1. 2. ] [ 3. 4. ] [ 5. 6. ]], shape = ( 3 , 2 ), dtype = float16 ) \u6211\u4eec\u4e5f\u53ef\u4ee5\u521b\u5efa\u66f4\u9ad8\u7ef4\u7684\u5f20\u91cf\uff1a # \u521b\u5efafloat32\u7c7b\u578b\u7684\u5f20\u91cf rank_3_tensor = tf . constant ([ [[ 0 , 1 , 2 , 3 , 4 ], [ 5 , 6 , 7 , 8 , 9 ]], [[ 10 , 11 , 12 , 13 , 14 ], [ 15 , 16 , 17 , 18 , 19 ]], [[ 20 , 21 , 22 , 23 , 24 ], [ 25 , 26 , 27 , 28 , 29 ]],]) print ( rank_3_tensor ) \u8be5\u8f93\u51fa\u7ed3\u679c\u6211\u4eec\u6709\u66f4\u591a\u7684\u65b9\u5f0f\u5c06\u5176\u5c55\u793a\u51fa\u6765\uff1a 2.\u8f6c\u6362\u6210numpy \u00b6 \u6211\u4eec\u53ef\u5c06\u5f20\u91cf\u8f6c\u6362\u4e3anumpy\u4e2d\u7684ndarray\u7684\u5f62\u5f0f\uff0c\u8f6c\u6362\u65b9\u6cd5\u6709\u4e24\u79cd\uff0c\u4ee5\u5f20\u91cfrank_2_tensor\u4e3a\u4f8b\uff1a np.array np . array ( rank_2_tensor ) Tensor.numpy() rank_2_tensor . numpy () 3.\u5e38\u7528\u51fd\u6570 \u00b6 \u6211\u4eec\u53ef\u4ee5\u5bf9\u5f20\u91cf\u505a\u4e00\u4e9b\u57fa\u672c\u7684\u6570\u5b66\u8fd0\u7b97\uff0c\u5305\u62ec\u52a0\u6cd5\u3001\u5143\u7d20\u4e58\u6cd5\u548c\u77e9\u9635\u4e58\u6cd5\u7b49\uff1a # \u5b9a\u4e49\u5f20\u91cfa\u548cb a = tf . constant ([[ 1 , 2 ], [ 3 , 4 ]]) b = tf . constant ([[ 1 , 1 ], [ 1 , 1 ]]) print ( tf . add ( a , b ), \" \\n \" ) # \u8ba1\u7b97\u5f20\u91cf\u7684\u548c print ( tf . multiply ( a , b ), \" \\n \" ) # \u8ba1\u7b97\u5f20\u91cf\u7684\u5143\u7d20\u4e58\u6cd5 print ( tf . matmul ( a , b ), \" \\n \" ) # \u8ba1\u7b97\u4e58\u6cd5 \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ 2 3 ] [ 4 5 ]], shape = ( 2 , 2 ), dtype = int32 ) tf . Tensor ( [[ 1 2 ] [ 3 4 ]], shape = ( 2 , 2 ), dtype = int32 ) tf . Tensor ( [[ 3 3 ] [ 7 7 ]], shape = ( 2 , 2 ), dtype = int32 ) \u53e6\u5916\u5f20\u91cf\u4e5f\u53ef\u7528\u4e8e\u5404\u79cd\u805a\u5408\u8fd0\u7b97\uff1a tf . reduce_sum () # \u6c42\u548c tf . reduce_mean () # \u5e73\u5747\u503c tf . reduce_max () # \u6700\u5927\u503c tf . reduce_min () # \u6700\u5c0f\u503c tf . argmax () # \u6700\u5927\u503c\u7684\u7d22\u5f15 tf . argmin () # \u6700\u5c0f\u503c\u7684\u7d22\u5f15 \u4f8b\u5982\uff1a c = tf . constant ([[ 4.0 , 5.0 ], [ 10.0 , 1.0 ]]) # \u6700\u5927\u503c print ( tf . reduce_max ( c )) # \u6700\u5927\u503c\u7d22\u5f15 print ( tf . argmax ( c )) # \u8ba1\u7b97\u5747\u503c print ( tf . reduce_mean ( c )) \u8f93\u51fa\u4e3a\uff1a tf . Tensor ( 10.0 , shape = (), dtype = float32 ) tf . Tensor ([ 1 0 ], shape = ( 2 ,), dtype = int64 ) tf . Tensor ( 5.0 , shape = (), dtype = float32 ) 4.\u53d8\u91cf \u00b6 \u53d8\u91cf\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u5f20\u91cf\uff0c\u5f62\u72b6\u662f\u4e0d\u53ef\u53d8\uff0c\u4f46\u53ef\u4ee5\u66f4\u6539\u5176\u4e2d\u7684\u53c2\u6570\u3002\u5b9a\u4e49\u65f6\u7684\u65b9\u6cd5\u662f\uff1a my_variable = tf . Variable ([[ 1.0 , 2.0 ], [ 3.0 , 4.0 ]]) \u6211\u4eec\u4e5f\u53ef\u4ee5\u83b7\u53d6\u5b83\u7684\u5f62\u72b6\uff0c\u7c7b\u578b\u53ca\u8f6c\u6362\u4e3andarray: print ( \"Shape: \" , my_variable . shape ) print ( \"DType: \" , my_variable . dtype ) print ( \"As NumPy: \" , my_variable . numpy ) \u8f93\u51fa\u4e3a\uff1a Shape: (2, 2) DType: <dtype: 'float32'> As NumPy: <bound method BaseResourceVariable.numpy of <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy= array([[1., 2.], [3., 4.]], dtype=float32)>> 1.4 tf.keras\u4ecb\u7ecd \u00b6 tf.keras\u662fTensorFlow 2.0\u7684\u9ad8\u9636API\u63a5\u53e3\uff0c\u4e3aTensorFlow\u7684\u4ee3\u7801\u63d0\u4f9b\u4e86\u65b0\u7684\u98ce\u683c\u548c\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u5927\u5927\u63d0\u5347\u4e86TF\u4ee3\u7801\u7684\u7b80\u6d01\u6027\u548c\u590d\u7528\u6027\uff0c\u5b98\u65b9\u4e5f\u63a8\u8350\u4f7f\u7528tf.keras\u6765\u8fdb\u884c\u6a21\u578b\u8bbe\u8ba1\u548c\u5f00\u53d1\u3002 1.4.1 \u5e38\u7528\u6a21\u5757 \u00b6 tf.keras\u4e2d\u5e38\u7528\u6a21\u5757\u5982\u4e0b\u8868\u6240\u793a\uff1a \u6a21\u5757 \u6982\u8ff0 activations \u6fc0\u6d3b\u51fd\u6570 applications \u9884\u8bad\u7ec3\u7f51\u7edc\u6a21\u5757 Callbacks \u5728\u6a21\u578b\u8bad\u7ec3\u671f\u95f4\u88ab\u8c03\u7528 datasets tf.keras\u6570\u636e\u96c6\u6a21\u5757\uff0c\u5305\u62ecboston_housing\uff0ccifar10\uff0cfashion_mnist\uff0cimdb \uff0cmnist layers Keras\u5c42API losses \u5404\u79cd\u635f\u5931\u51fd\u6570 metircs \u5404\u79cd\u8bc4\u4ef7\u6307\u6807 models \u6a21\u578b\u521b\u5efa\u6a21\u5757\uff0c\u4ee5\u53ca\u4e0e\u6a21\u578b\u76f8\u5173\u7684API optimizers \u4f18\u5316\u65b9\u6cd5 preprocessing Keras\u6570\u636e\u7684\u9884\u5904\u7406\u6a21\u5757 regularizers \u6b63\u5219\u5316\uff0cL1,L2\u7b49 utils \u8f85\u52a9\u529f\u80fd\u5b9e\u73b0 1.4.2 \u5e38\u7528\u65b9\u6cd5 \u00b6 \u6df1\u5ea6\u5b66\u4e60\u5b9e\u73b0\u7684\u4e3b\u8981\u6d41\u7a0b\uff1a1.\u6570\u636e\u83b7\u53d6\uff0c2\uff0c\u6570\u636e\u5904\u7406\uff0c3.\u6a21\u578b\u521b\u5efa\u4e0e\u8bad\u7ec3\uff0c4 \u6a21\u578b\u6d4b\u8bd5\u4e0e\u8bc4\u4f30\uff0c5.\u6a21\u578b\u9884\u6d4b 1.\u5bfc\u5165tf.keras \u00b6 \u4f7f\u7528 tf.keras \uff0c\u9996\u5148\u9700\u8981\u5728\u4ee3\u7801\u5f00\u59cb\u65f6\u5bfc\u5165 tf.keras import tensorflow as tf from tensorflow import keras 2.\u6570\u636e\u8f93\u5165 \u00b6 \u5bf9\u4e8e\u5c0f\u7684\u6570\u636e\u96c6\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528numpy\u683c\u5f0f\u7684\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u3001\u8bc4\u4f30\u6a21\u578b\uff0c\u5bf9\u4e8e\u5927\u578b\u6570\u636e\u96c6\u6216\u8005\u8981\u8fdb\u884c\u8de8\u8bbe\u5907\u8bad\u7ec3\u65f6\u4f7f\u7528tf.data.datasets\u6765\u8fdb\u884c\u6570\u636e\u8f93\u5165\u3002 3.\u6a21\u578b\u6784\u5efa \u00b6 \u7b80\u5355\u6a21\u578b\u4f7f\u7528Sequential\u8fdb\u884c\u6784\u5efa \u590d\u6742\u6a21\u578b\u4f7f\u7528\u51fd\u6570\u5f0f\u7f16\u7a0b\u6765\u6784\u5efa \u81ea\u5b9a\u4e49layers 4.\u8bad\u7ec3\u4e0e\u8bc4\u4f30 \u00b6 \u914d\u7f6e\u8bad\u7ec3\u8fc7\u7a0b\uff1a # \u914d\u7f6e\u4f18\u5316\u65b9\u6cd5\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 model . compile ( optimizer = tf . train . AdamOptimizer ( 0.001 ), loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) \u6a21\u578b\u8bad\u7ec3 # \u6307\u660e\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u8bad\u7ec3epoch,\u6279\u6b21\u5927\u5c0f\u548c\u9a8c\u8bc1\u96c6\u6570\u636e model . fit / fit_generator ( dataset , epochs = 10 , batch_size = 3 , validation_data = val_dataset , ) \u6a21\u578b\u8bc4\u4f30 # \u6307\u660e\u8bc4\u4f30\u6570\u636e\u96c6\u548c\u6279\u6b21\u5927\u5c0f model . evaluate ( x , y , batch_size = 32 ) \u6a21\u578b\u9884\u6d4b # \u5bf9\u65b0\u7684\u6837\u672c\u8fdb\u884c\u9884\u6d4b model . predict ( x , batch_size = 32 ) 5.\u56de\u8c03\u51fd\u6570\uff08callbacks\uff09 \u00b6 \u56de\u8c03\u51fd\u6570\u7528\u5728\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6765\u63a7\u5236\u6a21\u578b\u8bad\u7ec3\u884c\u4e3a\uff0c\u53ef\u4ee5\u81ea\u5b9a\u4e49\u56de\u8c03\u51fd\u6570\uff0c\u4e5f\u53ef\u4f7f\u7528tf.keras.callbacks \u5185\u7f6e\u7684 callback \uff1a ModelCheckpoint\uff1a\u5b9a\u671f\u4fdd\u5b58 checkpoints\u3002 LearningRateScheduler\uff1a\u52a8\u6001\u6539\u53d8\u5b66\u4e60\u901f\u7387\u3002 EarlyStopping\uff1a\u5f53\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6027\u80fd\u4e0d\u518d\u63d0\u9ad8\u65f6\uff0c\u7ec8\u6b62\u8bad\u7ec3\u3002 TensorBoard\uff1a\u4f7f\u7528 TensorBoard \u76d1\u6d4b\u6a21\u578b\u7684\u72b6\u6001\u3002 6.\u6a21\u578b\u7684\u4fdd\u5b58\u548c\u6062\u590d \u00b6 \u53ea\u4fdd\u5b58\u53c2\u6570 # \u53ea\u4fdd\u5b58\u6a21\u578b\u7684\u6743\u91cd model . save_weights ( './my_model' ) # \u52a0\u8f7d\u6a21\u578b\u7684\u6743\u91cd model . load_weights ( 'my_model' ) \u4fdd\u5b58\u6574\u4e2a\u6a21\u578b # \u4fdd\u5b58\u6a21\u578b\u67b6\u6784\u4e0e\u6743\u91cd\u5728h5\u6587\u4ef6\u4e2d model . save ( 'my_model.h5' ) # \u52a0\u8f7d\u6a21\u578b\uff1a\u5305\u62ec\u67b6\u6784\u548c\u5bf9\u5e94\u7684\u6743\u91cd model = keras . models . load_model ( 'my_model.h5' ) \u603b\u7ed3 \u4e86\u89e3Tensorflow2.0\u6846\u67b6\u7684\u7528\u9014\u53ca\u6d41\u7a0b 1.\u4f7f\u7528tf.data\u52a0\u8f7d\u6570\u636e 2\u3001\u6a21\u578b\u7684\u5efa\u7acb\u4e0e\u8c03\u8bd5 3\u3001\u6a21\u578b\u7684\u8bad\u7ec3 4\u3001\u9884\u8bad\u7ec3\u6a21\u578b\u8c03\u7528 5\u3001\u6a21\u578b\u7684\u90e8\u7f72 \u77e5\u9053tf2.0\u7684\u5f20\u91cf\u53ca\u5176\u64cd\u4f5c \u5f20\u91cf\u662f\u591a\u7ef4\u6570\u7ec4\u3002 1\u3001\u521b\u5efa\u65b9\u6cd5\uff1atf.constant() 2\u3001\u8f6c\u6362\u4e3anumpy: np.array()\u6216tensor.asnumpy() 3\u3001\u5e38\u7528\u51fd\u6570\uff1a\u52a0\u6cd5\uff0c\u4e58\u6cd5\uff0c\u53ca\u5404\u79cd\u805a\u5408\u8fd0\u7b97 4\u3001\u53d8\u91cf\uff1atf.Variable() \u77e5\u9053tf.keras\u4e2d\u7684\u76f8\u5173\u6a21\u5757\u53ca\u5e38\u7528\u65b9\u6cd5 \u5e38\u7528\u6a21\u5757\uff1amodels,losses,application\u7b49 \u5e38\u7528\u65b9\u6cd5\uff1a 1\u3001\u5bfc\u5165tf.keras 2\u3001\u6570\u636e\u8f93\u5165 3\u3001\u6a21\u578b\u6784\u5efa 4\u3001\u8bad\u7ec3\u4e0e\u8bc4\u4f30 5\u3001\u56de\u8c03\u51fd\u6570 6\u3001\u6a21\u578b\u7684\u4fdd\u5b58\u4e0e\u6062\u590d","title":"tensorflow\u548ckeras\u7b80\u4ecb"},{"location":"tensorFlow/section1/#-tensorflow","text":"\u5b66\u4e60\u76ee\u6807 \u4e86\u89e3Tensorflow2.0\u6846\u67b6\u7684\u7528\u9014\u53ca\u6d41\u7a0b \u77e5\u9053tf2.0\u7684\u5f20\u91cf\u53ca\u5176\u64cd\u4f5c \u77e5\u9053tf.keras\u4e2d\u7684\u76f8\u5173\u6a21\u5757\u53ca\u5e38\u7528\u65b9\u6cd5","title":"\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-TensorFlow"},{"location":"tensorFlow/section1/#11-tensorflow","text":"\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6TensorFlow\u4e00\u7ecf\u53d1\u5e03\uff0c\u5c31\u53d7\u5230\u4e86\u5e7f\u6cdb\u7684\u5173\u6ce8\uff0c\u5e76\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u97f3\u9891\u5904\u7406\u3001\u63a8\u8350\u7cfb\u7edf\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u573a\u666f\u4e0b\u90fd\u88ab\u5927\u9762\u79ef\u63a8\u5e7f\u4f7f\u7528\uff0c\u73b0\u5728\u5df2\u53d1\u5e032.3.0\u7248\u672c\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u6df1\u5165\u6d45\u51fa\u7684\u4ecb\u7ecdTensorflow\u7684\u76f8\u5173\u5e94\u7528\u3002 TensorFlow\u7684\u4f9d\u8d56\u89c6\u56fe\u5982\u4e0b\u6240\u793a\uff1a TF\u6258\u7ba1\u5728github\u5e73\u53f0\uff0c\u6709google groups\u548ccontributors\u5171\u540c\u7ef4\u62a4\u3002 TF\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u6df1\u5ea6\u5b66\u4e60\u76f8\u5173\u7684API\uff0c\u652f\u6301Python\u548cC/C++\u63a5\u53e3\u3002 TF\u63d0\u4f9b\u4e86\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177Tensorboard\uff0c\u65b9\u4fbf\u5206\u6790\u548c\u8c03\u6574\u6a21\u578b\u3002 TF\u652f\u6301Linux\u5e73\u53f0\uff0cWindows\u5e73\u53f0\uff0cMac\u5e73\u53f0\uff0c\u751a\u81f3\u624b\u673a\u79fb\u52a8\u8bbe\u5907\u7b49\u5404\u79cd\u5e73\u53f0\u3002 TensorFlow 2.0 \u5c06\u4e13\u6ce8\u4e8e\u7b80\u5355\u6027\u548c\u6613\u7528\u6027\uff0c\u5de5\u4f5c\u6d41\u7a0b\u5982\u4e0b\u6240\u793a\uff1a 1\u3001\u4f7f\u7528tf.data\u52a0\u8f7d\u6570\u636e\u3002 \u4f7f\u7528tf.data\u5b9e\u4f8b\u5316\u8bfb\u53d6\u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e 2\u3001\u6a21\u578b\u7684\u5efa\u7acb\u4e0e\u8c03\u8bd5\uff1a \u4f7f\u7528\u52a8\u6001\u56fe\u6a21\u5f0f Eager Execution \u548c\u8457\u540d\u7684\u795e\u7ecf\u7f51\u7edc\u9ad8\u5c42 API \u6846\u67b6 Keras\uff0c\u7ed3\u5408\u53ef\u89c6\u5316\u5de5\u5177 TensorBoard\uff0c\u7b80\u6613\u3001\u5feb\u901f\u5730\u5efa\u7acb\u548c\u8c03\u8bd5\u6a21\u578b\uff1b 3\u3001\u6a21\u578b\u7684\u8bad\u7ec3\uff1a \u652f\u6301 CPU / \u5355 GPU / \u5355\u673a\u591a\u5361 GPU / \u591a\u673a\u96c6\u7fa4 / TPU \u8bad\u7ec3\u6a21\u578b\uff0c\u5145\u5206\u5229\u7528\u6d77\u91cf\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u8fdb\u884c\u9ad8\u6548\u8bad\u7ec3\uff1b 4\u3001\u9884\u8bad\u7ec3\u6a21\u578b\u8c03\u7528\uff1a \u901a\u8fc7 TensorFlow Hub\uff0c\u53ef\u4ee5\u65b9\u4fbf\u5730\u8c03\u7528\u9884\u8bad\u7ec3\u5b8c\u6bd5\u7684\u5df2\u6709\u6210\u719f\u6a21\u578b\u3002 5\u3001\u6a21\u578b\u7684\u90e8\u7f72\uff1a \u901a\u8fc7 TensorFlow Serving\u3001TensorFlow Lite\u3001TensorFlow.js \u7b49\u7ec4\u4ef6\uff0c\u53ef\u4ee5\u5c06TensorFlow \u6a21\u578b\u90e8\u7f72\u5230\u670d\u52a1\u5668\u3001\u79fb\u52a8\u7aef\u3001\u5d4c\u5165\u5f0f\u7aef\u7b49\u591a\u79cd\u4f7f\u7528\u573a\u666f\uff1b","title":"1.1 TensorFlow\u4ecb\u7ecd"},{"location":"tensorFlow/section1/#12-tensorflow","text":"\u5b89\u88c5 TensorFlow\u572864 \u4f4d\u7cfb\u7edf\u4e0a\u6d4b\u8bd5\u8fd9\u4e9b\u7cfb\u7edf\u652f\u6301 TensorFlow\uff1a Ubuntu 16.04 \u6216\u66f4\u9ad8\u7248\u672c Windows 7 \u6216\u66f4\u9ad8\u7248\u672c macOS 10.12.6 (Sierra) \u6216\u66f4\u9ad8\u7248\u672c\uff08\u4e0d\u652f\u6301 GPU\uff09 \u8fdb\u5165\u865a\u62df\u73af\u5883\u5f53\u4e2d\u518d\u5b89\u88c5\u3002\u63a8\u8350\u4f7f\u7528anoconda\u8fdb\u884c\u5b89\u88c5 1\u3001\u975eGPU\u7248\u672c\u5b89\u88c5 ubuntu\u5b89\u88c5 pip install tensorflow==2.3.0 -i https://pypi.tuna.tsinghua.edu.cn/simple 2\u3001GPU\u7248\u672c\u5b89\u88c5 pip install tensorflow-gpu==2.3.0 -i https://pypi.tuna.tsinghua.edu.cn/simple \u6ce8\uff1a\u5982\u679c\u9700\u8981\u4e0b\u8f7dGPU\u7248\u672c\u7684\uff08TensorFlow\u53ea\u63d0\u4f9bwindows\u548clinux\u7248\u672c\u7684\uff0c\u6ca1\u6709Macos\u7248\u672c\u7684\uff09\u3002","title":"1.2 TensorFlow\u7684\u5b89\u88c5"},{"location":"tensorFlow/section1/#13","text":"","title":"1.3 \u5f20\u91cf\u53ca\u5176\u64cd\u4f5c"},{"location":"tensorFlow/section1/#131-tensor","text":"\u5f20\u91cf\u662f\u4e00\u4e2a\u591a\u7ef4\u6570\u7ec4\u3002 \u4e0eNumPy ndarray\u5bf9\u8c61\u7c7b\u4f3c\uff0ctf.Tensor\u5bf9\u8c61\u4e5f\u5177\u6709\u6570\u636e\u7c7b\u578b\u548c\u5f62\u72b6\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6b64\u5916\uff0ctf.Tensors\u53ef\u4ee5\u4fdd\u7559\u5728GPU\u4e2d\u3002 TensorFlow\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u64cd\u4f5c\u5e93\uff08tf.add\uff0ctf.matmul\uff0ctf.linalg.inv\u7b49\uff09\uff0c\u5b83\u4eec\u4f7f\u7528\u548c\u751f\u6210tf.Tensor\u3002\u5728\u8fdb\u884c\u5f20\u91cf\u64cd\u4f5c\u4e4b\u524d\u5148\u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305\uff1a import tensorflow as tf import numpy as np","title":"1.3.1 \u5f20\u91cfTensor"},{"location":"tensorFlow/section1/#1","text":"\u9996\u5148\u8ba9\u6211\u4eec\u521b\u5efa\u57fa\u7840\u7684\u5f20\u91cf\uff1a # \u521b\u5efaint32\u7c7b\u578b\u76840\u7ef4\u5f20\u91cf\uff0c\u5373\u6807\u91cf rank_0_tensor = tf . constant ( 4 ) print ( rank_0_tensor ) # \u521b\u5efafloat32\u7c7b\u578b\u76841\u7ef4\u5f20\u91cf rank_1_tensor = tf . constant ([ 2.0 , 3.0 , 4.0 ]) print ( rank_1_tensor ) # \u521b\u5efafloat16\u7c7b\u578b\u7684\u4e8c\u7ef4\u5f20\u91cf rank_2_tensor = tf . constant ([[ 1 , 2 ], [ 3 , 4 ], [ 5 , 6 ]], dtype = tf . float16 ) print ( rank_2_tensor ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( 4 , shape = (), dtype = int32 ) tf . Tensor ([ 2. 3. 4. ], shape = ( 3 ,), dtype = float32 ) tf . Tensor ( [[ 1. 2. ] [ 3. 4. ] [ 5. 6. ]], shape = ( 3 , 2 ), dtype = float16 ) \u6211\u4eec\u4e5f\u53ef\u4ee5\u521b\u5efa\u66f4\u9ad8\u7ef4\u7684\u5f20\u91cf\uff1a # \u521b\u5efafloat32\u7c7b\u578b\u7684\u5f20\u91cf rank_3_tensor = tf . constant ([ [[ 0 , 1 , 2 , 3 , 4 ], [ 5 , 6 , 7 , 8 , 9 ]], [[ 10 , 11 , 12 , 13 , 14 ], [ 15 , 16 , 17 , 18 , 19 ]], [[ 20 , 21 , 22 , 23 , 24 ], [ 25 , 26 , 27 , 28 , 29 ]],]) print ( rank_3_tensor ) \u8be5\u8f93\u51fa\u7ed3\u679c\u6211\u4eec\u6709\u66f4\u591a\u7684\u65b9\u5f0f\u5c06\u5176\u5c55\u793a\u51fa\u6765\uff1a","title":"1.\u57fa\u672c\u65b9\u6cd5"},{"location":"tensorFlow/section1/#2numpy","text":"\u6211\u4eec\u53ef\u5c06\u5f20\u91cf\u8f6c\u6362\u4e3anumpy\u4e2d\u7684ndarray\u7684\u5f62\u5f0f\uff0c\u8f6c\u6362\u65b9\u6cd5\u6709\u4e24\u79cd\uff0c\u4ee5\u5f20\u91cfrank_2_tensor\u4e3a\u4f8b\uff1a np.array np . array ( rank_2_tensor ) Tensor.numpy() rank_2_tensor . numpy ()","title":"2.\u8f6c\u6362\u6210numpy"},{"location":"tensorFlow/section1/#3","text":"\u6211\u4eec\u53ef\u4ee5\u5bf9\u5f20\u91cf\u505a\u4e00\u4e9b\u57fa\u672c\u7684\u6570\u5b66\u8fd0\u7b97\uff0c\u5305\u62ec\u52a0\u6cd5\u3001\u5143\u7d20\u4e58\u6cd5\u548c\u77e9\u9635\u4e58\u6cd5\u7b49\uff1a # \u5b9a\u4e49\u5f20\u91cfa\u548cb a = tf . constant ([[ 1 , 2 ], [ 3 , 4 ]]) b = tf . constant ([[ 1 , 1 ], [ 1 , 1 ]]) print ( tf . add ( a , b ), \" \\n \" ) # \u8ba1\u7b97\u5f20\u91cf\u7684\u548c print ( tf . multiply ( a , b ), \" \\n \" ) # \u8ba1\u7b97\u5f20\u91cf\u7684\u5143\u7d20\u4e58\u6cd5 print ( tf . matmul ( a , b ), \" \\n \" ) # \u8ba1\u7b97\u4e58\u6cd5 \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ 2 3 ] [ 4 5 ]], shape = ( 2 , 2 ), dtype = int32 ) tf . Tensor ( [[ 1 2 ] [ 3 4 ]], shape = ( 2 , 2 ), dtype = int32 ) tf . Tensor ( [[ 3 3 ] [ 7 7 ]], shape = ( 2 , 2 ), dtype = int32 ) \u53e6\u5916\u5f20\u91cf\u4e5f\u53ef\u7528\u4e8e\u5404\u79cd\u805a\u5408\u8fd0\u7b97\uff1a tf . reduce_sum () # \u6c42\u548c tf . reduce_mean () # \u5e73\u5747\u503c tf . reduce_max () # \u6700\u5927\u503c tf . reduce_min () # \u6700\u5c0f\u503c tf . argmax () # \u6700\u5927\u503c\u7684\u7d22\u5f15 tf . argmin () # \u6700\u5c0f\u503c\u7684\u7d22\u5f15 \u4f8b\u5982\uff1a c = tf . constant ([[ 4.0 , 5.0 ], [ 10.0 , 1.0 ]]) # \u6700\u5927\u503c print ( tf . reduce_max ( c )) # \u6700\u5927\u503c\u7d22\u5f15 print ( tf . argmax ( c )) # \u8ba1\u7b97\u5747\u503c print ( tf . reduce_mean ( c )) \u8f93\u51fa\u4e3a\uff1a tf . Tensor ( 10.0 , shape = (), dtype = float32 ) tf . Tensor ([ 1 0 ], shape = ( 2 ,), dtype = int64 ) tf . Tensor ( 5.0 , shape = (), dtype = float32 )","title":"3.\u5e38\u7528\u51fd\u6570"},{"location":"tensorFlow/section1/#4","text":"\u53d8\u91cf\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u5f20\u91cf\uff0c\u5f62\u72b6\u662f\u4e0d\u53ef\u53d8\uff0c\u4f46\u53ef\u4ee5\u66f4\u6539\u5176\u4e2d\u7684\u53c2\u6570\u3002\u5b9a\u4e49\u65f6\u7684\u65b9\u6cd5\u662f\uff1a my_variable = tf . Variable ([[ 1.0 , 2.0 ], [ 3.0 , 4.0 ]]) \u6211\u4eec\u4e5f\u53ef\u4ee5\u83b7\u53d6\u5b83\u7684\u5f62\u72b6\uff0c\u7c7b\u578b\u53ca\u8f6c\u6362\u4e3andarray: print ( \"Shape: \" , my_variable . shape ) print ( \"DType: \" , my_variable . dtype ) print ( \"As NumPy: \" , my_variable . numpy ) \u8f93\u51fa\u4e3a\uff1a Shape: (2, 2) DType: <dtype: 'float32'> As NumPy: <bound method BaseResourceVariable.numpy of <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy= array([[1., 2.], [3., 4.]], dtype=float32)>>","title":"4.\u53d8\u91cf"},{"location":"tensorFlow/section1/#14-tfkeras","text":"tf.keras\u662fTensorFlow 2.0\u7684\u9ad8\u9636API\u63a5\u53e3\uff0c\u4e3aTensorFlow\u7684\u4ee3\u7801\u63d0\u4f9b\u4e86\u65b0\u7684\u98ce\u683c\u548c\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u5927\u5927\u63d0\u5347\u4e86TF\u4ee3\u7801\u7684\u7b80\u6d01\u6027\u548c\u590d\u7528\u6027\uff0c\u5b98\u65b9\u4e5f\u63a8\u8350\u4f7f\u7528tf.keras\u6765\u8fdb\u884c\u6a21\u578b\u8bbe\u8ba1\u548c\u5f00\u53d1\u3002","title":"1.4 tf.keras\u4ecb\u7ecd"},{"location":"tensorFlow/section1/#141","text":"tf.keras\u4e2d\u5e38\u7528\u6a21\u5757\u5982\u4e0b\u8868\u6240\u793a\uff1a \u6a21\u5757 \u6982\u8ff0 activations \u6fc0\u6d3b\u51fd\u6570 applications \u9884\u8bad\u7ec3\u7f51\u7edc\u6a21\u5757 Callbacks \u5728\u6a21\u578b\u8bad\u7ec3\u671f\u95f4\u88ab\u8c03\u7528 datasets tf.keras\u6570\u636e\u96c6\u6a21\u5757\uff0c\u5305\u62ecboston_housing\uff0ccifar10\uff0cfashion_mnist\uff0cimdb \uff0cmnist layers Keras\u5c42API losses \u5404\u79cd\u635f\u5931\u51fd\u6570 metircs \u5404\u79cd\u8bc4\u4ef7\u6307\u6807 models \u6a21\u578b\u521b\u5efa\u6a21\u5757\uff0c\u4ee5\u53ca\u4e0e\u6a21\u578b\u76f8\u5173\u7684API optimizers \u4f18\u5316\u65b9\u6cd5 preprocessing Keras\u6570\u636e\u7684\u9884\u5904\u7406\u6a21\u5757 regularizers \u6b63\u5219\u5316\uff0cL1,L2\u7b49 utils \u8f85\u52a9\u529f\u80fd\u5b9e\u73b0","title":"1.4.1 \u5e38\u7528\u6a21\u5757"},{"location":"tensorFlow/section1/#142","text":"\u6df1\u5ea6\u5b66\u4e60\u5b9e\u73b0\u7684\u4e3b\u8981\u6d41\u7a0b\uff1a1.\u6570\u636e\u83b7\u53d6\uff0c2\uff0c\u6570\u636e\u5904\u7406\uff0c3.\u6a21\u578b\u521b\u5efa\u4e0e\u8bad\u7ec3\uff0c4 \u6a21\u578b\u6d4b\u8bd5\u4e0e\u8bc4\u4f30\uff0c5.\u6a21\u578b\u9884\u6d4b","title":"1.4.2 \u5e38\u7528\u65b9\u6cd5"},{"location":"tensorFlow/section1/#1tfkeras","text":"\u4f7f\u7528 tf.keras \uff0c\u9996\u5148\u9700\u8981\u5728\u4ee3\u7801\u5f00\u59cb\u65f6\u5bfc\u5165 tf.keras import tensorflow as tf from tensorflow import keras","title":"1.\u5bfc\u5165tf.keras"},{"location":"tensorFlow/section1/#2","text":"\u5bf9\u4e8e\u5c0f\u7684\u6570\u636e\u96c6\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528numpy\u683c\u5f0f\u7684\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u3001\u8bc4\u4f30\u6a21\u578b\uff0c\u5bf9\u4e8e\u5927\u578b\u6570\u636e\u96c6\u6216\u8005\u8981\u8fdb\u884c\u8de8\u8bbe\u5907\u8bad\u7ec3\u65f6\u4f7f\u7528tf.data.datasets\u6765\u8fdb\u884c\u6570\u636e\u8f93\u5165\u3002","title":"2.\u6570\u636e\u8f93\u5165"},{"location":"tensorFlow/section1/#3_1","text":"\u7b80\u5355\u6a21\u578b\u4f7f\u7528Sequential\u8fdb\u884c\u6784\u5efa \u590d\u6742\u6a21\u578b\u4f7f\u7528\u51fd\u6570\u5f0f\u7f16\u7a0b\u6765\u6784\u5efa \u81ea\u5b9a\u4e49layers","title":"3.\u6a21\u578b\u6784\u5efa"},{"location":"tensorFlow/section1/#4_1","text":"\u914d\u7f6e\u8bad\u7ec3\u8fc7\u7a0b\uff1a # \u914d\u7f6e\u4f18\u5316\u65b9\u6cd5\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 model . compile ( optimizer = tf . train . AdamOptimizer ( 0.001 ), loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) \u6a21\u578b\u8bad\u7ec3 # \u6307\u660e\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u8bad\u7ec3epoch,\u6279\u6b21\u5927\u5c0f\u548c\u9a8c\u8bc1\u96c6\u6570\u636e model . fit / fit_generator ( dataset , epochs = 10 , batch_size = 3 , validation_data = val_dataset , ) \u6a21\u578b\u8bc4\u4f30 # \u6307\u660e\u8bc4\u4f30\u6570\u636e\u96c6\u548c\u6279\u6b21\u5927\u5c0f model . evaluate ( x , y , batch_size = 32 ) \u6a21\u578b\u9884\u6d4b # \u5bf9\u65b0\u7684\u6837\u672c\u8fdb\u884c\u9884\u6d4b model . predict ( x , batch_size = 32 )","title":"4.\u8bad\u7ec3\u4e0e\u8bc4\u4f30"},{"location":"tensorFlow/section1/#5callbacks","text":"\u56de\u8c03\u51fd\u6570\u7528\u5728\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6765\u63a7\u5236\u6a21\u578b\u8bad\u7ec3\u884c\u4e3a\uff0c\u53ef\u4ee5\u81ea\u5b9a\u4e49\u56de\u8c03\u51fd\u6570\uff0c\u4e5f\u53ef\u4f7f\u7528tf.keras.callbacks \u5185\u7f6e\u7684 callback \uff1a ModelCheckpoint\uff1a\u5b9a\u671f\u4fdd\u5b58 checkpoints\u3002 LearningRateScheduler\uff1a\u52a8\u6001\u6539\u53d8\u5b66\u4e60\u901f\u7387\u3002 EarlyStopping\uff1a\u5f53\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6027\u80fd\u4e0d\u518d\u63d0\u9ad8\u65f6\uff0c\u7ec8\u6b62\u8bad\u7ec3\u3002 TensorBoard\uff1a\u4f7f\u7528 TensorBoard \u76d1\u6d4b\u6a21\u578b\u7684\u72b6\u6001\u3002","title":"5.\u56de\u8c03\u51fd\u6570\uff08callbacks\uff09"},{"location":"tensorFlow/section1/#6","text":"\u53ea\u4fdd\u5b58\u53c2\u6570 # \u53ea\u4fdd\u5b58\u6a21\u578b\u7684\u6743\u91cd model . save_weights ( './my_model' ) # \u52a0\u8f7d\u6a21\u578b\u7684\u6743\u91cd model . load_weights ( 'my_model' ) \u4fdd\u5b58\u6574\u4e2a\u6a21\u578b # \u4fdd\u5b58\u6a21\u578b\u67b6\u6784\u4e0e\u6743\u91cd\u5728h5\u6587\u4ef6\u4e2d model . save ( 'my_model.h5' ) # \u52a0\u8f7d\u6a21\u578b\uff1a\u5305\u62ec\u67b6\u6784\u548c\u5bf9\u5e94\u7684\u6743\u91cd model = keras . models . load_model ( 'my_model.h5' ) \u603b\u7ed3 \u4e86\u89e3Tensorflow2.0\u6846\u67b6\u7684\u7528\u9014\u53ca\u6d41\u7a0b 1.\u4f7f\u7528tf.data\u52a0\u8f7d\u6570\u636e 2\u3001\u6a21\u578b\u7684\u5efa\u7acb\u4e0e\u8c03\u8bd5 3\u3001\u6a21\u578b\u7684\u8bad\u7ec3 4\u3001\u9884\u8bad\u7ec3\u6a21\u578b\u8c03\u7528 5\u3001\u6a21\u578b\u7684\u90e8\u7f72 \u77e5\u9053tf2.0\u7684\u5f20\u91cf\u53ca\u5176\u64cd\u4f5c \u5f20\u91cf\u662f\u591a\u7ef4\u6570\u7ec4\u3002 1\u3001\u521b\u5efa\u65b9\u6cd5\uff1atf.constant() 2\u3001\u8f6c\u6362\u4e3anumpy: np.array()\u6216tensor.asnumpy() 3\u3001\u5e38\u7528\u51fd\u6570\uff1a\u52a0\u6cd5\uff0c\u4e58\u6cd5\uff0c\u53ca\u5404\u79cd\u805a\u5408\u8fd0\u7b97 4\u3001\u53d8\u91cf\uff1atf.Variable() \u77e5\u9053tf.keras\u4e2d\u7684\u76f8\u5173\u6a21\u5757\u53ca\u5e38\u7528\u65b9\u6cd5 \u5e38\u7528\u6a21\u5757\uff1amodels,losses,application\u7b49 \u5e38\u7528\u65b9\u6cd5\uff1a 1\u3001\u5bfc\u5165tf.keras 2\u3001\u6570\u636e\u8f93\u5165 3\u3001\u6a21\u578b\u6784\u5efa 4\u3001\u8bad\u7ec3\u4e0e\u8bc4\u4f30 5\u3001\u56de\u8c03\u51fd\u6570 6\u3001\u6a21\u578b\u7684\u4fdd\u5b58\u4e0e\u6062\u590d","title":"6.\u6a21\u578b\u7684\u4fdd\u5b58\u548c\u6062\u590d"},{"location":"tensorFlow/section2/","text":"1.2 \u5feb\u901f\u5165\u95e8\u6a21\u578b \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u4f7f\u7528tf.keras\u7684\u57fa\u672c\u6d41\u7a0b \u4e86\u89e3tf.keras\u5b9e\u73b0\u6a21\u578b\u6784\u5efa\u7684\u65b9\u6cd5 \u4e86\u89e3tf.keras\u4e2d\u6a21\u578b\u8bad\u7ec3\u9a8c\u8bc1\u7684\u76f8\u5173\u65b9\u6cd5 \u4eca\u5929\u6211\u4eec\u901a\u8fc7\u9e22\u5c3e\u82b1\u5206\u7c7b\u6848\u4f8b\uff0c\u6765\u7ed9\u5927\u5bb6\u4ecb\u7ecdtf.keras\u7684\u57fa\u672c\u4f7f\u7528\u6d41\u7a0b\u3002tf.keras\u4f7f\u7528tensorflow\u4e2d\u7684\u9ad8\u7ea7\u63a5\u53e3\uff0c\u6211\u4eec\u8c03\u7528\u5b83\u5373\u53ef\u5b8c\u6210\uff1a \u5bfc\u5165\u548c\u89e3\u6790\u6570\u636e\u96c6 \u6784\u5efa\u6a21\u578b \u4f7f\u7528\u6837\u672c\u6570\u636e\u8bad\u7ec3\u8be5\u6a21\u578b \u8bc4\u4f30\u6a21\u578b\u7684\u6548\u679c\u3002 \u7531\u4e8e\u4e0escikit -learn\u7684\u76f8\u4f3c\u6027\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u5c06\u901a\u8fc7\u5c06Keras\u4e0escikit -learn\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ecb\u7ecdtf.Keras\u7684\u76f8\u5173\u4f7f\u7528\u65b9\u6cd5\u3002 1.\u76f8\u5173\u7684\u5e93\u7684\u5bfc\u5165 \u00b6 \u5728\u8fd9\u91cc\u4f7f\u7528sklearn\u548ctf.keras\u5b8c\u6210\u9e22\u5c3e\u82b1\u5206\u7c7b\uff0c\u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305\uff1a # \u7ed8\u56fe import seaborn as sns # \u6570\u503c\u8ba1\u7b97 import numpy as np # sklearn\u4e2d\u7684\u76f8\u5173\u5de5\u5177 # \u5212\u5206\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6 from sklearn.model_selection import train_test_split # \u903b\u8f91\u56de\u5f52 from sklearn.linear_model import LogisticRegressionCV # tf.keras\u4e2d\u4f7f\u7528\u7684\u76f8\u5173\u5de5\u5177 # \u7528\u4e8e\u6a21\u578b\u642d\u5efa from tensorflow.keras.models import Sequential # \u6784\u5efa\u6a21\u578b\u7684\u5c42\u548c\u6fc0\u6d3b\u65b9\u6cd5 from tensorflow.keras.layers import Dense , Activation # \u6570\u636e\u5904\u7406\u7684\u8f85\u52a9\u5de5\u5177 from tensorflow.keras import utils 2.\u6570\u636e\u5c55\u793a\u548c\u5212\u5206 \u00b6 \u5229\u7528seborn\u5bfc\u5165\u76f8\u5173\u7684\u6570\u636e\uff0ciris\u6570\u636e\u4ee5dataFrame\u7684\u65b9\u5f0f\u5728seaborn\u8fdb\u884c\u5b58\u50a8\uff0c\u6211\u4eec\u8bfb\u53d6\u540e\u5e76\u8fdb\u884c\u5c55\u793a\uff1a # \u8bfb\u53d6\u6570\u636e iris = sns . load_dataset ( \"iris\" ) # \u5c55\u793a\u6570\u636e\u7684\u524d\u4e94\u884c iris . head () \u53e6\u5916\uff0c\u5229\u7528seaborn\u4e2dpairplot\u51fd\u6570\u63a2\u7d22\u6570\u636e\u7279\u5f81\u95f4\u7684\u5173\u7cfb\uff1a # \u5c06\u6570\u636e\u4e4b\u95f4\u7684\u5173\u7cfb\u8fdb\u884c\u53ef\u89c6\u5316 sns . pairplot ( iris , hue = 'species' ) \u5c06\u6570\u636e\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\uff1a\u4eceiris dataframe\u4e2d\u63d0\u53d6\u539f\u59cb\u6570\u636e\uff0c\u5c06\u82b1\u74e3\u548c\u843c\u7247\u6570\u636e\u4fdd\u5b58\u5728\u6570\u7ec4X\u4e2d\uff0c\u6807\u7b7e\u4fdd\u5b58\u5728\u76f8\u5e94\u7684\u6570\u7ec4y\u4e2d\uff1a # \u82b1\u74e3\u548c\u82b1\u843c\u7684\u6570\u636e X = iris . values [:, : 4 ] # \u6807\u7b7e\u503c y = iris . values [:, 4 ] \u5229\u7528train_test_split\u5b8c\u6210\u6570\u636e\u96c6\u5212\u5206\uff1a # \u5c06\u6570\u636e\u96c6\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6 train_X , test_X , train_y , test_y = train_test_split ( X , y , train_size = 0.5 , test_size = 0.5 , random_state = 0 ) \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u4f7f\u7528sklearn\u548ctf.keras\u6765\u5b8c\u6210\u9884\u6d4b 3.sklearn\u5b9e\u73b0 \u00b6 \u5229\u7528\u903b\u8f91\u56de\u5f52\u7684\u5206\u7c7b\u5668\uff0c\u5e76\u4f7f\u7528\u4ea4\u53c9\u9a8c\u8bc1\u7684\u65b9\u6cd5\u6765\u9009\u62e9\u6700\u4f18\u7684\u8d85\u53c2\u6570\uff0c\u5b9e\u4f8b\u5316LogisticRegressionCV\u5206\u7c7b\u5668\uff0c\u5e76\u4f7f\u7528fit\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3\uff1a # \u5b9e\u4f8b\u5316\u5206\u7c7b\u5668 lr = LogisticRegressionCV () # \u8bad\u7ec3 lr . fit ( train_X , train_y ) \u5229\u7528\u8bad\u7ec3\u597d\u7684\u5206\u7c7b\u5668\u8fdb\u884c\u9884\u6d4b\uff0c\u5e76\u8ba1\u7b97\u51c6\u786e\u7387\uff1a # \u8ba1\u7b97\u51c6\u786e\u7387\u5e76\u8fdb\u884c\u6253\u5370 print ( \"Accuracy = {:.2f} \" . format ( lr . score ( test_X , test_y ))) \u903b\u8f91\u56de\u5f52\u7684\u51c6\u786e\u7387\u4e3a\uff1a Accuracy = 0.93 4.tf.keras\u5b9e\u73b0 \u00b6 \u5728sklearn\u4e2d\u6211\u4eec\u53ea\u8981\u5b9e\u4f8b\u5316\u5206\u7c7b\u5668\u5e76\u5229\u7528fit\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3\uff0c\u6700\u540e\u8861\u91cf\u5b83\u7684\u6027\u80fd\u5c31\u53ef\u4ee5\u4e86\uff0c\u90a3\u5728tf.keras\u4e2d\u4e0e\u5728sklearn\u975e\u5e38\u76f8\u4f3c\uff0c\u4e0d\u540c\u7684\u662f\uff1a \u6784\u5efa\u5206\u7c7b\u5668\u65f6\u9700\u8981\u8fdb\u884c\u6a21\u578b\u642d\u5efa \u6570\u636e\u91c7\u96c6\u65f6\uff0csklearn\u53ef\u4ee5\u63a5\u6536\u5b57\u7b26\u4e32\u578b\u7684\u6807\u7b7e\uff0c\u5982\uff1a\u201csetosa\u201d\uff0c\u4f46\u662f\u5728tf.keras\u4e2d\u9700\u8981\u5bf9\u6807\u7b7e\u503c\u8fdb\u884c\u70ed\u7f16\u7801\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u6709\u5f88\u591a\u65b9\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u70ed\u7f16\u7801\uff0c\u6bd4\u5982pandas\u4e2d\u7684get_dummies(),\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528tf.keras\u4e2d\u7684\u65b9\u6cd5\u8fdb\u884c\u70ed\u7f16\u7801\uff1a # \u8fdb\u884c\u70ed\u7f16\u7801 def one_hot_encode_object_array ( arr ): # \u53bb\u91cd\u83b7\u53d6\u5168\u90e8\u7684\u7c7b\u522b uniques , ids = np . unique ( arr , return_inverse = True ) # \u8fd4\u56de\u70ed\u7f16\u7801\u7684\u7ed3\u679c return utils . to_categorical ( ids , len ( uniques )) 4.1 \u6570\u636e\u5904\u7406 \u00b6 \u63a5\u4e0b\u6765\u5bf9\u6807\u7b7e\u503c\u8fdb\u884c\u70ed\u7f16\u7801\uff1a # \u8bad\u7ec3\u96c6\u70ed\u7f16\u7801 train_y_ohe = one_hot_encode_object_array ( train_y ) # \u6d4b\u8bd5\u96c6\u70ed\u7f16\u7801 test_y_ohe = one_hot_encode_object_array ( test_y ) 4.2 \u6a21\u578b\u642d\u5efa \u00b6 \u5728sklearn\u4e2d\uff0c\u6a21\u578b\u90fd\u662f\u73b0\u6210\u7684\u3002tf.Keras\u662f\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u5e93,\u6211\u4eec\u9700\u8981\u6839\u636e\u6570\u636e\u548c\u6807\u7b7e\u503c\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u3002\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u53d1\u73b0\u7279\u5f81\u4e0e\u6807\u7b7e\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\u3002\u795e\u7ecf\u7f51\u7edc\u662f\u4e00\u4e2a\u9ad8\u5ea6\u7ed3\u6784\u5316\u7684\u56fe\uff0c\u5176\u4e2d\u5305\u542b\u4e00\u4e2a\u6216\u591a\u4e2a\u9690\u85cf\u5c42\u3002\u6bcf\u4e2a\u9690\u85cf\u5c42\u90fd\u5305\u542b\u4e00\u4e2a\u6216\u591a\u4e2a\u795e\u7ecf\u5143\u3002\u795e\u7ecf\u7f51\u7edc\u6709\u591a\u79cd\u7c7b\u522b\uff0c\u8be5\u7a0b\u5e8f\u4f7f\u7528\u7684\u662f\u5bc6\u96c6\u578b\u795e\u7ecf\u7f51\u7edc\uff0c\u4e5f\u79f0\u4e3a\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\uff1a\u4e00\u4e2a\u5c42\u4e2d\u7684\u795e\u7ecf\u5143\u5c06\u4ece\u4e0a\u4e00\u5c42\u4e2d\u7684\u6bcf\u4e2a\u795e\u7ecf\u5143\u83b7\u53d6\u8f93\u5165\u8fde\u63a5\u3002\u4f8b\u5982\uff0c\u56fe 2 \u663e\u793a\u4e86\u4e00\u4e2a\u5bc6\u96c6\u578b\u795e\u7ecf\u7f51\u7edc\uff0c\u5176\u4e2d\u5305\u542b 1 \u4e2a\u8f93\u5165\u5c42\u30012 \u4e2a\u9690\u85cf\u5c42\u4ee5\u53ca 1 \u4e2a\u8f93\u51fa\u5c42\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4e0a\u56fe \u4e2d\u7684\u6a21\u578b\u7ecf\u8fc7\u8bad\u7ec3\u5e76\u9988\u9001\u672a\u6807\u8bb0\u7684\u6837\u672c\u65f6\uff0c\u5b83\u4f1a\u4ea7\u751f 3 \u4e2a\u9884\u6d4b\u7ed3\u679c\uff1a\u76f8\u5e94\u9e22\u5c3e\u82b1\u5c5e\u4e8e\u6307\u5b9a\u54c1\u79cd\u7684\u53ef\u80fd\u6027\u3002\u5bf9\u4e8e\u8be5\u793a\u4f8b\uff0c\u8f93\u51fa\u9884\u6d4b\u7ed3\u679c\u7684\u603b\u548c\u662f 1.0\u3002\u8be5\u9884\u6d4b\u7ed3\u679c\u5206\u89e3\u5982\u4e0b\uff1a\u5c71\u9e22\u5c3e\u4e3a 0.02\uff0c\u53d8\u8272\u9e22\u5c3e\u4e3a 0.95\uff0c\u7ef4\u5409\u5c3c\u4e9a\u9e22\u5c3e\u4e3a 0.03\u3002\u8fd9\u610f\u5473\u7740\u8be5\u6a21\u578b\u9884\u6d4b\u67d0\u4e2a\u65e0\u6807\u7b7e\u9e22\u5c3e\u82b1\u6837\u672c\u662f\u53d8\u8272\u9e22\u5c3e\u7684\u6982\u7387\u4e3a 95\uff05\u3002 TensorFlow tf.keras API \u662f\u521b\u5efa\u6a21\u578b\u548c\u5c42\u7684\u9996\u9009\u65b9\u5f0f\u3002\u901a\u8fc7\u8be5 API\uff0c\u60a8\u53ef\u4ee5\u8f7b\u677e\u5730\u6784\u5efa\u6a21\u578b\u5e76\u8fdb\u884c\u5b9e\u9a8c\uff0c\u800c\u5c06\u6240\u6709\u90e8\u5206\u8fde\u63a5\u5728\u4e00\u8d77\u7684\u590d\u6742\u5de5\u4f5c\u5219\u7531 Keras \u5904\u7406\u3002 tf.keras.Sequential \u6a21\u578b\u662f\u5c42\u7684\u7ebf\u6027\u5806\u53e0\u3002\u8be5\u6a21\u578b\u7684\u6784\u9020\u51fd\u6570\u4f1a\u91c7\u7528\u4e00\u7cfb\u5217\u5c42\u5b9e\u4f8b\uff1b\u5728\u672c\u793a\u4f8b\u4e2d\uff0c\u91c7\u7528\u7684\u662f 2 \u4e2a\u5bc6\u96c6\u5c42\uff08\u5206\u522b\u5305\u542b 10 \u4e2a\u8282\u70b9\uff09\u4ee5\u53ca 1 \u4e2a\u8f93\u51fa\u5c42\uff08\u5305\u542b 3 \u4e2a\u4ee3\u8868\u6807\u7b7e\u9884\u6d4b\u7684\u8282\u70b9\uff09\u3002\u7b2c\u4e00\u4e2a\u5c42\u7684 input_shape \u53c2\u6570\u5bf9\u5e94\u8be5\u6570\u636e\u96c6\u4e2d\u7684\u7279\u5f81\u6570\u91cf\uff1a # \u5229\u7528sequential\u65b9\u5f0f\u6784\u5efa\u6a21\u578b model = Sequential ([ # \u9690\u85cf\u5c421\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu,\u8f93\u5165\u5927\u5c0f\u6709input_shape\u6307\u5b9a Dense ( 10 , activation = \"relu\" , input_shape = ( 4 ,)), # \u9690\u85cf\u5c422\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu Dense ( 10 , activation = \"relu\" ), # \u8f93\u51fa\u5c42 Dense ( 3 , activation = \"softmax\" ) ]) \u901a\u8fc7model.summary\u53ef\u4ee5\u67e5\u770b\u6a21\u578b\u7684\u67b6\u6784\uff1a Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 10) 50 _________________________________________________________________ dense_1 (Dense) (None, 10) 110 _________________________________________________________________ dense_2 (Dense) (None, 3) 33 ================================================================= Total params: 193 Trainable params: 193 Non-trainable params: 0 _________________________________________________________________ \u6fc0\u6d3b\u51fd\u6570\u53ef\u51b3\u5b9a\u5c42\u4e2d\u6bcf\u4e2a\u8282\u70b9\u7684\u8f93\u51fa\u5f62\u72b6\u3002\u8fd9\u4e9b\u975e\u7ebf\u6027\u5173\u7cfb\u5f88\u91cd\u8981\uff0c\u5982\u679c\u6ca1\u6709\u5b83\u4eec\uff0c\u6a21\u578b\u5c06\u7b49\u540c\u4e8e\u5355\u4e2a\u5c42\u3002\u6fc0\u6d3b\u51fd\u6570\u6709\u5f88\u591a\uff0c\u4f46\u9690\u85cf\u5c42\u901a\u5e38\u4f7f\u7528 ReLU\u3002 \u9690\u85cf\u5c42\u548c\u795e\u7ecf\u5143\u7684\u7406\u60f3\u6570\u91cf\u53d6\u51b3\u4e8e\u95ee\u9898\u548c\u6570\u636e\u96c6\u3002\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u591a\u4e2a\u65b9\u9762\u4e00\u6837\uff0c\u9009\u62e9\u6700\u4f73\u7684\u795e\u7ecf\u7f51\u7edc\u5f62\u72b6\u9700\u8981\u4e00\u5b9a\u7684\u77e5\u8bc6\u6c34\u5e73\u548c\u5b9e\u9a8c\u57fa\u7840\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u589e\u52a0\u9690\u85cf\u5c42\u548c\u795e\u7ecf\u5143\u7684\u6570\u91cf\u901a\u5e38\u4f1a\u4ea7\u751f\u66f4\u5f3a\u5927\u7684\u6a21\u578b\uff0c\u800c\u8fd9\u9700\u8981\u66f4\u591a\u6570\u636e\u624d\u80fd\u6709\u6548\u5730\u8fdb\u884c\u8bad\u7ec3\u3002 4.3 \u6a21\u578b\u8bad\u7ec3\u548c\u9884\u6d4b \u00b6 \u5728\u8bad\u7ec3\u548c\u8bc4\u4f30\u9636\u6bb5\uff0c\u6211\u4eec\u90fd\u9700\u8981\u8ba1\u7b97\u6a21\u578b\u7684\u635f\u5931\u3002\u8fd9\u6837\u53ef\u4ee5\u8861\u91cf\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\u4e0e\u9884\u671f\u6807\u7b7e\u6709\u591a\u5927\u504f\u5dee\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u6a21\u578b\u7684\u6548\u679c\u6709\u591a\u5dee\u3002\u6211\u4eec\u5e0c\u671b\u5c3d\u53ef\u80fd\u51cf\u5c0f\u6216\u4f18\u5316\u8fd9\u4e2a\u503c\uff0c\u6240\u4ee5\u6211\u4eec\u8bbe\u7f6e\u4f18\u5316\u7b56\u7565\u548c\u635f\u5931\u51fd\u6570\uff0c\u4ee5\u53ca\u6a21\u578b\u7cbe\u5ea6\u7684\u8ba1\u7b97\u65b9\u6cd5\uff1a # \u8bbe\u7f6e\u6a21\u578b\u7684\u76f8\u5173\u53c2\u6570\uff1a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 model . compile ( optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = [ \"accuracy\" ]) \u63a5\u4e0b\u6765\u4e0e\u5728sklearn\u4e2d\u76f8\u540c\uff0c\u5206\u522b\u8c03\u7528fit\u548cpredict\u65b9\u6cd5\u8fdb\u884c\u9884\u6d4b\u5373\u53ef\u3002 # \u6a21\u578b\u8bad\u7ec3\uff1aepochs,\u8bad\u7ec3\u6837\u672c\u9001\u5165\u5230\u7f51\u7edc\u4e2d\u7684\u6b21\u6570\uff0cbatch_size:\u6bcf\u6b21\u8bad\u7ec3\u7684\u9001\u5165\u5230\u7f51\u7edc\u4e2d\u7684\u6837\u672c\u4e2a\u6570 model . fit ( train_X , train_y_ohe , epochs = 10 , batch_size = 1 , verbose = 1 ); \u4e0a\u8ff0\u4ee3\u7801\u5b8c\u6210\u7684\u662f\uff1a \u8fed\u4ee3\u6bcf\u4e2aepoch\u3002\u901a\u8fc7\u4e00\u6b21\u6570\u636e\u96c6\u5373\u4e3a\u4e00\u4e2aepoch\u3002 \u5728\u4e00\u4e2aepoch\u4e2d\uff0c\u904d\u5386\u8bad\u7ec3 Dataset \u4e2d\u7684\u6bcf\u4e2a\u6837\u672c\uff0c\u5e76\u83b7\u53d6\u6837\u672c\u7684\u7279\u5f81 (x) \u548c\u6807\u7b7e (y)\u3002 \u6839\u636e\u6837\u672c\u7684\u7279\u5f81\u8fdb\u884c\u9884\u6d4b\uff0c\u5e76\u6bd4\u8f83\u9884\u6d4b\u7ed3\u679c\u548c\u6807\u7b7e\u3002\u8861\u91cf\u9884\u6d4b\u7ed3\u679c\u7684\u4e0d\u51c6\u786e\u6027\uff0c\u5e76\u4f7f\u7528\u6240\u5f97\u7684\u503c\u8ba1\u7b97\u6a21\u578b\u7684\u635f\u5931\u548c\u68af\u5ea6\u3002 \u4f7f\u7528 optimizer \u66f4\u65b0\u6a21\u578b\u7684\u53d8\u91cf\u3002 \u5bf9\u6bcf\u4e2aepoch\u91cd\u590d\u6267\u884c\u4ee5\u4e0a\u6b65\u9aa4\uff0c\u76f4\u5230\u6a21\u578b\u8bad\u7ec3\u5b8c\u6210\u3002 \u8bad\u7ec3\u8fc7\u7a0b\u5c55\u793a\u5982\u4e0b\uff1a Epoch 1/10 75/75 [==============================] - 0s 616us/step - loss: 0.0585 - accuracy: 0.9733 Epoch 2/10 75/75 [==============================] - 0s 535us/step - loss: 0.0541 - accuracy: 0.9867 Epoch 3/10 75/75 [==============================] - 0s 545us/step - loss: 0.0650 - accuracy: 0.9733 Epoch 4/10 75/75 [==============================] - 0s 542us/step - loss: 0.0865 - accuracy: 0.9733 Epoch 5/10 75/75 [==============================] - 0s 510us/step - loss: 0.0607 - accuracy: 0.9733 Epoch 6/10 75/75 [==============================] - 0s 659us/step - loss: 0.0735 - accuracy: 0.9733 Epoch 7/10 75/75 [==============================] - 0s 497us/step - loss: 0.0691 - accuracy: 0.9600 Epoch 8/10 75/75 [==============================] - 0s 497us/step - loss: 0.0724 - accuracy: 0.9733 Epoch 9/10 75/75 [==============================] - 0s 493us/step - loss: 0.0645 - accuracy: 0.9600 Epoch 10/10 75/75 [==============================] - 0s 482us/step - loss: 0.0660 - accuracy: 0.9867 \u4e0esklearn\u4e2d\u4e0d\u540c\uff0c\u5bf9\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u65f6\uff0c\u4e0esklearn.score\u65b9\u6cd5\u5bf9\u5e94\u7684\u662ftf.keras.evaluate()\u65b9\u6cd5\uff0c\u8fd4\u56de\u7684\u662f\u635f\u5931\u51fd\u6570\u548c\u5728compile\u6a21\u578b\u65f6\u8981\u6c42\u7684\u6307\u6807: # \u8ba1\u7b97\u6a21\u578b\u7684\u635f\u5931\u548c\u51c6\u786e\u7387 loss , accuracy = model . evaluate ( test_X , test_y_ohe , verbose = 1 ) print ( \"Accuracy = {:.2f} \" . format ( accuracy )) \u5206\u7c7b\u5668\u7684\u51c6\u786e\u7387\u4e3a\uff1a 3 / 3 [ ============================== ] - 0 s 591 us / step - loss : 0.1031 - accuracy : 0.9733 Accuracy = 0.97 \u5230\u6b64\u6211\u4eec\u5bf9tf.kears\u7684\u4f7f\u7528\u6709\u4e86\u4e00\u4e2a\u57fa\u672c\u7684\u8ba4\u77e5\uff0c\u5728\u63a5\u4e0b\u6765\u7684\u8bfe\u7a0b\u4e2d\u4f1a\u7ed9\u5927\u5bb6\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u4ee5\u53ca\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u5e38\u7528\u7684CNN\u7684\u4f7f\u7528\u3002 \u603b\u7ed3 1.\u4f7f\u7528tf.keras\u8fdb\u884c\u5206\u7c7b\u65f6\u7684\u4e3b\u8981\u6d41\u7a0b\uff1a \u6570\u636e\u5904\u7406-\u6784\u5efa\u6a21\u578b-\u6a21\u578b\u8bad\u7ec3-\u6a21\u578b\u9a8c\u8bc1 2.tf.keras\u4e2d\u6784\u5efa\u6a21\u578b\u53ef\u901a\u8fc7squential()\u6765\u5b9e\u73b0\u5e76\u5229\u7528.fit()\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3 3.\u4f7f\u7528evaluate()\u65b9\u6cd5\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u548c\u51c6\u786e\u7387","title":"\u5feb\u901f\u5165\u95e8\u6a21\u578b"},{"location":"tensorFlow/section2/#12","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u4f7f\u7528tf.keras\u7684\u57fa\u672c\u6d41\u7a0b \u4e86\u89e3tf.keras\u5b9e\u73b0\u6a21\u578b\u6784\u5efa\u7684\u65b9\u6cd5 \u4e86\u89e3tf.keras\u4e2d\u6a21\u578b\u8bad\u7ec3\u9a8c\u8bc1\u7684\u76f8\u5173\u65b9\u6cd5 \u4eca\u5929\u6211\u4eec\u901a\u8fc7\u9e22\u5c3e\u82b1\u5206\u7c7b\u6848\u4f8b\uff0c\u6765\u7ed9\u5927\u5bb6\u4ecb\u7ecdtf.keras\u7684\u57fa\u672c\u4f7f\u7528\u6d41\u7a0b\u3002tf.keras\u4f7f\u7528tensorflow\u4e2d\u7684\u9ad8\u7ea7\u63a5\u53e3\uff0c\u6211\u4eec\u8c03\u7528\u5b83\u5373\u53ef\u5b8c\u6210\uff1a \u5bfc\u5165\u548c\u89e3\u6790\u6570\u636e\u96c6 \u6784\u5efa\u6a21\u578b \u4f7f\u7528\u6837\u672c\u6570\u636e\u8bad\u7ec3\u8be5\u6a21\u578b \u8bc4\u4f30\u6a21\u578b\u7684\u6548\u679c\u3002 \u7531\u4e8e\u4e0escikit -learn\u7684\u76f8\u4f3c\u6027\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u5c06\u901a\u8fc7\u5c06Keras\u4e0escikit -learn\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ecb\u7ecdtf.Keras\u7684\u76f8\u5173\u4f7f\u7528\u65b9\u6cd5\u3002","title":"1.2 \u5feb\u901f\u5165\u95e8\u6a21\u578b"},{"location":"tensorFlow/section2/#1","text":"\u5728\u8fd9\u91cc\u4f7f\u7528sklearn\u548ctf.keras\u5b8c\u6210\u9e22\u5c3e\u82b1\u5206\u7c7b\uff0c\u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305\uff1a # \u7ed8\u56fe import seaborn as sns # \u6570\u503c\u8ba1\u7b97 import numpy as np # sklearn\u4e2d\u7684\u76f8\u5173\u5de5\u5177 # \u5212\u5206\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6 from sklearn.model_selection import train_test_split # \u903b\u8f91\u56de\u5f52 from sklearn.linear_model import LogisticRegressionCV # tf.keras\u4e2d\u4f7f\u7528\u7684\u76f8\u5173\u5de5\u5177 # \u7528\u4e8e\u6a21\u578b\u642d\u5efa from tensorflow.keras.models import Sequential # \u6784\u5efa\u6a21\u578b\u7684\u5c42\u548c\u6fc0\u6d3b\u65b9\u6cd5 from tensorflow.keras.layers import Dense , Activation # \u6570\u636e\u5904\u7406\u7684\u8f85\u52a9\u5de5\u5177 from tensorflow.keras import utils","title":"1.\u76f8\u5173\u7684\u5e93\u7684\u5bfc\u5165"},{"location":"tensorFlow/section2/#2","text":"\u5229\u7528seborn\u5bfc\u5165\u76f8\u5173\u7684\u6570\u636e\uff0ciris\u6570\u636e\u4ee5dataFrame\u7684\u65b9\u5f0f\u5728seaborn\u8fdb\u884c\u5b58\u50a8\uff0c\u6211\u4eec\u8bfb\u53d6\u540e\u5e76\u8fdb\u884c\u5c55\u793a\uff1a # \u8bfb\u53d6\u6570\u636e iris = sns . load_dataset ( \"iris\" ) # \u5c55\u793a\u6570\u636e\u7684\u524d\u4e94\u884c iris . head () \u53e6\u5916\uff0c\u5229\u7528seaborn\u4e2dpairplot\u51fd\u6570\u63a2\u7d22\u6570\u636e\u7279\u5f81\u95f4\u7684\u5173\u7cfb\uff1a # \u5c06\u6570\u636e\u4e4b\u95f4\u7684\u5173\u7cfb\u8fdb\u884c\u53ef\u89c6\u5316 sns . pairplot ( iris , hue = 'species' ) \u5c06\u6570\u636e\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\uff1a\u4eceiris dataframe\u4e2d\u63d0\u53d6\u539f\u59cb\u6570\u636e\uff0c\u5c06\u82b1\u74e3\u548c\u843c\u7247\u6570\u636e\u4fdd\u5b58\u5728\u6570\u7ec4X\u4e2d\uff0c\u6807\u7b7e\u4fdd\u5b58\u5728\u76f8\u5e94\u7684\u6570\u7ec4y\u4e2d\uff1a # \u82b1\u74e3\u548c\u82b1\u843c\u7684\u6570\u636e X = iris . values [:, : 4 ] # \u6807\u7b7e\u503c y = iris . values [:, 4 ] \u5229\u7528train_test_split\u5b8c\u6210\u6570\u636e\u96c6\u5212\u5206\uff1a # \u5c06\u6570\u636e\u96c6\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6 train_X , test_X , train_y , test_y = train_test_split ( X , y , train_size = 0.5 , test_size = 0.5 , random_state = 0 ) \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u4f7f\u7528sklearn\u548ctf.keras\u6765\u5b8c\u6210\u9884\u6d4b","title":"2.\u6570\u636e\u5c55\u793a\u548c\u5212\u5206"},{"location":"tensorFlow/section2/#3sklearn","text":"\u5229\u7528\u903b\u8f91\u56de\u5f52\u7684\u5206\u7c7b\u5668\uff0c\u5e76\u4f7f\u7528\u4ea4\u53c9\u9a8c\u8bc1\u7684\u65b9\u6cd5\u6765\u9009\u62e9\u6700\u4f18\u7684\u8d85\u53c2\u6570\uff0c\u5b9e\u4f8b\u5316LogisticRegressionCV\u5206\u7c7b\u5668\uff0c\u5e76\u4f7f\u7528fit\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3\uff1a # \u5b9e\u4f8b\u5316\u5206\u7c7b\u5668 lr = LogisticRegressionCV () # \u8bad\u7ec3 lr . fit ( train_X , train_y ) \u5229\u7528\u8bad\u7ec3\u597d\u7684\u5206\u7c7b\u5668\u8fdb\u884c\u9884\u6d4b\uff0c\u5e76\u8ba1\u7b97\u51c6\u786e\u7387\uff1a # \u8ba1\u7b97\u51c6\u786e\u7387\u5e76\u8fdb\u884c\u6253\u5370 print ( \"Accuracy = {:.2f} \" . format ( lr . score ( test_X , test_y ))) \u903b\u8f91\u56de\u5f52\u7684\u51c6\u786e\u7387\u4e3a\uff1a Accuracy = 0.93","title":"3.sklearn\u5b9e\u73b0"},{"location":"tensorFlow/section2/#4tfkeras","text":"\u5728sklearn\u4e2d\u6211\u4eec\u53ea\u8981\u5b9e\u4f8b\u5316\u5206\u7c7b\u5668\u5e76\u5229\u7528fit\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3\uff0c\u6700\u540e\u8861\u91cf\u5b83\u7684\u6027\u80fd\u5c31\u53ef\u4ee5\u4e86\uff0c\u90a3\u5728tf.keras\u4e2d\u4e0e\u5728sklearn\u975e\u5e38\u76f8\u4f3c\uff0c\u4e0d\u540c\u7684\u662f\uff1a \u6784\u5efa\u5206\u7c7b\u5668\u65f6\u9700\u8981\u8fdb\u884c\u6a21\u578b\u642d\u5efa \u6570\u636e\u91c7\u96c6\u65f6\uff0csklearn\u53ef\u4ee5\u63a5\u6536\u5b57\u7b26\u4e32\u578b\u7684\u6807\u7b7e\uff0c\u5982\uff1a\u201csetosa\u201d\uff0c\u4f46\u662f\u5728tf.keras\u4e2d\u9700\u8981\u5bf9\u6807\u7b7e\u503c\u8fdb\u884c\u70ed\u7f16\u7801\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u6709\u5f88\u591a\u65b9\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u70ed\u7f16\u7801\uff0c\u6bd4\u5982pandas\u4e2d\u7684get_dummies(),\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528tf.keras\u4e2d\u7684\u65b9\u6cd5\u8fdb\u884c\u70ed\u7f16\u7801\uff1a # \u8fdb\u884c\u70ed\u7f16\u7801 def one_hot_encode_object_array ( arr ): # \u53bb\u91cd\u83b7\u53d6\u5168\u90e8\u7684\u7c7b\u522b uniques , ids = np . unique ( arr , return_inverse = True ) # \u8fd4\u56de\u70ed\u7f16\u7801\u7684\u7ed3\u679c return utils . to_categorical ( ids , len ( uniques ))","title":"4.tf.keras\u5b9e\u73b0"},{"location":"tensorFlow/section2/#41","text":"\u63a5\u4e0b\u6765\u5bf9\u6807\u7b7e\u503c\u8fdb\u884c\u70ed\u7f16\u7801\uff1a # \u8bad\u7ec3\u96c6\u70ed\u7f16\u7801 train_y_ohe = one_hot_encode_object_array ( train_y ) # \u6d4b\u8bd5\u96c6\u70ed\u7f16\u7801 test_y_ohe = one_hot_encode_object_array ( test_y )","title":"4.1 \u6570\u636e\u5904\u7406"},{"location":"tensorFlow/section2/#42","text":"\u5728sklearn\u4e2d\uff0c\u6a21\u578b\u90fd\u662f\u73b0\u6210\u7684\u3002tf.Keras\u662f\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u5e93,\u6211\u4eec\u9700\u8981\u6839\u636e\u6570\u636e\u548c\u6807\u7b7e\u503c\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u3002\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u53d1\u73b0\u7279\u5f81\u4e0e\u6807\u7b7e\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\u3002\u795e\u7ecf\u7f51\u7edc\u662f\u4e00\u4e2a\u9ad8\u5ea6\u7ed3\u6784\u5316\u7684\u56fe\uff0c\u5176\u4e2d\u5305\u542b\u4e00\u4e2a\u6216\u591a\u4e2a\u9690\u85cf\u5c42\u3002\u6bcf\u4e2a\u9690\u85cf\u5c42\u90fd\u5305\u542b\u4e00\u4e2a\u6216\u591a\u4e2a\u795e\u7ecf\u5143\u3002\u795e\u7ecf\u7f51\u7edc\u6709\u591a\u79cd\u7c7b\u522b\uff0c\u8be5\u7a0b\u5e8f\u4f7f\u7528\u7684\u662f\u5bc6\u96c6\u578b\u795e\u7ecf\u7f51\u7edc\uff0c\u4e5f\u79f0\u4e3a\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\uff1a\u4e00\u4e2a\u5c42\u4e2d\u7684\u795e\u7ecf\u5143\u5c06\u4ece\u4e0a\u4e00\u5c42\u4e2d\u7684\u6bcf\u4e2a\u795e\u7ecf\u5143\u83b7\u53d6\u8f93\u5165\u8fde\u63a5\u3002\u4f8b\u5982\uff0c\u56fe 2 \u663e\u793a\u4e86\u4e00\u4e2a\u5bc6\u96c6\u578b\u795e\u7ecf\u7f51\u7edc\uff0c\u5176\u4e2d\u5305\u542b 1 \u4e2a\u8f93\u5165\u5c42\u30012 \u4e2a\u9690\u85cf\u5c42\u4ee5\u53ca 1 \u4e2a\u8f93\u51fa\u5c42\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4e0a\u56fe \u4e2d\u7684\u6a21\u578b\u7ecf\u8fc7\u8bad\u7ec3\u5e76\u9988\u9001\u672a\u6807\u8bb0\u7684\u6837\u672c\u65f6\uff0c\u5b83\u4f1a\u4ea7\u751f 3 \u4e2a\u9884\u6d4b\u7ed3\u679c\uff1a\u76f8\u5e94\u9e22\u5c3e\u82b1\u5c5e\u4e8e\u6307\u5b9a\u54c1\u79cd\u7684\u53ef\u80fd\u6027\u3002\u5bf9\u4e8e\u8be5\u793a\u4f8b\uff0c\u8f93\u51fa\u9884\u6d4b\u7ed3\u679c\u7684\u603b\u548c\u662f 1.0\u3002\u8be5\u9884\u6d4b\u7ed3\u679c\u5206\u89e3\u5982\u4e0b\uff1a\u5c71\u9e22\u5c3e\u4e3a 0.02\uff0c\u53d8\u8272\u9e22\u5c3e\u4e3a 0.95\uff0c\u7ef4\u5409\u5c3c\u4e9a\u9e22\u5c3e\u4e3a 0.03\u3002\u8fd9\u610f\u5473\u7740\u8be5\u6a21\u578b\u9884\u6d4b\u67d0\u4e2a\u65e0\u6807\u7b7e\u9e22\u5c3e\u82b1\u6837\u672c\u662f\u53d8\u8272\u9e22\u5c3e\u7684\u6982\u7387\u4e3a 95\uff05\u3002 TensorFlow tf.keras API \u662f\u521b\u5efa\u6a21\u578b\u548c\u5c42\u7684\u9996\u9009\u65b9\u5f0f\u3002\u901a\u8fc7\u8be5 API\uff0c\u60a8\u53ef\u4ee5\u8f7b\u677e\u5730\u6784\u5efa\u6a21\u578b\u5e76\u8fdb\u884c\u5b9e\u9a8c\uff0c\u800c\u5c06\u6240\u6709\u90e8\u5206\u8fde\u63a5\u5728\u4e00\u8d77\u7684\u590d\u6742\u5de5\u4f5c\u5219\u7531 Keras \u5904\u7406\u3002 tf.keras.Sequential \u6a21\u578b\u662f\u5c42\u7684\u7ebf\u6027\u5806\u53e0\u3002\u8be5\u6a21\u578b\u7684\u6784\u9020\u51fd\u6570\u4f1a\u91c7\u7528\u4e00\u7cfb\u5217\u5c42\u5b9e\u4f8b\uff1b\u5728\u672c\u793a\u4f8b\u4e2d\uff0c\u91c7\u7528\u7684\u662f 2 \u4e2a\u5bc6\u96c6\u5c42\uff08\u5206\u522b\u5305\u542b 10 \u4e2a\u8282\u70b9\uff09\u4ee5\u53ca 1 \u4e2a\u8f93\u51fa\u5c42\uff08\u5305\u542b 3 \u4e2a\u4ee3\u8868\u6807\u7b7e\u9884\u6d4b\u7684\u8282\u70b9\uff09\u3002\u7b2c\u4e00\u4e2a\u5c42\u7684 input_shape \u53c2\u6570\u5bf9\u5e94\u8be5\u6570\u636e\u96c6\u4e2d\u7684\u7279\u5f81\u6570\u91cf\uff1a # \u5229\u7528sequential\u65b9\u5f0f\u6784\u5efa\u6a21\u578b model = Sequential ([ # \u9690\u85cf\u5c421\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu,\u8f93\u5165\u5927\u5c0f\u6709input_shape\u6307\u5b9a Dense ( 10 , activation = \"relu\" , input_shape = ( 4 ,)), # \u9690\u85cf\u5c422\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu Dense ( 10 , activation = \"relu\" ), # \u8f93\u51fa\u5c42 Dense ( 3 , activation = \"softmax\" ) ]) \u901a\u8fc7model.summary\u53ef\u4ee5\u67e5\u770b\u6a21\u578b\u7684\u67b6\u6784\uff1a Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 10) 50 _________________________________________________________________ dense_1 (Dense) (None, 10) 110 _________________________________________________________________ dense_2 (Dense) (None, 3) 33 ================================================================= Total params: 193 Trainable params: 193 Non-trainable params: 0 _________________________________________________________________ \u6fc0\u6d3b\u51fd\u6570\u53ef\u51b3\u5b9a\u5c42\u4e2d\u6bcf\u4e2a\u8282\u70b9\u7684\u8f93\u51fa\u5f62\u72b6\u3002\u8fd9\u4e9b\u975e\u7ebf\u6027\u5173\u7cfb\u5f88\u91cd\u8981\uff0c\u5982\u679c\u6ca1\u6709\u5b83\u4eec\uff0c\u6a21\u578b\u5c06\u7b49\u540c\u4e8e\u5355\u4e2a\u5c42\u3002\u6fc0\u6d3b\u51fd\u6570\u6709\u5f88\u591a\uff0c\u4f46\u9690\u85cf\u5c42\u901a\u5e38\u4f7f\u7528 ReLU\u3002 \u9690\u85cf\u5c42\u548c\u795e\u7ecf\u5143\u7684\u7406\u60f3\u6570\u91cf\u53d6\u51b3\u4e8e\u95ee\u9898\u548c\u6570\u636e\u96c6\u3002\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u591a\u4e2a\u65b9\u9762\u4e00\u6837\uff0c\u9009\u62e9\u6700\u4f73\u7684\u795e\u7ecf\u7f51\u7edc\u5f62\u72b6\u9700\u8981\u4e00\u5b9a\u7684\u77e5\u8bc6\u6c34\u5e73\u548c\u5b9e\u9a8c\u57fa\u7840\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u589e\u52a0\u9690\u85cf\u5c42\u548c\u795e\u7ecf\u5143\u7684\u6570\u91cf\u901a\u5e38\u4f1a\u4ea7\u751f\u66f4\u5f3a\u5927\u7684\u6a21\u578b\uff0c\u800c\u8fd9\u9700\u8981\u66f4\u591a\u6570\u636e\u624d\u80fd\u6709\u6548\u5730\u8fdb\u884c\u8bad\u7ec3\u3002","title":"4.2 \u6a21\u578b\u642d\u5efa"},{"location":"tensorFlow/section2/#43","text":"\u5728\u8bad\u7ec3\u548c\u8bc4\u4f30\u9636\u6bb5\uff0c\u6211\u4eec\u90fd\u9700\u8981\u8ba1\u7b97\u6a21\u578b\u7684\u635f\u5931\u3002\u8fd9\u6837\u53ef\u4ee5\u8861\u91cf\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\u4e0e\u9884\u671f\u6807\u7b7e\u6709\u591a\u5927\u504f\u5dee\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u6a21\u578b\u7684\u6548\u679c\u6709\u591a\u5dee\u3002\u6211\u4eec\u5e0c\u671b\u5c3d\u53ef\u80fd\u51cf\u5c0f\u6216\u4f18\u5316\u8fd9\u4e2a\u503c\uff0c\u6240\u4ee5\u6211\u4eec\u8bbe\u7f6e\u4f18\u5316\u7b56\u7565\u548c\u635f\u5931\u51fd\u6570\uff0c\u4ee5\u53ca\u6a21\u578b\u7cbe\u5ea6\u7684\u8ba1\u7b97\u65b9\u6cd5\uff1a # \u8bbe\u7f6e\u6a21\u578b\u7684\u76f8\u5173\u53c2\u6570\uff1a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 model . compile ( optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = [ \"accuracy\" ]) \u63a5\u4e0b\u6765\u4e0e\u5728sklearn\u4e2d\u76f8\u540c\uff0c\u5206\u522b\u8c03\u7528fit\u548cpredict\u65b9\u6cd5\u8fdb\u884c\u9884\u6d4b\u5373\u53ef\u3002 # \u6a21\u578b\u8bad\u7ec3\uff1aepochs,\u8bad\u7ec3\u6837\u672c\u9001\u5165\u5230\u7f51\u7edc\u4e2d\u7684\u6b21\u6570\uff0cbatch_size:\u6bcf\u6b21\u8bad\u7ec3\u7684\u9001\u5165\u5230\u7f51\u7edc\u4e2d\u7684\u6837\u672c\u4e2a\u6570 model . fit ( train_X , train_y_ohe , epochs = 10 , batch_size = 1 , verbose = 1 ); \u4e0a\u8ff0\u4ee3\u7801\u5b8c\u6210\u7684\u662f\uff1a \u8fed\u4ee3\u6bcf\u4e2aepoch\u3002\u901a\u8fc7\u4e00\u6b21\u6570\u636e\u96c6\u5373\u4e3a\u4e00\u4e2aepoch\u3002 \u5728\u4e00\u4e2aepoch\u4e2d\uff0c\u904d\u5386\u8bad\u7ec3 Dataset \u4e2d\u7684\u6bcf\u4e2a\u6837\u672c\uff0c\u5e76\u83b7\u53d6\u6837\u672c\u7684\u7279\u5f81 (x) \u548c\u6807\u7b7e (y)\u3002 \u6839\u636e\u6837\u672c\u7684\u7279\u5f81\u8fdb\u884c\u9884\u6d4b\uff0c\u5e76\u6bd4\u8f83\u9884\u6d4b\u7ed3\u679c\u548c\u6807\u7b7e\u3002\u8861\u91cf\u9884\u6d4b\u7ed3\u679c\u7684\u4e0d\u51c6\u786e\u6027\uff0c\u5e76\u4f7f\u7528\u6240\u5f97\u7684\u503c\u8ba1\u7b97\u6a21\u578b\u7684\u635f\u5931\u548c\u68af\u5ea6\u3002 \u4f7f\u7528 optimizer \u66f4\u65b0\u6a21\u578b\u7684\u53d8\u91cf\u3002 \u5bf9\u6bcf\u4e2aepoch\u91cd\u590d\u6267\u884c\u4ee5\u4e0a\u6b65\u9aa4\uff0c\u76f4\u5230\u6a21\u578b\u8bad\u7ec3\u5b8c\u6210\u3002 \u8bad\u7ec3\u8fc7\u7a0b\u5c55\u793a\u5982\u4e0b\uff1a Epoch 1/10 75/75 [==============================] - 0s 616us/step - loss: 0.0585 - accuracy: 0.9733 Epoch 2/10 75/75 [==============================] - 0s 535us/step - loss: 0.0541 - accuracy: 0.9867 Epoch 3/10 75/75 [==============================] - 0s 545us/step - loss: 0.0650 - accuracy: 0.9733 Epoch 4/10 75/75 [==============================] - 0s 542us/step - loss: 0.0865 - accuracy: 0.9733 Epoch 5/10 75/75 [==============================] - 0s 510us/step - loss: 0.0607 - accuracy: 0.9733 Epoch 6/10 75/75 [==============================] - 0s 659us/step - loss: 0.0735 - accuracy: 0.9733 Epoch 7/10 75/75 [==============================] - 0s 497us/step - loss: 0.0691 - accuracy: 0.9600 Epoch 8/10 75/75 [==============================] - 0s 497us/step - loss: 0.0724 - accuracy: 0.9733 Epoch 9/10 75/75 [==============================] - 0s 493us/step - loss: 0.0645 - accuracy: 0.9600 Epoch 10/10 75/75 [==============================] - 0s 482us/step - loss: 0.0660 - accuracy: 0.9867 \u4e0esklearn\u4e2d\u4e0d\u540c\uff0c\u5bf9\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u65f6\uff0c\u4e0esklearn.score\u65b9\u6cd5\u5bf9\u5e94\u7684\u662ftf.keras.evaluate()\u65b9\u6cd5\uff0c\u8fd4\u56de\u7684\u662f\u635f\u5931\u51fd\u6570\u548c\u5728compile\u6a21\u578b\u65f6\u8981\u6c42\u7684\u6307\u6807: # \u8ba1\u7b97\u6a21\u578b\u7684\u635f\u5931\u548c\u51c6\u786e\u7387 loss , accuracy = model . evaluate ( test_X , test_y_ohe , verbose = 1 ) print ( \"Accuracy = {:.2f} \" . format ( accuracy )) \u5206\u7c7b\u5668\u7684\u51c6\u786e\u7387\u4e3a\uff1a 3 / 3 [ ============================== ] - 0 s 591 us / step - loss : 0.1031 - accuracy : 0.9733 Accuracy = 0.97 \u5230\u6b64\u6211\u4eec\u5bf9tf.kears\u7684\u4f7f\u7528\u6709\u4e86\u4e00\u4e2a\u57fa\u672c\u7684\u8ba4\u77e5\uff0c\u5728\u63a5\u4e0b\u6765\u7684\u8bfe\u7a0b\u4e2d\u4f1a\u7ed9\u5927\u5bb6\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u4ee5\u53ca\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u5e38\u7528\u7684CNN\u7684\u4f7f\u7528\u3002 \u603b\u7ed3 1.\u4f7f\u7528tf.keras\u8fdb\u884c\u5206\u7c7b\u65f6\u7684\u4e3b\u8981\u6d41\u7a0b\uff1a \u6570\u636e\u5904\u7406-\u6784\u5efa\u6a21\u578b-\u6a21\u578b\u8bad\u7ec3-\u6a21\u578b\u9a8c\u8bc1 2.tf.keras\u4e2d\u6784\u5efa\u6a21\u578b\u53ef\u901a\u8fc7squential()\u6765\u5b9e\u73b0\u5e76\u5229\u7528.fit()\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3 3.\u4f7f\u7528evaluate()\u65b9\u6cd5\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u548c\u51c6\u786e\u7387","title":"4.3 \u6a21\u578b\u8bad\u7ec3\u548c\u9884\u6d4b"}]}