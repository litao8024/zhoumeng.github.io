{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"\u4f20\u667a\u6559\u80b2\u7684AI\u5f15\u9886IT\u6559\u80b2\u524d\u6cbf\uff0c\u7279\u6b64\u63a8\u51fa\u7ea2\u8718\u86db\u9879\u76ee\uff0c\u5e26\u9886\u540c\u5b66\u4eec\u5b8c\u6574\u7684\u5b66\u4e60\u77e5\u8bc6\u56fe\u8c31\u76f8\u5173\u6280\u672f\uff0c\u5e76\u624e\u5b9e\u7684\u638c\u63e1\u6838\u5fc3\u5185\u5bb9\u548c\u4ee3\u7801\u80fd\u529b\u3002","title":"Home"},{"location":"10_1.html","text":"\u7ea2\u8718\u86db\u67b6\u6784\u8bbe\u8ba1 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u7406\u89e3\u7ea2\u8718\u86db\u9879\u76ee\u7684\u67b6\u6784. \u638c\u63e1\u67b6\u6784\u8bbe\u8ba1\u7684\u601d\u60f3. \u9879\u76ee\u603b\u4f53\u67b6\u6784 \u00b6 \u7ea2\u8718\u86db\u4f5c\u4e3a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684AI\u533b\u7597\u52a9\u7406, \u53ef\u4ee5\u5177\u5907\u975e\u5e38\u4e30\u5bcc\u7684\u529f\u80fd, \u5f80\u5c0f\u578b\u5316\u53d1\u5c55, \u53ef\u4ee5\u4ec5\u4ec5\u652f\u6301\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u67e5\u8be2\u5b8c\u6210\u7b80\u5355\u56de\u590d; \u5f80\u5927\u578b\u5316\u53d1\u5c55, \u53ef\u4ee5\u652f\u6301\u591a\u8f6e\u5bf9\u8bdd\u7684\u72b6\u6001\u8ffd\u8e2a, \u53ef\u4ee5\u652f\u6301\u7c7b\u4f3cUnit\u673a\u5668\u4eba\u7684\u95f2\u804a\u529f\u80fd, \u53ef\u4ee5\u652f\u6301\u66f4\u5e7f\u6cdb\u7684\u610f\u56fe\u8bc6\u522b\u548c\u8bed\u4e49\u751f\u6210\u7b49. \u5f53\u524d\u9879\u76ee\u4f5c\u4e3aV1.0\u7248\u672c, \u91c7\u53d6\u5c11\u91cf\u529f\u80fd\u7684\u7b56\u7565, \u652f\u6301\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u67e5\u8be2\u5b8c\u6210\u9884\u5b9a\u4e49\u6a21\u677f\u7684\u56de\u590d\u529f\u80fd. \u67b6\u6784\u8bbe\u8ba1\u7684\u53d6\u820d\u4e4b\u9053 \u00b6 \u4ece\u672c\u8d28\u4e0a\u6765\u8bf4, \u5de5\u4e1a\u754c\u7684AI\u843d\u5730\u65e0\u6cd5\u5355\u72ec\u5b9e\u73b0, \u90fd\u662f\"\u9690\u85cf\u5728\u7cfb\u7edf\u80cc\u540e\", \u9ed8\u9ed8\u7684\u63d0\u4f9b\u4eba\u5de5\u667a\u80fd\u7684\u652f\u6301. \u6240\u4ee5\u53ef\u4ee5\u914d\u5408\u524d\u7aef\u5f00\u53d1, UI\u8bbe\u8ba1\u7b49, \u5171\u540c\u5b8c\u6210\u4e00\u4e2a\u5927\u578b\u5316\u7684\u9879\u76ee. \u4e3a\u4e86\u89c4\u907f\u524d\u7aef\u5f00\u53d1, UI\u8bbe\u8ba1\u7684\u590d\u6742\u6027, \u6211\u4eec\u4ec5\u8fdb\u884cAI\u529f\u80fd\u7684\u5f00\u53d1, \u6838\u5fc3\u805a\u7126\u5728\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u548c\u67e5\u8be2\u4e0a. \u5728AI\u533b\u7597\u9886\u57df, V1.0\u7248\u672c\u91c7\u53d6\u652f\u6301\u57fa\u4e8e(\u75be\u75c5, \u75c7\u72b6)\u7684\u67e5\u8be2, (\u75be\u75c5, \u63a8\u8350\u98df\u54c1)\u7684\u67e5\u8be2, (\u75be\u75c5, \u63a8\u8350\u836f\u54c1)\u7684\u67e5\u8be2, \u5373\u533b\u7597\u52a9\u7406\u7684\u6838\u5fc3\u529f\u80fd. \u672a\u6765\u5728V2.0\u7248\u672c\u4e2d, \u53ef\u4ee5\u5c1d\u8bd5\u8003\u8651\u52a0\u5165(\u75be\u75c5, \u7981\u5fcc\u98df\u7269), (\u75be\u75c5, \u5982\u4f55\u9884\u9632), (\u75c7\u72b6, \u5408\u7406\u81b3\u98df), (\u75c7\u72b6, \u6062\u590d\u5468\u671f), (\u75be\u75c5, \u533b\u4fdd\u62a5\u9500)\u7b49\u7b49\u66f4\u591a\u7684\u529f\u80fd. \u4e3a\u4e86\u5b8c\u6210V1.0\u7248\u672c\u7684\u529f\u80fd, \u9700\u8981\u7cfb\u7edf\u5177\u5907\u7528\u6237\u95ee\u53e5\u7684\u5206\u7c7b\u80fd\u529b, \u7528\u6237\u95ee\u53e5\u7684\u89e3\u6790\u80fd\u529b, \u7b54\u6848\u7684\u77e5\u8bc6\u56fe\u8c31\u641c\u7d22\u80fd\u529b, \u56de\u590d\u6a21\u677f\u7684\u7ec4\u88c5\u80fd\u529b\u7b49. \u540e\u7eed\u5c06\u5206\u522b\u8fdb\u884c\u4ee3\u7801\u51fd\u6570\u7684\u529f\u80fd\u7f16\u5199, \u6bcf\u4e00\u4e2a\u4ee3\u7801\u6a21\u5757\u5b8c\u6210\u5355\u4e00\u529f\u80fd. \u4f8b\u5982: \u5173\u4e8e\u7528\u6237\u95ee\u53e5\u7684\u5206\u7c7b\u80fd\u529b, \u53ef\u4ee5\u6709\u4e24\u79cd\u7b56\u7565, \u4e00\u79cd\u662f\u6a21\u578b\u6d3e, \u4e00\u79cd\u662f\u89c4\u5219\u6d3e. \u90a3\u6211\u4eec\u5e94\u8be5\u600e\u4e48\u529e\u5462? \u4f8b\u5982: \u5173\u4e8e\u7528\u6237\u95ee\u53e5\u7684\u89e3\u6790\u80fd\u529b, \u53ef\u4ee5\u6709\u4e24\u79cd\u7b56\u7565, \u4e00\u79cd\u662f\u786c\u89e3\u6790, \u4e00\u79cd\u662f\u8f6f\u89e3\u6790. \u90a3\u6211\u4eec\u5e94\u8be5\u600e\u4e48\u529e\u5462? \u4f8b\u5982: \u7b54\u6848\u7684\u77e5\u8bc6\u56fe\u8c31\u641c\u7d22\u80fd\u529b, \u53ef\u4ee5\u6709\u4e24\u79cd\u7b56\u7565, \u4e00\u79cd\u662f\u5355\u6b65\u641c\u7d22, \u4e00\u79cd\u662f\u591a\u6b65\u641c\u7d22. \u90a3\u6211\u4eec\u5e94\u8be5\u600e\u4e48\u529e\u5462? \u5c0f\u8282\u603b\u7ed3 \u00b6 \u901a\u8fc7\u5bf9\u591a\u79cd\u7b56\u7565\u7684\u5206\u6790, \u878d\u5408, \u8003\u8651\u6570\u636e\u6210\u672c, \u7814\u53d1\u6210\u672c, \u4ea7\u54c1\u7b56\u7565\u7b49, \u7efc\u5408\u51b3\u5b9a\u5404\u79cd\u6280\u672f\u9009\u578b\u548c\u7b56\u7565, \u624d\u80fd\u5bf9\u9879\u76ee\u7684\u7814\u53d1\u8fdb\u884c\u5b9a\u7248.","title":"10.1 \u603b\u4f53\u8bbe\u8ba1\u65b9\u6848"},{"location":"10_1.html#_1","text":"","title":"\u7ea2\u8718\u86db\u67b6\u6784\u8bbe\u8ba1"},{"location":"10_1.html#_2","text":"\u7406\u89e3\u7ea2\u8718\u86db\u9879\u76ee\u7684\u67b6\u6784. \u638c\u63e1\u67b6\u6784\u8bbe\u8ba1\u7684\u601d\u60f3.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"10_1.html#_3","text":"\u7ea2\u8718\u86db\u4f5c\u4e3a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684AI\u533b\u7597\u52a9\u7406, \u53ef\u4ee5\u5177\u5907\u975e\u5e38\u4e30\u5bcc\u7684\u529f\u80fd, \u5f80\u5c0f\u578b\u5316\u53d1\u5c55, \u53ef\u4ee5\u4ec5\u4ec5\u652f\u6301\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u67e5\u8be2\u5b8c\u6210\u7b80\u5355\u56de\u590d; \u5f80\u5927\u578b\u5316\u53d1\u5c55, \u53ef\u4ee5\u652f\u6301\u591a\u8f6e\u5bf9\u8bdd\u7684\u72b6\u6001\u8ffd\u8e2a, \u53ef\u4ee5\u652f\u6301\u7c7b\u4f3cUnit\u673a\u5668\u4eba\u7684\u95f2\u804a\u529f\u80fd, \u53ef\u4ee5\u652f\u6301\u66f4\u5e7f\u6cdb\u7684\u610f\u56fe\u8bc6\u522b\u548c\u8bed\u4e49\u751f\u6210\u7b49. \u5f53\u524d\u9879\u76ee\u4f5c\u4e3aV1.0\u7248\u672c, \u91c7\u53d6\u5c11\u91cf\u529f\u80fd\u7684\u7b56\u7565, \u652f\u6301\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u67e5\u8be2\u5b8c\u6210\u9884\u5b9a\u4e49\u6a21\u677f\u7684\u56de\u590d\u529f\u80fd.","title":"\u9879\u76ee\u603b\u4f53\u67b6\u6784"},{"location":"10_1.html#_4","text":"\u4ece\u672c\u8d28\u4e0a\u6765\u8bf4, \u5de5\u4e1a\u754c\u7684AI\u843d\u5730\u65e0\u6cd5\u5355\u72ec\u5b9e\u73b0, \u90fd\u662f\"\u9690\u85cf\u5728\u7cfb\u7edf\u80cc\u540e\", \u9ed8\u9ed8\u7684\u63d0\u4f9b\u4eba\u5de5\u667a\u80fd\u7684\u652f\u6301. \u6240\u4ee5\u53ef\u4ee5\u914d\u5408\u524d\u7aef\u5f00\u53d1, UI\u8bbe\u8ba1\u7b49, \u5171\u540c\u5b8c\u6210\u4e00\u4e2a\u5927\u578b\u5316\u7684\u9879\u76ee. \u4e3a\u4e86\u89c4\u907f\u524d\u7aef\u5f00\u53d1, UI\u8bbe\u8ba1\u7684\u590d\u6742\u6027, \u6211\u4eec\u4ec5\u8fdb\u884cAI\u529f\u80fd\u7684\u5f00\u53d1, \u6838\u5fc3\u805a\u7126\u5728\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u548c\u67e5\u8be2\u4e0a. \u5728AI\u533b\u7597\u9886\u57df, V1.0\u7248\u672c\u91c7\u53d6\u652f\u6301\u57fa\u4e8e(\u75be\u75c5, \u75c7\u72b6)\u7684\u67e5\u8be2, (\u75be\u75c5, \u63a8\u8350\u98df\u54c1)\u7684\u67e5\u8be2, (\u75be\u75c5, \u63a8\u8350\u836f\u54c1)\u7684\u67e5\u8be2, \u5373\u533b\u7597\u52a9\u7406\u7684\u6838\u5fc3\u529f\u80fd. \u672a\u6765\u5728V2.0\u7248\u672c\u4e2d, \u53ef\u4ee5\u5c1d\u8bd5\u8003\u8651\u52a0\u5165(\u75be\u75c5, \u7981\u5fcc\u98df\u7269), (\u75be\u75c5, \u5982\u4f55\u9884\u9632), (\u75c7\u72b6, \u5408\u7406\u81b3\u98df), (\u75c7\u72b6, \u6062\u590d\u5468\u671f), (\u75be\u75c5, \u533b\u4fdd\u62a5\u9500)\u7b49\u7b49\u66f4\u591a\u7684\u529f\u80fd. \u4e3a\u4e86\u5b8c\u6210V1.0\u7248\u672c\u7684\u529f\u80fd, \u9700\u8981\u7cfb\u7edf\u5177\u5907\u7528\u6237\u95ee\u53e5\u7684\u5206\u7c7b\u80fd\u529b, \u7528\u6237\u95ee\u53e5\u7684\u89e3\u6790\u80fd\u529b, \u7b54\u6848\u7684\u77e5\u8bc6\u56fe\u8c31\u641c\u7d22\u80fd\u529b, \u56de\u590d\u6a21\u677f\u7684\u7ec4\u88c5\u80fd\u529b\u7b49. \u540e\u7eed\u5c06\u5206\u522b\u8fdb\u884c\u4ee3\u7801\u51fd\u6570\u7684\u529f\u80fd\u7f16\u5199, \u6bcf\u4e00\u4e2a\u4ee3\u7801\u6a21\u5757\u5b8c\u6210\u5355\u4e00\u529f\u80fd. \u4f8b\u5982: \u5173\u4e8e\u7528\u6237\u95ee\u53e5\u7684\u5206\u7c7b\u80fd\u529b, \u53ef\u4ee5\u6709\u4e24\u79cd\u7b56\u7565, \u4e00\u79cd\u662f\u6a21\u578b\u6d3e, \u4e00\u79cd\u662f\u89c4\u5219\u6d3e. \u90a3\u6211\u4eec\u5e94\u8be5\u600e\u4e48\u529e\u5462? \u4f8b\u5982: \u5173\u4e8e\u7528\u6237\u95ee\u53e5\u7684\u89e3\u6790\u80fd\u529b, \u53ef\u4ee5\u6709\u4e24\u79cd\u7b56\u7565, \u4e00\u79cd\u662f\u786c\u89e3\u6790, \u4e00\u79cd\u662f\u8f6f\u89e3\u6790. \u90a3\u6211\u4eec\u5e94\u8be5\u600e\u4e48\u529e\u5462? \u4f8b\u5982: \u7b54\u6848\u7684\u77e5\u8bc6\u56fe\u8c31\u641c\u7d22\u80fd\u529b, \u53ef\u4ee5\u6709\u4e24\u79cd\u7b56\u7565, \u4e00\u79cd\u662f\u5355\u6b65\u641c\u7d22, \u4e00\u79cd\u662f\u591a\u6b65\u641c\u7d22. \u90a3\u6211\u4eec\u5e94\u8be5\u600e\u4e48\u529e\u5462?","title":"\u67b6\u6784\u8bbe\u8ba1\u7684\u53d6\u820d\u4e4b\u9053"},{"location":"10_1.html#_5","text":"\u901a\u8fc7\u5bf9\u591a\u79cd\u7b56\u7565\u7684\u5206\u6790, \u878d\u5408, \u8003\u8651\u6570\u636e\u6210\u672c, \u7814\u53d1\u6210\u672c, \u4ea7\u54c1\u7b56\u7565\u7b49, \u7efc\u5408\u51b3\u5b9a\u5404\u79cd\u6280\u672f\u9009\u578b\u548c\u7b56\u7565, \u624d\u80fd\u5bf9\u9879\u76ee\u7684\u7814\u53d1\u8fdb\u884c\u5b9a\u7248.","title":"\u5c0f\u8282\u603b\u7ed3"},{"location":"10_2.html","text":"\u7ea2\u8718\u86db\u642d\u5efa\u5168\u6d41\u7a0b \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u7406\u89e3\u7ea2\u8718\u86db\u76f8\u5173\u6a21\u5757\u7684\u8bbe\u8ba1\u601d\u8def. \u638c\u63e1\u7ea2\u8718\u86db\u673a\u5668\u4eba\u7684\u4ee3\u7801\u5b9e\u73b0. \u56fe\u8c31\u6570\u636e\u6784\u5efa \u00b6 \u7ea2\u8718\u86db\u673a\u5668\u4eba\u7684\u642d\u5efa, \u9996\u8981\u4efb\u52a1\u5c31\u662f\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31, \u56fe\u8c31\u8d8a\u4e30\u5bcc, \u5185\u5bb9\u8d8a\u8be6\u5b9e, \u672a\u6765\u7ea2\u8718\u86db\u80fd\u5bf9\u5916\u63d0\u4f9b\u7684\u670d\u52a1\u5c31\u8d8a\u4f18\u8d28. \u603b\u4f53\u6765\u8bf4, \u5728\u6b64\u9009\u5b9aneo4j\u4f5c\u4e3a\u9879\u76ee\u7684\u56fe\u6570\u636e\u5e93, \u914d\u7f6e\u4fe1\u606f\u5982\u4e0b: /home/ec2-user/knowledge_graph/red_spider/config.py NEO4J_CONFIG = { \"uri\" : \"bolt://0.0.0.0:7687\" , \"auth\" : ( \"neo4j\" , \"neo4j\" ), \"encrypted\" : False } \u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u7684\u4ee3\u7801\u8def\u5f84: /home/ec2-user/knowledge_graph/red_spider/build_medicalgraph.py import os import json from neo4j import GraphDatabase from config import NEO4J_CONFIG # \u77e5\u8bc6\u56fe\u8c31\u4e3b\u7c7b class MedicalGraph : def __init__ ( self ): cur_dir = '/' . join ( os . path . abspath ( __file__ ) . split ( '/' )[: - 1 ]) self . data_path = os . path . join ( cur_dir , 'data/temp.json' ) # \u8bfb\u53d6\u6587\u4ef6 def read_nodes ( self ): # \u51714\u7c7b\u8282\u70b9 drugs = [] # \u836f\u54c1 foods = [] # \u98df\u7269 diseases = [] # \u75be\u75c5 symptoms = [] # \u75c7\u72b6 # \u6784\u5efa\u8282\u70b9\u5b9e\u4f53\u5173\u7cfb rels_recommandeat = [] # \u75be\u75c5-\u63a8\u8350\u5403\u98df\u7269\u5173\u7cfb rels_recommanddrug = [] # \u75be\u75c5-\u63a8\u8350\u836f\u54c1\u5173\u7cfb rels_symptom = [] # \u75be\u75c5-\u75c7\u72b6\u5173\u7cfb count = 0 for data in open ( self . data_path ): disease_dict = {} count += 1 if count % 10 == 0 : print ( 'count = ' , count ) # \u5f53\u524dV1.0\u7248\u672c\u4ec5\u652f\u6301\u75be\u75c5\u75c7\u72b6, \u836f\u54c1, \u98df\u54c1\u7684\u76f8\u5173\u54a8\u8be2 data_json = json . loads ( data ) disease = data_json [ 'name' ] diseases . append ( disease ) if 'symptom' in data_json : symptoms += data_json [ 'symptom' ] for symptom in data_json [ 'symptom' ]: rels_symptom . append ([ disease , symptom ]) if 'recommand_drug' in data_json : recommand_drug = data_json [ 'recommand_drug' ] drugs += recommand_drug for drug in recommand_drug : rels_recommanddrug . append ([ disease , drug ]) if 'recommand_eat' in data_json : recommand_eat = data_json [ 'recommand_eat' ] for _recommand in recommand_eat : rels_recommandeat . append ([ disease , _recommand ]) foods += recommand_eat return set ( drugs ), set ( foods ), set ( symptoms ), set ( diseases ), rels_recommandeat , rels_recommanddrug , rels_symptom # \u521b\u5efa\u77e5\u8bc6\u56fe\u8c31\u75be\u75c5\u76f8\u5173\u7684\u8282\u70b9, \u75be\u75c5, \u75c7\u72b6, \u836f\u54c1, \u98df\u54c1 def create_graphnodes_and_graphrels ( self ): Drugs , Foods , Symptoms , Diseases , rels_recommandeat , rels_recommanddrug , rels_symptom = self . read_nodes () # \u6253\u5370\u76f8\u5173\u6570\u636e\u7684\u6761\u6570 print ( 'Drugs:' , len ( Drugs )) print ( 'Foods:' , len ( Foods )) print ( 'Symptoms:' , len ( Symptoms )) print ( 'Diseases:' , len ( Diseases )) print ( 'rels_recommandeat:' , len ( rels_recommandeat )) print ( 'rels_recommanddrug:' , len ( rels_recommanddrug )) print ( 'rels_symptom:' , len ( rels_symptom )) # \u5b9e\u4f8b\u5316\u56fe\u6570\u636e\u5e93\u9a71\u52a8\u5668\u5bf9\u8c61 driver = GraphDatabase . driver ( ** NEO4J_CONFIG ) with driver . session () as session : # \u521b\u5efa\u4e2d\u5fc3\u75be\u75c5\u7684\u77e5\u8bc6\u56fe\u8c31\u8282\u70b9 print ( '\u5f00\u59cb\u521b\u5efa\u4e2d\u5fc3\u75be\u75c5\u8282\u70b9......' ) for d in Diseases : cypher = \"MERGE (a:Disease{name: %r }) RETURN a\" % d session . run ( cypher ) # \u521b\u5efa\"\u836f\u54c1\", \"\u98df\u54c1\", \"\u75c7\u72b6\"\u7684\u77e5\u8bc6\u56fe\u8c31\u8282\u70b9, V1.0\u7248\u672c\u53ea\u63d0\u4f9b\u8fd93\u79cd\u95ee\u8bca\u4fe1\u606f print ( '\u5f00\u59cb\u521b\u5efa\u836f\u54c1\u8282\u70b9Drug......' ) for n in Drugs : cypher = \"MERGE (a:Drug{name: %r }) RETURN a\" % n session . run ( cypher ) print ( '\u5f00\u59cb\u521b\u5efa\u98df\u54c1\u8282\u70b9Food......' ) for n in Foods : cypher = \"MERGE (a:Food{name: %r }) RETURN a\" % n session . run ( cypher ) print ( '\u5f00\u59cb\u521b\u5efa\u75c7\u72b6\u8282\u70b9Symptom......' ) for n in Symptoms : cypher = \"MERGE (a:Symptom{name: %r }) RETURN a\" % n session . run ( cypher ) # \u521b\u5efa\u5b9e\u4f53\u5173\u7cfb\u8fb9, V1.0\u7248\u672c\u4ec5\u652f\u63013\u79cd\u5173\u7cfb\u7684\u67e5\u8be2 self . create_relationship ( 'Disease' , 'Food' , rels_recommandeat , 'recommand_eat' , '\u63a8\u8350\u98df\u8c31' ) self . create_relationship ( 'Disease' , 'Drug' , rels_recommanddrug , 'recommand_drug' , '\u63a8\u8350\u836f\u54c1' ) self . create_relationship ( 'Disease' , 'Symptom' , rels_symptom , 'has_symptom' , '\u75c7\u72b6' ) # \u521b\u5efa\u5b9e\u4f53\u5173\u8054\u8fb9 def create_relationship ( self , start_node , end_node , edges , rel_type , rel_name ): # \u5173\u7cfb\u7684\u53bb\u91cd\u5904\u7406 set_edges = [] for edge in edges : set_edges . append ( '###' . join ( edge )) num_edges = len ( set ( set_edges )) print ( 'num_edges = ' , num_edges ) # \u5b9e\u4f8b\u5316\u56fe\u6570\u636e\u5e93\u9a71\u52a8\u5668\u5bf9\u8c61 driver = GraphDatabase . driver ( ** NEO4J_CONFIG ) with driver . session () as session : for edge in set ( set_edges ): edge = edge . split ( '###' ) p = edge [ 0 ] q = edge [ 1 ] # \u9501\u5b9a\u8282\u70b9\u548c\u5173\u7cfb, \u8fdb\u884c\u4e09\u5143\u7ec4\u7684\u521b\u5efa cypher = \"match(p: %s ), (q: %s ) where p.name=' %s 'and q.name=' %s ' create (p)-[rel: %s {name:' %s '}]->(q)\" % ( start_node , end_node , p , q , rel_type , rel_name ) try : session . run ( cypher ) except Exception as e : print ( e ) return if __name__ == '__main__' : mg = MedicalGraph () print ( '\u521b\u5efa\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u8282\u70b9\u548c\u5173\u7cfb......' ) mg . create_graphnodes_and_graphrels () \u8c03\u7528: python build_medicalgraph.py \u8f93\u51fa\u7ed3\u679c: \u521b\u5efa\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u8282\u70b9\u548c\u5173\u7cfb...... count = 10 count = 20 count = 30 count = 40 count = 50 count = 60 count = 70 count = 80 count = 90 count = 100 Drugs: 320 Foods: 283 Symptoms: 314 Diseases: 100 rels_recommandeat: 553 rels_recommanddrug: 675 rels_symptom: 748 \u5f00\u59cb\u521b\u5efa\u4e2d\u5fc3\u75be\u75c5\u8282\u70b9...... \u5f00\u59cb\u521b\u5efa\u836f\u54c1\u8282\u70b9Drug...... \u5f00\u59cb\u521b\u5efa\u98df\u54c1\u8282\u70b9Food...... \u5f00\u59cb\u521b\u5efa\u75c7\u72b6\u8282\u70b9Symptom...... num_edges = 553 num_edges = 675 num_edges = 748 \u5c55\u793aneo4j\u56fe\u6570\u636e\u5e93\u7684\u6570\u636e: \u95ee\u9898\u5206\u7c7b\u4e0e\u7b54\u6848\u641c\u7d22 \u00b6 \u6784\u5efa\u597d\u77e5\u8bc6\u56fe\u8c31\u540e, \u6211\u4eec\u8981\u642d\u5efa\u4e00\u4e2a\u7b80\u5355\u7684\u57fa\u4e8e\u89c4\u5219\u6d3e\u7684\u7ea2\u8718\u86db\u5bf9\u8bdd\u673a\u5668\u4eba, \u9700\u8981\u5b8c\u62103\u4e2a\u5b50\u529f\u80fd: \u95ee\u9898\u5206\u7c7b\u5b50\u4efb\u52a1 \u95ee\u9898\u89e3\u6790\u5b50\u4efb\u52a1 \u7b54\u6848\u641c\u7d22\u5b50\u4efb\u52a1 \u95ee\u9898\u5206\u7c7b\u5b50\u4efb\u52a1 \u00b6 \u5bf9\u4e8e\u7528\u6237\u7684\u4efb\u610f\u95ee\u53e5, \u5c06\u5176\u5206\u7c7b\u5230\u7ea2\u8718\u86db\u53ef\u4ee5\u652f\u6301\u56de\u7b54\u7684\u82e5\u5e72\u5b50\u7c7b\u4e2d, \u6709\u5229\u4e8e\u540e\u7eed\u67e5\u8be2\u548c\u56de\u7b54\u6a21\u677f\u7684\u7f16\u5199. \u4ee3\u7801\u8def\u5f84: /home/ec2-user/knowledge_graph/red_spider/question_classifier.py import os import ahocorasick class QuestionClassifier : def __init__ ( self ): cur_dir = '/' . join ( os . path . abspath ( __file__ ) . split ( '/' )[: - 1 ]) #\u3000\u7279\u5f81\u8bcd\u8def\u5f84 self . disease_path = os . path . join ( cur_dir , 'dict/disease.txt' ) self . drug_path = os . path . join ( cur_dir , 'dict/drug.txt' ) self . food_path = os . path . join ( cur_dir , 'dict/food.txt' ) self . symptom_path = os . path . join ( cur_dir , 'dict/symptom.txt' ) # \u52a0\u8f7d\u7279\u5f81\u8bcd self . disease_words = [ i . strip () for i in open ( self . disease_path ) if i . strip ()] self . drug_words = [ i . strip () for i in open ( self . drug_path ) if i . strip ()] self . food_words = [ i . strip () for i in open ( self . food_path ) if i . strip ()] self . symptom_words = [ i . strip () for i in open ( self . symptom_path ) if i . strip ()] self . region_words = set ( self . disease_words + self . drug_words + self . food_words + self . symptom_words ) # \u6784\u9020\u9886\u57dfactree, \u53ef\u4ee5\u52a0\u901f\u5173\u952e\u8bcd\u5339\u914d\u67e5\u627e self . region_tree = self . build_actree ( list ( self . region_words )) # \u6784\u5efa\u8bcd\u5178 self . wdtype_dict = self . build_wdtype_dict () # \u95ee\u53e5\u7591\u95ee\u8bcd, V1.0\u7248\u672c\u4ec5\u652f\u6301\u75c7\u72b6, \u98df\u54c1, \u836f\u54c1\u7684\u67e5\u8be2. self . symptom_request = [ '\u75c7\u72b6' , '\u8868\u5f81' , '\u73b0\u8c61' , '\u75c7\u5019' , '\u8868\u73b0' ] self . food_request = [ '\u996e\u98df' , '\u996e\u7528' , '\u5403' , '\u98df' , '\u4f19\u98df' , '\u81b3\u98df' , '\u559d' , '\u83dc' , '\u5fcc\u53e3' , '\u8865\u54c1' , '\u4fdd\u5065\u54c1' , '\u98df\u8c31' , '\u83dc\u8c31' , '\u98df\u7528' , '\u98df\u7269' , '\u8865\u54c1' ] self . drug_request = [ '\u836f' , '\u836f\u54c1' , '\u7528\u836f' , '\u80f6\u56ca' , '\u53e3\u670d\u6db2' , '\u708e\u7247' ] print ( 'model init finished ......' ) # \u5206\u7c7b\u4e3b\u51fd\u6570 def classify ( self , question ): data = {} medical_dict = self . check_medical ( question ) if not medical_dict : return {} data [ 'args' ] = medical_dict # \u6536\u96c6\u95ee\u53e5\u5f53\u4e2d\u6240\u6d89\u53ca\u5230\u7684\u5b9e\u4f53\u7c7b\u578b types = [] for type_ in medical_dict . values (): types += type_ question_type = 'others' question_types = [] # \u75c7\u72b6 if self . check_words ( self . symptom_request , question ) and ( 'disease' in types ): question_type = 'disease_symptom' question_types . append ( question_type ) # \u63a8\u8350\u98df\u54c1 if self . check_words ( self . food_request , question ) and ( 'disease' in types ): question_type = 'disease_food' question_types . append ( question_type ) # \u63a8\u8350\u836f\u54c1 if self . check_words ( self . drug_request , question ) and ( 'disease' in types ): question_type = 'disease_drug' question_types . append ( question_type ) # \u82e5\u6ca1\u6709\u67e5\u5230\u76f8\u5173\u7684\u5916\u90e8\u67e5\u8be2\u4fe1\u606f\uff0c\u90a3\u4e48\u5219\u5c06\u8be5\u75be\u75c5\u7684\u63cf\u8ff0\u4fe1\u606f\u8fd4\u56de if question_types == [] and 'symptom' in types : question_types = [ 'disease_symptom' ] # \u5c06\u591a\u4e2a\u5206\u7c7b\u7ed3\u679c\u8fdb\u884c\u5408\u5e76\u5904\u7406\uff0c\u7ec4\u88c5\u6210\u4e00\u4e2a\u5b57\u5178 data [ 'question_types' ] = question_types return data # \u6784\u9020\u5173\u952e\u8bcd\u5bf9\u5e94\u7684\u8282\u70b9\u7c7b\u578b def build_wdtype_dict ( self ): word_dict = dict () for word in self . region_words : word_dict [ word ] = [] # \u68c0\u67e5\u662f\u5426\u6709\u75be\u75c5\u5173\u952e\u8bcd if word in self . disease_words : word_dict [ word ] . append ( 'disease' ) # \u68c0\u67e5\u662f\u5426\u6709\u836f\u54c1\u5173\u952e\u8bcd if word in self . drug_words : word_dict [ word ] . append ( 'drug' ) # \u68c0\u67e5\u662f\u5426\u6709\u98df\u54c1\u5173\u952e\u8bcd if word in self . food_words : word_dict [ word ] . append ( 'food' ) # \u68c0\u67e5\u662f\u5426\u6709\u75c7\u72b6\u5173\u952e\u8bcd if word in self . symptom_words : word_dict [ word ] . append ( 'symptom' ) return word_dict # \u6784\u9020actree\u52a0\u901f\u8fc7\u6ee4 def build_actree ( self , wordlist ): actree = ahocorasick . Automaton () for index , word in enumerate ( wordlist ): actree . add_word ( word , ( index , word )) actree . make_automaton () return actree # \u95ee\u53e5\u68c0\u67e5 def check_medical ( self , question ): region_words = [] # \u5229\u7528AcTree\u52a0\u901f\u67e5\u8be2\u5173\u952e\u8bcd for i in self . region_tree . iter ( question ): word = i [ 1 ][ 1 ] region_words . append ( word ) stop_words = [] # \u5b50\u8bcd\u8fdb\u5165\u505c\u7528\u8bcd\u8868 for word1 in region_words : for word2 in region_words : if word1 in word2 and word1 != word2 : stop_words . append ( word1 ) final_words = [ i for i in region_words if i not in stop_words ] final_dict = { i : self . wdtype_dict . get ( i ) for i in final_words } return final_dict # \u57fa\u4e8e\u7279\u5f81\u8bcd\u8fdb\u884c\u95ee\u53e5\u68c0\u6d4b, \u5e76\u8fdb\u884c\u95ee\u53e5\u7c7b\u578b\u7684\u89c4\u5219\u5206\u7c7b def check_words ( self , words , sent ): for word in words : if word in sent : return True return False if __name__ == '__main__' : qc = QuestionClassifier () while True : question = input ( 'input an question:' ) data = qc . classify ( question ) print ( data ) \u8c03\u7528: python question_classifier.py \u8f93\u51fa\u7ed3\u679c: input an question:\u8eab\u4f53\u53d1\u70ed\u6076\u5fc3\u5e94\u8be5\u5403\u4ec0\u4e48? {'args': {'\u6076\u5fc3': ['symptom']}, 'question_types': ['disease_symptom']} input an question:Q {} \u95ee\u9898\u89e3\u6790\u5b50\u4efb\u52a1 \u00b6 \u5bf9\u4e8e\u7528\u6237\u7684\u4efb\u610f\u95ee\u53e5, \u7ecf\u8fc7\u4e0a\u4e00\u6b65\u9aa4\u8fdb\u884c\u5206\u7c7b\u540e, \u5df2\u7ecf\u5f97\u5230\u4e86\u95ee\u9898\u7684\u5206\u7c7b\u6807\u7b7e, \u63a5\u4e0b\u6765\u8981\u5bf9\u75c7\u72b6, \u98df\u54c1, \u836f\u54c1\u8fdb\u884cneo4j\u67e5\u8be2\u7684cypher\u8bed\u53e5\u7ec4\u88c5\u548c\u89e3\u6790. \u4ee3\u7801\u8def\u5f84: /home/ec2-user/knowledge_graph/red_spider/question_parser.py class QuestionPaser : # \u6784\u5efa\u5b9e\u4f53\u8282\u70b9 def build_entitydict ( self , args ): entity_dict = {} for arg , types in args . items (): for type in types : if type not in entity_dict : entity_dict [ type ] = [ arg ] else : entity_dict [ type ] . append ( arg ) return entity_dict # \u89e3\u6790\u4e3b\u51fd\u6570 def parser_main ( self , res_classify ): args = res_classify [ 'args' ] entity_dict = self . build_entitydict ( args ) question_types = res_classify [ 'question_types' ] sqls = [] for question_type in question_types : sql_ = {} sql_ [ 'question_type' ] = question_type sql = [] # \u6309\u7167\u4e0d\u540c\u7684\u5206\u7c7b\u7ed3\u679c, \u7ec4\u88c5\u4e0d\u540c\u7684cypher\u67e5\u8be2\u8bed\u53e5 if question_type == 'disease_symptom' : sql = self . sql_transfer ( question_type , entity_dict . get ( 'disease' )) elif question_type == 'disease_food' : sql = self . sql_transfer ( question_type , entity_dict . get ( 'disease' )) elif question_type == 'disease_drug' : sql = self . sql_transfer ( question_type , entity_dict . get ( 'disease' )) if sql : sql_ [ 'sql' ] = sql sqls . append ( sql_ ) return sqls # \u9488\u5bf9\u4e0d\u540c\u7684\u95ee\u9898\uff0c\u5206\u5f00\u8fdb\u884c\u5904\u7406 def sql_transfer ( self , question_type , entities ): if not entities : return [] # \u67e5\u8be2\u8bed\u53e5 sql = [] # \u67e5\u8be2\u75be\u75c5\u6709\u54ea\u4e9b\u75c7\u72b6 if question_type == 'disease_symptom' : sql = [ \"MATCH (m:Disease)-[r:has_symptom]->(n:Symptom) where m.name = ' {0} ' return m.name, r.name, n.name\" . format ( i ) for i in entities ] # \u67e5\u8be2\u75be\u75c5\u5efa\u8bae\u5403\u7684\u4e1c\u897f elif question_type == 'disease_food' : sql = [ \"MATCH (m:Disease)-[r:recommand_eat]->(n:Food) where m.name = ' {0} ' return m.name, r.name, n.name\" . format ( i ) for i in entities ] # \u67e5\u8be2\u75be\u75c5\u5e38\u7528\u836f\u54c1 elif question_type == 'disease_drug' : sql = [ \"MATCH (m:Disease)-[r:recommand_drug]->(n:Drug) where m.name = ' {0} ' return m.name, r.name, n.name\" . format ( i ) for i in entities ] return sql if __name__ == '__main__' : qp = QuestionPaser () print ( qp ) \u8c03\u7528: python question_parser.py \u8f93\u51fa\u7ed3\u679c: <__main__.QuestionPaser object at 0x7f656f8407d0> \u7b54\u6848\u641c\u7d22\u5b50\u4efb\u52a1 \u00b6 \u5bf9\u4e8e\u4efb\u610f\u7528\u6237\u7684\u95ee\u53e5, \u7ecf\u8fc7\u524d\u9762\u4e24\u4e2a\u6b65\u9aa4\u7684\u5904\u7406, \u5df2\u7ecf\u6709\u4e86\u5177\u4f53\u7684\u67e5\u8be2\u8ba1\u5212, \u5f53\u524d\u5b50\u4efb\u52a1\u53ea\u9700\u8981\u5b8c\u6210\u5177\u4f53\u7684\u67e5\u8be2, \u5e76\u7ec4\u88c5\u56de\u590d\u6a21\u677f\u5373\u53ef. \u4ee3\u7801\u8def\u5f84: /home/ec2-user/knowledge_graph/red_spider/answer_search.py import os import json from neo4j import GraphDatabase from config import NEO4J_CONFIG # \u7b54\u6848\u641c\u7d22\u7684\u4e3b\u7c7b class AnswerSearcher : def __init__ ( self ): self . num_limit = 10 self . driver = GraphDatabase . driver ( ** NEO4J_CONFIG ) # \u6267\u884ccypher\u67e5\u8be2\uff0c\u5e76\u8fd4\u56de\u76f8\u5e94\u7ed3\u679c def search_main ( self , sqls ): final_answers = [] # \u5f00\u542f\u4f1a\u8bdd with self . driver . session () as session : for sql_ in sqls : question_type = sql_ [ 'question_type' ] queries = sql_ [ 'sql' ] answers = [] # \u904d\u5386\u6240\u6709\u7684\u67e5\u8be2cypher, \u4f9d\u6b21\u6267\u884c, \u5e76\u5c06\u7ed3\u679c\u9010\u4e2a\u6dfb\u52a0\u8fdb\u5217\u8868\u4e2d for query in queries : ress = session . run ( query ) . data () answers += ress # \u8c03\u7528\u7cbe\u51c6\u56de\u590d\u6a21\u677f final_answer = self . answer_prettify ( question_type , answers ) if final_answer : final_answers . append ( final_answer ) return final_answers # \u6839\u636e\u5bf9\u5e94\u7684qustion_type, \u8c03\u7528\u76f8\u5e94\u7684\u56de\u590d\u6a21\u677f def answer_prettify ( self , question_type , answers ): final_answer = [] if not answers : return '' if question_type == 'disease_symptom' : desc = [ i [ 'n.name' ] for i in answers ] subject = answers [ 0 ][ 'm.name' ] final_answer = ' {0} \u7684\u75c7\u72b6\u5305\u62ec: {1} ' . format ( subject , ';' . join ( list ( set ( desc ))[: self . num_limit ])) elif question_type == 'disease_food' : desc = [ i [ 'n.name' ] for i in answers ] subject = answers [ 0 ][ 'm.name' ] final_answer = ' {0} \u63a8\u8350\u98df\u8c31\u5305\u62ec: {1} ' . format ( subject , ';' . join ( list ( set ( desc ))[: self . num_limit ])) elif question_type == 'disease_drug' : desc = [ i [ 'n.name' ] for i in answers ] subject = answers [ 0 ][ 'm.name' ] final_answer = ' {0} \u63a8\u8350\u7684\u836f\u54c1\u5305\u62ec: {1} ' . format ( subject , ';' . join ( list ( set ( desc ))[: self . num_limit ])) return final_answer if __name__ == '__main__' : ans = AnswerSearcher () print ( ans ) \u8c03\u7528: python answer_search.py \u8f93\u51fa\u7ed3\u679c: <__main__.AnswerSearcher object at 0x7fdc589a3a50> \u5c0f\u8282\u603b\u7ed3 \u00b6 \u672c\u5c0f\u8282\u5b8c\u6210\u4e86\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa, \u4ee5\u53ca\u7ea2\u8718\u86db\u673a\u5668\u4eba\u4e0a\u7ebf\u524d\u76843\u4e2a\u5b50\u4efb\u52a1\u4ee3\u7801.","title":"10.2 \u642d\u5efa\u7ea2\u8718\u86db\u673a\u5668\u4eba"},{"location":"10_2.html#_1","text":"","title":"\u7ea2\u8718\u86db\u642d\u5efa\u5168\u6d41\u7a0b"},{"location":"10_2.html#_2","text":"\u7406\u89e3\u7ea2\u8718\u86db\u76f8\u5173\u6a21\u5757\u7684\u8bbe\u8ba1\u601d\u8def. \u638c\u63e1\u7ea2\u8718\u86db\u673a\u5668\u4eba\u7684\u4ee3\u7801\u5b9e\u73b0.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"10_2.html#_3","text":"\u7ea2\u8718\u86db\u673a\u5668\u4eba\u7684\u642d\u5efa, \u9996\u8981\u4efb\u52a1\u5c31\u662f\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31, \u56fe\u8c31\u8d8a\u4e30\u5bcc, \u5185\u5bb9\u8d8a\u8be6\u5b9e, \u672a\u6765\u7ea2\u8718\u86db\u80fd\u5bf9\u5916\u63d0\u4f9b\u7684\u670d\u52a1\u5c31\u8d8a\u4f18\u8d28. \u603b\u4f53\u6765\u8bf4, \u5728\u6b64\u9009\u5b9aneo4j\u4f5c\u4e3a\u9879\u76ee\u7684\u56fe\u6570\u636e\u5e93, \u914d\u7f6e\u4fe1\u606f\u5982\u4e0b: /home/ec2-user/knowledge_graph/red_spider/config.py NEO4J_CONFIG = { \"uri\" : \"bolt://0.0.0.0:7687\" , \"auth\" : ( \"neo4j\" , \"neo4j\" ), \"encrypted\" : False } \u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u7684\u4ee3\u7801\u8def\u5f84: /home/ec2-user/knowledge_graph/red_spider/build_medicalgraph.py import os import json from neo4j import GraphDatabase from config import NEO4J_CONFIG # \u77e5\u8bc6\u56fe\u8c31\u4e3b\u7c7b class MedicalGraph : def __init__ ( self ): cur_dir = '/' . join ( os . path . abspath ( __file__ ) . split ( '/' )[: - 1 ]) self . data_path = os . path . join ( cur_dir , 'data/temp.json' ) # \u8bfb\u53d6\u6587\u4ef6 def read_nodes ( self ): # \u51714\u7c7b\u8282\u70b9 drugs = [] # \u836f\u54c1 foods = [] # \u98df\u7269 diseases = [] # \u75be\u75c5 symptoms = [] # \u75c7\u72b6 # \u6784\u5efa\u8282\u70b9\u5b9e\u4f53\u5173\u7cfb rels_recommandeat = [] # \u75be\u75c5-\u63a8\u8350\u5403\u98df\u7269\u5173\u7cfb rels_recommanddrug = [] # \u75be\u75c5-\u63a8\u8350\u836f\u54c1\u5173\u7cfb rels_symptom = [] # \u75be\u75c5-\u75c7\u72b6\u5173\u7cfb count = 0 for data in open ( self . data_path ): disease_dict = {} count += 1 if count % 10 == 0 : print ( 'count = ' , count ) # \u5f53\u524dV1.0\u7248\u672c\u4ec5\u652f\u6301\u75be\u75c5\u75c7\u72b6, \u836f\u54c1, \u98df\u54c1\u7684\u76f8\u5173\u54a8\u8be2 data_json = json . loads ( data ) disease = data_json [ 'name' ] diseases . append ( disease ) if 'symptom' in data_json : symptoms += data_json [ 'symptom' ] for symptom in data_json [ 'symptom' ]: rels_symptom . append ([ disease , symptom ]) if 'recommand_drug' in data_json : recommand_drug = data_json [ 'recommand_drug' ] drugs += recommand_drug for drug in recommand_drug : rels_recommanddrug . append ([ disease , drug ]) if 'recommand_eat' in data_json : recommand_eat = data_json [ 'recommand_eat' ] for _recommand in recommand_eat : rels_recommandeat . append ([ disease , _recommand ]) foods += recommand_eat return set ( drugs ), set ( foods ), set ( symptoms ), set ( diseases ), rels_recommandeat , rels_recommanddrug , rels_symptom # \u521b\u5efa\u77e5\u8bc6\u56fe\u8c31\u75be\u75c5\u76f8\u5173\u7684\u8282\u70b9, \u75be\u75c5, \u75c7\u72b6, \u836f\u54c1, \u98df\u54c1 def create_graphnodes_and_graphrels ( self ): Drugs , Foods , Symptoms , Diseases , rels_recommandeat , rels_recommanddrug , rels_symptom = self . read_nodes () # \u6253\u5370\u76f8\u5173\u6570\u636e\u7684\u6761\u6570 print ( 'Drugs:' , len ( Drugs )) print ( 'Foods:' , len ( Foods )) print ( 'Symptoms:' , len ( Symptoms )) print ( 'Diseases:' , len ( Diseases )) print ( 'rels_recommandeat:' , len ( rels_recommandeat )) print ( 'rels_recommanddrug:' , len ( rels_recommanddrug )) print ( 'rels_symptom:' , len ( rels_symptom )) # \u5b9e\u4f8b\u5316\u56fe\u6570\u636e\u5e93\u9a71\u52a8\u5668\u5bf9\u8c61 driver = GraphDatabase . driver ( ** NEO4J_CONFIG ) with driver . session () as session : # \u521b\u5efa\u4e2d\u5fc3\u75be\u75c5\u7684\u77e5\u8bc6\u56fe\u8c31\u8282\u70b9 print ( '\u5f00\u59cb\u521b\u5efa\u4e2d\u5fc3\u75be\u75c5\u8282\u70b9......' ) for d in Diseases : cypher = \"MERGE (a:Disease{name: %r }) RETURN a\" % d session . run ( cypher ) # \u521b\u5efa\"\u836f\u54c1\", \"\u98df\u54c1\", \"\u75c7\u72b6\"\u7684\u77e5\u8bc6\u56fe\u8c31\u8282\u70b9, V1.0\u7248\u672c\u53ea\u63d0\u4f9b\u8fd93\u79cd\u95ee\u8bca\u4fe1\u606f print ( '\u5f00\u59cb\u521b\u5efa\u836f\u54c1\u8282\u70b9Drug......' ) for n in Drugs : cypher = \"MERGE (a:Drug{name: %r }) RETURN a\" % n session . run ( cypher ) print ( '\u5f00\u59cb\u521b\u5efa\u98df\u54c1\u8282\u70b9Food......' ) for n in Foods : cypher = \"MERGE (a:Food{name: %r }) RETURN a\" % n session . run ( cypher ) print ( '\u5f00\u59cb\u521b\u5efa\u75c7\u72b6\u8282\u70b9Symptom......' ) for n in Symptoms : cypher = \"MERGE (a:Symptom{name: %r }) RETURN a\" % n session . run ( cypher ) # \u521b\u5efa\u5b9e\u4f53\u5173\u7cfb\u8fb9, V1.0\u7248\u672c\u4ec5\u652f\u63013\u79cd\u5173\u7cfb\u7684\u67e5\u8be2 self . create_relationship ( 'Disease' , 'Food' , rels_recommandeat , 'recommand_eat' , '\u63a8\u8350\u98df\u8c31' ) self . create_relationship ( 'Disease' , 'Drug' , rels_recommanddrug , 'recommand_drug' , '\u63a8\u8350\u836f\u54c1' ) self . create_relationship ( 'Disease' , 'Symptom' , rels_symptom , 'has_symptom' , '\u75c7\u72b6' ) # \u521b\u5efa\u5b9e\u4f53\u5173\u8054\u8fb9 def create_relationship ( self , start_node , end_node , edges , rel_type , rel_name ): # \u5173\u7cfb\u7684\u53bb\u91cd\u5904\u7406 set_edges = [] for edge in edges : set_edges . append ( '###' . join ( edge )) num_edges = len ( set ( set_edges )) print ( 'num_edges = ' , num_edges ) # \u5b9e\u4f8b\u5316\u56fe\u6570\u636e\u5e93\u9a71\u52a8\u5668\u5bf9\u8c61 driver = GraphDatabase . driver ( ** NEO4J_CONFIG ) with driver . session () as session : for edge in set ( set_edges ): edge = edge . split ( '###' ) p = edge [ 0 ] q = edge [ 1 ] # \u9501\u5b9a\u8282\u70b9\u548c\u5173\u7cfb, \u8fdb\u884c\u4e09\u5143\u7ec4\u7684\u521b\u5efa cypher = \"match(p: %s ), (q: %s ) where p.name=' %s 'and q.name=' %s ' create (p)-[rel: %s {name:' %s '}]->(q)\" % ( start_node , end_node , p , q , rel_type , rel_name ) try : session . run ( cypher ) except Exception as e : print ( e ) return if __name__ == '__main__' : mg = MedicalGraph () print ( '\u521b\u5efa\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u8282\u70b9\u548c\u5173\u7cfb......' ) mg . create_graphnodes_and_graphrels () \u8c03\u7528: python build_medicalgraph.py \u8f93\u51fa\u7ed3\u679c: \u521b\u5efa\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u8282\u70b9\u548c\u5173\u7cfb...... count = 10 count = 20 count = 30 count = 40 count = 50 count = 60 count = 70 count = 80 count = 90 count = 100 Drugs: 320 Foods: 283 Symptoms: 314 Diseases: 100 rels_recommandeat: 553 rels_recommanddrug: 675 rels_symptom: 748 \u5f00\u59cb\u521b\u5efa\u4e2d\u5fc3\u75be\u75c5\u8282\u70b9...... \u5f00\u59cb\u521b\u5efa\u836f\u54c1\u8282\u70b9Drug...... \u5f00\u59cb\u521b\u5efa\u98df\u54c1\u8282\u70b9Food...... \u5f00\u59cb\u521b\u5efa\u75c7\u72b6\u8282\u70b9Symptom...... num_edges = 553 num_edges = 675 num_edges = 748 \u5c55\u793aneo4j\u56fe\u6570\u636e\u5e93\u7684\u6570\u636e:","title":"\u56fe\u8c31\u6570\u636e\u6784\u5efa"},{"location":"10_2.html#_4","text":"\u6784\u5efa\u597d\u77e5\u8bc6\u56fe\u8c31\u540e, \u6211\u4eec\u8981\u642d\u5efa\u4e00\u4e2a\u7b80\u5355\u7684\u57fa\u4e8e\u89c4\u5219\u6d3e\u7684\u7ea2\u8718\u86db\u5bf9\u8bdd\u673a\u5668\u4eba, \u9700\u8981\u5b8c\u62103\u4e2a\u5b50\u529f\u80fd: \u95ee\u9898\u5206\u7c7b\u5b50\u4efb\u52a1 \u95ee\u9898\u89e3\u6790\u5b50\u4efb\u52a1 \u7b54\u6848\u641c\u7d22\u5b50\u4efb\u52a1","title":"\u95ee\u9898\u5206\u7c7b\u4e0e\u7b54\u6848\u641c\u7d22"},{"location":"10_2.html#_5","text":"\u5bf9\u4e8e\u7528\u6237\u7684\u4efb\u610f\u95ee\u53e5, \u5c06\u5176\u5206\u7c7b\u5230\u7ea2\u8718\u86db\u53ef\u4ee5\u652f\u6301\u56de\u7b54\u7684\u82e5\u5e72\u5b50\u7c7b\u4e2d, \u6709\u5229\u4e8e\u540e\u7eed\u67e5\u8be2\u548c\u56de\u7b54\u6a21\u677f\u7684\u7f16\u5199. \u4ee3\u7801\u8def\u5f84: /home/ec2-user/knowledge_graph/red_spider/question_classifier.py import os import ahocorasick class QuestionClassifier : def __init__ ( self ): cur_dir = '/' . join ( os . path . abspath ( __file__ ) . split ( '/' )[: - 1 ]) #\u3000\u7279\u5f81\u8bcd\u8def\u5f84 self . disease_path = os . path . join ( cur_dir , 'dict/disease.txt' ) self . drug_path = os . path . join ( cur_dir , 'dict/drug.txt' ) self . food_path = os . path . join ( cur_dir , 'dict/food.txt' ) self . symptom_path = os . path . join ( cur_dir , 'dict/symptom.txt' ) # \u52a0\u8f7d\u7279\u5f81\u8bcd self . disease_words = [ i . strip () for i in open ( self . disease_path ) if i . strip ()] self . drug_words = [ i . strip () for i in open ( self . drug_path ) if i . strip ()] self . food_words = [ i . strip () for i in open ( self . food_path ) if i . strip ()] self . symptom_words = [ i . strip () for i in open ( self . symptom_path ) if i . strip ()] self . region_words = set ( self . disease_words + self . drug_words + self . food_words + self . symptom_words ) # \u6784\u9020\u9886\u57dfactree, \u53ef\u4ee5\u52a0\u901f\u5173\u952e\u8bcd\u5339\u914d\u67e5\u627e self . region_tree = self . build_actree ( list ( self . region_words )) # \u6784\u5efa\u8bcd\u5178 self . wdtype_dict = self . build_wdtype_dict () # \u95ee\u53e5\u7591\u95ee\u8bcd, V1.0\u7248\u672c\u4ec5\u652f\u6301\u75c7\u72b6, \u98df\u54c1, \u836f\u54c1\u7684\u67e5\u8be2. self . symptom_request = [ '\u75c7\u72b6' , '\u8868\u5f81' , '\u73b0\u8c61' , '\u75c7\u5019' , '\u8868\u73b0' ] self . food_request = [ '\u996e\u98df' , '\u996e\u7528' , '\u5403' , '\u98df' , '\u4f19\u98df' , '\u81b3\u98df' , '\u559d' , '\u83dc' , '\u5fcc\u53e3' , '\u8865\u54c1' , '\u4fdd\u5065\u54c1' , '\u98df\u8c31' , '\u83dc\u8c31' , '\u98df\u7528' , '\u98df\u7269' , '\u8865\u54c1' ] self . drug_request = [ '\u836f' , '\u836f\u54c1' , '\u7528\u836f' , '\u80f6\u56ca' , '\u53e3\u670d\u6db2' , '\u708e\u7247' ] print ( 'model init finished ......' ) # \u5206\u7c7b\u4e3b\u51fd\u6570 def classify ( self , question ): data = {} medical_dict = self . check_medical ( question ) if not medical_dict : return {} data [ 'args' ] = medical_dict # \u6536\u96c6\u95ee\u53e5\u5f53\u4e2d\u6240\u6d89\u53ca\u5230\u7684\u5b9e\u4f53\u7c7b\u578b types = [] for type_ in medical_dict . values (): types += type_ question_type = 'others' question_types = [] # \u75c7\u72b6 if self . check_words ( self . symptom_request , question ) and ( 'disease' in types ): question_type = 'disease_symptom' question_types . append ( question_type ) # \u63a8\u8350\u98df\u54c1 if self . check_words ( self . food_request , question ) and ( 'disease' in types ): question_type = 'disease_food' question_types . append ( question_type ) # \u63a8\u8350\u836f\u54c1 if self . check_words ( self . drug_request , question ) and ( 'disease' in types ): question_type = 'disease_drug' question_types . append ( question_type ) # \u82e5\u6ca1\u6709\u67e5\u5230\u76f8\u5173\u7684\u5916\u90e8\u67e5\u8be2\u4fe1\u606f\uff0c\u90a3\u4e48\u5219\u5c06\u8be5\u75be\u75c5\u7684\u63cf\u8ff0\u4fe1\u606f\u8fd4\u56de if question_types == [] and 'symptom' in types : question_types = [ 'disease_symptom' ] # \u5c06\u591a\u4e2a\u5206\u7c7b\u7ed3\u679c\u8fdb\u884c\u5408\u5e76\u5904\u7406\uff0c\u7ec4\u88c5\u6210\u4e00\u4e2a\u5b57\u5178 data [ 'question_types' ] = question_types return data # \u6784\u9020\u5173\u952e\u8bcd\u5bf9\u5e94\u7684\u8282\u70b9\u7c7b\u578b def build_wdtype_dict ( self ): word_dict = dict () for word in self . region_words : word_dict [ word ] = [] # \u68c0\u67e5\u662f\u5426\u6709\u75be\u75c5\u5173\u952e\u8bcd if word in self . disease_words : word_dict [ word ] . append ( 'disease' ) # \u68c0\u67e5\u662f\u5426\u6709\u836f\u54c1\u5173\u952e\u8bcd if word in self . drug_words : word_dict [ word ] . append ( 'drug' ) # \u68c0\u67e5\u662f\u5426\u6709\u98df\u54c1\u5173\u952e\u8bcd if word in self . food_words : word_dict [ word ] . append ( 'food' ) # \u68c0\u67e5\u662f\u5426\u6709\u75c7\u72b6\u5173\u952e\u8bcd if word in self . symptom_words : word_dict [ word ] . append ( 'symptom' ) return word_dict # \u6784\u9020actree\u52a0\u901f\u8fc7\u6ee4 def build_actree ( self , wordlist ): actree = ahocorasick . Automaton () for index , word in enumerate ( wordlist ): actree . add_word ( word , ( index , word )) actree . make_automaton () return actree # \u95ee\u53e5\u68c0\u67e5 def check_medical ( self , question ): region_words = [] # \u5229\u7528AcTree\u52a0\u901f\u67e5\u8be2\u5173\u952e\u8bcd for i in self . region_tree . iter ( question ): word = i [ 1 ][ 1 ] region_words . append ( word ) stop_words = [] # \u5b50\u8bcd\u8fdb\u5165\u505c\u7528\u8bcd\u8868 for word1 in region_words : for word2 in region_words : if word1 in word2 and word1 != word2 : stop_words . append ( word1 ) final_words = [ i for i in region_words if i not in stop_words ] final_dict = { i : self . wdtype_dict . get ( i ) for i in final_words } return final_dict # \u57fa\u4e8e\u7279\u5f81\u8bcd\u8fdb\u884c\u95ee\u53e5\u68c0\u6d4b, \u5e76\u8fdb\u884c\u95ee\u53e5\u7c7b\u578b\u7684\u89c4\u5219\u5206\u7c7b def check_words ( self , words , sent ): for word in words : if word in sent : return True return False if __name__ == '__main__' : qc = QuestionClassifier () while True : question = input ( 'input an question:' ) data = qc . classify ( question ) print ( data ) \u8c03\u7528: python question_classifier.py \u8f93\u51fa\u7ed3\u679c: input an question:\u8eab\u4f53\u53d1\u70ed\u6076\u5fc3\u5e94\u8be5\u5403\u4ec0\u4e48? {'args': {'\u6076\u5fc3': ['symptom']}, 'question_types': ['disease_symptom']} input an question:Q {}","title":"\u95ee\u9898\u5206\u7c7b\u5b50\u4efb\u52a1"},{"location":"10_2.html#_6","text":"\u5bf9\u4e8e\u7528\u6237\u7684\u4efb\u610f\u95ee\u53e5, \u7ecf\u8fc7\u4e0a\u4e00\u6b65\u9aa4\u8fdb\u884c\u5206\u7c7b\u540e, \u5df2\u7ecf\u5f97\u5230\u4e86\u95ee\u9898\u7684\u5206\u7c7b\u6807\u7b7e, \u63a5\u4e0b\u6765\u8981\u5bf9\u75c7\u72b6, \u98df\u54c1, \u836f\u54c1\u8fdb\u884cneo4j\u67e5\u8be2\u7684cypher\u8bed\u53e5\u7ec4\u88c5\u548c\u89e3\u6790. \u4ee3\u7801\u8def\u5f84: /home/ec2-user/knowledge_graph/red_spider/question_parser.py class QuestionPaser : # \u6784\u5efa\u5b9e\u4f53\u8282\u70b9 def build_entitydict ( self , args ): entity_dict = {} for arg , types in args . items (): for type in types : if type not in entity_dict : entity_dict [ type ] = [ arg ] else : entity_dict [ type ] . append ( arg ) return entity_dict # \u89e3\u6790\u4e3b\u51fd\u6570 def parser_main ( self , res_classify ): args = res_classify [ 'args' ] entity_dict = self . build_entitydict ( args ) question_types = res_classify [ 'question_types' ] sqls = [] for question_type in question_types : sql_ = {} sql_ [ 'question_type' ] = question_type sql = [] # \u6309\u7167\u4e0d\u540c\u7684\u5206\u7c7b\u7ed3\u679c, \u7ec4\u88c5\u4e0d\u540c\u7684cypher\u67e5\u8be2\u8bed\u53e5 if question_type == 'disease_symptom' : sql = self . sql_transfer ( question_type , entity_dict . get ( 'disease' )) elif question_type == 'disease_food' : sql = self . sql_transfer ( question_type , entity_dict . get ( 'disease' )) elif question_type == 'disease_drug' : sql = self . sql_transfer ( question_type , entity_dict . get ( 'disease' )) if sql : sql_ [ 'sql' ] = sql sqls . append ( sql_ ) return sqls # \u9488\u5bf9\u4e0d\u540c\u7684\u95ee\u9898\uff0c\u5206\u5f00\u8fdb\u884c\u5904\u7406 def sql_transfer ( self , question_type , entities ): if not entities : return [] # \u67e5\u8be2\u8bed\u53e5 sql = [] # \u67e5\u8be2\u75be\u75c5\u6709\u54ea\u4e9b\u75c7\u72b6 if question_type == 'disease_symptom' : sql = [ \"MATCH (m:Disease)-[r:has_symptom]->(n:Symptom) where m.name = ' {0} ' return m.name, r.name, n.name\" . format ( i ) for i in entities ] # \u67e5\u8be2\u75be\u75c5\u5efa\u8bae\u5403\u7684\u4e1c\u897f elif question_type == 'disease_food' : sql = [ \"MATCH (m:Disease)-[r:recommand_eat]->(n:Food) where m.name = ' {0} ' return m.name, r.name, n.name\" . format ( i ) for i in entities ] # \u67e5\u8be2\u75be\u75c5\u5e38\u7528\u836f\u54c1 elif question_type == 'disease_drug' : sql = [ \"MATCH (m:Disease)-[r:recommand_drug]->(n:Drug) where m.name = ' {0} ' return m.name, r.name, n.name\" . format ( i ) for i in entities ] return sql if __name__ == '__main__' : qp = QuestionPaser () print ( qp ) \u8c03\u7528: python question_parser.py \u8f93\u51fa\u7ed3\u679c: <__main__.QuestionPaser object at 0x7f656f8407d0>","title":"\u95ee\u9898\u89e3\u6790\u5b50\u4efb\u52a1"},{"location":"10_2.html#_7","text":"\u5bf9\u4e8e\u4efb\u610f\u7528\u6237\u7684\u95ee\u53e5, \u7ecf\u8fc7\u524d\u9762\u4e24\u4e2a\u6b65\u9aa4\u7684\u5904\u7406, \u5df2\u7ecf\u6709\u4e86\u5177\u4f53\u7684\u67e5\u8be2\u8ba1\u5212, \u5f53\u524d\u5b50\u4efb\u52a1\u53ea\u9700\u8981\u5b8c\u6210\u5177\u4f53\u7684\u67e5\u8be2, \u5e76\u7ec4\u88c5\u56de\u590d\u6a21\u677f\u5373\u53ef. \u4ee3\u7801\u8def\u5f84: /home/ec2-user/knowledge_graph/red_spider/answer_search.py import os import json from neo4j import GraphDatabase from config import NEO4J_CONFIG # \u7b54\u6848\u641c\u7d22\u7684\u4e3b\u7c7b class AnswerSearcher : def __init__ ( self ): self . num_limit = 10 self . driver = GraphDatabase . driver ( ** NEO4J_CONFIG ) # \u6267\u884ccypher\u67e5\u8be2\uff0c\u5e76\u8fd4\u56de\u76f8\u5e94\u7ed3\u679c def search_main ( self , sqls ): final_answers = [] # \u5f00\u542f\u4f1a\u8bdd with self . driver . session () as session : for sql_ in sqls : question_type = sql_ [ 'question_type' ] queries = sql_ [ 'sql' ] answers = [] # \u904d\u5386\u6240\u6709\u7684\u67e5\u8be2cypher, \u4f9d\u6b21\u6267\u884c, \u5e76\u5c06\u7ed3\u679c\u9010\u4e2a\u6dfb\u52a0\u8fdb\u5217\u8868\u4e2d for query in queries : ress = session . run ( query ) . data () answers += ress # \u8c03\u7528\u7cbe\u51c6\u56de\u590d\u6a21\u677f final_answer = self . answer_prettify ( question_type , answers ) if final_answer : final_answers . append ( final_answer ) return final_answers # \u6839\u636e\u5bf9\u5e94\u7684qustion_type, \u8c03\u7528\u76f8\u5e94\u7684\u56de\u590d\u6a21\u677f def answer_prettify ( self , question_type , answers ): final_answer = [] if not answers : return '' if question_type == 'disease_symptom' : desc = [ i [ 'n.name' ] for i in answers ] subject = answers [ 0 ][ 'm.name' ] final_answer = ' {0} \u7684\u75c7\u72b6\u5305\u62ec: {1} ' . format ( subject , ';' . join ( list ( set ( desc ))[: self . num_limit ])) elif question_type == 'disease_food' : desc = [ i [ 'n.name' ] for i in answers ] subject = answers [ 0 ][ 'm.name' ] final_answer = ' {0} \u63a8\u8350\u98df\u8c31\u5305\u62ec: {1} ' . format ( subject , ';' . join ( list ( set ( desc ))[: self . num_limit ])) elif question_type == 'disease_drug' : desc = [ i [ 'n.name' ] for i in answers ] subject = answers [ 0 ][ 'm.name' ] final_answer = ' {0} \u63a8\u8350\u7684\u836f\u54c1\u5305\u62ec: {1} ' . format ( subject , ';' . join ( list ( set ( desc ))[: self . num_limit ])) return final_answer if __name__ == '__main__' : ans = AnswerSearcher () print ( ans ) \u8c03\u7528: python answer_search.py \u8f93\u51fa\u7ed3\u679c: <__main__.AnswerSearcher object at 0x7fdc589a3a50>","title":"\u7b54\u6848\u641c\u7d22\u5b50\u4efb\u52a1"},{"location":"10_2.html#_8","text":"\u672c\u5c0f\u8282\u5b8c\u6210\u4e86\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa, \u4ee5\u53ca\u7ea2\u8718\u86db\u673a\u5668\u4eba\u4e0a\u7ebf\u524d\u76843\u4e2a\u5b50\u4efb\u52a1\u4ee3\u7801.","title":"\u5c0f\u8282\u603b\u7ed3"},{"location":"10_3.html","text":"\u7ea2\u8718\u86db\u4e0a\u7ebf \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u638c\u63e1\u7ea2\u8718\u86db\u4e0a\u7ebf\u7684\u4ee3\u7801\u5b9e\u73b0. \u7ea2\u8718\u86db\u673a\u5668\u4eba \u00b6 \u5b8c\u6210\u4e86\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa, \u4ee5\u53ca\u82e5\u5e72\u5b50\u4efb\u52a1\u4ee3\u7801\u540e, \u9700\u8981\u4e00\u4e2a\u603b\u4f53\u8c03\u7528\u7684\u529f\u80fd\u4ee3\u7801\u5b9e\u73b0\u7ea2\u8718\u86db\u673a\u5668\u4eba\u7684\u4e0a\u7ebf. \u4ee3\u7801\u8def\u5f84: /home/ec2-user/knowledge_graph/red_spider/chatbot.py # \u5bfc\u51653\u4e2a\u5b50\u4efb\u52a1\u7684\u529f\u80fd\u51fd\u6570 from question_classifier import * from question_parser import * from answer_search import * # \u7ea2\u8718\u86db\u673a\u5668\u4eba\u7efc\u5408\u95ee\u7b54\u7c7b class Red_Spider : def __init__ ( self ): # 1: \u95ee\u9898\u5206\u7c7b\u5668 self . classifier = QuestionClassifier () # 2: \u95ee\u9898\u89e3\u6790\u5668 self . parser = QuestionPaser () # 3: \u7b54\u6848\u641c\u7d22\u5668 self . searcher = AnswerSearcher () def chat_main ( self , sentence ): answer = '\u60a8\u597d, \u6211\u662f\u7ea2\u8718\u86dbAI\u52a9\u7406, \u5e0c\u671b\u53ef\u4ee5\u5e2e\u5230\u60a8, \u795d\u60a8\u8eab\u4f53\u5b89\u5eb7, \u5feb\u4e50\u5e38\u4f34~' # 1: \u9996\u5148\u8fdb\u884c\u95ee\u9898\u5206\u7c7b, \u5982\u679c\u65e0\u6cd5\u5206\u7c7b\u5230\u75c7\u72b6, \u98df\u54c1, \u836f\u54c1\u76f8\u5173\u95ee\u9898\u4e0a, \u5219\u76f4\u63a5\u8fd4\u56de\u5ba2\u5957\u8bdd res_classify = self . classifier . classify ( sentence ) if not res_classify : return answer # print('res_classify: ', res_classify) # 2: \u5bf9\u5206\u7c7b\u540e\u7684\u95ee\u9898\u8fdb\u884c\u89e3\u6790, \u7ec4\u88c5\u51faneo4j\u67e5\u8be2\u8bed\u53e5 res_sql = self . parser . parser_main ( res_classify ) # print('res_sql: ', res_sql) # 3: \u5229\u7528\u67e5\u8be2\u8bed\u53e5, \u76f4\u63a5\u8c03\u7528\u7b54\u6848\u641c\u7d22\u5668\u67e5\u8be2neo4j, \u5f97\u5230\u6700\u7ec8\u7b54\u6848 final_answers = self . searcher . search_main ( res_sql ) # \u65e0\u6cd5\u67e5\u8be2\u5230\u76f8\u5173\u7b54\u6848, \u5219\u8fd4\u56de\u5ba2\u5957\u8bdd; \u5426\u5219\u5c06\u82e5\u5e72\u7b54\u6848\u5206\u884c\u8fd4\u56de if not final_answers : return answer else : return ' \\n ' . join ( final_answers ) if __name__ == '__main__' : # \u5b9e\u4f8b\u5316\u7ea2\u8718\u86db\u673a\u5668\u4eba red_spider = Red_Spider () # \u65e0\u9650\u5faa\u73af\u591a\u8f6e\u5bf9\u8bdd while True : question = input ( '\u7528\u6237:' ) answer = red_spider . chat_main ( question ) print ( '\u7ea2\u8718\u86db:' , answer ) if question == 'Q' or question == 'q' : break \u8054\u8c03\u6d4b\u8bd5 \u00b6 \u8c03\u7528: python chatbot.py \u8f93\u51fa\u7ed3\u679c: \u7528\u6237:\u611f\u5192\u9700\u8981\u5403\u4ec0\u4e48\u836f? \u7ea2\u8718\u86db: \u611f\u5192\u63a8\u8350\u98df\u8c31\u5305\u62ec:\u9999\u693f\u82bd\u7ca5;\u51c9\u62cc\u9999\u693f;\u858f\u7c73\u83b2\u5b50\u7ca5;\u59dc\u4e1d\u841d\u535c\u6c64;\u918b\u7198\u571f\u8c46\u4e1d;\u8d64\u5c0f\u8c46\u7ca5;\u7eff\u8c46\u858f\u7c73\u996d;\u8471\u849c\u7ca5 \u611f\u5192\u63a8\u8350\u7684\u836f\u54c1\u5305\u62ec:\u6297\u75c5\u6bd2\u53e3\u670d\u6db2;\u9ebb\u9ec4\u6b62\u55fd\u4e38;\u915a\u5496\u7247;\u4f9d\u6258\u7ea2\u9709\u7d20\u7247;\u7a7f\u5fc3\u83b2\u7247;\u5934\u5b62\u62c9\u5b9a\u80f6\u56ca;\u5934\u5b62\u4e19\u70ef\u5206\u6563\u7247;\u5339\u591a\u83ab\u5fb7\u5206\u6563\u7247;\u94f6\u82a9\u80f6\u56ca;\u5589\u75db\u7075\u7247 \u7528\u6237:\u9ad8\u8840\u538b\u5403\u70b9\u4ec0\u4e48? \u7ea2\u8718\u86db: \u60a8\u597d, \u6211\u662f\u7ea2\u8718\u86dbAI\u52a9\u7406, \u5e0c\u671b\u53ef\u4ee5\u5e2e\u5230\u60a8, \u795d\u60a8\u8eab\u4f53\u5b89\u5eb7, \u5feb\u4e50\u5e38\u4f34~ \u7528\u6237:\u80ba\u708e\u6027\u5047\u7624\u9700\u8981\u4ec0\u4e48\u836f? \u7ea2\u8718\u86db: \u60a8\u597d, \u6211\u662f\u7ea2\u8718\u86dbAI\u52a9\u7406, \u5e0c\u671b\u53ef\u4ee5\u5e2e\u5230\u60a8, \u795d\u60a8\u8eab\u4f53\u5b89\u5eb7, \u5feb\u4e50\u5e38\u4f34~ \u7528\u6237:q \u5c0f\u8282\u603b\u7ed3 \u00b6 \u672c\u5c0f\u8282\u5b8c\u6210\u4e86\u7ea2\u8718\u86db\u673a\u5668\u4eba\u7684\u4e0a\u7ebf\u5373\u6d4b\u8bd5, \u8fde\u63a5\u4f01\u4e1a\u524d\u7aef\u754c\u9762\u540e, \u5373\u53ef\u5bf9\u5916\u63d0\u4f9b\u66f4\u52a0\u4eba\u6027\u5316\u7684\u670d\u52a1.","title":"10.3 \u4e0a\u7ebf\u90e8\u7f72\u4e0e\u8054\u8c03\u6d4b\u8bd5"},{"location":"10_3.html#_1","text":"","title":"\u7ea2\u8718\u86db\u4e0a\u7ebf"},{"location":"10_3.html#_2","text":"\u638c\u63e1\u7ea2\u8718\u86db\u4e0a\u7ebf\u7684\u4ee3\u7801\u5b9e\u73b0.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"10_3.html#_3","text":"\u5b8c\u6210\u4e86\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa, \u4ee5\u53ca\u82e5\u5e72\u5b50\u4efb\u52a1\u4ee3\u7801\u540e, \u9700\u8981\u4e00\u4e2a\u603b\u4f53\u8c03\u7528\u7684\u529f\u80fd\u4ee3\u7801\u5b9e\u73b0\u7ea2\u8718\u86db\u673a\u5668\u4eba\u7684\u4e0a\u7ebf. \u4ee3\u7801\u8def\u5f84: /home/ec2-user/knowledge_graph/red_spider/chatbot.py # \u5bfc\u51653\u4e2a\u5b50\u4efb\u52a1\u7684\u529f\u80fd\u51fd\u6570 from question_classifier import * from question_parser import * from answer_search import * # \u7ea2\u8718\u86db\u673a\u5668\u4eba\u7efc\u5408\u95ee\u7b54\u7c7b class Red_Spider : def __init__ ( self ): # 1: \u95ee\u9898\u5206\u7c7b\u5668 self . classifier = QuestionClassifier () # 2: \u95ee\u9898\u89e3\u6790\u5668 self . parser = QuestionPaser () # 3: \u7b54\u6848\u641c\u7d22\u5668 self . searcher = AnswerSearcher () def chat_main ( self , sentence ): answer = '\u60a8\u597d, \u6211\u662f\u7ea2\u8718\u86dbAI\u52a9\u7406, \u5e0c\u671b\u53ef\u4ee5\u5e2e\u5230\u60a8, \u795d\u60a8\u8eab\u4f53\u5b89\u5eb7, \u5feb\u4e50\u5e38\u4f34~' # 1: \u9996\u5148\u8fdb\u884c\u95ee\u9898\u5206\u7c7b, \u5982\u679c\u65e0\u6cd5\u5206\u7c7b\u5230\u75c7\u72b6, \u98df\u54c1, \u836f\u54c1\u76f8\u5173\u95ee\u9898\u4e0a, \u5219\u76f4\u63a5\u8fd4\u56de\u5ba2\u5957\u8bdd res_classify = self . classifier . classify ( sentence ) if not res_classify : return answer # print('res_classify: ', res_classify) # 2: \u5bf9\u5206\u7c7b\u540e\u7684\u95ee\u9898\u8fdb\u884c\u89e3\u6790, \u7ec4\u88c5\u51faneo4j\u67e5\u8be2\u8bed\u53e5 res_sql = self . parser . parser_main ( res_classify ) # print('res_sql: ', res_sql) # 3: \u5229\u7528\u67e5\u8be2\u8bed\u53e5, \u76f4\u63a5\u8c03\u7528\u7b54\u6848\u641c\u7d22\u5668\u67e5\u8be2neo4j, \u5f97\u5230\u6700\u7ec8\u7b54\u6848 final_answers = self . searcher . search_main ( res_sql ) # \u65e0\u6cd5\u67e5\u8be2\u5230\u76f8\u5173\u7b54\u6848, \u5219\u8fd4\u56de\u5ba2\u5957\u8bdd; \u5426\u5219\u5c06\u82e5\u5e72\u7b54\u6848\u5206\u884c\u8fd4\u56de if not final_answers : return answer else : return ' \\n ' . join ( final_answers ) if __name__ == '__main__' : # \u5b9e\u4f8b\u5316\u7ea2\u8718\u86db\u673a\u5668\u4eba red_spider = Red_Spider () # \u65e0\u9650\u5faa\u73af\u591a\u8f6e\u5bf9\u8bdd while True : question = input ( '\u7528\u6237:' ) answer = red_spider . chat_main ( question ) print ( '\u7ea2\u8718\u86db:' , answer ) if question == 'Q' or question == 'q' : break","title":"\u7ea2\u8718\u86db\u673a\u5668\u4eba"},{"location":"10_3.html#_4","text":"\u8c03\u7528: python chatbot.py \u8f93\u51fa\u7ed3\u679c: \u7528\u6237:\u611f\u5192\u9700\u8981\u5403\u4ec0\u4e48\u836f? \u7ea2\u8718\u86db: \u611f\u5192\u63a8\u8350\u98df\u8c31\u5305\u62ec:\u9999\u693f\u82bd\u7ca5;\u51c9\u62cc\u9999\u693f;\u858f\u7c73\u83b2\u5b50\u7ca5;\u59dc\u4e1d\u841d\u535c\u6c64;\u918b\u7198\u571f\u8c46\u4e1d;\u8d64\u5c0f\u8c46\u7ca5;\u7eff\u8c46\u858f\u7c73\u996d;\u8471\u849c\u7ca5 \u611f\u5192\u63a8\u8350\u7684\u836f\u54c1\u5305\u62ec:\u6297\u75c5\u6bd2\u53e3\u670d\u6db2;\u9ebb\u9ec4\u6b62\u55fd\u4e38;\u915a\u5496\u7247;\u4f9d\u6258\u7ea2\u9709\u7d20\u7247;\u7a7f\u5fc3\u83b2\u7247;\u5934\u5b62\u62c9\u5b9a\u80f6\u56ca;\u5934\u5b62\u4e19\u70ef\u5206\u6563\u7247;\u5339\u591a\u83ab\u5fb7\u5206\u6563\u7247;\u94f6\u82a9\u80f6\u56ca;\u5589\u75db\u7075\u7247 \u7528\u6237:\u9ad8\u8840\u538b\u5403\u70b9\u4ec0\u4e48? \u7ea2\u8718\u86db: \u60a8\u597d, \u6211\u662f\u7ea2\u8718\u86dbAI\u52a9\u7406, \u5e0c\u671b\u53ef\u4ee5\u5e2e\u5230\u60a8, \u795d\u60a8\u8eab\u4f53\u5b89\u5eb7, \u5feb\u4e50\u5e38\u4f34~ \u7528\u6237:\u80ba\u708e\u6027\u5047\u7624\u9700\u8981\u4ec0\u4e48\u836f? \u7ea2\u8718\u86db: \u60a8\u597d, \u6211\u662f\u7ea2\u8718\u86dbAI\u52a9\u7406, \u5e0c\u671b\u53ef\u4ee5\u5e2e\u5230\u60a8, \u795d\u60a8\u8eab\u4f53\u5b89\u5eb7, \u5feb\u4e50\u5e38\u4f34~ \u7528\u6237:q","title":"\u8054\u8c03\u6d4b\u8bd5"},{"location":"10_3.html#_5","text":"\u672c\u5c0f\u8282\u5b8c\u6210\u4e86\u7ea2\u8718\u86db\u673a\u5668\u4eba\u7684\u4e0a\u7ebf\u5373\u6d4b\u8bd5, \u8fde\u63a5\u4f01\u4e1a\u524d\u7aef\u754c\u9762\u540e, \u5373\u53ef\u5bf9\u5916\u63d0\u4f9b\u66f4\u52a0\u4eba\u6027\u5316\u7684\u670d\u52a1.","title":"\u5c0f\u8282\u603b\u7ed3"},{"location":"11_1.html","text":"TENER\u6a21\u578b \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u638c\u63e1TENER\u6a21\u578b\u7684\u642d\u5efa, \u8bad\u7ec3\u548c\u6d4b\u8bd5\u4ee3\u7801\u5b9e\u73b0. TENER\u6a21\u578b\u4ee3\u7801\u5b9e\u73b0 \u00b6 TENER\u6a21\u578b\u7684\u5b9e\u73b0\u6b65\u9aa4\u5982\u4e0b: \u7b2c1\u6b65: \u6784\u5efa\u5b50\u6a21\u5757\u7684\u4ee3\u7801 \u7b2c2\u6b65: \u6784\u5efa\u6a21\u578b\u7c7b\u7684\u4ee3\u7801 \u7b2c3\u6b65: \u8bad\u7ec3\u51fd\u6570\u7684\u4ee3\u7801 \u7b2c1\u6b65: \u6784\u5efa\u5b50\u6a21\u5757\u7684\u4ee3\u7801 \u00b6 1.1: \u5b9e\u73b0callbacks.py\u4ee3\u7801 from fastNLP import Callback , Tester , DataSet class EvaluateCallback ( Callback ): \"\"\" \u901a\u8fc7\u4f7f\u7528\u8be5Callback\u53ef\u4ee5\u4f7f\u5f97Trainer\u5728evaluate dev\u4e4b\u5916\u8fd8\u53ef\u4ee5evaluate\u5176\u5b83\u6570\u636e\u96c6\uff0c\u6bd4\u5982\u6d4b\u8bd5\u96c6\u3002\u6bcf\u4e00\u6b21\u9a8c\u8bc1dev\u4e4b\u524d\u90fd\u4f1a\u5148\u9a8c\u8bc1EvaluateCallback \u4e2d\u7684\u6570\u636e\u3002 \"\"\" def __init__ ( self , data = None , tester = None ): \"\"\" :param ~fastNLP.DataSet,Dict[~fastNLP.DataSet] data: \u4f20\u5165DataSet\u5bf9\u8c61\uff0c\u4f1a\u4f7f\u7528Trainer\u4e2d\u7684metric\u5bf9\u6570\u636e\u8fdb\u884c\u9a8c\u8bc1\u3002\u5982\u679c\u9700\u8981 \u4f20\u5165\u591a\u4e2a DataSet\u8bf7\u901a\u8fc7dict\u7684\u65b9\u5f0f\u4f20\u5165\u3002 :param ~fastNLP.Tester,Dict[~fastNLP.DataSet] tester: Tester\u5bf9\u8c61, \u901a\u8fc7\u4f7f\u7528Tester\u5bf9\u8c61\uff0c\u53ef\u4ee5\u4f7f\u5f97\u9a8c\u8bc1\u7684metric\u4e0eTrainer\u4e2d \u7684metric\u4e0d\u4e00\u6837\u3002 \"\"\" super () . __init__ () self . datasets = {} self . testers = {} self . best_test_metric_sofar = 0 self . best_test_sofar = None self . best_test_epoch = 0 self . best_dev_test = None self . best_dev_epoch = 0 if tester is not None : if isinstance ( tester , dict ): for name , test in tester . items (): if not isinstance ( test , Tester ): raise TypeError ( f \" { name } in tester is not a valid fastNLP.Tester.\" ) self . testers [ 'tester-' + name ] = test if isinstance ( tester , Tester ): self . testers [ 'tester-test' ] = tester for tester in self . testers . values (): setattr ( tester , 'verbose' , 0 ) if isinstance ( data , dict ): for key , value in data . items (): assert isinstance ( value , DataSet ), f \"Only DataSet object is allowed, not { type ( value ) } .\" for key , value in data . items (): self . datasets [ 'data-' + key ] = value elif isinstance ( data , DataSet ): self . datasets [ 'data-test' ] = data elif data is not None : raise TypeError ( \"data receives dict[DataSet] or DataSet object.\" ) def on_train_begin ( self ): if len ( self . datasets ) > 0 and self . trainer . dev_data is None : raise RuntimeError ( \"Trainer has no dev data, you cannot pass extra DataSet to do evaluation.\" ) if len ( self . datasets ) > 0 : for key , data in self . datasets . items (): tester = Tester ( data = data , model = self . model , batch_size = self . trainer . kwargs . get ( 'dev_batch_size' , self . batch_size ), metrics = self . trainer . metrics , verbose = 0 , use_tqdm = self . trainer . test_use_tqdm ) self . testers [ key ] = tester def on_valid_end ( self , eval_result , metric_key , optimizer , better_result ): if len ( self . testers ) > 0 : for idx , ( key , tester ) in enumerate ( self . testers . items ()): try : eval_result = tester . test () if idx == 0 : indicator , indicator_val = _check_eval_results ( eval_result ) if indicator_val > self . best_test_metric_sofar : self . best_test_metric_sofar = indicator_val self . best_test_epoch = self . epoch self . best_test_sofar = eval_result if better_result : self . best_dev_test = eval_result self . best_dev_epoch = self . epoch self . logger . info ( \"EvaluateCallback evaluation on {} :\" . format ( key )) self . logger . info ( tester . _format_eval_results ( eval_result )) except Exception as e : self . logger . error ( \"Exception happens when evaluate on DataSet named ` {} `.\" . format ( key )) raise e def on_train_end ( self ): if self . best_test_sofar : self . logger . info ( \"Best test performance(may not correspond to the best dev performance): {} achieved at Epoch: {} .\" . format ( self . best_test_sofar , self . best_test_epoch )) if self . best_dev_test : self . logger . info ( \"Best test performance(correspond to the best dev performance): {} achieved at Epoch: {} .\" . format ( self . best_dev_test , self . best_dev_epoch )) def _check_eval_results ( metrics , metric_key = None ): # metrics: tester\u8fd4\u56de\u7684\u7ed3\u679c # metric_key: \u4e00\u4e2a\u7528\u6765\u505a\u7b5b\u9009\u7684\u6307\u6807\uff0c\u6765\u81eaTrainer\u7684\u521d\u59cb\u5316 if isinstance ( metrics , tuple ): loss , metrics = metrics if isinstance ( metrics , dict ): metric_dict = list ( metrics . values ())[ 0 ] # \u53d6\u7b2c\u4e00\u4e2ametric if metric_key is None : indicator_val , indicator = list ( metric_dict . values ())[ 0 ], list ( metric_dict . keys ())[ 0 ] else : # metric_key is set if metric_key not in metric_dict : raise RuntimeError ( f \"metric key { metric_key } not found in { metric_dict } \" ) indicator_val = metric_dict [ metric_key ] indicator = metric_key else : raise RuntimeError ( \"Invalid metrics type. Expect {} , got {} \" . format (( tuple , dict ), type ( metrics ))) return indicator , indicator_val 1.2: \u5b9e\u73b0relative_transformer.py\u4ee3\u7801 # encoding: utf-8 import torch from torch import nn import torch.nn.functional as F import math class RelativeSinusoidalPositionalEmbedding ( nn . Module ): # This module produces sinusoidal positional embeddings of any length. # Padding symbols are ignored. def __init__ ( self , embedding_dim , padding_idx , init_size = 1568 ): # embedding_dim: \u6bcf\u4e2a\u4f4d\u7f6e\u7684dimension # padding_idx: PAD\u5b57\u7b26\u6240\u5bf9\u5e94\u7684id\u503c # init_size: \u521d\u59cb\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6(\u6bd4\u5982BERT\u662f512) super () . __init__ () self . embedding_dim = embedding_dim self . padding_idx = padding_idx assert init_size % 2 == 0 weights = self . get_embedding ( init_size + 1 , embedding_dim , padding_idx ) self . register_buffer ( 'weights' , weights ) self . register_buffer ( '_float_tensor' , torch . FloatTensor ( 1 )) def get_embedding ( self , num_embeddings , embedding_dim , padding_idx = None ): # Build sinusoidal embeddings. # This matches the implementation in tensor2tensor, but differs slightly # from the description in Section 3.5 of \"Attention Is All You Need\". half_dim = embedding_dim // 2 emb = math . log ( 10000 ) / ( half_dim - 1 ) emb = torch . exp ( torch . arange ( half_dim , dtype = torch . float ) * - emb ) emb = torch . arange ( - num_embeddings // 2 , num_embeddings // 2 , dtype = torch . float ) . unsqueeze ( 1 ) * emb . unsqueeze ( 0 ) emb = torch . cat ([ torch . sin ( emb ), torch . cos ( emb )], dim = 1 ) . view ( num_embeddings , - 1 ) if embedding_dim % 2 == 1 : # zero pad emb = torch . cat ([ emb , torch . zeros ( num_embeddings , 1 )], dim = 1 ) if padding_idx is not None : emb [ padding_idx , :] = 0 self . origin_shift = num_embeddings // 2 + 1 return emb def forward ( self , input ): # Input is expected to be of size [bsz x seqlen]. bsz , seq_len = input . size () max_pos = self . padding_idx + seq_len if max_pos > self . origin_shift : # recompute/expand embeddings if needed weights = self . get_embedding ( max_pos * 2 , self . embedding_dim , self . padding_idx ) weights = weights . to ( self . _float_tensor ) del self . weights self . origin_shift = weights . size ( 0 ) // 2 self . register_buffer ( 'weights' , weights ) positions = torch . arange ( - seq_len , seq_len ) . to ( input . device ) . long () + self . origin_shift # 2*seq_len embed = self . weights . index_select ( 0 , positions . long ()) . detach () return embed class RelativeMultiHeadAttn ( nn . Module ): def __init__ ( self , d_model , n_head , dropout , r_w_bias = None , r_r_bias = None , scale = False ): \"\"\" :param int d_model: :param int n_head: :param dropout: \u5bf9attention map\u7684dropout :param r_w_bias: n_head x head_dim or None, \u5982\u679c\u4e3adim :param r_r_bias: n_head x head_dim or None, :param scale: :param rel_pos_embed: \"\"\" super () . __init__ () self . qkv_linear = nn . Linear ( d_model , d_model * 3 , bias = False ) self . n_head = n_head self . head_dim = d_model // n_head self . dropout_layer = nn . Dropout ( dropout ) self . pos_embed = RelativeSinusoidalPositionalEmbedding ( d_model // n_head , 0 , 1200 ) if scale : self . scale = math . sqrt ( d_model // n_head ) else : self . scale = 1 if r_r_bias is None or r_w_bias is None : # Biases are not shared self . r_r_bias = nn . Parameter ( nn . init . xavier_normal_ ( torch . zeros ( n_head , d_model // n_head ))) self . r_w_bias = nn . Parameter ( nn . init . xavier_normal_ ( torch . zeros ( n_head , d_model // n_head ))) else : self . r_r_bias = r_r_bias # r_r_bias\u5c31\u662fv self . r_w_bias = r_w_bias # r_w_bias\u5c31\u662fu def forward ( self , x , mask ): \"\"\" :param x: batch_size x max_len x d_model :param mask: batch_size x max_len :return: \"\"\" batch_size , max_len , d_model = x . size () pos_embed = self . pos_embed ( mask ) # l x head_dim qkv = self . qkv_linear ( x ) # batch_size x max_len x d_model 3 q , k , v = torch . chunk ( qkv , chunks = 3 , dim =- 1 ) q = q . view ( batch_size , max_len , self . n_head , - 1 ) . transpose ( 1 , 2 ) k = k . view ( batch_size , max_len , self . n_head , - 1 ) . transpose ( 1 , 2 ) v = v . view ( batch_size , max_len , self . n_head , - 1 ) . transpose ( 1 , 2 ) # b x n x l x d rw_head_q = q + self . r_r_bias [:, None ] AC = torch . einsum ( 'bnqd,bnkd->bnqk' , rw_head_q , k ) # b x n x l x d, n\u662fhead D_ = torch . einsum ( 'nd,ld->nl' , self . r_w_bias , pos_embed )[ None , :, None ] # head x 2max_len, \u6bcf\u4e2ahead\u5bf9\u4f4d\u7f6e\u7684bias B_ = torch . einsum ( 'bnqd,ld->bnql' , q , pos_embed ) # bsz x head x max_len x 2max_len\uff0c\u6bcf\u4e2aquery\u5bf9\u6bcf\u4e2ashift\u7684\u504f\u79fb E_ = torch . einsum ( 'bnqd,ld->bnql' , k , pos_embed ) # bsz x head x max_len x 2max_len, key\u5bf9relative\u7684bias BD = B_ + D_ # bsz x head x max_len x 2max_len, \u8981\u8f6c\u6362\u4e3absz x head x max_len x max_len BDE = self . _shift ( BD ) + self . _transpose_shift ( E_ ) # BDE = self._shift(BD) attn = AC + BDE attn = attn / self . scale attn = attn . masked_fill ( mask [:, None , None , :] . eq ( 0 ), float ( '-inf' )) attn = F . softmax ( attn , dim =- 1 ) attn = self . dropout_layer ( attn ) v = torch . matmul ( attn , v ) . transpose ( 1 , 2 ) . reshape ( batch_size , max_len , d_model ) # b x n x l x d return v def _shift ( self , BD ): \"\"\" \u7c7b\u4f3c -3 -2 -1 0 1 2 -3 -2 -1 0 1 2 -3 -2 -1 0 1 2 \u8f6c\u6362\u4e3a 0 1 2 -1 0 1 -2 -1 0 :param BD: batch_size x n_head x max_len x 2max_len :return: batch_size x n_head x max_len x max_len \"\"\" bsz , n_head , max_len , _ = BD . size () zero_pad = BD . new_zeros ( bsz , n_head , max_len , 1 ) BD = torch . cat ([ BD , zero_pad ], dim =- 1 ) . view ( bsz , n_head , - 1 , max_len ) # bsz x n_head x (2max_len+1) x max_len BD = BD [:, :, : - 1 ] . view ( bsz , n_head , max_len , - 1 ) # bsz x n_head x 2max_len x max_len BD = BD [:, :, :, max_len :] return BD def _transpose_shift ( self , E ): \"\"\" \u7c7b\u4f3c -3 -2 -1 0 1 2 -30 -20 -10 00 10 20 -300 -200 -100 000 100 200 \u8f6c\u6362\u4e3a 0 -10 -200 1 00 -100 2 10 000 :param E: batch_size x n_head x max_len x 2max_len :return: batch_size x n_head x max_len x max_len \"\"\" bsz , n_head , max_len , _ = E . size () zero_pad = E . new_zeros ( bsz , n_head , max_len , 1 ) # bsz x n_head x -1 x (max_len+1) E = torch . cat ([ E , zero_pad ], dim =- 1 ) . view ( bsz , n_head , - 1 , max_len ) indice = ( torch . arange ( max_len ) * 2 + 1 ) . to ( E . device ) E = E . index_select ( index = indice , dim =- 2 ) . transpose ( - 1 , - 2 ) # bsz x n_head x max_len x max_len return E 1.3: \u5b9e\u73b0TransformerEmbedding.py\u4ee3\u7801 # encoding: utf-8 from fastNLP.embeddings import TokenEmbedding import torch from fastNLP import Vocabulary import torch.nn.functional as F from fastNLP import logger from fastNLP.embeddings.utils import _construct_char_vocab_from_vocab , get_embeddings from torch import nn from .transformer import TransformerEncoder class TransformerCharEmbed ( TokenEmbedding ): def __init__ ( self , vocab : Vocabulary , embed_size : int = 30 , char_emb_size : int = 30 , word_dropout : float = 0 , dropout : float = 0 , pool_method : str = 'max' , activation = 'relu' , min_char_freq : int = 2 , requires_grad = True , include_word_start_end = True , char_attn_type = 'adatrans' , char_n_head = 3 , char_dim_ffn = 60 , char_scale = False , char_pos_embed = None , char_dropout = 0.15 , char_after_norm = False ): \"\"\" :param vocab: \u8bcd\u8868 :param embed_size: TransformerCharEmbed\u7684\u8f93\u51fa\u7ef4\u5ea6\u3002\u9ed8\u8ba4\u503c\u4e3a50. :param char_emb_size: character\u7684embedding\u7684\u7ef4\u5ea6\u3002\u9ed8\u8ba4\u503c\u4e3a50. \u540c\u65f6\u4e5f\u662fTransformer\u7684d_model\u5927\u5c0f :param float word_dropout: \u4ee5\u591a\u5927\u7684\u6982\u7387\u5c06\u4e00\u4e2a\u8bcd\u66ff\u6362\u4e3aunk\u3002\u8fd9\u6837\u65e2\u53ef\u4ee5\u8bad\u7ec3unk\u4e5f\u662f\u4e00\u5b9a\u7684regularize\u3002 :param dropout: \u4ee5\u591a\u5927\u6982\u7387drop character embedding\u7684\u8f93\u51fa\u4ee5\u53ca\u6700\u7ec8\u7684word\u7684\u8f93\u51fa\u3002 :param pool_method: \u652f\u6301'max', 'avg'\u3002 :param activation: \u6fc0\u6d3b\u51fd\u6570\uff0c\u652f\u6301'relu', 'sigmoid', 'tanh', \u6216\u8005\u81ea\u5b9a\u4e49\u51fd\u6570. :param min_char_freq: character\u7684\u6700\u5c0f\u51fa\u73b0\u6b21\u6570\u3002\u9ed8\u8ba4\u503c\u4e3a2. :param requires_grad: :param include_word_start_end: \u662f\u5426\u4f7f\u7528\u7279\u6b8a\u7684tag\u6807\u8bb0word\u7684\u5f00\u59cb\u4e0e\u7ed3\u675f :param char_attn_type: adatrans or naive. :param char_n_head: \u591a\u5c11\u4e2ahead :param char_dim_ffn: transformer\u4e2dffn\u4e2d\u95f4\u5c42\u7684\u5927\u5c0f :param char_scale: \u662f\u5426\u4f7f\u7528scale :param char_pos_embed: None, 'fix', 'sin'. What kind of position embedding. When char_attn_type=relative, None is ok :param char_dropout: Dropout in Transformer encoder :param char_after_norm: the normalization place. \"\"\" super ( TransformerCharEmbed , self ) . __init__ ( vocab , word_dropout = word_dropout , dropout = dropout ) assert char_emb_size % char_n_head == 0 , \"d_model should divide n_head.\" assert pool_method in ( 'max' , 'avg' ) self . pool_method = pool_method # activation function if isinstance ( activation , str ): if activation . lower () == 'relu' : self . activation = F . relu elif activation . lower () == 'sigmoid' : self . activation = F . sigmoid elif activation . lower () == 'tanh' : self . activation = F . tanh elif activation is None : self . activation = lambda x : x elif callable ( activation ): self . activation = activation else : raise Exception ( \"Undefined activation function: choose from: [relu, tanh, sigmoid, or a callable function]\" ) logger . info ( \"Start constructing character vocabulary.\" ) # \u5efa\u7acbchar\u7684\u8bcd\u8868 self . char_vocab = _construct_char_vocab_from_vocab ( vocab , min_freq = min_char_freq , include_word_start_end = include_word_start_end ) self . char_pad_index = self . char_vocab . padding_idx logger . info ( f \"In total, there are { len ( self . char_vocab ) } distinct characters.\" ) # \u5bf9vocab\u8fdb\u884cindex max_word_len = max ( map ( lambda x : len ( x [ 0 ]), vocab )) if include_word_start_end : max_word_len += 2 self . register_buffer ( 'words_to_chars_embedding' , torch . full (( len ( vocab ), max_word_len ), fill_value = self . char_pad_index , dtype = torch . long )) self . register_buffer ( 'word_lengths' , torch . zeros ( len ( vocab )) . long ()) for word , index in vocab : # if index!=vocab.padding_idx: # \u5982\u679c\u662fpad\u7684\u8bdd\uff0c\u76f4\u63a5\u5c31\u4e3apad_value\u4e86. \u4fee\u6539\u4e3a\u4e0d\u533a\u5206pad\u4e0e\u5426 if include_word_start_end : word = [ '<bow>' ] + list ( word ) + [ '<eow>' ] self . words_to_chars_embedding [ index , : len ( word )] = \\ torch . LongTensor ([ self . char_vocab . to_index ( c ) for c in word ]) self . word_lengths [ index ] = len ( word ) self . char_embedding = get_embeddings (( len ( self . char_vocab ), char_emb_size )) self . transformer = TransformerEncoder ( 1 , char_emb_size , char_n_head , char_dim_ffn , dropout = char_dropout , after_norm = char_after_norm , attn_type = char_attn_type , pos_embed = char_pos_embed , scale = char_scale ) self . fc = nn . Linear ( char_emb_size , embed_size ) self . _embed_size = embed_size self . requires_grad = requires_grad def forward ( self , words ): \"\"\" \u8f93\u5165words\u7684index\u540e\uff0c\u751f\u6210\u5bf9\u5e94\u7684words\u7684\u8868\u793a\u3002 :param words: [batch_size, max_len] :return: [batch_size, max_len, embed_size] \"\"\" words = self . drop_word ( words ) batch_size , max_len = words . size () chars = self . words_to_chars_embedding [ words ] # batch_size x max_len x max_word_len word_lengths = self . word_lengths [ words ] # batch_size x max_len max_word_len = word_lengths . max () chars = chars [:, :, : max_word_len ] # \u4e3amask\u7684\u5730\u65b9\u4e3a1 chars_masks = chars . eq ( self . char_pad_index ) # batch_size x max_len x max_word_len \u5982\u679c\u4e3a0, \u8bf4\u660e\u662fpadding\u7684\u4f4d\u7f6e\u4e86 char_embeds = self . char_embedding ( chars ) # batch_size x max_len x max_word_len x embed_size char_embeds = self . dropout ( char_embeds ) reshaped_chars = char_embeds . reshape ( batch_size * max_len , max_word_len , - 1 ) trans_chars = self . transformer ( reshaped_chars , chars_masks . eq ( 0 ) . reshape ( - 1 , max_word_len )) trans_chars = trans_chars . reshape ( batch_size , max_len , max_word_len , - 1 ) trans_chars = self . activation ( trans_chars ) if self . pool_method == 'max' : trans_chars = trans_chars . masked_fill ( chars_masks . unsqueeze ( - 1 ), float ( '-inf' )) chars , _ = torch . max ( trans_chars , dim =- 2 ) # batch_size x max_len x H else : trans_chars = trans_chars . masked_fill ( chars_masks . unsqueeze ( - 1 ), 0 ) chars = torch . sum ( trans_chars , dim =- 2 ) / chars_masks . eq ( 0 ) . sum ( dim =- 1 , keepdim = True ) . float () chars = self . fc ( chars ) return self . dropout ( chars ) 1.4: \u5b9e\u73b0utils.py\u4ee3\u7801 # encoding: utf-8 # \u8bbe\u7f6e\u968f\u673a\u6570\u79cd\u5b50 def set_rng_seed ( rng_seed : int = None , random : bool = True , numpy : bool = True , pytorch : bool = True , deterministic : bool = True ): \"\"\" \u8bbe\u7f6e\u6a21\u5757\u7684\u968f\u673a\u6570\u79cd\u5b50\u3002\u7531\u4e8epytorch\u8fd8\u5b58\u5728cudnn\u5bfc\u81f4\u7684\u975edeterministic\u7684\u8fd0\u884c\uff0c\u6240\u4ee5\u4e00\u4e9b\u60c5\u51b5\u4e0b\u53ef\u80fd\u5373\u4f7fseed\u4e00\u6837\uff0c\u7ed3\u679c\u4e5f\u4e0d\u4e00\u81f4 \u9700\u8981\u5728fitlog.commit()\u6216fitlog.set_log_dir()\u4e4b\u540e\u8fd0\u884c\u624d\u4f1a\u8bb0\u5f55\u8be5rng_seed\u5230log\u4e2d :param int rng_seed: \u5c06\u8fd9\u4e9b\u6a21\u5757\u7684\u968f\u673a\u6570\u8bbe\u7f6e\u5230\u591a\u5c11\uff0c\u9ed8\u8ba4\u4e3a\u968f\u673a\u751f\u6210\u4e00\u4e2a\u3002 :param bool, random: \u662f\u5426\u5c06python\u81ea\u5e26\u7684random\u6a21\u5757\u7684seed\u8bbe\u7f6e\u4e3arng_seed. :param bool, numpy: \u662f\u5426\u5c06numpy\u7684seed\u8bbe\u7f6e\u4e3arng_seed. :param bool, pytorch: \u662f\u5426\u5c06pytorch\u7684seed\u8bbe\u7f6e\u4e3arng_seed(\u8bbe\u7f6etorch.manual_seed\u548ctorch.cuda.manual_seed_all). :param bool, deterministic: \u662f\u5426\u5c06pytorch\u7684torch.backends.cudnn.deterministic\u8bbe\u7f6e\u4e3aTrue \"\"\" if rng_seed is None : import time rng_seed = int ( time . time () % 1000000 ) if random : import random random . seed ( rng_seed ) if numpy : try : import numpy numpy . random . seed ( rng_seed ) except : pass if pytorch : try : import torch torch . manual_seed ( rng_seed ) torch . cuda . manual_seed_all ( rng_seed ) if deterministic : torch . backends . cudnn . deterministic = True except : pass return rng_seed \u7b2c2\u6b65: \u6784\u5efa\u6a21\u578b\u7c7b\u7684\u4ee3\u7801 \u00b6 \u5b9e\u73b0TENER\u7c7b\u7684\u4ee3\u7801: /home/ec2-user/red_spider/ner/tener/models/TENER.py # encoding: utf-8 import torch from torch import nn import torch.nn.functional as F from fastNLP.modules import ConditionalRandomField , allowed_transitions from modules.transformer import TransformerEncoder class TENER ( nn . Module ): def __init__ ( self , tag_vocab , embed , num_layers , d_model , n_head , feedforward_dim , dropout , after_norm = True , attn_type = 'adatrans' , bi_embed = None , fc_dropout = 0.3 , pos_embed = None , encoding_type = None , scale = False , dropout_attn = None ): # tag_vocab: fastNLP Vocabulary # embed: fastNLP TokenEmbedding # num_layers: number of self-attention layers # d_model: input size # n_head: number of head # feedforward_dim: the dimension of ffn # dropout: dropout in self-attention # after_norm: normalization place # attn_type: adatrans, naive # rel_pos_embed: position embedding\u7684\u7c7b\u578b\uff0c\u652f\u6301sin, fix, None. relative\u65f6\u53ef\u4e3aNone # bi_embed: Used in Chinese scenerio # encoding_type: NER\u4efb\u52a1\u7684\u7f16\u7801\u6a21\u5f0f, \u6b64\u5904\u91c7\u7528'bmeso'\u6a21\u5f0f # fc_dropout: dropout rate before the fc layer super () . __init__ () self . embed = embed embed_size = self . embed . embed_size self . bi_embed = None if bi_embed is not None : self . bi_embed = bi_embed embed_size += self . bi_embed . embed_size self . in_fc = nn . Linear ( embed_size , d_model ) self . transformer = TransformerEncoder ( num_layers , d_model , n_head , feedforward_dim , dropout , after_norm = after_norm , attn_type = attn_type , scale = scale , dropout_attn = dropout_attn , pos_embed = pos_embed ) self . fc_dropout = nn . Dropout ( fc_dropout ) self . out_fc = nn . Linear ( d_model , len ( tag_vocab )) trans = allowed_transitions ( tag_vocab , encoding_type = encoding_type , include_start_end = True ) self . crf = ConditionalRandomField ( len ( tag_vocab ), include_start_end_trans = True , allowed_transitions = trans ) def _forward ( self , chars , target , bigrams = None ): mask = chars . ne ( 0 ) chars = self . embed ( chars ) if self . bi_embed is not None : bigrams = self . bi_embed ( bigrams ) chars = torch . cat ([ chars , bigrams ], dim =- 1 ) chars = self . in_fc ( chars ) chars = self . transformer ( chars , mask ) chars = self . fc_dropout ( chars ) chars = self . out_fc ( chars ) logits = F . log_softmax ( chars , dim =- 1 ) if target is None : paths , _ = self . crf . viterbi_decode ( logits , mask ) return { 'pred' : paths } else : loss = self . crf ( logits , target , mask ) return { 'loss' : loss } def forward ( self , chars , target , bigrams = None ): return self . _forward ( chars , target , bigrams ) def predict ( self , chars , bigrams = None ): return self . _forward ( chars , target = None , bigrams = bigrams ) \u7b2c3\u6b65: \u8bad\u7ec3\u51fd\u6570\u7684\u4ee3\u7801 \u00b6 \u5b9e\u73b0\u8bad\u7ec3\u4ee3\u7801: /home/ec2-user/red_spider/ner/tener/train_tener_cn.py # encoding: utf-8 from models.TENER import TENER from fastNLP import cache_results from fastNLP import Trainer , Tester from fastNLP.core.predictor import Predictor from fastNLP import GradientClipCallback , WarmupCallback from torch import optim from fastNLP import SpanFPreRecMetric , BucketSampler from fastNLP.embeddings import StaticEmbedding from modules.pipe import CNNERPipe import argparse from modules.callbacks import EvaluateCallback import os import sys import time import torch device = 0 parser = argparse . ArgumentParser () parser . add_argument ( '--dataset' , type = str , default = 'resume' , choices = [ 'weibo' , 'resume' , 'ontonotes' , 'msra' ]) parser . add_argument ( '--status' , type = str , default = 'train' , choices = [ 'train' , 'test' , 'predict' ]) args = parser . parse_args () dataset = args . dataset if dataset == 'resume' : n_heads = 4 head_dims = 64 num_layers = 2 lr = 0.0007 attn_type = 'adatrans' n_epochs = 100 elif dataset == 'weibo' : n_heads = 4 head_dims = 32 num_layers = 1 lr = 0.001 attn_type = 'adatrans' n_epochs = 100 elif dataset == 'ontonotes' : n_heads = 4 head_dims = 48 num_layers = 2 lr = 0.0007 attn_type = 'adatrans' n_epochs = 100 elif dataset == 'msra' : n_heads = 6 head_dims = 80 num_layers = 2 lr = 0.0007 attn_type = 'adatrans' n_epochs = 100 pos_embed = None batch_size = 128 warmup_steps = 0.01 after_norm = 1 model_type = 'transformer' normalize_embed = True dropout = 0.15 fc_dropout = 0.4 encoding_type = 'bmeso' name = './cache/ {} _ {} _ {} _ {} .pkl' . format ( dataset , model_type , encoding_type , normalize_embed ) d_model = n_heads * head_dims dim_feedforward = int ( 2 * d_model ) @cache_results ( name , _refresh = False ) def load_data (): # \u66ff\u6362\u8def\u5f84 if dataset == 'ontonotes' : paths = { 'train' : './data/OntoNote4NER/train.char.bmes' , \"dev\" : './data/OntoNote4NER/dev.char.bmes' , \"test\" : './data/OntoNote4NER/test.char.bmes' } min_freq = 2 elif dataset == 'weibo' : paths = { 'train' : './data/WeiboNER/train.all.bmes' , 'dev' : './data/WeiboNER/dev.all.bmes' , 'test' : './data/WeiboNER/test.all.bmes' } min_freq = 1 elif dataset == 'resume' : paths = { 'train' : './data/ResumeNER/train.char.bmes' , 'dev' : './data/ResumeNER/dev.char.bmes' , 'test' : './data/ResumeNER/test.char.bmes' } min_freq = 1 elif dataset == 'msra' : paths = { 'train' : './data/MSRANER/train_dev.char.bmes' , 'dev' : './data/MSRANER/test.char.bmes' , 'test' : './data/MSRANER/test.char.bmes' } min_freq = 2 data_bundle = CNNERPipe ( bigrams = True , encoding_type = encoding_type ) . process_from_file ( paths ) embed = StaticEmbedding ( data_bundle . get_vocab ( 'chars' ), model_dir_or_name = './data/gigaword_chn.all.a2b.uni.ite50.vec' , min_freq = 1 , only_norm_found_vector = normalize_embed , word_dropout = 0.01 , dropout = 0.3 ) bi_embed = StaticEmbedding ( data_bundle . get_vocab ( 'bigrams' ), model_dir_or_name = './data/gigaword_chn.all.a2b.bi.ite50.vec' , word_dropout = 0.02 , dropout = 0.3 , min_freq = min_freq , only_norm_found_vector = normalize_embed , only_train_min_freq = True ) return data_bundle , embed , bi_embed data_bundle , embed , bi_embed = load_data () print ( data_bundle ) model = TENER ( tag_vocab = data_bundle . get_vocab ( 'target' ), embed = embed , num_layers = num_layers , d_model = d_model , n_head = n_heads , feedforward_dim = dim_feedforward , dropout = dropout , after_norm = after_norm , attn_type = attn_type , bi_embed = bi_embed , fc_dropout = fc_dropout , pos_embed = pos_embed , encoding_type = encoding_type , scale = attn_type == 'transformer' ) optimizer = optim . SGD ( model . parameters (), lr = lr , momentum = 0.9 ) metrics = SpanFPreRecMetric ( tag_vocab = data_bundle . get_vocab ( 'target' ), encoding_type = encoding_type ) callbacks = [] clip_callback = GradientClipCallback ( clip_type = 'value' , clip_value = 5 ) evaluate_callback = EvaluateCallback ( data_bundle . get_dataset ( 'test' )) if warmup_steps > 0 : warmup_callback = WarmupCallback ( warmup_steps , schedule = 'linear' ) callbacks . append ( warmup_callback ) callbacks . extend ([ clip_callback , evaluate_callback ]) if args . status == 'train' : trainer = Trainer ( data_bundle . get_dataset ( 'train' ), model , optimizer , batch_size = batch_size , sampler = BucketSampler (), num_workers = 4 , n_epochs = n_epochs , dev_data = data_bundle . get_dataset ( 'dev' ), metrics = metrics , dev_batch_size = batch_size // 2 , callbacks = callbacks , device = device , test_use_tqdm = True , use_tqdm = True , print_every = 1 ) # \u8bad\u7ec3\u7ed3\u675f\u540e\u4e00\u5b9a\u8981\u4fdd\u5b58\u6700\u597d\u7684\u6a21\u578b, \u9ed8\u8ba4\u4f1a\u8fdb\u884c\u4fdd\u5b58. trainer . train () model_save_dir = \"./saved_model/ {} / {} \" . format ( args . dataset , time . strftime ( '%Y_%m_ %d _%H_%M_%S' )) if not os . path . exists ( model_save_dir ): os . makedirs ( model_save_dir ) model_save_path = \" {} /model_tener.pt\" . format ( model_save_dir ) torch . save ( model . state_dict (), model_save_path ) if args . status == 'test' : time_stamp = '2021_12_01_05_24_10' model_save_path = \"./saved_model/ {} / {} /model_tener.pt\" . format ( args . dataset , time_stamp ) model . load_state_dict ( torch . load ( model_save_path )) tester = Tester ( data_bundle . get_dataset ( 'test' ), model , metrics = metrics , device = device ) res = tester . test () print ( res ) predictor = Predictor ( model ) predictor . batch_size = 32 start_time = time . time () # \u9884\u6d4b\u7ed3\u679c test_label_list = predictor . predict ( data_bundle . get_dataset ( 'test' ))[ 'pred' ] end_time = time . time () print ( 'Prediction cost time:' , end_time - start_time ) pred_tags = [] for test_label in test_label_list : for item in test_label : pred_tags . append ( item ) # \u539f\u59cb\u6587\u5b57 test_raw_char = data_bundle . get_dataset ( 'test' )[ 'raw_chars' ] predict_path = \"./results/ner_predict.txt\" with open ( predict_path , \"w\" , encoding = 'utf-8' ) as f : for sentence , tags in zip ( test_raw_char , pred_tags ): for i in range ( len ( sentence )): ch = sentence [ i ] tag_text = data_bundle . get_vocab ( 'target' ) . to_word ( tags [ i ]) f . write ( ch + ' ' + tag_text + ' \\n ' ) f . write ( ' \\n ' ) \u7b2c4\u6b65: \u6a21\u578b\u8bad\u7ec3 \u00b6 \u8c03\u7528: python train_tener_cn.py --dataset resume \u8f93\u51fa\u7ed3\u679c: Read cache from ./cache/resume_transformer_bmeso_True.pkl. In total 3 datasets: train has 2000 instances. dev has 532 instances. test has 532 instances. In total 3 vocabs: chars has 1096 entries. bigrams has 5550 entries. target has 7 entries. input fields after batch(if batch size is 2): target: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2, 59]) chars: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2, 59]) bigrams: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2, 59]) seq_len: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2]) target fields after batch(if batch size is 2): target: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2, 59]) seq_len: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2]) training epochs started 2023-02-25-12-52-13 Evaluate data in 0.69 seconds! Evaluate data in 0.69 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.080617, pre=0.043392, rec=0.567179 Evaluation on dev at Epoch 1/200. Step:16/3200: SpanFPreRecMetric: f=0.080617, pre=0.043392, rec=0.567179 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0 Evaluation on dev at Epoch 2/200. Step:32/3200: SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0 Evaluate data in 0.67 seconds! Evaluate data in 0.67 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0 Evaluation on dev at Epoch 3/200. Step:48/3200: SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0 Evaluation on dev at Epoch 4/200. Step:64/3200: SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0 Evaluate data in 0.67 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.093066, pre=0.944444, rec=0.048944 Evaluation on dev at Epoch 5/200. Step:80/3200: SpanFPreRecMetric: f=0.093066, pre=0.944444, rec=0.048944 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.524046, pre=0.461314, rec=0.606526 Evaluation on dev at Epoch 6/200. Step:96/3200: SpanFPreRecMetric: f=0.524046, pre=0.461314, rec=0.606526 Evaluate data in 0.67 seconds! Evaluate data in 0.67 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.484195, pre=0.962857, rec=0.323417 Evaluation on dev at Epoch 7/200. Step:112/3200: SpanFPreRecMetric: f=0.484195, pre=0.962857, rec=0.323417 Evaluate data in 0.67 seconds! Evaluate data in 0.67 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.700119, pre=0.927215, rec=0.56238 Evaluation on dev at Epoch 8/200. Step:128/3200: SpanFPreRecMetric: f=0.700119, pre=0.927215, rec=0.56238 Evaluate data in 0.67 seconds! Evaluate data in 0.67 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.784035, pre=0.911055, rec=0.6881 Evaluation on dev at Epoch 9/200. Step:144/3200: SpanFPreRecMetric: f=0.784035, pre=0.911055, rec=0.6881 Evaluate data in 0.67 seconds! Evaluate data in 0.67 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.78663, pre=0.937583, rec=0.677543 Evaluation on dev at Epoch 10/200. Step:160/3200: SpanFPreRecMetric: f=0.78663, pre=0.937583, rec=0.677543 Evaluate data in 0.68 seconds! Evaluate data in 0.67 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.809218, pre=0.916262, rec=0.724568 Evaluation on dev at Epoch 11/200. Step:176/3200: SpanFPreRecMetric: f=0.809218, pre=0.916262, rec=0.724568 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.817942, pre=0.908558, rec=0.743762 Evaluation on dev at Epoch 12/200. Step:192/3200: SpanFPreRecMetric: f=0.817942, pre=0.908558, rec=0.743762 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.819672, pre=0.912839, rec=0.743762 Evaluation on dev at Epoch 13/200. Step:208/3200: SpanFPreRecMetric: f=0.819672, pre=0.912839, rec=0.743762 Evaluate data in 0.68 seconds! Evaluate data in 0.67 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.837686, pre=0.897914, rec=0.785029 Evaluation on dev at Epoch 14/200. Step:224/3200: SpanFPreRecMetric: f=0.837686, pre=0.897914, rec=0.785029 Evaluate data in 0.67 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.846582, pre=0.896034, rec=0.802303 Evaluation on dev at Epoch 15/200. Step:240/3200: SpanFPreRecMetric: f=0.846582, pre=0.896034, rec=0.802303 ...... ...... ...... ...... ...... ...... Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluation on dev at Epoch 192/200. Step:3072/3200: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.978663, pre=0.967198, rec=0.990403 Evaluation on dev at Epoch 193/200. Step:3088/3200: SpanFPreRecMetric: f=0.978663, pre=0.967198, rec=0.990403 Evaluate data in 0.67 seconds! Evaluate data in 0.67 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.981455, pre=0.972667, rec=0.990403 Evaluation on dev at Epoch 194/200. Step:3104/3200: SpanFPreRecMetric: f=0.981455, pre=0.972667, rec=0.990403 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.981455, pre=0.972667, rec=0.990403 Evaluation on dev at Epoch 195/200. Step:3120/3200: SpanFPreRecMetric: f=0.981455, pre=0.972667, rec=0.990403 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluation on dev at Epoch 196/200. Step:3136/3200: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluation on dev at Epoch 197/200. Step:3152/3200: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluation on dev at Epoch 198/200. Step:3168/3200: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluate data in 0.67 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluation on dev at Epoch 199/200. Step:3184/3200: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluation on dev at Epoch 200/200. Step:3200/3200: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Best test performance(may not correspond to the best dev performance):{'SpanFPreRecMetric': {'f': 0.987112, 'pre': 0.981956, 'rec': 0.992322}} achieved at Epoch:173. Best test performance(correspond to the best dev performance):{'SpanFPreRecMetric': {'f': 0.987112, 'pre': 0.981956, 'rec': 0.992322}} achieved at Epoch:173. In Epoch:173/Step:2768, got best dev performance: SpanFPreRecMetric: f=0.987112, pre=0.981956, rec=0.992322 Reloaded the best model. \u5c0f\u8282\u603b\u7ed3 \u00b6 \u672c\u5c0f\u8282\u5b66\u4e60\u4e86TENER\u6a21\u578b\u7684\u67b6\u6784\u548c\u4ee3\u7801\u5b9e\u73b0.","title":"11.1 TENER\u6a21\u578b"},{"location":"11_1.html#tener","text":"","title":"TENER\u6a21\u578b"},{"location":"11_1.html#_1","text":"\u638c\u63e1TENER\u6a21\u578b\u7684\u642d\u5efa, \u8bad\u7ec3\u548c\u6d4b\u8bd5\u4ee3\u7801\u5b9e\u73b0.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"11_1.html#tener_1","text":"TENER\u6a21\u578b\u7684\u5b9e\u73b0\u6b65\u9aa4\u5982\u4e0b: \u7b2c1\u6b65: \u6784\u5efa\u5b50\u6a21\u5757\u7684\u4ee3\u7801 \u7b2c2\u6b65: \u6784\u5efa\u6a21\u578b\u7c7b\u7684\u4ee3\u7801 \u7b2c3\u6b65: \u8bad\u7ec3\u51fd\u6570\u7684\u4ee3\u7801","title":"TENER\u6a21\u578b\u4ee3\u7801\u5b9e\u73b0"},{"location":"11_1.html#1","text":"1.1: \u5b9e\u73b0callbacks.py\u4ee3\u7801 from fastNLP import Callback , Tester , DataSet class EvaluateCallback ( Callback ): \"\"\" \u901a\u8fc7\u4f7f\u7528\u8be5Callback\u53ef\u4ee5\u4f7f\u5f97Trainer\u5728evaluate dev\u4e4b\u5916\u8fd8\u53ef\u4ee5evaluate\u5176\u5b83\u6570\u636e\u96c6\uff0c\u6bd4\u5982\u6d4b\u8bd5\u96c6\u3002\u6bcf\u4e00\u6b21\u9a8c\u8bc1dev\u4e4b\u524d\u90fd\u4f1a\u5148\u9a8c\u8bc1EvaluateCallback \u4e2d\u7684\u6570\u636e\u3002 \"\"\" def __init__ ( self , data = None , tester = None ): \"\"\" :param ~fastNLP.DataSet,Dict[~fastNLP.DataSet] data: \u4f20\u5165DataSet\u5bf9\u8c61\uff0c\u4f1a\u4f7f\u7528Trainer\u4e2d\u7684metric\u5bf9\u6570\u636e\u8fdb\u884c\u9a8c\u8bc1\u3002\u5982\u679c\u9700\u8981 \u4f20\u5165\u591a\u4e2a DataSet\u8bf7\u901a\u8fc7dict\u7684\u65b9\u5f0f\u4f20\u5165\u3002 :param ~fastNLP.Tester,Dict[~fastNLP.DataSet] tester: Tester\u5bf9\u8c61, \u901a\u8fc7\u4f7f\u7528Tester\u5bf9\u8c61\uff0c\u53ef\u4ee5\u4f7f\u5f97\u9a8c\u8bc1\u7684metric\u4e0eTrainer\u4e2d \u7684metric\u4e0d\u4e00\u6837\u3002 \"\"\" super () . __init__ () self . datasets = {} self . testers = {} self . best_test_metric_sofar = 0 self . best_test_sofar = None self . best_test_epoch = 0 self . best_dev_test = None self . best_dev_epoch = 0 if tester is not None : if isinstance ( tester , dict ): for name , test in tester . items (): if not isinstance ( test , Tester ): raise TypeError ( f \" { name } in tester is not a valid fastNLP.Tester.\" ) self . testers [ 'tester-' + name ] = test if isinstance ( tester , Tester ): self . testers [ 'tester-test' ] = tester for tester in self . testers . values (): setattr ( tester , 'verbose' , 0 ) if isinstance ( data , dict ): for key , value in data . items (): assert isinstance ( value , DataSet ), f \"Only DataSet object is allowed, not { type ( value ) } .\" for key , value in data . items (): self . datasets [ 'data-' + key ] = value elif isinstance ( data , DataSet ): self . datasets [ 'data-test' ] = data elif data is not None : raise TypeError ( \"data receives dict[DataSet] or DataSet object.\" ) def on_train_begin ( self ): if len ( self . datasets ) > 0 and self . trainer . dev_data is None : raise RuntimeError ( \"Trainer has no dev data, you cannot pass extra DataSet to do evaluation.\" ) if len ( self . datasets ) > 0 : for key , data in self . datasets . items (): tester = Tester ( data = data , model = self . model , batch_size = self . trainer . kwargs . get ( 'dev_batch_size' , self . batch_size ), metrics = self . trainer . metrics , verbose = 0 , use_tqdm = self . trainer . test_use_tqdm ) self . testers [ key ] = tester def on_valid_end ( self , eval_result , metric_key , optimizer , better_result ): if len ( self . testers ) > 0 : for idx , ( key , tester ) in enumerate ( self . testers . items ()): try : eval_result = tester . test () if idx == 0 : indicator , indicator_val = _check_eval_results ( eval_result ) if indicator_val > self . best_test_metric_sofar : self . best_test_metric_sofar = indicator_val self . best_test_epoch = self . epoch self . best_test_sofar = eval_result if better_result : self . best_dev_test = eval_result self . best_dev_epoch = self . epoch self . logger . info ( \"EvaluateCallback evaluation on {} :\" . format ( key )) self . logger . info ( tester . _format_eval_results ( eval_result )) except Exception as e : self . logger . error ( \"Exception happens when evaluate on DataSet named ` {} `.\" . format ( key )) raise e def on_train_end ( self ): if self . best_test_sofar : self . logger . info ( \"Best test performance(may not correspond to the best dev performance): {} achieved at Epoch: {} .\" . format ( self . best_test_sofar , self . best_test_epoch )) if self . best_dev_test : self . logger . info ( \"Best test performance(correspond to the best dev performance): {} achieved at Epoch: {} .\" . format ( self . best_dev_test , self . best_dev_epoch )) def _check_eval_results ( metrics , metric_key = None ): # metrics: tester\u8fd4\u56de\u7684\u7ed3\u679c # metric_key: \u4e00\u4e2a\u7528\u6765\u505a\u7b5b\u9009\u7684\u6307\u6807\uff0c\u6765\u81eaTrainer\u7684\u521d\u59cb\u5316 if isinstance ( metrics , tuple ): loss , metrics = metrics if isinstance ( metrics , dict ): metric_dict = list ( metrics . values ())[ 0 ] # \u53d6\u7b2c\u4e00\u4e2ametric if metric_key is None : indicator_val , indicator = list ( metric_dict . values ())[ 0 ], list ( metric_dict . keys ())[ 0 ] else : # metric_key is set if metric_key not in metric_dict : raise RuntimeError ( f \"metric key { metric_key } not found in { metric_dict } \" ) indicator_val = metric_dict [ metric_key ] indicator = metric_key else : raise RuntimeError ( \"Invalid metrics type. Expect {} , got {} \" . format (( tuple , dict ), type ( metrics ))) return indicator , indicator_val 1.2: \u5b9e\u73b0relative_transformer.py\u4ee3\u7801 # encoding: utf-8 import torch from torch import nn import torch.nn.functional as F import math class RelativeSinusoidalPositionalEmbedding ( nn . Module ): # This module produces sinusoidal positional embeddings of any length. # Padding symbols are ignored. def __init__ ( self , embedding_dim , padding_idx , init_size = 1568 ): # embedding_dim: \u6bcf\u4e2a\u4f4d\u7f6e\u7684dimension # padding_idx: PAD\u5b57\u7b26\u6240\u5bf9\u5e94\u7684id\u503c # init_size: \u521d\u59cb\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6(\u6bd4\u5982BERT\u662f512) super () . __init__ () self . embedding_dim = embedding_dim self . padding_idx = padding_idx assert init_size % 2 == 0 weights = self . get_embedding ( init_size + 1 , embedding_dim , padding_idx ) self . register_buffer ( 'weights' , weights ) self . register_buffer ( '_float_tensor' , torch . FloatTensor ( 1 )) def get_embedding ( self , num_embeddings , embedding_dim , padding_idx = None ): # Build sinusoidal embeddings. # This matches the implementation in tensor2tensor, but differs slightly # from the description in Section 3.5 of \"Attention Is All You Need\". half_dim = embedding_dim // 2 emb = math . log ( 10000 ) / ( half_dim - 1 ) emb = torch . exp ( torch . arange ( half_dim , dtype = torch . float ) * - emb ) emb = torch . arange ( - num_embeddings // 2 , num_embeddings // 2 , dtype = torch . float ) . unsqueeze ( 1 ) * emb . unsqueeze ( 0 ) emb = torch . cat ([ torch . sin ( emb ), torch . cos ( emb )], dim = 1 ) . view ( num_embeddings , - 1 ) if embedding_dim % 2 == 1 : # zero pad emb = torch . cat ([ emb , torch . zeros ( num_embeddings , 1 )], dim = 1 ) if padding_idx is not None : emb [ padding_idx , :] = 0 self . origin_shift = num_embeddings // 2 + 1 return emb def forward ( self , input ): # Input is expected to be of size [bsz x seqlen]. bsz , seq_len = input . size () max_pos = self . padding_idx + seq_len if max_pos > self . origin_shift : # recompute/expand embeddings if needed weights = self . get_embedding ( max_pos * 2 , self . embedding_dim , self . padding_idx ) weights = weights . to ( self . _float_tensor ) del self . weights self . origin_shift = weights . size ( 0 ) // 2 self . register_buffer ( 'weights' , weights ) positions = torch . arange ( - seq_len , seq_len ) . to ( input . device ) . long () + self . origin_shift # 2*seq_len embed = self . weights . index_select ( 0 , positions . long ()) . detach () return embed class RelativeMultiHeadAttn ( nn . Module ): def __init__ ( self , d_model , n_head , dropout , r_w_bias = None , r_r_bias = None , scale = False ): \"\"\" :param int d_model: :param int n_head: :param dropout: \u5bf9attention map\u7684dropout :param r_w_bias: n_head x head_dim or None, \u5982\u679c\u4e3adim :param r_r_bias: n_head x head_dim or None, :param scale: :param rel_pos_embed: \"\"\" super () . __init__ () self . qkv_linear = nn . Linear ( d_model , d_model * 3 , bias = False ) self . n_head = n_head self . head_dim = d_model // n_head self . dropout_layer = nn . Dropout ( dropout ) self . pos_embed = RelativeSinusoidalPositionalEmbedding ( d_model // n_head , 0 , 1200 ) if scale : self . scale = math . sqrt ( d_model // n_head ) else : self . scale = 1 if r_r_bias is None or r_w_bias is None : # Biases are not shared self . r_r_bias = nn . Parameter ( nn . init . xavier_normal_ ( torch . zeros ( n_head , d_model // n_head ))) self . r_w_bias = nn . Parameter ( nn . init . xavier_normal_ ( torch . zeros ( n_head , d_model // n_head ))) else : self . r_r_bias = r_r_bias # r_r_bias\u5c31\u662fv self . r_w_bias = r_w_bias # r_w_bias\u5c31\u662fu def forward ( self , x , mask ): \"\"\" :param x: batch_size x max_len x d_model :param mask: batch_size x max_len :return: \"\"\" batch_size , max_len , d_model = x . size () pos_embed = self . pos_embed ( mask ) # l x head_dim qkv = self . qkv_linear ( x ) # batch_size x max_len x d_model 3 q , k , v = torch . chunk ( qkv , chunks = 3 , dim =- 1 ) q = q . view ( batch_size , max_len , self . n_head , - 1 ) . transpose ( 1 , 2 ) k = k . view ( batch_size , max_len , self . n_head , - 1 ) . transpose ( 1 , 2 ) v = v . view ( batch_size , max_len , self . n_head , - 1 ) . transpose ( 1 , 2 ) # b x n x l x d rw_head_q = q + self . r_r_bias [:, None ] AC = torch . einsum ( 'bnqd,bnkd->bnqk' , rw_head_q , k ) # b x n x l x d, n\u662fhead D_ = torch . einsum ( 'nd,ld->nl' , self . r_w_bias , pos_embed )[ None , :, None ] # head x 2max_len, \u6bcf\u4e2ahead\u5bf9\u4f4d\u7f6e\u7684bias B_ = torch . einsum ( 'bnqd,ld->bnql' , q , pos_embed ) # bsz x head x max_len x 2max_len\uff0c\u6bcf\u4e2aquery\u5bf9\u6bcf\u4e2ashift\u7684\u504f\u79fb E_ = torch . einsum ( 'bnqd,ld->bnql' , k , pos_embed ) # bsz x head x max_len x 2max_len, key\u5bf9relative\u7684bias BD = B_ + D_ # bsz x head x max_len x 2max_len, \u8981\u8f6c\u6362\u4e3absz x head x max_len x max_len BDE = self . _shift ( BD ) + self . _transpose_shift ( E_ ) # BDE = self._shift(BD) attn = AC + BDE attn = attn / self . scale attn = attn . masked_fill ( mask [:, None , None , :] . eq ( 0 ), float ( '-inf' )) attn = F . softmax ( attn , dim =- 1 ) attn = self . dropout_layer ( attn ) v = torch . matmul ( attn , v ) . transpose ( 1 , 2 ) . reshape ( batch_size , max_len , d_model ) # b x n x l x d return v def _shift ( self , BD ): \"\"\" \u7c7b\u4f3c -3 -2 -1 0 1 2 -3 -2 -1 0 1 2 -3 -2 -1 0 1 2 \u8f6c\u6362\u4e3a 0 1 2 -1 0 1 -2 -1 0 :param BD: batch_size x n_head x max_len x 2max_len :return: batch_size x n_head x max_len x max_len \"\"\" bsz , n_head , max_len , _ = BD . size () zero_pad = BD . new_zeros ( bsz , n_head , max_len , 1 ) BD = torch . cat ([ BD , zero_pad ], dim =- 1 ) . view ( bsz , n_head , - 1 , max_len ) # bsz x n_head x (2max_len+1) x max_len BD = BD [:, :, : - 1 ] . view ( bsz , n_head , max_len , - 1 ) # bsz x n_head x 2max_len x max_len BD = BD [:, :, :, max_len :] return BD def _transpose_shift ( self , E ): \"\"\" \u7c7b\u4f3c -3 -2 -1 0 1 2 -30 -20 -10 00 10 20 -300 -200 -100 000 100 200 \u8f6c\u6362\u4e3a 0 -10 -200 1 00 -100 2 10 000 :param E: batch_size x n_head x max_len x 2max_len :return: batch_size x n_head x max_len x max_len \"\"\" bsz , n_head , max_len , _ = E . size () zero_pad = E . new_zeros ( bsz , n_head , max_len , 1 ) # bsz x n_head x -1 x (max_len+1) E = torch . cat ([ E , zero_pad ], dim =- 1 ) . view ( bsz , n_head , - 1 , max_len ) indice = ( torch . arange ( max_len ) * 2 + 1 ) . to ( E . device ) E = E . index_select ( index = indice , dim =- 2 ) . transpose ( - 1 , - 2 ) # bsz x n_head x max_len x max_len return E 1.3: \u5b9e\u73b0TransformerEmbedding.py\u4ee3\u7801 # encoding: utf-8 from fastNLP.embeddings import TokenEmbedding import torch from fastNLP import Vocabulary import torch.nn.functional as F from fastNLP import logger from fastNLP.embeddings.utils import _construct_char_vocab_from_vocab , get_embeddings from torch import nn from .transformer import TransformerEncoder class TransformerCharEmbed ( TokenEmbedding ): def __init__ ( self , vocab : Vocabulary , embed_size : int = 30 , char_emb_size : int = 30 , word_dropout : float = 0 , dropout : float = 0 , pool_method : str = 'max' , activation = 'relu' , min_char_freq : int = 2 , requires_grad = True , include_word_start_end = True , char_attn_type = 'adatrans' , char_n_head = 3 , char_dim_ffn = 60 , char_scale = False , char_pos_embed = None , char_dropout = 0.15 , char_after_norm = False ): \"\"\" :param vocab: \u8bcd\u8868 :param embed_size: TransformerCharEmbed\u7684\u8f93\u51fa\u7ef4\u5ea6\u3002\u9ed8\u8ba4\u503c\u4e3a50. :param char_emb_size: character\u7684embedding\u7684\u7ef4\u5ea6\u3002\u9ed8\u8ba4\u503c\u4e3a50. \u540c\u65f6\u4e5f\u662fTransformer\u7684d_model\u5927\u5c0f :param float word_dropout: \u4ee5\u591a\u5927\u7684\u6982\u7387\u5c06\u4e00\u4e2a\u8bcd\u66ff\u6362\u4e3aunk\u3002\u8fd9\u6837\u65e2\u53ef\u4ee5\u8bad\u7ec3unk\u4e5f\u662f\u4e00\u5b9a\u7684regularize\u3002 :param dropout: \u4ee5\u591a\u5927\u6982\u7387drop character embedding\u7684\u8f93\u51fa\u4ee5\u53ca\u6700\u7ec8\u7684word\u7684\u8f93\u51fa\u3002 :param pool_method: \u652f\u6301'max', 'avg'\u3002 :param activation: \u6fc0\u6d3b\u51fd\u6570\uff0c\u652f\u6301'relu', 'sigmoid', 'tanh', \u6216\u8005\u81ea\u5b9a\u4e49\u51fd\u6570. :param min_char_freq: character\u7684\u6700\u5c0f\u51fa\u73b0\u6b21\u6570\u3002\u9ed8\u8ba4\u503c\u4e3a2. :param requires_grad: :param include_word_start_end: \u662f\u5426\u4f7f\u7528\u7279\u6b8a\u7684tag\u6807\u8bb0word\u7684\u5f00\u59cb\u4e0e\u7ed3\u675f :param char_attn_type: adatrans or naive. :param char_n_head: \u591a\u5c11\u4e2ahead :param char_dim_ffn: transformer\u4e2dffn\u4e2d\u95f4\u5c42\u7684\u5927\u5c0f :param char_scale: \u662f\u5426\u4f7f\u7528scale :param char_pos_embed: None, 'fix', 'sin'. What kind of position embedding. When char_attn_type=relative, None is ok :param char_dropout: Dropout in Transformer encoder :param char_after_norm: the normalization place. \"\"\" super ( TransformerCharEmbed , self ) . __init__ ( vocab , word_dropout = word_dropout , dropout = dropout ) assert char_emb_size % char_n_head == 0 , \"d_model should divide n_head.\" assert pool_method in ( 'max' , 'avg' ) self . pool_method = pool_method # activation function if isinstance ( activation , str ): if activation . lower () == 'relu' : self . activation = F . relu elif activation . lower () == 'sigmoid' : self . activation = F . sigmoid elif activation . lower () == 'tanh' : self . activation = F . tanh elif activation is None : self . activation = lambda x : x elif callable ( activation ): self . activation = activation else : raise Exception ( \"Undefined activation function: choose from: [relu, tanh, sigmoid, or a callable function]\" ) logger . info ( \"Start constructing character vocabulary.\" ) # \u5efa\u7acbchar\u7684\u8bcd\u8868 self . char_vocab = _construct_char_vocab_from_vocab ( vocab , min_freq = min_char_freq , include_word_start_end = include_word_start_end ) self . char_pad_index = self . char_vocab . padding_idx logger . info ( f \"In total, there are { len ( self . char_vocab ) } distinct characters.\" ) # \u5bf9vocab\u8fdb\u884cindex max_word_len = max ( map ( lambda x : len ( x [ 0 ]), vocab )) if include_word_start_end : max_word_len += 2 self . register_buffer ( 'words_to_chars_embedding' , torch . full (( len ( vocab ), max_word_len ), fill_value = self . char_pad_index , dtype = torch . long )) self . register_buffer ( 'word_lengths' , torch . zeros ( len ( vocab )) . long ()) for word , index in vocab : # if index!=vocab.padding_idx: # \u5982\u679c\u662fpad\u7684\u8bdd\uff0c\u76f4\u63a5\u5c31\u4e3apad_value\u4e86. \u4fee\u6539\u4e3a\u4e0d\u533a\u5206pad\u4e0e\u5426 if include_word_start_end : word = [ '<bow>' ] + list ( word ) + [ '<eow>' ] self . words_to_chars_embedding [ index , : len ( word )] = \\ torch . LongTensor ([ self . char_vocab . to_index ( c ) for c in word ]) self . word_lengths [ index ] = len ( word ) self . char_embedding = get_embeddings (( len ( self . char_vocab ), char_emb_size )) self . transformer = TransformerEncoder ( 1 , char_emb_size , char_n_head , char_dim_ffn , dropout = char_dropout , after_norm = char_after_norm , attn_type = char_attn_type , pos_embed = char_pos_embed , scale = char_scale ) self . fc = nn . Linear ( char_emb_size , embed_size ) self . _embed_size = embed_size self . requires_grad = requires_grad def forward ( self , words ): \"\"\" \u8f93\u5165words\u7684index\u540e\uff0c\u751f\u6210\u5bf9\u5e94\u7684words\u7684\u8868\u793a\u3002 :param words: [batch_size, max_len] :return: [batch_size, max_len, embed_size] \"\"\" words = self . drop_word ( words ) batch_size , max_len = words . size () chars = self . words_to_chars_embedding [ words ] # batch_size x max_len x max_word_len word_lengths = self . word_lengths [ words ] # batch_size x max_len max_word_len = word_lengths . max () chars = chars [:, :, : max_word_len ] # \u4e3amask\u7684\u5730\u65b9\u4e3a1 chars_masks = chars . eq ( self . char_pad_index ) # batch_size x max_len x max_word_len \u5982\u679c\u4e3a0, \u8bf4\u660e\u662fpadding\u7684\u4f4d\u7f6e\u4e86 char_embeds = self . char_embedding ( chars ) # batch_size x max_len x max_word_len x embed_size char_embeds = self . dropout ( char_embeds ) reshaped_chars = char_embeds . reshape ( batch_size * max_len , max_word_len , - 1 ) trans_chars = self . transformer ( reshaped_chars , chars_masks . eq ( 0 ) . reshape ( - 1 , max_word_len )) trans_chars = trans_chars . reshape ( batch_size , max_len , max_word_len , - 1 ) trans_chars = self . activation ( trans_chars ) if self . pool_method == 'max' : trans_chars = trans_chars . masked_fill ( chars_masks . unsqueeze ( - 1 ), float ( '-inf' )) chars , _ = torch . max ( trans_chars , dim =- 2 ) # batch_size x max_len x H else : trans_chars = trans_chars . masked_fill ( chars_masks . unsqueeze ( - 1 ), 0 ) chars = torch . sum ( trans_chars , dim =- 2 ) / chars_masks . eq ( 0 ) . sum ( dim =- 1 , keepdim = True ) . float () chars = self . fc ( chars ) return self . dropout ( chars ) 1.4: \u5b9e\u73b0utils.py\u4ee3\u7801 # encoding: utf-8 # \u8bbe\u7f6e\u968f\u673a\u6570\u79cd\u5b50 def set_rng_seed ( rng_seed : int = None , random : bool = True , numpy : bool = True , pytorch : bool = True , deterministic : bool = True ): \"\"\" \u8bbe\u7f6e\u6a21\u5757\u7684\u968f\u673a\u6570\u79cd\u5b50\u3002\u7531\u4e8epytorch\u8fd8\u5b58\u5728cudnn\u5bfc\u81f4\u7684\u975edeterministic\u7684\u8fd0\u884c\uff0c\u6240\u4ee5\u4e00\u4e9b\u60c5\u51b5\u4e0b\u53ef\u80fd\u5373\u4f7fseed\u4e00\u6837\uff0c\u7ed3\u679c\u4e5f\u4e0d\u4e00\u81f4 \u9700\u8981\u5728fitlog.commit()\u6216fitlog.set_log_dir()\u4e4b\u540e\u8fd0\u884c\u624d\u4f1a\u8bb0\u5f55\u8be5rng_seed\u5230log\u4e2d :param int rng_seed: \u5c06\u8fd9\u4e9b\u6a21\u5757\u7684\u968f\u673a\u6570\u8bbe\u7f6e\u5230\u591a\u5c11\uff0c\u9ed8\u8ba4\u4e3a\u968f\u673a\u751f\u6210\u4e00\u4e2a\u3002 :param bool, random: \u662f\u5426\u5c06python\u81ea\u5e26\u7684random\u6a21\u5757\u7684seed\u8bbe\u7f6e\u4e3arng_seed. :param bool, numpy: \u662f\u5426\u5c06numpy\u7684seed\u8bbe\u7f6e\u4e3arng_seed. :param bool, pytorch: \u662f\u5426\u5c06pytorch\u7684seed\u8bbe\u7f6e\u4e3arng_seed(\u8bbe\u7f6etorch.manual_seed\u548ctorch.cuda.manual_seed_all). :param bool, deterministic: \u662f\u5426\u5c06pytorch\u7684torch.backends.cudnn.deterministic\u8bbe\u7f6e\u4e3aTrue \"\"\" if rng_seed is None : import time rng_seed = int ( time . time () % 1000000 ) if random : import random random . seed ( rng_seed ) if numpy : try : import numpy numpy . random . seed ( rng_seed ) except : pass if pytorch : try : import torch torch . manual_seed ( rng_seed ) torch . cuda . manual_seed_all ( rng_seed ) if deterministic : torch . backends . cudnn . deterministic = True except : pass return rng_seed","title":"\u7b2c1\u6b65: \u6784\u5efa\u5b50\u6a21\u5757\u7684\u4ee3\u7801"},{"location":"11_1.html#2","text":"\u5b9e\u73b0TENER\u7c7b\u7684\u4ee3\u7801: /home/ec2-user/red_spider/ner/tener/models/TENER.py # encoding: utf-8 import torch from torch import nn import torch.nn.functional as F from fastNLP.modules import ConditionalRandomField , allowed_transitions from modules.transformer import TransformerEncoder class TENER ( nn . Module ): def __init__ ( self , tag_vocab , embed , num_layers , d_model , n_head , feedforward_dim , dropout , after_norm = True , attn_type = 'adatrans' , bi_embed = None , fc_dropout = 0.3 , pos_embed = None , encoding_type = None , scale = False , dropout_attn = None ): # tag_vocab: fastNLP Vocabulary # embed: fastNLP TokenEmbedding # num_layers: number of self-attention layers # d_model: input size # n_head: number of head # feedforward_dim: the dimension of ffn # dropout: dropout in self-attention # after_norm: normalization place # attn_type: adatrans, naive # rel_pos_embed: position embedding\u7684\u7c7b\u578b\uff0c\u652f\u6301sin, fix, None. relative\u65f6\u53ef\u4e3aNone # bi_embed: Used in Chinese scenerio # encoding_type: NER\u4efb\u52a1\u7684\u7f16\u7801\u6a21\u5f0f, \u6b64\u5904\u91c7\u7528'bmeso'\u6a21\u5f0f # fc_dropout: dropout rate before the fc layer super () . __init__ () self . embed = embed embed_size = self . embed . embed_size self . bi_embed = None if bi_embed is not None : self . bi_embed = bi_embed embed_size += self . bi_embed . embed_size self . in_fc = nn . Linear ( embed_size , d_model ) self . transformer = TransformerEncoder ( num_layers , d_model , n_head , feedforward_dim , dropout , after_norm = after_norm , attn_type = attn_type , scale = scale , dropout_attn = dropout_attn , pos_embed = pos_embed ) self . fc_dropout = nn . Dropout ( fc_dropout ) self . out_fc = nn . Linear ( d_model , len ( tag_vocab )) trans = allowed_transitions ( tag_vocab , encoding_type = encoding_type , include_start_end = True ) self . crf = ConditionalRandomField ( len ( tag_vocab ), include_start_end_trans = True , allowed_transitions = trans ) def _forward ( self , chars , target , bigrams = None ): mask = chars . ne ( 0 ) chars = self . embed ( chars ) if self . bi_embed is not None : bigrams = self . bi_embed ( bigrams ) chars = torch . cat ([ chars , bigrams ], dim =- 1 ) chars = self . in_fc ( chars ) chars = self . transformer ( chars , mask ) chars = self . fc_dropout ( chars ) chars = self . out_fc ( chars ) logits = F . log_softmax ( chars , dim =- 1 ) if target is None : paths , _ = self . crf . viterbi_decode ( logits , mask ) return { 'pred' : paths } else : loss = self . crf ( logits , target , mask ) return { 'loss' : loss } def forward ( self , chars , target , bigrams = None ): return self . _forward ( chars , target , bigrams ) def predict ( self , chars , bigrams = None ): return self . _forward ( chars , target = None , bigrams = bigrams )","title":"\u7b2c2\u6b65: \u6784\u5efa\u6a21\u578b\u7c7b\u7684\u4ee3\u7801"},{"location":"11_1.html#3","text":"\u5b9e\u73b0\u8bad\u7ec3\u4ee3\u7801: /home/ec2-user/red_spider/ner/tener/train_tener_cn.py # encoding: utf-8 from models.TENER import TENER from fastNLP import cache_results from fastNLP import Trainer , Tester from fastNLP.core.predictor import Predictor from fastNLP import GradientClipCallback , WarmupCallback from torch import optim from fastNLP import SpanFPreRecMetric , BucketSampler from fastNLP.embeddings import StaticEmbedding from modules.pipe import CNNERPipe import argparse from modules.callbacks import EvaluateCallback import os import sys import time import torch device = 0 parser = argparse . ArgumentParser () parser . add_argument ( '--dataset' , type = str , default = 'resume' , choices = [ 'weibo' , 'resume' , 'ontonotes' , 'msra' ]) parser . add_argument ( '--status' , type = str , default = 'train' , choices = [ 'train' , 'test' , 'predict' ]) args = parser . parse_args () dataset = args . dataset if dataset == 'resume' : n_heads = 4 head_dims = 64 num_layers = 2 lr = 0.0007 attn_type = 'adatrans' n_epochs = 100 elif dataset == 'weibo' : n_heads = 4 head_dims = 32 num_layers = 1 lr = 0.001 attn_type = 'adatrans' n_epochs = 100 elif dataset == 'ontonotes' : n_heads = 4 head_dims = 48 num_layers = 2 lr = 0.0007 attn_type = 'adatrans' n_epochs = 100 elif dataset == 'msra' : n_heads = 6 head_dims = 80 num_layers = 2 lr = 0.0007 attn_type = 'adatrans' n_epochs = 100 pos_embed = None batch_size = 128 warmup_steps = 0.01 after_norm = 1 model_type = 'transformer' normalize_embed = True dropout = 0.15 fc_dropout = 0.4 encoding_type = 'bmeso' name = './cache/ {} _ {} _ {} _ {} .pkl' . format ( dataset , model_type , encoding_type , normalize_embed ) d_model = n_heads * head_dims dim_feedforward = int ( 2 * d_model ) @cache_results ( name , _refresh = False ) def load_data (): # \u66ff\u6362\u8def\u5f84 if dataset == 'ontonotes' : paths = { 'train' : './data/OntoNote4NER/train.char.bmes' , \"dev\" : './data/OntoNote4NER/dev.char.bmes' , \"test\" : './data/OntoNote4NER/test.char.bmes' } min_freq = 2 elif dataset == 'weibo' : paths = { 'train' : './data/WeiboNER/train.all.bmes' , 'dev' : './data/WeiboNER/dev.all.bmes' , 'test' : './data/WeiboNER/test.all.bmes' } min_freq = 1 elif dataset == 'resume' : paths = { 'train' : './data/ResumeNER/train.char.bmes' , 'dev' : './data/ResumeNER/dev.char.bmes' , 'test' : './data/ResumeNER/test.char.bmes' } min_freq = 1 elif dataset == 'msra' : paths = { 'train' : './data/MSRANER/train_dev.char.bmes' , 'dev' : './data/MSRANER/test.char.bmes' , 'test' : './data/MSRANER/test.char.bmes' } min_freq = 2 data_bundle = CNNERPipe ( bigrams = True , encoding_type = encoding_type ) . process_from_file ( paths ) embed = StaticEmbedding ( data_bundle . get_vocab ( 'chars' ), model_dir_or_name = './data/gigaword_chn.all.a2b.uni.ite50.vec' , min_freq = 1 , only_norm_found_vector = normalize_embed , word_dropout = 0.01 , dropout = 0.3 ) bi_embed = StaticEmbedding ( data_bundle . get_vocab ( 'bigrams' ), model_dir_or_name = './data/gigaword_chn.all.a2b.bi.ite50.vec' , word_dropout = 0.02 , dropout = 0.3 , min_freq = min_freq , only_norm_found_vector = normalize_embed , only_train_min_freq = True ) return data_bundle , embed , bi_embed data_bundle , embed , bi_embed = load_data () print ( data_bundle ) model = TENER ( tag_vocab = data_bundle . get_vocab ( 'target' ), embed = embed , num_layers = num_layers , d_model = d_model , n_head = n_heads , feedforward_dim = dim_feedforward , dropout = dropout , after_norm = after_norm , attn_type = attn_type , bi_embed = bi_embed , fc_dropout = fc_dropout , pos_embed = pos_embed , encoding_type = encoding_type , scale = attn_type == 'transformer' ) optimizer = optim . SGD ( model . parameters (), lr = lr , momentum = 0.9 ) metrics = SpanFPreRecMetric ( tag_vocab = data_bundle . get_vocab ( 'target' ), encoding_type = encoding_type ) callbacks = [] clip_callback = GradientClipCallback ( clip_type = 'value' , clip_value = 5 ) evaluate_callback = EvaluateCallback ( data_bundle . get_dataset ( 'test' )) if warmup_steps > 0 : warmup_callback = WarmupCallback ( warmup_steps , schedule = 'linear' ) callbacks . append ( warmup_callback ) callbacks . extend ([ clip_callback , evaluate_callback ]) if args . status == 'train' : trainer = Trainer ( data_bundle . get_dataset ( 'train' ), model , optimizer , batch_size = batch_size , sampler = BucketSampler (), num_workers = 4 , n_epochs = n_epochs , dev_data = data_bundle . get_dataset ( 'dev' ), metrics = metrics , dev_batch_size = batch_size // 2 , callbacks = callbacks , device = device , test_use_tqdm = True , use_tqdm = True , print_every = 1 ) # \u8bad\u7ec3\u7ed3\u675f\u540e\u4e00\u5b9a\u8981\u4fdd\u5b58\u6700\u597d\u7684\u6a21\u578b, \u9ed8\u8ba4\u4f1a\u8fdb\u884c\u4fdd\u5b58. trainer . train () model_save_dir = \"./saved_model/ {} / {} \" . format ( args . dataset , time . strftime ( '%Y_%m_ %d _%H_%M_%S' )) if not os . path . exists ( model_save_dir ): os . makedirs ( model_save_dir ) model_save_path = \" {} /model_tener.pt\" . format ( model_save_dir ) torch . save ( model . state_dict (), model_save_path ) if args . status == 'test' : time_stamp = '2021_12_01_05_24_10' model_save_path = \"./saved_model/ {} / {} /model_tener.pt\" . format ( args . dataset , time_stamp ) model . load_state_dict ( torch . load ( model_save_path )) tester = Tester ( data_bundle . get_dataset ( 'test' ), model , metrics = metrics , device = device ) res = tester . test () print ( res ) predictor = Predictor ( model ) predictor . batch_size = 32 start_time = time . time () # \u9884\u6d4b\u7ed3\u679c test_label_list = predictor . predict ( data_bundle . get_dataset ( 'test' ))[ 'pred' ] end_time = time . time () print ( 'Prediction cost time:' , end_time - start_time ) pred_tags = [] for test_label in test_label_list : for item in test_label : pred_tags . append ( item ) # \u539f\u59cb\u6587\u5b57 test_raw_char = data_bundle . get_dataset ( 'test' )[ 'raw_chars' ] predict_path = \"./results/ner_predict.txt\" with open ( predict_path , \"w\" , encoding = 'utf-8' ) as f : for sentence , tags in zip ( test_raw_char , pred_tags ): for i in range ( len ( sentence )): ch = sentence [ i ] tag_text = data_bundle . get_vocab ( 'target' ) . to_word ( tags [ i ]) f . write ( ch + ' ' + tag_text + ' \\n ' ) f . write ( ' \\n ' )","title":"\u7b2c3\u6b65: \u8bad\u7ec3\u51fd\u6570\u7684\u4ee3\u7801"},{"location":"11_1.html#4","text":"\u8c03\u7528: python train_tener_cn.py --dataset resume \u8f93\u51fa\u7ed3\u679c: Read cache from ./cache/resume_transformer_bmeso_True.pkl. In total 3 datasets: train has 2000 instances. dev has 532 instances. test has 532 instances. In total 3 vocabs: chars has 1096 entries. bigrams has 5550 entries. target has 7 entries. input fields after batch(if batch size is 2): target: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2, 59]) chars: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2, 59]) bigrams: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2, 59]) seq_len: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2]) target fields after batch(if batch size is 2): target: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2, 59]) seq_len: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2]) training epochs started 2023-02-25-12-52-13 Evaluate data in 0.69 seconds! Evaluate data in 0.69 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.080617, pre=0.043392, rec=0.567179 Evaluation on dev at Epoch 1/200. Step:16/3200: SpanFPreRecMetric: f=0.080617, pre=0.043392, rec=0.567179 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0 Evaluation on dev at Epoch 2/200. Step:32/3200: SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0 Evaluate data in 0.67 seconds! Evaluate data in 0.67 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0 Evaluation on dev at Epoch 3/200. Step:48/3200: SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0 Evaluation on dev at Epoch 4/200. Step:64/3200: SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0 Evaluate data in 0.67 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.093066, pre=0.944444, rec=0.048944 Evaluation on dev at Epoch 5/200. Step:80/3200: SpanFPreRecMetric: f=0.093066, pre=0.944444, rec=0.048944 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.524046, pre=0.461314, rec=0.606526 Evaluation on dev at Epoch 6/200. Step:96/3200: SpanFPreRecMetric: f=0.524046, pre=0.461314, rec=0.606526 Evaluate data in 0.67 seconds! Evaluate data in 0.67 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.484195, pre=0.962857, rec=0.323417 Evaluation on dev at Epoch 7/200. Step:112/3200: SpanFPreRecMetric: f=0.484195, pre=0.962857, rec=0.323417 Evaluate data in 0.67 seconds! Evaluate data in 0.67 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.700119, pre=0.927215, rec=0.56238 Evaluation on dev at Epoch 8/200. Step:128/3200: SpanFPreRecMetric: f=0.700119, pre=0.927215, rec=0.56238 Evaluate data in 0.67 seconds! Evaluate data in 0.67 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.784035, pre=0.911055, rec=0.6881 Evaluation on dev at Epoch 9/200. Step:144/3200: SpanFPreRecMetric: f=0.784035, pre=0.911055, rec=0.6881 Evaluate data in 0.67 seconds! Evaluate data in 0.67 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.78663, pre=0.937583, rec=0.677543 Evaluation on dev at Epoch 10/200. Step:160/3200: SpanFPreRecMetric: f=0.78663, pre=0.937583, rec=0.677543 Evaluate data in 0.68 seconds! Evaluate data in 0.67 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.809218, pre=0.916262, rec=0.724568 Evaluation on dev at Epoch 11/200. Step:176/3200: SpanFPreRecMetric: f=0.809218, pre=0.916262, rec=0.724568 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.817942, pre=0.908558, rec=0.743762 Evaluation on dev at Epoch 12/200. Step:192/3200: SpanFPreRecMetric: f=0.817942, pre=0.908558, rec=0.743762 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.819672, pre=0.912839, rec=0.743762 Evaluation on dev at Epoch 13/200. Step:208/3200: SpanFPreRecMetric: f=0.819672, pre=0.912839, rec=0.743762 Evaluate data in 0.68 seconds! Evaluate data in 0.67 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.837686, pre=0.897914, rec=0.785029 Evaluation on dev at Epoch 14/200. Step:224/3200: SpanFPreRecMetric: f=0.837686, pre=0.897914, rec=0.785029 Evaluate data in 0.67 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.846582, pre=0.896034, rec=0.802303 Evaluation on dev at Epoch 15/200. Step:240/3200: SpanFPreRecMetric: f=0.846582, pre=0.896034, rec=0.802303 ...... ...... ...... ...... ...... ...... Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluation on dev at Epoch 192/200. Step:3072/3200: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.978663, pre=0.967198, rec=0.990403 Evaluation on dev at Epoch 193/200. Step:3088/3200: SpanFPreRecMetric: f=0.978663, pre=0.967198, rec=0.990403 Evaluate data in 0.67 seconds! Evaluate data in 0.67 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.981455, pre=0.972667, rec=0.990403 Evaluation on dev at Epoch 194/200. Step:3104/3200: SpanFPreRecMetric: f=0.981455, pre=0.972667, rec=0.990403 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.981455, pre=0.972667, rec=0.990403 Evaluation on dev at Epoch 195/200. Step:3120/3200: SpanFPreRecMetric: f=0.981455, pre=0.972667, rec=0.990403 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluation on dev at Epoch 196/200. Step:3136/3200: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluation on dev at Epoch 197/200. Step:3152/3200: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluation on dev at Epoch 198/200. Step:3168/3200: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluate data in 0.67 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluation on dev at Epoch 199/200. Step:3184/3200: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluate data in 0.68 seconds! Evaluate data in 0.68 seconds! EvaluateCallback evaluation on data-test: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Evaluation on dev at Epoch 200/200. Step:3200/3200: SpanFPreRecMetric: f=0.982389, pre=0.974504, rec=0.990403 Best test performance(may not correspond to the best dev performance):{'SpanFPreRecMetric': {'f': 0.987112, 'pre': 0.981956, 'rec': 0.992322}} achieved at Epoch:173. Best test performance(correspond to the best dev performance):{'SpanFPreRecMetric': {'f': 0.987112, 'pre': 0.981956, 'rec': 0.992322}} achieved at Epoch:173. In Epoch:173/Step:2768, got best dev performance: SpanFPreRecMetric: f=0.987112, pre=0.981956, rec=0.992322 Reloaded the best model.","title":"\u7b2c4\u6b65: \u6a21\u578b\u8bad\u7ec3"},{"location":"11_1.html#_2","text":"\u672c\u5c0f\u8282\u5b66\u4e60\u4e86TENER\u6a21\u578b\u7684\u67b6\u6784\u548c\u4ee3\u7801\u5b9e\u73b0.","title":"\u5c0f\u8282\u603b\u7ed3"},{"location":"12_1.html","text":"Soft-lexicon\u6a21\u578b \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u638c\u63e1Soft-lexicon\u6a21\u578b\u7684\u4ee3\u7801\u5b9e\u73b0. Soft-lexicon\u6a21\u578b\u4ee3\u7801\u5b9e\u73b0 \u00b6 \u6574\u4e2a\u6d41\u7a0b\u7684\u5b9e\u73b0\u6b65\u9aa4\u5982\u4e0b: \u7b2c1\u6b65: \u6784\u5efa\u5de5\u5177\u7c7b\u76f8\u5173\u51fd\u6570 \u7b2c2\u6b65: \u6784\u5efa\u6a21\u578b\u7c7b\u7684\u4ee3\u7801 \u7b2c3\u6b65: \u4e3b\u51fd\u6570\u4ee3\u7801\u7684\u5b9e\u73b0 \u7b2c4\u6b65: \u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u811a\u672c \u7b2c5\u6b65: \u6a21\u578b\u7684\u8bad\u7ec3 \u7b2c1\u6b65: \u6784\u5efa\u5de5\u5177\u7c7b\u76f8\u5173\u51fd\u6570 \u00b6 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/code/ner/soft-lexicon/utils.py 1.1: alphabet.py\u4ee3\u7801\u5b9e\u73b0 import json import os class Alphabet : def __init__ ( self , name , label = False , keep_growing = True ): self . __name = name self . UNKNOWN = \"</unk>\" self . label = label self . instance2index = {} self . instances = [] self . keep_growing = keep_growing # Index 0 is occupied by default, all else following. self . default_index = 0 self . next_index = 1 if not self . label : self . add ( self . UNKNOWN ) def clear ( self , keep_growing = True ): self . instance2index = {} self . instances = [] self . keep_growing = keep_growing # Index 0 is occupied by default, all else following. self . default_index = 0 self . next_index = 1 def add ( self , instance ): if instance not in self . instance2index : self . instances . append ( instance ) self . instance2index [ instance ] = self . next_index self . next_index += 1 def get_index ( self , instance ): try : return self . instance2index [ instance ] except KeyError : if self . keep_growing : index = self . next_index self . add ( instance ) return index else : return self . instance2index [ self . UNKNOWN ] def get_instance ( self , index ): if index == 0 : # First index is occupied by the wildcard element. return None try : return self . instances [ index - 1 ] except IndexError : print ( 'WARNING:Alphabet get_instance ,unknown instance index {} , return the first label.' . format ( index )) return self . instances [ 0 ] def size ( self ): # if self.label: # return len(self.instances) # else: return len ( self . instances ) + 1 def iteritems ( self ): return self . instance2index . items () def enumerate_items ( self , start = 1 ): if start < 1 or start >= self . size (): raise IndexError ( \"Enumerate is allowed between [1 : size of the alphabet)\" ) return zip ( range ( start , len ( self . instances ) + 1 ), self . instances [ start - 1 :]) def close ( self ): self . keep_growing = False def open ( self ): self . keep_growing = True def get_content ( self ): return { 'instance2index' : self . instance2index , 'instances' : self . instances } def from_json ( self , data ): self . instances = data [ \"instances\" ] self . instance2index = data [ \"instance2index\" ] def save ( self , output_directory , name = None ): \"\"\" Save both alhpabet records to the given directory. :param output_directory: Directory to save model and weights. :param name: The alphabet saving name, optional. :return: \"\"\" saving_name = name if name else self . __name try : json . dump ( self . get_content (), open ( os . path . join ( output_directory , saving_name + \".json\" ), 'w' )) except Exception as e : print ( \"Exception: Alphabet is not saved: \" % repr ( e )) def load ( self , input_directory , name = None ): \"\"\" Load model architecture and weights from the give directory. This allow we use old models even the structure changes. :param input_directory: Directory to save model and weights :return: \"\"\" loading_name = name if name else self . __name self . from_json ( json . load ( open ( os . path . join ( input_directory , loading_name + \".json\" )))) 1.2: data.py\u4ee3\u7801\u5b9e\u73b0 from utils.functions import * from utils.gazetteer import Gazetteer START = \"</s>\" UNKNOWN = \"</unk>\" PADDING = \"</pad>\" NULLKEY = \"-null-\" class Data : def __init__ ( self ): self . MAX_SENTENCE_LENGTH = 250 self . MAX_WORD_LENGTH = - 1 self . number_normalized = True self . norm_word_emb = True self . norm_biword_emb = True self . norm_gaz_emb = False self . word_alphabet = Alphabet ( 'word' ) self . biword_alphabet = Alphabet ( 'biword' ) self . char_alphabet = Alphabet ( 'character' ) self . label_alphabet = Alphabet ( 'label' , True ) self . gaz_lower = False self . gaz = Gazetteer ( self . gaz_lower ) self . gaz_alphabet = Alphabet ( 'gaz' ) self . gaz_count = {} self . gaz_split = {} self . biword_count = {} self . HP_fix_gaz_emb = False self . HP_use_gaz = True self . HP_use_count = False self . tagScheme = \"NoSeg\" self . char_features = \"LSTM\" self . train_texts = [] self . dev_texts = [] self . test_texts = [] self . raw_texts = [] self . train_Ids = [] self . dev_Ids = [] self . test_Ids = [] self . raw_Ids = [] self . train_split_index = [] self . dev_split_index = [] self . use_bigram = True self . word_emb_dim = 50 self . biword_emb_dim = 50 self . char_emb_dim = 30 self . gaz_emb_dim = 50 self . gaz_dropout = 0.5 self . pretrain_word_embedding = None self . pretrain_biword_embedding = None self . pretrain_gaz_embedding = None self . label_size = 0 self . word_alphabet_size = 0 self . biword_alphabet_size = 0 self . char_alphabet_size = 0 self . label_alphabet_size = 0 # hyperparameters self . HP_iteration = 100 self . HP_batch_size = 10 self . HP_char_hidden_dim = 50 self . HP_hidden_dim = 128 self . HP_dropout = 0.5 self . HP_lstm_layer = 1 self . HP_bilstm = True self . HP_use_char = False self . HP_gpu = True self . HP_lr = 0.015 self . HP_lr_decay = 0.05 self . HP_clip = 5.0 self . HP_momentum = 0 self . HP_num_layer = 4 def show_data_summary ( self ): print ( \"DATA SUMMARY START:\" ) print ( \" Tag scheme: %s \" % ( self . tagScheme )) print ( \" MAX SENTENCE LENGTH: %s \" % ( self . MAX_SENTENCE_LENGTH )) print ( \" MAX WORD LENGTH: %s \" % ( self . MAX_WORD_LENGTH )) print ( \" Number normalized: %s \" % ( self . number_normalized )) print ( \" Use bigram: %s \" % ( self . use_bigram )) print ( \" Word alphabet size: %s \" % ( self . word_alphabet_size )) print ( \" Biword alphabet size: %s \" % ( self . biword_alphabet_size )) print ( \" Char alphabet size: %s \" % ( self . char_alphabet_size )) print ( \" Gaz alphabet size: %s \" % ( self . gaz_alphabet . size ())) print ( \" Label alphabet size: %s \" % ( self . label_alphabet_size )) print ( \" Word embedding size: %s \" % ( self . word_emb_dim )) print ( \" Biword embedding size: %s \" % ( self . biword_emb_dim )) print ( \" Char embedding size: %s \" % ( self . char_emb_dim )) print ( \" Gaz embedding size: %s \" % ( self . gaz_emb_dim )) print ( \" Norm word emb: %s \" % ( self . norm_word_emb )) print ( \" Norm biword emb: %s \" % ( self . norm_biword_emb )) print ( \" Norm gaz emb: %s \" % ( self . norm_gaz_emb )) print ( \" Norm gaz dropout: %s \" % ( self . gaz_dropout )) print ( \" Train instance number: %s \" % ( len ( self . train_texts ))) print ( \" Dev instance number: %s \" % ( len ( self . dev_texts ))) print ( \" Test instance number: %s \" % ( len ( self . test_texts ))) def refresh_label_alphabet ( self , input_file ): old_size = self . label_alphabet_size self . label_alphabet . clear ( True ) in_lines = open ( input_file , 'r' , encoding = \"utf-8\" ) . readlines () for line in in_lines : if len ( line ) > 2 : pairs = line . strip () . split () label = pairs [ - 1 ] self . label_alphabet . add ( label ) self . label_alphabet_size = self . label_alphabet . size () startS = False startB = False for label , _ in self . label_alphabet . iteritems (): if \"S-\" in label . upper (): startS = True elif \"B-\" in label . upper (): startB = True if startB : if startS : self . tagScheme = \"BMES\" else : self . tagScheme = \"BIO\" self . fix_alphabet () print ( \"Refresh label alphabet finished: old: %s -> new: %s \" % ( old_size , self . label_alphabet_size )) def build_alphabet ( self , input_file ): in_lines = open ( input_file , 'r' , encoding = \"utf-8\" ) . readlines () seqlen = 0 for idx in range ( len ( in_lines )): line = in_lines [ idx ] if len ( line ) > 2 : pairs = line . strip () . split () word = pairs [ 0 ] if self . number_normalized : word = normalize_word ( word ) label = pairs [ - 1 ] self . label_alphabet . add ( label ) self . word_alphabet . add ( word ) if idx < len ( in_lines ) - 1 and len ( in_lines [ idx + 1 ]) > 2 : biword = word + in_lines [ idx + 1 ] . strip () . split ()[ 0 ] else : biword = word + NULLKEY self . biword_alphabet . add ( biword ) # biword_index = self.biword_alphabet.get_index(biword) self . biword_count [ biword ] = self . biword_count . get ( biword , 0 ) + 1 for char in word : self . char_alphabet . add ( char ) seqlen += 1 else : seqlen = 0 self . word_alphabet_size = self . word_alphabet . size () self . biword_alphabet_size = self . biword_alphabet . size () self . char_alphabet_size = self . char_alphabet . size () self . label_alphabet_size = self . label_alphabet . size () startS = False startB = False for label , _ in self . label_alphabet . iteritems (): if \"S-\" in label . upper (): startS = True elif \"B-\" in label . upper (): startB = True if startB : if startS : self . tagScheme = \"BMES\" else : self . tagScheme = \"BIO\" def build_gaz_file ( self , gaz_file ): # build gaz file,initial read gaz embedding file if gaz_file : fins = open ( gaz_file , 'r' , encoding = \"utf-8\" ) . readlines () for fin in fins : fin = fin . strip () . split ()[ 0 ] if fin : self . gaz . insert ( fin , \"one_source\" ) print ( \"Load gaz file: \" , gaz_file , \" total size:\" , self . gaz . size ()) else : print ( \"Gaz file is None, load nothing\" ) def write_decoded_results ( self , output_file , predict_results , name ): fout = open ( output_file , 'w' ) sent_num = len ( predict_results ) content_list = [] if name == 'raw' : content_list = self . raw_texts elif name == 'test' : content_list = self . test_texts elif name == 'dev' : content_list = self . dev_texts elif name == 'train' : content_list = self . train_texts else : print ( \"Error: illegal name during writing predict result, name should be within train/dev/test/raw !\" ) assert ( sent_num == len ( content_list )) for idx in range ( sent_num ): sent_length = len ( predict_results [ idx ]) for idy in range ( sent_length ): # content_list[idx] is a list with [word, char, label] fout . write ( content_list [ idx ][ 0 ][ idy ] . encode ( 'utf-8' ) + \" \" + predict_results [ idx ][ idy ] + ' \\n ' ) fout . write ( ' \\n ' ) fout . close () print ( \"Predict %s result has been written into file. %s \" % ( name , output_file )) 1.3: functions.py\u4ee3\u7801\u5b9e\u73b0 import sys import numpy as np import re from utils.alphabet import Alphabet from transformers.tokenization_bert import BertTokenizer NULLKEY = \"-null-\" def normalize_word ( word ): new_word = \"\" for char in word : if char . isdigit (): new_word += '0' else : new_word += char return new_word def read_instance_with_gaz ( num_layer , input_file , gaz , word_alphabet , biword_alphabet , biword_count , char_alphabet , gaz_alphabet , gaz_count , gaz_split , label_alphabet , number_normalized , max_sent_length , char_padding_size =- 1 , char_padding_symbol = '</pad>' ): tokenizer = BertTokenizer . from_pretrained ( 'bert-base-chinese' , do_lower_case = True ) in_lines = open ( input_file , 'r' , encoding = \"utf-8\" ) . readlines () instence_texts = [] instence_Ids = [] words = [] biwords = [] chars = [] labels = [] word_Ids = [] biword_Ids = [] char_Ids = [] label_Ids = [] for idx in range ( len ( in_lines )): line = in_lines [ idx ] if len ( line ) > 2 : pairs = line . strip () . split () word = pairs [ 0 ] if number_normalized : word = normalize_word ( word ) label = pairs [ - 1 ] if idx < len ( in_lines ) - 1 and len ( in_lines [ idx + 1 ]) > 2 : biword = word + in_lines [ idx + 1 ] . strip () . split ()[ 0 ] else : biword = word + NULLKEY biwords . append ( biword ) words . append ( word ) labels . append ( label ) word_Ids . append ( word_alphabet . get_index ( word )) biword_index = biword_alphabet . get_index ( biword ) biword_Ids . append ( biword_index ) label_Ids . append ( label_alphabet . get_index ( label )) char_list = [] char_Id = [] for char in word : char_list . append ( char ) if char_padding_size > 0 : char_number = len ( char_list ) if char_number < char_padding_size : char_list = char_list + [ char_padding_symbol ] * ( char_padding_size - char_number ) assert ( len ( char_list ) == char_padding_size ) else : # not padding pass for char in char_list : char_Id . append ( char_alphabet . get_index ( char )) chars . append ( char_list ) char_Ids . append ( char_Id ) else : if (( max_sent_length < 0 ) or ( len ( words ) < max_sent_length )) and ( len ( words ) > 0 ): gaz_Ids = [] layergazmasks = [] gazchar_masks = [] w_length = len ( words ) gazs = [[[] for i in range ( 4 )] for _ in range ( w_length )] # gazs:[c1,c2,...,cn] ci:[B,M,E,S] B/M/E/S :[w_id1,w_id2,...] None:0 gazs_count = [[[] for _ in range ( 4 )] for _ in range ( w_length )] gaz_char_Id = [[[] for _ in range ( 4 )] for _ in range ( w_length )] # gazs:[c1,c2,...,cn] ci:[B,M,E,S] B/M/E/S :[[w1c1,w1c2,...],[],...] max_gazlist = 0 max_gazcharlen = 0 for idx in range ( w_length ): matched_list = gaz . enumerateMatchList ( words [ idx :]) matched_length = [ len ( a ) for a in matched_list ] matched_Id = [ gaz_alphabet . get_index ( entity ) for entity in matched_list ] if matched_length : max_gazcharlen = max ( max ( matched_length ), max_gazcharlen ) for w in range ( len ( matched_Id )): gaz_chars = [] g = matched_list [ w ] for c in g : gaz_chars . append ( word_alphabet . get_index ( c )) if matched_length [ w ] == 1 : # Single gazs [ idx ][ 3 ] . append ( matched_Id [ w ]) gazs_count [ idx ][ 3 ] . append ( 1 ) gaz_char_Id [ idx ][ 3 ] . append ( gaz_chars ) else : gazs [ idx ][ 0 ] . append ( matched_Id [ w ]) # Begin gazs_count [ idx ][ 0 ] . append ( gaz_count [ matched_Id [ w ]]) gaz_char_Id [ idx ][ 0 ] . append ( gaz_chars ) wlen = matched_length [ w ] gazs [ idx + wlen - 1 ][ 2 ] . append ( matched_Id [ w ]) # End gazs_count [ idx + wlen - 1 ][ 2 ] . append ( gaz_count [ matched_Id [ w ]]) gaz_char_Id [ idx + wlen - 1 ][ 2 ] . append ( gaz_chars ) for l in range ( wlen - 2 ): gazs [ idx + l + 1 ][ 1 ] . append ( matched_Id [ w ]) # Middle gazs_count [ idx + l + 1 ][ 1 ] . append ( gaz_count [ matched_Id [ w ]]) gaz_char_Id [ idx + l + 1 ][ 1 ] . append ( gaz_chars ) for label in range ( 4 ): if not gazs [ idx ][ label ]: gazs [ idx ][ label ] . append ( 0 ) gazs_count [ idx ][ label ] . append ( 1 ) gaz_char_Id [ idx ][ label ] . append ([ 0 ]) max_gazlist = max ( len ( gazs [ idx ][ label ]), max_gazlist ) matched_Id = [ gaz_alphabet . get_index ( entity ) for entity in matched_list ] # \u8bcd\u53f7 if matched_Id : gaz_Ids . append ([ matched_Id , matched_length ]) else : gaz_Ids . append ([]) # batch_size = 1 for idx in range ( w_length ): gazmask = [] gazcharmask = [] for label in range ( 4 ): label_len = len ( gazs [ idx ][ label ]) count_set = set ( gazs_count [ idx ][ label ]) if len ( count_set ) == 1 and 0 in count_set : gazs_count [ idx ][ label ] = [ 1 ] * label_len mask = label_len * [ 0 ] mask += ( max_gazlist - label_len ) * [ 1 ] gazs [ idx ][ label ] += ( max_gazlist - label_len ) * [ 0 ] # padding gazs_count [ idx ][ label ] += ( max_gazlist - label_len ) * [ 0 ] # padding char_mask = [] for g in range ( len ( gaz_char_Id [ idx ][ label ])): glen = len ( gaz_char_Id [ idx ][ label ][ g ]) charmask = glen * [ 0 ] charmask += ( max_gazcharlen - glen ) * [ 1 ] char_mask . append ( charmask ) gaz_char_Id [ idx ][ label ][ g ] += ( max_gazcharlen - glen ) * [ 0 ] gaz_char_Id [ idx ][ label ] += ( max_gazlist - label_len ) * [[ 0 for i in range ( max_gazcharlen )]] char_mask += ( max_gazlist - label_len ) * [[ 1 for i in range ( max_gazcharlen )]] gazmask . append ( mask ) gazcharmask . append ( char_mask ) layergazmasks . append ( gazmask ) gazchar_masks . append ( gazcharmask ) texts = [ '[CLS]' ] + words + [ '[SEP]' ] bert_text_ids = tokenizer . convert_tokens_to_ids ( texts ) instence_texts . append ([ words , biwords , chars , gazs , labels ]) instence_Ids . append ( [ word_Ids , biword_Ids , char_Ids , gaz_Ids , label_Ids , gazs , gazs_count , gaz_char_Id , layergazmasks , gazchar_masks , bert_text_ids ]) words = [] biwords = [] chars = [] labels = [] word_Ids = [] biword_Ids = [] char_Ids = [] label_Ids = [] return instence_texts , instence_Ids 1.4: gazetteer.py\u4ee3\u7801\u5b9e\u73b0 from utils.trie import Trie class Gazetteer : def __init__ ( self , lower ): self . trie = Trie () self . ent2type = {} ## word list to type self . ent2id = { \"<UNK>\" : 0 } ## word list to id self . lower = lower self . space = \"\" def enumerateMatchList ( self , word_list ): if self . lower : word_list = [ word . lower () for word in word_list ] match_list = self . trie . enumerateMatch ( word_list , self . space ) return match_list def insert ( self , word_list , source ): if self . lower : word_list = [ word . lower () for word in word_list ] self . trie . insert ( word_list ) string = self . space . join ( word_list ) if string not in self . ent2type : self . ent2type [ string ] = source if string not in self . ent2id : self . ent2id [ string ] = len ( self . ent2id ) def searchId ( self , word_list ): if self . lower : word_list = [ word . lower () for word in word_list ] string = self . space . join ( word_list ) if string in self . ent2id : return self . ent2id [ string ] return self . ent2id [ \"<UNK>\" ] def searchType ( self , word_list ): if self . lower : word_list = [ word . lower () for word in word_list ] string = self . space . join ( word_list ) if string in self . ent2type : return self . ent2type [ string ] print ( \"Error in finding entity type at gazetteer.py, exit program! String:\" , string ) exit ( 0 ) def size ( self ): return len ( self . ent2type ) 1.5: metric.py\u4ee3\u7801\u5b9e\u73b0 import sys # input as sentence level labels def get_ner_fmeasure ( golden_lists , predict_lists , label_type = \"BMES\" , printnum = True ): sent_num = len ( golden_lists ) golden_full = [] predict_full = [] right_full = [] right_tag = 0 all_tag = 0 for idx in range ( 0 , sent_num ): # word_list = sentence_lists[idx] golden_list = golden_lists [ idx ] predict_list = predict_lists [ idx ] for idy in range ( len ( golden_list )): if golden_list [ idy ] == predict_list [ idy ]: right_tag += 1 all_tag += len ( golden_list ) if label_type == \"BMES\" : gold_matrix = get_ner_BMES ( golden_list ) pred_matrix = get_ner_BMES ( predict_list ) else : gold_matrix = get_ner_BIO ( golden_list ) pred_matrix = get_ner_BIO ( predict_list ) # print \"gold\", gold_matrix # print \"pred\", pred_matrix right_ner = list ( set ( gold_matrix ) . intersection ( set ( pred_matrix ))) golden_full += gold_matrix predict_full += pred_matrix right_full += right_ner right_num = len ( right_full ) golden_num = len ( golden_full ) predict_num = len ( predict_full ) if predict_num == 0 : precision = - 1 else : precision = ( right_num + 0.0 ) / predict_num if golden_num == 0 : recall = - 1 else : recall = ( right_num + 0.0 ) / golden_num if ( precision == - 1 ) or ( recall == - 1 ) or ( precision + recall ) <= 0. : f_measure = - 1 else : f_measure = 2 * precision * recall / ( precision + recall ) accuracy = ( right_tag + 0.0 ) / all_tag # print \"Accuracy: \", right_tag,\"/\",all_tag,\"=\",accuracy if printnum : print ( \"gold_num = \" , golden_num , \" pred_num = \" , predict_num , \" right_num = \" , right_num ) return accuracy , precision , recall , f_measure def reverse_style ( input_string ): target_position = input_string . index ( '[' ) input_len = len ( input_string ) output_string = input_string [ target_position : input_len ] + input_string [ 0 : target_position ] return output_string def get_ner_BMES ( label_list ): # list_len = len(word_list) # assert(list_len == len(label_list)), \"word list size unmatch with label list\" list_len = len ( label_list ) begin_label = 'B-' end_label = 'E-' single_label = 'S-' whole_tag = '' index_tag = '' tag_list = [] stand_matrix = [] for i in range ( 0 , list_len ): # wordlabel = word_list[i] current_label = label_list [ i ] . upper () if label_list [ i ] else [] if begin_label in current_label : if index_tag != '' : tag_list . append ( whole_tag + ',' + str ( i - 1 )) whole_tag = current_label . replace ( begin_label , \"\" , 1 ) + '[' + str ( i ) index_tag = current_label . replace ( begin_label , \"\" , 1 ) elif single_label in current_label : if index_tag != '' : tag_list . append ( whole_tag + ',' + str ( i - 1 )) whole_tag = current_label . replace ( single_label , \"\" , 1 ) + '[' + str ( i ) tag_list . append ( whole_tag ) whole_tag = \"\" index_tag = \"\" elif end_label in current_label : if index_tag != '' : tag_list . append ( whole_tag + ',' + str ( i )) whole_tag = '' index_tag = '' else : continue if whole_tag != '' and index_tag != '' : tag_list . append ( whole_tag ) tag_list_len = len ( tag_list ) for i in range ( 0 , tag_list_len ): if len ( tag_list [ i ]) > 0 : tag_list [ i ] = tag_list [ i ] + ']' insert_list = reverse_style ( tag_list [ i ]) stand_matrix . append ( insert_list ) # print stand_matrix return stand_matrix def get_ner_BIO ( label_list ): # list_len = len(word_list) # assert(list_len == len(label_list)), \"word list size unmatch with label list\" list_len = len ( label_list ) begin_label = 'B-' inside_label = 'I-' whole_tag = '' index_tag = '' tag_list = [] stand_matrix = [] for i in range ( 0 , list_len ): # wordlabel = word_list[i] current_label = label_list [ i ] . upper () if begin_label in current_label : if index_tag == '' : whole_tag = current_label . replace ( begin_label , \"\" , 1 ) + '[' + str ( i ) index_tag = current_label . replace ( begin_label , \"\" , 1 ) else : tag_list . append ( whole_tag + ',' + str ( i - 1 )) whole_tag = current_label . replace ( begin_label , \"\" , 1 ) + '[' + str ( i ) index_tag = current_label . replace ( begin_label , \"\" , 1 ) elif inside_label in current_label : if current_label . replace ( inside_label , \"\" , 1 ) == index_tag : whole_tag = whole_tag else : if ( whole_tag != '' ) & ( index_tag != '' ): tag_list . append ( whole_tag + ',' + str ( i - 1 )) whole_tag = '' index_tag = '' else : if ( whole_tag != '' ) & ( index_tag != '' ): tag_list . append ( whole_tag + ',' + str ( i - 1 )) whole_tag = '' index_tag = '' if ( whole_tag != '' ) & ( index_tag != '' ): tag_list . append ( whole_tag ) tag_list_len = len ( tag_list ) for i in range ( 0 , tag_list_len ): if len ( tag_list [ i ]) > 0 : tag_list [ i ] = tag_list [ i ] + ']' insert_list = reverse_style ( tag_list [ i ]) stand_matrix . append ( insert_list ) return stand_matrix def readSentence ( input_file ): in_lines = open ( input_file , 'r' ) . readlines () sentences = [] labels = [] sentence = [] label = [] for line in in_lines : if len ( line ) < 2 : sentences . append ( sentence ) labels . append ( label ) sentence = [] label = [] else : pair = line . strip ( ' \\n ' ) . split ( ' ' ) sentence . append ( pair [ 0 ]) label . append ( pair [ - 1 ]) return sentences , labels \u7b2c2\u6b65: \u6784\u5efa\u6a21\u578b\u7c7b\u7684\u4ee3\u7801 \u00b6 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/code/ner/soft-lexicon/model/gazlstm.py import torch import numpy as np import torch.nn as nn from model.crf import CRF from model.layers import NERmodel from transformers.modeling_bert import BertModel class GazLSTM ( nn . Module ): def __init__ ( self , data ): super ( GazLSTM , self ) . __init__ () self . gpu = data . HP_gpu self . use_biword = data . use_bigram self . hidden_dim = data . HP_hidden_dim self . gaz_alphabet = data . gaz_alphabet self . gaz_emb_dim = data . gaz_emb_dim self . word_emb_dim = data . word_emb_dim self . biword_emb_dim = data . biword_emb_dim self . use_char = data . HP_use_char self . bilstm_flag = data . HP_bilstm self . lstm_layer = data . HP_lstm_layer self . use_count = data . HP_use_count self . num_layer = data . HP_num_layer self . model_type = data . model_type self . use_bert = data . use_bert scale = np . sqrt ( 3.0 / self . gaz_emb_dim ) data . pretrain_gaz_embedding [ 0 , :] = np . random . uniform ( - scale , scale , [ 1 , self . gaz_emb_dim ]) if self . use_char : scale = np . sqrt ( 3.0 / self . word_emb_dim ) data . pretrain_word_embedding [ 0 , :] = np . random . uniform ( - scale , scale , [ 1 , self . word_emb_dim ]) self . gaz_embedding = nn . Embedding ( data . gaz_alphabet . size (), self . gaz_emb_dim ) self . word_embedding = nn . Embedding ( data . word_alphabet . size (), self . word_emb_dim ) if self . use_biword : self . biword_embedding = nn . Embedding ( data . biword_alphabet . size (), self . biword_emb_dim ) if data . pretrain_gaz_embedding is not None : self . gaz_embedding . weight . data . copy_ ( torch . from_numpy ( data . pretrain_gaz_embedding )) else : self . gaz_embedding . weight . data . copy_ ( torch . from_numpy ( self . random_embedding ( data . gaz_alphabet . size (), self . gaz_emb_dim ))) if data . pretrain_word_embedding is not None : self . word_embedding . weight . data . copy_ ( torch . from_numpy ( data . pretrain_word_embedding )) else : self . word_embedding . weight . data . copy_ ( torch . from_numpy ( self . random_embedding ( data . word_alphabet . size (), self . word_emb_dim ))) if self . use_biword : if data . pretrain_biword_embedding is not None : self . biword_embedding . weight . data . copy_ ( torch . from_numpy ( data . pretrain_biword_embedding )) else : self . biword_embedding . weight . data . copy_ ( torch . from_numpy ( self . random_embedding ( data . biword_alphabet . size (), self . word_emb_dim ))) char_feature_dim = self . word_emb_dim + 4 * self . gaz_emb_dim if self . use_biword : char_feature_dim += self . biword_emb_dim if self . use_bert : char_feature_dim = char_feature_dim + 768 # lstm model if self . model_type == 'lstm' : lstm_hidden = self . hidden_dim if self . bilstm_flag : self . hidden_dim *= 2 self . NERmodel = NERmodel ( model_type = 'lstm' , input_dim = char_feature_dim , hidden_dim = lstm_hidden , num_layer = self . lstm_layer , biflag = self . bilstm_flag ) # cnn model if self . model_type == 'cnn' : self . NERmodel = NERmodel ( model_type = 'cnn' , input_dim = char_feature_dim , hidden_dim = self . hidden_dim , num_layer = self . num_layer , dropout = data . HP_dropout , gpu = self . gpu ) # attention model if self . model_type == 'transformer' : self . NERmodel = NERmodel ( model_type = 'transformer' , input_dim = char_feature_dim , hidden_dim = self . hidden_dim , num_layer = self . num_layer , dropout = data . HP_dropout ) self . drop = nn . Dropout ( p = data . HP_dropout ) self . hidden2tag = nn . Linear ( self . hidden_dim , data . label_alphabet_size + 2 ) self . crf = CRF ( data . label_alphabet_size , self . gpu ) if self . use_bert : self . bert_encoder = BertModel . from_pretrained ( 'bert-base-chinese' ) for p in self . bert_encoder . parameters (): p . requires_grad = False if self . gpu : self . gaz_embedding = self . gaz_embedding . cuda () self . word_embedding = self . word_embedding . cuda () if self . use_biword : self . biword_embedding = self . biword_embedding . cuda () self . NERmodel = self . NERmodel . cuda () self . hidden2tag = self . hidden2tag . cuda () self . crf = self . crf . cuda () if self . use_bert : self . bert_encoder = self . bert_encoder . cuda () def get_tags ( self , gaz_list , word_inputs , biword_inputs , layer_gaz , gaz_count , gaz_chars , gaz_mask_input , gazchar_mask_input , mask , word_seq_lengths , batch_bert , bert_mask ): batch_size = word_inputs . size ()[ 0 ] seq_len = word_inputs . size ()[ 1 ] max_gaz_num = layer_gaz . size ( - 1 ) gaz_match = [] word_embs = self . word_embedding ( word_inputs ) if self . use_biword : biword_embs = self . biword_embedding ( biword_inputs ) word_embs = torch . cat ([ word_embs , biword_embs ], dim =- 1 ) if self . model_type != 'transformer' : word_inputs_d = self . drop ( word_embs ) # (b,l,we) else : word_inputs_d = word_embs if self . use_char : gazchar_embeds = self . word_embedding ( gaz_chars ) gazchar_mask = gazchar_mask_input . unsqueeze ( - 1 ) . repeat ( 1 , 1 , 1 , 1 , 1 , self . word_emb_dim ) gazchar_embeds = gazchar_embeds . data . masked_fill_ ( gazchar_mask . data . bool (), 0 ) # (b,l,4,gl,cl,ce) # gazchar_mask_input:(b,l,4,gl,cl) gaz_charnum = ( gazchar_mask_input == 0 ) . sum ( dim =- 1 , keepdim = True ) . float () # (b,l,4,gl,1) gaz_charnum = gaz_charnum + ( gaz_charnum == 0 ) . float () gaz_embeds = gazchar_embeds . sum ( - 2 ) / gaz_charnum # (b,l,4,gl,ce) if self . model_type != 'transformer' : gaz_embeds = self . drop ( gaz_embeds ) else : gaz_embeds = gaz_embeds else : # use gaz embedding gaz_embeds = self . gaz_embedding ( layer_gaz ) if self . model_type != 'transformer' : gaz_embeds_d = self . drop ( gaz_embeds ) else : gaz_embeds_d = gaz_embeds gaz_mask = gaz_mask_input . unsqueeze ( - 1 ) . repeat ( 1 , 1 , 1 , 1 , self . gaz_emb_dim ) gaz_embeds = gaz_embeds_d . data . masked_fill_ ( gaz_mask . data . bool (), 0 ) # (b,l,4,g,ge) ge:gaz_embed_dim if self . use_count : count_sum = torch . sum ( gaz_count , dim = 3 , keepdim = True ) # (b,l,4,gn) count_sum = torch . sum ( count_sum , dim = 2 , keepdim = True ) # (b,l,1,1) weights = gaz_count . div ( count_sum ) # (b,l,4,g) weights = weights * 4 weights = weights . unsqueeze ( - 1 ) gaz_embeds = weights * gaz_embeds # (b,l,4,g,e) gaz_embeds = torch . sum ( gaz_embeds , dim = 3 ) # (b,l,4,e) else : gaz_num = ( gaz_mask_input == 0 ) . sum ( dim =- 1 , keepdim = True ) . float () # (b,l,4,1) gaz_embeds = gaz_embeds . sum ( - 2 ) / gaz_num # (b,l,4,ge)/(b,l,4,1) gaz_embeds_cat = gaz_embeds . view ( batch_size , seq_len , - 1 ) # (b,l,4*ge) word_input_cat = torch . cat ([ word_inputs_d , gaz_embeds_cat ], dim =- 1 ) # (b,l,we+4*ge) # cat bert feature if self . use_bert : seg_id = torch . zeros ( bert_mask . size ()) . long () . cuda () outputs = self . bert_encoder ( batch_bert , bert_mask , seg_id ) outputs = outputs [ 0 ][:, 1 : - 1 , :] word_input_cat = torch . cat ([ word_input_cat , outputs ], dim =- 1 ) feature_out_d = self . NERmodel ( word_input_cat ) tags = self . hidden2tag ( feature_out_d ) return tags , gaz_match def neg_log_likelihood_loss ( self , gaz_list , word_inputs , biword_inputs , word_seq_lengths , layer_gaz , gaz_count , gaz_chars , gaz_mask , gazchar_mask , mask , batch_label , batch_bert , bert_mask ): tags , _ = self . get_tags ( gaz_list , word_inputs , biword_inputs , layer_gaz , gaz_count , gaz_chars , gaz_mask , gazchar_mask , mask , word_seq_lengths , batch_bert , bert_mask ) total_loss = self . crf . neg_log_likelihood_loss ( tags , mask , batch_label ) scores , tag_seq = self . crf . _viterbi_decode ( tags , mask ) return total_loss , tag_seq def forward ( self , gaz_list , word_inputs , biword_inputs , word_seq_lengths , layer_gaz , gaz_count , gaz_chars , gaz_mask , gazchar_mask , mask , batch_bert , bert_mask ): tags , gaz_match = self . get_tags ( gaz_list , word_inputs , biword_inputs , layer_gaz , gaz_count , gaz_chars , gaz_mask , gazchar_mask , mask , word_seq_lengths , batch_bert , bert_mask ) scores , tag_seq = self . crf . _viterbi_decode ( tags , mask ) return tag_seq , gaz_match \u4ee3\u7801\u8def\u5f84: /models/zhudejun/paper/information_extraction/ner/soft-lexicon/model/layers.py import torch import math , copy import torch.autograd as autograd import torch.nn as nn import torch.nn.functional as F class CNNmodel ( nn . Module ): def __init__ ( self , input_dim , hidden_dim , num_layer , dropout , gpu = True ): super ( CNNmodel , self ) . __init__ () self . input_dim = input_dim self . hidden_dim = hidden_dim self . num_layer = num_layer self . gpu = gpu self . cnn_layer0 = nn . Conv1d ( self . input_dim , self . hidden_dim , kernel_size = 1 , padding = 0 ) self . cnn_layers = [ nn . Conv1d ( self . hidden_dim , self . hidden_dim , kernel_size = 3 , padding = 1 ) for i in range ( self . num_layer - 1 )] self . drop = nn . Dropout ( dropout ) if self . gpu : self . cnn_layer0 = self . cnn_layer0 . cuda () for i in range ( self . num_layer - 1 ): self . cnn_layers [ i ] = self . cnn_layers [ i ] . cuda () def forward ( self , input_feature ): input_feature = input_feature . transpose ( 2 , 1 ) . contiguous () cnn_output = self . cnn_layer0 ( input_feature ) # (b,h,l) cnn_output = self . drop ( cnn_output ) cnn_output = torch . tanh ( cnn_output ) for layer in range ( self . num_layer - 1 ): cnn_output = self . cnn_layers [ layer ]( cnn_output ) cnn_output = self . drop ( cnn_output ) cnn_output = torch . tanh ( cnn_output ) cnn_output = cnn_output . transpose ( 2 , 1 ) . contiguous () return cnn_output def clones ( module , N ): \"Produce N identical layers.\" return nn . ModuleList ([ copy . deepcopy ( module ) for _ in range ( N )]) class LayerNorm ( nn . Module ): \"Construct a layernorm module (See citation for details).\" def __init__ ( self , features , eps = 1e-6 ): super ( LayerNorm , self ) . __init__ () self . a_2 = nn . Parameter ( torch . ones ( features )) self . b_2 = nn . Parameter ( torch . zeros ( features )) self . eps = eps def forward ( self , x ): mean = x . mean ( - 1 , keepdim = True ) std = x . std ( - 1 , keepdim = True ) return self . a_2 * ( x - mean ) / ( std + self . eps ) + self . b_2 class SublayerConnection ( nn . Module ): \"\"\" A residual connection followed by a layer norm. Note for code simplicity the norm is first as opposed to last. \"\"\" def __init__ ( self , size , dropout ): super ( SublayerConnection , self ) . __init__ () self . norm = LayerNorm ( size ) self . dropout = nn . Dropout ( dropout ) def forward ( self , x , sublayer ): \"Apply residual connection to any sublayer with the same size.\" return x + self . dropout ( sublayer ( self . norm ( x ))) class EncoderLayer ( nn . Module ): \"Encoder is made up of self-attn and feed forward (defined below)\" def __init__ ( self , size , self_attn , feed_forward , dropout ): super ( EncoderLayer , self ) . __init__ () self . self_attn = self_attn self . feed_forward = feed_forward self . sublayer = clones ( SublayerConnection ( size , dropout ), 2 ) self . size = size def forward ( self , x , mask ): \"Follow Figure 1 (left) for connections.\" x = self . sublayer [ 0 ]( x , lambda x : self . self_attn ( x , x , x , mask . bool ())) return self . sublayer [ 1 ]( x , self . feed_forward ) def attention ( query , key , value , mask = None , dropout = None ): \"Compute 'Scaled Dot Product Attention'\" d_k = query . size ( - 1 ) scores = torch . matmul ( query , key . transpose ( - 2 , - 1 )) / math . sqrt ( d_k ) # (b,h,l,d) * (b,h,d,l) if mask is not None : scores = scores . masked_fill ( mask . bool (), - 1e9 ) p_attn = F . softmax ( scores , dim =- 1 ) if dropout is not None : p_attn = dropout ( p_attn ) return torch . matmul ( p_attn , value ), p_attn # (b,h,l,l) * (b,h,l,d) = (b,h,l,d) class MultiHeadedAttention ( nn . Module ): def __init__ ( self , h , d_model , dropout = 0.1 ): \"Take in model size and number of heads.\" super ( MultiHeadedAttention , self ) . __init__ () assert d_model % h == 0 # We assume d_v always equals d_k self . d_k = d_model // h self . h = h self . linears = clones ( nn . Linear ( d_model , d_model ), 4 ) self . attn = None self . dropout = nn . Dropout ( p = dropout ) def forward ( self , query , key , value , mask = None ): \"Implements Figure 2\" if mask is not None : # Same mask applied to all h heads. mask = mask . unsqueeze ( 1 ) . bool () nbatches = query . size ( 0 ) # 1) Do all the linear projections in batch from d_model => h x d_k query , key , value = \\ [ l ( x ) . view ( nbatches , - 1 , self . h , self . d_k ) . transpose ( 1 , 2 ) for l , x in zip ( self . linears , ( query , key , value ))] # 2) Apply attention on all the projected vectors in batch. x , self . attn = attention ( query , key , value , mask = mask , dropout = self . dropout ) # 3) \"Concat\" using a view and apply a final linear. x = x . transpose ( 1 , 2 ) . contiguous () . view ( nbatches , - 1 , self . h * self . d_k ) return self . linears [ - 1 ]( x ) class PositionwiseFeedForward ( nn . Module ): \"Implements FFN equation.\" def __init__ ( self , d_model , d_ff , dropout = 0.1 ): super ( PositionwiseFeedForward , self ) . __init__ () self . w_1 = nn . Linear ( d_model , d_ff ) self . w_2 = nn . Linear ( d_ff , d_model ) self . dropout = nn . Dropout ( dropout ) def forward ( self , x ): return self . w_2 ( self . dropout ( F . relu ( self . w_1 ( x )))) class PositionalEncoding ( nn . Module ): \"Implement the PE function.\" def __init__ ( self , d_model , dropout , max_len = 5000 ): super ( PositionalEncoding , self ) . __init__ () self . dropout = nn . Dropout ( p = dropout ) # Compute the positional encodings once in log space. pe = torch . zeros ( max_len , d_model ) position = torch . arange ( 0. , max_len ) . unsqueeze ( 1 ) div_term = torch . exp ( torch . arange ( 0. , d_model , 2 ) * - ( math . log ( 10000.0 ) / d_model )) pe [:, 0 :: 2 ] = torch . sin ( position * div_term ) pe [:, 1 :: 2 ] = torch . cos ( position * div_term ) pe = pe . unsqueeze ( 0 ) self . register_buffer ( 'pe' , pe ) def forward ( self , x ): x = x + autograd . Variable ( self . pe [:, : x . size ( 1 )], requires_grad = False ) return self . dropout ( x ) class AttentionModel ( nn . Module ): \"Core encoder is a stack of N layers\" def __init__ ( self , d_input , d_model , d_ff , head , num_layer , dropout ): super ( AttentionModel , self ) . __init__ () c = copy . deepcopy # attn0 = MultiHeadedAttention(head, d_input, d_model) attn = MultiHeadedAttention ( head , d_model , dropout ) ff = PositionwiseFeedForward ( d_model , d_ff , dropout ) # position = PositionalEncoding(d_model, dropout) # layer0 = EncoderLayer(d_model, c(attn0), c(ff), dropout) layer = EncoderLayer ( d_model , c ( attn ), c ( ff ), dropout ) self . layers = clones ( layer , num_layer ) # layerlist = [copy.deepcopy(layer0),] # for _ in range(num_layer-1): # layerlist.append(copy.deepcopy(layer)) # self.layers = nn.ModuleList(layerlist) self . norm = LayerNorm ( layer . size ) self . posi = PositionalEncoding ( d_model , dropout ) self . input2model = nn . Linear ( d_input , d_model ) def forward ( self , x , mask ): \"Pass the input (and mask) through each layer in turn.\" # x: embedding (b,l,we) x = self . posi ( self . input2model ( x )) for layer in self . layers : x = layer ( x , mask . bool ()) return self . norm ( x ) class NERmodel ( nn . Module ): def __init__ ( self , model_type , input_dim , hidden_dim , num_layer , dropout = 0.5 , gpu = True , biflag = True ): super ( NERmodel , self ) . __init__ () self . model_type = model_type if self . model_type == 'cnn' : self . cnn = CNNmodel ( input_dim , hidden_dim , num_layer , dropout , gpu ) # attention model elif self . model_type == 'transformer' : self . attention_model = AttentionModel ( d_input = input_dim , d_model = hidden_dim , d_ff = 2 * hidden_dim , head = 4 , num_layer = num_layer , dropout = dropout ) for p in self . attention_model . parameters (): if p . dim () > 1 : nn . init . xavier_uniform_ ( p ) else : assert self . model_type == 'lstm' self . lstm = nn . LSTM ( input_dim , hidden_dim , num_layers = num_layer , batch_first = True , bidirectional = biflag ) self . drop = nn . Dropout ( dropout ) def forward ( self , input , mask = None ): if self . model_type == 'cnn' : feature_out_d = self . cnn ( input ) elif self . model_type == 'transformer' : feature_out_d = self . attention_model ( input , mask ) else : assert self . model_type == 'lstm' hidden = None feature_out , hidden = self . lstm ( input , hidden ) feature_out_d = self . drop ( feature_out ) return feature_out_d \u7b2c3\u6b65: \u4e3b\u51fd\u6570\u4ee3\u7801\u7684\u5b9e\u73b0 \u00b6 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/code/ner/soft-lexicon/main.py def predict_check ( pred_variable , gold_variable , mask_variable ): \"\"\" input: pred_variable (batch_size, sent_len): pred tag result, in numpy format gold_variable (batch_size, sent_len): gold result variable mask_variable (batch_size, sent_len): mask variable \"\"\" pred = pred_variable . cpu () . data . numpy () gold = gold_variable . cpu () . data . numpy () mask = mask_variable . cpu () . data . numpy () overlaped = ( pred == gold ) right_token = np . sum ( overlaped * mask ) total_token = mask . sum () return right_token , total_token def recover_label ( pred_variable , gold_variable , mask_variable , label_alphabet ): \"\"\" input: pred_variable (batch_size, sent_len): pred tag result gold_variable (batch_size, sent_len): gold result variable mask_variable (batch_size, sent_len): mask variable \"\"\" batch_size = gold_variable . size ( 0 ) seq_len = gold_variable . size ( 1 ) mask = mask_variable . cpu () . data . numpy () pred_tag = pred_variable . cpu () . data . numpy () gold_tag = gold_variable . cpu () . data . numpy () batch_size = mask . shape [ 0 ] pred_label = [] gold_label = [] for idx in range ( batch_size ): pred = [ label_alphabet . get_instance ( int ( pred_tag [ idx ][ idy ])) for idy in range ( seq_len ) if mask [ idx ][ idy ] != 0 ] gold = [ label_alphabet . get_instance ( gold_tag [ idx ][ idy ]) for idy in range ( seq_len ) if mask [ idx ][ idy ] != 0 ] assert ( len ( pred ) == len ( gold )) pred_label . append ( pred ) gold_label . append ( gold ) return pred_label , gold_label def print_batchword ( data , batch_word , n ): with open ( \"labels/batchwords.txt\" , \"a\" ) as fp : for i in range ( len ( batch_word )): words = [] for id in batch_word [ i ]: words . append ( data . word_alphabet . get_instance ( id )) fp . write ( str ( words )) def save_data_setting ( data , save_file ): new_data = copy . deepcopy ( data ) # remove input instances new_data . train_texts = [] new_data . dev_texts = [] new_data . test_texts = [] new_data . raw_texts = [] new_data . train_Ids = [] new_data . dev_Ids = [] new_data . test_Ids = [] new_data . raw_Ids = [] # save data settings with open ( save_file , 'wb' ) as fp : pickle . dump ( new_data , fp ) print ( \"Data setting saved to file: \" , save_file ) def load_data_setting ( save_file ): with open ( save_file , 'rb' ) as fp : data = pickle . load ( fp ) print ( \"Data setting loaded from file: \" , save_file ) data . show_data_summary () return data def lr_decay ( optimizer , epoch , decay_rate , init_lr ): lr = init_lr * (( 1 - decay_rate ) ** epoch ) print ( \" Learning rate is setted as:\" , lr ) for param_group in optimizer . param_groups : param_group [ 'lr' ] = lr return optimizer def set_seed ( seed_num = 1023 ): random . seed ( seed_num ) torch . manual_seed ( seed_num ) np . random . seed ( seed_num ) def evaluate ( data , model , name ): if name == \"train\" : instances = data . train_Ids elif name == \"dev\" : instances = data . dev_Ids elif name == 'test' : instances = data . test_Ids elif name == 'raw' : instances = data . raw_Ids else : print ( \"Error: wrong evaluate name,\" , name ) pred_results = [] gold_results = [] # set model in eval model model . eval () batch_size = 1 start_time = time . time () train_num = len ( instances ) total_batch = train_num // batch_size + 1 gazes = [] for batch_id in range ( total_batch ): with torch . no_grad (): start = batch_id * batch_size end = ( batch_id + 1 ) * batch_size if end > train_num : end = train_num instance = instances [ start : end ] if not instance : continue gaz_list , batch_word , batch_biword , batch_wordlen , batch_label , layer_gaz , gaz_count , gaz_chars , gaz_mask , gazchar_mask , mask , batch_bert , bert_mask = batchify_with_label ( instance , data . HP_gpu , data . HP_num_layer , True ) tag_seq , gaz_match = model ( gaz_list , batch_word , batch_biword , batch_wordlen , layer_gaz , gaz_count , gaz_chars , gaz_mask , gazchar_mask , mask , batch_bert , bert_mask ) gaz_list = [ data . gaz_alphabet . get_instance ( id ) for batchlist in gaz_match if len ( batchlist ) > 0 for id in batchlist ] gazes . append ( gaz_list ) if name == \"dev\" : pred_label , gold_label = recover_label ( tag_seq , batch_label , mask , data . label_alphabet ) else : pred_label , gold_label = recover_label ( tag_seq , batch_label , mask , data . label_alphabet ) pred_results += pred_label gold_results += gold_label decode_time = time . time () - start_time speed = len ( instances ) / decode_time acc , p , r , f = get_ner_fmeasure ( gold_results , pred_results , data . tagScheme ) return speed , acc , p , r , f , pred_results , gazes def get_text_input ( self , caption ): caption_tokens = self . tokenizer . tokenize ( caption ) caption_tokens = [ '[CLS]' ] + caption_tokens + [ '[SEP]' ] caption_ids = self . tokenizer . convert_tokens_to_ids ( caption_tokens ) if len ( caption_ids ) >= self . max_seq_len : caption_ids = caption_ids [: self . max_seq_len ] else : caption_ids = caption_ids + [ 0 ] * ( self . max_seq_len - len ( caption_ids )) caption = torch . tensor ( caption_ids ) return caption def batchify_with_label ( input_batch_list , gpu , num_layer , volatile_flag = False ): batch_size = len ( input_batch_list ) words = [ sent [ 0 ] for sent in input_batch_list ] biwords = [ sent [ 1 ] for sent in input_batch_list ] gazs = [ sent [ 3 ] for sent in input_batch_list ] labels = [ sent [ 4 ] for sent in input_batch_list ] layer_gazs = [ sent [ 5 ] for sent in input_batch_list ] gaz_count = [ sent [ 6 ] for sent in input_batch_list ] gaz_chars = [ sent [ 7 ] for sent in input_batch_list ] gaz_mask = [ sent [ 8 ] for sent in input_batch_list ] gazchar_mask = [ sent [ 9 ] for sent in input_batch_list ] # bert tokens bert_ids = [ sent [ 10 ] for sent in input_batch_list ] word_seq_lengths = torch . LongTensor ( list ( map ( len , words ))) max_seq_len = word_seq_lengths . max () word_seq_tensor = autograd . Variable ( torch . zeros (( batch_size , max_seq_len ))) . long () biword_seq_tensor = autograd . Variable ( torch . zeros (( batch_size , max_seq_len ))) . long () label_seq_tensor = autograd . Variable ( torch . zeros (( batch_size , max_seq_len ))) . long () mask = autograd . Variable ( torch . zeros (( batch_size , max_seq_len ))) . byte () # bert seq tensor bert_seq_tensor = autograd . Variable ( torch . zeros (( batch_size , max_seq_len + 2 ))) . long () bert_mask = autograd . Variable ( torch . zeros (( batch_size , max_seq_len + 2 ))) . long () gaz_num = [ len ( layer_gazs [ i ][ 0 ][ 0 ]) for i in range ( batch_size )] max_gaz_num = max ( gaz_num ) layer_gaz_tensor = torch . zeros ( batch_size , max_seq_len , 4 , max_gaz_num ) . long () gaz_count_tensor = torch . zeros ( batch_size , max_seq_len , 4 , max_gaz_num ) . float () gaz_len = [ len ( gaz_chars [ i ][ 0 ][ 0 ][ 0 ]) for i in range ( batch_size )] max_gaz_len = max ( gaz_len ) gaz_chars_tensor = torch . zeros ( batch_size , max_seq_len , 4 , max_gaz_num , max_gaz_len ) . long () gaz_mask_tensor = torch . ones ( batch_size , max_seq_len , 4 , max_gaz_num ) . byte () gazchar_mask_tensor = torch . ones ( batch_size , max_seq_len , 4 , max_gaz_num , max_gaz_len ) . byte () for b , ( seq , bert_id , biseq , label , seqlen , layergaz , gazmask , gazcount , gazchar , gazchar_mask , gaznum , gazlen ) in enumerate ( zip ( words , bert_ids , biwords , labels , word_seq_lengths , layer_gazs , gaz_mask , gaz_count , gaz_chars , gazchar_mask , gaz_num , gaz_len )): word_seq_tensor [ b , : seqlen ] = torch . LongTensor ( seq ) biword_seq_tensor [ b , : seqlen ] = torch . LongTensor ( biseq ) label_seq_tensor [ b , : seqlen ] = torch . LongTensor ( label ) layer_gaz_tensor [ b , : seqlen , :, : gaznum ] = torch . LongTensor ( layergaz ) mask [ b , : seqlen ] = torch . Tensor ([ 1 ] * int ( seqlen )) bert_mask [ b , : seqlen + 2 ] = torch . LongTensor ([ 1 ] * int ( seqlen + 2 )) gaz_mask_tensor [ b , : seqlen , :, : gaznum ] = torch . ByteTensor ( gazmask ) gaz_count_tensor [ b , : seqlen , :, : gaznum ] = torch . FloatTensor ( gazcount ) gaz_count_tensor [ b , seqlen :] = 1 gaz_chars_tensor [ b , : seqlen , :, : gaznum , : gazlen ] = torch . LongTensor ( gazchar ) gazchar_mask_tensor [ b , : seqlen , :, : gaznum , : gazlen ] = torch . ByteTensor ( gazchar_mask ) # bert bert_seq_tensor [ b , : seqlen + 2 ] = torch . LongTensor ( bert_id ) if gpu : word_seq_tensor = word_seq_tensor . cuda () biword_seq_tensor = biword_seq_tensor . cuda () word_seq_lengths = word_seq_lengths . cuda () label_seq_tensor = label_seq_tensor . cuda () layer_gaz_tensor = layer_gaz_tensor . cuda () gaz_chars_tensor = gaz_chars_tensor . cuda () gaz_mask_tensor = gaz_mask_tensor . cuda () gazchar_mask_tensor = gazchar_mask_tensor . cuda () gaz_count_tensor = gaz_count_tensor . cuda () mask = mask . cuda () bert_seq_tensor = bert_seq_tensor . cuda () bert_mask = bert_mask . cuda () # print(bert_seq_tensor.type()) return gazs , word_seq_tensor , biword_seq_tensor , word_seq_lengths , label_seq_tensor , layer_gaz_tensor , gaz_count_tensor , gaz_chars_tensor , gaz_mask_tensor , gazchar_mask_tensor , mask , bert_seq_tensor , bert_mask def train ( data , save_model_dir , seg = True ): print ( \"Training with {} model.\" . format ( data . model_type )) # data.show_data_summary() model = SeqModel ( data ) print ( \"finish building model.\" ) parameters = filter ( lambda p : p . requires_grad , model . parameters ()) optimizer = optim . Adamax ( parameters , lr = data . HP_lr ) best_dev = - 1 best_dev_p = - 1 best_dev_r = - 1 best_test = - 1 best_test_p = - 1 best_test_r = - 1 # start training for idx in range ( data . HP_iteration ): epoch_start = time . time () temp_start = epoch_start print (( \"Epoch: %s / %s \" % ( idx , data . HP_iteration ))) optimizer = lr_decay ( optimizer , idx , data . HP_lr_decay , data . HP_lr ) instance_count = 0 sample_loss = 0 batch_loss = 0 total_loss = 0 right_token = 0 whole_token = 0 random . shuffle ( data . train_Ids ) # set model in train model model . train () model . zero_grad () batch_size = data . HP_batch_size batch_id = 0 train_num = len ( data . train_Ids ) total_batch = train_num // batch_size + 1 for batch_id in range ( total_batch ): start = batch_id * batch_size end = ( batch_id + 1 ) * batch_size if end > train_num : end = train_num instance = data . train_Ids [ start : end ] words = data . train_texts [ start : end ] if not instance : continue gaz_list , batch_word , batch_biword , batch_wordlen , batch_label , layer_gaz , gaz_count , gaz_chars , gaz_mask , gazchar_mask , mask , batch_bert , bert_mask = batchify_with_label ( instance , data . HP_gpu , data . HP_num_layer ) instance_count += 1 loss , tag_seq = model . neg_log_likelihood_loss ( gaz_list , batch_word , batch_biword , batch_wordlen , layer_gaz , gaz_count , gaz_chars , gaz_mask , gazchar_mask , mask , batch_label , batch_bert , bert_mask ) right , whole = predict_check ( tag_seq , batch_label , mask ) right_token += right whole_token += whole sample_loss += loss . data total_loss += loss . data batch_loss += loss if end % 500 == 0 : temp_time = time . time () temp_cost = temp_time - temp_start temp_start = temp_time print (( \" Instance: %s ; Time: %.2f s; loss: %.4f ; acc: %s / %s = %.4f \" % ( end , temp_cost , sample_loss , right_token , whole_token , ( right_token + 0. ) / whole_token ))) sys . stdout . flush () sample_loss = 0 if end % data . HP_batch_size == 0 : batch_loss . backward () optimizer . step () model . zero_grad () batch_loss = 0 temp_time = time . time () temp_cost = temp_time - temp_start print (( \" Instance: %s ; Time: %.2f s; loss: %.4f ; acc: %s / %s = %.4f \" % ( end , temp_cost , sample_loss , right_token , whole_token , ( right_token + 0. ) / whole_token ))) epoch_finish = time . time () epoch_cost = epoch_finish - epoch_start print (( \"Epoch: %s training finished. Time: %.2f s, speed: %.2f st/s, total loss: %s \" % ( idx , epoch_cost , train_num / epoch_cost , total_loss ))) speed , acc , p , r , f , pred_labels , gazs = evaluate ( data , model , \"dev\" ) dev_finish = time . time () dev_cost = dev_finish - epoch_finish if seg : current_score = f print (( \"Dev: time: %.2f s, speed: %.2f st/s; acc: %.4f , p: %.4f , r: %.4f , f: %.4f \" % ( dev_cost , speed , acc , p , r , f ))) else : current_score = acc print (( \"Dev: time: %.2f s speed: %.2f st/s; acc: %.4f \" % ( dev_cost , speed , acc ))) if current_score > best_dev : if seg : print ( \"Exceed previous best f score:\" , best_dev ) else : print ( \"Exceed previous best acc score:\" , best_dev ) model_name = save_model_dir torch . save ( model . state_dict (), model_name ) # best_dev = current_score best_dev_p = p best_dev_r = r # ## decode test speed , acc , p , r , f , pred_labels , gazs = evaluate ( data , model , \"test\" ) test_finish = time . time () test_cost = test_finish - dev_finish if seg : current_test_score = f print (( \"Test: time: %.2f s, speed: %.2f st/s; acc: %.4f , p: %.4f , r: %.4f , f: %.4f \" % ( test_cost , speed , acc , p , r , f ))) else : current_test_score = acc print (( \"Test: time: %.2f s, speed: %.2f st/s; acc: %.4f \" % ( test_cost , speed , acc ))) if current_score > best_dev : best_dev = current_score best_test = current_test_score best_test_p = p best_test_r = r print ( \"Best dev score: p: {} , r: {} , f: {} \" . format ( best_dev_p , best_dev_r , best_dev )) print ( \"Test score: p: {} , r: {} , f: {} \" . format ( best_test_p , best_test_r , best_test )) gc . collect () with open ( data . result_file , \"a\" ) as f : f . write ( save_model_dir + ' \\n ' ) f . write ( \"Best dev score: p: {} , r: {} , f: {} \\n \" . format ( best_dev_p , best_dev_r , best_dev )) f . write ( \"Test score: p: {} , r: {} , f: {} \\n\\n \" . format ( best_test_p , best_test_r , best_test )) f . close () def load_model_decode ( model_dir , data , name , gpu , seg = True ): data . HP_gpu = gpu print ( \"Load Model from file: \" , model_dir ) model = SeqModel ( data ) model . load_state_dict ( torch . load ( model_dir )) print (( \"Decode %s data ...\" % ( name ))) start_time = time . time () speed , acc , p , r , f , pred_results , gazs = evaluate ( data , model , name ) end_time = time . time () time_cost = end_time - start_time if seg : print (( \" %s : time: %.2f s, speed: %.2f st/s; acc: %.4f , p: %.4f , r: %.4f , f: %.4f \" % ( name , time_cost , speed , acc , p , r , f ))) else : print (( \" %s : time: %.2f s, speed: %.2f st/s; acc: %.4f \" % ( name , time_cost , speed , acc ))) return pred_results def print_results ( pred , modelname = \"\" ): toprint = [] for sen in pred : sen = \" \" . join ( sen ) + ' \\n ' toprint . append ( sen ) with open ( modelname + '_labels.txt' , 'w' ) as f : f . writelines ( toprint ) \u7b2c4\u6b65: \u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u811a\u672c \u00b6 \u8bad\u7ec3\u811a\u672c: /home/ec2-user/code/ner/soft-lexicon/train.sh python main . py -- train data / ResumeNER / train . char . bmes -- dev data / ResumeNER / dev . char . bmes -- test data / ResumeNER / test . char . bmes -- modelname ResumeNER -- savedset data / data . dset \u6d4b\u8bd5\u811a\u672c: /home/ec2-user/code/ner/soft-lexicon/test.sh python main . py -- test data / ResumeNER / test . char . bmes -- modelname ResumeNER -- savedset data / data . dset \u7b2c5\u6b65: \u6a21\u578b\u7684\u8bad\u7ec3 \u00b6 \u8c03\u7528: sh train.sh \u8f93\u51fa\u7ed3\u679c: Loading processed train data data.use_biword= False Training with lstm model. build batched crf... finish building model. Epoch: 0/100 Learning rate is setted as: 0.0015 Instance: 500; Time: 32.52s; loss: 6444.8052; acc: 21720.0/23426.0=0.9272 Instance: 1000; Time: 30.42s; loss: 3167.6731; acc: 42567.0/45188.0=0.9420 Instance: 1500; Time: 30.38s; loss: 2078.1272; acc: 63642.0/66928.0=0.9509 Instance: 1999; Time: 32.58s; loss: 1800.6085; acc: 86516.0/90371.0=0.9573 Epoch: 0 training finished. Time: 125.90s, speed: 15.88st/s, total loss: tensor(13491.2178, device='cuda:0') gold_num = 1026 pred_num = 1044 right_num = 860 Dev: time: 4.59s, speed: 115.96st/s; acc: 0.9660, p: 0.8238, r: 0.8382, f: 0.8309 Exceed previous best f score: -1 gold_num = 1026 pred_num = 1044 right_num = 860 Test: time: 4.58s, speed: 117.17st/s; acc: 0.9660, p: 0.8238, r: 0.8382, f: 0.8309 Best dev score: p:0.8237547892720306, r:0.8382066276803118, f:0.8309178743961353 Test score: p:0.8237547892720306, r:0.8382066276803118, f:0.8309178743961353 Epoch: 1/100 Learning rate is setted as: 0.001425 Instance: 500; Time: 30.69s; loss: 1172.0479; acc: 21708.0/22138.0=0.9806 Instance: 1000; Time: 30.97s; loss: 1389.0051; acc: 43721.0/44522.0=0.9820 Instance: 1500; Time: 31.34s; loss: 1115.4781; acc: 66035.0/67218.0=0.9824 Instance: 1999; Time: 32.04s; loss: 991.1306; acc: 88852.0/90371.0=0.9832 Epoch: 1 training finished. Time: 125.04s, speed: 15.99st/s, total loss: tensor(4667.6572, device='cuda:0') gold_num = 1026 pred_num = 1059 right_num = 922 Dev: time: 4.55s, speed: 116.99st/s; acc: 0.9761, p: 0.8706, r: 0.8986, f: 0.8844 Exceed previous best f score: 0.8309178743961353 gold_num = 1026 pred_num = 1059 right_num = 922 Test: time: 4.59s, speed: 116.86st/s; acc: 0.9761, p: 0.8706, r: 0.8986, f: 0.8844 Best dev score: p:0.8706326723323891, r:0.898635477582846, f:0.8844124700239807 Test score: p:0.8706326723323891, r:0.898635477582846, f:0.8844124700239807 Epoch: 2/100 Learning rate is setted as: 0.00135375 Instance: 500; Time: 30.50s; loss: 1005.5997; acc: 21713.0/21989.0=0.9874 Instance: 1000; Time: 32.26s; loss: 812.4775; acc: 44653.0/45218.0=0.9875 Instance: 1500; Time: 30.83s; loss: 613.4433; acc: 66666.0/67473.0=0.9880 Instance: 1999; Time: 31.60s; loss: 657.8646; acc: 89294.0/90371.0=0.9881 Epoch: 2 training finished. Time: 125.19s, speed: 15.97st/s, total loss: tensor(3089.3857, device='cuda:0') gold_num = 1026 pred_num = 944 right_num = 916 Dev: time: 4.54s, speed: 117.28st/s; acc: 0.9832, p: 0.9703, r: 0.8928, f: 0.9299 Exceed previous best f score: 0.8844124700239807 gold_num = 1026 pred_num = 944 right_num = 916 Test: time: 4.57s, speed: 117.25st/s; acc: 0.9832, p: 0.9703, r: 0.8928, f: 0.9299 Best dev score: p:0.9703389830508474, r:0.8927875243664717, f:0.9299492385786802 Test score: p:0.9703389830508474, r:0.8927875243664717, f:0.9299492385786802 Epoch: 3/100 Learning rate is setted as: 0.0012860624999999999 Instance: 500; Time: 31.68s; loss: 403.6226; acc: 22831.0/22985.0=0.9933 Instance: 1000; Time: 30.65s; loss: 794.4869; acc: 44707.0/45127.0=0.9907 Instance: 1500; Time: 30.32s; loss: 544.4160; acc: 66367.0/67016.0=0.9903 Instance: 1999; Time: 32.27s; loss: 545.2573; acc: 89498.0/90371.0=0.9903 Epoch: 3 training finished. Time: 124.93s, speed: 16.00st/s, total loss: tensor(2287.7854, device='cuda:0') gold_num = 1026 pred_num = 1086 right_num = 983 Dev: time: 4.56s, speed: 116.88st/s; acc: 0.9847, p: 0.9052, r: 0.9581, f: 0.9309 Exceed previous best f score: 0.9299492385786802 gold_num = 1026 pred_num = 1086 right_num = 983 Test: time: 4.58s, speed: 117.16st/s; acc: 0.9847, p: 0.9052, r: 0.9581, f: 0.9309 Best dev score: p:0.9051565377532228, r:0.9580896686159844, f:0.9308712121212122 Test score: p:0.9051565377532228, r:0.9580896686159844, f:0.9308712121212122 Epoch: 4/100 Learning rate is setted as: 0.0012217593749999998 Instance: 500; Time: 31.63s; loss: 430.0888; acc: 22695.0/22871.0=0.9923 Instance: 1000; Time: 30.07s; loss: 396.8073; acc: 44065.0/44404.0=0.9924 Instance: 1500; Time: 31.81s; loss: 561.2547; acc: 66870.0/67412.0=0.9920 Instance: 1999; Time: 31.80s; loss: 382.0838; acc: 89671.0/90371.0=0.9923 Epoch: 4 training finished. Time: 125.31s, speed: 15.95st/s, total loss: tensor(1770.2340, device='cuda:0') gold_num = 1026 pred_num = 1035 right_num = 976 Dev: time: 4.53s, speed: 117.55st/s; acc: 0.9872, p: 0.9430, r: 0.9513, f: 0.9471 Exceed previous best f score: 0.9308712121212122 gold_num = 1026 pred_num = 1035 right_num = 976 Test: time: 4.55s, speed: 117.74st/s; acc: 0.9872, p: 0.9430, r: 0.9513, f: 0.9471 Best dev score: p:0.9429951690821256, r:0.9512670565302144, f:0.9471130519165454 Test score: p:0.9429951690821256, r:0.9512670565302144, f:0.9471130519165454 Epoch: 5/100 Learning rate is setted as: 0.0011606714062499996 Instance: 500; Time: 31.05s; loss: 476.5773; acc: 22253.0/22429.0=0.9922 Instance: 1000; Time: 31.19s; loss: 347.2917; acc: 44649.0/44970.0=0.9929 Instance: 1500; Time: 31.67s; loss: 251.4872; acc: 67279.0/67724.0=0.9934 Instance: 1999; Time: 31.51s; loss: 402.8557; acc: 89768.0/90371.0=0.9933 Epoch: 5 training finished. Time: 125.42s, speed: 15.94st/s, total loss: tensor(1478.2144, device='cuda:0') gold_num = 1026 pred_num = 1093 right_num = 1006 Dev: time: 4.52s, speed: 117.85st/s; acc: 0.9883, p: 0.9204, r: 0.9805, f: 0.9495 Exceed previous best f score: 0.9471130519165454 gold_num = 1026 pred_num = 1093 right_num = 1006 Test: time: 4.55s, speed: 117.84st/s; acc: 0.9883, p: 0.9204, r: 0.9805, f: 0.9495 Best dev score: p:0.9204025617566332, r:0.9805068226120858, f:0.9495044832468145 Test score: p:0.9204025617566332, r:0.9805068226120858, f:0.9495044832468145 Epoch: 6/100 Learning rate is setted as: 0.0011026378359374996 Instance: 500; Time: 30.73s; loss: 262.0597; acc: 22079.0/22186.0=0.9952 Instance: 1000; Time: 32.20s; loss: 478.9395; acc: 45099.0/45386.0=0.9937 Instance: 1500; Time: 32.35s; loss: 300.3384; acc: 68196.0/68619.0=0.9938 Instance: 1999; Time: 30.45s; loss: 234.9602; acc: 89839.0/90371.0=0.9941 Epoch: 6 training finished. Time: 125.73s, speed: 15.90st/s, total loss: tensor(1276.2983, device='cuda:0') gold_num = 1026 pred_num = 1041 right_num = 993 Dev: time: 4.51s, speed: 117.94st/s; acc: 0.9901, p: 0.9539, r: 0.9678, f: 0.9608 Exceed previous best f score: 0.9495044832468145 gold_num = 1026 pred_num = 1041 right_num = 993 Test: time: 4.54s, speed: 118.11st/s; acc: 0.9901, p: 0.9539, r: 0.9678, f: 0.9608 Best dev score: p:0.9538904899135446, r:0.9678362573099415, f:0.9608127721335267 Test score: p:0.9538904899135446, r:0.9678362573099415, f:0.9608127721335267 Epoch: 7/100 Learning rate is setted as: 0.0010475059441406246 Instance: 500; Time: 32.10s; loss: 325.9810; acc: 23012.0/23160.0=0.9936 Instance: 1000; Time: 31.01s; loss: 345.6270; acc: 45099.0/45378.0=0.9939 Instance: 1500; Time: 30.36s; loss: 232.4619; acc: 66770.0/67140.0=0.9945 Instance: 1999; Time: 31.99s; loss: 206.1491; acc: 89900.0/90371.0=0.9948 Epoch: 7 training finished. Time: 125.46s, speed: 15.93st/s, total loss: tensor(1110.2185, device='cuda:0') gold_num = 1026 pred_num = 1027 right_num = 995 Dev: time: 4.52s, speed: 117.89st/s; acc: 0.9918, p: 0.9688, r: 0.9698, f: 0.9693 Exceed previous best f score: 0.9608127721335267 gold_num = 1026 pred_num = 1027 right_num = 995 Test: time: 4.55s, speed: 117.85st/s; acc: 0.9918, p: 0.9688, r: 0.9698, f: 0.9693 Best dev score: p:0.9688412852969815, r:0.969785575048733, f:0.9693132001948369 Test score: p:0.9688412852969815, r:0.969785575048733, f:0.9693132001948369 Epoch: 8/100 Learning rate is setted as: 0.0009951306469335934 Instance: 500; Time: 30.15s; loss: 145.6180; acc: 21728.0/21791.0=0.9971 Instance: 1000; Time: 31.16s; loss: 179.2465; acc: 44238.0/44364.0=0.9972 Instance: 1500; Time: 31.83s; loss: 358.9080; acc: 67124.0/67392.0=0.9960 Instance: 1999; Time: 31.94s; loss: 207.7906; acc: 90002.0/90371.0=0.9959 Epoch: 8 training finished. Time: 125.08s, speed: 15.98st/s, total loss: tensor(891.5626, device='cuda:0') gold_num = 1026 pred_num = 1010 right_num = 991 Dev: time: 4.53s, speed: 117.62st/s; acc: 0.9921, p: 0.9812, r: 0.9659, f: 0.9735 Exceed previous best f score: 0.9693132001948369 gold_num = 1026 pred_num = 1010 right_num = 991 Test: time: 4.56s, speed: 117.50st/s; acc: 0.9921, p: 0.9812, r: 0.9659, f: 0.9735 Best dev score: p:0.9811881188118812, r:0.9658869395711501, f:0.9734774066797642 Test score: p:0.9811881188118812, r:0.9658869395711501, f:0.9734774066797642 Epoch: 9/100 Learning rate is setted as: 0.0009453741145869137 Instance: 500; Time: 31.15s; loss: 138.0381; acc: 22476.0/22555.0=0.9965 Instance: 1000; Time: 32.52s; loss: 178.7251; acc: 45873.0/46036.0=0.9965 Instance: 1500; Time: 31.77s; loss: 158.4235; acc: 68650.0/68897.0=0.9964 Instance: 1999; Time: 29.93s; loss: 303.3596; acc: 89993.0/90371.0=0.9958 Epoch: 9 training finished. Time: 125.36s, speed: 15.95st/s, total loss: tensor(778.5462, device='cuda:0') gold_num = 1026 pred_num = 1074 right_num = 1010 Dev: time: 4.50s, speed: 118.26st/s; acc: 0.9905, p: 0.9404, r: 0.9844, f: 0.9619 gold_num = 1026 pred_num = 1074 right_num = 1010 Test: time: 4.50s, speed: 118.24st/s; acc: 0.9905, p: 0.9404, r: 0.9844, f: 0.9619 Best dev score: p:0.9811881188118812, r:0.9658869395711501, f:0.9734774066797642 Test score: p:0.9811881188118812, r:0.9658869395711501, f:0.9734774066797642 Epoch: 10/100 Learning rate is setted as: 0.000898105408857568 Instance: 500; Time: 30.77s; loss: 185.2131; acc: 22130.0/22219.0=0.9960 Instance: 1000; Time: 31.61s; loss: 170.6009; acc: 44944.0/45115.0=0.9962 Instance: 1500; Time: 30.81s; loss: 338.3507; acc: 66986.0/67311.0=0.9952 Instance: 1999; Time: 31.91s; loss: 98.8729; acc: 90000.0/90371.0=0.9959 Epoch: 10 training finished. Time: 125.10s, speed: 15.98st/s, total loss: tensor(793.0366, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1006 Dev: time: 4.54s, speed: 117.18st/s; acc: 0.9926, p: 0.9673, r: 0.9805, f: 0.9739 Exceed previous best f score: 0.9734774066797642 gold_num = 1026 pred_num = 1040 right_num = 1006 Test: time: 4.58s, speed: 117.11st/s; acc: 0.9926, p: 0.9673, r: 0.9805, f: 0.9739 Best dev score: p:0.9673076923076923, r:0.9805068226120858, f:0.973862536302033 Test score: p:0.9673076923076923, r:0.9805068226120858, f:0.973862536302033 Epoch: 11/100 Learning rate is setted as: 0.0008532001384146896 Instance: 500; Time: 32.79s; loss: 127.8185; acc: 23598.0/23661.0=0.9973 Instance: 1000; Time: 30.19s; loss: 93.6887; acc: 45117.0/45227.0=0.9976 Instance: 1500; Time: 31.18s; loss: 346.0098; acc: 67379.0/67649.0=0.9960 Instance: 1999; Time: 31.40s; loss: 128.3599; acc: 90036.0/90371.0=0.9963 Epoch: 11 training finished. Time: 125.57s, speed: 15.92st/s, total loss: tensor(695.8771, device='cuda:0') gold_num = 1026 pred_num = 1044 right_num = 1006 Dev: time: 4.52s, speed: 117.92st/s; acc: 0.9926, p: 0.9636, r: 0.9805, f: 0.9720 gold_num = 1026 pred_num = 1044 right_num = 1006 Test: time: 4.51s, speed: 117.99st/s; acc: 0.9926, p: 0.9636, r: 0.9805, f: 0.9720 Best dev score: p:0.9673076923076923, r:0.9805068226120858, f:0.973862536302033 Test score: p:0.9673076923076923, r:0.9805068226120858, f:0.973862536302033 Epoch: 12/100 Learning rate is setted as: 0.000810540131493955 Instance: 500; Time: 31.66s; loss: 100.7936; acc: 22946.0/22989.0=0.9981 Instance: 1000; Time: 31.42s; loss: 144.7101; acc: 45592.0/45712.0=0.9974 Instance: 1500; Time: 30.43s; loss: 118.6685; acc: 67384.0/67560.0=0.9974 Instance: 1999; Time: 31.69s; loss: 211.4471; acc: 90094.0/90371.0=0.9969 Epoch: 12 training finished. Time: 125.20s, speed: 15.97st/s, total loss: tensor(575.6193, device='cuda:0') gold_num = 1026 pred_num = 1070 right_num = 1011 Dev: time: 4.52s, speed: 117.76st/s; acc: 0.9895, p: 0.9449, r: 0.9854, f: 0.9647 gold_num = 1026 pred_num = 1070 right_num = 1011 Test: time: 4.52s, speed: 117.67st/s; acc: 0.9895, p: 0.9449, r: 0.9854, f: 0.9647 Best dev score: p:0.9673076923076923, r:0.9805068226120858, f:0.973862536302033 Test score: p:0.9673076923076923, r:0.9805068226120858, f:0.973862536302033 Epoch: 13/100 Learning rate is setted as: 0.0007700131249192573 Instance: 500; Time: 30.08s; loss: 81.7210; acc: 21509.0/21544.0=0.9984 Instance: 1000; Time: 31.09s; loss: 80.9707; acc: 43756.0/43829.0=0.9983 Instance: 1500; Time: 32.41s; loss: 87.4174; acc: 67061.0/67178.0=0.9983 Instance: 1999; Time: 32.24s; loss: 293.8628; acc: 90114.0/90371.0=0.9972 Epoch: 13 training finished. Time: 125.82s, speed: 15.89st/s, total loss: tensor(543.9722, device='cuda:0') gold_num = 1026 pred_num = 1034 right_num = 1010 Dev: time: 4.51s, speed: 118.14st/s; acc: 0.9944, p: 0.9768, r: 0.9844, f: 0.9806 Exceed previous best f score: 0.973862536302033 gold_num = 1026 pred_num = 1034 right_num = 1010 Test: time: 4.55s, speed: 117.89st/s; acc: 0.9944, p: 0.9768, r: 0.9844, f: 0.9806 Best dev score: p:0.97678916827853, r:0.9844054580896686, f:0.9805825242718447 Test score: p:0.97678916827853, r:0.9844054580896686, f:0.9805825242718447 Epoch: 14/100 Learning rate is setted as: 0.0007315124686732943 Instance: 500; Time: 31.85s; loss: 87.1234; acc: 22878.0/22919.0=0.9982 Instance: 1000; Time: 30.23s; loss: 94.5787; acc: 44529.0/44614.0=0.9981 Instance: 1500; Time: 31.13s; loss: 76.8431; acc: 67039.0/67169.0=0.9981 Instance: 1999; Time: 32.10s; loss: 156.5844; acc: 90155.0/90371.0=0.9976 Epoch: 14 training finished. Time: 125.31s, speed: 15.95st/s, total loss: tensor(415.1297, device='cuda:0') gold_num = 1026 pred_num = 1043 right_num = 1014 Dev: time: 4.53s, speed: 117.54st/s; acc: 0.9941, p: 0.9722, r: 0.9883, f: 0.9802 gold_num = 1026 pred_num = 1043 right_num = 1014 Test: time: 4.53s, speed: 117.41st/s; acc: 0.9941, p: 0.9722, r: 0.9883, f: 0.9802 Best dev score: p:0.97678916827853, r:0.9844054580896686, f:0.9805825242718447 Test score: p:0.97678916827853, r:0.9844054580896686, f:0.9805825242718447 Epoch: 15/100 Learning rate is setted as: 0.0006949368452396295 Instance: 500; Time: 31.66s; loss: 244.4252; acc: 22714.0/22827.0=0.9950 Instance: 1000; Time: 31.72s; loss: 93.6701; acc: 45398.0/45558.0=0.9965 Instance: 1500; Time: 31.31s; loss: 81.0918; acc: 67734.0/67935.0=0.9970 Instance: 1999; Time: 31.39s; loss: 74.4658; acc: 90132.0/90371.0=0.9974 Epoch: 15 training finished. Time: 126.09s, speed: 15.85st/s, total loss: tensor(493.6528, device='cuda:0') gold_num = 1026 pred_num = 1029 right_num = 1008 Dev: time: 4.52s, speed: 117.79st/s; acc: 0.9945, p: 0.9796, r: 0.9825, f: 0.9810 Exceed previous best f score: 0.9805825242718447 gold_num = 1026 pred_num = 1029 right_num = 1008 Test: time: 4.56s, speed: 117.55st/s; acc: 0.9945, p: 0.9796, r: 0.9825, f: 0.9810 Best dev score: p:0.9795918367346939, r:0.9824561403508771, f:0.981021897810219 Test score: p:0.9795918367346939, r:0.9824561403508771, f:0.981021897810219 Epoch: 16/100 Learning rate is setted as: 0.000660190002977648 Instance: 500; Time: 31.77s; loss: 61.9987; acc: 22716.0/22752.0=0.9984 Instance: 1000; Time: 31.52s; loss: 116.4953; acc: 45145.0/45245.0=0.9978 Instance: 1500; Time: 30.96s; loss: 189.4300; acc: 67209.0/67403.0=0.9971 Instance: 1999; Time: 31.70s; loss: 78.8190; acc: 90139.0/90371.0=0.9974 Epoch: 16 training finished. Time: 125.94s, speed: 15.87st/s, total loss: tensor(446.7428, device='cuda:0') gold_num = 1026 pred_num = 1025 right_num = 1006 Dev: time: 4.55s, speed: 117.12st/s; acc: 0.9945, p: 0.9815, r: 0.9805, f: 0.9810 gold_num = 1026 pred_num = 1025 right_num = 1006 Test: time: 4.52s, speed: 117.67st/s; acc: 0.9945, p: 0.9815, r: 0.9805, f: 0.9810 Best dev score: p:0.9795918367346939, r:0.9824561403508771, f:0.981021897810219 Test score: p:0.9795918367346939, r:0.9824561403508771, f:0.981021897810219 Epoch: 17/100 Learning rate is setted as: 0.0006271805028287656 Instance: 500; Time: 30.86s; loss: 63.2982; acc: 22168.0/22201.0=0.9985 Instance: 1000; Time: 30.91s; loss: 126.2816; acc: 44340.0/44464.0=0.9972 Instance: 1500; Time: 30.83s; loss: 64.3312; acc: 66554.0/66713.0=0.9976 Instance: 1999; Time: 32.72s; loss: 110.6324; acc: 90159.0/90371.0=0.9977 Epoch: 17 training finished. Time: 125.31s, speed: 15.95st/s, total loss: tensor(364.5435, device='cuda:0') gold_num = 1026 pred_num = 1038 right_num = 1012 Dev: time: 4.60s, speed: 115.66st/s; acc: 0.9943, p: 0.9750, r: 0.9864, f: 0.9806 gold_num = 1026 pred_num = 1038 right_num = 1012 Test: time: 4.59s, speed: 116.02st/s; acc: 0.9943, p: 0.9750, r: 0.9864, f: 0.9806 Best dev score: p:0.9795918367346939, r:0.9824561403508771, f:0.981021897810219 Test score: p:0.9795918367346939, r:0.9824561403508771, f:0.981021897810219 Epoch: 18/100 Learning rate is setted as: 0.0005958214776873273 Instance: 500; Time: 30.93s; loss: 131.2264; acc: 22098.0/22176.0=0.9965 Instance: 1000; Time: 30.89s; loss: 73.0984; acc: 44383.0/44492.0=0.9976 Instance: 1500; Time: 31.22s; loss: 42.7435; acc: 66946.0/67074.0=0.9981 Instance: 1999; Time: 32.11s; loss: 79.4446; acc: 90198.0/90371.0=0.9981 Epoch: 18 training finished. Time: 125.15s, speed: 15.97st/s, total loss: tensor(326.5130, device='cuda:0') gold_num = 1026 pred_num = 1011 right_num = 998 Dev: time: 4.53s, speed: 117.67st/s; acc: 0.9941, p: 0.9871, r: 0.9727, f: 0.9799 gold_num = 1026 pred_num = 1011 right_num = 998 Test: time: 4.53s, speed: 117.62st/s; acc: 0.9941, p: 0.9871, r: 0.9727, f: 0.9799 Best dev score: p:0.9795918367346939, r:0.9824561403508771, f:0.981021897810219 Test score: p:0.9795918367346939, r:0.9824561403508771, f:0.981021897810219 Epoch: 19/100 Learning rate is setted as: 0.0005660304038029609 Instance: 500; Time: 31.59s; loss: 52.7217; acc: 22897.0/22920.0=0.9990 Instance: 1000; Time: 31.10s; loss: 198.4854; acc: 45232.0/45347.0=0.9975 Instance: 1500; Time: 31.76s; loss: 62.1483; acc: 68046.0/68191.0=0.9979 Instance: 1999; Time: 30.82s; loss: 64.5167; acc: 90188.0/90371.0=0.9980 Epoch: 19 training finished. Time: 125.27s, speed: 15.96st/s, total loss: tensor(377.8722, device='cuda:0') gold_num = 1026 pred_num = 1045 right_num = 1016 Dev: time: 4.52s, speed: 117.86st/s; acc: 0.9944, p: 0.9722, r: 0.9903, f: 0.9812 Exceed previous best f score: 0.981021897810219 gold_num = 1026 pred_num = 1045 right_num = 1016 Test: time: 4.55s, speed: 117.94st/s; acc: 0.9944, p: 0.9722, r: 0.9903, f: 0.9812 Best dev score: p:0.9722488038277513, r:0.9902534113060428, f:0.9811685176243361 Test score: p:0.9722488038277513, r:0.9902534113060428, f:0.9811685176243361 Epoch: 20/100 Learning rate is setted as: 0.0005377288836128128 Instance: 500; Time: 31.84s; loss: 95.1913; acc: 23041.0/23102.0=0.9974 Instance: 1000; Time: 29.55s; loss: 47.7070; acc: 44288.0/44371.0=0.9981 Instance: 1500; Time: 32.16s; loss: 65.6617; acc: 67602.0/67718.0=0.9983 Instance: 1999; Time: 31.32s; loss: 72.9049; acc: 90226.0/90371.0=0.9984 Epoch: 20 training finished. Time: 124.86s, speed: 16.01st/s, total loss: tensor(281.4650, device='cuda:0') gold_num = 1026 pred_num = 1023 right_num = 1006 Dev: time: 4.54s, speed: 117.30st/s; acc: 0.9946, p: 0.9834, r: 0.9805, f: 0.9819 Exceed previous best f score: 0.9811685176243361 gold_num = 1026 pred_num = 1023 right_num = 1006 Test: time: 4.57s, speed: 117.33st/s; acc: 0.9946, p: 0.9834, r: 0.9805, f: 0.9819 Best dev score: p:0.9833822091886608, r:0.9805068226120858, f:0.9819424109321621 Test score: p:0.9833822091886608, r:0.9805068226120858, f:0.9819424109321621 ...... ...... ...... ...... ...... ...... Epoch: 90/100 Learning rate is setted as: 1.4832547064488426e-05 Instance: 500; Time: 32.04s; loss: 24.2524; acc: 23116.0/23131.0=0.9994 Instance: 1000; Time: 31.03s; loss: 19.0902; acc: 45323.0/45349.0=0.9994 Instance: 1500; Time: 32.69s; loss: 36.7891; acc: 68823.0/68869.0=0.9993 Instance: 1999; Time: 30.16s; loss: 24.1088; acc: 90307.0/90371.0=0.9993 Epoch: 90 training finished. Time: 125.93s, speed: 15.87st/s, total loss: tensor(104.2405, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1024 Dev: time: 4.57s, speed: 116.48st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 gold_num = 1026 pred_num = 1040 right_num = 1024 Test: time: 4.57s, speed: 116.51st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 Best dev score: p:0.9846153846153847, r:0.9980506822612085, f:0.9912875121006777 Test score: p:0.9846153846153847, r:0.9980506822612085, f:0.9912875121006777 Epoch: 91/100 Learning rate is setted as: 1.4090919711264e-05 Instance: 500; Time: 32.25s; loss: 19.7567; acc: 23080.0/23086.0=0.9997 Instance: 1000; Time: 30.20s; loss: 32.0599; acc: 44758.0/44783.0=0.9994 Instance: 1500; Time: 31.94s; loss: 9.9867; acc: 67778.0/67803.0=0.9996 Instance: 1999; Time: 31.45s; loss: 26.3107; acc: 90328.0/90371.0=0.9995 Epoch: 91 training finished. Time: 125.84s, speed: 15.89st/s, total loss: tensor(88.1140, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1024 Dev: time: 4.60s, speed: 115.75st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 gold_num = 1026 pred_num = 1040 right_num = 1024 Test: time: 4.59s, speed: 115.96st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 Best dev score: p:0.9846153846153847, r:0.9980506822612085, f:0.9912875121006777 Test score: p:0.9846153846153847, r:0.9980506822612085, f:0.9912875121006777 Epoch: 92/100 Learning rate is setted as: 1.3386373725700803e-05 Instance: 500; Time: 32.52s; loss: 38.6252; acc: 23335.0/23361.0=0.9989 Instance: 1000; Time: 32.01s; loss: 18.8413; acc: 46320.0/46358.0=0.9992 Instance: 1500; Time: 30.23s; loss: 10.8565; acc: 67986.0/68026.0=0.9994 Instance: 1999; Time: 31.26s; loss: 24.7076; acc: 90316.0/90371.0=0.9994 Epoch: 92 training finished. Time: 126.02s, speed: 15.86st/s, total loss: tensor(93.0306, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1024 Dev: time: 4.55s, speed: 117.03st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 gold_num = 1026 pred_num = 1040 right_num = 1024 Test: time: 4.55s, speed: 117.09st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 Best dev score: p:0.9846153846153847, r:0.9980506822612085, f:0.9912875121006777 Test score: p:0.9846153846153847, r:0.9980506822612085, f:0.9912875121006777 Epoch: 93/100 Learning rate is setted as: 1.2717055039415761e-05 Instance: 500; Time: 31.41s; loss: 43.6084; acc: 22583.0/22612.0=0.9987 Instance: 1000; Time: 31.97s; loss: 16.5049; acc: 45712.0/45747.0=0.9992 Instance: 1500; Time: 31.36s; loss: 30.4766; acc: 68166.0/68222.0=0.9992 Instance: 1999; Time: 31.01s; loss: 15.8847; acc: 90307.0/90371.0=0.9993 Epoch: 93 training finished. Time: 125.75s, speed: 15.90st/s, total loss: tensor(106.4745, device='cuda:0') gold_num = 1026 pred_num = 1038 right_num = 1024 Dev: time: 4.57s, speed: 116.39st/s; acc: 0.9972, p: 0.9865, r: 0.9981, f: 0.9922 Exceed previous best f score: 0.9912875121006777 gold_num = 1026 pred_num = 1038 right_num = 1024 Test: time: 4.55s, speed: 117.91st/s; acc: 0.9972, p: 0.9865, r: 0.9981, f: 0.9922 Best dev score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Test score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Epoch: 94/100 Learning rate is setted as: 1.2081202287444973e-05 Instance: 500; Time: 31.96s; loss: 33.8862; acc: 23115.0/23138.0=0.9990 Instance: 1000; Time: 30.13s; loss: 7.8426; acc: 44838.0/44862.0=0.9995 Instance: 1500; Time: 30.85s; loss: 54.5449; acc: 67080.0/67141.0=0.9991 Instance: 1999; Time: 32.18s; loss: 17.7653; acc: 90308.0/90371.0=0.9993 Epoch: 94 training finished. Time: 125.12s, speed: 15.98st/s, total loss: tensor(114.0390, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1024 Dev: time: 4.52s, speed: 117.68st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 gold_num = 1026 pred_num = 1040 right_num = 1024 Test: time: 4.53s, speed: 117.63st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 Best dev score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Test score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Epoch: 95/100 Learning rate is setted as: 1.1477142173072723e-05 Instance: 500; Time: 32.72s; loss: 18.1870; acc: 23747.0/23760.0=0.9995 Instance: 1000; Time: 30.51s; loss: 19.2969; acc: 45707.0/45728.0=0.9995 Instance: 1500; Time: 31.00s; loss: 32.6200; acc: 67997.0/68033.0=0.9995 Instance: 1999; Time: 30.85s; loss: 33.8846; acc: 90313.0/90371.0=0.9994 Epoch: 95 training finished. Time: 125.08s, speed: 15.98st/s, total loss: tensor(103.9886, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1024 Dev: time: 4.53s, speed: 117.52st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 gold_num = 1026 pred_num = 1040 right_num = 1024 Test: time: 4.54s, speed: 117.25st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 Best dev score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Test score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Epoch: 96/100 Learning rate is setted as: 1.0903285064419087e-05 Instance: 500; Time: 30.00s; loss: 6.9263; acc: 21548.0/21550.0=0.9999 Instance: 1000; Time: 32.30s; loss: 29.8059; acc: 44736.0/44756.0=0.9996 Instance: 1500; Time: 32.04s; loss: 10.8405; acc: 67736.0/67759.0=0.9997 Instance: 1999; Time: 31.53s; loss: 27.1229; acc: 90340.0/90371.0=0.9997 Epoch: 96 training finished. Time: 125.88s, speed: 15.88st/s, total loss: tensor(74.6956, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1024 Dev: time: 4.52s, speed: 117.91st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 gold_num = 1026 pred_num = 1040 right_num = 1024 Test: time: 4.52s, speed: 117.68st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 Best dev score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Test score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Epoch: 97/100 Learning rate is setted as: 1.0358120811198132e-05 Instance: 500; Time: 30.54s; loss: 17.3246; acc: 22084.0/22091.0=0.9997 Instance: 1000; Time: 30.07s; loss: 28.2827; acc: 43779.0/43806.0=0.9994 Instance: 1500; Time: 32.11s; loss: 20.7174; acc: 67004.0/67037.0=0.9995 Instance: 1999; Time: 32.38s; loss: 24.8686; acc: 90326.0/90371.0=0.9995 Epoch: 97 training finished. Time: 125.10s, speed: 15.98st/s, total loss: tensor(91.1934, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1024 Dev: time: 4.54s, speed: 117.32st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 gold_num = 1026 pred_num = 1040 right_num = 1024 Test: time: 4.53s, speed: 117.44st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 Best dev score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Test score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Epoch: 98/100 Learning rate is setted as: 9.840214770638225e-06 Instance: 500; Time: 31.66s; loss: 16.9288; acc: 22965.0/22976.0=0.9995 Instance: 1000; Time: 32.19s; loss: 15.7932; acc: 46301.0/46319.0=0.9996 Instance: 1500; Time: 30.15s; loss: 13.8526; acc: 68054.0/68078.0=0.9996 Instance: 1999; Time: 30.90s; loss: 34.6453; acc: 90327.0/90371.0=0.9995 Epoch: 98 training finished. Time: 124.90s, speed: 16.01st/s, total loss: tensor(81.2200, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1024 Dev: time: 4.58s, speed: 116.30st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 gold_num = 1026 pred_num = 1040 right_num = 1024 Test: time: 4.58s, speed: 116.27st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 Best dev score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Test score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Epoch: 99/100 Learning rate is setted as: 9.348204032106314e-06 Instance: 500; Time: 32.17s; loss: 39.2616; acc: 23105.0/23122.0=0.9993 Instance: 1000; Time: 32.35s; loss: 13.0373; acc: 46368.0/46387.0=0.9996 Instance: 1500; Time: 30.69s; loss: 20.9561; acc: 68285.0/68309.0=0.9996 Instance: 1999; Time: 30.82s; loss: 17.9313; acc: 90343.0/90371.0=0.9997 Epoch: 99 training finished. Time: 126.03s, speed: 15.86st/s, total loss: tensor(91.1863, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1024 Dev: time: 4.58s, speed: 116.20st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 gold_num = 1026 pred_num = 1040 right_num = 1024 Test: time: 4.59s, speed: 116.02st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 Best dev score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Test score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 \u5c0f\u8282\u603b\u7ed3 \u00b6 \u672c\u5c0f\u8282\u5b66\u4e60\u4e86Soft-lexicon\u6a21\u578b\u7684\u67b6\u6784\u548c\u4ee3\u7801\u5b9e\u73b0.","title":"12.1 Soft-lexicon\u6a21\u578b"},{"location":"12_1.html#soft-lexicon","text":"","title":"Soft-lexicon\u6a21\u578b"},{"location":"12_1.html#_1","text":"\u638c\u63e1Soft-lexicon\u6a21\u578b\u7684\u4ee3\u7801\u5b9e\u73b0.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"12_1.html#soft-lexicon_1","text":"\u6574\u4e2a\u6d41\u7a0b\u7684\u5b9e\u73b0\u6b65\u9aa4\u5982\u4e0b: \u7b2c1\u6b65: \u6784\u5efa\u5de5\u5177\u7c7b\u76f8\u5173\u51fd\u6570 \u7b2c2\u6b65: \u6784\u5efa\u6a21\u578b\u7c7b\u7684\u4ee3\u7801 \u7b2c3\u6b65: \u4e3b\u51fd\u6570\u4ee3\u7801\u7684\u5b9e\u73b0 \u7b2c4\u6b65: \u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u811a\u672c \u7b2c5\u6b65: \u6a21\u578b\u7684\u8bad\u7ec3","title":"Soft-lexicon\u6a21\u578b\u4ee3\u7801\u5b9e\u73b0"},{"location":"12_1.html#1","text":"\u4ee3\u7801\u8def\u5f84: /home/ec2-user/code/ner/soft-lexicon/utils.py 1.1: alphabet.py\u4ee3\u7801\u5b9e\u73b0 import json import os class Alphabet : def __init__ ( self , name , label = False , keep_growing = True ): self . __name = name self . UNKNOWN = \"</unk>\" self . label = label self . instance2index = {} self . instances = [] self . keep_growing = keep_growing # Index 0 is occupied by default, all else following. self . default_index = 0 self . next_index = 1 if not self . label : self . add ( self . UNKNOWN ) def clear ( self , keep_growing = True ): self . instance2index = {} self . instances = [] self . keep_growing = keep_growing # Index 0 is occupied by default, all else following. self . default_index = 0 self . next_index = 1 def add ( self , instance ): if instance not in self . instance2index : self . instances . append ( instance ) self . instance2index [ instance ] = self . next_index self . next_index += 1 def get_index ( self , instance ): try : return self . instance2index [ instance ] except KeyError : if self . keep_growing : index = self . next_index self . add ( instance ) return index else : return self . instance2index [ self . UNKNOWN ] def get_instance ( self , index ): if index == 0 : # First index is occupied by the wildcard element. return None try : return self . instances [ index - 1 ] except IndexError : print ( 'WARNING:Alphabet get_instance ,unknown instance index {} , return the first label.' . format ( index )) return self . instances [ 0 ] def size ( self ): # if self.label: # return len(self.instances) # else: return len ( self . instances ) + 1 def iteritems ( self ): return self . instance2index . items () def enumerate_items ( self , start = 1 ): if start < 1 or start >= self . size (): raise IndexError ( \"Enumerate is allowed between [1 : size of the alphabet)\" ) return zip ( range ( start , len ( self . instances ) + 1 ), self . instances [ start - 1 :]) def close ( self ): self . keep_growing = False def open ( self ): self . keep_growing = True def get_content ( self ): return { 'instance2index' : self . instance2index , 'instances' : self . instances } def from_json ( self , data ): self . instances = data [ \"instances\" ] self . instance2index = data [ \"instance2index\" ] def save ( self , output_directory , name = None ): \"\"\" Save both alhpabet records to the given directory. :param output_directory: Directory to save model and weights. :param name: The alphabet saving name, optional. :return: \"\"\" saving_name = name if name else self . __name try : json . dump ( self . get_content (), open ( os . path . join ( output_directory , saving_name + \".json\" ), 'w' )) except Exception as e : print ( \"Exception: Alphabet is not saved: \" % repr ( e )) def load ( self , input_directory , name = None ): \"\"\" Load model architecture and weights from the give directory. This allow we use old models even the structure changes. :param input_directory: Directory to save model and weights :return: \"\"\" loading_name = name if name else self . __name self . from_json ( json . load ( open ( os . path . join ( input_directory , loading_name + \".json\" )))) 1.2: data.py\u4ee3\u7801\u5b9e\u73b0 from utils.functions import * from utils.gazetteer import Gazetteer START = \"</s>\" UNKNOWN = \"</unk>\" PADDING = \"</pad>\" NULLKEY = \"-null-\" class Data : def __init__ ( self ): self . MAX_SENTENCE_LENGTH = 250 self . MAX_WORD_LENGTH = - 1 self . number_normalized = True self . norm_word_emb = True self . norm_biword_emb = True self . norm_gaz_emb = False self . word_alphabet = Alphabet ( 'word' ) self . biword_alphabet = Alphabet ( 'biword' ) self . char_alphabet = Alphabet ( 'character' ) self . label_alphabet = Alphabet ( 'label' , True ) self . gaz_lower = False self . gaz = Gazetteer ( self . gaz_lower ) self . gaz_alphabet = Alphabet ( 'gaz' ) self . gaz_count = {} self . gaz_split = {} self . biword_count = {} self . HP_fix_gaz_emb = False self . HP_use_gaz = True self . HP_use_count = False self . tagScheme = \"NoSeg\" self . char_features = \"LSTM\" self . train_texts = [] self . dev_texts = [] self . test_texts = [] self . raw_texts = [] self . train_Ids = [] self . dev_Ids = [] self . test_Ids = [] self . raw_Ids = [] self . train_split_index = [] self . dev_split_index = [] self . use_bigram = True self . word_emb_dim = 50 self . biword_emb_dim = 50 self . char_emb_dim = 30 self . gaz_emb_dim = 50 self . gaz_dropout = 0.5 self . pretrain_word_embedding = None self . pretrain_biword_embedding = None self . pretrain_gaz_embedding = None self . label_size = 0 self . word_alphabet_size = 0 self . biword_alphabet_size = 0 self . char_alphabet_size = 0 self . label_alphabet_size = 0 # hyperparameters self . HP_iteration = 100 self . HP_batch_size = 10 self . HP_char_hidden_dim = 50 self . HP_hidden_dim = 128 self . HP_dropout = 0.5 self . HP_lstm_layer = 1 self . HP_bilstm = True self . HP_use_char = False self . HP_gpu = True self . HP_lr = 0.015 self . HP_lr_decay = 0.05 self . HP_clip = 5.0 self . HP_momentum = 0 self . HP_num_layer = 4 def show_data_summary ( self ): print ( \"DATA SUMMARY START:\" ) print ( \" Tag scheme: %s \" % ( self . tagScheme )) print ( \" MAX SENTENCE LENGTH: %s \" % ( self . MAX_SENTENCE_LENGTH )) print ( \" MAX WORD LENGTH: %s \" % ( self . MAX_WORD_LENGTH )) print ( \" Number normalized: %s \" % ( self . number_normalized )) print ( \" Use bigram: %s \" % ( self . use_bigram )) print ( \" Word alphabet size: %s \" % ( self . word_alphabet_size )) print ( \" Biword alphabet size: %s \" % ( self . biword_alphabet_size )) print ( \" Char alphabet size: %s \" % ( self . char_alphabet_size )) print ( \" Gaz alphabet size: %s \" % ( self . gaz_alphabet . size ())) print ( \" Label alphabet size: %s \" % ( self . label_alphabet_size )) print ( \" Word embedding size: %s \" % ( self . word_emb_dim )) print ( \" Biword embedding size: %s \" % ( self . biword_emb_dim )) print ( \" Char embedding size: %s \" % ( self . char_emb_dim )) print ( \" Gaz embedding size: %s \" % ( self . gaz_emb_dim )) print ( \" Norm word emb: %s \" % ( self . norm_word_emb )) print ( \" Norm biword emb: %s \" % ( self . norm_biword_emb )) print ( \" Norm gaz emb: %s \" % ( self . norm_gaz_emb )) print ( \" Norm gaz dropout: %s \" % ( self . gaz_dropout )) print ( \" Train instance number: %s \" % ( len ( self . train_texts ))) print ( \" Dev instance number: %s \" % ( len ( self . dev_texts ))) print ( \" Test instance number: %s \" % ( len ( self . test_texts ))) def refresh_label_alphabet ( self , input_file ): old_size = self . label_alphabet_size self . label_alphabet . clear ( True ) in_lines = open ( input_file , 'r' , encoding = \"utf-8\" ) . readlines () for line in in_lines : if len ( line ) > 2 : pairs = line . strip () . split () label = pairs [ - 1 ] self . label_alphabet . add ( label ) self . label_alphabet_size = self . label_alphabet . size () startS = False startB = False for label , _ in self . label_alphabet . iteritems (): if \"S-\" in label . upper (): startS = True elif \"B-\" in label . upper (): startB = True if startB : if startS : self . tagScheme = \"BMES\" else : self . tagScheme = \"BIO\" self . fix_alphabet () print ( \"Refresh label alphabet finished: old: %s -> new: %s \" % ( old_size , self . label_alphabet_size )) def build_alphabet ( self , input_file ): in_lines = open ( input_file , 'r' , encoding = \"utf-8\" ) . readlines () seqlen = 0 for idx in range ( len ( in_lines )): line = in_lines [ idx ] if len ( line ) > 2 : pairs = line . strip () . split () word = pairs [ 0 ] if self . number_normalized : word = normalize_word ( word ) label = pairs [ - 1 ] self . label_alphabet . add ( label ) self . word_alphabet . add ( word ) if idx < len ( in_lines ) - 1 and len ( in_lines [ idx + 1 ]) > 2 : biword = word + in_lines [ idx + 1 ] . strip () . split ()[ 0 ] else : biword = word + NULLKEY self . biword_alphabet . add ( biword ) # biword_index = self.biword_alphabet.get_index(biword) self . biword_count [ biword ] = self . biword_count . get ( biword , 0 ) + 1 for char in word : self . char_alphabet . add ( char ) seqlen += 1 else : seqlen = 0 self . word_alphabet_size = self . word_alphabet . size () self . biword_alphabet_size = self . biword_alphabet . size () self . char_alphabet_size = self . char_alphabet . size () self . label_alphabet_size = self . label_alphabet . size () startS = False startB = False for label , _ in self . label_alphabet . iteritems (): if \"S-\" in label . upper (): startS = True elif \"B-\" in label . upper (): startB = True if startB : if startS : self . tagScheme = \"BMES\" else : self . tagScheme = \"BIO\" def build_gaz_file ( self , gaz_file ): # build gaz file,initial read gaz embedding file if gaz_file : fins = open ( gaz_file , 'r' , encoding = \"utf-8\" ) . readlines () for fin in fins : fin = fin . strip () . split ()[ 0 ] if fin : self . gaz . insert ( fin , \"one_source\" ) print ( \"Load gaz file: \" , gaz_file , \" total size:\" , self . gaz . size ()) else : print ( \"Gaz file is None, load nothing\" ) def write_decoded_results ( self , output_file , predict_results , name ): fout = open ( output_file , 'w' ) sent_num = len ( predict_results ) content_list = [] if name == 'raw' : content_list = self . raw_texts elif name == 'test' : content_list = self . test_texts elif name == 'dev' : content_list = self . dev_texts elif name == 'train' : content_list = self . train_texts else : print ( \"Error: illegal name during writing predict result, name should be within train/dev/test/raw !\" ) assert ( sent_num == len ( content_list )) for idx in range ( sent_num ): sent_length = len ( predict_results [ idx ]) for idy in range ( sent_length ): # content_list[idx] is a list with [word, char, label] fout . write ( content_list [ idx ][ 0 ][ idy ] . encode ( 'utf-8' ) + \" \" + predict_results [ idx ][ idy ] + ' \\n ' ) fout . write ( ' \\n ' ) fout . close () print ( \"Predict %s result has been written into file. %s \" % ( name , output_file )) 1.3: functions.py\u4ee3\u7801\u5b9e\u73b0 import sys import numpy as np import re from utils.alphabet import Alphabet from transformers.tokenization_bert import BertTokenizer NULLKEY = \"-null-\" def normalize_word ( word ): new_word = \"\" for char in word : if char . isdigit (): new_word += '0' else : new_word += char return new_word def read_instance_with_gaz ( num_layer , input_file , gaz , word_alphabet , biword_alphabet , biword_count , char_alphabet , gaz_alphabet , gaz_count , gaz_split , label_alphabet , number_normalized , max_sent_length , char_padding_size =- 1 , char_padding_symbol = '</pad>' ): tokenizer = BertTokenizer . from_pretrained ( 'bert-base-chinese' , do_lower_case = True ) in_lines = open ( input_file , 'r' , encoding = \"utf-8\" ) . readlines () instence_texts = [] instence_Ids = [] words = [] biwords = [] chars = [] labels = [] word_Ids = [] biword_Ids = [] char_Ids = [] label_Ids = [] for idx in range ( len ( in_lines )): line = in_lines [ idx ] if len ( line ) > 2 : pairs = line . strip () . split () word = pairs [ 0 ] if number_normalized : word = normalize_word ( word ) label = pairs [ - 1 ] if idx < len ( in_lines ) - 1 and len ( in_lines [ idx + 1 ]) > 2 : biword = word + in_lines [ idx + 1 ] . strip () . split ()[ 0 ] else : biword = word + NULLKEY biwords . append ( biword ) words . append ( word ) labels . append ( label ) word_Ids . append ( word_alphabet . get_index ( word )) biword_index = biword_alphabet . get_index ( biword ) biword_Ids . append ( biword_index ) label_Ids . append ( label_alphabet . get_index ( label )) char_list = [] char_Id = [] for char in word : char_list . append ( char ) if char_padding_size > 0 : char_number = len ( char_list ) if char_number < char_padding_size : char_list = char_list + [ char_padding_symbol ] * ( char_padding_size - char_number ) assert ( len ( char_list ) == char_padding_size ) else : # not padding pass for char in char_list : char_Id . append ( char_alphabet . get_index ( char )) chars . append ( char_list ) char_Ids . append ( char_Id ) else : if (( max_sent_length < 0 ) or ( len ( words ) < max_sent_length )) and ( len ( words ) > 0 ): gaz_Ids = [] layergazmasks = [] gazchar_masks = [] w_length = len ( words ) gazs = [[[] for i in range ( 4 )] for _ in range ( w_length )] # gazs:[c1,c2,...,cn] ci:[B,M,E,S] B/M/E/S :[w_id1,w_id2,...] None:0 gazs_count = [[[] for _ in range ( 4 )] for _ in range ( w_length )] gaz_char_Id = [[[] for _ in range ( 4 )] for _ in range ( w_length )] # gazs:[c1,c2,...,cn] ci:[B,M,E,S] B/M/E/S :[[w1c1,w1c2,...],[],...] max_gazlist = 0 max_gazcharlen = 0 for idx in range ( w_length ): matched_list = gaz . enumerateMatchList ( words [ idx :]) matched_length = [ len ( a ) for a in matched_list ] matched_Id = [ gaz_alphabet . get_index ( entity ) for entity in matched_list ] if matched_length : max_gazcharlen = max ( max ( matched_length ), max_gazcharlen ) for w in range ( len ( matched_Id )): gaz_chars = [] g = matched_list [ w ] for c in g : gaz_chars . append ( word_alphabet . get_index ( c )) if matched_length [ w ] == 1 : # Single gazs [ idx ][ 3 ] . append ( matched_Id [ w ]) gazs_count [ idx ][ 3 ] . append ( 1 ) gaz_char_Id [ idx ][ 3 ] . append ( gaz_chars ) else : gazs [ idx ][ 0 ] . append ( matched_Id [ w ]) # Begin gazs_count [ idx ][ 0 ] . append ( gaz_count [ matched_Id [ w ]]) gaz_char_Id [ idx ][ 0 ] . append ( gaz_chars ) wlen = matched_length [ w ] gazs [ idx + wlen - 1 ][ 2 ] . append ( matched_Id [ w ]) # End gazs_count [ idx + wlen - 1 ][ 2 ] . append ( gaz_count [ matched_Id [ w ]]) gaz_char_Id [ idx + wlen - 1 ][ 2 ] . append ( gaz_chars ) for l in range ( wlen - 2 ): gazs [ idx + l + 1 ][ 1 ] . append ( matched_Id [ w ]) # Middle gazs_count [ idx + l + 1 ][ 1 ] . append ( gaz_count [ matched_Id [ w ]]) gaz_char_Id [ idx + l + 1 ][ 1 ] . append ( gaz_chars ) for label in range ( 4 ): if not gazs [ idx ][ label ]: gazs [ idx ][ label ] . append ( 0 ) gazs_count [ idx ][ label ] . append ( 1 ) gaz_char_Id [ idx ][ label ] . append ([ 0 ]) max_gazlist = max ( len ( gazs [ idx ][ label ]), max_gazlist ) matched_Id = [ gaz_alphabet . get_index ( entity ) for entity in matched_list ] # \u8bcd\u53f7 if matched_Id : gaz_Ids . append ([ matched_Id , matched_length ]) else : gaz_Ids . append ([]) # batch_size = 1 for idx in range ( w_length ): gazmask = [] gazcharmask = [] for label in range ( 4 ): label_len = len ( gazs [ idx ][ label ]) count_set = set ( gazs_count [ idx ][ label ]) if len ( count_set ) == 1 and 0 in count_set : gazs_count [ idx ][ label ] = [ 1 ] * label_len mask = label_len * [ 0 ] mask += ( max_gazlist - label_len ) * [ 1 ] gazs [ idx ][ label ] += ( max_gazlist - label_len ) * [ 0 ] # padding gazs_count [ idx ][ label ] += ( max_gazlist - label_len ) * [ 0 ] # padding char_mask = [] for g in range ( len ( gaz_char_Id [ idx ][ label ])): glen = len ( gaz_char_Id [ idx ][ label ][ g ]) charmask = glen * [ 0 ] charmask += ( max_gazcharlen - glen ) * [ 1 ] char_mask . append ( charmask ) gaz_char_Id [ idx ][ label ][ g ] += ( max_gazcharlen - glen ) * [ 0 ] gaz_char_Id [ idx ][ label ] += ( max_gazlist - label_len ) * [[ 0 for i in range ( max_gazcharlen )]] char_mask += ( max_gazlist - label_len ) * [[ 1 for i in range ( max_gazcharlen )]] gazmask . append ( mask ) gazcharmask . append ( char_mask ) layergazmasks . append ( gazmask ) gazchar_masks . append ( gazcharmask ) texts = [ '[CLS]' ] + words + [ '[SEP]' ] bert_text_ids = tokenizer . convert_tokens_to_ids ( texts ) instence_texts . append ([ words , biwords , chars , gazs , labels ]) instence_Ids . append ( [ word_Ids , biword_Ids , char_Ids , gaz_Ids , label_Ids , gazs , gazs_count , gaz_char_Id , layergazmasks , gazchar_masks , bert_text_ids ]) words = [] biwords = [] chars = [] labels = [] word_Ids = [] biword_Ids = [] char_Ids = [] label_Ids = [] return instence_texts , instence_Ids 1.4: gazetteer.py\u4ee3\u7801\u5b9e\u73b0 from utils.trie import Trie class Gazetteer : def __init__ ( self , lower ): self . trie = Trie () self . ent2type = {} ## word list to type self . ent2id = { \"<UNK>\" : 0 } ## word list to id self . lower = lower self . space = \"\" def enumerateMatchList ( self , word_list ): if self . lower : word_list = [ word . lower () for word in word_list ] match_list = self . trie . enumerateMatch ( word_list , self . space ) return match_list def insert ( self , word_list , source ): if self . lower : word_list = [ word . lower () for word in word_list ] self . trie . insert ( word_list ) string = self . space . join ( word_list ) if string not in self . ent2type : self . ent2type [ string ] = source if string not in self . ent2id : self . ent2id [ string ] = len ( self . ent2id ) def searchId ( self , word_list ): if self . lower : word_list = [ word . lower () for word in word_list ] string = self . space . join ( word_list ) if string in self . ent2id : return self . ent2id [ string ] return self . ent2id [ \"<UNK>\" ] def searchType ( self , word_list ): if self . lower : word_list = [ word . lower () for word in word_list ] string = self . space . join ( word_list ) if string in self . ent2type : return self . ent2type [ string ] print ( \"Error in finding entity type at gazetteer.py, exit program! String:\" , string ) exit ( 0 ) def size ( self ): return len ( self . ent2type ) 1.5: metric.py\u4ee3\u7801\u5b9e\u73b0 import sys # input as sentence level labels def get_ner_fmeasure ( golden_lists , predict_lists , label_type = \"BMES\" , printnum = True ): sent_num = len ( golden_lists ) golden_full = [] predict_full = [] right_full = [] right_tag = 0 all_tag = 0 for idx in range ( 0 , sent_num ): # word_list = sentence_lists[idx] golden_list = golden_lists [ idx ] predict_list = predict_lists [ idx ] for idy in range ( len ( golden_list )): if golden_list [ idy ] == predict_list [ idy ]: right_tag += 1 all_tag += len ( golden_list ) if label_type == \"BMES\" : gold_matrix = get_ner_BMES ( golden_list ) pred_matrix = get_ner_BMES ( predict_list ) else : gold_matrix = get_ner_BIO ( golden_list ) pred_matrix = get_ner_BIO ( predict_list ) # print \"gold\", gold_matrix # print \"pred\", pred_matrix right_ner = list ( set ( gold_matrix ) . intersection ( set ( pred_matrix ))) golden_full += gold_matrix predict_full += pred_matrix right_full += right_ner right_num = len ( right_full ) golden_num = len ( golden_full ) predict_num = len ( predict_full ) if predict_num == 0 : precision = - 1 else : precision = ( right_num + 0.0 ) / predict_num if golden_num == 0 : recall = - 1 else : recall = ( right_num + 0.0 ) / golden_num if ( precision == - 1 ) or ( recall == - 1 ) or ( precision + recall ) <= 0. : f_measure = - 1 else : f_measure = 2 * precision * recall / ( precision + recall ) accuracy = ( right_tag + 0.0 ) / all_tag # print \"Accuracy: \", right_tag,\"/\",all_tag,\"=\",accuracy if printnum : print ( \"gold_num = \" , golden_num , \" pred_num = \" , predict_num , \" right_num = \" , right_num ) return accuracy , precision , recall , f_measure def reverse_style ( input_string ): target_position = input_string . index ( '[' ) input_len = len ( input_string ) output_string = input_string [ target_position : input_len ] + input_string [ 0 : target_position ] return output_string def get_ner_BMES ( label_list ): # list_len = len(word_list) # assert(list_len == len(label_list)), \"word list size unmatch with label list\" list_len = len ( label_list ) begin_label = 'B-' end_label = 'E-' single_label = 'S-' whole_tag = '' index_tag = '' tag_list = [] stand_matrix = [] for i in range ( 0 , list_len ): # wordlabel = word_list[i] current_label = label_list [ i ] . upper () if label_list [ i ] else [] if begin_label in current_label : if index_tag != '' : tag_list . append ( whole_tag + ',' + str ( i - 1 )) whole_tag = current_label . replace ( begin_label , \"\" , 1 ) + '[' + str ( i ) index_tag = current_label . replace ( begin_label , \"\" , 1 ) elif single_label in current_label : if index_tag != '' : tag_list . append ( whole_tag + ',' + str ( i - 1 )) whole_tag = current_label . replace ( single_label , \"\" , 1 ) + '[' + str ( i ) tag_list . append ( whole_tag ) whole_tag = \"\" index_tag = \"\" elif end_label in current_label : if index_tag != '' : tag_list . append ( whole_tag + ',' + str ( i )) whole_tag = '' index_tag = '' else : continue if whole_tag != '' and index_tag != '' : tag_list . append ( whole_tag ) tag_list_len = len ( tag_list ) for i in range ( 0 , tag_list_len ): if len ( tag_list [ i ]) > 0 : tag_list [ i ] = tag_list [ i ] + ']' insert_list = reverse_style ( tag_list [ i ]) stand_matrix . append ( insert_list ) # print stand_matrix return stand_matrix def get_ner_BIO ( label_list ): # list_len = len(word_list) # assert(list_len == len(label_list)), \"word list size unmatch with label list\" list_len = len ( label_list ) begin_label = 'B-' inside_label = 'I-' whole_tag = '' index_tag = '' tag_list = [] stand_matrix = [] for i in range ( 0 , list_len ): # wordlabel = word_list[i] current_label = label_list [ i ] . upper () if begin_label in current_label : if index_tag == '' : whole_tag = current_label . replace ( begin_label , \"\" , 1 ) + '[' + str ( i ) index_tag = current_label . replace ( begin_label , \"\" , 1 ) else : tag_list . append ( whole_tag + ',' + str ( i - 1 )) whole_tag = current_label . replace ( begin_label , \"\" , 1 ) + '[' + str ( i ) index_tag = current_label . replace ( begin_label , \"\" , 1 ) elif inside_label in current_label : if current_label . replace ( inside_label , \"\" , 1 ) == index_tag : whole_tag = whole_tag else : if ( whole_tag != '' ) & ( index_tag != '' ): tag_list . append ( whole_tag + ',' + str ( i - 1 )) whole_tag = '' index_tag = '' else : if ( whole_tag != '' ) & ( index_tag != '' ): tag_list . append ( whole_tag + ',' + str ( i - 1 )) whole_tag = '' index_tag = '' if ( whole_tag != '' ) & ( index_tag != '' ): tag_list . append ( whole_tag ) tag_list_len = len ( tag_list ) for i in range ( 0 , tag_list_len ): if len ( tag_list [ i ]) > 0 : tag_list [ i ] = tag_list [ i ] + ']' insert_list = reverse_style ( tag_list [ i ]) stand_matrix . append ( insert_list ) return stand_matrix def readSentence ( input_file ): in_lines = open ( input_file , 'r' ) . readlines () sentences = [] labels = [] sentence = [] label = [] for line in in_lines : if len ( line ) < 2 : sentences . append ( sentence ) labels . append ( label ) sentence = [] label = [] else : pair = line . strip ( ' \\n ' ) . split ( ' ' ) sentence . append ( pair [ 0 ]) label . append ( pair [ - 1 ]) return sentences , labels","title":"\u7b2c1\u6b65: \u6784\u5efa\u5de5\u5177\u7c7b\u76f8\u5173\u51fd\u6570"},{"location":"12_1.html#2","text":"\u4ee3\u7801\u8def\u5f84: /home/ec2-user/code/ner/soft-lexicon/model/gazlstm.py import torch import numpy as np import torch.nn as nn from model.crf import CRF from model.layers import NERmodel from transformers.modeling_bert import BertModel class GazLSTM ( nn . Module ): def __init__ ( self , data ): super ( GazLSTM , self ) . __init__ () self . gpu = data . HP_gpu self . use_biword = data . use_bigram self . hidden_dim = data . HP_hidden_dim self . gaz_alphabet = data . gaz_alphabet self . gaz_emb_dim = data . gaz_emb_dim self . word_emb_dim = data . word_emb_dim self . biword_emb_dim = data . biword_emb_dim self . use_char = data . HP_use_char self . bilstm_flag = data . HP_bilstm self . lstm_layer = data . HP_lstm_layer self . use_count = data . HP_use_count self . num_layer = data . HP_num_layer self . model_type = data . model_type self . use_bert = data . use_bert scale = np . sqrt ( 3.0 / self . gaz_emb_dim ) data . pretrain_gaz_embedding [ 0 , :] = np . random . uniform ( - scale , scale , [ 1 , self . gaz_emb_dim ]) if self . use_char : scale = np . sqrt ( 3.0 / self . word_emb_dim ) data . pretrain_word_embedding [ 0 , :] = np . random . uniform ( - scale , scale , [ 1 , self . word_emb_dim ]) self . gaz_embedding = nn . Embedding ( data . gaz_alphabet . size (), self . gaz_emb_dim ) self . word_embedding = nn . Embedding ( data . word_alphabet . size (), self . word_emb_dim ) if self . use_biword : self . biword_embedding = nn . Embedding ( data . biword_alphabet . size (), self . biword_emb_dim ) if data . pretrain_gaz_embedding is not None : self . gaz_embedding . weight . data . copy_ ( torch . from_numpy ( data . pretrain_gaz_embedding )) else : self . gaz_embedding . weight . data . copy_ ( torch . from_numpy ( self . random_embedding ( data . gaz_alphabet . size (), self . gaz_emb_dim ))) if data . pretrain_word_embedding is not None : self . word_embedding . weight . data . copy_ ( torch . from_numpy ( data . pretrain_word_embedding )) else : self . word_embedding . weight . data . copy_ ( torch . from_numpy ( self . random_embedding ( data . word_alphabet . size (), self . word_emb_dim ))) if self . use_biword : if data . pretrain_biword_embedding is not None : self . biword_embedding . weight . data . copy_ ( torch . from_numpy ( data . pretrain_biword_embedding )) else : self . biword_embedding . weight . data . copy_ ( torch . from_numpy ( self . random_embedding ( data . biword_alphabet . size (), self . word_emb_dim ))) char_feature_dim = self . word_emb_dim + 4 * self . gaz_emb_dim if self . use_biword : char_feature_dim += self . biword_emb_dim if self . use_bert : char_feature_dim = char_feature_dim + 768 # lstm model if self . model_type == 'lstm' : lstm_hidden = self . hidden_dim if self . bilstm_flag : self . hidden_dim *= 2 self . NERmodel = NERmodel ( model_type = 'lstm' , input_dim = char_feature_dim , hidden_dim = lstm_hidden , num_layer = self . lstm_layer , biflag = self . bilstm_flag ) # cnn model if self . model_type == 'cnn' : self . NERmodel = NERmodel ( model_type = 'cnn' , input_dim = char_feature_dim , hidden_dim = self . hidden_dim , num_layer = self . num_layer , dropout = data . HP_dropout , gpu = self . gpu ) # attention model if self . model_type == 'transformer' : self . NERmodel = NERmodel ( model_type = 'transformer' , input_dim = char_feature_dim , hidden_dim = self . hidden_dim , num_layer = self . num_layer , dropout = data . HP_dropout ) self . drop = nn . Dropout ( p = data . HP_dropout ) self . hidden2tag = nn . Linear ( self . hidden_dim , data . label_alphabet_size + 2 ) self . crf = CRF ( data . label_alphabet_size , self . gpu ) if self . use_bert : self . bert_encoder = BertModel . from_pretrained ( 'bert-base-chinese' ) for p in self . bert_encoder . parameters (): p . requires_grad = False if self . gpu : self . gaz_embedding = self . gaz_embedding . cuda () self . word_embedding = self . word_embedding . cuda () if self . use_biword : self . biword_embedding = self . biword_embedding . cuda () self . NERmodel = self . NERmodel . cuda () self . hidden2tag = self . hidden2tag . cuda () self . crf = self . crf . cuda () if self . use_bert : self . bert_encoder = self . bert_encoder . cuda () def get_tags ( self , gaz_list , word_inputs , biword_inputs , layer_gaz , gaz_count , gaz_chars , gaz_mask_input , gazchar_mask_input , mask , word_seq_lengths , batch_bert , bert_mask ): batch_size = word_inputs . size ()[ 0 ] seq_len = word_inputs . size ()[ 1 ] max_gaz_num = layer_gaz . size ( - 1 ) gaz_match = [] word_embs = self . word_embedding ( word_inputs ) if self . use_biword : biword_embs = self . biword_embedding ( biword_inputs ) word_embs = torch . cat ([ word_embs , biword_embs ], dim =- 1 ) if self . model_type != 'transformer' : word_inputs_d = self . drop ( word_embs ) # (b,l,we) else : word_inputs_d = word_embs if self . use_char : gazchar_embeds = self . word_embedding ( gaz_chars ) gazchar_mask = gazchar_mask_input . unsqueeze ( - 1 ) . repeat ( 1 , 1 , 1 , 1 , 1 , self . word_emb_dim ) gazchar_embeds = gazchar_embeds . data . masked_fill_ ( gazchar_mask . data . bool (), 0 ) # (b,l,4,gl,cl,ce) # gazchar_mask_input:(b,l,4,gl,cl) gaz_charnum = ( gazchar_mask_input == 0 ) . sum ( dim =- 1 , keepdim = True ) . float () # (b,l,4,gl,1) gaz_charnum = gaz_charnum + ( gaz_charnum == 0 ) . float () gaz_embeds = gazchar_embeds . sum ( - 2 ) / gaz_charnum # (b,l,4,gl,ce) if self . model_type != 'transformer' : gaz_embeds = self . drop ( gaz_embeds ) else : gaz_embeds = gaz_embeds else : # use gaz embedding gaz_embeds = self . gaz_embedding ( layer_gaz ) if self . model_type != 'transformer' : gaz_embeds_d = self . drop ( gaz_embeds ) else : gaz_embeds_d = gaz_embeds gaz_mask = gaz_mask_input . unsqueeze ( - 1 ) . repeat ( 1 , 1 , 1 , 1 , self . gaz_emb_dim ) gaz_embeds = gaz_embeds_d . data . masked_fill_ ( gaz_mask . data . bool (), 0 ) # (b,l,4,g,ge) ge:gaz_embed_dim if self . use_count : count_sum = torch . sum ( gaz_count , dim = 3 , keepdim = True ) # (b,l,4,gn) count_sum = torch . sum ( count_sum , dim = 2 , keepdim = True ) # (b,l,1,1) weights = gaz_count . div ( count_sum ) # (b,l,4,g) weights = weights * 4 weights = weights . unsqueeze ( - 1 ) gaz_embeds = weights * gaz_embeds # (b,l,4,g,e) gaz_embeds = torch . sum ( gaz_embeds , dim = 3 ) # (b,l,4,e) else : gaz_num = ( gaz_mask_input == 0 ) . sum ( dim =- 1 , keepdim = True ) . float () # (b,l,4,1) gaz_embeds = gaz_embeds . sum ( - 2 ) / gaz_num # (b,l,4,ge)/(b,l,4,1) gaz_embeds_cat = gaz_embeds . view ( batch_size , seq_len , - 1 ) # (b,l,4*ge) word_input_cat = torch . cat ([ word_inputs_d , gaz_embeds_cat ], dim =- 1 ) # (b,l,we+4*ge) # cat bert feature if self . use_bert : seg_id = torch . zeros ( bert_mask . size ()) . long () . cuda () outputs = self . bert_encoder ( batch_bert , bert_mask , seg_id ) outputs = outputs [ 0 ][:, 1 : - 1 , :] word_input_cat = torch . cat ([ word_input_cat , outputs ], dim =- 1 ) feature_out_d = self . NERmodel ( word_input_cat ) tags = self . hidden2tag ( feature_out_d ) return tags , gaz_match def neg_log_likelihood_loss ( self , gaz_list , word_inputs , biword_inputs , word_seq_lengths , layer_gaz , gaz_count , gaz_chars , gaz_mask , gazchar_mask , mask , batch_label , batch_bert , bert_mask ): tags , _ = self . get_tags ( gaz_list , word_inputs , biword_inputs , layer_gaz , gaz_count , gaz_chars , gaz_mask , gazchar_mask , mask , word_seq_lengths , batch_bert , bert_mask ) total_loss = self . crf . neg_log_likelihood_loss ( tags , mask , batch_label ) scores , tag_seq = self . crf . _viterbi_decode ( tags , mask ) return total_loss , tag_seq def forward ( self , gaz_list , word_inputs , biword_inputs , word_seq_lengths , layer_gaz , gaz_count , gaz_chars , gaz_mask , gazchar_mask , mask , batch_bert , bert_mask ): tags , gaz_match = self . get_tags ( gaz_list , word_inputs , biword_inputs , layer_gaz , gaz_count , gaz_chars , gaz_mask , gazchar_mask , mask , word_seq_lengths , batch_bert , bert_mask ) scores , tag_seq = self . crf . _viterbi_decode ( tags , mask ) return tag_seq , gaz_match \u4ee3\u7801\u8def\u5f84: /models/zhudejun/paper/information_extraction/ner/soft-lexicon/model/layers.py import torch import math , copy import torch.autograd as autograd import torch.nn as nn import torch.nn.functional as F class CNNmodel ( nn . Module ): def __init__ ( self , input_dim , hidden_dim , num_layer , dropout , gpu = True ): super ( CNNmodel , self ) . __init__ () self . input_dim = input_dim self . hidden_dim = hidden_dim self . num_layer = num_layer self . gpu = gpu self . cnn_layer0 = nn . Conv1d ( self . input_dim , self . hidden_dim , kernel_size = 1 , padding = 0 ) self . cnn_layers = [ nn . Conv1d ( self . hidden_dim , self . hidden_dim , kernel_size = 3 , padding = 1 ) for i in range ( self . num_layer - 1 )] self . drop = nn . Dropout ( dropout ) if self . gpu : self . cnn_layer0 = self . cnn_layer0 . cuda () for i in range ( self . num_layer - 1 ): self . cnn_layers [ i ] = self . cnn_layers [ i ] . cuda () def forward ( self , input_feature ): input_feature = input_feature . transpose ( 2 , 1 ) . contiguous () cnn_output = self . cnn_layer0 ( input_feature ) # (b,h,l) cnn_output = self . drop ( cnn_output ) cnn_output = torch . tanh ( cnn_output ) for layer in range ( self . num_layer - 1 ): cnn_output = self . cnn_layers [ layer ]( cnn_output ) cnn_output = self . drop ( cnn_output ) cnn_output = torch . tanh ( cnn_output ) cnn_output = cnn_output . transpose ( 2 , 1 ) . contiguous () return cnn_output def clones ( module , N ): \"Produce N identical layers.\" return nn . ModuleList ([ copy . deepcopy ( module ) for _ in range ( N )]) class LayerNorm ( nn . Module ): \"Construct a layernorm module (See citation for details).\" def __init__ ( self , features , eps = 1e-6 ): super ( LayerNorm , self ) . __init__ () self . a_2 = nn . Parameter ( torch . ones ( features )) self . b_2 = nn . Parameter ( torch . zeros ( features )) self . eps = eps def forward ( self , x ): mean = x . mean ( - 1 , keepdim = True ) std = x . std ( - 1 , keepdim = True ) return self . a_2 * ( x - mean ) / ( std + self . eps ) + self . b_2 class SublayerConnection ( nn . Module ): \"\"\" A residual connection followed by a layer norm. Note for code simplicity the norm is first as opposed to last. \"\"\" def __init__ ( self , size , dropout ): super ( SublayerConnection , self ) . __init__ () self . norm = LayerNorm ( size ) self . dropout = nn . Dropout ( dropout ) def forward ( self , x , sublayer ): \"Apply residual connection to any sublayer with the same size.\" return x + self . dropout ( sublayer ( self . norm ( x ))) class EncoderLayer ( nn . Module ): \"Encoder is made up of self-attn and feed forward (defined below)\" def __init__ ( self , size , self_attn , feed_forward , dropout ): super ( EncoderLayer , self ) . __init__ () self . self_attn = self_attn self . feed_forward = feed_forward self . sublayer = clones ( SublayerConnection ( size , dropout ), 2 ) self . size = size def forward ( self , x , mask ): \"Follow Figure 1 (left) for connections.\" x = self . sublayer [ 0 ]( x , lambda x : self . self_attn ( x , x , x , mask . bool ())) return self . sublayer [ 1 ]( x , self . feed_forward ) def attention ( query , key , value , mask = None , dropout = None ): \"Compute 'Scaled Dot Product Attention'\" d_k = query . size ( - 1 ) scores = torch . matmul ( query , key . transpose ( - 2 , - 1 )) / math . sqrt ( d_k ) # (b,h,l,d) * (b,h,d,l) if mask is not None : scores = scores . masked_fill ( mask . bool (), - 1e9 ) p_attn = F . softmax ( scores , dim =- 1 ) if dropout is not None : p_attn = dropout ( p_attn ) return torch . matmul ( p_attn , value ), p_attn # (b,h,l,l) * (b,h,l,d) = (b,h,l,d) class MultiHeadedAttention ( nn . Module ): def __init__ ( self , h , d_model , dropout = 0.1 ): \"Take in model size and number of heads.\" super ( MultiHeadedAttention , self ) . __init__ () assert d_model % h == 0 # We assume d_v always equals d_k self . d_k = d_model // h self . h = h self . linears = clones ( nn . Linear ( d_model , d_model ), 4 ) self . attn = None self . dropout = nn . Dropout ( p = dropout ) def forward ( self , query , key , value , mask = None ): \"Implements Figure 2\" if mask is not None : # Same mask applied to all h heads. mask = mask . unsqueeze ( 1 ) . bool () nbatches = query . size ( 0 ) # 1) Do all the linear projections in batch from d_model => h x d_k query , key , value = \\ [ l ( x ) . view ( nbatches , - 1 , self . h , self . d_k ) . transpose ( 1 , 2 ) for l , x in zip ( self . linears , ( query , key , value ))] # 2) Apply attention on all the projected vectors in batch. x , self . attn = attention ( query , key , value , mask = mask , dropout = self . dropout ) # 3) \"Concat\" using a view and apply a final linear. x = x . transpose ( 1 , 2 ) . contiguous () . view ( nbatches , - 1 , self . h * self . d_k ) return self . linears [ - 1 ]( x ) class PositionwiseFeedForward ( nn . Module ): \"Implements FFN equation.\" def __init__ ( self , d_model , d_ff , dropout = 0.1 ): super ( PositionwiseFeedForward , self ) . __init__ () self . w_1 = nn . Linear ( d_model , d_ff ) self . w_2 = nn . Linear ( d_ff , d_model ) self . dropout = nn . Dropout ( dropout ) def forward ( self , x ): return self . w_2 ( self . dropout ( F . relu ( self . w_1 ( x )))) class PositionalEncoding ( nn . Module ): \"Implement the PE function.\" def __init__ ( self , d_model , dropout , max_len = 5000 ): super ( PositionalEncoding , self ) . __init__ () self . dropout = nn . Dropout ( p = dropout ) # Compute the positional encodings once in log space. pe = torch . zeros ( max_len , d_model ) position = torch . arange ( 0. , max_len ) . unsqueeze ( 1 ) div_term = torch . exp ( torch . arange ( 0. , d_model , 2 ) * - ( math . log ( 10000.0 ) / d_model )) pe [:, 0 :: 2 ] = torch . sin ( position * div_term ) pe [:, 1 :: 2 ] = torch . cos ( position * div_term ) pe = pe . unsqueeze ( 0 ) self . register_buffer ( 'pe' , pe ) def forward ( self , x ): x = x + autograd . Variable ( self . pe [:, : x . size ( 1 )], requires_grad = False ) return self . dropout ( x ) class AttentionModel ( nn . Module ): \"Core encoder is a stack of N layers\" def __init__ ( self , d_input , d_model , d_ff , head , num_layer , dropout ): super ( AttentionModel , self ) . __init__ () c = copy . deepcopy # attn0 = MultiHeadedAttention(head, d_input, d_model) attn = MultiHeadedAttention ( head , d_model , dropout ) ff = PositionwiseFeedForward ( d_model , d_ff , dropout ) # position = PositionalEncoding(d_model, dropout) # layer0 = EncoderLayer(d_model, c(attn0), c(ff), dropout) layer = EncoderLayer ( d_model , c ( attn ), c ( ff ), dropout ) self . layers = clones ( layer , num_layer ) # layerlist = [copy.deepcopy(layer0),] # for _ in range(num_layer-1): # layerlist.append(copy.deepcopy(layer)) # self.layers = nn.ModuleList(layerlist) self . norm = LayerNorm ( layer . size ) self . posi = PositionalEncoding ( d_model , dropout ) self . input2model = nn . Linear ( d_input , d_model ) def forward ( self , x , mask ): \"Pass the input (and mask) through each layer in turn.\" # x: embedding (b,l,we) x = self . posi ( self . input2model ( x )) for layer in self . layers : x = layer ( x , mask . bool ()) return self . norm ( x ) class NERmodel ( nn . Module ): def __init__ ( self , model_type , input_dim , hidden_dim , num_layer , dropout = 0.5 , gpu = True , biflag = True ): super ( NERmodel , self ) . __init__ () self . model_type = model_type if self . model_type == 'cnn' : self . cnn = CNNmodel ( input_dim , hidden_dim , num_layer , dropout , gpu ) # attention model elif self . model_type == 'transformer' : self . attention_model = AttentionModel ( d_input = input_dim , d_model = hidden_dim , d_ff = 2 * hidden_dim , head = 4 , num_layer = num_layer , dropout = dropout ) for p in self . attention_model . parameters (): if p . dim () > 1 : nn . init . xavier_uniform_ ( p ) else : assert self . model_type == 'lstm' self . lstm = nn . LSTM ( input_dim , hidden_dim , num_layers = num_layer , batch_first = True , bidirectional = biflag ) self . drop = nn . Dropout ( dropout ) def forward ( self , input , mask = None ): if self . model_type == 'cnn' : feature_out_d = self . cnn ( input ) elif self . model_type == 'transformer' : feature_out_d = self . attention_model ( input , mask ) else : assert self . model_type == 'lstm' hidden = None feature_out , hidden = self . lstm ( input , hidden ) feature_out_d = self . drop ( feature_out ) return feature_out_d","title":"\u7b2c2\u6b65: \u6784\u5efa\u6a21\u578b\u7c7b\u7684\u4ee3\u7801"},{"location":"12_1.html#3","text":"\u4ee3\u7801\u8def\u5f84: /home/ec2-user/code/ner/soft-lexicon/main.py def predict_check ( pred_variable , gold_variable , mask_variable ): \"\"\" input: pred_variable (batch_size, sent_len): pred tag result, in numpy format gold_variable (batch_size, sent_len): gold result variable mask_variable (batch_size, sent_len): mask variable \"\"\" pred = pred_variable . cpu () . data . numpy () gold = gold_variable . cpu () . data . numpy () mask = mask_variable . cpu () . data . numpy () overlaped = ( pred == gold ) right_token = np . sum ( overlaped * mask ) total_token = mask . sum () return right_token , total_token def recover_label ( pred_variable , gold_variable , mask_variable , label_alphabet ): \"\"\" input: pred_variable (batch_size, sent_len): pred tag result gold_variable (batch_size, sent_len): gold result variable mask_variable (batch_size, sent_len): mask variable \"\"\" batch_size = gold_variable . size ( 0 ) seq_len = gold_variable . size ( 1 ) mask = mask_variable . cpu () . data . numpy () pred_tag = pred_variable . cpu () . data . numpy () gold_tag = gold_variable . cpu () . data . numpy () batch_size = mask . shape [ 0 ] pred_label = [] gold_label = [] for idx in range ( batch_size ): pred = [ label_alphabet . get_instance ( int ( pred_tag [ idx ][ idy ])) for idy in range ( seq_len ) if mask [ idx ][ idy ] != 0 ] gold = [ label_alphabet . get_instance ( gold_tag [ idx ][ idy ]) for idy in range ( seq_len ) if mask [ idx ][ idy ] != 0 ] assert ( len ( pred ) == len ( gold )) pred_label . append ( pred ) gold_label . append ( gold ) return pred_label , gold_label def print_batchword ( data , batch_word , n ): with open ( \"labels/batchwords.txt\" , \"a\" ) as fp : for i in range ( len ( batch_word )): words = [] for id in batch_word [ i ]: words . append ( data . word_alphabet . get_instance ( id )) fp . write ( str ( words )) def save_data_setting ( data , save_file ): new_data = copy . deepcopy ( data ) # remove input instances new_data . train_texts = [] new_data . dev_texts = [] new_data . test_texts = [] new_data . raw_texts = [] new_data . train_Ids = [] new_data . dev_Ids = [] new_data . test_Ids = [] new_data . raw_Ids = [] # save data settings with open ( save_file , 'wb' ) as fp : pickle . dump ( new_data , fp ) print ( \"Data setting saved to file: \" , save_file ) def load_data_setting ( save_file ): with open ( save_file , 'rb' ) as fp : data = pickle . load ( fp ) print ( \"Data setting loaded from file: \" , save_file ) data . show_data_summary () return data def lr_decay ( optimizer , epoch , decay_rate , init_lr ): lr = init_lr * (( 1 - decay_rate ) ** epoch ) print ( \" Learning rate is setted as:\" , lr ) for param_group in optimizer . param_groups : param_group [ 'lr' ] = lr return optimizer def set_seed ( seed_num = 1023 ): random . seed ( seed_num ) torch . manual_seed ( seed_num ) np . random . seed ( seed_num ) def evaluate ( data , model , name ): if name == \"train\" : instances = data . train_Ids elif name == \"dev\" : instances = data . dev_Ids elif name == 'test' : instances = data . test_Ids elif name == 'raw' : instances = data . raw_Ids else : print ( \"Error: wrong evaluate name,\" , name ) pred_results = [] gold_results = [] # set model in eval model model . eval () batch_size = 1 start_time = time . time () train_num = len ( instances ) total_batch = train_num // batch_size + 1 gazes = [] for batch_id in range ( total_batch ): with torch . no_grad (): start = batch_id * batch_size end = ( batch_id + 1 ) * batch_size if end > train_num : end = train_num instance = instances [ start : end ] if not instance : continue gaz_list , batch_word , batch_biword , batch_wordlen , batch_label , layer_gaz , gaz_count , gaz_chars , gaz_mask , gazchar_mask , mask , batch_bert , bert_mask = batchify_with_label ( instance , data . HP_gpu , data . HP_num_layer , True ) tag_seq , gaz_match = model ( gaz_list , batch_word , batch_biword , batch_wordlen , layer_gaz , gaz_count , gaz_chars , gaz_mask , gazchar_mask , mask , batch_bert , bert_mask ) gaz_list = [ data . gaz_alphabet . get_instance ( id ) for batchlist in gaz_match if len ( batchlist ) > 0 for id in batchlist ] gazes . append ( gaz_list ) if name == \"dev\" : pred_label , gold_label = recover_label ( tag_seq , batch_label , mask , data . label_alphabet ) else : pred_label , gold_label = recover_label ( tag_seq , batch_label , mask , data . label_alphabet ) pred_results += pred_label gold_results += gold_label decode_time = time . time () - start_time speed = len ( instances ) / decode_time acc , p , r , f = get_ner_fmeasure ( gold_results , pred_results , data . tagScheme ) return speed , acc , p , r , f , pred_results , gazes def get_text_input ( self , caption ): caption_tokens = self . tokenizer . tokenize ( caption ) caption_tokens = [ '[CLS]' ] + caption_tokens + [ '[SEP]' ] caption_ids = self . tokenizer . convert_tokens_to_ids ( caption_tokens ) if len ( caption_ids ) >= self . max_seq_len : caption_ids = caption_ids [: self . max_seq_len ] else : caption_ids = caption_ids + [ 0 ] * ( self . max_seq_len - len ( caption_ids )) caption = torch . tensor ( caption_ids ) return caption def batchify_with_label ( input_batch_list , gpu , num_layer , volatile_flag = False ): batch_size = len ( input_batch_list ) words = [ sent [ 0 ] for sent in input_batch_list ] biwords = [ sent [ 1 ] for sent in input_batch_list ] gazs = [ sent [ 3 ] for sent in input_batch_list ] labels = [ sent [ 4 ] for sent in input_batch_list ] layer_gazs = [ sent [ 5 ] for sent in input_batch_list ] gaz_count = [ sent [ 6 ] for sent in input_batch_list ] gaz_chars = [ sent [ 7 ] for sent in input_batch_list ] gaz_mask = [ sent [ 8 ] for sent in input_batch_list ] gazchar_mask = [ sent [ 9 ] for sent in input_batch_list ] # bert tokens bert_ids = [ sent [ 10 ] for sent in input_batch_list ] word_seq_lengths = torch . LongTensor ( list ( map ( len , words ))) max_seq_len = word_seq_lengths . max () word_seq_tensor = autograd . Variable ( torch . zeros (( batch_size , max_seq_len ))) . long () biword_seq_tensor = autograd . Variable ( torch . zeros (( batch_size , max_seq_len ))) . long () label_seq_tensor = autograd . Variable ( torch . zeros (( batch_size , max_seq_len ))) . long () mask = autograd . Variable ( torch . zeros (( batch_size , max_seq_len ))) . byte () # bert seq tensor bert_seq_tensor = autograd . Variable ( torch . zeros (( batch_size , max_seq_len + 2 ))) . long () bert_mask = autograd . Variable ( torch . zeros (( batch_size , max_seq_len + 2 ))) . long () gaz_num = [ len ( layer_gazs [ i ][ 0 ][ 0 ]) for i in range ( batch_size )] max_gaz_num = max ( gaz_num ) layer_gaz_tensor = torch . zeros ( batch_size , max_seq_len , 4 , max_gaz_num ) . long () gaz_count_tensor = torch . zeros ( batch_size , max_seq_len , 4 , max_gaz_num ) . float () gaz_len = [ len ( gaz_chars [ i ][ 0 ][ 0 ][ 0 ]) for i in range ( batch_size )] max_gaz_len = max ( gaz_len ) gaz_chars_tensor = torch . zeros ( batch_size , max_seq_len , 4 , max_gaz_num , max_gaz_len ) . long () gaz_mask_tensor = torch . ones ( batch_size , max_seq_len , 4 , max_gaz_num ) . byte () gazchar_mask_tensor = torch . ones ( batch_size , max_seq_len , 4 , max_gaz_num , max_gaz_len ) . byte () for b , ( seq , bert_id , biseq , label , seqlen , layergaz , gazmask , gazcount , gazchar , gazchar_mask , gaznum , gazlen ) in enumerate ( zip ( words , bert_ids , biwords , labels , word_seq_lengths , layer_gazs , gaz_mask , gaz_count , gaz_chars , gazchar_mask , gaz_num , gaz_len )): word_seq_tensor [ b , : seqlen ] = torch . LongTensor ( seq ) biword_seq_tensor [ b , : seqlen ] = torch . LongTensor ( biseq ) label_seq_tensor [ b , : seqlen ] = torch . LongTensor ( label ) layer_gaz_tensor [ b , : seqlen , :, : gaznum ] = torch . LongTensor ( layergaz ) mask [ b , : seqlen ] = torch . Tensor ([ 1 ] * int ( seqlen )) bert_mask [ b , : seqlen + 2 ] = torch . LongTensor ([ 1 ] * int ( seqlen + 2 )) gaz_mask_tensor [ b , : seqlen , :, : gaznum ] = torch . ByteTensor ( gazmask ) gaz_count_tensor [ b , : seqlen , :, : gaznum ] = torch . FloatTensor ( gazcount ) gaz_count_tensor [ b , seqlen :] = 1 gaz_chars_tensor [ b , : seqlen , :, : gaznum , : gazlen ] = torch . LongTensor ( gazchar ) gazchar_mask_tensor [ b , : seqlen , :, : gaznum , : gazlen ] = torch . ByteTensor ( gazchar_mask ) # bert bert_seq_tensor [ b , : seqlen + 2 ] = torch . LongTensor ( bert_id ) if gpu : word_seq_tensor = word_seq_tensor . cuda () biword_seq_tensor = biword_seq_tensor . cuda () word_seq_lengths = word_seq_lengths . cuda () label_seq_tensor = label_seq_tensor . cuda () layer_gaz_tensor = layer_gaz_tensor . cuda () gaz_chars_tensor = gaz_chars_tensor . cuda () gaz_mask_tensor = gaz_mask_tensor . cuda () gazchar_mask_tensor = gazchar_mask_tensor . cuda () gaz_count_tensor = gaz_count_tensor . cuda () mask = mask . cuda () bert_seq_tensor = bert_seq_tensor . cuda () bert_mask = bert_mask . cuda () # print(bert_seq_tensor.type()) return gazs , word_seq_tensor , biword_seq_tensor , word_seq_lengths , label_seq_tensor , layer_gaz_tensor , gaz_count_tensor , gaz_chars_tensor , gaz_mask_tensor , gazchar_mask_tensor , mask , bert_seq_tensor , bert_mask def train ( data , save_model_dir , seg = True ): print ( \"Training with {} model.\" . format ( data . model_type )) # data.show_data_summary() model = SeqModel ( data ) print ( \"finish building model.\" ) parameters = filter ( lambda p : p . requires_grad , model . parameters ()) optimizer = optim . Adamax ( parameters , lr = data . HP_lr ) best_dev = - 1 best_dev_p = - 1 best_dev_r = - 1 best_test = - 1 best_test_p = - 1 best_test_r = - 1 # start training for idx in range ( data . HP_iteration ): epoch_start = time . time () temp_start = epoch_start print (( \"Epoch: %s / %s \" % ( idx , data . HP_iteration ))) optimizer = lr_decay ( optimizer , idx , data . HP_lr_decay , data . HP_lr ) instance_count = 0 sample_loss = 0 batch_loss = 0 total_loss = 0 right_token = 0 whole_token = 0 random . shuffle ( data . train_Ids ) # set model in train model model . train () model . zero_grad () batch_size = data . HP_batch_size batch_id = 0 train_num = len ( data . train_Ids ) total_batch = train_num // batch_size + 1 for batch_id in range ( total_batch ): start = batch_id * batch_size end = ( batch_id + 1 ) * batch_size if end > train_num : end = train_num instance = data . train_Ids [ start : end ] words = data . train_texts [ start : end ] if not instance : continue gaz_list , batch_word , batch_biword , batch_wordlen , batch_label , layer_gaz , gaz_count , gaz_chars , gaz_mask , gazchar_mask , mask , batch_bert , bert_mask = batchify_with_label ( instance , data . HP_gpu , data . HP_num_layer ) instance_count += 1 loss , tag_seq = model . neg_log_likelihood_loss ( gaz_list , batch_word , batch_biword , batch_wordlen , layer_gaz , gaz_count , gaz_chars , gaz_mask , gazchar_mask , mask , batch_label , batch_bert , bert_mask ) right , whole = predict_check ( tag_seq , batch_label , mask ) right_token += right whole_token += whole sample_loss += loss . data total_loss += loss . data batch_loss += loss if end % 500 == 0 : temp_time = time . time () temp_cost = temp_time - temp_start temp_start = temp_time print (( \" Instance: %s ; Time: %.2f s; loss: %.4f ; acc: %s / %s = %.4f \" % ( end , temp_cost , sample_loss , right_token , whole_token , ( right_token + 0. ) / whole_token ))) sys . stdout . flush () sample_loss = 0 if end % data . HP_batch_size == 0 : batch_loss . backward () optimizer . step () model . zero_grad () batch_loss = 0 temp_time = time . time () temp_cost = temp_time - temp_start print (( \" Instance: %s ; Time: %.2f s; loss: %.4f ; acc: %s / %s = %.4f \" % ( end , temp_cost , sample_loss , right_token , whole_token , ( right_token + 0. ) / whole_token ))) epoch_finish = time . time () epoch_cost = epoch_finish - epoch_start print (( \"Epoch: %s training finished. Time: %.2f s, speed: %.2f st/s, total loss: %s \" % ( idx , epoch_cost , train_num / epoch_cost , total_loss ))) speed , acc , p , r , f , pred_labels , gazs = evaluate ( data , model , \"dev\" ) dev_finish = time . time () dev_cost = dev_finish - epoch_finish if seg : current_score = f print (( \"Dev: time: %.2f s, speed: %.2f st/s; acc: %.4f , p: %.4f , r: %.4f , f: %.4f \" % ( dev_cost , speed , acc , p , r , f ))) else : current_score = acc print (( \"Dev: time: %.2f s speed: %.2f st/s; acc: %.4f \" % ( dev_cost , speed , acc ))) if current_score > best_dev : if seg : print ( \"Exceed previous best f score:\" , best_dev ) else : print ( \"Exceed previous best acc score:\" , best_dev ) model_name = save_model_dir torch . save ( model . state_dict (), model_name ) # best_dev = current_score best_dev_p = p best_dev_r = r # ## decode test speed , acc , p , r , f , pred_labels , gazs = evaluate ( data , model , \"test\" ) test_finish = time . time () test_cost = test_finish - dev_finish if seg : current_test_score = f print (( \"Test: time: %.2f s, speed: %.2f st/s; acc: %.4f , p: %.4f , r: %.4f , f: %.4f \" % ( test_cost , speed , acc , p , r , f ))) else : current_test_score = acc print (( \"Test: time: %.2f s, speed: %.2f st/s; acc: %.4f \" % ( test_cost , speed , acc ))) if current_score > best_dev : best_dev = current_score best_test = current_test_score best_test_p = p best_test_r = r print ( \"Best dev score: p: {} , r: {} , f: {} \" . format ( best_dev_p , best_dev_r , best_dev )) print ( \"Test score: p: {} , r: {} , f: {} \" . format ( best_test_p , best_test_r , best_test )) gc . collect () with open ( data . result_file , \"a\" ) as f : f . write ( save_model_dir + ' \\n ' ) f . write ( \"Best dev score: p: {} , r: {} , f: {} \\n \" . format ( best_dev_p , best_dev_r , best_dev )) f . write ( \"Test score: p: {} , r: {} , f: {} \\n\\n \" . format ( best_test_p , best_test_r , best_test )) f . close () def load_model_decode ( model_dir , data , name , gpu , seg = True ): data . HP_gpu = gpu print ( \"Load Model from file: \" , model_dir ) model = SeqModel ( data ) model . load_state_dict ( torch . load ( model_dir )) print (( \"Decode %s data ...\" % ( name ))) start_time = time . time () speed , acc , p , r , f , pred_results , gazs = evaluate ( data , model , name ) end_time = time . time () time_cost = end_time - start_time if seg : print (( \" %s : time: %.2f s, speed: %.2f st/s; acc: %.4f , p: %.4f , r: %.4f , f: %.4f \" % ( name , time_cost , speed , acc , p , r , f ))) else : print (( \" %s : time: %.2f s, speed: %.2f st/s; acc: %.4f \" % ( name , time_cost , speed , acc ))) return pred_results def print_results ( pred , modelname = \"\" ): toprint = [] for sen in pred : sen = \" \" . join ( sen ) + ' \\n ' toprint . append ( sen ) with open ( modelname + '_labels.txt' , 'w' ) as f : f . writelines ( toprint )","title":"\u7b2c3\u6b65: \u4e3b\u51fd\u6570\u4ee3\u7801\u7684\u5b9e\u73b0"},{"location":"12_1.html#4","text":"\u8bad\u7ec3\u811a\u672c: /home/ec2-user/code/ner/soft-lexicon/train.sh python main . py -- train data / ResumeNER / train . char . bmes -- dev data / ResumeNER / dev . char . bmes -- test data / ResumeNER / test . char . bmes -- modelname ResumeNER -- savedset data / data . dset \u6d4b\u8bd5\u811a\u672c: /home/ec2-user/code/ner/soft-lexicon/test.sh python main . py -- test data / ResumeNER / test . char . bmes -- modelname ResumeNER -- savedset data / data . dset","title":"\u7b2c4\u6b65: \u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u811a\u672c"},{"location":"12_1.html#5","text":"\u8c03\u7528: sh train.sh \u8f93\u51fa\u7ed3\u679c: Loading processed train data data.use_biword= False Training with lstm model. build batched crf... finish building model. Epoch: 0/100 Learning rate is setted as: 0.0015 Instance: 500; Time: 32.52s; loss: 6444.8052; acc: 21720.0/23426.0=0.9272 Instance: 1000; Time: 30.42s; loss: 3167.6731; acc: 42567.0/45188.0=0.9420 Instance: 1500; Time: 30.38s; loss: 2078.1272; acc: 63642.0/66928.0=0.9509 Instance: 1999; Time: 32.58s; loss: 1800.6085; acc: 86516.0/90371.0=0.9573 Epoch: 0 training finished. Time: 125.90s, speed: 15.88st/s, total loss: tensor(13491.2178, device='cuda:0') gold_num = 1026 pred_num = 1044 right_num = 860 Dev: time: 4.59s, speed: 115.96st/s; acc: 0.9660, p: 0.8238, r: 0.8382, f: 0.8309 Exceed previous best f score: -1 gold_num = 1026 pred_num = 1044 right_num = 860 Test: time: 4.58s, speed: 117.17st/s; acc: 0.9660, p: 0.8238, r: 0.8382, f: 0.8309 Best dev score: p:0.8237547892720306, r:0.8382066276803118, f:0.8309178743961353 Test score: p:0.8237547892720306, r:0.8382066276803118, f:0.8309178743961353 Epoch: 1/100 Learning rate is setted as: 0.001425 Instance: 500; Time: 30.69s; loss: 1172.0479; acc: 21708.0/22138.0=0.9806 Instance: 1000; Time: 30.97s; loss: 1389.0051; acc: 43721.0/44522.0=0.9820 Instance: 1500; Time: 31.34s; loss: 1115.4781; acc: 66035.0/67218.0=0.9824 Instance: 1999; Time: 32.04s; loss: 991.1306; acc: 88852.0/90371.0=0.9832 Epoch: 1 training finished. Time: 125.04s, speed: 15.99st/s, total loss: tensor(4667.6572, device='cuda:0') gold_num = 1026 pred_num = 1059 right_num = 922 Dev: time: 4.55s, speed: 116.99st/s; acc: 0.9761, p: 0.8706, r: 0.8986, f: 0.8844 Exceed previous best f score: 0.8309178743961353 gold_num = 1026 pred_num = 1059 right_num = 922 Test: time: 4.59s, speed: 116.86st/s; acc: 0.9761, p: 0.8706, r: 0.8986, f: 0.8844 Best dev score: p:0.8706326723323891, r:0.898635477582846, f:0.8844124700239807 Test score: p:0.8706326723323891, r:0.898635477582846, f:0.8844124700239807 Epoch: 2/100 Learning rate is setted as: 0.00135375 Instance: 500; Time: 30.50s; loss: 1005.5997; acc: 21713.0/21989.0=0.9874 Instance: 1000; Time: 32.26s; loss: 812.4775; acc: 44653.0/45218.0=0.9875 Instance: 1500; Time: 30.83s; loss: 613.4433; acc: 66666.0/67473.0=0.9880 Instance: 1999; Time: 31.60s; loss: 657.8646; acc: 89294.0/90371.0=0.9881 Epoch: 2 training finished. Time: 125.19s, speed: 15.97st/s, total loss: tensor(3089.3857, device='cuda:0') gold_num = 1026 pred_num = 944 right_num = 916 Dev: time: 4.54s, speed: 117.28st/s; acc: 0.9832, p: 0.9703, r: 0.8928, f: 0.9299 Exceed previous best f score: 0.8844124700239807 gold_num = 1026 pred_num = 944 right_num = 916 Test: time: 4.57s, speed: 117.25st/s; acc: 0.9832, p: 0.9703, r: 0.8928, f: 0.9299 Best dev score: p:0.9703389830508474, r:0.8927875243664717, f:0.9299492385786802 Test score: p:0.9703389830508474, r:0.8927875243664717, f:0.9299492385786802 Epoch: 3/100 Learning rate is setted as: 0.0012860624999999999 Instance: 500; Time: 31.68s; loss: 403.6226; acc: 22831.0/22985.0=0.9933 Instance: 1000; Time: 30.65s; loss: 794.4869; acc: 44707.0/45127.0=0.9907 Instance: 1500; Time: 30.32s; loss: 544.4160; acc: 66367.0/67016.0=0.9903 Instance: 1999; Time: 32.27s; loss: 545.2573; acc: 89498.0/90371.0=0.9903 Epoch: 3 training finished. Time: 124.93s, speed: 16.00st/s, total loss: tensor(2287.7854, device='cuda:0') gold_num = 1026 pred_num = 1086 right_num = 983 Dev: time: 4.56s, speed: 116.88st/s; acc: 0.9847, p: 0.9052, r: 0.9581, f: 0.9309 Exceed previous best f score: 0.9299492385786802 gold_num = 1026 pred_num = 1086 right_num = 983 Test: time: 4.58s, speed: 117.16st/s; acc: 0.9847, p: 0.9052, r: 0.9581, f: 0.9309 Best dev score: p:0.9051565377532228, r:0.9580896686159844, f:0.9308712121212122 Test score: p:0.9051565377532228, r:0.9580896686159844, f:0.9308712121212122 Epoch: 4/100 Learning rate is setted as: 0.0012217593749999998 Instance: 500; Time: 31.63s; loss: 430.0888; acc: 22695.0/22871.0=0.9923 Instance: 1000; Time: 30.07s; loss: 396.8073; acc: 44065.0/44404.0=0.9924 Instance: 1500; Time: 31.81s; loss: 561.2547; acc: 66870.0/67412.0=0.9920 Instance: 1999; Time: 31.80s; loss: 382.0838; acc: 89671.0/90371.0=0.9923 Epoch: 4 training finished. Time: 125.31s, speed: 15.95st/s, total loss: tensor(1770.2340, device='cuda:0') gold_num = 1026 pred_num = 1035 right_num = 976 Dev: time: 4.53s, speed: 117.55st/s; acc: 0.9872, p: 0.9430, r: 0.9513, f: 0.9471 Exceed previous best f score: 0.9308712121212122 gold_num = 1026 pred_num = 1035 right_num = 976 Test: time: 4.55s, speed: 117.74st/s; acc: 0.9872, p: 0.9430, r: 0.9513, f: 0.9471 Best dev score: p:0.9429951690821256, r:0.9512670565302144, f:0.9471130519165454 Test score: p:0.9429951690821256, r:0.9512670565302144, f:0.9471130519165454 Epoch: 5/100 Learning rate is setted as: 0.0011606714062499996 Instance: 500; Time: 31.05s; loss: 476.5773; acc: 22253.0/22429.0=0.9922 Instance: 1000; Time: 31.19s; loss: 347.2917; acc: 44649.0/44970.0=0.9929 Instance: 1500; Time: 31.67s; loss: 251.4872; acc: 67279.0/67724.0=0.9934 Instance: 1999; Time: 31.51s; loss: 402.8557; acc: 89768.0/90371.0=0.9933 Epoch: 5 training finished. Time: 125.42s, speed: 15.94st/s, total loss: tensor(1478.2144, device='cuda:0') gold_num = 1026 pred_num = 1093 right_num = 1006 Dev: time: 4.52s, speed: 117.85st/s; acc: 0.9883, p: 0.9204, r: 0.9805, f: 0.9495 Exceed previous best f score: 0.9471130519165454 gold_num = 1026 pred_num = 1093 right_num = 1006 Test: time: 4.55s, speed: 117.84st/s; acc: 0.9883, p: 0.9204, r: 0.9805, f: 0.9495 Best dev score: p:0.9204025617566332, r:0.9805068226120858, f:0.9495044832468145 Test score: p:0.9204025617566332, r:0.9805068226120858, f:0.9495044832468145 Epoch: 6/100 Learning rate is setted as: 0.0011026378359374996 Instance: 500; Time: 30.73s; loss: 262.0597; acc: 22079.0/22186.0=0.9952 Instance: 1000; Time: 32.20s; loss: 478.9395; acc: 45099.0/45386.0=0.9937 Instance: 1500; Time: 32.35s; loss: 300.3384; acc: 68196.0/68619.0=0.9938 Instance: 1999; Time: 30.45s; loss: 234.9602; acc: 89839.0/90371.0=0.9941 Epoch: 6 training finished. Time: 125.73s, speed: 15.90st/s, total loss: tensor(1276.2983, device='cuda:0') gold_num = 1026 pred_num = 1041 right_num = 993 Dev: time: 4.51s, speed: 117.94st/s; acc: 0.9901, p: 0.9539, r: 0.9678, f: 0.9608 Exceed previous best f score: 0.9495044832468145 gold_num = 1026 pred_num = 1041 right_num = 993 Test: time: 4.54s, speed: 118.11st/s; acc: 0.9901, p: 0.9539, r: 0.9678, f: 0.9608 Best dev score: p:0.9538904899135446, r:0.9678362573099415, f:0.9608127721335267 Test score: p:0.9538904899135446, r:0.9678362573099415, f:0.9608127721335267 Epoch: 7/100 Learning rate is setted as: 0.0010475059441406246 Instance: 500; Time: 32.10s; loss: 325.9810; acc: 23012.0/23160.0=0.9936 Instance: 1000; Time: 31.01s; loss: 345.6270; acc: 45099.0/45378.0=0.9939 Instance: 1500; Time: 30.36s; loss: 232.4619; acc: 66770.0/67140.0=0.9945 Instance: 1999; Time: 31.99s; loss: 206.1491; acc: 89900.0/90371.0=0.9948 Epoch: 7 training finished. Time: 125.46s, speed: 15.93st/s, total loss: tensor(1110.2185, device='cuda:0') gold_num = 1026 pred_num = 1027 right_num = 995 Dev: time: 4.52s, speed: 117.89st/s; acc: 0.9918, p: 0.9688, r: 0.9698, f: 0.9693 Exceed previous best f score: 0.9608127721335267 gold_num = 1026 pred_num = 1027 right_num = 995 Test: time: 4.55s, speed: 117.85st/s; acc: 0.9918, p: 0.9688, r: 0.9698, f: 0.9693 Best dev score: p:0.9688412852969815, r:0.969785575048733, f:0.9693132001948369 Test score: p:0.9688412852969815, r:0.969785575048733, f:0.9693132001948369 Epoch: 8/100 Learning rate is setted as: 0.0009951306469335934 Instance: 500; Time: 30.15s; loss: 145.6180; acc: 21728.0/21791.0=0.9971 Instance: 1000; Time: 31.16s; loss: 179.2465; acc: 44238.0/44364.0=0.9972 Instance: 1500; Time: 31.83s; loss: 358.9080; acc: 67124.0/67392.0=0.9960 Instance: 1999; Time: 31.94s; loss: 207.7906; acc: 90002.0/90371.0=0.9959 Epoch: 8 training finished. Time: 125.08s, speed: 15.98st/s, total loss: tensor(891.5626, device='cuda:0') gold_num = 1026 pred_num = 1010 right_num = 991 Dev: time: 4.53s, speed: 117.62st/s; acc: 0.9921, p: 0.9812, r: 0.9659, f: 0.9735 Exceed previous best f score: 0.9693132001948369 gold_num = 1026 pred_num = 1010 right_num = 991 Test: time: 4.56s, speed: 117.50st/s; acc: 0.9921, p: 0.9812, r: 0.9659, f: 0.9735 Best dev score: p:0.9811881188118812, r:0.9658869395711501, f:0.9734774066797642 Test score: p:0.9811881188118812, r:0.9658869395711501, f:0.9734774066797642 Epoch: 9/100 Learning rate is setted as: 0.0009453741145869137 Instance: 500; Time: 31.15s; loss: 138.0381; acc: 22476.0/22555.0=0.9965 Instance: 1000; Time: 32.52s; loss: 178.7251; acc: 45873.0/46036.0=0.9965 Instance: 1500; Time: 31.77s; loss: 158.4235; acc: 68650.0/68897.0=0.9964 Instance: 1999; Time: 29.93s; loss: 303.3596; acc: 89993.0/90371.0=0.9958 Epoch: 9 training finished. Time: 125.36s, speed: 15.95st/s, total loss: tensor(778.5462, device='cuda:0') gold_num = 1026 pred_num = 1074 right_num = 1010 Dev: time: 4.50s, speed: 118.26st/s; acc: 0.9905, p: 0.9404, r: 0.9844, f: 0.9619 gold_num = 1026 pred_num = 1074 right_num = 1010 Test: time: 4.50s, speed: 118.24st/s; acc: 0.9905, p: 0.9404, r: 0.9844, f: 0.9619 Best dev score: p:0.9811881188118812, r:0.9658869395711501, f:0.9734774066797642 Test score: p:0.9811881188118812, r:0.9658869395711501, f:0.9734774066797642 Epoch: 10/100 Learning rate is setted as: 0.000898105408857568 Instance: 500; Time: 30.77s; loss: 185.2131; acc: 22130.0/22219.0=0.9960 Instance: 1000; Time: 31.61s; loss: 170.6009; acc: 44944.0/45115.0=0.9962 Instance: 1500; Time: 30.81s; loss: 338.3507; acc: 66986.0/67311.0=0.9952 Instance: 1999; Time: 31.91s; loss: 98.8729; acc: 90000.0/90371.0=0.9959 Epoch: 10 training finished. Time: 125.10s, speed: 15.98st/s, total loss: tensor(793.0366, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1006 Dev: time: 4.54s, speed: 117.18st/s; acc: 0.9926, p: 0.9673, r: 0.9805, f: 0.9739 Exceed previous best f score: 0.9734774066797642 gold_num = 1026 pred_num = 1040 right_num = 1006 Test: time: 4.58s, speed: 117.11st/s; acc: 0.9926, p: 0.9673, r: 0.9805, f: 0.9739 Best dev score: p:0.9673076923076923, r:0.9805068226120858, f:0.973862536302033 Test score: p:0.9673076923076923, r:0.9805068226120858, f:0.973862536302033 Epoch: 11/100 Learning rate is setted as: 0.0008532001384146896 Instance: 500; Time: 32.79s; loss: 127.8185; acc: 23598.0/23661.0=0.9973 Instance: 1000; Time: 30.19s; loss: 93.6887; acc: 45117.0/45227.0=0.9976 Instance: 1500; Time: 31.18s; loss: 346.0098; acc: 67379.0/67649.0=0.9960 Instance: 1999; Time: 31.40s; loss: 128.3599; acc: 90036.0/90371.0=0.9963 Epoch: 11 training finished. Time: 125.57s, speed: 15.92st/s, total loss: tensor(695.8771, device='cuda:0') gold_num = 1026 pred_num = 1044 right_num = 1006 Dev: time: 4.52s, speed: 117.92st/s; acc: 0.9926, p: 0.9636, r: 0.9805, f: 0.9720 gold_num = 1026 pred_num = 1044 right_num = 1006 Test: time: 4.51s, speed: 117.99st/s; acc: 0.9926, p: 0.9636, r: 0.9805, f: 0.9720 Best dev score: p:0.9673076923076923, r:0.9805068226120858, f:0.973862536302033 Test score: p:0.9673076923076923, r:0.9805068226120858, f:0.973862536302033 Epoch: 12/100 Learning rate is setted as: 0.000810540131493955 Instance: 500; Time: 31.66s; loss: 100.7936; acc: 22946.0/22989.0=0.9981 Instance: 1000; Time: 31.42s; loss: 144.7101; acc: 45592.0/45712.0=0.9974 Instance: 1500; Time: 30.43s; loss: 118.6685; acc: 67384.0/67560.0=0.9974 Instance: 1999; Time: 31.69s; loss: 211.4471; acc: 90094.0/90371.0=0.9969 Epoch: 12 training finished. Time: 125.20s, speed: 15.97st/s, total loss: tensor(575.6193, device='cuda:0') gold_num = 1026 pred_num = 1070 right_num = 1011 Dev: time: 4.52s, speed: 117.76st/s; acc: 0.9895, p: 0.9449, r: 0.9854, f: 0.9647 gold_num = 1026 pred_num = 1070 right_num = 1011 Test: time: 4.52s, speed: 117.67st/s; acc: 0.9895, p: 0.9449, r: 0.9854, f: 0.9647 Best dev score: p:0.9673076923076923, r:0.9805068226120858, f:0.973862536302033 Test score: p:0.9673076923076923, r:0.9805068226120858, f:0.973862536302033 Epoch: 13/100 Learning rate is setted as: 0.0007700131249192573 Instance: 500; Time: 30.08s; loss: 81.7210; acc: 21509.0/21544.0=0.9984 Instance: 1000; Time: 31.09s; loss: 80.9707; acc: 43756.0/43829.0=0.9983 Instance: 1500; Time: 32.41s; loss: 87.4174; acc: 67061.0/67178.0=0.9983 Instance: 1999; Time: 32.24s; loss: 293.8628; acc: 90114.0/90371.0=0.9972 Epoch: 13 training finished. Time: 125.82s, speed: 15.89st/s, total loss: tensor(543.9722, device='cuda:0') gold_num = 1026 pred_num = 1034 right_num = 1010 Dev: time: 4.51s, speed: 118.14st/s; acc: 0.9944, p: 0.9768, r: 0.9844, f: 0.9806 Exceed previous best f score: 0.973862536302033 gold_num = 1026 pred_num = 1034 right_num = 1010 Test: time: 4.55s, speed: 117.89st/s; acc: 0.9944, p: 0.9768, r: 0.9844, f: 0.9806 Best dev score: p:0.97678916827853, r:0.9844054580896686, f:0.9805825242718447 Test score: p:0.97678916827853, r:0.9844054580896686, f:0.9805825242718447 Epoch: 14/100 Learning rate is setted as: 0.0007315124686732943 Instance: 500; Time: 31.85s; loss: 87.1234; acc: 22878.0/22919.0=0.9982 Instance: 1000; Time: 30.23s; loss: 94.5787; acc: 44529.0/44614.0=0.9981 Instance: 1500; Time: 31.13s; loss: 76.8431; acc: 67039.0/67169.0=0.9981 Instance: 1999; Time: 32.10s; loss: 156.5844; acc: 90155.0/90371.0=0.9976 Epoch: 14 training finished. Time: 125.31s, speed: 15.95st/s, total loss: tensor(415.1297, device='cuda:0') gold_num = 1026 pred_num = 1043 right_num = 1014 Dev: time: 4.53s, speed: 117.54st/s; acc: 0.9941, p: 0.9722, r: 0.9883, f: 0.9802 gold_num = 1026 pred_num = 1043 right_num = 1014 Test: time: 4.53s, speed: 117.41st/s; acc: 0.9941, p: 0.9722, r: 0.9883, f: 0.9802 Best dev score: p:0.97678916827853, r:0.9844054580896686, f:0.9805825242718447 Test score: p:0.97678916827853, r:0.9844054580896686, f:0.9805825242718447 Epoch: 15/100 Learning rate is setted as: 0.0006949368452396295 Instance: 500; Time: 31.66s; loss: 244.4252; acc: 22714.0/22827.0=0.9950 Instance: 1000; Time: 31.72s; loss: 93.6701; acc: 45398.0/45558.0=0.9965 Instance: 1500; Time: 31.31s; loss: 81.0918; acc: 67734.0/67935.0=0.9970 Instance: 1999; Time: 31.39s; loss: 74.4658; acc: 90132.0/90371.0=0.9974 Epoch: 15 training finished. Time: 126.09s, speed: 15.85st/s, total loss: tensor(493.6528, device='cuda:0') gold_num = 1026 pred_num = 1029 right_num = 1008 Dev: time: 4.52s, speed: 117.79st/s; acc: 0.9945, p: 0.9796, r: 0.9825, f: 0.9810 Exceed previous best f score: 0.9805825242718447 gold_num = 1026 pred_num = 1029 right_num = 1008 Test: time: 4.56s, speed: 117.55st/s; acc: 0.9945, p: 0.9796, r: 0.9825, f: 0.9810 Best dev score: p:0.9795918367346939, r:0.9824561403508771, f:0.981021897810219 Test score: p:0.9795918367346939, r:0.9824561403508771, f:0.981021897810219 Epoch: 16/100 Learning rate is setted as: 0.000660190002977648 Instance: 500; Time: 31.77s; loss: 61.9987; acc: 22716.0/22752.0=0.9984 Instance: 1000; Time: 31.52s; loss: 116.4953; acc: 45145.0/45245.0=0.9978 Instance: 1500; Time: 30.96s; loss: 189.4300; acc: 67209.0/67403.0=0.9971 Instance: 1999; Time: 31.70s; loss: 78.8190; acc: 90139.0/90371.0=0.9974 Epoch: 16 training finished. Time: 125.94s, speed: 15.87st/s, total loss: tensor(446.7428, device='cuda:0') gold_num = 1026 pred_num = 1025 right_num = 1006 Dev: time: 4.55s, speed: 117.12st/s; acc: 0.9945, p: 0.9815, r: 0.9805, f: 0.9810 gold_num = 1026 pred_num = 1025 right_num = 1006 Test: time: 4.52s, speed: 117.67st/s; acc: 0.9945, p: 0.9815, r: 0.9805, f: 0.9810 Best dev score: p:0.9795918367346939, r:0.9824561403508771, f:0.981021897810219 Test score: p:0.9795918367346939, r:0.9824561403508771, f:0.981021897810219 Epoch: 17/100 Learning rate is setted as: 0.0006271805028287656 Instance: 500; Time: 30.86s; loss: 63.2982; acc: 22168.0/22201.0=0.9985 Instance: 1000; Time: 30.91s; loss: 126.2816; acc: 44340.0/44464.0=0.9972 Instance: 1500; Time: 30.83s; loss: 64.3312; acc: 66554.0/66713.0=0.9976 Instance: 1999; Time: 32.72s; loss: 110.6324; acc: 90159.0/90371.0=0.9977 Epoch: 17 training finished. Time: 125.31s, speed: 15.95st/s, total loss: tensor(364.5435, device='cuda:0') gold_num = 1026 pred_num = 1038 right_num = 1012 Dev: time: 4.60s, speed: 115.66st/s; acc: 0.9943, p: 0.9750, r: 0.9864, f: 0.9806 gold_num = 1026 pred_num = 1038 right_num = 1012 Test: time: 4.59s, speed: 116.02st/s; acc: 0.9943, p: 0.9750, r: 0.9864, f: 0.9806 Best dev score: p:0.9795918367346939, r:0.9824561403508771, f:0.981021897810219 Test score: p:0.9795918367346939, r:0.9824561403508771, f:0.981021897810219 Epoch: 18/100 Learning rate is setted as: 0.0005958214776873273 Instance: 500; Time: 30.93s; loss: 131.2264; acc: 22098.0/22176.0=0.9965 Instance: 1000; Time: 30.89s; loss: 73.0984; acc: 44383.0/44492.0=0.9976 Instance: 1500; Time: 31.22s; loss: 42.7435; acc: 66946.0/67074.0=0.9981 Instance: 1999; Time: 32.11s; loss: 79.4446; acc: 90198.0/90371.0=0.9981 Epoch: 18 training finished. Time: 125.15s, speed: 15.97st/s, total loss: tensor(326.5130, device='cuda:0') gold_num = 1026 pred_num = 1011 right_num = 998 Dev: time: 4.53s, speed: 117.67st/s; acc: 0.9941, p: 0.9871, r: 0.9727, f: 0.9799 gold_num = 1026 pred_num = 1011 right_num = 998 Test: time: 4.53s, speed: 117.62st/s; acc: 0.9941, p: 0.9871, r: 0.9727, f: 0.9799 Best dev score: p:0.9795918367346939, r:0.9824561403508771, f:0.981021897810219 Test score: p:0.9795918367346939, r:0.9824561403508771, f:0.981021897810219 Epoch: 19/100 Learning rate is setted as: 0.0005660304038029609 Instance: 500; Time: 31.59s; loss: 52.7217; acc: 22897.0/22920.0=0.9990 Instance: 1000; Time: 31.10s; loss: 198.4854; acc: 45232.0/45347.0=0.9975 Instance: 1500; Time: 31.76s; loss: 62.1483; acc: 68046.0/68191.0=0.9979 Instance: 1999; Time: 30.82s; loss: 64.5167; acc: 90188.0/90371.0=0.9980 Epoch: 19 training finished. Time: 125.27s, speed: 15.96st/s, total loss: tensor(377.8722, device='cuda:0') gold_num = 1026 pred_num = 1045 right_num = 1016 Dev: time: 4.52s, speed: 117.86st/s; acc: 0.9944, p: 0.9722, r: 0.9903, f: 0.9812 Exceed previous best f score: 0.981021897810219 gold_num = 1026 pred_num = 1045 right_num = 1016 Test: time: 4.55s, speed: 117.94st/s; acc: 0.9944, p: 0.9722, r: 0.9903, f: 0.9812 Best dev score: p:0.9722488038277513, r:0.9902534113060428, f:0.9811685176243361 Test score: p:0.9722488038277513, r:0.9902534113060428, f:0.9811685176243361 Epoch: 20/100 Learning rate is setted as: 0.0005377288836128128 Instance: 500; Time: 31.84s; loss: 95.1913; acc: 23041.0/23102.0=0.9974 Instance: 1000; Time: 29.55s; loss: 47.7070; acc: 44288.0/44371.0=0.9981 Instance: 1500; Time: 32.16s; loss: 65.6617; acc: 67602.0/67718.0=0.9983 Instance: 1999; Time: 31.32s; loss: 72.9049; acc: 90226.0/90371.0=0.9984 Epoch: 20 training finished. Time: 124.86s, speed: 16.01st/s, total loss: tensor(281.4650, device='cuda:0') gold_num = 1026 pred_num = 1023 right_num = 1006 Dev: time: 4.54s, speed: 117.30st/s; acc: 0.9946, p: 0.9834, r: 0.9805, f: 0.9819 Exceed previous best f score: 0.9811685176243361 gold_num = 1026 pred_num = 1023 right_num = 1006 Test: time: 4.57s, speed: 117.33st/s; acc: 0.9946, p: 0.9834, r: 0.9805, f: 0.9819 Best dev score: p:0.9833822091886608, r:0.9805068226120858, f:0.9819424109321621 Test score: p:0.9833822091886608, r:0.9805068226120858, f:0.9819424109321621 ...... ...... ...... ...... ...... ...... Epoch: 90/100 Learning rate is setted as: 1.4832547064488426e-05 Instance: 500; Time: 32.04s; loss: 24.2524; acc: 23116.0/23131.0=0.9994 Instance: 1000; Time: 31.03s; loss: 19.0902; acc: 45323.0/45349.0=0.9994 Instance: 1500; Time: 32.69s; loss: 36.7891; acc: 68823.0/68869.0=0.9993 Instance: 1999; Time: 30.16s; loss: 24.1088; acc: 90307.0/90371.0=0.9993 Epoch: 90 training finished. Time: 125.93s, speed: 15.87st/s, total loss: tensor(104.2405, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1024 Dev: time: 4.57s, speed: 116.48st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 gold_num = 1026 pred_num = 1040 right_num = 1024 Test: time: 4.57s, speed: 116.51st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 Best dev score: p:0.9846153846153847, r:0.9980506822612085, f:0.9912875121006777 Test score: p:0.9846153846153847, r:0.9980506822612085, f:0.9912875121006777 Epoch: 91/100 Learning rate is setted as: 1.4090919711264e-05 Instance: 500; Time: 32.25s; loss: 19.7567; acc: 23080.0/23086.0=0.9997 Instance: 1000; Time: 30.20s; loss: 32.0599; acc: 44758.0/44783.0=0.9994 Instance: 1500; Time: 31.94s; loss: 9.9867; acc: 67778.0/67803.0=0.9996 Instance: 1999; Time: 31.45s; loss: 26.3107; acc: 90328.0/90371.0=0.9995 Epoch: 91 training finished. Time: 125.84s, speed: 15.89st/s, total loss: tensor(88.1140, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1024 Dev: time: 4.60s, speed: 115.75st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 gold_num = 1026 pred_num = 1040 right_num = 1024 Test: time: 4.59s, speed: 115.96st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 Best dev score: p:0.9846153846153847, r:0.9980506822612085, f:0.9912875121006777 Test score: p:0.9846153846153847, r:0.9980506822612085, f:0.9912875121006777 Epoch: 92/100 Learning rate is setted as: 1.3386373725700803e-05 Instance: 500; Time: 32.52s; loss: 38.6252; acc: 23335.0/23361.0=0.9989 Instance: 1000; Time: 32.01s; loss: 18.8413; acc: 46320.0/46358.0=0.9992 Instance: 1500; Time: 30.23s; loss: 10.8565; acc: 67986.0/68026.0=0.9994 Instance: 1999; Time: 31.26s; loss: 24.7076; acc: 90316.0/90371.0=0.9994 Epoch: 92 training finished. Time: 126.02s, speed: 15.86st/s, total loss: tensor(93.0306, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1024 Dev: time: 4.55s, speed: 117.03st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 gold_num = 1026 pred_num = 1040 right_num = 1024 Test: time: 4.55s, speed: 117.09st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 Best dev score: p:0.9846153846153847, r:0.9980506822612085, f:0.9912875121006777 Test score: p:0.9846153846153847, r:0.9980506822612085, f:0.9912875121006777 Epoch: 93/100 Learning rate is setted as: 1.2717055039415761e-05 Instance: 500; Time: 31.41s; loss: 43.6084; acc: 22583.0/22612.0=0.9987 Instance: 1000; Time: 31.97s; loss: 16.5049; acc: 45712.0/45747.0=0.9992 Instance: 1500; Time: 31.36s; loss: 30.4766; acc: 68166.0/68222.0=0.9992 Instance: 1999; Time: 31.01s; loss: 15.8847; acc: 90307.0/90371.0=0.9993 Epoch: 93 training finished. Time: 125.75s, speed: 15.90st/s, total loss: tensor(106.4745, device='cuda:0') gold_num = 1026 pred_num = 1038 right_num = 1024 Dev: time: 4.57s, speed: 116.39st/s; acc: 0.9972, p: 0.9865, r: 0.9981, f: 0.9922 Exceed previous best f score: 0.9912875121006777 gold_num = 1026 pred_num = 1038 right_num = 1024 Test: time: 4.55s, speed: 117.91st/s; acc: 0.9972, p: 0.9865, r: 0.9981, f: 0.9922 Best dev score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Test score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Epoch: 94/100 Learning rate is setted as: 1.2081202287444973e-05 Instance: 500; Time: 31.96s; loss: 33.8862; acc: 23115.0/23138.0=0.9990 Instance: 1000; Time: 30.13s; loss: 7.8426; acc: 44838.0/44862.0=0.9995 Instance: 1500; Time: 30.85s; loss: 54.5449; acc: 67080.0/67141.0=0.9991 Instance: 1999; Time: 32.18s; loss: 17.7653; acc: 90308.0/90371.0=0.9993 Epoch: 94 training finished. Time: 125.12s, speed: 15.98st/s, total loss: tensor(114.0390, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1024 Dev: time: 4.52s, speed: 117.68st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 gold_num = 1026 pred_num = 1040 right_num = 1024 Test: time: 4.53s, speed: 117.63st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 Best dev score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Test score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Epoch: 95/100 Learning rate is setted as: 1.1477142173072723e-05 Instance: 500; Time: 32.72s; loss: 18.1870; acc: 23747.0/23760.0=0.9995 Instance: 1000; Time: 30.51s; loss: 19.2969; acc: 45707.0/45728.0=0.9995 Instance: 1500; Time: 31.00s; loss: 32.6200; acc: 67997.0/68033.0=0.9995 Instance: 1999; Time: 30.85s; loss: 33.8846; acc: 90313.0/90371.0=0.9994 Epoch: 95 training finished. Time: 125.08s, speed: 15.98st/s, total loss: tensor(103.9886, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1024 Dev: time: 4.53s, speed: 117.52st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 gold_num = 1026 pred_num = 1040 right_num = 1024 Test: time: 4.54s, speed: 117.25st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 Best dev score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Test score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Epoch: 96/100 Learning rate is setted as: 1.0903285064419087e-05 Instance: 500; Time: 30.00s; loss: 6.9263; acc: 21548.0/21550.0=0.9999 Instance: 1000; Time: 32.30s; loss: 29.8059; acc: 44736.0/44756.0=0.9996 Instance: 1500; Time: 32.04s; loss: 10.8405; acc: 67736.0/67759.0=0.9997 Instance: 1999; Time: 31.53s; loss: 27.1229; acc: 90340.0/90371.0=0.9997 Epoch: 96 training finished. Time: 125.88s, speed: 15.88st/s, total loss: tensor(74.6956, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1024 Dev: time: 4.52s, speed: 117.91st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 gold_num = 1026 pred_num = 1040 right_num = 1024 Test: time: 4.52s, speed: 117.68st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 Best dev score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Test score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Epoch: 97/100 Learning rate is setted as: 1.0358120811198132e-05 Instance: 500; Time: 30.54s; loss: 17.3246; acc: 22084.0/22091.0=0.9997 Instance: 1000; Time: 30.07s; loss: 28.2827; acc: 43779.0/43806.0=0.9994 Instance: 1500; Time: 32.11s; loss: 20.7174; acc: 67004.0/67037.0=0.9995 Instance: 1999; Time: 32.38s; loss: 24.8686; acc: 90326.0/90371.0=0.9995 Epoch: 97 training finished. Time: 125.10s, speed: 15.98st/s, total loss: tensor(91.1934, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1024 Dev: time: 4.54s, speed: 117.32st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 gold_num = 1026 pred_num = 1040 right_num = 1024 Test: time: 4.53s, speed: 117.44st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 Best dev score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Test score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Epoch: 98/100 Learning rate is setted as: 9.840214770638225e-06 Instance: 500; Time: 31.66s; loss: 16.9288; acc: 22965.0/22976.0=0.9995 Instance: 1000; Time: 32.19s; loss: 15.7932; acc: 46301.0/46319.0=0.9996 Instance: 1500; Time: 30.15s; loss: 13.8526; acc: 68054.0/68078.0=0.9996 Instance: 1999; Time: 30.90s; loss: 34.6453; acc: 90327.0/90371.0=0.9995 Epoch: 98 training finished. Time: 124.90s, speed: 16.01st/s, total loss: tensor(81.2200, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1024 Dev: time: 4.58s, speed: 116.30st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 gold_num = 1026 pred_num = 1040 right_num = 1024 Test: time: 4.58s, speed: 116.27st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 Best dev score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Test score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Epoch: 99/100 Learning rate is setted as: 9.348204032106314e-06 Instance: 500; Time: 32.17s; loss: 39.2616; acc: 23105.0/23122.0=0.9993 Instance: 1000; Time: 32.35s; loss: 13.0373; acc: 46368.0/46387.0=0.9996 Instance: 1500; Time: 30.69s; loss: 20.9561; acc: 68285.0/68309.0=0.9996 Instance: 1999; Time: 30.82s; loss: 17.9313; acc: 90343.0/90371.0=0.9997 Epoch: 99 training finished. Time: 126.03s, speed: 15.86st/s, total loss: tensor(91.1863, device='cuda:0') gold_num = 1026 pred_num = 1040 right_num = 1024 Dev: time: 4.58s, speed: 116.20st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 gold_num = 1026 pred_num = 1040 right_num = 1024 Test: time: 4.59s, speed: 116.02st/s; acc: 0.9970, p: 0.9846, r: 0.9981, f: 0.9913 Best dev score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038 Test score: p:0.9865125240847784, r:0.9980506822612085, f:0.9922480620155038","title":"\u7b2c5\u6b65: \u6a21\u578b\u7684\u8bad\u7ec3"},{"location":"12_1.html#_2","text":"\u672c\u5c0f\u8282\u5b66\u4e60\u4e86Soft-lexicon\u6a21\u578b\u7684\u67b6\u6784\u548c\u4ee3\u7801\u5b9e\u73b0.","title":"\u5c0f\u8282\u603b\u7ed3"},{"location":"13_1.html","text":"CNN\u6a21\u578b\u5904\u7406RE\u95ee\u9898 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u7406\u89e3CNN\u6a21\u578b\u662f\u5982\u4f55\u5904\u7406RE\u95ee\u9898\u7684. \u638c\u63e1CNN\u5904\u7406RE\u7684\u5177\u4f53\u4ee3\u7801\u5b9e\u73b0. CNN\u5904\u7406RE\u95ee\u9898\u7684\u67b6\u6784 \u00b6 \u539f\u59cb\u8bba\u6587<< Relation Classification via Convolutional Deep Neural Network >>. \u6574\u4e2a\u6a21\u578b\u7684\u67b6\u6784\u56fe\u5982\u4e0b\u6240\u793a: CNN\u6a21\u578b\u7684\u6838\u5fc3\u64cd\u4f5c\u67092\u4e2a: \u7279\u5f81\u62bd\u53d6\u878d\u5408\u4e86\u8bed\u6cd5\u5c42\u9762\u7684\u7279\u5f81 + \u8bed\u53e5\u5c42\u9762\u7684\u7279\u5f81. \u8bed\u53e5\u5c42\u9762\u7684\u7279\u5f81\u62bd\u53d6, \u9664\u4e86word embedding\u5916, \u8fd8\u878d\u5165\u4e86position embedding\u7684\u4fe1\u606f. CNN\u5904\u7406RE\u7684\u5b9e\u73b0 \u00b6 \u6570\u636e\u9884\u5904\u7406 \u00b6 \u672c\u9879\u76ee\u91c7\u7528\u533b\u7597\u6570\u636e\u96c6CMeIE_train.json, \u4f46\u662f\u6240\u5c55\u793a\u7684\u6570\u636e\u683c\u5f0f\u5bf9CNN\u6a21\u578b\u5e76\u4e0d\u53cb\u597d, \u9700\u8981\u5bf9\u539f\u59cb\u6570\u636e\u96c6\u505a\u683c\u5f0f\u8f6c\u6362\u7684\u9884\u5904\u7406. \u9996\u5148\u5c55\u793a\u539f\u59cb\u533b\u7597\u6570\u636e: /home/ec2-user/information_extraction/relation/cnn_medical/data/CMeIE_train.json {\"text\": \"\u4ea7\u540e\u6291\u90c1\u75c7@\u533a\u5206\u4ea7\u540e\u6291\u90c1\u75c7\u4e0e\u8f7b\u5ea6\u60c5\u7eea\u5931\u8c03\uff08\u4ea7\u540e\u5fe7\u90c1\u6216\u201c\u5a74\u513f\u5fe7\u90c1\u201d\uff09\u662f\u91cd\u8981\u7684\uff0c\u56e0\u4e3a\u8f7b\u5ea6\u60c5\u7eea\u5931\u8c03\u4e0d\u9700\u8981\u6cbb\u7597\u3002\", \"spo_list\": [{\"Combined\": false, \"predicate\": \"\u9274\u522b\u8bca\u65ad\", \"subject\": \"\u4ea7\u540e\u6291\u90c1\u75c7\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u8f7b\u5ea6\u60c5\u7eea\u5931\u8c03\"}, \"object_type\": {\"@value\": \"\u75be\u75c5\"}}]} {\"text\": \"\u7c7b\u98ce\u6e7f\u5173\u8282\u708e@\u5c3a\u4fa7\u504f\u659c\u662f\u7531\u4e8eMCP\u5173\u8282\u708e\u75c7\u9020\u6210\u7684\u3002\", \"spo_list\": [{\"Combined\": false, \"predicate\": \"\u4e34\u5e8a\u8868\u73b0\", \"subject\": \"MCP\u5173\u8282\u708e\u75c7\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u5c3a\u4fa7\u504f\u659c\"}, \"object_type\": {\"@value\": \"\u75c7\u72b6\"}}]} \u9700\u8981\u5c06\u539f\u59cb\u6570\u636e\u8f6c\u53d8\u6210\u66f4\u6709\u5229\u4e8eCNN\u6a21\u578b\u5904\u7406\u7684\u5982\u4e0b\u683c\u5f0f: {\"id\": \"1\", \"sentence\": [\"\u4ea7\", \"\u540e\", \"\u6291\", \"\u90c1\", \"\u75c7\", \"@\", \"\u533a\", \"\u5206\", \"\u4ea7\", \"\u540e\", \"\u6291\", \"\u90c1\", \"\u75c7\", \"\u4e0e\", \"\u8f7b\", \"\u5ea6\", \"\u60c5\", \"\u7eea\", \"\u5931\", \"\u8c03\", \"\uff08\", \"\u4ea7\", \"\u540e\", \"\u5fe7\", \"\u90c1\", \"\u6216\", \"\u201c\", \"\u5a74\", \"\u513f\", \"\u5fe7\", \"\u90c1\", \"\u201d\", \"\uff09\", \"\u662f\", \"\u91cd\", \"\u8981\", \"\u7684\", \"\uff0c\", \"\u56e0\", \"\u4e3a\", \"\u8f7b\", \"\u5ea6\", \"\u60c5\", \"\u7eea\", \"\u5931\", \"\u8c03\", \"\u4e0d\", \"\u9700\", \"\u8981\", \"\u6cbb\", \"\u7597\", \"\u3002\"], \"head\": \"\u4ea7\u540e\u6291\u90c1\u75c7\", \"tail\": \"\u8f7b\u5ea6\u60c5\u7eea\u5931\u8c03\", \"relation\": \"\u9274\u522b\u8bca\u65ad\", \"subj_start\": 0, \"subj_end\": 4, \"obj_start\": 14, \"obj_end\": 19, \"comment\": \"\"} {\"id\": \"2\", \"sentence\": [\"\u7c7b\", \"\u98ce\", \"\u6e7f\", \"\u5173\", \"\u8282\", \"\u708e\", \"@\", \"\u5c3a\", \"\u4fa7\", \"\u504f\", \"\u659c\", \"\u662f\", \"\u7531\", \"\u4e8e\", \"M\", \"C\", \"P\", \"\u5173\", \"\u8282\", \"\u708e\", \"\u75c7\", \"\u9020\", \"\u6210\", \"\u7684\", \"\u3002\"], \"head\": \"MCP\u5173\u8282\u708e\u75c7\", \"tail\": \"\u5c3a\u4fa7\u504f\u659c\", \"relation\": \"\u4e34\u5e8a\u8868\u73b0\", \"subj_start\": 14, \"subj_end\": 20, \"obj_start\": 7, \"obj_end\": 10, \"comment\": \"\"} \u4f5c\u4e1a: \u4e0a\u8ff0\u6570\u636e\u683c\u5f0f\u8f6c\u6362\u5c5e\u4e8e\u5de5\u4f5c\u4e2d\u7684\u57fa\u672c\u64cd\u4f5c, \u4ee5\u4f5c\u4e1a\u7684\u5f62\u5f0f\u5b8c\u6210, \u953b\u70bc\u81ea\u5df1\u771f\u5b9e\u8fdb\u884c\u6570\u636e\u5904\u7406\u7684\u4ee3\u7801\u80fd\u529b! \u5173\u7cfb\u6570\u636e\u5b9a\u4e49\u6587\u4ef6: /home/ec2-user/information_extraction/relation/cnn_medical/data/53_schemas.json {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u9884\u9632\", \"object_type\": \"\u5176\u4ed6\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u9636\u6bb5\", \"object_type\": \"\u5176\u4ed6\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u5c31\u8bca\u79d1\u5ba4\", \"object_type\": \"\u5176\u4ed6\"} {\"subject_type\": \"\u5176\u4ed6\", \"predicate\": \"\u540c\u4e49\u8bcd-\u5176\u4ed6\", \"object_type\": \"\u5176\u4ed6\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u8f85\u52a9\u6cbb\u7597\", \"object_type\": \"\u5176\u4ed6\u6cbb\u7597\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u5316\u7597\", \"object_type\": \"\u5176\u4ed6\u6cbb\u7597\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u653e\u5c04\u6cbb\u7597\", \"object_type\": \"\u5176\u4ed6\u6cbb\u7597\"} {\"subject_type\": \"\u5176\u4ed6\u6cbb\u7597\", \"predicate\": \"\u540c\u4e49\u8bcd-\u5176\u4ed6\u6cbb\u7597\", \"object_type\": \"\u5176\u4ed6\u6cbb\u7597\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u624b\u672f\u6cbb\u7597\", \"object_type\": \"\u624b\u672f\u6cbb\u7597\"} {\"subject_type\": \"\u624b\u672f\u6cbb\u7597\", \"predicate\": \"\u540c\u4e49\u8bcd-\u624b\u672f\u6cbb\u7597\", \"object_type\": \"\u624b\u672f\u6cbb\u7597\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u5b9e\u9a8c\u5ba4\u68c0\u67e5\", \"object_type\": \"\u68c0\u67e5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u5f71\u50cf\u5b66\u68c0\u67e5\", \"object_type\": \"\u68c0\u67e5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u8f85\u52a9\u68c0\u67e5\", \"object_type\": \"\u68c0\u67e5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u7ec4\u7ec7\u5b66\u68c0\u67e5\", \"object_type\": \"\u68c0\u67e5\"} {\"subject_type\": \"\u68c0\u67e5\", \"predicate\": \"\u540c\u4e49\u8bcd-\u68c0\u67e5\", \"object_type\": \"\u68c0\u67e5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u5185\u7aa5\u955c\u68c0\u67e5\", \"object_type\": \"\u68c0\u67e5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u7b5b\u67e5\", \"object_type\": \"\u68c0\u67e5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u591a\u53d1\u7fa4\u4f53\", \"object_type\": \"\u6d41\u884c\u75c5\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u53d1\u75c5\u7387\", \"object_type\": \"\u6d41\u884c\u75c5\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u53d1\u75c5\u5e74\u9f84\", \"object_type\": \"\u6d41\u884c\u75c5\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u591a\u53d1\u5730\u533a\", \"object_type\": \"\u6d41\u884c\u75c5\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u53d1\u75c5\u6027\u522b\u503e\u5411\", \"object_type\": \"\u6d41\u884c\u75c5\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u6b7b\u4ea1\u7387\", \"object_type\": \"\u6d41\u884c\u75c5\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u591a\u53d1\u5b63\u8282\", \"object_type\": \"\u6d41\u884c\u75c5\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u4f20\u64ad\u9014\u5f84\", \"object_type\": \"\u6d41\u884c\u75c5\u5b66\"} {\"subject_type\": \"\u6d41\u884c\u75c5\u5b66\", \"predicate\": \"\u540c\u4e49\u8bcd-\u6d41\u884c\u75c5\u5b66\", \"object_type\": \"\u6d41\u884c\u75c5\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u540c\u4e49\u8bcd-\u75be\u75c5\", \"object_type\": \"\u75be\u75c5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u5e76\u53d1\u75c7\", \"object_type\": \"\u75be\u75c5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u75c5\u7406\u5206\u578b\", \"object_type\": \"\u75be\u75c5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u76f8\u5173\uff08\u5bfc\u81f4\uff09\", \"object_type\": \"\u75be\u75c5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u9274\u522b\u8bca\u65ad\", \"object_type\": \"\u75be\u75c5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u76f8\u5173\uff08\u8f6c\u5316\uff09\", \"object_type\": \"\u75be\u75c5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u76f8\u5173\uff08\u75c7\u72b6\uff09\", \"object_type\": \"\u75be\u75c5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u4e34\u5e8a\u8868\u73b0\", \"object_type\": \"\u75c7\u72b6\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u6cbb\u7597\u540e\u75c7\u72b6\", \"object_type\": \"\u75c7\u72b6\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u4fb5\u53ca\u5468\u56f4\u7ec4\u7ec7\u8f6c\u79fb\u7684\u75c7\u72b6\", \"object_type\": \"\u75c7\u72b6\"} {\"subject_type\": \"\u75c7\u72b6\", \"predicate\": \"\u540c\u4e49\u8bcd-\u75c7\u72b6\", \"object_type\": \"\u75c7\u72b6\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u75c5\u56e0\", \"object_type\": \"\u793e\u4f1a\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u9ad8\u5371\u56e0\u7d20\", \"object_type\": \"\u793e\u4f1a\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u98ce\u9669\u8bc4\u4f30\u56e0\u7d20\", \"object_type\": \"\u793e\u4f1a\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u75c5\u53f2\", \"object_type\": \"\u793e\u4f1a\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u9057\u4f20\u56e0\u7d20\", \"object_type\": \"\u793e\u4f1a\u5b66\"} {\"subject_type\": \"\u793e\u4f1a\u5b66\", \"predicate\": \"\u540c\u4e49\u8bcd-\u793e\u4f1a\u5b66\", \"object_type\": \"\u793e\u4f1a\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u53d1\u75c5\u673a\u5236\", \"object_type\": \"\u793e\u4f1a\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u75c5\u7406\u751f\u7406\", \"object_type\": \"\u793e\u4f1a\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u836f\u7269\u6cbb\u7597\", \"object_type\": \"\u836f\u7269\"} {\"subject_type\": \"\u836f\u7269\", \"predicate\": \"\u540c\u4e49\u8bcd-\u836f\u7269\", \"object_type\": \"\u836f\u7269\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u53d1\u75c5\u90e8\u4f4d\", \"object_type\": \"\u90e8\u4f4d\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u8f6c\u79fb\u90e8\u4f4d\", \"object_type\": \"\u90e8\u4f4d\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u5916\u4fb5\u90e8\u4f4d\", \"object_type\": \"\u90e8\u4f4d\"} {\"subject_type\": \"\u90e8\u4f4d\", \"predicate\": \"\u540c\u4e49\u8bcd-\u90e8\u4f4d\", \"object_type\": \"\u90e8\u4f4d\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u9884\u540e\u72b6\u51b5\", \"object_type\": \"\u9884\u540e\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u9884\u540e\u751f\u5b58\u7387\", \"object_type\": \"\u9884\u540e\"} \u5173\u7cfb\u6620\u5c04\u8868: /home/ec2-user/information_extraction/relation/cnn_medical/data/rel2idx.json {\"\u9884\u9632\": 0, \"\u9636\u6bb5\": 1, \"\u5c31\u8bca\u79d1\u5ba4\": 2, \"\u540c\u4e49\u8bcd-\u5176\u4ed6\": 3, \"\u8f85\u52a9\u6cbb\u7597\": 4, \"\u5316\u7597\": 5, \"\u653e\u5c04\u6cbb\u7597\": 6, \"\u540c\u4e49\u8bcd-\u5176\u4ed6\u6cbb\u7597\": 7, \"\u624b\u672f\u6cbb\u7597\": 8, \"\u540c\u4e49\u8bcd-\u624b\u672f\u6cbb\u7597\": 9, \"\u5b9e\u9a8c\u5ba4\u68c0\u67e5\": 10, \"\u5f71\u50cf\u5b66\u68c0\u67e5\": 11, \"\u8f85\u52a9\u68c0\u67e5\": 12, \"\u7ec4\u7ec7\u5b66\u68c0\u67e5\": 13, \"\u540c\u4e49\u8bcd-\u68c0\u67e5\": 14, \"\u5185\u7aa5\u955c\u68c0\u67e5\": 15, \"\u7b5b\u67e5\": 16, \"\u591a\u53d1\u7fa4\u4f53\": 17, \"\u53d1\u75c5\u7387\": 18, \"\u53d1\u75c5\u5e74\u9f84\": 19, \"\u591a\u53d1\u5730\u533a\": 20, \"\u53d1\u75c5\u6027\u522b\u503e\u5411\": 21, \"\u6b7b\u4ea1\u7387\": 22, \"\u591a\u53d1\u5b63\u8282\": 23, \"\u4f20\u64ad\u9014\u5f84\": 24, \"\u540c\u4e49\u8bcd-\u6d41\u884c\u75c5\u5b66\": 25, \"\u540c\u4e49\u8bcd-\u75be\u75c5\": 26, \"\u5e76\u53d1\u75c7\": 27, \"\u75c5\u7406\u5206\u578b\": 28, \"\u76f8\u5173\uff08\u5bfc\u81f4\uff09\": 29, \"\u9274\u522b\u8bca\u65ad\": 30, \"\u76f8\u5173\uff08\u8f6c\u5316\uff09\": 31, \"\u76f8\u5173\uff08\u75c7\u72b6\uff09\": 32, \"\u4e34\u5e8a\u8868\u73b0\": 33, \"\u6cbb\u7597\u540e\u75c7\u72b6\": 34, \"\u4fb5\u53ca\u5468\u56f4\u7ec4\u7ec7\u8f6c\u79fb\u7684\u75c7\u72b6\": 35, \"\u540c\u4e49\u8bcd-\u75c7\u72b6\": 36, \"\u75c5\u56e0\": 37, \"\u9ad8\u5371\u56e0\u7d20\": 38, \"\u98ce\u9669\u8bc4\u4f30\u56e0\u7d20\": 39, \"\u75c5\u53f2\": 40, \"\u9057\u4f20\u56e0\u7d20\": 41, \"\u540c\u4e49\u8bcd-\u793e\u4f1a\u5b66\": 42, \"\u53d1\u75c5\u673a\u5236\": 43, \"\u75c5\u7406\u751f\u7406\": 44, \"\u836f\u7269\u6cbb\u7597\": 45, \"\u540c\u4e49\u8bcd-\u836f\u7269\": 46, \"\u53d1\u75c5\u90e8\u4f4d\": 47, \"\u8f6c\u79fb\u90e8\u4f4d\": 48, \"\u5916\u4fb5\u90e8\u4f4d\": 49, \"\u540c\u4e49\u8bcd-\u90e8\u4f4d\": 50, \"\u9884\u540e\u72b6\u51b5\": 51, \"\u9884\u540e\u751f\u5b58\u7387\": 52} \u5de5\u5177\u7c7b\u51fd\u6570\u7684\u5b9e\u73b0 \u00b6 \u5de5\u5177\u7c7b\u51fd\u6570\u67092\u4e2a: 1: \u8d1f\u8d23\u5904\u7406\u8bcd\u5d4c\u5165\u7684embedding.py 2: \u8d1f\u8d23\u5904\u7406\u6570\u636e\u52a0\u8f7d\u548c\u5176\u4ed6\u5de5\u5177\u7c7b\u529f\u80fd\u7684utils.py 1: \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/cnn_medical/embedding.py # \u5bfc\u5165\u5de5\u5177\u5305 from collections import Counter from tqdm import tqdm import jieba import bz2 import torch import numpy as np # \u83b7\u53d6\u8bcd\u5178\u7684\u51fd\u6570 def get_vocab ( train_file_path , vocab_size ): # \u521d\u59cb\u5316\u4e00\u4e2a\u8ba1\u6570\u5668 token_counter = Counter () # \u904d\u5386\u8bad\u7ec3\u96c6\u6570\u636e, \u5c06\u5206\u8bcd\u540e\u7684\u6240\u6709\u4e2d\u6587\u8bcd\u653e\u5165\u8ba1\u6570\u5668\u4e2d with open ( train_file_path , 'r' , encoding = 'utf-8' ) as f : lines = f . readlines () for line in tqdm ( lines , total = len ( lines ), desc = 'Counting tokens' ): sent = line . split ( ',' )[ - 1 ] . strip () # \u91c7\u7528jieba\u5206\u8bcd\u4f5c\u4e3a\u4e2d\u6587\u573a\u666f\u4e0b\u7684\u5206\u8bcd\u5668 sent_cut = list ( jieba . cut ( sent )) # \u66f4\u65b0\u8ba1\u6570\u5668 token_counter . update ( sent_cut ) # \u6309\u7167\u4eba\u5de5\u8bbe\u7f6e\u9009\u5b9a\u8bcd\u9891\u6700\u9ad8\u7684vocab_size\u4e2a\u4e2d\u6587\u8bcd vocab = set ( token for token , _ in token_counter . most_common ( vocab_size )) return vocab # \u83b7\u53d6\u8bcd\u5d4c\u5165\u5411\u91cf\u7684\u51fd\u6570 def get_embedding ( vocab , embedding_file_path ): print ( 'processing embedding file ...' ) token2embedding = {} # \u6253\u5f00\u65b0\u6d6a\u5fae\u535a\u5f00\u6e90\u7684\u9884\u8bad\u7ec3\u8bcd\u5411\u91cf\u6587\u4ef6 with bz2 . open ( embedding_file_path ) as f : token_vectors = f . readlines () meta_info = token_vectors [ 0 ] . split () print ( f ' { meta_info [ 0 ] } tokens in embedding file in total, vector size is { meta_info [ - 1 ] } ' ) # \u904d\u5386\u6bcf\u4e00\u884c\u6570\u636e for line in tqdm ( token_vectors [ 1 :]): line = line . split () # \u7b2c\u4e00\u5217\u662f\u5bf9\u5e94\u7684\u4e2d\u6587\u8bcd token = line [ 0 ] . decode ( 'utf-8' ) # \u7b2c\u4e00\u5217\u4e4b\u540e\u90fd\u662f\u6570\u5b57\u5316\u7684\u8bcd\u5411\u91cf vector = line [ 1 :] # \u53ea\u9009\u53d6\u90a3\u4e9b\u5df2\u7ecf\u5728\u8bcd\u5178\u4e2d\u7684\u8bcd\u5411\u91cf\u5b58\u5165\u8bcd\u5411\u91cf\u8bcd\u5178\u4e2d if token in vocab : token2embedding [ token ] = [ float ( num ) for num in vector ] # \u5c064\u4e2a\u7279\u6b8a\u5b57\u7b26\u5360\u636e0,1,2,3\u7684\u6807\u7b7e, \u5176\u4ed6\u5355\u8bcd\u6309\u5e8f\u5411\u540e\u6392\u5217 token2idx = { token : idx for idx , token in enumerate ( token2embedding . keys (), 4 )} UNK , PAD , BOS , EOS = '<unk>' , '<pad>' , '<bos>' , '<eos>' token2idx [ PAD ] = 0 token2idx [ UNK ] = 1 token2idx [ BOS ] = 2 token2idx [ EOS ] = 3 idx2token = { idx : token for token , idx in token2idx . items ()} idx2embedding = { token2idx [ token ]: embedding for token , embedding in token2embedding . items ()} idx2embedding [ 0 ] = [ .0 ] * int ( meta_info [ - 1 ]) idx2embedding [ 1 ] = [ .0 ] * int ( meta_info [ - 1 ]) idx2embedding [ 2 ] = np . random . random ( int ( meta_info [ - 1 ])) . tolist () idx2embedding [ 3 ] = np . random . random ( int ( meta_info [ - 1 ])) . tolist () emb_mat = [ idx2embedding [ idx ] for idx in range ( len ( idx2embedding ))] emb_mat = torch . tensor ( emb_mat , dtype = torch . float ) return emb_mat , token2idx , len ( vocab ) + 4 2: \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/cnn_medical/utils.py # \u5bfc\u5165\u5de5\u5177\u5305 import os import json import torch import numpy as np from collections import Counter import bz2 import jieba from tqdm import tqdm from torch.utils.data import Dataset , DataLoader # \u8bcd\u5d4c\u5165\u5f20\u91cf\u7684\u52a0\u8f7d\u7c7b\u4ee3\u7801 class WordEmbeddingLoader ( object ): def __init__ ( self , config ): self . embedding_path = config . embedding_path self . word_dim = config . word_dim self . train_raw = config . train_raw self . vocab_size = config . vocab_size # \u83b7\u53d6\u8bcd\u5178\u7684\u7c7b\u5185\u51fd\u6570 def get_vocab ( self ): # \u521d\u59cb\u5316\u4e00\u4e2a\u8ba1\u6570\u5668 token_counter = Counter () # \u904d\u5386\u8bad\u7ec3\u96c6\u6570\u636e, \u5c06\u5206\u8bcd\u540e\u7684\u6240\u6709\u4e2d\u6587\u8bcd\u653e\u5165\u8ba1\u6570\u5668\u4e2d with open ( self . train_raw , 'r' , encoding = 'utf-8' ) as f : for line in f . readlines (): data = json . loads ( line ) text = data [ 'text' ] # \u91c7\u7528jieba\u5206\u8bcd\u4f5c\u4e3a\u4e2d\u6587\u573a\u666f\u4e0b\u7684\u5206\u8bcd\u5668 sentence_words = jieba . lcut ( text ) # \u66f4\u65b0\u8ba1\u6570\u5668 token_counter . update ( sentence_words ) # \u6309\u7167\u4eba\u5de5\u8bbe\u7f6e\u9009\u5b9a\u8bcd\u9891\u6700\u9ad8\u7684vocab_size\u4e2a\u4e2d\u6587\u8bcd vocab = set ( token for token , _ in token_counter . most_common ( self . vocab_size )) return vocab # \u83b7\u53d6\u8bcd\u5d4c\u5165\u5411\u91cf\u7684\u7c7b\u5185\u51fd\u6570 def get_embedding ( self , vocab ): print ( 'processing embedding file ...' ) token2embedding = {} # \u6253\u5f00\u65b0\u6d6a\u5fae\u535a\u5f00\u6e90\u7684\u9884\u8bad\u7ec3\u8bcd\u5411\u91cf\u6587\u4ef6 with bz2 . open ( self . embedding_path ) as f : token_vectors = f . readlines () meta_info = token_vectors [ 0 ] . split () print ( f ' { meta_info [ 0 ] } tokens in embedding file in total, vector size is { meta_info [ - 1 ] } ' ) for line in tqdm ( token_vectors [ 1 :]): line = line . split () # \u7b2c\u4e00\u5217\u662f\u5bf9\u5e94\u7684\u4e2d\u6587\u8bcd token = line [ 0 ] . decode ( 'utf-8' ) # \u7b2c\u4e00\u5217\u4e4b\u540e\u90fd\u662f\u6570\u5b57\u5316\u7684\u8bcd\u5411\u91cf vector = line [ 1 :] # \u53ea\u9009\u53d6\u90a3\u4e9b\u5df2\u7ecf\u5728\u8bcd\u5178\u4e2d\u7684\u8bcd\u5411\u91cf\u5b58\u5165\u8bcd\u5411\u91cf\u8bcd\u5178\u4e2d if token in vocab : token2embedding [ token ] = [ float ( num ) for num in vector ] # \u5c064\u4e2a\u7279\u6b8a\u5b57\u7b26\u5360\u636e0,1,2,3\u7684\u6807\u7b7e, \u5176\u4ed6\u5355\u8bcd\u6309\u5e8f\u5411\u540e\u6392\u5217 token2idx = { token : idx for idx , token in enumerate ( token2embedding . keys (), 4 )} UNK , PAD , BOS , EOS = 'UNK' , 'PAD' , 'BOS' , 'EOS' token2idx [ PAD ] = 0 token2idx [ UNK ] = 1 token2idx [ BOS ] = 2 token2idx [ EOS ] = 3 idx2token = { idx : token for token , idx in token2idx . items ()} idx2embedding = { token2idx [ token ]: embedding for token , embedding in token2embedding . items ()} idx2embedding [ 0 ] = [ .0 ] * int ( meta_info [ - 1 ]) idx2embedding [ 1 ] = [ .0 ] * int ( meta_info [ - 1 ]) idx2embedding [ 2 ] = np . random . random ( int ( meta_info [ - 1 ])) . tolist () idx2embedding [ 3 ] = np . random . random ( int ( meta_info [ - 1 ])) . tolist () emb_mat = [ idx2embedding [ idx ] for idx in range ( len ( idx2embedding ))] emb_mat = torch . tensor ( emb_mat , dtype = torch . float ) return emb_mat , token2idx # \u5173\u7cfb\u52a0\u8f7d\u7c7b\u4ee3\u7801 class RelationLoader ( object ): def __init__ ( self , config ): self . data_dir = config . data_dir # \u8bfb\u53d6\u6587\u4ef6\u5c06\u5173\u7cfb\u6620\u5c04\u8868\u52a0\u8f7d\u6210\u5b57\u5178\u7c7b\u578b def __load_relation ( self ): relation_file = os . path . join ( self . data_dir , 'relation2id.txt' ) rel2id = {} id2rel = {} # \u904d\u5386\u5173\u7cfb\u6587\u4ef6\u8fdb\u884c\u6570\u636e\u8bfb\u53d6 with open ( relation_file , 'r' , encoding = 'utf-8' ) as fr : for line in fr : relation , id_s = line . strip () . split () id_d = int ( id_s ) rel2id [ relation ] = id_d id2rel [ id_d ] = relation # \u8fd4\u56de\u4e24\u4e2a\u6620\u5c04\u5b57\u5178, \u4ee5\u53ca\u5173\u7cfb\u6570\u76ee return rel2id , id2rel , len ( rel2id ) # \u5916\u5c42\u63a5\u53e3\u51fd\u6570, \u5185\u90e8\u8c03\u7528\u4e0a\u9762\u7684\u7c7b\u5185\u51fd\u6570 def get_relation ( self ): return self . __load_relation () # \u6784\u5efa\u6570\u636e\u96c6\u7684\u7c7b\u4ee3\u7801 class SemEvalDateset ( Dataset ): def __init__ ( self , filename , rel2id , word2id , config ): self . filename = filename self . rel2id = rel2id self . word2id = word2id self . max_len = config . max_len # \u5728config\u6587\u4ef6\u4e2d\u8bbe\u5b9apos_dis\u9ed8\u8ba4\u503c\u4e3a50 self . pos_dis = config . pos_dis self . data_dir = config . data_dir self . dataset , self . label = self . __load_data () # \u83b7\u53d6\u4f4d\u7f6e\u7d22\u5f15\u7684\u51fd\u6570 def __get_pos_index ( self , x ): # pos_dis\u9ed8\u8ba4\u503c\u4e3a50, \u5df2\u5728config.py\u6587\u4ef6\u4e2d\u8bbe\u7f6e. # 1: \u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u5c0f\u4e8e-50, \u76f4\u63a5\u8fd4\u56de\u4f4d\u7f6e\u7f16\u78010. if x < - self . pos_dis : return 0 # 2: \u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801[-50, 50]\u4e4b\u95f4, \u91c7\u7528x + 50 + 1\u7684\u4f4d\u7f6e\u7f16\u7801\u503c. if x >= - self . pos_dis and x <= self . pos_dis : return x + self . pos_dis + 1 # 3: \u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u5927\u4e8e50, \u91c7\u75282 * 50 + 2 = 102\u7684\u4f4d\u7f6e\u7f16\u7801\u503c. if x > self . pos_dis : return 2 * self . pos_dis + 2 # \u83b7\u53d6\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u7684\u51fd\u6570 def __get_relative_pos ( self , x , entity_pos ): # 1: \u7d22\u5f15x\u5728\u5b9e\u4f53\u7684\u5de6\u4fa7, \u91c7\u7528x - \u5de6\u8fb9\u754c\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801 if x < entity_pos [ 0 ]: return self . __get_pos_index ( x - entity_pos [ 0 ]) # 2: \u7d22\u5f15x\u5728\u5b9e\u4f53\u7684\u53f3\u4fa7, \u91c7\u7528x - \u53f3\u8fb9\u754c\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801 elif x > entity_pos [ 1 ]: return self . __get_pos_index ( x - entity_pos [ 1 ]) # 3: \u7d22\u5f15x\u5728\u5b9e\u4f53\u533a\u57df\u5185, \u91c7\u75280\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801 else : return self . __get_pos_index ( 0 ) # \u5c06\u6587\u672c\u8fdb\u884c\u7b26\u53f7\u5316\u7684\u51fd\u6570, \u6838\u5fc3\u64cd\u4f5c\u5728\u4e8e\u8bbe\u5b9amask\u63a9\u7801\u89c4\u5219 def __symbolize_sentence ( self , e1_pos , e2_pos , sentence ): # e1_pos (tuple) span of e1 # e2_pos (tuple) span of e2 # sentence (list) # \u521d\u59cb\u5316mask\u4e3a\u51681\u7684\u5217\u8868 mask = [ 1 ] * len ( sentence ) # \u60c5\u51b51: \u5982\u679c\u5b9e\u4f531\u5728\u5b9e\u4f532\u7684\u5de6\u4fa7. (e1, e2) if e1_pos [ 0 ] < e2_pos [ 0 ]: # \u4e0b\u9762\u4e24\u4e2afor\u5faa\u73af, \u4f7f\u5f97\u5b9e\u4f531,2\u7684\u533a\u95f4\u88ab\u8d4b\u503c\u62102, \u540e\u9762\u5168\u662f3, \u524d\u9762\u5168\u662f1 # \u7c7b\u4f3c\u6548\u679c: [1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3,3,3] for i in range ( e1_pos [ 0 ], e2_pos [ 1 ] + 1 ): mask [ i ] = 2 for i in range ( e2_pos [ 1 ] + 1 , len ( sentence )): mask [ i ] = 3 # \u60c5\u51b52: \u5982\u679c\u5b9e\u4f531\u5728\u5b9e\u4f532\u7684\u53f3\u4fa7. (e2, e1) else : # \u4e0b\u9762\u4e24\u4e2afor\u5faa\u73af, \u4f7f\u5f97\u5b9e\u4f532,1\u7684\u533a\u95f4\u88ab\u8d4b\u503c\u62102, \u540e\u9762\u5168\u662f3, \u524d\u9762\u5168\u662f1 # \u7c7b\u4f3c\u6548\u679c: [1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3,3,3] for i in range ( e2_pos [ 0 ], e1_pos [ 1 ] + 1 ): mask [ i ] = 2 for i in range ( e1_pos [ 1 ] + 1 , len ( sentence )): mask [ i ] = 3 # \u521d\u59cb\u5316\u82e5\u5e72\u53d8\u91cf words = [] pos1 = [] pos2 = [] length = min ( self . max_len , len ( sentence )) mask = mask [: length ] # \u8fdb\u884c\u6570\u5b57\u5316\u7f16\u7801, \u6dfb\u52a0\u6210\u5217\u8868\u683c\u5f0f for i in range ( length ): words . append ( self . word2id . get ( sentence [ i ] . lower (), self . word2id [ 'UNK' ])) pos1 . append ( self . __get_relative_pos ( i , e1_pos )) pos2 . append ( self . __get_relative_pos ( i , e2_pos )) # \u8fdb\u884c\u957f\u5ea6\u7684\u8865\u9f50\u64cd\u4f5c if length < self . max_len : for i in range ( length , self . max_len ): mask . append ( 0 ) # 'PAD' mask is zero words . append ( self . word2id [ 'PAD' ]) pos1 . append ( self . __get_relative_pos ( i , e1_pos )) pos2 . append ( self . __get_relative_pos ( i , e2_pos )) # \u5c01\u88c5\u6210numpy\u6570\u7ec4\u5e76\u8c03\u6574shape unit = np . asarray ([ words , pos1 , pos2 , mask ], dtype = np . int64 ) unit = np . reshape ( unit , newshape = ( 1 , 4 , self . max_len )) # \u8fd4\u56de\u5c01\u88c5\u597d\u7684\u6570\u7ec4\u5bf9\u8c61 return unit # \u7c7b\u5185\u8d1f\u8d23\u52a0\u8f7d\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u7684\u51fd\u6570 def __load_data ( self ): path_data_file = os . path . join ( self . data_dir , self . filename ) data = [] labels = [] count = 0 # \u6253\u5f00\u6570\u636e\u6587\u4ef6\u5e76\u904d\u5386\u8bfb\u53d6\u6570\u636e with open ( path_data_file , 'r' , encoding = 'utf-8' ) as f : for line in f : line = json . loads ( line . strip ()) # \u5148\u5c06\u539f\u59cb\u6570\u636e\u8bfb\u53d6\u5e76\u63d0\u53d6\u4e0d\u540c\u5b57\u6bb5\u7684\u503c label = line [ 'relation' ] sentence = line [ 'sentence' ] e1_pos = ( line [ 'subj_start' ], line [ 'subj_end' ]) e2_pos = ( line [ 'obj_start' ], line [ 'obj_end' ]) count += 1 label_idx = self . rel2id [ label ] # \u6838\u5fc3\u64cd\u4f5c\u5728\u4e8e\u5c06\u6587\u672c\u8fdb\u884c\u6570\u5b57\u5316\u7f16\u7801 one_sentence = self . __symbolize_sentence ( e1_pos , e2_pos , sentence ) data . append ( one_sentence ) labels . append ( label_idx ) # \u8fd4\u56de\u6570\u5b57\u5316\u6587\u672c\u548c\u5bf9\u5e94\u7684\u6570\u5b57\u5316\u6807\u7b7e return data , labels # \u6309\u7167\u7d22\u5f15\u8bfb\u53d6\u6570\u636e def __getitem__ ( self , index ): data = self . dataset [ index ] label = self . label [ index ] return data , label # \u7c7b\u5185\u6570\u636e\u7684\u957f\u5ea6\u6d4b\u91cf\u51fd\u6570 def __len__ ( self ): return len ( self . label ) # \u6784\u5efa\u6570\u636e\u8fed\u4ee3\u5668\u7684\u7c7b\u4ee3\u7801 class SemEvalDataLoader ( object ): def __init__ ( self , rel2id , word2id , config ): self . rel2id = rel2id self . word2id = word2id self . config = config # \u521b\u5efaDataLoader\u7684\"\u4e2a\u6027\u5316\"\u5904\u7406\u51fd\u6570collate_fn() def __collate_fn ( self , batch ): data , label = zip ( * batch ) data = list ( data ) label = list ( label ) data = torch . from_numpy ( np . concatenate ( data , axis = 0 )) label = torch . from_numpy ( np . asarray ( label , dtype = np . int64 )) return data , label # \u83b7\u53d6\u6570\u636e\u8fed\u4ee3\u5668\u7684\u7c7b\u5185\u51fd\u6570 def __get_data ( self , filename , shuffle = False ): # \u7b2c\u4e00\u6b65: \u8c03\u7528\u6784\u5efa\u6570\u636e\u96c6\u7684\u7c7b\u5bf9\u8c61 dataset = SemEvalDateset ( filename , self . rel2id , self . word2id , self . config ) # \u7b2c\u4e8c\u6b65: \u5728\u6570\u636e\u96c6\u5bf9\u8c61\u7684\u57fa\u7840\u4e0a, \u6784\u5efa\u6570\u636e\u8fed\u4ee3\u5668\u5bf9\u8c61, \u5176\u4e2d\u91c7\u7528\u81ea\u5b9a\u4e49\u7684\u4e2a\u6027\u5316\u5904\u7406\u51fd\u6570 loader = DataLoader ( dataset = dataset , batch_size = self . config . batch_size , shuffle = shuffle , num_workers = 4 , collate_fn = self . __collate_fn ) return loader # \u83b7\u53d6\u8bad\u7ec3\u6570\u636e\u8fed\u4ee3\u5668\u7684\u5bf9\u5916\u63a5\u53e3 def get_train ( self ): return self . __get_data ( 'train.json' , shuffle = True ) # \u83b7\u53d6\u9a8c\u8bc1\u6570\u636e\u8fed\u4ee3\u5668\u7684\u5bf9\u5916\u63a5\u53e3(\u9a8c\u8bc1\u96c6\u4f7f\u7528\u6d4b\u8bd5\u96c6\u4ee3\u66ff) def get_dev ( self ): return self . __get_data ( 'test.json' , shuffle = False ) # \u83b7\u53d6\u6d4b\u8bd5\u6570\u636e\u8fed\u4ee3\u5668\u7684\u5bf9\u5916\u63a5\u53e3 def get_test ( self ): return self . __get_data ( 'test.json' , shuffle = False ) if __name__ == '__main__' : from config import Config config = Config () vocab = WordEmbeddingLoader ( config ) . get_vocab () word_vec , word2id = WordEmbeddingLoader ( config ) . get_embedding ( vocab ) rel2id , id2rel , class_num = RelationLoader ( config ) . get_relation () loader = SemEvalDataLoader ( rel2id , word2id , config ) test_loader = loader . get_train () min_v , max_v = float ( 'inf' ), - float ( 'inf' ) for step , ( data , label ) in enumerate ( test_loader ): # print(type(data), data.shape) # print(type(label), label.shape) # break pos1 = data [:, 1 , :] . view ( - 1 , config . max_len ) pos2 = data [:, 2 , :] . view ( - 1 , config . max_len ) mask = data [:, 3 , :] . view ( - 1 , config . max_len ) min_v = min ( min_v , torch . min ( pos1 ) . item ()) max_v = max ( max_v , torch . max ( pos1 ) . item ()) min_v = min ( min_v , torch . min ( pos2 ) . item ()) max_v = max ( max_v , torch . max ( pos2 ) . item ()) print ( min_v , max_v ) \u6a21\u578b\u7c7b\u7684\u5b9e\u73b0 \u00b6 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/cnn_medical/model.py # \u5bfc\u5165\u5de5\u5177\u5305 import torch import torch.nn as nn import torch.nn.functional as F from torch.nn import init class CNN ( nn . Module ): def __init__ ( self , word_vec , class_num , config ): super () . __init__ () # \u521d\u59cb\u5316\u5173\u952e\u53c2\u6570 self . word_vec = word_vec self . class_num = class_num self . max_len = config . max_len self . word_dim = config . word_dim self . pos_dim = config . pos_dim self . pos_dis = config . pos_dis self . dropout_value = config . dropout self . filter_num = config . filter_num self . window = config . window self . hidden_size = config . hidden_size # dim\u7ef4\u5ea6\u8bbe\u7f6e\u4e3a\u8bcd\u5d4c\u5165\u7684\u7ef4\u5ea6 + 2\u4e2a\u5355\u8bcd\u7684\u4f4d\u7f6e\u7f16\u7801\u7ef4\u5ea6 self . dim = self . word_dim + 2 * self . pos_dim # 1: \u4efb\u610f\u4e00\u4e2a\u5355\u8bcd\u5d4c\u5165\u5f20\u91cf, 2: \u7b2c\u4e00\u4e2a\u5355\u8bcd\u7684\u4f4d\u7f6e\u5d4c\u5165\u5f20\u91cf, 3: \u7b2c\u4e8c\u4e2a\u5355\u8bcd\u7684\u4f4d\u7f6e\u5d4c\u5165\u5f20\u91cf self . word_embedding = nn . Embedding . from_pretrained ( embeddings = self . word_vec , freeze = False ) self . pos1_embedding = nn . Embedding ( num_embeddings = 2 * self . pos_dis + 3 , embedding_dim = self . pos_dim ) self . pos2_embedding = nn . Embedding ( num_embeddings = 2 * self . pos_dis + 3 , embedding_dim = self . pos_dim ) # CNN\u7684\u6838\u5fc3\u64cd\u4f5c, \u4e8c\u7ef4\u5377\u79ef self . conv = nn . Conv2d ( in_channels = 1 , out_channels = self . filter_num , kernel_size = ( self . window , self . dim ), stride = ( 1 , 1 ), bias = True , padding = ( 1 , 0 ), padding_mode = 'zeros' ) # \u8bbe\u7f6e\u6700\u5927\u6c60\u5316\u5c42, \u6fc0\u6d3b\u5c42, Dropout\u5c42 self . maxpool = nn . MaxPool2d (( self . max_len , 1 )) self . tanh = nn . Tanh () self . dropout = nn . Dropout ( self . dropout_value ) # \u5377\u79ef\u5c42\u5411\u4e0b\u4e00\u5c42\u7684\u6620\u5c04\u77e9\u9635, \u4ece\u5377\u79ef\u6838\u6570\u91cf -> \u9690\u85cf\u5c42\u7ef4\u5ea6 self . linear = nn . Linear ( in_features = self . filter_num , out_features = self . hidden_size , bias = True ) # \u6574\u4e2a\u7f51\u7edc\u7684\u8f93\u51fa\u5c42, \u4ece\u9690\u85cf\u5c42\u7ef4\u5ea6 -> \u5206\u7c7b\u6570\u91cf self . dense = nn . Linear ( in_features = self . hidden_size , out_features = self . class_num , bias = True ) # \u521d\u59cb\u5316\u7f51\u7edc\u4e2d\u7684\u4e00\u4e9b\u6743\u91cd init . xavier_normal_ ( self . pos1_embedding . weight ) init . xavier_normal_ ( self . pos2_embedding . weight ) init . xavier_normal_ ( self . conv . weight ) init . constant_ ( self . conv . bias , 0. ) init . xavier_normal_ ( self . linear . weight ) init . constant_ ( self . linear . bias , 0. ) init . xavier_normal_ ( self . dense . weight ) init . constant_ ( self . dense . bias , 0. ) # \u7f16\u7801\u5c42\u51fd\u6570 def encoder_layer ( self , token , pos1 , pos2 ): # word_emb: [batch_size, seq_len, word_dim] word_emb = self . word_embedding ( token ) # pos1_emb: [batch_size, seq_len, pos_dim] pos1_emb = self . pos1_embedding ( pos1 ) # pos2_emb: [batch_size, seq_len, pos_dim] pos2_emb = self . pos2_embedding ( pos2 ) # \u6700\u7ec8\u7684\u5d4c\u5165\u5f20\u91cf, \u662f3\u4e2a\u5b50\u90e8\u5206\u7684\u7b80\u5355\u62fc\u63a5 emb = torch . cat ( tensors = [ word_emb , pos1_emb , pos2_emb ], dim =- 1 ) # emb: [batch_size, seq_len, word_dim + 2 * pos_dim] return emb # \u5377\u79ef\u5c42\u51fd\u6570 def conv_layer ( self , emb , mask ): # emb: [batch_size, 1, seq_len, dim] emb = emb . unsqueeze ( dim = 1 ) # conv: [batch_size, filter_num, seq_len, 1] conv = self . conv ( emb ) # conv: [batch_size, filter_num, seq_len] conv = conv . view ( - 1 , self . filter_num , self . max_len ) # mask: [batch_size, 1, seq_len] mask = mask . unsqueeze ( dim = 1 ) # mask: [batch_size, filter_num, seq_len] mask = mask . expand ( - 1 , self . filter_num , - 1 ) # \u6240\u6709mask\u5f20\u91cf\u7b49\u4e8e0\u7684\u4f4d\u7f6e, \u90fd\u7528'-inf'\u586b\u5145, \u7b49\u6548\u4e8e\u6570\u5b66\u4e0a\u7684\u906e\u63a9 conv = conv . masked_fill_ ( mask . eq ( 0 ), float ( '-inf' )) # conv: [batch_size, filter_num, seq_len, 1] conv = conv . unsqueeze ( dim =- 1 ) return conv # \u6700\u5927\u6c60\u5316\u7684\u64cd\u4f5c\u51fd\u6570 def single_maxpool_layer ( self , conv ): # pool: [batch_size, filter_num, 1, 1] pool = self . maxpool ( conv ) # pool: [batch_size, filter_num] pool = pool . view ( - 1 , self . filter_num ) return pool def forward ( self , data ): # \u4f9d\u6b21\u53d6\u51fa\u6570\u636e, \u5e76\u5c06\u5f20\u91cf\u7684shape\u8f6c\u53d8\u6210[X, seq_len] token = data [:, 0 , :] . view ( - 1 , self . max_len ) pos1 = data [:, 1 , :] . view ( - 1 , self . max_len ) pos2 = data [:, 2 , :] . view ( - 1 , self . max_len ) mask = data [:, 3 , :] . view ( - 1 , self . max_len ) # 1: \u9996\u5148\u8fdb\u5165\u7f16\u7801\u5668\u8fdb\u884c\u7f16\u7801 emb = self . encoder_layer ( token , pos1 , pos2 ) # 2: \u5bf9\u8f93\u51fa\u5f20\u91cf\u8fdb\u884cDropout\u64cd\u4f5c emb = self . dropout ( emb ) # 3: \u5377\u79ef\u64cd\u4f5c\u662fCNN\u7684\u6838\u5fc3 conv = self . conv_layer ( emb , mask ) # 4: \u6700\u5927\u6c60\u5316\u7684\u64cd\u4f5c pool = self . single_maxpool_layer ( conv ) # 5: \u5168\u8fde\u63a5\u5c42\u7684\u6620\u5c04\u64cd\u4f5c sentence_feature = self . linear ( pool ) # 6: \u6fc0\u6d3b\u5c42\u8fd0\u7b97 sentence_feature = self . tanh ( sentence_feature ) # 7: \u518d\u6b21\u8fdb\u884cDropout\u64cd\u4f5c sentence_feature = self . dropout ( sentence_feature ) # 8: \u6700\u540e\u8fdb\u884c\u5168\u8fde\u63a5\u5c42\u7684\u6620\u5c04, logits\u5bf9\u5e94\u5206\u7c7b\u6570\u76ee logits = self . dense ( sentence_feature ) return logits \u8bad\u7ec3\u4e0e\u8bc4\u4f30\u51fd\u6570\u7684\u5b9e\u73b0 \u00b6 \u8bc4\u4f30\u51fd\u6570\u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/cnn_medical/evaluate.py # \u5bfc\u5165\u5de5\u5177\u5305 import numpy as np import torch from tqdm import tqdm import math # \u8ba1\u7b97\u8bc4\u4f30\u5206\u6570\u7684\u51fd\u6570 def semeval_scorer ( predict_label , true_label , class_num = 50 ): assert true_label . shape [ 0 ] == predict_label . shape [ 0 ] # \u8bbe\u7f6e\u56f0\u60d1\u77e9\u9635, \u5168\u96f6\u521d\u59cb\u5316\u5373\u53ef confusion_matrix = np . zeros ( shape = [ class_num , class_num ], dtype = np . float32 ) xDIRx = np . zeros ( shape = [ class_num ], dtype = np . float32 ) # \u904d\u5386\u6240\u6709\u6837\u672c\u6807\u7b7e, \u6bd4\u8f83\u6b63\u786e\u7684\u9884\u6d4b, \u9519\u8bef\u7684\u9884\u6d4b for i in range ( true_label . shape [ 0 ]): # \u83b7\u53d6\u771f\u5b9e\u6807\u7b7e, \u9884\u6d4b\u6807\u7b7e true_idx = math . ceil ( true_label [ i ] / 2 ) predict_idx = math . ceil ( predict_label [ i ] / 2 ) # \u6784\u9020\u56f0\u60d1\u77e9\u9635, \u6bcf\u6b63\u786e\u9884\u6d4b\u4e00\u4e2a\u6837\u672c, \u5bf9\u5e94\u7684\u5206\u7c7b\u503c+1 if true_label [ i ] == predict_label [ i ]: confusion_matrix [ predict_idx ][ true_idx ] += 1 else : if true_idx == predict_idx : xDIRx [ predict_idx ] += 1 else : confusion_matrix [ predict_idx ][ true_idx ] += 1 col_sum = np . sum ( confusion_matrix , axis = 0 ) . reshape ( - 1 ) row_sum = np . sum ( confusion_matrix , axis = 1 ) . reshape ( - 1 ) f1 = np . zeros ( shape = [ class_num ], dtype = np . float32 ) # \u5ffd\u7565\u6389'Other' for i in range ( 0 , class_num ): try : p = float ( confusion_matrix [ i ][ i ]) / float ( col_sum [ i ] + xDIRx [ i ]) r = float ( confusion_matrix [ i ][ i ]) / float ( row_sum [ i ] + xDIRx [ i ]) f1 [ i ] = ( 2 * p * r / ( p + r )) except : pass actual_class = 0 total_f1 = 0.0 for i in range ( 1 , class_num ): # \u4e0d\u5728\u9884\u6d4b\u6807\u7b7e\u4e2d\u7684\u5206\u7c7b, \u4e0d\u505a\u8003\u8651 if f1 [ i ] > 0.0 : actual_class += 1 total_f1 += f1 [ i ] # \u9632\u6b62\u9664\u96f6\u9519\u8bef try : macro_f1 = total_f1 / actual_class except : macro_f1 = 0.0 return macro_f1 # \u6784\u5efa\u8bc4\u4f30\u7c7b\u7684\u4ee3\u7801 class Eval ( object ): def __init__ ( self , config ): self . device = config . device def evaluate ( self , model , criterion , data_loader ): predict_label = [] true_label = [] total_loss = 0.0 # \u8bc4\u4f30\u9636\u6bb5, \u8bbe\u7f6e\u8bc4\u4f30\u6a21\u5f0f, \u5e76\u4e14\u4e0d\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u548c\u68af\u5ea6\u8ba1\u7b97 with torch . no_grad (): model . eval () for _ , ( data , label ) in tqdm ( enumerate ( data_loader )): data = data . to ( self . device ) label = label . to ( self . device ) # print('data.shape:', data.shape) # print('label:', label) # \u5c06\u8f93\u5165\u9001\u5165\u6a21\u578b, \u5f97\u5230\u6982\u7387\u5206\u5e03\u8f93\u51fa, \u8ba1\u7b97\u635f\u5931\u503c logits = model ( data ) loss = criterion ( logits , label ) total_loss += loss . item () * logits . shape [ 0 ] # print('logits:', logits) _ , pred = torch . max ( logits , dim = 1 ) # print('pred:', pred) pred = pred . cpu () . detach () . numpy () . reshape (( - 1 , 1 )) label = label . cpu () . detach () . numpy () . reshape (( - 1 , 1 )) # print('pred1:', pred) # print('******') predict_label . append ( pred ) true_label . append ( label ) # \u5c06\u6240\u6709batch\u7684\u9884\u6d4b\u7ed3\u679c\u548c\u771f\u5b9e\u7ed3\u679c, \u8fdb\u884c\u62fc\u63a5 predict_label = np . concatenate ( predict_label , axis = 0 ) . reshape ( - 1 ) . astype ( np . int64 ) true_label = np . concatenate ( true_label , axis = 0 ) . reshape ( - 1 ) . astype ( np . int64 ) eval_loss = total_loss / predict_label . shape [ 0 ] # \u8c03\u7528\u4e0a\u9762\u7684\u8bc4\u4f30\u5206\u6570\u51fd\u6570, \u5f97\u5230\u6d4b\u8bd5\u96c6\u4e0a\u603b\u4f53\u7684F1\u503c f1 = semeval_scorer ( predict_label , true_label ) return f1 , eval_loss , predict_label \u8bad\u7ec3\u51fd\u6570\u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/cnn_medical/run.py # \u5bfc\u5165\u5de5\u5177\u5305 import os import torch import torch.nn as nn import torch.optim as optim from config import Config from utils import WordEmbeddingLoader , RelationLoader , SemEvalDataLoader from model import CNN from evaluate import Eval from tqdm import tqdm # \u5c06\u63a8\u7406\u540e\u7684\u7ed3\u679c\u5199\u5165\u6587\u4ef6\u4e2d def print_result ( predict_label , id2rel , start_idx = 8001 ): with open ( 'predicted_result.txt' , 'w' , encoding = 'utf-8' ) as fw : for i in range ( 0 , predict_label . shape [ 0 ]): fw . write ( ' {} \\t {} \\n ' . format ( start_idx + i , id2rel [ int ( predict_label [ i ])])) # \u6a21\u578b\u7684\u603b\u4f53\u8bad\u7ec3\u51fd\u6570 def train ( model , criterion , loader , config ): train_loader , dev_loader , _ = loader optimizer = optim . Adam ( model . parameters (), lr = config . lr , weight_decay = config . L2_decay ) # \u4e0b\u97627\u884c\u4ee3\u7801\u4e3a\u663e\u793a\u4fe1\u606f\u7684\u8c03\u8bd5\u4ee3\u7801, \u4e0a\u7ebf\u540e\u53ef\u4ee5\u6ce8\u91ca\u6389 print ( model ) print ( 'traning model parameters:' ) for name , param in model . named_parameters (): if param . requires_grad : print ( ' %s : %s ' % ( name , str ( param . data . shape ))) print ( '--------------------------------------' ) print ( 'start to train the model ...' ) # \u8bc4\u4f30\u7c7b\u7684\u5bf9\u8c61, \u7528\u4e8e\u5bf9\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u8ba1\u7b97F1\u503c eval_tool = Eval ( config ) max_f1 = - float ( 'inf' ) # \u53cc\u91cdfor\u5faa\u73af\u6a21\u5f0f\u8fdb\u884c\u8bad\u7ec3 for epoch in tqdm ( range ( 1 , config . epoch + 1 )): model . train () for step , ( data , label ) in enumerate ( train_loader ): data = data . to ( config . device ) label = label . to ( config . device ) # \u7ecf\u5178\u7684\"\u8001\u4e09\u6837\" + \u6a21\u578b\u524d\u5411\u8ba1\u7b97 + \u635f\u5931\u503c\u8ba1\u7b97 optimizer . zero_grad () logits = model ( data ) loss = criterion ( logits , label ) loss . backward () optimizer . step () # \u6bcf\u4e00\u4e2aepoch\u7ed3\u675f\u540e, \u8fdb\u884c\u4e00\u8f6e\u8bad\u7ec3\u96c6\u7684\u8bc4\u4f30\u548c\u9a8c\u8bc1\u96c6\u7684\u8bc4\u4f30 _ , train_loss , _ = eval_tool . evaluate ( model , criterion , train_loader ) f1 , dev_loss , _ = eval_tool . evaluate ( model , criterion , dev_loader ) # \u5c06\u5173\u952e\u8bc4\u4f30\u7ed3\u679c\u6253\u5370\u51fa\u6765 print ( '[ %03d ] train_loss: %.3f | dev_loss: %.3f | micro f1 on dev: %.4f ' % ( epoch , train_loss , dev_loss , f1 ), end = ' ' ) # \u4ee5F1\u503c\u4f5c\u4e3a\u6807\u51c6, \u5c06\u8868\u73b0\u6700\u4f18\u7684\u6a21\u578b\u4fdd\u5b58\u4e0b\u6765 if f1 > max_f1 : max_f1 = f1 torch . save ( model . state_dict (), os . path . join ( config . model_dir , 'model.pt' )) print ( '>>> save models!' ) else : print () # \u6d4b\u8bd5\u51fd\u6570 def test ( model , criterion , loader , config ): print ( '--------------------------------------' ) print ( 'start test ...' ) _ , _ , test_loader = loader model . load_state_dict ( torch . load ( os . path . join ( config . model_dir , 'model.pt' ))) eval_tool = Eval ( config ) f1 , test_loss , predict_label = eval_tool . evaluate ( model , criterion , test_loader ) print ( 'test_loss: %.3f | micro f1 on test: %.4f ' % ( test_loss , f1 )) return predict_label # \u6700\u5916\u5c42\u63a5\u53e3, \u8c03\u8d77\u5168\u90e8\u51fd\u6570 if __name__ == '__main__' : config = Config () print ( '--------------------------------------' ) print ( 'some config:' ) config . print_config () print ( '--------------------------------------' ) print ( 'start to load data ...' ) vocab = WordEmbeddingLoader ( config ) . get_vocab () word_vec , word2id = WordEmbeddingLoader ( config ) . get_embedding ( vocab ) rel2id , id2rel , class_num = RelationLoader ( config ) . get_relation () loader = SemEvalDataLoader ( rel2id , word2id , config ) train_loader , dev_loader = None , None # mode\u8bbe\u7f6e\u4e3a1, \u4ee3\u8868\u8bad\u7ec3\u6a21\u5f0f if config . mode == 1 : train_loader = loader . get_train () dev_loader = loader . get_dev () test_loader = loader . get_test () loader = [ train_loader , dev_loader , test_loader ] print ( 'finish!' ) print ( '--------------------------------------' ) model = CNN ( word_vec = word_vec , class_num = class_num , config = config ) model = model . to ( config . device ) criterion = nn . CrossEntropyLoss () # model\u7b49\u4e8e1, \u5904\u4e8e\u8bad\u7ec3\u6a21\u5f0f if config . mode == 1 : train ( model , criterion , loader , config ) # \u5bf9\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\u5e76\u6253\u5370\u7ed3\u679c\u6587\u4ef6 predict_label = test ( model , criterion , loader , config ) print_result ( predict_label , id2rel ) \u8c03\u7528: python run.py \u8f93\u51fa\u7ed3\u679c: some config: data_dir = ./data output_dir = ./output train_raw = ./data/CMeIE_train.json embedding_path = ./embedding/sgns.weibo.word.bz2 vocab_size = 30000 word_dim = 300 model_name = CNN mode = 1 seed = 5782 cuda = 0 epoch = 50 dropout = 0.5 batch_size = 64 lr = 0.001 max_len = 100 pos_dis = 50 pos_dim = 5 hidden_size = 128 filter_num = 256 window = 3 L2_decay = 1e-05 device = cuda:0 model_dir = ./output/CNN -------------------------------------- start to load data ... Building prefix dict from the default dictionary ... Loading model from cache /tmp/jieba.cache Loading model cost 0.760 seconds. Prefix dict has been built successfully. processing embedding file ... b'195202' tokens in embedding file in total, vector size is b'300' 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 195202/195202 [00:03<00:00, 55842.67it/s] finish! -------------------------------------- CNN( (word_embedding): Embedding(11723, 300) (pos1_embedding): Embedding(103, 5) (pos2_embedding): Embedding(103, 5) (conv): Conv2d(1, 256, kernel_size=(3, 310), stride=(1, 1), padding=(1, 0)) (maxpool): MaxPool2d(kernel_size=(100, 1), stride=(100, 1), padding=0, dilation=1, ceil_mode=False) (tanh): Tanh() (dropout): Dropout(p=0.5, inplace=False) (linear): Linear(in_features=256, out_features=128, bias=True) (dense): Linear(in_features=128, out_features=53, bias=True) ) traning model parameters: word_embedding.weight : torch.Size([11723, 300]) pos1_embedding.weight : torch.Size([103, 5]) pos2_embedding.weight : torch.Size([103, 5]) conv.weight : torch.Size([256, 1, 3, 310]) conv.bias : torch.Size([256]) linear.weight : torch.Size([128, 256]) linear.bias : torch.Size([128]) dense.weight : torch.Size([53, 128]) dense.bias : torch.Size([53]) -------------------------------------- start to train the model ... 756it [00:01, 400.37it/s] | 0/50 [00:00<?, ?it/s] 93it [00:00, 321.20it/s]] [001] train_loss: 0.825 | dev_loss: 1.145 | micro f1 on dev: 0.6200 >>> save models! 756it [00:01, 401.55it/s] | 1/50 [00:08<07:03, 8.64s/it] 93it [00:00, 323.06it/s]] [002] train_loss: 0.466 | dev_loss: 0.999 | micro f1 on dev: 0.6643 >>> save models! 756it [00:01, 400.84it/s] | 2/50 [00:16<06:49, 8.53s/it] 93it [00:00, 314.22it/s]] [003] train_loss: 0.314 | dev_loss: 0.955 | micro f1 on dev: 0.7100 >>> save models! 756it [00:01, 401.99it/s] | 3/50 [00:25<06:37, 8.46s/it] 93it [00:00, 323.06it/s]] [004] train_loss: 0.239 | dev_loss: 0.994 | micro f1 on dev: 0.7169 >>> save models! 756it [00:01, 396.38it/s] | 4/50 [00:33<06:28, 8.44s/it] 93it [00:00, 323.16it/s]] [005] train_loss: 0.196 | dev_loss: 0.973 | micro f1 on dev: 0.7198 >>> save models! 756it [00:01, 389.98it/s] | 5/50 [00:41<06:18, 8.41s/it] 93it [00:00, 320.01it/s]] [006] train_loss: 0.154 | dev_loss: 0.999 | micro f1 on dev: 0.7152 756it [00:01, 400.31it/s] | 6/50 [00:50<06:08, 8.38s/it] 93it [00:00, 316.25it/s]] [007] train_loss: 0.136 | dev_loss: 0.999 | micro f1 on dev: 0.7112 756it [00:01, 400.90it/s] | 7/50 [00:58<05:58, 8.34s/it] 93it [00:00, 323.26it/s]] [008] train_loss: 0.122 | dev_loss: 1.039 | micro f1 on dev: 0.7243 >>> save models! 756it [00:01, 388.92it/s] | 8/50 [01:06<05:50, 8.34s/it] 93it [00:00, 316.58it/s]] [009] train_loss: 0.102 | dev_loss: 1.059 | micro f1 on dev: 0.7322 >>> save models! 756it [00:01, 390.39it/s] | 9/50 [01:15<05:42, 8.36s/it] 93it [00:00, 323.51it/s]] [010] train_loss: 0.094 | dev_loss: 1.063 | micro f1 on dev: 0.7156 756it [00:01, 395.49it/s] | 10/50 [01:23<05:34, 8.35s/it] 93it [00:00, 326.63it/s]] [011] train_loss: 0.084 | dev_loss: 1.090 | micro f1 on dev: 0.7295 756it [00:01, 399.23it/s] | 11/50 [01:31<05:24, 8.33s/it] 93it [00:00, 308.80it/s]] [012] train_loss: 0.078 | dev_loss: 1.089 | micro f1 on dev: 0.7195 756it [00:01, 393.74it/s] | 12/50 [01:40<05:16, 8.33s/it] 93it [00:00, 309.83it/s]] [013] train_loss: 0.069 | dev_loss: 1.143 | micro f1 on dev: 0.7288 756it [00:01, 388.05it/s] | 13/50 [01:48<05:08, 8.34s/it] 93it [00:00, 312.54it/s]] [014] train_loss: 0.067 | dev_loss: 1.195 | micro f1 on dev: 0.7193 756it [00:01, 391.20it/s] | 14/50 [01:56<05:00, 8.34s/it] 93it [00:00, 314.68it/s]] [015] train_loss: 0.059 | dev_loss: 1.144 | micro f1 on dev: 0.7165 756it [00:01, 393.72it/s]\u2588 | 15/50 [02:05<04:52, 8.35s/it] 93it [00:00, 320.70it/s]] [016] train_loss: 0.056 | dev_loss: 1.148 | micro f1 on dev: 0.6821 756it [00:01, 382.80it/s]\u2588\u2588\u258d | 16/50 [02:13<04:44, 8.35s/it] 93it [00:00, 318.80it/s]] [017] train_loss: 0.053 | dev_loss: 1.123 | micro f1 on dev: 0.7317 756it [00:01, 391.59it/s]\u2588\u2588\u2588\u258a | 17/50 [02:22<04:36, 8.37s/it] 93it [00:00, 320.01it/s]] [018] train_loss: 0.050 | dev_loss: 1.156 | micro f1 on dev: 0.7513 >>> save models! 756it [00:01, 390.35it/s]\u2588\u2588\u2588\u2588\u2588\u258f | 18/50 [02:30<04:29, 8.41s/it] 93it [00:00, 314.89it/s]] [019] train_loss: 0.046 | dev_loss: 1.125 | micro f1 on dev: 0.7299 756it [00:01, 384.87it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 19/50 [02:38<04:20, 8.41s/it] 93it [00:00, 319.72it/s]] [020] train_loss: 0.045 | dev_loss: 1.172 | micro f1 on dev: 0.7255 756it [00:01, 386.72it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 20/50 [02:47<04:12, 8.41s/it] 93it [00:00, 318.43it/s]] [021] train_loss: 0.040 | dev_loss: 1.195 | micro f1 on dev: 0.7018 756it [00:01, 395.28it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 21/50 [02:55<04:04, 8.43s/it] 93it [00:00, 318.02it/s]] [022] train_loss: 0.043 | dev_loss: 1.178 | micro f1 on dev: 0.7164 756it [00:01, 390.67it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 22/50 [03:04<03:55, 8.41s/it] 93it [00:00, 315.83it/s]] [023] train_loss: 0.038 | dev_loss: 1.153 | micro f1 on dev: 0.7326 756it [00:01, 390.15it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 23/50 [03:12<03:47, 8.42s/it] 93it [00:00, 320.54it/s]] [024] train_loss: 0.035 | dev_loss: 1.191 | micro f1 on dev: 0.7195 756it [00:01, 390.48it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 24/50 [03:21<03:38, 8.42s/it] 93it [00:00, 315.26it/s]] [025] train_loss: 0.033 | dev_loss: 1.187 | micro f1 on dev: 0.7206 756it [00:01, 384.46it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 25/50 [03:29<03:30, 8.43s/it] 93it [00:00, 315.56it/s]] [026] train_loss: 0.030 | dev_loss: 1.191 | micro f1 on dev: 0.7059 756it [00:01, 392.18it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 26/50 [03:37<03:22, 8.44s/it] 93it [00:00, 304.06it/s]] [027] train_loss: 0.030 | dev_loss: 1.185 | micro f1 on dev: 0.7271 756it [00:01, 389.80it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 27/50 [03:46<03:14, 8.44s/it] 93it [00:00, 310.55it/s]] [028] train_loss: 0.030 | dev_loss: 1.193 | micro f1 on dev: 0.7057 756it [00:01, 379.01it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 28/50 [03:54<03:05, 8.45s/it] 93it [00:00, 312.63it/s]] [029] train_loss: 0.028 | dev_loss: 1.243 | micro f1 on dev: 0.7497 756it [00:01, 387.16it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 29/50 [04:03<02:57, 8.47s/it] 93it [00:00, 310.71it/s]] [030] train_loss: 0.029 | dev_loss: 1.235 | micro f1 on dev: 0.7416 756it [00:01, 387.02it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 30/50 [04:11<02:49, 8.47s/it] 93it [00:00, 321.98it/s]] [031] train_loss: 0.026 | dev_loss: 1.230 | micro f1 on dev: 0.7244 756it [00:01, 388.13it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 31/50 [04:20<02:40, 8.47s/it] 93it [00:00, 319.43it/s]] [032] train_loss: 0.028 | dev_loss: 1.226 | micro f1 on dev: 0.7267 756it [00:01, 387.05it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 32/50 [04:28<02:32, 8.46s/it] 93it [00:00, 315.43it/s]] [033] train_loss: 0.025 | dev_loss: 1.246 | micro f1 on dev: 0.7370 756it [00:01, 390.52it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 33/50 [04:37<02:24, 8.47s/it] 93it [00:00, 320.73it/s]] [034] train_loss: 0.023 | dev_loss: 1.216 | micro f1 on dev: 0.7383 756it [00:01, 380.61it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 34/50 [04:45<02:15, 8.47s/it] 93it [00:00, 303.98it/s]] [035] train_loss: 0.022 | dev_loss: 1.253 | micro f1 on dev: 0.7239 756it [00:01, 384.96it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 35/50 [04:54<02:07, 8.49s/it] 93it [00:00, 320.49it/s]] [036] train_loss: 0.025 | dev_loss: 1.306 | micro f1 on dev: 0.7067 756it [00:01, 386.49it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 36/50 [05:02<01:58, 8.49s/it] 93it [00:00, 316.58it/s]] [037] train_loss: 0.021 | dev_loss: 1.293 | micro f1 on dev: 0.7109 756it [00:01, 389.53it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 37/50 [05:11<01:50, 8.48s/it] 93it [00:00, 312.16it/s]] [038] train_loss: 0.021 | dev_loss: 1.264 | micro f1 on dev: 0.7156 756it [00:01, 384.69it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 38/50 [05:19<01:41, 8.48s/it] 93it [00:00, 314.61it/s]] [039] train_loss: 0.020 | dev_loss: 1.275 | micro f1 on dev: 0.7333 756it [00:01, 389.65it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 39/50 [05:28<01:33, 8.48s/it] 93it [00:00, 314.57it/s]] [040] train_loss: 0.024 | dev_loss: 1.233 | micro f1 on dev: 0.7171 756it [00:01, 384.13it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 40/50 [05:36<01:24, 8.47s/it] 93it [00:00, 306.72it/s]] [041] train_loss: 0.019 | dev_loss: 1.287 | micro f1 on dev: 0.7411 756it [00:01, 390.68it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 41/50 [05:45<01:16, 8.48s/it] 93it [00:00, 318.88it/s]] [042] train_loss: 0.021 | dev_loss: 1.321 | micro f1 on dev: 0.7298 756it [00:01, 389.55it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 42/50 [05:53<01:07, 8.47s/it] 93it [00:00, 320.90it/s]] [043] train_loss: 0.018 | dev_loss: 1.256 | micro f1 on dev: 0.7520 >>> save models! 756it [00:01, 392.47it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 43/50 [06:02<00:59, 8.51s/it] 93it [00:00, 312.12it/s]] [044] train_loss: 0.018 | dev_loss: 1.284 | micro f1 on dev: 0.7397 756it [00:01, 382.02it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 44/50 [06:10<00:50, 8.50s/it] 93it [00:00, 316.05it/s]] [045] train_loss: 0.018 | dev_loss: 1.250 | micro f1 on dev: 0.7342 756it [00:01, 384.63it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 45/50 [06:19<00:42, 8.51s/it] 93it [00:00, 316.54it/s]] [046] train_loss: 0.018 | dev_loss: 1.288 | micro f1 on dev: 0.7446 756it [00:01, 387.57it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 46/50 [06:27<00:34, 8.50s/it] 93it [00:00, 309.89it/s]] [047] train_loss: 0.017 | dev_loss: 1.250 | micro f1 on dev: 0.7419 756it [00:01, 385.43it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 47/50 [06:36<00:25, 8.49s/it] 93it [00:00, 312.21it/s]] [048] train_loss: 0.018 | dev_loss: 1.282 | micro f1 on dev: 0.7186 756it [00:01, 381.55it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 48/50 [06:44<00:16, 8.49s/it] 93it [00:00, 310.74it/s]] [049] train_loss: 0.016 | dev_loss: 1.321 | micro f1 on dev: 0.7359 756it [00:01, 387.89it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 49/50 [06:53<00:08, 8.51s/it] 93it [00:00, 314.01it/s]] [050] train_loss: 0.017 | dev_loss: 1.296 | micro f1 on dev: 0.7193 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50/50 [07:01<00:00, 8.43s/it] -------------------------------------- start test ... 93it [00:00, 301.00it/s] test_loss: 1.256 | micro f1 on test: 0.7520 \u601d\u8003: \u5bf9\u4e8e\u5f53\u524d\u9879\u76ee\u4e2d\u768453\u79cd\u5173\u7cfb\u62bd\u53d6\u6a21\u578b, f1\u8fbe\u523075.20%\u7b97\u597d\u7684\u8868\u73b0\u5417? \u63a8\u7406\u4ee3\u7801\u7684\u5b9e\u73b0 \u00b6 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/cnn_medical/predict.py import numpy as np import torch import time from torch.utils.data import Dataset , DataLoader from config import Config from utils import * from model import CNN config = Config () vocab = WordEmbeddingLoader ( config ) . get_vocab () word_vec , word2id = WordEmbeddingLoader ( config ) . get_embedding ( vocab ) rel2id , id2rel , class_num = RelationLoader ( config ) . get_relation () def get_pos_index ( x ): # pos_dis\u9ed8\u8ba4\u503c\u4e3a50, \u5df2\u5728config.py\u6587\u4ef6\u4e2d\u8bbe\u7f6e. # 1: \u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u5c0f\u4e8e-50, \u76f4\u63a5\u8fd4\u56de\u4f4d\u7f6e\u7f16\u78010. if x < - config . pos_dis : return 0 # 2: \u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801[-50, 50]\u4e4b\u95f4, \u91c7\u7528x + 50 + 1\u7684\u4f4d\u7f6e\u7f16\u7801\u503c. if x >= - config . pos_dis and x <= config . pos_dis : return x + config . pos_dis + 1 # 3: \u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u5927\u4e8e50, \u91c7\u75282 * 50 + 2 = 102\u7684\u4f4d\u7f6e\u7f16\u7801\u503c. if x > config . pos_dis : return 2 * config . pos_dis + 2 def get_relative_pos ( x , entity_pos ): # 1: \u7d22\u5f15x\u5728\u5b9e\u4f53\u7684\u5de6\u4fa7, \u91c7\u7528x - \u5de6\u8fb9\u754c\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801 if x < entity_pos [ 0 ]: return get_pos_index ( x - entity_pos [ 0 ]) # 2: \u7d22\u5f15x\u5728\u5b9e\u4f53\u7684\u53f3\u4fa7, \u91c7\u7528x - \u53f3\u8fb9\u754c\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801 elif x > entity_pos [ 1 ]: return get_pos_index ( x - entity_pos [ 1 ]) # 3: \u7d22\u5f15x\u5728\u5b9e\u4f53\u533a\u57df\u5185, \u91c7\u75280\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801 else : return get_pos_index ( 0 ) def preprocess_sentence ( e1_pos , e2_pos , sentence ): mask = [ 1 ] * len ( sentence ) if e1_pos [ 0 ] < e2_pos [ 0 ]: for i in range ( e1_pos [ 0 ], e2_pos [ 1 ] + 1 ): mask [ i ] = 2 for i in range ( e2_pos [ 1 ] + 1 , len ( sentence )): mask [ i ] = 3 else : for i in range ( e2_pos [ 0 ], e1_pos [ 1 ] + 1 ): mask [ i ] = 2 for i in range ( e1_pos [ 1 ] + 1 , len ( sentence )): mask [ i ] = 3 words , pos1 , pos2 = [], [], [] length = min ( config . max_len , len ( sentence )) mask = mask [: length ] for i in range ( length ): words . append ( word2id . get ( sentence [ i ] . lower (), word2id [ 'UNK' ])) pos1 . append ( get_relative_pos ( i , e1_pos )) pos2 . append ( get_relative_pos ( i , e2_pos )) if length < config . max_len : for i in range ( length , config . max_len ): mask . append ( 0 ) words . append ( word2id [ 'PAD' ]) pos1 . append ( get_relative_pos ( i , e1_pos )) pos2 . append ( get_relative_pos ( i , e2_pos )) unit = np . asarray ([ words , pos1 , pos2 , mask ], dtype = np . int64 ) unit = np . reshape ( unit , newshape = ( 1 , 4 , config . max_len )) return unit s1 = time . time () model = CNN ( word_vec = word_vec , class_num = class_num , config = config ) model . load_state_dict ( torch . load ( os . path . join ( config . model_dir , 'model.pt' ))) e1 = time . time () print ( 'init model cost time:' , e1 - s1 ) def predict ( model , data ): sentence = data [ 'sentence' ] e1_pos = ( data [ 'subject_start' ], data [ 'subject_end' ]) e2_pos = ( data [ 'object_start' ], data [ 'object_end' ]) one_sentence = preprocess_sentence ( e1_pos , e2_pos , sentence ) # input_data: [1, 4, 100] input_data = torch . from_numpy ( one_sentence ) logits = model ( input_data ) _ , pred = torch . max ( logits , dim = 1 ) pred_id = pred . item () pred_rel = id2rel [ pred_id ] return pred_rel if __name__ == '__main__' : data = { \"subject_start\" : 117 , \"subject_end\" : 119 , \"object_start\" : 163 , \"object_end\" : 166 , \"sentence\" : [ \"\u8111\" , \"\u708e\" , \"@\" , \"#\" , \"#\" , \"#\" , \" \" , \"\u5c40\" , \"\u7076\" , \"\u6027\" , \"\u795e\" , \"\u7ecf\" , \"\u529f\" , \"\u80fd\" , \"\u969c\" , \"\u788d\" , \" \" , \"\u5305\" , \"\u62ec\" , \"\u5931\" , \"\u8bed\" , \"\u3001\" , \"\u504f\" , \"\u76f2\" , \"\u3001\" , \"\u504f\" , \"\u762b\" , \"\u3001\" , \"\u5171\" , \"\u6d4e\" , \"\u5931\" , \"\u8c03\" , \"\u3001\" , \"\u8171\" , \"\u53cd\" , \"\u5c04\" , \"\u51cf\" , \"\u5f31\" , \"\u3001\" , \"\u5df4\" , \"\u5f6c\" , \"\u65af\" , \"\u57fa\" , \"\u5f81\" , \"\u3001\" , \"\u9885\" , \"\u795e\" , \"\u7ecf\" , \"\u529f\" , \"\u80fd\" , \"\u7f3a\" , \"\u9677\" , \"\uff08\" , \"\u53ef\" , \"\u89c1\" , \"\u4e8e\" , \" \" , \"H\" , \"H\" , \"V\" , \"-\" , \"6\" , \"\uff0c\" , \"\u7ed3\" , \"\u6838\" , \"\u75c5\" , \"\u3001\" , \"\u6885\" , \"\u6bd2\" , \"\u3001\" , \"\u5e03\" , \"\u6c0f\" , \"\u83cc\" , \"\u75c5\" , \"\u3001\" , \"\u6025\" , \"\u6027\" , \"\u64ad\" , \"\u6563\" , \"\u6027\" , \"\u8111\" , \"\u810a\" , \"\u9ad3\" , \"\u708e\" , \"\u3001\" , \"\u897f\" , \"\u5c3c\" , \"\u7f57\" , \"\u6cb3\" , \"\u75c5\" , \"\u6bd2\" , \"\u3001\" , \"\u5723\" , \"\u8def\" , \"\u6613\" , \"\u65af\" , \"\u8111\" , \"\u708e\" , \"\u75c5\" , \"\u6bd2\" , \"\u3001\" , \"\u6c34\" , \"\u75d8\" , \"\u5e26\" , \"\u72b6\" , \"\u75b1\" , \"\u75b9\" , \"\u75c5\" , \"\u6bd2\" , \"\u3001\" , \"\u4e59\" , \"\u578b\" , \"\u75b1\" , \"\u75b9\" , \"\u75c5\" , \"\u6bd2\" , \"\u3001\" , \"\u72c2\" , \"\u72ac\" , \"\u75c5\" , \"\uff09\" , \"\uff1b\" , \"\u9707\" , \"\u98a4\" , \"\uff08\" , \"\u866b\" , \"\u5a92\" , \"\u75c5\" , \"\u6bd2\" , \"\uff09\" , \"\uff1b\" , \"\u808c\" , \"\u9635\" , \"\u631b\" , \"\uff08\" , \"\u4e9a\" , \"\u6025\" , \"\u6027\" , \"\u786c\" , \"\u5316\" , \"\u6027\" , \"\u5168\" , \"\u8111\" , \"\u708e\" , \"\uff09\" , \"\uff1b\" , \"\u611f\" , \"\u89c9\" , \"\u5f02\" , \"\u5e38\" , \"\uff08\" , \"\u79d1\" , \"\u7f57\" , \"\u62c9\" , \"\u591a\" , \"\u8731\" , \"\u70ed\" , \"\u3001\" , \"\u72c2\" , \"\u72ac\" , \"\u75c5\" , \"\uff09\" , \"\uff1b\" , \"\u5168\" , \"\u8eab\" , \"\u865a\" , \"\u5f31\" , \"\uff08\" , \"\u897f\" , \"\u5c3c\" , \"\u7f57\" , \"\u6cb3\" , \"\u75c5\" , \"\u6bd2\" , \"\u3001\" , \"\u72c2\" , \"\u72ac\" , \"\u75c5\" , \"\uff09\" , \"\u3002\" ]} start_time = time . time () res = predict ( model , data ) end_time = time . time () print ( 'res=' , res ) print ( 'prediction time:' , end_time - start_time ) \u8c03\u7528: python predict.py \u8f93\u51fa\u7ed3\u679c: Building prefix dict from the default dictionary ... Loading model from cache /tmp/jieba.cache Loading model cost 0.754 seconds. Prefix dict has been built successfully. processing embedding file ... b'195202' tokens in embedding file in total, vector size is b'300' 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 195202/195202 [00:03<00:00, 55853.24it/s] init model cost time: 2.119168996810913 res= \u4e34\u5e8a\u8868\u73b0 prediction time: 0.0063593387603759766 \u5c0f\u8282\u603b\u7ed3 \u00b6","title":"13.1 \u57fa\u4e8eCNN\u7684\u5173\u7cfb\u62bd\u53d6\u6a21\u578b"},{"location":"13_1.html#cnnre","text":"","title":"CNN\u6a21\u578b\u5904\u7406RE\u95ee\u9898"},{"location":"13_1.html#_1","text":"\u7406\u89e3CNN\u6a21\u578b\u662f\u5982\u4f55\u5904\u7406RE\u95ee\u9898\u7684. \u638c\u63e1CNN\u5904\u7406RE\u7684\u5177\u4f53\u4ee3\u7801\u5b9e\u73b0.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"13_1.html#cnnre_1","text":"\u539f\u59cb\u8bba\u6587<< Relation Classification via Convolutional Deep Neural Network >>. \u6574\u4e2a\u6a21\u578b\u7684\u67b6\u6784\u56fe\u5982\u4e0b\u6240\u793a: CNN\u6a21\u578b\u7684\u6838\u5fc3\u64cd\u4f5c\u67092\u4e2a: \u7279\u5f81\u62bd\u53d6\u878d\u5408\u4e86\u8bed\u6cd5\u5c42\u9762\u7684\u7279\u5f81 + \u8bed\u53e5\u5c42\u9762\u7684\u7279\u5f81. \u8bed\u53e5\u5c42\u9762\u7684\u7279\u5f81\u62bd\u53d6, \u9664\u4e86word embedding\u5916, \u8fd8\u878d\u5165\u4e86position embedding\u7684\u4fe1\u606f.","title":"CNN\u5904\u7406RE\u95ee\u9898\u7684\u67b6\u6784"},{"location":"13_1.html#cnnre_2","text":"","title":"CNN\u5904\u7406RE\u7684\u5b9e\u73b0"},{"location":"13_1.html#_2","text":"\u672c\u9879\u76ee\u91c7\u7528\u533b\u7597\u6570\u636e\u96c6CMeIE_train.json, \u4f46\u662f\u6240\u5c55\u793a\u7684\u6570\u636e\u683c\u5f0f\u5bf9CNN\u6a21\u578b\u5e76\u4e0d\u53cb\u597d, \u9700\u8981\u5bf9\u539f\u59cb\u6570\u636e\u96c6\u505a\u683c\u5f0f\u8f6c\u6362\u7684\u9884\u5904\u7406. \u9996\u5148\u5c55\u793a\u539f\u59cb\u533b\u7597\u6570\u636e: /home/ec2-user/information_extraction/relation/cnn_medical/data/CMeIE_train.json {\"text\": \"\u4ea7\u540e\u6291\u90c1\u75c7@\u533a\u5206\u4ea7\u540e\u6291\u90c1\u75c7\u4e0e\u8f7b\u5ea6\u60c5\u7eea\u5931\u8c03\uff08\u4ea7\u540e\u5fe7\u90c1\u6216\u201c\u5a74\u513f\u5fe7\u90c1\u201d\uff09\u662f\u91cd\u8981\u7684\uff0c\u56e0\u4e3a\u8f7b\u5ea6\u60c5\u7eea\u5931\u8c03\u4e0d\u9700\u8981\u6cbb\u7597\u3002\", \"spo_list\": [{\"Combined\": false, \"predicate\": \"\u9274\u522b\u8bca\u65ad\", \"subject\": \"\u4ea7\u540e\u6291\u90c1\u75c7\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u8f7b\u5ea6\u60c5\u7eea\u5931\u8c03\"}, \"object_type\": {\"@value\": \"\u75be\u75c5\"}}]} {\"text\": \"\u7c7b\u98ce\u6e7f\u5173\u8282\u708e@\u5c3a\u4fa7\u504f\u659c\u662f\u7531\u4e8eMCP\u5173\u8282\u708e\u75c7\u9020\u6210\u7684\u3002\", \"spo_list\": [{\"Combined\": false, \"predicate\": \"\u4e34\u5e8a\u8868\u73b0\", \"subject\": \"MCP\u5173\u8282\u708e\u75c7\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u5c3a\u4fa7\u504f\u659c\"}, \"object_type\": {\"@value\": \"\u75c7\u72b6\"}}]} \u9700\u8981\u5c06\u539f\u59cb\u6570\u636e\u8f6c\u53d8\u6210\u66f4\u6709\u5229\u4e8eCNN\u6a21\u578b\u5904\u7406\u7684\u5982\u4e0b\u683c\u5f0f: {\"id\": \"1\", \"sentence\": [\"\u4ea7\", \"\u540e\", \"\u6291\", \"\u90c1\", \"\u75c7\", \"@\", \"\u533a\", \"\u5206\", \"\u4ea7\", \"\u540e\", \"\u6291\", \"\u90c1\", \"\u75c7\", \"\u4e0e\", \"\u8f7b\", \"\u5ea6\", \"\u60c5\", \"\u7eea\", \"\u5931\", \"\u8c03\", \"\uff08\", \"\u4ea7\", \"\u540e\", \"\u5fe7\", \"\u90c1\", \"\u6216\", \"\u201c\", \"\u5a74\", \"\u513f\", \"\u5fe7\", \"\u90c1\", \"\u201d\", \"\uff09\", \"\u662f\", \"\u91cd\", \"\u8981\", \"\u7684\", \"\uff0c\", \"\u56e0\", \"\u4e3a\", \"\u8f7b\", \"\u5ea6\", \"\u60c5\", \"\u7eea\", \"\u5931\", \"\u8c03\", \"\u4e0d\", \"\u9700\", \"\u8981\", \"\u6cbb\", \"\u7597\", \"\u3002\"], \"head\": \"\u4ea7\u540e\u6291\u90c1\u75c7\", \"tail\": \"\u8f7b\u5ea6\u60c5\u7eea\u5931\u8c03\", \"relation\": \"\u9274\u522b\u8bca\u65ad\", \"subj_start\": 0, \"subj_end\": 4, \"obj_start\": 14, \"obj_end\": 19, \"comment\": \"\"} {\"id\": \"2\", \"sentence\": [\"\u7c7b\", \"\u98ce\", \"\u6e7f\", \"\u5173\", \"\u8282\", \"\u708e\", \"@\", \"\u5c3a\", \"\u4fa7\", \"\u504f\", \"\u659c\", \"\u662f\", \"\u7531\", \"\u4e8e\", \"M\", \"C\", \"P\", \"\u5173\", \"\u8282\", \"\u708e\", \"\u75c7\", \"\u9020\", \"\u6210\", \"\u7684\", \"\u3002\"], \"head\": \"MCP\u5173\u8282\u708e\u75c7\", \"tail\": \"\u5c3a\u4fa7\u504f\u659c\", \"relation\": \"\u4e34\u5e8a\u8868\u73b0\", \"subj_start\": 14, \"subj_end\": 20, \"obj_start\": 7, \"obj_end\": 10, \"comment\": \"\"} \u4f5c\u4e1a: \u4e0a\u8ff0\u6570\u636e\u683c\u5f0f\u8f6c\u6362\u5c5e\u4e8e\u5de5\u4f5c\u4e2d\u7684\u57fa\u672c\u64cd\u4f5c, \u4ee5\u4f5c\u4e1a\u7684\u5f62\u5f0f\u5b8c\u6210, \u953b\u70bc\u81ea\u5df1\u771f\u5b9e\u8fdb\u884c\u6570\u636e\u5904\u7406\u7684\u4ee3\u7801\u80fd\u529b! \u5173\u7cfb\u6570\u636e\u5b9a\u4e49\u6587\u4ef6: /home/ec2-user/information_extraction/relation/cnn_medical/data/53_schemas.json {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u9884\u9632\", \"object_type\": \"\u5176\u4ed6\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u9636\u6bb5\", \"object_type\": \"\u5176\u4ed6\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u5c31\u8bca\u79d1\u5ba4\", \"object_type\": \"\u5176\u4ed6\"} {\"subject_type\": \"\u5176\u4ed6\", \"predicate\": \"\u540c\u4e49\u8bcd-\u5176\u4ed6\", \"object_type\": \"\u5176\u4ed6\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u8f85\u52a9\u6cbb\u7597\", \"object_type\": \"\u5176\u4ed6\u6cbb\u7597\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u5316\u7597\", \"object_type\": \"\u5176\u4ed6\u6cbb\u7597\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u653e\u5c04\u6cbb\u7597\", \"object_type\": \"\u5176\u4ed6\u6cbb\u7597\"} {\"subject_type\": \"\u5176\u4ed6\u6cbb\u7597\", \"predicate\": \"\u540c\u4e49\u8bcd-\u5176\u4ed6\u6cbb\u7597\", \"object_type\": \"\u5176\u4ed6\u6cbb\u7597\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u624b\u672f\u6cbb\u7597\", \"object_type\": \"\u624b\u672f\u6cbb\u7597\"} {\"subject_type\": \"\u624b\u672f\u6cbb\u7597\", \"predicate\": \"\u540c\u4e49\u8bcd-\u624b\u672f\u6cbb\u7597\", \"object_type\": \"\u624b\u672f\u6cbb\u7597\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u5b9e\u9a8c\u5ba4\u68c0\u67e5\", \"object_type\": \"\u68c0\u67e5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u5f71\u50cf\u5b66\u68c0\u67e5\", \"object_type\": \"\u68c0\u67e5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u8f85\u52a9\u68c0\u67e5\", \"object_type\": \"\u68c0\u67e5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u7ec4\u7ec7\u5b66\u68c0\u67e5\", \"object_type\": \"\u68c0\u67e5\"} {\"subject_type\": \"\u68c0\u67e5\", \"predicate\": \"\u540c\u4e49\u8bcd-\u68c0\u67e5\", \"object_type\": \"\u68c0\u67e5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u5185\u7aa5\u955c\u68c0\u67e5\", \"object_type\": \"\u68c0\u67e5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u7b5b\u67e5\", \"object_type\": \"\u68c0\u67e5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u591a\u53d1\u7fa4\u4f53\", \"object_type\": \"\u6d41\u884c\u75c5\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u53d1\u75c5\u7387\", \"object_type\": \"\u6d41\u884c\u75c5\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u53d1\u75c5\u5e74\u9f84\", \"object_type\": \"\u6d41\u884c\u75c5\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u591a\u53d1\u5730\u533a\", \"object_type\": \"\u6d41\u884c\u75c5\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u53d1\u75c5\u6027\u522b\u503e\u5411\", \"object_type\": \"\u6d41\u884c\u75c5\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u6b7b\u4ea1\u7387\", \"object_type\": \"\u6d41\u884c\u75c5\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u591a\u53d1\u5b63\u8282\", \"object_type\": \"\u6d41\u884c\u75c5\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u4f20\u64ad\u9014\u5f84\", \"object_type\": \"\u6d41\u884c\u75c5\u5b66\"} {\"subject_type\": \"\u6d41\u884c\u75c5\u5b66\", \"predicate\": \"\u540c\u4e49\u8bcd-\u6d41\u884c\u75c5\u5b66\", \"object_type\": \"\u6d41\u884c\u75c5\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u540c\u4e49\u8bcd-\u75be\u75c5\", \"object_type\": \"\u75be\u75c5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u5e76\u53d1\u75c7\", \"object_type\": \"\u75be\u75c5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u75c5\u7406\u5206\u578b\", \"object_type\": \"\u75be\u75c5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u76f8\u5173\uff08\u5bfc\u81f4\uff09\", \"object_type\": \"\u75be\u75c5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u9274\u522b\u8bca\u65ad\", \"object_type\": \"\u75be\u75c5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u76f8\u5173\uff08\u8f6c\u5316\uff09\", \"object_type\": \"\u75be\u75c5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u76f8\u5173\uff08\u75c7\u72b6\uff09\", \"object_type\": \"\u75be\u75c5\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u4e34\u5e8a\u8868\u73b0\", \"object_type\": \"\u75c7\u72b6\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u6cbb\u7597\u540e\u75c7\u72b6\", \"object_type\": \"\u75c7\u72b6\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u4fb5\u53ca\u5468\u56f4\u7ec4\u7ec7\u8f6c\u79fb\u7684\u75c7\u72b6\", \"object_type\": \"\u75c7\u72b6\"} {\"subject_type\": \"\u75c7\u72b6\", \"predicate\": \"\u540c\u4e49\u8bcd-\u75c7\u72b6\", \"object_type\": \"\u75c7\u72b6\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u75c5\u56e0\", \"object_type\": \"\u793e\u4f1a\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u9ad8\u5371\u56e0\u7d20\", \"object_type\": \"\u793e\u4f1a\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u98ce\u9669\u8bc4\u4f30\u56e0\u7d20\", \"object_type\": \"\u793e\u4f1a\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u75c5\u53f2\", \"object_type\": \"\u793e\u4f1a\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u9057\u4f20\u56e0\u7d20\", \"object_type\": \"\u793e\u4f1a\u5b66\"} {\"subject_type\": \"\u793e\u4f1a\u5b66\", \"predicate\": \"\u540c\u4e49\u8bcd-\u793e\u4f1a\u5b66\", \"object_type\": \"\u793e\u4f1a\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u53d1\u75c5\u673a\u5236\", \"object_type\": \"\u793e\u4f1a\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u75c5\u7406\u751f\u7406\", \"object_type\": \"\u793e\u4f1a\u5b66\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u836f\u7269\u6cbb\u7597\", \"object_type\": \"\u836f\u7269\"} {\"subject_type\": \"\u836f\u7269\", \"predicate\": \"\u540c\u4e49\u8bcd-\u836f\u7269\", \"object_type\": \"\u836f\u7269\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u53d1\u75c5\u90e8\u4f4d\", \"object_type\": \"\u90e8\u4f4d\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u8f6c\u79fb\u90e8\u4f4d\", \"object_type\": \"\u90e8\u4f4d\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u5916\u4fb5\u90e8\u4f4d\", \"object_type\": \"\u90e8\u4f4d\"} {\"subject_type\": \"\u90e8\u4f4d\", \"predicate\": \"\u540c\u4e49\u8bcd-\u90e8\u4f4d\", \"object_type\": \"\u90e8\u4f4d\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u9884\u540e\u72b6\u51b5\", \"object_type\": \"\u9884\u540e\"} {\"subject_type\": \"\u75be\u75c5\", \"predicate\": \"\u9884\u540e\u751f\u5b58\u7387\", \"object_type\": \"\u9884\u540e\"} \u5173\u7cfb\u6620\u5c04\u8868: /home/ec2-user/information_extraction/relation/cnn_medical/data/rel2idx.json {\"\u9884\u9632\": 0, \"\u9636\u6bb5\": 1, \"\u5c31\u8bca\u79d1\u5ba4\": 2, \"\u540c\u4e49\u8bcd-\u5176\u4ed6\": 3, \"\u8f85\u52a9\u6cbb\u7597\": 4, \"\u5316\u7597\": 5, \"\u653e\u5c04\u6cbb\u7597\": 6, \"\u540c\u4e49\u8bcd-\u5176\u4ed6\u6cbb\u7597\": 7, \"\u624b\u672f\u6cbb\u7597\": 8, \"\u540c\u4e49\u8bcd-\u624b\u672f\u6cbb\u7597\": 9, \"\u5b9e\u9a8c\u5ba4\u68c0\u67e5\": 10, \"\u5f71\u50cf\u5b66\u68c0\u67e5\": 11, \"\u8f85\u52a9\u68c0\u67e5\": 12, \"\u7ec4\u7ec7\u5b66\u68c0\u67e5\": 13, \"\u540c\u4e49\u8bcd-\u68c0\u67e5\": 14, \"\u5185\u7aa5\u955c\u68c0\u67e5\": 15, \"\u7b5b\u67e5\": 16, \"\u591a\u53d1\u7fa4\u4f53\": 17, \"\u53d1\u75c5\u7387\": 18, \"\u53d1\u75c5\u5e74\u9f84\": 19, \"\u591a\u53d1\u5730\u533a\": 20, \"\u53d1\u75c5\u6027\u522b\u503e\u5411\": 21, \"\u6b7b\u4ea1\u7387\": 22, \"\u591a\u53d1\u5b63\u8282\": 23, \"\u4f20\u64ad\u9014\u5f84\": 24, \"\u540c\u4e49\u8bcd-\u6d41\u884c\u75c5\u5b66\": 25, \"\u540c\u4e49\u8bcd-\u75be\u75c5\": 26, \"\u5e76\u53d1\u75c7\": 27, \"\u75c5\u7406\u5206\u578b\": 28, \"\u76f8\u5173\uff08\u5bfc\u81f4\uff09\": 29, \"\u9274\u522b\u8bca\u65ad\": 30, \"\u76f8\u5173\uff08\u8f6c\u5316\uff09\": 31, \"\u76f8\u5173\uff08\u75c7\u72b6\uff09\": 32, \"\u4e34\u5e8a\u8868\u73b0\": 33, \"\u6cbb\u7597\u540e\u75c7\u72b6\": 34, \"\u4fb5\u53ca\u5468\u56f4\u7ec4\u7ec7\u8f6c\u79fb\u7684\u75c7\u72b6\": 35, \"\u540c\u4e49\u8bcd-\u75c7\u72b6\": 36, \"\u75c5\u56e0\": 37, \"\u9ad8\u5371\u56e0\u7d20\": 38, \"\u98ce\u9669\u8bc4\u4f30\u56e0\u7d20\": 39, \"\u75c5\u53f2\": 40, \"\u9057\u4f20\u56e0\u7d20\": 41, \"\u540c\u4e49\u8bcd-\u793e\u4f1a\u5b66\": 42, \"\u53d1\u75c5\u673a\u5236\": 43, \"\u75c5\u7406\u751f\u7406\": 44, \"\u836f\u7269\u6cbb\u7597\": 45, \"\u540c\u4e49\u8bcd-\u836f\u7269\": 46, \"\u53d1\u75c5\u90e8\u4f4d\": 47, \"\u8f6c\u79fb\u90e8\u4f4d\": 48, \"\u5916\u4fb5\u90e8\u4f4d\": 49, \"\u540c\u4e49\u8bcd-\u90e8\u4f4d\": 50, \"\u9884\u540e\u72b6\u51b5\": 51, \"\u9884\u540e\u751f\u5b58\u7387\": 52}","title":"\u6570\u636e\u9884\u5904\u7406"},{"location":"13_1.html#_3","text":"\u5de5\u5177\u7c7b\u51fd\u6570\u67092\u4e2a: 1: \u8d1f\u8d23\u5904\u7406\u8bcd\u5d4c\u5165\u7684embedding.py 2: \u8d1f\u8d23\u5904\u7406\u6570\u636e\u52a0\u8f7d\u548c\u5176\u4ed6\u5de5\u5177\u7c7b\u529f\u80fd\u7684utils.py 1: \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/cnn_medical/embedding.py # \u5bfc\u5165\u5de5\u5177\u5305 from collections import Counter from tqdm import tqdm import jieba import bz2 import torch import numpy as np # \u83b7\u53d6\u8bcd\u5178\u7684\u51fd\u6570 def get_vocab ( train_file_path , vocab_size ): # \u521d\u59cb\u5316\u4e00\u4e2a\u8ba1\u6570\u5668 token_counter = Counter () # \u904d\u5386\u8bad\u7ec3\u96c6\u6570\u636e, \u5c06\u5206\u8bcd\u540e\u7684\u6240\u6709\u4e2d\u6587\u8bcd\u653e\u5165\u8ba1\u6570\u5668\u4e2d with open ( train_file_path , 'r' , encoding = 'utf-8' ) as f : lines = f . readlines () for line in tqdm ( lines , total = len ( lines ), desc = 'Counting tokens' ): sent = line . split ( ',' )[ - 1 ] . strip () # \u91c7\u7528jieba\u5206\u8bcd\u4f5c\u4e3a\u4e2d\u6587\u573a\u666f\u4e0b\u7684\u5206\u8bcd\u5668 sent_cut = list ( jieba . cut ( sent )) # \u66f4\u65b0\u8ba1\u6570\u5668 token_counter . update ( sent_cut ) # \u6309\u7167\u4eba\u5de5\u8bbe\u7f6e\u9009\u5b9a\u8bcd\u9891\u6700\u9ad8\u7684vocab_size\u4e2a\u4e2d\u6587\u8bcd vocab = set ( token for token , _ in token_counter . most_common ( vocab_size )) return vocab # \u83b7\u53d6\u8bcd\u5d4c\u5165\u5411\u91cf\u7684\u51fd\u6570 def get_embedding ( vocab , embedding_file_path ): print ( 'processing embedding file ...' ) token2embedding = {} # \u6253\u5f00\u65b0\u6d6a\u5fae\u535a\u5f00\u6e90\u7684\u9884\u8bad\u7ec3\u8bcd\u5411\u91cf\u6587\u4ef6 with bz2 . open ( embedding_file_path ) as f : token_vectors = f . readlines () meta_info = token_vectors [ 0 ] . split () print ( f ' { meta_info [ 0 ] } tokens in embedding file in total, vector size is { meta_info [ - 1 ] } ' ) # \u904d\u5386\u6bcf\u4e00\u884c\u6570\u636e for line in tqdm ( token_vectors [ 1 :]): line = line . split () # \u7b2c\u4e00\u5217\u662f\u5bf9\u5e94\u7684\u4e2d\u6587\u8bcd token = line [ 0 ] . decode ( 'utf-8' ) # \u7b2c\u4e00\u5217\u4e4b\u540e\u90fd\u662f\u6570\u5b57\u5316\u7684\u8bcd\u5411\u91cf vector = line [ 1 :] # \u53ea\u9009\u53d6\u90a3\u4e9b\u5df2\u7ecf\u5728\u8bcd\u5178\u4e2d\u7684\u8bcd\u5411\u91cf\u5b58\u5165\u8bcd\u5411\u91cf\u8bcd\u5178\u4e2d if token in vocab : token2embedding [ token ] = [ float ( num ) for num in vector ] # \u5c064\u4e2a\u7279\u6b8a\u5b57\u7b26\u5360\u636e0,1,2,3\u7684\u6807\u7b7e, \u5176\u4ed6\u5355\u8bcd\u6309\u5e8f\u5411\u540e\u6392\u5217 token2idx = { token : idx for idx , token in enumerate ( token2embedding . keys (), 4 )} UNK , PAD , BOS , EOS = '<unk>' , '<pad>' , '<bos>' , '<eos>' token2idx [ PAD ] = 0 token2idx [ UNK ] = 1 token2idx [ BOS ] = 2 token2idx [ EOS ] = 3 idx2token = { idx : token for token , idx in token2idx . items ()} idx2embedding = { token2idx [ token ]: embedding for token , embedding in token2embedding . items ()} idx2embedding [ 0 ] = [ .0 ] * int ( meta_info [ - 1 ]) idx2embedding [ 1 ] = [ .0 ] * int ( meta_info [ - 1 ]) idx2embedding [ 2 ] = np . random . random ( int ( meta_info [ - 1 ])) . tolist () idx2embedding [ 3 ] = np . random . random ( int ( meta_info [ - 1 ])) . tolist () emb_mat = [ idx2embedding [ idx ] for idx in range ( len ( idx2embedding ))] emb_mat = torch . tensor ( emb_mat , dtype = torch . float ) return emb_mat , token2idx , len ( vocab ) + 4 2: \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/cnn_medical/utils.py # \u5bfc\u5165\u5de5\u5177\u5305 import os import json import torch import numpy as np from collections import Counter import bz2 import jieba from tqdm import tqdm from torch.utils.data import Dataset , DataLoader # \u8bcd\u5d4c\u5165\u5f20\u91cf\u7684\u52a0\u8f7d\u7c7b\u4ee3\u7801 class WordEmbeddingLoader ( object ): def __init__ ( self , config ): self . embedding_path = config . embedding_path self . word_dim = config . word_dim self . train_raw = config . train_raw self . vocab_size = config . vocab_size # \u83b7\u53d6\u8bcd\u5178\u7684\u7c7b\u5185\u51fd\u6570 def get_vocab ( self ): # \u521d\u59cb\u5316\u4e00\u4e2a\u8ba1\u6570\u5668 token_counter = Counter () # \u904d\u5386\u8bad\u7ec3\u96c6\u6570\u636e, \u5c06\u5206\u8bcd\u540e\u7684\u6240\u6709\u4e2d\u6587\u8bcd\u653e\u5165\u8ba1\u6570\u5668\u4e2d with open ( self . train_raw , 'r' , encoding = 'utf-8' ) as f : for line in f . readlines (): data = json . loads ( line ) text = data [ 'text' ] # \u91c7\u7528jieba\u5206\u8bcd\u4f5c\u4e3a\u4e2d\u6587\u573a\u666f\u4e0b\u7684\u5206\u8bcd\u5668 sentence_words = jieba . lcut ( text ) # \u66f4\u65b0\u8ba1\u6570\u5668 token_counter . update ( sentence_words ) # \u6309\u7167\u4eba\u5de5\u8bbe\u7f6e\u9009\u5b9a\u8bcd\u9891\u6700\u9ad8\u7684vocab_size\u4e2a\u4e2d\u6587\u8bcd vocab = set ( token for token , _ in token_counter . most_common ( self . vocab_size )) return vocab # \u83b7\u53d6\u8bcd\u5d4c\u5165\u5411\u91cf\u7684\u7c7b\u5185\u51fd\u6570 def get_embedding ( self , vocab ): print ( 'processing embedding file ...' ) token2embedding = {} # \u6253\u5f00\u65b0\u6d6a\u5fae\u535a\u5f00\u6e90\u7684\u9884\u8bad\u7ec3\u8bcd\u5411\u91cf\u6587\u4ef6 with bz2 . open ( self . embedding_path ) as f : token_vectors = f . readlines () meta_info = token_vectors [ 0 ] . split () print ( f ' { meta_info [ 0 ] } tokens in embedding file in total, vector size is { meta_info [ - 1 ] } ' ) for line in tqdm ( token_vectors [ 1 :]): line = line . split () # \u7b2c\u4e00\u5217\u662f\u5bf9\u5e94\u7684\u4e2d\u6587\u8bcd token = line [ 0 ] . decode ( 'utf-8' ) # \u7b2c\u4e00\u5217\u4e4b\u540e\u90fd\u662f\u6570\u5b57\u5316\u7684\u8bcd\u5411\u91cf vector = line [ 1 :] # \u53ea\u9009\u53d6\u90a3\u4e9b\u5df2\u7ecf\u5728\u8bcd\u5178\u4e2d\u7684\u8bcd\u5411\u91cf\u5b58\u5165\u8bcd\u5411\u91cf\u8bcd\u5178\u4e2d if token in vocab : token2embedding [ token ] = [ float ( num ) for num in vector ] # \u5c064\u4e2a\u7279\u6b8a\u5b57\u7b26\u5360\u636e0,1,2,3\u7684\u6807\u7b7e, \u5176\u4ed6\u5355\u8bcd\u6309\u5e8f\u5411\u540e\u6392\u5217 token2idx = { token : idx for idx , token in enumerate ( token2embedding . keys (), 4 )} UNK , PAD , BOS , EOS = 'UNK' , 'PAD' , 'BOS' , 'EOS' token2idx [ PAD ] = 0 token2idx [ UNK ] = 1 token2idx [ BOS ] = 2 token2idx [ EOS ] = 3 idx2token = { idx : token for token , idx in token2idx . items ()} idx2embedding = { token2idx [ token ]: embedding for token , embedding in token2embedding . items ()} idx2embedding [ 0 ] = [ .0 ] * int ( meta_info [ - 1 ]) idx2embedding [ 1 ] = [ .0 ] * int ( meta_info [ - 1 ]) idx2embedding [ 2 ] = np . random . random ( int ( meta_info [ - 1 ])) . tolist () idx2embedding [ 3 ] = np . random . random ( int ( meta_info [ - 1 ])) . tolist () emb_mat = [ idx2embedding [ idx ] for idx in range ( len ( idx2embedding ))] emb_mat = torch . tensor ( emb_mat , dtype = torch . float ) return emb_mat , token2idx # \u5173\u7cfb\u52a0\u8f7d\u7c7b\u4ee3\u7801 class RelationLoader ( object ): def __init__ ( self , config ): self . data_dir = config . data_dir # \u8bfb\u53d6\u6587\u4ef6\u5c06\u5173\u7cfb\u6620\u5c04\u8868\u52a0\u8f7d\u6210\u5b57\u5178\u7c7b\u578b def __load_relation ( self ): relation_file = os . path . join ( self . data_dir , 'relation2id.txt' ) rel2id = {} id2rel = {} # \u904d\u5386\u5173\u7cfb\u6587\u4ef6\u8fdb\u884c\u6570\u636e\u8bfb\u53d6 with open ( relation_file , 'r' , encoding = 'utf-8' ) as fr : for line in fr : relation , id_s = line . strip () . split () id_d = int ( id_s ) rel2id [ relation ] = id_d id2rel [ id_d ] = relation # \u8fd4\u56de\u4e24\u4e2a\u6620\u5c04\u5b57\u5178, \u4ee5\u53ca\u5173\u7cfb\u6570\u76ee return rel2id , id2rel , len ( rel2id ) # \u5916\u5c42\u63a5\u53e3\u51fd\u6570, \u5185\u90e8\u8c03\u7528\u4e0a\u9762\u7684\u7c7b\u5185\u51fd\u6570 def get_relation ( self ): return self . __load_relation () # \u6784\u5efa\u6570\u636e\u96c6\u7684\u7c7b\u4ee3\u7801 class SemEvalDateset ( Dataset ): def __init__ ( self , filename , rel2id , word2id , config ): self . filename = filename self . rel2id = rel2id self . word2id = word2id self . max_len = config . max_len # \u5728config\u6587\u4ef6\u4e2d\u8bbe\u5b9apos_dis\u9ed8\u8ba4\u503c\u4e3a50 self . pos_dis = config . pos_dis self . data_dir = config . data_dir self . dataset , self . label = self . __load_data () # \u83b7\u53d6\u4f4d\u7f6e\u7d22\u5f15\u7684\u51fd\u6570 def __get_pos_index ( self , x ): # pos_dis\u9ed8\u8ba4\u503c\u4e3a50, \u5df2\u5728config.py\u6587\u4ef6\u4e2d\u8bbe\u7f6e. # 1: \u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u5c0f\u4e8e-50, \u76f4\u63a5\u8fd4\u56de\u4f4d\u7f6e\u7f16\u78010. if x < - self . pos_dis : return 0 # 2: \u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801[-50, 50]\u4e4b\u95f4, \u91c7\u7528x + 50 + 1\u7684\u4f4d\u7f6e\u7f16\u7801\u503c. if x >= - self . pos_dis and x <= self . pos_dis : return x + self . pos_dis + 1 # 3: \u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u5927\u4e8e50, \u91c7\u75282 * 50 + 2 = 102\u7684\u4f4d\u7f6e\u7f16\u7801\u503c. if x > self . pos_dis : return 2 * self . pos_dis + 2 # \u83b7\u53d6\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u7684\u51fd\u6570 def __get_relative_pos ( self , x , entity_pos ): # 1: \u7d22\u5f15x\u5728\u5b9e\u4f53\u7684\u5de6\u4fa7, \u91c7\u7528x - \u5de6\u8fb9\u754c\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801 if x < entity_pos [ 0 ]: return self . __get_pos_index ( x - entity_pos [ 0 ]) # 2: \u7d22\u5f15x\u5728\u5b9e\u4f53\u7684\u53f3\u4fa7, \u91c7\u7528x - \u53f3\u8fb9\u754c\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801 elif x > entity_pos [ 1 ]: return self . __get_pos_index ( x - entity_pos [ 1 ]) # 3: \u7d22\u5f15x\u5728\u5b9e\u4f53\u533a\u57df\u5185, \u91c7\u75280\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801 else : return self . __get_pos_index ( 0 ) # \u5c06\u6587\u672c\u8fdb\u884c\u7b26\u53f7\u5316\u7684\u51fd\u6570, \u6838\u5fc3\u64cd\u4f5c\u5728\u4e8e\u8bbe\u5b9amask\u63a9\u7801\u89c4\u5219 def __symbolize_sentence ( self , e1_pos , e2_pos , sentence ): # e1_pos (tuple) span of e1 # e2_pos (tuple) span of e2 # sentence (list) # \u521d\u59cb\u5316mask\u4e3a\u51681\u7684\u5217\u8868 mask = [ 1 ] * len ( sentence ) # \u60c5\u51b51: \u5982\u679c\u5b9e\u4f531\u5728\u5b9e\u4f532\u7684\u5de6\u4fa7. (e1, e2) if e1_pos [ 0 ] < e2_pos [ 0 ]: # \u4e0b\u9762\u4e24\u4e2afor\u5faa\u73af, \u4f7f\u5f97\u5b9e\u4f531,2\u7684\u533a\u95f4\u88ab\u8d4b\u503c\u62102, \u540e\u9762\u5168\u662f3, \u524d\u9762\u5168\u662f1 # \u7c7b\u4f3c\u6548\u679c: [1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3,3,3] for i in range ( e1_pos [ 0 ], e2_pos [ 1 ] + 1 ): mask [ i ] = 2 for i in range ( e2_pos [ 1 ] + 1 , len ( sentence )): mask [ i ] = 3 # \u60c5\u51b52: \u5982\u679c\u5b9e\u4f531\u5728\u5b9e\u4f532\u7684\u53f3\u4fa7. (e2, e1) else : # \u4e0b\u9762\u4e24\u4e2afor\u5faa\u73af, \u4f7f\u5f97\u5b9e\u4f532,1\u7684\u533a\u95f4\u88ab\u8d4b\u503c\u62102, \u540e\u9762\u5168\u662f3, \u524d\u9762\u5168\u662f1 # \u7c7b\u4f3c\u6548\u679c: [1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3,3,3] for i in range ( e2_pos [ 0 ], e1_pos [ 1 ] + 1 ): mask [ i ] = 2 for i in range ( e1_pos [ 1 ] + 1 , len ( sentence )): mask [ i ] = 3 # \u521d\u59cb\u5316\u82e5\u5e72\u53d8\u91cf words = [] pos1 = [] pos2 = [] length = min ( self . max_len , len ( sentence )) mask = mask [: length ] # \u8fdb\u884c\u6570\u5b57\u5316\u7f16\u7801, \u6dfb\u52a0\u6210\u5217\u8868\u683c\u5f0f for i in range ( length ): words . append ( self . word2id . get ( sentence [ i ] . lower (), self . word2id [ 'UNK' ])) pos1 . append ( self . __get_relative_pos ( i , e1_pos )) pos2 . append ( self . __get_relative_pos ( i , e2_pos )) # \u8fdb\u884c\u957f\u5ea6\u7684\u8865\u9f50\u64cd\u4f5c if length < self . max_len : for i in range ( length , self . max_len ): mask . append ( 0 ) # 'PAD' mask is zero words . append ( self . word2id [ 'PAD' ]) pos1 . append ( self . __get_relative_pos ( i , e1_pos )) pos2 . append ( self . __get_relative_pos ( i , e2_pos )) # \u5c01\u88c5\u6210numpy\u6570\u7ec4\u5e76\u8c03\u6574shape unit = np . asarray ([ words , pos1 , pos2 , mask ], dtype = np . int64 ) unit = np . reshape ( unit , newshape = ( 1 , 4 , self . max_len )) # \u8fd4\u56de\u5c01\u88c5\u597d\u7684\u6570\u7ec4\u5bf9\u8c61 return unit # \u7c7b\u5185\u8d1f\u8d23\u52a0\u8f7d\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u7684\u51fd\u6570 def __load_data ( self ): path_data_file = os . path . join ( self . data_dir , self . filename ) data = [] labels = [] count = 0 # \u6253\u5f00\u6570\u636e\u6587\u4ef6\u5e76\u904d\u5386\u8bfb\u53d6\u6570\u636e with open ( path_data_file , 'r' , encoding = 'utf-8' ) as f : for line in f : line = json . loads ( line . strip ()) # \u5148\u5c06\u539f\u59cb\u6570\u636e\u8bfb\u53d6\u5e76\u63d0\u53d6\u4e0d\u540c\u5b57\u6bb5\u7684\u503c label = line [ 'relation' ] sentence = line [ 'sentence' ] e1_pos = ( line [ 'subj_start' ], line [ 'subj_end' ]) e2_pos = ( line [ 'obj_start' ], line [ 'obj_end' ]) count += 1 label_idx = self . rel2id [ label ] # \u6838\u5fc3\u64cd\u4f5c\u5728\u4e8e\u5c06\u6587\u672c\u8fdb\u884c\u6570\u5b57\u5316\u7f16\u7801 one_sentence = self . __symbolize_sentence ( e1_pos , e2_pos , sentence ) data . append ( one_sentence ) labels . append ( label_idx ) # \u8fd4\u56de\u6570\u5b57\u5316\u6587\u672c\u548c\u5bf9\u5e94\u7684\u6570\u5b57\u5316\u6807\u7b7e return data , labels # \u6309\u7167\u7d22\u5f15\u8bfb\u53d6\u6570\u636e def __getitem__ ( self , index ): data = self . dataset [ index ] label = self . label [ index ] return data , label # \u7c7b\u5185\u6570\u636e\u7684\u957f\u5ea6\u6d4b\u91cf\u51fd\u6570 def __len__ ( self ): return len ( self . label ) # \u6784\u5efa\u6570\u636e\u8fed\u4ee3\u5668\u7684\u7c7b\u4ee3\u7801 class SemEvalDataLoader ( object ): def __init__ ( self , rel2id , word2id , config ): self . rel2id = rel2id self . word2id = word2id self . config = config # \u521b\u5efaDataLoader\u7684\"\u4e2a\u6027\u5316\"\u5904\u7406\u51fd\u6570collate_fn() def __collate_fn ( self , batch ): data , label = zip ( * batch ) data = list ( data ) label = list ( label ) data = torch . from_numpy ( np . concatenate ( data , axis = 0 )) label = torch . from_numpy ( np . asarray ( label , dtype = np . int64 )) return data , label # \u83b7\u53d6\u6570\u636e\u8fed\u4ee3\u5668\u7684\u7c7b\u5185\u51fd\u6570 def __get_data ( self , filename , shuffle = False ): # \u7b2c\u4e00\u6b65: \u8c03\u7528\u6784\u5efa\u6570\u636e\u96c6\u7684\u7c7b\u5bf9\u8c61 dataset = SemEvalDateset ( filename , self . rel2id , self . word2id , self . config ) # \u7b2c\u4e8c\u6b65: \u5728\u6570\u636e\u96c6\u5bf9\u8c61\u7684\u57fa\u7840\u4e0a, \u6784\u5efa\u6570\u636e\u8fed\u4ee3\u5668\u5bf9\u8c61, \u5176\u4e2d\u91c7\u7528\u81ea\u5b9a\u4e49\u7684\u4e2a\u6027\u5316\u5904\u7406\u51fd\u6570 loader = DataLoader ( dataset = dataset , batch_size = self . config . batch_size , shuffle = shuffle , num_workers = 4 , collate_fn = self . __collate_fn ) return loader # \u83b7\u53d6\u8bad\u7ec3\u6570\u636e\u8fed\u4ee3\u5668\u7684\u5bf9\u5916\u63a5\u53e3 def get_train ( self ): return self . __get_data ( 'train.json' , shuffle = True ) # \u83b7\u53d6\u9a8c\u8bc1\u6570\u636e\u8fed\u4ee3\u5668\u7684\u5bf9\u5916\u63a5\u53e3(\u9a8c\u8bc1\u96c6\u4f7f\u7528\u6d4b\u8bd5\u96c6\u4ee3\u66ff) def get_dev ( self ): return self . __get_data ( 'test.json' , shuffle = False ) # \u83b7\u53d6\u6d4b\u8bd5\u6570\u636e\u8fed\u4ee3\u5668\u7684\u5bf9\u5916\u63a5\u53e3 def get_test ( self ): return self . __get_data ( 'test.json' , shuffle = False ) if __name__ == '__main__' : from config import Config config = Config () vocab = WordEmbeddingLoader ( config ) . get_vocab () word_vec , word2id = WordEmbeddingLoader ( config ) . get_embedding ( vocab ) rel2id , id2rel , class_num = RelationLoader ( config ) . get_relation () loader = SemEvalDataLoader ( rel2id , word2id , config ) test_loader = loader . get_train () min_v , max_v = float ( 'inf' ), - float ( 'inf' ) for step , ( data , label ) in enumerate ( test_loader ): # print(type(data), data.shape) # print(type(label), label.shape) # break pos1 = data [:, 1 , :] . view ( - 1 , config . max_len ) pos2 = data [:, 2 , :] . view ( - 1 , config . max_len ) mask = data [:, 3 , :] . view ( - 1 , config . max_len ) min_v = min ( min_v , torch . min ( pos1 ) . item ()) max_v = max ( max_v , torch . max ( pos1 ) . item ()) min_v = min ( min_v , torch . min ( pos2 ) . item ()) max_v = max ( max_v , torch . max ( pos2 ) . item ()) print ( min_v , max_v )","title":"\u5de5\u5177\u7c7b\u51fd\u6570\u7684\u5b9e\u73b0"},{"location":"13_1.html#_4","text":"\u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/cnn_medical/model.py # \u5bfc\u5165\u5de5\u5177\u5305 import torch import torch.nn as nn import torch.nn.functional as F from torch.nn import init class CNN ( nn . Module ): def __init__ ( self , word_vec , class_num , config ): super () . __init__ () # \u521d\u59cb\u5316\u5173\u952e\u53c2\u6570 self . word_vec = word_vec self . class_num = class_num self . max_len = config . max_len self . word_dim = config . word_dim self . pos_dim = config . pos_dim self . pos_dis = config . pos_dis self . dropout_value = config . dropout self . filter_num = config . filter_num self . window = config . window self . hidden_size = config . hidden_size # dim\u7ef4\u5ea6\u8bbe\u7f6e\u4e3a\u8bcd\u5d4c\u5165\u7684\u7ef4\u5ea6 + 2\u4e2a\u5355\u8bcd\u7684\u4f4d\u7f6e\u7f16\u7801\u7ef4\u5ea6 self . dim = self . word_dim + 2 * self . pos_dim # 1: \u4efb\u610f\u4e00\u4e2a\u5355\u8bcd\u5d4c\u5165\u5f20\u91cf, 2: \u7b2c\u4e00\u4e2a\u5355\u8bcd\u7684\u4f4d\u7f6e\u5d4c\u5165\u5f20\u91cf, 3: \u7b2c\u4e8c\u4e2a\u5355\u8bcd\u7684\u4f4d\u7f6e\u5d4c\u5165\u5f20\u91cf self . word_embedding = nn . Embedding . from_pretrained ( embeddings = self . word_vec , freeze = False ) self . pos1_embedding = nn . Embedding ( num_embeddings = 2 * self . pos_dis + 3 , embedding_dim = self . pos_dim ) self . pos2_embedding = nn . Embedding ( num_embeddings = 2 * self . pos_dis + 3 , embedding_dim = self . pos_dim ) # CNN\u7684\u6838\u5fc3\u64cd\u4f5c, \u4e8c\u7ef4\u5377\u79ef self . conv = nn . Conv2d ( in_channels = 1 , out_channels = self . filter_num , kernel_size = ( self . window , self . dim ), stride = ( 1 , 1 ), bias = True , padding = ( 1 , 0 ), padding_mode = 'zeros' ) # \u8bbe\u7f6e\u6700\u5927\u6c60\u5316\u5c42, \u6fc0\u6d3b\u5c42, Dropout\u5c42 self . maxpool = nn . MaxPool2d (( self . max_len , 1 )) self . tanh = nn . Tanh () self . dropout = nn . Dropout ( self . dropout_value ) # \u5377\u79ef\u5c42\u5411\u4e0b\u4e00\u5c42\u7684\u6620\u5c04\u77e9\u9635, \u4ece\u5377\u79ef\u6838\u6570\u91cf -> \u9690\u85cf\u5c42\u7ef4\u5ea6 self . linear = nn . Linear ( in_features = self . filter_num , out_features = self . hidden_size , bias = True ) # \u6574\u4e2a\u7f51\u7edc\u7684\u8f93\u51fa\u5c42, \u4ece\u9690\u85cf\u5c42\u7ef4\u5ea6 -> \u5206\u7c7b\u6570\u91cf self . dense = nn . Linear ( in_features = self . hidden_size , out_features = self . class_num , bias = True ) # \u521d\u59cb\u5316\u7f51\u7edc\u4e2d\u7684\u4e00\u4e9b\u6743\u91cd init . xavier_normal_ ( self . pos1_embedding . weight ) init . xavier_normal_ ( self . pos2_embedding . weight ) init . xavier_normal_ ( self . conv . weight ) init . constant_ ( self . conv . bias , 0. ) init . xavier_normal_ ( self . linear . weight ) init . constant_ ( self . linear . bias , 0. ) init . xavier_normal_ ( self . dense . weight ) init . constant_ ( self . dense . bias , 0. ) # \u7f16\u7801\u5c42\u51fd\u6570 def encoder_layer ( self , token , pos1 , pos2 ): # word_emb: [batch_size, seq_len, word_dim] word_emb = self . word_embedding ( token ) # pos1_emb: [batch_size, seq_len, pos_dim] pos1_emb = self . pos1_embedding ( pos1 ) # pos2_emb: [batch_size, seq_len, pos_dim] pos2_emb = self . pos2_embedding ( pos2 ) # \u6700\u7ec8\u7684\u5d4c\u5165\u5f20\u91cf, \u662f3\u4e2a\u5b50\u90e8\u5206\u7684\u7b80\u5355\u62fc\u63a5 emb = torch . cat ( tensors = [ word_emb , pos1_emb , pos2_emb ], dim =- 1 ) # emb: [batch_size, seq_len, word_dim + 2 * pos_dim] return emb # \u5377\u79ef\u5c42\u51fd\u6570 def conv_layer ( self , emb , mask ): # emb: [batch_size, 1, seq_len, dim] emb = emb . unsqueeze ( dim = 1 ) # conv: [batch_size, filter_num, seq_len, 1] conv = self . conv ( emb ) # conv: [batch_size, filter_num, seq_len] conv = conv . view ( - 1 , self . filter_num , self . max_len ) # mask: [batch_size, 1, seq_len] mask = mask . unsqueeze ( dim = 1 ) # mask: [batch_size, filter_num, seq_len] mask = mask . expand ( - 1 , self . filter_num , - 1 ) # \u6240\u6709mask\u5f20\u91cf\u7b49\u4e8e0\u7684\u4f4d\u7f6e, \u90fd\u7528'-inf'\u586b\u5145, \u7b49\u6548\u4e8e\u6570\u5b66\u4e0a\u7684\u906e\u63a9 conv = conv . masked_fill_ ( mask . eq ( 0 ), float ( '-inf' )) # conv: [batch_size, filter_num, seq_len, 1] conv = conv . unsqueeze ( dim =- 1 ) return conv # \u6700\u5927\u6c60\u5316\u7684\u64cd\u4f5c\u51fd\u6570 def single_maxpool_layer ( self , conv ): # pool: [batch_size, filter_num, 1, 1] pool = self . maxpool ( conv ) # pool: [batch_size, filter_num] pool = pool . view ( - 1 , self . filter_num ) return pool def forward ( self , data ): # \u4f9d\u6b21\u53d6\u51fa\u6570\u636e, \u5e76\u5c06\u5f20\u91cf\u7684shape\u8f6c\u53d8\u6210[X, seq_len] token = data [:, 0 , :] . view ( - 1 , self . max_len ) pos1 = data [:, 1 , :] . view ( - 1 , self . max_len ) pos2 = data [:, 2 , :] . view ( - 1 , self . max_len ) mask = data [:, 3 , :] . view ( - 1 , self . max_len ) # 1: \u9996\u5148\u8fdb\u5165\u7f16\u7801\u5668\u8fdb\u884c\u7f16\u7801 emb = self . encoder_layer ( token , pos1 , pos2 ) # 2: \u5bf9\u8f93\u51fa\u5f20\u91cf\u8fdb\u884cDropout\u64cd\u4f5c emb = self . dropout ( emb ) # 3: \u5377\u79ef\u64cd\u4f5c\u662fCNN\u7684\u6838\u5fc3 conv = self . conv_layer ( emb , mask ) # 4: \u6700\u5927\u6c60\u5316\u7684\u64cd\u4f5c pool = self . single_maxpool_layer ( conv ) # 5: \u5168\u8fde\u63a5\u5c42\u7684\u6620\u5c04\u64cd\u4f5c sentence_feature = self . linear ( pool ) # 6: \u6fc0\u6d3b\u5c42\u8fd0\u7b97 sentence_feature = self . tanh ( sentence_feature ) # 7: \u518d\u6b21\u8fdb\u884cDropout\u64cd\u4f5c sentence_feature = self . dropout ( sentence_feature ) # 8: \u6700\u540e\u8fdb\u884c\u5168\u8fde\u63a5\u5c42\u7684\u6620\u5c04, logits\u5bf9\u5e94\u5206\u7c7b\u6570\u76ee logits = self . dense ( sentence_feature ) return logits","title":"\u6a21\u578b\u7c7b\u7684\u5b9e\u73b0"},{"location":"13_1.html#_5","text":"\u8bc4\u4f30\u51fd\u6570\u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/cnn_medical/evaluate.py # \u5bfc\u5165\u5de5\u5177\u5305 import numpy as np import torch from tqdm import tqdm import math # \u8ba1\u7b97\u8bc4\u4f30\u5206\u6570\u7684\u51fd\u6570 def semeval_scorer ( predict_label , true_label , class_num = 50 ): assert true_label . shape [ 0 ] == predict_label . shape [ 0 ] # \u8bbe\u7f6e\u56f0\u60d1\u77e9\u9635, \u5168\u96f6\u521d\u59cb\u5316\u5373\u53ef confusion_matrix = np . zeros ( shape = [ class_num , class_num ], dtype = np . float32 ) xDIRx = np . zeros ( shape = [ class_num ], dtype = np . float32 ) # \u904d\u5386\u6240\u6709\u6837\u672c\u6807\u7b7e, \u6bd4\u8f83\u6b63\u786e\u7684\u9884\u6d4b, \u9519\u8bef\u7684\u9884\u6d4b for i in range ( true_label . shape [ 0 ]): # \u83b7\u53d6\u771f\u5b9e\u6807\u7b7e, \u9884\u6d4b\u6807\u7b7e true_idx = math . ceil ( true_label [ i ] / 2 ) predict_idx = math . ceil ( predict_label [ i ] / 2 ) # \u6784\u9020\u56f0\u60d1\u77e9\u9635, \u6bcf\u6b63\u786e\u9884\u6d4b\u4e00\u4e2a\u6837\u672c, \u5bf9\u5e94\u7684\u5206\u7c7b\u503c+1 if true_label [ i ] == predict_label [ i ]: confusion_matrix [ predict_idx ][ true_idx ] += 1 else : if true_idx == predict_idx : xDIRx [ predict_idx ] += 1 else : confusion_matrix [ predict_idx ][ true_idx ] += 1 col_sum = np . sum ( confusion_matrix , axis = 0 ) . reshape ( - 1 ) row_sum = np . sum ( confusion_matrix , axis = 1 ) . reshape ( - 1 ) f1 = np . zeros ( shape = [ class_num ], dtype = np . float32 ) # \u5ffd\u7565\u6389'Other' for i in range ( 0 , class_num ): try : p = float ( confusion_matrix [ i ][ i ]) / float ( col_sum [ i ] + xDIRx [ i ]) r = float ( confusion_matrix [ i ][ i ]) / float ( row_sum [ i ] + xDIRx [ i ]) f1 [ i ] = ( 2 * p * r / ( p + r )) except : pass actual_class = 0 total_f1 = 0.0 for i in range ( 1 , class_num ): # \u4e0d\u5728\u9884\u6d4b\u6807\u7b7e\u4e2d\u7684\u5206\u7c7b, \u4e0d\u505a\u8003\u8651 if f1 [ i ] > 0.0 : actual_class += 1 total_f1 += f1 [ i ] # \u9632\u6b62\u9664\u96f6\u9519\u8bef try : macro_f1 = total_f1 / actual_class except : macro_f1 = 0.0 return macro_f1 # \u6784\u5efa\u8bc4\u4f30\u7c7b\u7684\u4ee3\u7801 class Eval ( object ): def __init__ ( self , config ): self . device = config . device def evaluate ( self , model , criterion , data_loader ): predict_label = [] true_label = [] total_loss = 0.0 # \u8bc4\u4f30\u9636\u6bb5, \u8bbe\u7f6e\u8bc4\u4f30\u6a21\u5f0f, \u5e76\u4e14\u4e0d\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u548c\u68af\u5ea6\u8ba1\u7b97 with torch . no_grad (): model . eval () for _ , ( data , label ) in tqdm ( enumerate ( data_loader )): data = data . to ( self . device ) label = label . to ( self . device ) # print('data.shape:', data.shape) # print('label:', label) # \u5c06\u8f93\u5165\u9001\u5165\u6a21\u578b, \u5f97\u5230\u6982\u7387\u5206\u5e03\u8f93\u51fa, \u8ba1\u7b97\u635f\u5931\u503c logits = model ( data ) loss = criterion ( logits , label ) total_loss += loss . item () * logits . shape [ 0 ] # print('logits:', logits) _ , pred = torch . max ( logits , dim = 1 ) # print('pred:', pred) pred = pred . cpu () . detach () . numpy () . reshape (( - 1 , 1 )) label = label . cpu () . detach () . numpy () . reshape (( - 1 , 1 )) # print('pred1:', pred) # print('******') predict_label . append ( pred ) true_label . append ( label ) # \u5c06\u6240\u6709batch\u7684\u9884\u6d4b\u7ed3\u679c\u548c\u771f\u5b9e\u7ed3\u679c, \u8fdb\u884c\u62fc\u63a5 predict_label = np . concatenate ( predict_label , axis = 0 ) . reshape ( - 1 ) . astype ( np . int64 ) true_label = np . concatenate ( true_label , axis = 0 ) . reshape ( - 1 ) . astype ( np . int64 ) eval_loss = total_loss / predict_label . shape [ 0 ] # \u8c03\u7528\u4e0a\u9762\u7684\u8bc4\u4f30\u5206\u6570\u51fd\u6570, \u5f97\u5230\u6d4b\u8bd5\u96c6\u4e0a\u603b\u4f53\u7684F1\u503c f1 = semeval_scorer ( predict_label , true_label ) return f1 , eval_loss , predict_label \u8bad\u7ec3\u51fd\u6570\u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/cnn_medical/run.py # \u5bfc\u5165\u5de5\u5177\u5305 import os import torch import torch.nn as nn import torch.optim as optim from config import Config from utils import WordEmbeddingLoader , RelationLoader , SemEvalDataLoader from model import CNN from evaluate import Eval from tqdm import tqdm # \u5c06\u63a8\u7406\u540e\u7684\u7ed3\u679c\u5199\u5165\u6587\u4ef6\u4e2d def print_result ( predict_label , id2rel , start_idx = 8001 ): with open ( 'predicted_result.txt' , 'w' , encoding = 'utf-8' ) as fw : for i in range ( 0 , predict_label . shape [ 0 ]): fw . write ( ' {} \\t {} \\n ' . format ( start_idx + i , id2rel [ int ( predict_label [ i ])])) # \u6a21\u578b\u7684\u603b\u4f53\u8bad\u7ec3\u51fd\u6570 def train ( model , criterion , loader , config ): train_loader , dev_loader , _ = loader optimizer = optim . Adam ( model . parameters (), lr = config . lr , weight_decay = config . L2_decay ) # \u4e0b\u97627\u884c\u4ee3\u7801\u4e3a\u663e\u793a\u4fe1\u606f\u7684\u8c03\u8bd5\u4ee3\u7801, \u4e0a\u7ebf\u540e\u53ef\u4ee5\u6ce8\u91ca\u6389 print ( model ) print ( 'traning model parameters:' ) for name , param in model . named_parameters (): if param . requires_grad : print ( ' %s : %s ' % ( name , str ( param . data . shape ))) print ( '--------------------------------------' ) print ( 'start to train the model ...' ) # \u8bc4\u4f30\u7c7b\u7684\u5bf9\u8c61, \u7528\u4e8e\u5bf9\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u8ba1\u7b97F1\u503c eval_tool = Eval ( config ) max_f1 = - float ( 'inf' ) # \u53cc\u91cdfor\u5faa\u73af\u6a21\u5f0f\u8fdb\u884c\u8bad\u7ec3 for epoch in tqdm ( range ( 1 , config . epoch + 1 )): model . train () for step , ( data , label ) in enumerate ( train_loader ): data = data . to ( config . device ) label = label . to ( config . device ) # \u7ecf\u5178\u7684\"\u8001\u4e09\u6837\" + \u6a21\u578b\u524d\u5411\u8ba1\u7b97 + \u635f\u5931\u503c\u8ba1\u7b97 optimizer . zero_grad () logits = model ( data ) loss = criterion ( logits , label ) loss . backward () optimizer . step () # \u6bcf\u4e00\u4e2aepoch\u7ed3\u675f\u540e, \u8fdb\u884c\u4e00\u8f6e\u8bad\u7ec3\u96c6\u7684\u8bc4\u4f30\u548c\u9a8c\u8bc1\u96c6\u7684\u8bc4\u4f30 _ , train_loss , _ = eval_tool . evaluate ( model , criterion , train_loader ) f1 , dev_loss , _ = eval_tool . evaluate ( model , criterion , dev_loader ) # \u5c06\u5173\u952e\u8bc4\u4f30\u7ed3\u679c\u6253\u5370\u51fa\u6765 print ( '[ %03d ] train_loss: %.3f | dev_loss: %.3f | micro f1 on dev: %.4f ' % ( epoch , train_loss , dev_loss , f1 ), end = ' ' ) # \u4ee5F1\u503c\u4f5c\u4e3a\u6807\u51c6, \u5c06\u8868\u73b0\u6700\u4f18\u7684\u6a21\u578b\u4fdd\u5b58\u4e0b\u6765 if f1 > max_f1 : max_f1 = f1 torch . save ( model . state_dict (), os . path . join ( config . model_dir , 'model.pt' )) print ( '>>> save models!' ) else : print () # \u6d4b\u8bd5\u51fd\u6570 def test ( model , criterion , loader , config ): print ( '--------------------------------------' ) print ( 'start test ...' ) _ , _ , test_loader = loader model . load_state_dict ( torch . load ( os . path . join ( config . model_dir , 'model.pt' ))) eval_tool = Eval ( config ) f1 , test_loss , predict_label = eval_tool . evaluate ( model , criterion , test_loader ) print ( 'test_loss: %.3f | micro f1 on test: %.4f ' % ( test_loss , f1 )) return predict_label # \u6700\u5916\u5c42\u63a5\u53e3, \u8c03\u8d77\u5168\u90e8\u51fd\u6570 if __name__ == '__main__' : config = Config () print ( '--------------------------------------' ) print ( 'some config:' ) config . print_config () print ( '--------------------------------------' ) print ( 'start to load data ...' ) vocab = WordEmbeddingLoader ( config ) . get_vocab () word_vec , word2id = WordEmbeddingLoader ( config ) . get_embedding ( vocab ) rel2id , id2rel , class_num = RelationLoader ( config ) . get_relation () loader = SemEvalDataLoader ( rel2id , word2id , config ) train_loader , dev_loader = None , None # mode\u8bbe\u7f6e\u4e3a1, \u4ee3\u8868\u8bad\u7ec3\u6a21\u5f0f if config . mode == 1 : train_loader = loader . get_train () dev_loader = loader . get_dev () test_loader = loader . get_test () loader = [ train_loader , dev_loader , test_loader ] print ( 'finish!' ) print ( '--------------------------------------' ) model = CNN ( word_vec = word_vec , class_num = class_num , config = config ) model = model . to ( config . device ) criterion = nn . CrossEntropyLoss () # model\u7b49\u4e8e1, \u5904\u4e8e\u8bad\u7ec3\u6a21\u5f0f if config . mode == 1 : train ( model , criterion , loader , config ) # \u5bf9\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\u5e76\u6253\u5370\u7ed3\u679c\u6587\u4ef6 predict_label = test ( model , criterion , loader , config ) print_result ( predict_label , id2rel ) \u8c03\u7528: python run.py \u8f93\u51fa\u7ed3\u679c: some config: data_dir = ./data output_dir = ./output train_raw = ./data/CMeIE_train.json embedding_path = ./embedding/sgns.weibo.word.bz2 vocab_size = 30000 word_dim = 300 model_name = CNN mode = 1 seed = 5782 cuda = 0 epoch = 50 dropout = 0.5 batch_size = 64 lr = 0.001 max_len = 100 pos_dis = 50 pos_dim = 5 hidden_size = 128 filter_num = 256 window = 3 L2_decay = 1e-05 device = cuda:0 model_dir = ./output/CNN -------------------------------------- start to load data ... Building prefix dict from the default dictionary ... Loading model from cache /tmp/jieba.cache Loading model cost 0.760 seconds. Prefix dict has been built successfully. processing embedding file ... b'195202' tokens in embedding file in total, vector size is b'300' 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 195202/195202 [00:03<00:00, 55842.67it/s] finish! -------------------------------------- CNN( (word_embedding): Embedding(11723, 300) (pos1_embedding): Embedding(103, 5) (pos2_embedding): Embedding(103, 5) (conv): Conv2d(1, 256, kernel_size=(3, 310), stride=(1, 1), padding=(1, 0)) (maxpool): MaxPool2d(kernel_size=(100, 1), stride=(100, 1), padding=0, dilation=1, ceil_mode=False) (tanh): Tanh() (dropout): Dropout(p=0.5, inplace=False) (linear): Linear(in_features=256, out_features=128, bias=True) (dense): Linear(in_features=128, out_features=53, bias=True) ) traning model parameters: word_embedding.weight : torch.Size([11723, 300]) pos1_embedding.weight : torch.Size([103, 5]) pos2_embedding.weight : torch.Size([103, 5]) conv.weight : torch.Size([256, 1, 3, 310]) conv.bias : torch.Size([256]) linear.weight : torch.Size([128, 256]) linear.bias : torch.Size([128]) dense.weight : torch.Size([53, 128]) dense.bias : torch.Size([53]) -------------------------------------- start to train the model ... 756it [00:01, 400.37it/s] | 0/50 [00:00<?, ?it/s] 93it [00:00, 321.20it/s]] [001] train_loss: 0.825 | dev_loss: 1.145 | micro f1 on dev: 0.6200 >>> save models! 756it [00:01, 401.55it/s] | 1/50 [00:08<07:03, 8.64s/it] 93it [00:00, 323.06it/s]] [002] train_loss: 0.466 | dev_loss: 0.999 | micro f1 on dev: 0.6643 >>> save models! 756it [00:01, 400.84it/s] | 2/50 [00:16<06:49, 8.53s/it] 93it [00:00, 314.22it/s]] [003] train_loss: 0.314 | dev_loss: 0.955 | micro f1 on dev: 0.7100 >>> save models! 756it [00:01, 401.99it/s] | 3/50 [00:25<06:37, 8.46s/it] 93it [00:00, 323.06it/s]] [004] train_loss: 0.239 | dev_loss: 0.994 | micro f1 on dev: 0.7169 >>> save models! 756it [00:01, 396.38it/s] | 4/50 [00:33<06:28, 8.44s/it] 93it [00:00, 323.16it/s]] [005] train_loss: 0.196 | dev_loss: 0.973 | micro f1 on dev: 0.7198 >>> save models! 756it [00:01, 389.98it/s] | 5/50 [00:41<06:18, 8.41s/it] 93it [00:00, 320.01it/s]] [006] train_loss: 0.154 | dev_loss: 0.999 | micro f1 on dev: 0.7152 756it [00:01, 400.31it/s] | 6/50 [00:50<06:08, 8.38s/it] 93it [00:00, 316.25it/s]] [007] train_loss: 0.136 | dev_loss: 0.999 | micro f1 on dev: 0.7112 756it [00:01, 400.90it/s] | 7/50 [00:58<05:58, 8.34s/it] 93it [00:00, 323.26it/s]] [008] train_loss: 0.122 | dev_loss: 1.039 | micro f1 on dev: 0.7243 >>> save models! 756it [00:01, 388.92it/s] | 8/50 [01:06<05:50, 8.34s/it] 93it [00:00, 316.58it/s]] [009] train_loss: 0.102 | dev_loss: 1.059 | micro f1 on dev: 0.7322 >>> save models! 756it [00:01, 390.39it/s] | 9/50 [01:15<05:42, 8.36s/it] 93it [00:00, 323.51it/s]] [010] train_loss: 0.094 | dev_loss: 1.063 | micro f1 on dev: 0.7156 756it [00:01, 395.49it/s] | 10/50 [01:23<05:34, 8.35s/it] 93it [00:00, 326.63it/s]] [011] train_loss: 0.084 | dev_loss: 1.090 | micro f1 on dev: 0.7295 756it [00:01, 399.23it/s] | 11/50 [01:31<05:24, 8.33s/it] 93it [00:00, 308.80it/s]] [012] train_loss: 0.078 | dev_loss: 1.089 | micro f1 on dev: 0.7195 756it [00:01, 393.74it/s] | 12/50 [01:40<05:16, 8.33s/it] 93it [00:00, 309.83it/s]] [013] train_loss: 0.069 | dev_loss: 1.143 | micro f1 on dev: 0.7288 756it [00:01, 388.05it/s] | 13/50 [01:48<05:08, 8.34s/it] 93it [00:00, 312.54it/s]] [014] train_loss: 0.067 | dev_loss: 1.195 | micro f1 on dev: 0.7193 756it [00:01, 391.20it/s] | 14/50 [01:56<05:00, 8.34s/it] 93it [00:00, 314.68it/s]] [015] train_loss: 0.059 | dev_loss: 1.144 | micro f1 on dev: 0.7165 756it [00:01, 393.72it/s]\u2588 | 15/50 [02:05<04:52, 8.35s/it] 93it [00:00, 320.70it/s]] [016] train_loss: 0.056 | dev_loss: 1.148 | micro f1 on dev: 0.6821 756it [00:01, 382.80it/s]\u2588\u2588\u258d | 16/50 [02:13<04:44, 8.35s/it] 93it [00:00, 318.80it/s]] [017] train_loss: 0.053 | dev_loss: 1.123 | micro f1 on dev: 0.7317 756it [00:01, 391.59it/s]\u2588\u2588\u2588\u258a | 17/50 [02:22<04:36, 8.37s/it] 93it [00:00, 320.01it/s]] [018] train_loss: 0.050 | dev_loss: 1.156 | micro f1 on dev: 0.7513 >>> save models! 756it [00:01, 390.35it/s]\u2588\u2588\u2588\u2588\u2588\u258f | 18/50 [02:30<04:29, 8.41s/it] 93it [00:00, 314.89it/s]] [019] train_loss: 0.046 | dev_loss: 1.125 | micro f1 on dev: 0.7299 756it [00:01, 384.87it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 19/50 [02:38<04:20, 8.41s/it] 93it [00:00, 319.72it/s]] [020] train_loss: 0.045 | dev_loss: 1.172 | micro f1 on dev: 0.7255 756it [00:01, 386.72it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 20/50 [02:47<04:12, 8.41s/it] 93it [00:00, 318.43it/s]] [021] train_loss: 0.040 | dev_loss: 1.195 | micro f1 on dev: 0.7018 756it [00:01, 395.28it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 21/50 [02:55<04:04, 8.43s/it] 93it [00:00, 318.02it/s]] [022] train_loss: 0.043 | dev_loss: 1.178 | micro f1 on dev: 0.7164 756it [00:01, 390.67it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 22/50 [03:04<03:55, 8.41s/it] 93it [00:00, 315.83it/s]] [023] train_loss: 0.038 | dev_loss: 1.153 | micro f1 on dev: 0.7326 756it [00:01, 390.15it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 23/50 [03:12<03:47, 8.42s/it] 93it [00:00, 320.54it/s]] [024] train_loss: 0.035 | dev_loss: 1.191 | micro f1 on dev: 0.7195 756it [00:01, 390.48it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 24/50 [03:21<03:38, 8.42s/it] 93it [00:00, 315.26it/s]] [025] train_loss: 0.033 | dev_loss: 1.187 | micro f1 on dev: 0.7206 756it [00:01, 384.46it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 25/50 [03:29<03:30, 8.43s/it] 93it [00:00, 315.56it/s]] [026] train_loss: 0.030 | dev_loss: 1.191 | micro f1 on dev: 0.7059 756it [00:01, 392.18it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 26/50 [03:37<03:22, 8.44s/it] 93it [00:00, 304.06it/s]] [027] train_loss: 0.030 | dev_loss: 1.185 | micro f1 on dev: 0.7271 756it [00:01, 389.80it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 27/50 [03:46<03:14, 8.44s/it] 93it [00:00, 310.55it/s]] [028] train_loss: 0.030 | dev_loss: 1.193 | micro f1 on dev: 0.7057 756it [00:01, 379.01it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 28/50 [03:54<03:05, 8.45s/it] 93it [00:00, 312.63it/s]] [029] train_loss: 0.028 | dev_loss: 1.243 | micro f1 on dev: 0.7497 756it [00:01, 387.16it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 29/50 [04:03<02:57, 8.47s/it] 93it [00:00, 310.71it/s]] [030] train_loss: 0.029 | dev_loss: 1.235 | micro f1 on dev: 0.7416 756it [00:01, 387.02it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 30/50 [04:11<02:49, 8.47s/it] 93it [00:00, 321.98it/s]] [031] train_loss: 0.026 | dev_loss: 1.230 | micro f1 on dev: 0.7244 756it [00:01, 388.13it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 31/50 [04:20<02:40, 8.47s/it] 93it [00:00, 319.43it/s]] [032] train_loss: 0.028 | dev_loss: 1.226 | micro f1 on dev: 0.7267 756it [00:01, 387.05it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 32/50 [04:28<02:32, 8.46s/it] 93it [00:00, 315.43it/s]] [033] train_loss: 0.025 | dev_loss: 1.246 | micro f1 on dev: 0.7370 756it [00:01, 390.52it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 33/50 [04:37<02:24, 8.47s/it] 93it [00:00, 320.73it/s]] [034] train_loss: 0.023 | dev_loss: 1.216 | micro f1 on dev: 0.7383 756it [00:01, 380.61it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 34/50 [04:45<02:15, 8.47s/it] 93it [00:00, 303.98it/s]] [035] train_loss: 0.022 | dev_loss: 1.253 | micro f1 on dev: 0.7239 756it [00:01, 384.96it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 35/50 [04:54<02:07, 8.49s/it] 93it [00:00, 320.49it/s]] [036] train_loss: 0.025 | dev_loss: 1.306 | micro f1 on dev: 0.7067 756it [00:01, 386.49it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 36/50 [05:02<01:58, 8.49s/it] 93it [00:00, 316.58it/s]] [037] train_loss: 0.021 | dev_loss: 1.293 | micro f1 on dev: 0.7109 756it [00:01, 389.53it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 37/50 [05:11<01:50, 8.48s/it] 93it [00:00, 312.16it/s]] [038] train_loss: 0.021 | dev_loss: 1.264 | micro f1 on dev: 0.7156 756it [00:01, 384.69it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 38/50 [05:19<01:41, 8.48s/it] 93it [00:00, 314.61it/s]] [039] train_loss: 0.020 | dev_loss: 1.275 | micro f1 on dev: 0.7333 756it [00:01, 389.65it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 39/50 [05:28<01:33, 8.48s/it] 93it [00:00, 314.57it/s]] [040] train_loss: 0.024 | dev_loss: 1.233 | micro f1 on dev: 0.7171 756it [00:01, 384.13it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 40/50 [05:36<01:24, 8.47s/it] 93it [00:00, 306.72it/s]] [041] train_loss: 0.019 | dev_loss: 1.287 | micro f1 on dev: 0.7411 756it [00:01, 390.68it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 41/50 [05:45<01:16, 8.48s/it] 93it [00:00, 318.88it/s]] [042] train_loss: 0.021 | dev_loss: 1.321 | micro f1 on dev: 0.7298 756it [00:01, 389.55it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 42/50 [05:53<01:07, 8.47s/it] 93it [00:00, 320.90it/s]] [043] train_loss: 0.018 | dev_loss: 1.256 | micro f1 on dev: 0.7520 >>> save models! 756it [00:01, 392.47it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 43/50 [06:02<00:59, 8.51s/it] 93it [00:00, 312.12it/s]] [044] train_loss: 0.018 | dev_loss: 1.284 | micro f1 on dev: 0.7397 756it [00:01, 382.02it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 44/50 [06:10<00:50, 8.50s/it] 93it [00:00, 316.05it/s]] [045] train_loss: 0.018 | dev_loss: 1.250 | micro f1 on dev: 0.7342 756it [00:01, 384.63it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 45/50 [06:19<00:42, 8.51s/it] 93it [00:00, 316.54it/s]] [046] train_loss: 0.018 | dev_loss: 1.288 | micro f1 on dev: 0.7446 756it [00:01, 387.57it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 46/50 [06:27<00:34, 8.50s/it] 93it [00:00, 309.89it/s]] [047] train_loss: 0.017 | dev_loss: 1.250 | micro f1 on dev: 0.7419 756it [00:01, 385.43it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 47/50 [06:36<00:25, 8.49s/it] 93it [00:00, 312.21it/s]] [048] train_loss: 0.018 | dev_loss: 1.282 | micro f1 on dev: 0.7186 756it [00:01, 381.55it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 48/50 [06:44<00:16, 8.49s/it] 93it [00:00, 310.74it/s]] [049] train_loss: 0.016 | dev_loss: 1.321 | micro f1 on dev: 0.7359 756it [00:01, 387.89it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 49/50 [06:53<00:08, 8.51s/it] 93it [00:00, 314.01it/s]] [050] train_loss: 0.017 | dev_loss: 1.296 | micro f1 on dev: 0.7193 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50/50 [07:01<00:00, 8.43s/it] -------------------------------------- start test ... 93it [00:00, 301.00it/s] test_loss: 1.256 | micro f1 on test: 0.7520 \u601d\u8003: \u5bf9\u4e8e\u5f53\u524d\u9879\u76ee\u4e2d\u768453\u79cd\u5173\u7cfb\u62bd\u53d6\u6a21\u578b, f1\u8fbe\u523075.20%\u7b97\u597d\u7684\u8868\u73b0\u5417?","title":"\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u51fd\u6570\u7684\u5b9e\u73b0"},{"location":"13_1.html#_6","text":"\u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/cnn_medical/predict.py import numpy as np import torch import time from torch.utils.data import Dataset , DataLoader from config import Config from utils import * from model import CNN config = Config () vocab = WordEmbeddingLoader ( config ) . get_vocab () word_vec , word2id = WordEmbeddingLoader ( config ) . get_embedding ( vocab ) rel2id , id2rel , class_num = RelationLoader ( config ) . get_relation () def get_pos_index ( x ): # pos_dis\u9ed8\u8ba4\u503c\u4e3a50, \u5df2\u5728config.py\u6587\u4ef6\u4e2d\u8bbe\u7f6e. # 1: \u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u5c0f\u4e8e-50, \u76f4\u63a5\u8fd4\u56de\u4f4d\u7f6e\u7f16\u78010. if x < - config . pos_dis : return 0 # 2: \u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801[-50, 50]\u4e4b\u95f4, \u91c7\u7528x + 50 + 1\u7684\u4f4d\u7f6e\u7f16\u7801\u503c. if x >= - config . pos_dis and x <= config . pos_dis : return x + config . pos_dis + 1 # 3: \u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u5927\u4e8e50, \u91c7\u75282 * 50 + 2 = 102\u7684\u4f4d\u7f6e\u7f16\u7801\u503c. if x > config . pos_dis : return 2 * config . pos_dis + 2 def get_relative_pos ( x , entity_pos ): # 1: \u7d22\u5f15x\u5728\u5b9e\u4f53\u7684\u5de6\u4fa7, \u91c7\u7528x - \u5de6\u8fb9\u754c\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801 if x < entity_pos [ 0 ]: return get_pos_index ( x - entity_pos [ 0 ]) # 2: \u7d22\u5f15x\u5728\u5b9e\u4f53\u7684\u53f3\u4fa7, \u91c7\u7528x - \u53f3\u8fb9\u754c\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801 elif x > entity_pos [ 1 ]: return get_pos_index ( x - entity_pos [ 1 ]) # 3: \u7d22\u5f15x\u5728\u5b9e\u4f53\u533a\u57df\u5185, \u91c7\u75280\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801 else : return get_pos_index ( 0 ) def preprocess_sentence ( e1_pos , e2_pos , sentence ): mask = [ 1 ] * len ( sentence ) if e1_pos [ 0 ] < e2_pos [ 0 ]: for i in range ( e1_pos [ 0 ], e2_pos [ 1 ] + 1 ): mask [ i ] = 2 for i in range ( e2_pos [ 1 ] + 1 , len ( sentence )): mask [ i ] = 3 else : for i in range ( e2_pos [ 0 ], e1_pos [ 1 ] + 1 ): mask [ i ] = 2 for i in range ( e1_pos [ 1 ] + 1 , len ( sentence )): mask [ i ] = 3 words , pos1 , pos2 = [], [], [] length = min ( config . max_len , len ( sentence )) mask = mask [: length ] for i in range ( length ): words . append ( word2id . get ( sentence [ i ] . lower (), word2id [ 'UNK' ])) pos1 . append ( get_relative_pos ( i , e1_pos )) pos2 . append ( get_relative_pos ( i , e2_pos )) if length < config . max_len : for i in range ( length , config . max_len ): mask . append ( 0 ) words . append ( word2id [ 'PAD' ]) pos1 . append ( get_relative_pos ( i , e1_pos )) pos2 . append ( get_relative_pos ( i , e2_pos )) unit = np . asarray ([ words , pos1 , pos2 , mask ], dtype = np . int64 ) unit = np . reshape ( unit , newshape = ( 1 , 4 , config . max_len )) return unit s1 = time . time () model = CNN ( word_vec = word_vec , class_num = class_num , config = config ) model . load_state_dict ( torch . load ( os . path . join ( config . model_dir , 'model.pt' ))) e1 = time . time () print ( 'init model cost time:' , e1 - s1 ) def predict ( model , data ): sentence = data [ 'sentence' ] e1_pos = ( data [ 'subject_start' ], data [ 'subject_end' ]) e2_pos = ( data [ 'object_start' ], data [ 'object_end' ]) one_sentence = preprocess_sentence ( e1_pos , e2_pos , sentence ) # input_data: [1, 4, 100] input_data = torch . from_numpy ( one_sentence ) logits = model ( input_data ) _ , pred = torch . max ( logits , dim = 1 ) pred_id = pred . item () pred_rel = id2rel [ pred_id ] return pred_rel if __name__ == '__main__' : data = { \"subject_start\" : 117 , \"subject_end\" : 119 , \"object_start\" : 163 , \"object_end\" : 166 , \"sentence\" : [ \"\u8111\" , \"\u708e\" , \"@\" , \"#\" , \"#\" , \"#\" , \" \" , \"\u5c40\" , \"\u7076\" , \"\u6027\" , \"\u795e\" , \"\u7ecf\" , \"\u529f\" , \"\u80fd\" , \"\u969c\" , \"\u788d\" , \" \" , \"\u5305\" , \"\u62ec\" , \"\u5931\" , \"\u8bed\" , \"\u3001\" , \"\u504f\" , \"\u76f2\" , \"\u3001\" , \"\u504f\" , \"\u762b\" , \"\u3001\" , \"\u5171\" , \"\u6d4e\" , \"\u5931\" , \"\u8c03\" , \"\u3001\" , \"\u8171\" , \"\u53cd\" , \"\u5c04\" , \"\u51cf\" , \"\u5f31\" , \"\u3001\" , \"\u5df4\" , \"\u5f6c\" , \"\u65af\" , \"\u57fa\" , \"\u5f81\" , \"\u3001\" , \"\u9885\" , \"\u795e\" , \"\u7ecf\" , \"\u529f\" , \"\u80fd\" , \"\u7f3a\" , \"\u9677\" , \"\uff08\" , \"\u53ef\" , \"\u89c1\" , \"\u4e8e\" , \" \" , \"H\" , \"H\" , \"V\" , \"-\" , \"6\" , \"\uff0c\" , \"\u7ed3\" , \"\u6838\" , \"\u75c5\" , \"\u3001\" , \"\u6885\" , \"\u6bd2\" , \"\u3001\" , \"\u5e03\" , \"\u6c0f\" , \"\u83cc\" , \"\u75c5\" , \"\u3001\" , \"\u6025\" , \"\u6027\" , \"\u64ad\" , \"\u6563\" , \"\u6027\" , \"\u8111\" , \"\u810a\" , \"\u9ad3\" , \"\u708e\" , \"\u3001\" , \"\u897f\" , \"\u5c3c\" , \"\u7f57\" , \"\u6cb3\" , \"\u75c5\" , \"\u6bd2\" , \"\u3001\" , \"\u5723\" , \"\u8def\" , \"\u6613\" , \"\u65af\" , \"\u8111\" , \"\u708e\" , \"\u75c5\" , \"\u6bd2\" , \"\u3001\" , \"\u6c34\" , \"\u75d8\" , \"\u5e26\" , \"\u72b6\" , \"\u75b1\" , \"\u75b9\" , \"\u75c5\" , \"\u6bd2\" , \"\u3001\" , \"\u4e59\" , \"\u578b\" , \"\u75b1\" , \"\u75b9\" , \"\u75c5\" , \"\u6bd2\" , \"\u3001\" , \"\u72c2\" , \"\u72ac\" , \"\u75c5\" , \"\uff09\" , \"\uff1b\" , \"\u9707\" , \"\u98a4\" , \"\uff08\" , \"\u866b\" , \"\u5a92\" , \"\u75c5\" , \"\u6bd2\" , \"\uff09\" , \"\uff1b\" , \"\u808c\" , \"\u9635\" , \"\u631b\" , \"\uff08\" , \"\u4e9a\" , \"\u6025\" , \"\u6027\" , \"\u786c\" , \"\u5316\" , \"\u6027\" , \"\u5168\" , \"\u8111\" , \"\u708e\" , \"\uff09\" , \"\uff1b\" , \"\u611f\" , \"\u89c9\" , \"\u5f02\" , \"\u5e38\" , \"\uff08\" , \"\u79d1\" , \"\u7f57\" , \"\u62c9\" , \"\u591a\" , \"\u8731\" , \"\u70ed\" , \"\u3001\" , \"\u72c2\" , \"\u72ac\" , \"\u75c5\" , \"\uff09\" , \"\uff1b\" , \"\u5168\" , \"\u8eab\" , \"\u865a\" , \"\u5f31\" , \"\uff08\" , \"\u897f\" , \"\u5c3c\" , \"\u7f57\" , \"\u6cb3\" , \"\u75c5\" , \"\u6bd2\" , \"\u3001\" , \"\u72c2\" , \"\u72ac\" , \"\u75c5\" , \"\uff09\" , \"\u3002\" ]} start_time = time . time () res = predict ( model , data ) end_time = time . time () print ( 'res=' , res ) print ( 'prediction time:' , end_time - start_time ) \u8c03\u7528: python predict.py \u8f93\u51fa\u7ed3\u679c: Building prefix dict from the default dictionary ... Loading model from cache /tmp/jieba.cache Loading model cost 0.754 seconds. Prefix dict has been built successfully. processing embedding file ... b'195202' tokens in embedding file in total, vector size is b'300' 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 195202/195202 [00:03<00:00, 55853.24it/s] init model cost time: 2.119168996810913 res= \u4e34\u5e8a\u8868\u73b0 prediction time: 0.0063593387603759766","title":"\u63a8\u7406\u4ee3\u7801\u7684\u5b9e\u73b0"},{"location":"13_1.html#_7","text":"","title":"\u5c0f\u8282\u603b\u7ed3"},{"location":"14_1.html","text":"CR-CNN\u5173\u7cfb\u62bd\u53d6\u6a21\u578b \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u638c\u63e1CR-CNN\u5173\u7cfb\u62bd\u53d6\u6a21\u578b\u7684\u4ee3\u7801\u5b9e\u73b0. CR-CNN\u5173\u7cfb\u62bd\u53d6\u6a21\u578b\u5b9e\u73b0 \u00b6 CR-CNN\u6a21\u578b\u7684\u603b\u4f53\u6784\u5efa\u6d41\u7a0b\u6709\u5982\u4e0b\u51e0\u4e2a\u6b65\u9aa4: \u7b2c1\u6b65: \u5de5\u5177\u7c7b\u51fd\u6570\u7684\u5b9e\u73b0 \u7b2c2\u6b65: \u6a21\u578b\u7c7b\u7684\u5b9e\u73b0 \u7b2c3\u6b65: \u8bc4\u4f30\u51fd\u6570\u7684\u5b9e\u73b0 \u7b2c4\u6b65: \u8bad\u7ec3\u4ee3\u7801\u7684\u5b9e\u73b0 \u7b2c5\u6b65: \u6a21\u578b\u7684\u8bad\u7ec3 \u7b2c1\u6b65: \u5de5\u5177\u7c7b\u51fd\u6570\u7684\u5b9e\u73b0 \u00b6 \u4ee3\u7801\u6587\u4ef6\u8def\u5f84: /home/ec2-user/code/relation/relation-classify/utils.py import numpy as np import time def now (): return str ( time . strftime ( '%Y-%m- %d %H:%M:%S' )) def save_pr ( out_dir , name , epoch , pre , rec , fp_res = None , opt = None ): if opt is None : out = open ( ' {} / {} _ {} _PR.txt' . format ( out_dir , name , epoch + 1 ), 'w' ) else : out = open ( ' {} / {} _ {} _ {} _PR.txt' . format ( out_dir , name , opt , epoch + 1 ), 'w' ) if fp_res is not None : fp_out = open ( ' {} / {} _ {} _FP.txt' . format ( out_dir , name , epoch + 1 ), 'w' ) for idx , r , p in fp_res : fp_out . write ( ' {} {} {} \\n ' . format ( idx , r , p )) fp_out . close () for p , r in zip ( pre , rec ): out . write ( ' {} {} \\n ' . format ( p , r )) out . close () def eval_metric ( true_y , pred_y , pred_p ): ''' calculate the precision and recall for p-r curve reglect the NA relation ''' assert len ( true_y ) == len ( pred_y ) positive_num = len ([ i for i in true_y if i [ 0 ] > 0 ]) index = np . argsort ( pred_p )[:: - 1 ] tp = 0 fp = 0 fn = 0 all_pre = [ 0 ] all_rec = [ 0 ] fp_res = [] for idx in range ( len ( true_y )): i = true_y [ index [ idx ]] j = pred_y [ index [ idx ]] if i [ 0 ] == 0 : # NA relation if j > 0 : fp_res . append (( index [ idx ], j , pred_p [ index [ idx ]])) fp += 1 else : if j == 0 : fn += 1 else : for k in i : if k == - 1 : break if k == j : tp += 1 break if fp + tp == 0 : precision = 1.0 else : precision = tp * 1.0 / ( tp + fp ) recall = tp * 1.0 / positive_num if precision != all_pre [ - 1 ] or recall != all_rec [ - 1 ]: all_pre . append ( precision ) all_rec . append ( recall ) print ( \"tp= {} ; fp= {} ; fn= {} ; positive_num= {} \" . format ( tp , fp , fn , positive_num )) return all_pre [ 1 :], all_rec [ 1 :], fp_res \u7b2c2\u6b65: \u6a21\u578b\u7c7b\u7684\u5b9e\u73b0 \u00b6 \u4ee3\u7801\u6587\u4ef6\u8def\u5f84: /home/ec2-user/code/relation/relation-classify/models/crcnn.py import torch import torch.nn as nn import torch.nn.functional as F from torch.nn import init class CRCNN ( nn . Module ): def __init__ ( self , word_vec , class_num , config ): super () . __init__ () self . word_vec = word_vec self . class_num = class_num # hyper parameters and others self . max_len = config . max_len self . word_dim = config . word_dim self . pos_dim = config . pos_dim self . pos_dis = config . pos_dis self . dropout_value = config . dropout self . filter_num = config . filter_num self . window = config . window self . dim = self . word_dim + 2 * self . pos_dim # net structures and operations self . word_embedding = nn . Embedding . from_pretrained ( embeddings = self . word_vec , freeze = False , ) self . pos1_embedding = nn . Embedding ( num_embeddings = 2 * self . pos_dis + 3 , embedding_dim = self . pos_dim ) self . pos2_embedding = nn . Embedding ( num_embeddings = 2 * self . pos_dis + 3 , embedding_dim = self . pos_dim ) self . conv = nn . Conv2d ( in_channels = 1 , out_channels = self . filter_num , kernel_size = ( self . window , self . dim ), stride = ( 1 , 1 ), bias = True , padding = ( 1 , 0 ), # same padding padding_mode = 'zeros' ) self . maxpool = nn . MaxPool2d (( self . max_len , 1 )) self . tanh = nn . Tanh () self . dropout = nn . Dropout ( self . dropout_value ) self . dense = nn . Linear ( in_features = self . filter_num , out_features = self . class_num , bias = False ) # initialize weight init . xavier_uniform_ ( self . pos1_embedding . weight ) init . xavier_uniform_ ( self . pos2_embedding . weight ) init . xavier_uniform_ ( self . conv . weight ) init . constant_ ( self . conv . bias , 0. ) init . xavier_uniform_ ( self . dense . weight ) # init.constant_(self.dense.bias, 0.) def encoder_layer ( self , token , pos1 , pos2 ): word_emb = self . word_embedding ( token ) # B*L*word_dim pos1_emb = self . pos1_embedding ( pos1 ) # B*L*pos_dim pos2_emb = self . pos2_embedding ( pos2 ) # B*L*pos_dim emb = torch . cat ( tensors = [ word_emb , pos1_emb , pos2_emb ], dim =- 1 ) return emb # B*L*D, D=word_dim+2*pos_dim def conv_layer ( self , emb , mask ): emb = emb . unsqueeze ( dim = 1 ) # B*1*L*D conv = self . conv ( emb ) # B*C*L*1 # mask, remove the effect of 'PAD' conv = conv . view ( - 1 , self . filter_num , self . max_len ) # B*C*L mask = mask . unsqueeze ( dim = 1 ) # B*1*L mask = mask . expand ( - 1 , self . filter_num , - 1 ) # B*C*L conv = conv . masked_fill ( mask . eq ( 0 ), float ( '-inf' )) # B*C*L conv = conv . unsqueeze ( dim =- 1 ) # B*C*L*1 return conv def single_maxpool_layer ( self , conv ): pool = self . maxpool ( conv ) # B*C*1*1 pool = pool . view ( - 1 , self . filter_num ) # B*C return pool def forward ( self , data ): token = data [ 0 ][:, 0 , :] . view ( - 1 , self . max_len ) pos1 = data [ 0 ][:, 1 , :] . view ( - 1 , self . max_len ) pos2 = data [ 0 ][:, 2 , :] . view ( - 1 , self . max_len ) mask = data [ 0 ][:, 3 , :] . view ( - 1 , self . max_len ) emb = self . encoder_layer ( token , pos1 , pos2 ) emb = self . dropout ( emb ) conv = self . conv_layer ( emb , mask ) conv = self . tanh ( conv ) pool = self . single_maxpool_layer ( conv ) feature = self . dropout ( pool ) scores = self . dense ( feature ) return scores class PairwiseRankingLoss ( nn . Module ): def __init__ ( self , config ): super () . __init__ () self . margin_positive = config . margin_positive self . margin_negative = config . margin_negative self . gamma = config . gamma def forward ( self , scores , labels ): mask = F . one_hot ( labels , scores . shape [ - 1 ]) positive_scores = scores . masked_fill ( mask . eq ( 0 ), float ( '-inf' )) . max ( dim = 1 )[ 0 ] negative_scores = scores . masked_fill ( mask . eq ( 1 ), float ( '-inf' )) . max ( dim = 1 )[ 0 ] positive_loss = torch . log1p ( torch . exp ( self . gamma * ( self . margin_positive - positive_scores ))) positive_loss [ labels == 0 ] = 0.0 # exclusive `Other` loss negative_loss = torch . log1p ( torch . exp ( self . gamma * ( self . margin_negative + negative_scores ))) loss = torch . mean ( positive_loss + negative_loss ) return loss \u7b2c3\u6b65: \u8bc4\u4f30\u51fd\u6570\u7684\u5b9e\u73b0 \u00b6 \u4ee3\u7801\u6587\u4ef6\u8def\u5f84: /home/ec2-user/code/relation/relation-classify/evaluate.py import numpy as np import torch def semeval_scorer ( predict_label , true_label , class_num = 10 ): import math assert true_label . shape [ 0 ] == predict_label . shape [ 0 ] confusion_matrix = np . zeros ( shape = [ class_num , class_num ], dtype = np . float32 ) xDIRx = np . zeros ( shape = [ class_num ], dtype = np . float32 ) for i in range ( true_label . shape [ 0 ]): true_idx = math . ceil ( true_label [ i ] / 2 ) predict_idx = math . ceil ( predict_label [ i ] / 2 ) if true_label [ i ] == predict_label [ i ]: confusion_matrix [ predict_idx ][ true_idx ] += 1 else : if true_idx == predict_idx : xDIRx [ predict_idx ] += 1 else : confusion_matrix [ predict_idx ][ true_idx ] += 1 col_sum = np . sum ( confusion_matrix , axis = 0 ) . reshape ( - 1 ) row_sum = np . sum ( confusion_matrix , axis = 1 ) . reshape ( - 1 ) f1 = np . zeros ( shape = [ class_num ], dtype = np . float32 ) for i in range ( 0 , class_num ): # ignore the 'Other' try : p = float ( confusion_matrix [ i ][ i ]) / float ( col_sum [ i ] + xDIRx [ i ]) r = float ( confusion_matrix [ i ][ i ]) / float ( row_sum [ i ] + xDIRx [ i ]) f1 [ i ] = ( 2 * p * r / ( p + r )) except : pass actual_class = 0 total_f1 = 0.0 for i in range ( 1 , class_num ): if f1 [ i ] > 0.0 : # classes that not in the predict label are not considered actual_class += 1 total_f1 += f1 [ i ] try : macro_f1 = total_f1 / actual_class except : macro_f1 = 0.0 return macro_f1 class Eval ( object ): def __init__ ( self , config ): self . device = config . device def evaluate ( self , model , criterion , data_loader ): predict_label = [] true_label = [] total_loss = 0.0 with torch . no_grad (): model . eval () for _ , ( data , label ) in enumerate ( data_loader ): sent_feat = data [ 0 ] . to ( self . device ) lex_feat = data [ 1 ] . to ( self . device ) data = ( sent_feat , lex_feat ) label = label . to ( self . device ) scores = model ( data ) loss = criterion ( scores , label ) scores = torch . softmax ( scores , dim = 1 ) total_loss += loss . item () * scores . shape [ 0 ] scores , pred = torch . max ( scores [:, 1 :], dim = 1 ) pred = pred + 1 scores = scores . cpu () . detach () . numpy () . reshape (( - 1 , 1 )) pred = pred . cpu () . detach () . numpy () . reshape (( - 1 , 1 )) label = label . cpu () . detach () . numpy () . reshape (( - 1 , 1 )) # During prediction time, a relation is classified as Other # only if all actual classes have negative scores. # Otherwise, it is classified with the class which has the largest score. for i in range ( pred . shape [ 0 ]): if scores [ i ][ 0 ] < 0 : pred [ i ][ 0 ] = 0 predict_label . append ( pred ) true_label . append ( label ) predict_label = np . concatenate ( predict_label , axis = 0 ) . reshape ( - 1 ) . astype ( np . int64 ) true_label = np . concatenate ( true_label , axis = 0 ) . reshape ( - 1 ) . astype ( np . int64 ) eval_loss = total_loss / predict_label . shape [ 0 ] f1 = semeval_scorer ( predict_label , true_label ) return f1 , eval_loss , predict_label \u7b2c4\u6b65: \u8bad\u7ec3\u4ee3\u7801\u7684\u5b9e\u73b0 \u00b6 \u4ee3\u7801\u6587\u4ef6\u8def\u5f84: /home/ec2-user/code/relation/relation-classify/cr_cnn_train.py import os import torch import torch.nn as nn import torch.optim as optim from tqdm import tqdm from config_cr_cnn import Config from dataset.dataset import WordEmbeddingLoader , RelationLoader , SemEvalDataLoader , VocabGenerator from models import * from evaluate import Eval def print_result ( predict_label , id2rel , start_idx = 8001 ): with open ( 'script/predicted_result.txt' , 'w' , encoding = 'utf-8' ) as fw : for i in range ( 0 , predict_label . shape [ 0 ]): fw . write ( ' {} \\t {} \\n ' . format ( start_idx + i , id2rel [ int ( predict_label [ i ])])) def train ( model , criterion , loader , config ): train_loader , dev_loader , _ = loader optimizer = optim . Adam ( model . parameters (), lr = config . lr , weight_decay = config . L2_decay ) print ( model ) print ( 'traning model parameters:' ) for name , param in model . named_parameters (): if param . requires_grad : print ( ' %s : %s ' % ( name , str ( param . data . shape ))) print ( '--------------------------------------' ) print ( 'start to train the model ...' ) eval_tool = Eval ( config ) min_f1 = - float ( 'inf' ) for epoch in tqdm ( range ( 1 , config . epoch + 1 )): model . train () for step , ( data , label ) in tqdm ( enumerate ( train_loader )): sent_feat = data [ 0 ] . to ( config . device ) lex_feat = data [ 1 ] . to ( config . device ) data = ( sent_feat , lex_feat ) label = label . to ( config . device ) optimizer . zero_grad () logits = model ( data ) loss = criterion ( logits , label ) loss . backward () optimizer . step () _ , train_loss , _ = eval_tool . evaluate ( model , criterion , train_loader ) f1 , dev_loss , _ = eval_tool . evaluate ( model , criterion , dev_loader ) print ( '[ %03d ] train_loss: %.3f | dev_loss: %.3f | micro f1 on dev: %.4f ' % ( epoch , train_loss , dev_loss , f1 ), end = ' ' ) if f1 > min_f1 : min_f1 = f1 torch . save ( model . state_dict (), os . path . join ( config . model_dir , 'model.pt' )) print ( '>>> save models!' ) else : print () def test ( model , criterion , loader , config ): print ( '--------------------------------------' ) print ( 'start test ...' ) _ , _ , test_loader = loader model . load_state_dict ( torch . load ( os . path . join ( config . model_dir , 'model.pt' ))) eval_tool = Eval ( config ) f1 , test_loss , predict_label = eval_tool . evaluate ( model , criterion , test_loader ) print ( 'test_loss: %.3f | micro f1 on test: %.4f ' % ( test_loss , f1 )) return predict_label if __name__ == '__main__' : config = Config () print ( '--------------------------------------' ) print ( 'some config:' ) config . print_config () print ( '--------------------------------------' ) print ( 'start to load data ...' ) vocab = VocabGenerator ( 'data/train.json' , 'data/test.json' ) . get_vocab () word2id , word_vec = WordEmbeddingLoader ( config ) . trim_from_pre_embedding ( vocab ) rel2id , id2rel , class_num = RelationLoader ( config ) . get_relation () loader = SemEvalDataLoader ( rel2id , word2id , config ) train_loader , dev_loader = None , None if config . mode == 1 : # train mode train_loader = loader . get_train () dev_loader = loader . get_dev () test_loader = loader . get_test () loader = [ train_loader , dev_loader , test_loader ] print ( 'finish!' ) print ( '--------------------------------------' ) model = CRCNN ( word_vec = word_vec , class_num = class_num , config = config ) model = model . to ( config . device ) #criterion = nn.CrossEntropyLoss() criterion = PairwiseRankingLoss ( config ) if config . mode == 1 : # train mode train ( model , criterion , loader , config ) predict_label = test ( model , criterion , loader , config ) print_result ( predict_label , id2rel ) \u7b2c5\u6b65: \u6a21\u578b\u7684\u8bad\u7ec3 \u00b6 \u8c03\u7528: python cr_cnn_train.py \u8f93\u51fa\u7ed3\u679c: -------------------------------------- some config: data_dir = ./data output_dir = ./output embedding_path = ./embedding/glove.6B.50d.txt word_dim = 50 model_name = CNN2 mode = 1 seed = 666 cuda = 0 epoch = 500 dropout = 0.3 batch_size = 64 lr = 0.001 max_len = 256 pos_dis = 50 pos_dim = 5 hidden_size = 128 filter_num = 512 window = 3 margin_positive = 2.5 margin_negative = 0.5 gamma = 2.0 L2_decay = 0.0001 device = cuda:0 model_dir = ./output/CNN2 -------------------------------------- start to load data ... finish! -------------------------------------- CRCNN( (word_embedding): Embedding(23503, 50) (pos1_embedding): Embedding(103, 5) (pos2_embedding): Embedding(103, 5) (conv): Conv2d(1, 512, kernel_size=(3, 60), stride=(1, 1), padding=(1, 0)) (maxpool): MaxPool2d(kernel_size=(256, 1), stride=(256, 1), padding=0, dilation=1, ceil_mode=False) (tanh): Tanh() (dropout): Dropout(p=0.3, inplace=False) (dense): Linear(in_features=512, out_features=19, bias=False) ) traning model parameters: word_embedding.weight : torch.Size([23503, 50]) pos1_embedding.weight : torch.Size([103, 5]) pos2_embedding.weight : torch.Size([103, 5]) conv.weight : torch.Size([512, 1, 3, 60]) conv.bias : torch.Size([512]) dense.weight : torch.Size([19, 512]) -------------------------------------- start to train the model ... 125it [00:01, 72.47it/s] | 0/500 [00:00<?, ?it/s] [001] train_loss: 4.986 | dev_loss: 5.102 | micro f1 on dev: 0.4993 >>> save models! 125it [00:01, 93.19it/s] | 1/500 [00:03<25:11, 3.03s/it] [002] train_loss: 4.124 | dev_loss: 4.298 | micro f1 on dev: 0.6539 >>> save models! 125it [00:01, 91.50it/s] | 2/500 [00:05<24:10, 2.91s/it] [003] train_loss: 3.470 | dev_loss: 3.678 | micro f1 on dev: 0.6978 >>> save models! 125it [00:01, 92.03it/s] | 3/500 [00:08<23:31, 2.84s/it] [004] train_loss: 3.028 | dev_loss: 3.391 | micro f1 on dev: 0.7196 >>> save models! 125it [00:01, 92.32it/s] | 4/500 [00:11<23:02, 2.79s/it] [005] train_loss: 2.651 | dev_loss: 3.176 | micro f1 on dev: 0.7371 >>> save models! 125it [00:01, 92.14it/s] | 5/500 [00:13<22:41, 2.75s/it] [006] train_loss: 2.321 | dev_loss: 3.027 | micro f1 on dev: 0.7531 >>> save models! 125it [00:01, 91.87it/s] | 6/500 [00:16<22:24, 2.72s/it] [007] train_loss: 2.024 | dev_loss: 2.894 | micro f1 on dev: 0.7687 >>> save models! 125it [00:01, 92.68it/s] | 7/500 [00:18<22:14, 2.71s/it] [008] train_loss: 1.760 | dev_loss: 2.832 | micro f1 on dev: 0.7757 >>> save models! 125it [00:01, 91.36it/s] | 8/500 [00:21<22:02, 2.69s/it] [009] train_loss: 1.503 | dev_loss: 2.747 | micro f1 on dev: 0.7829 >>> save models! 125it [00:01, 92.58it/s] | 9/500 [00:24<21:57, 2.68s/it] [010] train_loss: 1.278 | dev_loss: 2.696 | micro f1 on dev: 0.7832 >>> save models! 125it [00:01, 93.99it/s] | 10/500 [00:26<21:48, 2.67s/it] [011] train_loss: 1.079 | dev_loss: 2.682 | micro f1 on dev: 0.7864 >>> save models! 125it [00:01, 92.89it/s] | 11/500 [00:29<21:41, 2.66s/it] [012] train_loss: 0.908 | dev_loss: 2.643 | micro f1 on dev: 0.7915 >>> save models! 125it [00:01, 93.47it/s] | 12/500 [00:32<21:37, 2.66s/it] [013] train_loss: 0.832 | dev_loss: 2.651 | micro f1 on dev: 0.7943 >>> save models! 125it [00:01, 92.52it/s] | 13/500 [00:34<21:32, 2.65s/it] [014] train_loss: 0.649 | dev_loss: 2.656 | micro f1 on dev: 0.7931 125it [00:01, 93.09it/s] | 14/500 [00:37<21:25, 2.64s/it] [015] train_loss: 0.529 | dev_loss: 2.646 | micro f1 on dev: 0.7933 125it [00:01, 92.17it/s] | 15/500 [00:40<21:18, 2.64s/it] [016] train_loss: 0.466 | dev_loss: 2.664 | micro f1 on dev: 0.7947 >>> save models! 125it [00:01, 92.91it/s] | 16/500 [00:42<21:18, 2.64s/it] [017] train_loss: 0.417 | dev_loss: 2.670 | micro f1 on dev: 0.7935 125it [00:01, 91.00it/s] | 17/500 [00:45<21:12, 2.64s/it] [018] train_loss: 0.349 | dev_loss: 2.718 | micro f1 on dev: 0.7946 125it [00:01, 92.02it/s] | 18/500 [00:48<21:11, 2.64s/it] [019] train_loss: 0.258 | dev_loss: 2.706 | micro f1 on dev: 0.7894 125it [00:01, 92.72it/s] | 19/500 [00:50<21:10, 2.64s/it] [020] train_loss: 0.232 | dev_loss: 2.734 | micro f1 on dev: 0.7881 125it [00:01, 92.14it/s] | 20/500 [00:53<21:05, 2.64s/it] [021] train_loss: 0.212 | dev_loss: 2.791 | micro f1 on dev: 0.7891 125it [00:01, 92.74it/s] | 21/500 [00:55<21:00, 2.63s/it] [022] train_loss: 0.147 | dev_loss: 2.758 | micro f1 on dev: 0.7909 125it [00:01, 91.67it/s] | 22/500 [00:58<20:54, 2.62s/it] [023] train_loss: 0.124 | dev_loss: 2.772 | micro f1 on dev: 0.7903 125it [00:01, 92.53it/s] | 23/500 [01:01<20:50, 2.62s/it] [024] train_loss: 0.115 | dev_loss: 2.797 | micro f1 on dev: 0.7948 >>> save models! 125it [00:01, 92.38it/s] | 24/500 [01:03<20:52, 2.63s/it] [025] train_loss: 0.091 | dev_loss: 2.819 | micro f1 on dev: 0.7944 125it [00:01, 93.38it/s] | 25/500 [01:06<20:47, 2.63s/it] [026] train_loss: 0.073 | dev_loss: 2.886 | micro f1 on dev: 0.7922 125it [00:01, 92.56it/s] | 26/500 [01:09<20:42, 2.62s/it] [027] train_loss: 0.069 | dev_loss: 2.942 | micro f1 on dev: 0.7913 125it [00:01, 92.54it/s] | 27/500 [01:11<20:38, 2.62s/it] [028] train_loss: 0.057 | dev_loss: 2.944 | micro f1 on dev: 0.7929 125it [00:01, 91.92it/s] | 28/500 [01:14<20:34, 2.62s/it] [029] train_loss: 0.063 | dev_loss: 2.988 | micro f1 on dev: 0.7911 125it [00:01, 91.53it/s] | 29/500 [01:16<20:33, 2.62s/it] [030] train_loss: 0.048 | dev_loss: 2.972 | micro f1 on dev: 0.7892 125it [00:01, 91.76it/s] | 30/500 [01:19<20:34, 2.63s/it] [031] train_loss: 0.041 | dev_loss: 3.001 | micro f1 on dev: 0.7874 125it [00:01, 92.71it/s] | 31/500 [01:22<20:33, 2.63s/it] [032] train_loss: 0.026 | dev_loss: 3.040 | micro f1 on dev: 0.7864 125it [00:01, 92.16it/s] | 32/500 [01:24<20:27, 2.62s/it] [033] train_loss: 0.022 | dev_loss: 3.027 | micro f1 on dev: 0.7892 125it [00:01, 92.27it/s] | 33/500 [01:27<20:22, 2.62s/it] [034] train_loss: 0.030 | dev_loss: 3.082 | micro f1 on dev: 0.7859 125it [00:01, 92.45it/s] | 34/500 [01:30<20:21, 2.62s/it] [035] train_loss: 0.020 | dev_loss: 3.103 | micro f1 on dev: 0.7902 125it [00:01, 91.99it/s] | 35/500 [01:32<20:18, 2.62s/it] [036] train_loss: 0.016 | dev_loss: 3.073 | micro f1 on dev: 0.7888 125it [00:01, 92.85it/s] | 36/500 [01:35<20:16, 2.62s/it] [037] train_loss: 0.014 | dev_loss: 3.077 | micro f1 on dev: 0.7890 125it [00:01, 92.45it/s] | 37/500 [01:37<20:15, 2.63s/it] [038] train_loss: 0.012 | dev_loss: 3.081 | micro f1 on dev: 0.7905 125it [00:01, 92.11it/s] | 38/500 [01:40<20:11, 2.62s/it] [039] train_loss: 0.014 | dev_loss: 3.088 | micro f1 on dev: 0.7888 125it [00:01, 92.07it/s] | 39/500 [01:43<20:09, 2.62s/it] [040] train_loss: 0.022 | dev_loss: 3.170 | micro f1 on dev: 0.7899 125it [00:01, 92.35it/s] | 40/500 [01:45<20:04, 2.62s/it] [041] train_loss: 0.013 | dev_loss: 3.135 | micro f1 on dev: 0.7890 125it [00:01, 91.45it/s] | 41/500 [01:48<20:02, 2.62s/it] [042] train_loss: 0.015 | dev_loss: 3.166 | micro f1 on dev: 0.7907 125it [00:01, 92.23it/s] | 42/500 [01:51<20:02, 2.63s/it] [043] train_loss: 0.006 | dev_loss: 3.240 | micro f1 on dev: 0.7893 125it [00:01, 91.28it/s] | 43/500 [01:53<19:59, 2.63s/it] [044] train_loss: 0.008 | dev_loss: 3.148 | micro f1 on dev: 0.7909 125it [00:01, 91.91it/s] | 44/500 [01:56<20:01, 2.64s/it] [045] train_loss: 0.011 | dev_loss: 3.219 | micro f1 on dev: 0.7886 125it [00:01, 90.89it/s] | 45/500 [01:58<20:00, 2.64s/it] [046] train_loss: 0.009 | dev_loss: 3.241 | micro f1 on dev: 0.7823 125it [00:01, 91.49it/s] | 46/500 [02:01<20:00, 2.64s/it] [047] train_loss: 0.004 | dev_loss: 3.310 | micro f1 on dev: 0.7829 125it [00:01, 91.44it/s] | 47/500 [02:04<19:57, 2.64s/it] [048] train_loss: 0.008 | dev_loss: 3.284 | micro f1 on dev: 0.7847 125it [00:01, 91.50it/s] | 48/500 [02:06<19:52, 2.64s/it] [049] train_loss: 0.005 | dev_loss: 3.320 | micro f1 on dev: 0.7867 125it [00:01, 91.67it/s] | 49/500 [02:09<19:50, 2.64s/it] [050] train_loss: 0.007 | dev_loss: 3.354 | micro f1 on dev: 0.7833 125it [00:01, 91.29it/s] | 50/500 [02:12<19:46, 2.64s/it] [051] train_loss: 0.007 | dev_loss: 3.352 | micro f1 on dev: 0.7831 125it [00:01, 91.35it/s] ...... ...... ...... ...... ...... ...... 125it [00:01, 91.35it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 451/500 [19:49<02:09, 2.65s/it] [452] train_loss: 0.001 | dev_loss: 3.575 | micro f1 on dev: 0.7664 125it [00:01, 91.33it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 452/500 [19:52<02:06, 2.64s/it] [453] train_loss: 0.002 | dev_loss: 3.567 | micro f1 on dev: 0.7705 125it [00:01, 91.46it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 453/500 [19:55<02:04, 2.64s/it] [454] train_loss: 0.001 | dev_loss: 3.575 | micro f1 on dev: 0.7750 125it [00:01, 91.57it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 454/500 [19:57<02:01, 2.64s/it] [455] train_loss: 0.002 | dev_loss: 3.555 | micro f1 on dev: 0.7721 125it [00:01, 91.27it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 455/500 [20:00<01:58, 2.64s/it] [456] train_loss: 0.001 | dev_loss: 3.630 | micro f1 on dev: 0.7656 125it [00:01, 91.73it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 456/500 [20:03<01:56, 2.64s/it] [457] train_loss: 0.001 | dev_loss: 3.574 | micro f1 on dev: 0.7624 125it [00:01, 91.71it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 457/500 [20:05<01:53, 2.63s/it] [458] train_loss: 0.002 | dev_loss: 3.534 | micro f1 on dev: 0.7666 125it [00:01, 92.20it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 458/500 [20:08<01:50, 2.63s/it] [459] train_loss: 0.001 | dev_loss: 3.593 | micro f1 on dev: 0.7624 125it [00:01, 91.57it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 459/500 [20:11<01:47, 2.63s/it] [460] train_loss: 0.002 | dev_loss: 3.513 | micro f1 on dev: 0.7653 125it [00:01, 90.88it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 460/500 [20:13<01:45, 2.63s/it] [461] train_loss: 0.001 | dev_loss: 3.623 | micro f1 on dev: 0.7630 125it [00:01, 90.88it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 461/500 [20:16<01:42, 2.63s/it] [462] train_loss: 0.001 | dev_loss: 3.616 | micro f1 on dev: 0.7657 125it [00:01, 92.40it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 462/500 [20:18<01:40, 2.64s/it] [463] train_loss: 0.001 | dev_loss: 3.542 | micro f1 on dev: 0.7658 125it [00:01, 90.01it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 463/500 [20:21<01:37, 2.63s/it] [464] train_loss: 0.001 | dev_loss: 3.535 | micro f1 on dev: 0.7681 125it [00:01, 90.92it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 464/500 [20:24<01:34, 2.64s/it] [465] train_loss: 0.001 | dev_loss: 3.603 | micro f1 on dev: 0.7693 125it [00:01, 91.30it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 465/500 [20:26<01:32, 2.64s/it] [466] train_loss: 0.002 | dev_loss: 3.590 | micro f1 on dev: 0.7676 125it [00:01, 91.11it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 466/500 [20:29<01:29, 2.64s/it] [467] train_loss: 0.001 | dev_loss: 3.568 | micro f1 on dev: 0.7664 125it [00:01, 91.60it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 467/500 [20:32<01:27, 2.64s/it] [468] train_loss: 0.002 | dev_loss: 3.587 | micro f1 on dev: 0.7680 125it [00:01, 91.54it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 468/500 [20:34<01:24, 2.64s/it] [469] train_loss: 0.001 | dev_loss: 3.603 | micro f1 on dev: 0.7640 125it [00:01, 91.40it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 469/500 [20:37<01:21, 2.64s/it] [470] train_loss: 0.001 | dev_loss: 3.551 | micro f1 on dev: 0.7668 125it [00:01, 91.04it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 470/500 [20:40<01:19, 2.63s/it] [471] train_loss: 0.001 | dev_loss: 3.595 | micro f1 on dev: 0.7672 125it [00:01, 91.39it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 471/500 [20:42<01:16, 2.63s/it] [472] train_loss: 0.001 | dev_loss: 3.582 | micro f1 on dev: 0.7666 125it [00:01, 91.65it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 472/500 [20:45<01:13, 2.64s/it] [473] train_loss: 0.001 | dev_loss: 3.543 | micro f1 on dev: 0.7672 125it [00:01, 91.70it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 473/500 [20:47<01:11, 2.63s/it] [474] train_loss: 0.002 | dev_loss: 3.566 | micro f1 on dev: 0.7662 125it [00:01, 92.36it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 474/500 [20:50<01:08, 2.64s/it] [475] train_loss: 0.001 | dev_loss: 3.634 | micro f1 on dev: 0.7628 125it [00:01, 91.30it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 475/500 [20:53<01:05, 2.63s/it] [476] train_loss: 0.001 | dev_loss: 3.693 | micro f1 on dev: 0.7624 125it [00:01, 91.98it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 476/500 [20:55<01:03, 2.63s/it] [477] train_loss: 0.002 | dev_loss: 3.640 | micro f1 on dev: 0.7622 125it [00:01, 91.08it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 477/500 [20:58<01:00, 2.63s/it] [478] train_loss: 0.001 | dev_loss: 3.635 | micro f1 on dev: 0.7642 125it [00:01, 90.69it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 478/500 [21:01<00:58, 2.64s/it] [479] train_loss: 0.001 | dev_loss: 3.563 | micro f1 on dev: 0.7687 125it [00:01, 91.59it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 479/500 [21:03<00:55, 2.65s/it] [480] train_loss: 0.001 | dev_loss: 3.607 | micro f1 on dev: 0.7688 125it [00:01, 91.57it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 480/500 [21:06<00:52, 2.65s/it] [481] train_loss: 0.001 | dev_loss: 3.532 | micro f1 on dev: 0.7674 125it [00:01, 90.23it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 481/500 [21:09<00:50, 2.64s/it] [482] train_loss: 0.001 | dev_loss: 3.606 | micro f1 on dev: 0.7714 125it [00:01, 91.32it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 482/500 [21:11<00:47, 2.65s/it] [483] train_loss: 0.002 | dev_loss: 3.573 | micro f1 on dev: 0.7689 125it [00:01, 90.71it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 483/500 [21:14<00:45, 2.65s/it] [484] train_loss: 0.001 | dev_loss: 3.534 | micro f1 on dev: 0.7704 125it [00:01, 91.12it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 484/500 [21:17<00:42, 2.65s/it] [485] train_loss: 0.003 | dev_loss: 3.540 | micro f1 on dev: 0.7655 125it [00:01, 90.58it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 485/500 [21:19<00:39, 2.65s/it] [486] train_loss: 0.002 | dev_loss: 3.533 | micro f1 on dev: 0.7610 125it [00:01, 91.35it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 486/500 [21:22<00:37, 2.65s/it] [487] train_loss: 0.001 | dev_loss: 3.556 | micro f1 on dev: 0.7661 125it [00:01, 91.92it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 487/500 [21:24<00:34, 2.65s/it] [488] train_loss: 0.001 | dev_loss: 3.533 | micro f1 on dev: 0.7650 125it [00:01, 91.90it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 488/500 [21:27<00:31, 2.64s/it] [489] train_loss: 0.002 | dev_loss: 3.597 | micro f1 on dev: 0.7590 125it [00:01, 90.40it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 489/500 [21:30<00:28, 2.63s/it] [490] train_loss: 0.003 | dev_loss: 3.524 | micro f1 on dev: 0.7665 125it [00:01, 91.52it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 490/500 [21:32<00:26, 2.64s/it] [491] train_loss: 0.001 | dev_loss: 3.568 | micro f1 on dev: 0.7617 125it [00:01, 91.35it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 491/500 [21:35<00:23, 2.63s/it] [492] train_loss: 0.001 | dev_loss: 3.574 | micro f1 on dev: 0.7619 125it [00:01, 90.90it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 492/500 [21:38<00:21, 2.64s/it] [493] train_loss: 0.001 | dev_loss: 3.536 | micro f1 on dev: 0.7673 125it [00:01, 91.73it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 493/500 [21:40<00:18, 2.65s/it] [494] train_loss: 0.002 | dev_loss: 3.542 | micro f1 on dev: 0.7645 125it [00:01, 91.76it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 494/500 [21:43<00:15, 2.64s/it] [495] train_loss: 0.002 | dev_loss: 3.509 | micro f1 on dev: 0.7662 125it [00:01, 91.15it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 495/500 [21:46<00:13, 2.64s/it] [496] train_loss: 0.001 | dev_loss: 3.584 | micro f1 on dev: 0.7671 125it [00:01, 91.37it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 496/500 [21:48<00:10, 2.63s/it] [497] train_loss: 0.001 | dev_loss: 3.549 | micro f1 on dev: 0.7625 125it [00:01, 91.07it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 497/500 [21:51<00:07, 2.63s/it] [498] train_loss: 0.001 | dev_loss: 3.578 | micro f1 on dev: 0.7593 125it [00:01, 90.88it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 498/500 [21:53<00:05, 2.64s/it] [499] train_loss: 0.001 | dev_loss: 3.546 | micro f1 on dev: 0.7663 125it [00:01, 92.01it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 499/500 [21:56<00:02, 2.64s/it] [500] train_loss: 0.001 | dev_loss: 3.600 | micro f1 on dev: 0.7644 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500/500 [21:59<00:00, 2.64s/it] -------------------------------------- start test ... test_loss: 2.797 | micro f1 on test: 0.7948 \u5c0f\u8282\u603b\u7ed3 \u00b6 \u672c\u5c0f\u8282\u5b66\u4e60\u4e86CR-CNN\u5173\u7cfb\u62bd\u53d6\u6a21\u578b\u7684\u4ee3\u7801\u5b9e\u73b0, \u5e76\u5b8c\u6210\u4e86\u6a21\u578b\u7684\u8bad\u7ec3\u4e0e\u6027\u80fd\u6d4b\u8bd5.","title":"14.1 CR-CNN\u5173\u7cfb\u62bd\u53d6\u6a21\u578b\u8be6\u89e3"},{"location":"14_1.html#cr-cnn","text":"","title":"CR-CNN\u5173\u7cfb\u62bd\u53d6\u6a21\u578b"},{"location":"14_1.html#_1","text":"\u638c\u63e1CR-CNN\u5173\u7cfb\u62bd\u53d6\u6a21\u578b\u7684\u4ee3\u7801\u5b9e\u73b0.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"14_1.html#cr-cnn_1","text":"CR-CNN\u6a21\u578b\u7684\u603b\u4f53\u6784\u5efa\u6d41\u7a0b\u6709\u5982\u4e0b\u51e0\u4e2a\u6b65\u9aa4: \u7b2c1\u6b65: \u5de5\u5177\u7c7b\u51fd\u6570\u7684\u5b9e\u73b0 \u7b2c2\u6b65: \u6a21\u578b\u7c7b\u7684\u5b9e\u73b0 \u7b2c3\u6b65: \u8bc4\u4f30\u51fd\u6570\u7684\u5b9e\u73b0 \u7b2c4\u6b65: \u8bad\u7ec3\u4ee3\u7801\u7684\u5b9e\u73b0 \u7b2c5\u6b65: \u6a21\u578b\u7684\u8bad\u7ec3","title":"CR-CNN\u5173\u7cfb\u62bd\u53d6\u6a21\u578b\u5b9e\u73b0"},{"location":"14_1.html#1","text":"\u4ee3\u7801\u6587\u4ef6\u8def\u5f84: /home/ec2-user/code/relation/relation-classify/utils.py import numpy as np import time def now (): return str ( time . strftime ( '%Y-%m- %d %H:%M:%S' )) def save_pr ( out_dir , name , epoch , pre , rec , fp_res = None , opt = None ): if opt is None : out = open ( ' {} / {} _ {} _PR.txt' . format ( out_dir , name , epoch + 1 ), 'w' ) else : out = open ( ' {} / {} _ {} _ {} _PR.txt' . format ( out_dir , name , opt , epoch + 1 ), 'w' ) if fp_res is not None : fp_out = open ( ' {} / {} _ {} _FP.txt' . format ( out_dir , name , epoch + 1 ), 'w' ) for idx , r , p in fp_res : fp_out . write ( ' {} {} {} \\n ' . format ( idx , r , p )) fp_out . close () for p , r in zip ( pre , rec ): out . write ( ' {} {} \\n ' . format ( p , r )) out . close () def eval_metric ( true_y , pred_y , pred_p ): ''' calculate the precision and recall for p-r curve reglect the NA relation ''' assert len ( true_y ) == len ( pred_y ) positive_num = len ([ i for i in true_y if i [ 0 ] > 0 ]) index = np . argsort ( pred_p )[:: - 1 ] tp = 0 fp = 0 fn = 0 all_pre = [ 0 ] all_rec = [ 0 ] fp_res = [] for idx in range ( len ( true_y )): i = true_y [ index [ idx ]] j = pred_y [ index [ idx ]] if i [ 0 ] == 0 : # NA relation if j > 0 : fp_res . append (( index [ idx ], j , pred_p [ index [ idx ]])) fp += 1 else : if j == 0 : fn += 1 else : for k in i : if k == - 1 : break if k == j : tp += 1 break if fp + tp == 0 : precision = 1.0 else : precision = tp * 1.0 / ( tp + fp ) recall = tp * 1.0 / positive_num if precision != all_pre [ - 1 ] or recall != all_rec [ - 1 ]: all_pre . append ( precision ) all_rec . append ( recall ) print ( \"tp= {} ; fp= {} ; fn= {} ; positive_num= {} \" . format ( tp , fp , fn , positive_num )) return all_pre [ 1 :], all_rec [ 1 :], fp_res","title":"\u7b2c1\u6b65: \u5de5\u5177\u7c7b\u51fd\u6570\u7684\u5b9e\u73b0"},{"location":"14_1.html#2","text":"\u4ee3\u7801\u6587\u4ef6\u8def\u5f84: /home/ec2-user/code/relation/relation-classify/models/crcnn.py import torch import torch.nn as nn import torch.nn.functional as F from torch.nn import init class CRCNN ( nn . Module ): def __init__ ( self , word_vec , class_num , config ): super () . __init__ () self . word_vec = word_vec self . class_num = class_num # hyper parameters and others self . max_len = config . max_len self . word_dim = config . word_dim self . pos_dim = config . pos_dim self . pos_dis = config . pos_dis self . dropout_value = config . dropout self . filter_num = config . filter_num self . window = config . window self . dim = self . word_dim + 2 * self . pos_dim # net structures and operations self . word_embedding = nn . Embedding . from_pretrained ( embeddings = self . word_vec , freeze = False , ) self . pos1_embedding = nn . Embedding ( num_embeddings = 2 * self . pos_dis + 3 , embedding_dim = self . pos_dim ) self . pos2_embedding = nn . Embedding ( num_embeddings = 2 * self . pos_dis + 3 , embedding_dim = self . pos_dim ) self . conv = nn . Conv2d ( in_channels = 1 , out_channels = self . filter_num , kernel_size = ( self . window , self . dim ), stride = ( 1 , 1 ), bias = True , padding = ( 1 , 0 ), # same padding padding_mode = 'zeros' ) self . maxpool = nn . MaxPool2d (( self . max_len , 1 )) self . tanh = nn . Tanh () self . dropout = nn . Dropout ( self . dropout_value ) self . dense = nn . Linear ( in_features = self . filter_num , out_features = self . class_num , bias = False ) # initialize weight init . xavier_uniform_ ( self . pos1_embedding . weight ) init . xavier_uniform_ ( self . pos2_embedding . weight ) init . xavier_uniform_ ( self . conv . weight ) init . constant_ ( self . conv . bias , 0. ) init . xavier_uniform_ ( self . dense . weight ) # init.constant_(self.dense.bias, 0.) def encoder_layer ( self , token , pos1 , pos2 ): word_emb = self . word_embedding ( token ) # B*L*word_dim pos1_emb = self . pos1_embedding ( pos1 ) # B*L*pos_dim pos2_emb = self . pos2_embedding ( pos2 ) # B*L*pos_dim emb = torch . cat ( tensors = [ word_emb , pos1_emb , pos2_emb ], dim =- 1 ) return emb # B*L*D, D=word_dim+2*pos_dim def conv_layer ( self , emb , mask ): emb = emb . unsqueeze ( dim = 1 ) # B*1*L*D conv = self . conv ( emb ) # B*C*L*1 # mask, remove the effect of 'PAD' conv = conv . view ( - 1 , self . filter_num , self . max_len ) # B*C*L mask = mask . unsqueeze ( dim = 1 ) # B*1*L mask = mask . expand ( - 1 , self . filter_num , - 1 ) # B*C*L conv = conv . masked_fill ( mask . eq ( 0 ), float ( '-inf' )) # B*C*L conv = conv . unsqueeze ( dim =- 1 ) # B*C*L*1 return conv def single_maxpool_layer ( self , conv ): pool = self . maxpool ( conv ) # B*C*1*1 pool = pool . view ( - 1 , self . filter_num ) # B*C return pool def forward ( self , data ): token = data [ 0 ][:, 0 , :] . view ( - 1 , self . max_len ) pos1 = data [ 0 ][:, 1 , :] . view ( - 1 , self . max_len ) pos2 = data [ 0 ][:, 2 , :] . view ( - 1 , self . max_len ) mask = data [ 0 ][:, 3 , :] . view ( - 1 , self . max_len ) emb = self . encoder_layer ( token , pos1 , pos2 ) emb = self . dropout ( emb ) conv = self . conv_layer ( emb , mask ) conv = self . tanh ( conv ) pool = self . single_maxpool_layer ( conv ) feature = self . dropout ( pool ) scores = self . dense ( feature ) return scores class PairwiseRankingLoss ( nn . Module ): def __init__ ( self , config ): super () . __init__ () self . margin_positive = config . margin_positive self . margin_negative = config . margin_negative self . gamma = config . gamma def forward ( self , scores , labels ): mask = F . one_hot ( labels , scores . shape [ - 1 ]) positive_scores = scores . masked_fill ( mask . eq ( 0 ), float ( '-inf' )) . max ( dim = 1 )[ 0 ] negative_scores = scores . masked_fill ( mask . eq ( 1 ), float ( '-inf' )) . max ( dim = 1 )[ 0 ] positive_loss = torch . log1p ( torch . exp ( self . gamma * ( self . margin_positive - positive_scores ))) positive_loss [ labels == 0 ] = 0.0 # exclusive `Other` loss negative_loss = torch . log1p ( torch . exp ( self . gamma * ( self . margin_negative + negative_scores ))) loss = torch . mean ( positive_loss + negative_loss ) return loss","title":"\u7b2c2\u6b65: \u6a21\u578b\u7c7b\u7684\u5b9e\u73b0"},{"location":"14_1.html#3","text":"\u4ee3\u7801\u6587\u4ef6\u8def\u5f84: /home/ec2-user/code/relation/relation-classify/evaluate.py import numpy as np import torch def semeval_scorer ( predict_label , true_label , class_num = 10 ): import math assert true_label . shape [ 0 ] == predict_label . shape [ 0 ] confusion_matrix = np . zeros ( shape = [ class_num , class_num ], dtype = np . float32 ) xDIRx = np . zeros ( shape = [ class_num ], dtype = np . float32 ) for i in range ( true_label . shape [ 0 ]): true_idx = math . ceil ( true_label [ i ] / 2 ) predict_idx = math . ceil ( predict_label [ i ] / 2 ) if true_label [ i ] == predict_label [ i ]: confusion_matrix [ predict_idx ][ true_idx ] += 1 else : if true_idx == predict_idx : xDIRx [ predict_idx ] += 1 else : confusion_matrix [ predict_idx ][ true_idx ] += 1 col_sum = np . sum ( confusion_matrix , axis = 0 ) . reshape ( - 1 ) row_sum = np . sum ( confusion_matrix , axis = 1 ) . reshape ( - 1 ) f1 = np . zeros ( shape = [ class_num ], dtype = np . float32 ) for i in range ( 0 , class_num ): # ignore the 'Other' try : p = float ( confusion_matrix [ i ][ i ]) / float ( col_sum [ i ] + xDIRx [ i ]) r = float ( confusion_matrix [ i ][ i ]) / float ( row_sum [ i ] + xDIRx [ i ]) f1 [ i ] = ( 2 * p * r / ( p + r )) except : pass actual_class = 0 total_f1 = 0.0 for i in range ( 1 , class_num ): if f1 [ i ] > 0.0 : # classes that not in the predict label are not considered actual_class += 1 total_f1 += f1 [ i ] try : macro_f1 = total_f1 / actual_class except : macro_f1 = 0.0 return macro_f1 class Eval ( object ): def __init__ ( self , config ): self . device = config . device def evaluate ( self , model , criterion , data_loader ): predict_label = [] true_label = [] total_loss = 0.0 with torch . no_grad (): model . eval () for _ , ( data , label ) in enumerate ( data_loader ): sent_feat = data [ 0 ] . to ( self . device ) lex_feat = data [ 1 ] . to ( self . device ) data = ( sent_feat , lex_feat ) label = label . to ( self . device ) scores = model ( data ) loss = criterion ( scores , label ) scores = torch . softmax ( scores , dim = 1 ) total_loss += loss . item () * scores . shape [ 0 ] scores , pred = torch . max ( scores [:, 1 :], dim = 1 ) pred = pred + 1 scores = scores . cpu () . detach () . numpy () . reshape (( - 1 , 1 )) pred = pred . cpu () . detach () . numpy () . reshape (( - 1 , 1 )) label = label . cpu () . detach () . numpy () . reshape (( - 1 , 1 )) # During prediction time, a relation is classified as Other # only if all actual classes have negative scores. # Otherwise, it is classified with the class which has the largest score. for i in range ( pred . shape [ 0 ]): if scores [ i ][ 0 ] < 0 : pred [ i ][ 0 ] = 0 predict_label . append ( pred ) true_label . append ( label ) predict_label = np . concatenate ( predict_label , axis = 0 ) . reshape ( - 1 ) . astype ( np . int64 ) true_label = np . concatenate ( true_label , axis = 0 ) . reshape ( - 1 ) . astype ( np . int64 ) eval_loss = total_loss / predict_label . shape [ 0 ] f1 = semeval_scorer ( predict_label , true_label ) return f1 , eval_loss , predict_label","title":"\u7b2c3\u6b65: \u8bc4\u4f30\u51fd\u6570\u7684\u5b9e\u73b0"},{"location":"14_1.html#4","text":"\u4ee3\u7801\u6587\u4ef6\u8def\u5f84: /home/ec2-user/code/relation/relation-classify/cr_cnn_train.py import os import torch import torch.nn as nn import torch.optim as optim from tqdm import tqdm from config_cr_cnn import Config from dataset.dataset import WordEmbeddingLoader , RelationLoader , SemEvalDataLoader , VocabGenerator from models import * from evaluate import Eval def print_result ( predict_label , id2rel , start_idx = 8001 ): with open ( 'script/predicted_result.txt' , 'w' , encoding = 'utf-8' ) as fw : for i in range ( 0 , predict_label . shape [ 0 ]): fw . write ( ' {} \\t {} \\n ' . format ( start_idx + i , id2rel [ int ( predict_label [ i ])])) def train ( model , criterion , loader , config ): train_loader , dev_loader , _ = loader optimizer = optim . Adam ( model . parameters (), lr = config . lr , weight_decay = config . L2_decay ) print ( model ) print ( 'traning model parameters:' ) for name , param in model . named_parameters (): if param . requires_grad : print ( ' %s : %s ' % ( name , str ( param . data . shape ))) print ( '--------------------------------------' ) print ( 'start to train the model ...' ) eval_tool = Eval ( config ) min_f1 = - float ( 'inf' ) for epoch in tqdm ( range ( 1 , config . epoch + 1 )): model . train () for step , ( data , label ) in tqdm ( enumerate ( train_loader )): sent_feat = data [ 0 ] . to ( config . device ) lex_feat = data [ 1 ] . to ( config . device ) data = ( sent_feat , lex_feat ) label = label . to ( config . device ) optimizer . zero_grad () logits = model ( data ) loss = criterion ( logits , label ) loss . backward () optimizer . step () _ , train_loss , _ = eval_tool . evaluate ( model , criterion , train_loader ) f1 , dev_loss , _ = eval_tool . evaluate ( model , criterion , dev_loader ) print ( '[ %03d ] train_loss: %.3f | dev_loss: %.3f | micro f1 on dev: %.4f ' % ( epoch , train_loss , dev_loss , f1 ), end = ' ' ) if f1 > min_f1 : min_f1 = f1 torch . save ( model . state_dict (), os . path . join ( config . model_dir , 'model.pt' )) print ( '>>> save models!' ) else : print () def test ( model , criterion , loader , config ): print ( '--------------------------------------' ) print ( 'start test ...' ) _ , _ , test_loader = loader model . load_state_dict ( torch . load ( os . path . join ( config . model_dir , 'model.pt' ))) eval_tool = Eval ( config ) f1 , test_loss , predict_label = eval_tool . evaluate ( model , criterion , test_loader ) print ( 'test_loss: %.3f | micro f1 on test: %.4f ' % ( test_loss , f1 )) return predict_label if __name__ == '__main__' : config = Config () print ( '--------------------------------------' ) print ( 'some config:' ) config . print_config () print ( '--------------------------------------' ) print ( 'start to load data ...' ) vocab = VocabGenerator ( 'data/train.json' , 'data/test.json' ) . get_vocab () word2id , word_vec = WordEmbeddingLoader ( config ) . trim_from_pre_embedding ( vocab ) rel2id , id2rel , class_num = RelationLoader ( config ) . get_relation () loader = SemEvalDataLoader ( rel2id , word2id , config ) train_loader , dev_loader = None , None if config . mode == 1 : # train mode train_loader = loader . get_train () dev_loader = loader . get_dev () test_loader = loader . get_test () loader = [ train_loader , dev_loader , test_loader ] print ( 'finish!' ) print ( '--------------------------------------' ) model = CRCNN ( word_vec = word_vec , class_num = class_num , config = config ) model = model . to ( config . device ) #criterion = nn.CrossEntropyLoss() criterion = PairwiseRankingLoss ( config ) if config . mode == 1 : # train mode train ( model , criterion , loader , config ) predict_label = test ( model , criterion , loader , config ) print_result ( predict_label , id2rel )","title":"\u7b2c4\u6b65: \u8bad\u7ec3\u4ee3\u7801\u7684\u5b9e\u73b0"},{"location":"14_1.html#5","text":"\u8c03\u7528: python cr_cnn_train.py \u8f93\u51fa\u7ed3\u679c: -------------------------------------- some config: data_dir = ./data output_dir = ./output embedding_path = ./embedding/glove.6B.50d.txt word_dim = 50 model_name = CNN2 mode = 1 seed = 666 cuda = 0 epoch = 500 dropout = 0.3 batch_size = 64 lr = 0.001 max_len = 256 pos_dis = 50 pos_dim = 5 hidden_size = 128 filter_num = 512 window = 3 margin_positive = 2.5 margin_negative = 0.5 gamma = 2.0 L2_decay = 0.0001 device = cuda:0 model_dir = ./output/CNN2 -------------------------------------- start to load data ... finish! -------------------------------------- CRCNN( (word_embedding): Embedding(23503, 50) (pos1_embedding): Embedding(103, 5) (pos2_embedding): Embedding(103, 5) (conv): Conv2d(1, 512, kernel_size=(3, 60), stride=(1, 1), padding=(1, 0)) (maxpool): MaxPool2d(kernel_size=(256, 1), stride=(256, 1), padding=0, dilation=1, ceil_mode=False) (tanh): Tanh() (dropout): Dropout(p=0.3, inplace=False) (dense): Linear(in_features=512, out_features=19, bias=False) ) traning model parameters: word_embedding.weight : torch.Size([23503, 50]) pos1_embedding.weight : torch.Size([103, 5]) pos2_embedding.weight : torch.Size([103, 5]) conv.weight : torch.Size([512, 1, 3, 60]) conv.bias : torch.Size([512]) dense.weight : torch.Size([19, 512]) -------------------------------------- start to train the model ... 125it [00:01, 72.47it/s] | 0/500 [00:00<?, ?it/s] [001] train_loss: 4.986 | dev_loss: 5.102 | micro f1 on dev: 0.4993 >>> save models! 125it [00:01, 93.19it/s] | 1/500 [00:03<25:11, 3.03s/it] [002] train_loss: 4.124 | dev_loss: 4.298 | micro f1 on dev: 0.6539 >>> save models! 125it [00:01, 91.50it/s] | 2/500 [00:05<24:10, 2.91s/it] [003] train_loss: 3.470 | dev_loss: 3.678 | micro f1 on dev: 0.6978 >>> save models! 125it [00:01, 92.03it/s] | 3/500 [00:08<23:31, 2.84s/it] [004] train_loss: 3.028 | dev_loss: 3.391 | micro f1 on dev: 0.7196 >>> save models! 125it [00:01, 92.32it/s] | 4/500 [00:11<23:02, 2.79s/it] [005] train_loss: 2.651 | dev_loss: 3.176 | micro f1 on dev: 0.7371 >>> save models! 125it [00:01, 92.14it/s] | 5/500 [00:13<22:41, 2.75s/it] [006] train_loss: 2.321 | dev_loss: 3.027 | micro f1 on dev: 0.7531 >>> save models! 125it [00:01, 91.87it/s] | 6/500 [00:16<22:24, 2.72s/it] [007] train_loss: 2.024 | dev_loss: 2.894 | micro f1 on dev: 0.7687 >>> save models! 125it [00:01, 92.68it/s] | 7/500 [00:18<22:14, 2.71s/it] [008] train_loss: 1.760 | dev_loss: 2.832 | micro f1 on dev: 0.7757 >>> save models! 125it [00:01, 91.36it/s] | 8/500 [00:21<22:02, 2.69s/it] [009] train_loss: 1.503 | dev_loss: 2.747 | micro f1 on dev: 0.7829 >>> save models! 125it [00:01, 92.58it/s] | 9/500 [00:24<21:57, 2.68s/it] [010] train_loss: 1.278 | dev_loss: 2.696 | micro f1 on dev: 0.7832 >>> save models! 125it [00:01, 93.99it/s] | 10/500 [00:26<21:48, 2.67s/it] [011] train_loss: 1.079 | dev_loss: 2.682 | micro f1 on dev: 0.7864 >>> save models! 125it [00:01, 92.89it/s] | 11/500 [00:29<21:41, 2.66s/it] [012] train_loss: 0.908 | dev_loss: 2.643 | micro f1 on dev: 0.7915 >>> save models! 125it [00:01, 93.47it/s] | 12/500 [00:32<21:37, 2.66s/it] [013] train_loss: 0.832 | dev_loss: 2.651 | micro f1 on dev: 0.7943 >>> save models! 125it [00:01, 92.52it/s] | 13/500 [00:34<21:32, 2.65s/it] [014] train_loss: 0.649 | dev_loss: 2.656 | micro f1 on dev: 0.7931 125it [00:01, 93.09it/s] | 14/500 [00:37<21:25, 2.64s/it] [015] train_loss: 0.529 | dev_loss: 2.646 | micro f1 on dev: 0.7933 125it [00:01, 92.17it/s] | 15/500 [00:40<21:18, 2.64s/it] [016] train_loss: 0.466 | dev_loss: 2.664 | micro f1 on dev: 0.7947 >>> save models! 125it [00:01, 92.91it/s] | 16/500 [00:42<21:18, 2.64s/it] [017] train_loss: 0.417 | dev_loss: 2.670 | micro f1 on dev: 0.7935 125it [00:01, 91.00it/s] | 17/500 [00:45<21:12, 2.64s/it] [018] train_loss: 0.349 | dev_loss: 2.718 | micro f1 on dev: 0.7946 125it [00:01, 92.02it/s] | 18/500 [00:48<21:11, 2.64s/it] [019] train_loss: 0.258 | dev_loss: 2.706 | micro f1 on dev: 0.7894 125it [00:01, 92.72it/s] | 19/500 [00:50<21:10, 2.64s/it] [020] train_loss: 0.232 | dev_loss: 2.734 | micro f1 on dev: 0.7881 125it [00:01, 92.14it/s] | 20/500 [00:53<21:05, 2.64s/it] [021] train_loss: 0.212 | dev_loss: 2.791 | micro f1 on dev: 0.7891 125it [00:01, 92.74it/s] | 21/500 [00:55<21:00, 2.63s/it] [022] train_loss: 0.147 | dev_loss: 2.758 | micro f1 on dev: 0.7909 125it [00:01, 91.67it/s] | 22/500 [00:58<20:54, 2.62s/it] [023] train_loss: 0.124 | dev_loss: 2.772 | micro f1 on dev: 0.7903 125it [00:01, 92.53it/s] | 23/500 [01:01<20:50, 2.62s/it] [024] train_loss: 0.115 | dev_loss: 2.797 | micro f1 on dev: 0.7948 >>> save models! 125it [00:01, 92.38it/s] | 24/500 [01:03<20:52, 2.63s/it] [025] train_loss: 0.091 | dev_loss: 2.819 | micro f1 on dev: 0.7944 125it [00:01, 93.38it/s] | 25/500 [01:06<20:47, 2.63s/it] [026] train_loss: 0.073 | dev_loss: 2.886 | micro f1 on dev: 0.7922 125it [00:01, 92.56it/s] | 26/500 [01:09<20:42, 2.62s/it] [027] train_loss: 0.069 | dev_loss: 2.942 | micro f1 on dev: 0.7913 125it [00:01, 92.54it/s] | 27/500 [01:11<20:38, 2.62s/it] [028] train_loss: 0.057 | dev_loss: 2.944 | micro f1 on dev: 0.7929 125it [00:01, 91.92it/s] | 28/500 [01:14<20:34, 2.62s/it] [029] train_loss: 0.063 | dev_loss: 2.988 | micro f1 on dev: 0.7911 125it [00:01, 91.53it/s] | 29/500 [01:16<20:33, 2.62s/it] [030] train_loss: 0.048 | dev_loss: 2.972 | micro f1 on dev: 0.7892 125it [00:01, 91.76it/s] | 30/500 [01:19<20:34, 2.63s/it] [031] train_loss: 0.041 | dev_loss: 3.001 | micro f1 on dev: 0.7874 125it [00:01, 92.71it/s] | 31/500 [01:22<20:33, 2.63s/it] [032] train_loss: 0.026 | dev_loss: 3.040 | micro f1 on dev: 0.7864 125it [00:01, 92.16it/s] | 32/500 [01:24<20:27, 2.62s/it] [033] train_loss: 0.022 | dev_loss: 3.027 | micro f1 on dev: 0.7892 125it [00:01, 92.27it/s] | 33/500 [01:27<20:22, 2.62s/it] [034] train_loss: 0.030 | dev_loss: 3.082 | micro f1 on dev: 0.7859 125it [00:01, 92.45it/s] | 34/500 [01:30<20:21, 2.62s/it] [035] train_loss: 0.020 | dev_loss: 3.103 | micro f1 on dev: 0.7902 125it [00:01, 91.99it/s] | 35/500 [01:32<20:18, 2.62s/it] [036] train_loss: 0.016 | dev_loss: 3.073 | micro f1 on dev: 0.7888 125it [00:01, 92.85it/s] | 36/500 [01:35<20:16, 2.62s/it] [037] train_loss: 0.014 | dev_loss: 3.077 | micro f1 on dev: 0.7890 125it [00:01, 92.45it/s] | 37/500 [01:37<20:15, 2.63s/it] [038] train_loss: 0.012 | dev_loss: 3.081 | micro f1 on dev: 0.7905 125it [00:01, 92.11it/s] | 38/500 [01:40<20:11, 2.62s/it] [039] train_loss: 0.014 | dev_loss: 3.088 | micro f1 on dev: 0.7888 125it [00:01, 92.07it/s] | 39/500 [01:43<20:09, 2.62s/it] [040] train_loss: 0.022 | dev_loss: 3.170 | micro f1 on dev: 0.7899 125it [00:01, 92.35it/s] | 40/500 [01:45<20:04, 2.62s/it] [041] train_loss: 0.013 | dev_loss: 3.135 | micro f1 on dev: 0.7890 125it [00:01, 91.45it/s] | 41/500 [01:48<20:02, 2.62s/it] [042] train_loss: 0.015 | dev_loss: 3.166 | micro f1 on dev: 0.7907 125it [00:01, 92.23it/s] | 42/500 [01:51<20:02, 2.63s/it] [043] train_loss: 0.006 | dev_loss: 3.240 | micro f1 on dev: 0.7893 125it [00:01, 91.28it/s] | 43/500 [01:53<19:59, 2.63s/it] [044] train_loss: 0.008 | dev_loss: 3.148 | micro f1 on dev: 0.7909 125it [00:01, 91.91it/s] | 44/500 [01:56<20:01, 2.64s/it] [045] train_loss: 0.011 | dev_loss: 3.219 | micro f1 on dev: 0.7886 125it [00:01, 90.89it/s] | 45/500 [01:58<20:00, 2.64s/it] [046] train_loss: 0.009 | dev_loss: 3.241 | micro f1 on dev: 0.7823 125it [00:01, 91.49it/s] | 46/500 [02:01<20:00, 2.64s/it] [047] train_loss: 0.004 | dev_loss: 3.310 | micro f1 on dev: 0.7829 125it [00:01, 91.44it/s] | 47/500 [02:04<19:57, 2.64s/it] [048] train_loss: 0.008 | dev_loss: 3.284 | micro f1 on dev: 0.7847 125it [00:01, 91.50it/s] | 48/500 [02:06<19:52, 2.64s/it] [049] train_loss: 0.005 | dev_loss: 3.320 | micro f1 on dev: 0.7867 125it [00:01, 91.67it/s] | 49/500 [02:09<19:50, 2.64s/it] [050] train_loss: 0.007 | dev_loss: 3.354 | micro f1 on dev: 0.7833 125it [00:01, 91.29it/s] | 50/500 [02:12<19:46, 2.64s/it] [051] train_loss: 0.007 | dev_loss: 3.352 | micro f1 on dev: 0.7831 125it [00:01, 91.35it/s] ...... ...... ...... ...... ...... ...... 125it [00:01, 91.35it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 451/500 [19:49<02:09, 2.65s/it] [452] train_loss: 0.001 | dev_loss: 3.575 | micro f1 on dev: 0.7664 125it [00:01, 91.33it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 452/500 [19:52<02:06, 2.64s/it] [453] train_loss: 0.002 | dev_loss: 3.567 | micro f1 on dev: 0.7705 125it [00:01, 91.46it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 453/500 [19:55<02:04, 2.64s/it] [454] train_loss: 0.001 | dev_loss: 3.575 | micro f1 on dev: 0.7750 125it [00:01, 91.57it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 454/500 [19:57<02:01, 2.64s/it] [455] train_loss: 0.002 | dev_loss: 3.555 | micro f1 on dev: 0.7721 125it [00:01, 91.27it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 455/500 [20:00<01:58, 2.64s/it] [456] train_loss: 0.001 | dev_loss: 3.630 | micro f1 on dev: 0.7656 125it [00:01, 91.73it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 456/500 [20:03<01:56, 2.64s/it] [457] train_loss: 0.001 | dev_loss: 3.574 | micro f1 on dev: 0.7624 125it [00:01, 91.71it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 457/500 [20:05<01:53, 2.63s/it] [458] train_loss: 0.002 | dev_loss: 3.534 | micro f1 on dev: 0.7666 125it [00:01, 92.20it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 458/500 [20:08<01:50, 2.63s/it] [459] train_loss: 0.001 | dev_loss: 3.593 | micro f1 on dev: 0.7624 125it [00:01, 91.57it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 459/500 [20:11<01:47, 2.63s/it] [460] train_loss: 0.002 | dev_loss: 3.513 | micro f1 on dev: 0.7653 125it [00:01, 90.88it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 460/500 [20:13<01:45, 2.63s/it] [461] train_loss: 0.001 | dev_loss: 3.623 | micro f1 on dev: 0.7630 125it [00:01, 90.88it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 461/500 [20:16<01:42, 2.63s/it] [462] train_loss: 0.001 | dev_loss: 3.616 | micro f1 on dev: 0.7657 125it [00:01, 92.40it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 462/500 [20:18<01:40, 2.64s/it] [463] train_loss: 0.001 | dev_loss: 3.542 | micro f1 on dev: 0.7658 125it [00:01, 90.01it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 463/500 [20:21<01:37, 2.63s/it] [464] train_loss: 0.001 | dev_loss: 3.535 | micro f1 on dev: 0.7681 125it [00:01, 90.92it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 464/500 [20:24<01:34, 2.64s/it] [465] train_loss: 0.001 | dev_loss: 3.603 | micro f1 on dev: 0.7693 125it [00:01, 91.30it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 465/500 [20:26<01:32, 2.64s/it] [466] train_loss: 0.002 | dev_loss: 3.590 | micro f1 on dev: 0.7676 125it [00:01, 91.11it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 466/500 [20:29<01:29, 2.64s/it] [467] train_loss: 0.001 | dev_loss: 3.568 | micro f1 on dev: 0.7664 125it [00:01, 91.60it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 467/500 [20:32<01:27, 2.64s/it] [468] train_loss: 0.002 | dev_loss: 3.587 | micro f1 on dev: 0.7680 125it [00:01, 91.54it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 468/500 [20:34<01:24, 2.64s/it] [469] train_loss: 0.001 | dev_loss: 3.603 | micro f1 on dev: 0.7640 125it [00:01, 91.40it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 469/500 [20:37<01:21, 2.64s/it] [470] train_loss: 0.001 | dev_loss: 3.551 | micro f1 on dev: 0.7668 125it [00:01, 91.04it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 470/500 [20:40<01:19, 2.63s/it] [471] train_loss: 0.001 | dev_loss: 3.595 | micro f1 on dev: 0.7672 125it [00:01, 91.39it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 471/500 [20:42<01:16, 2.63s/it] [472] train_loss: 0.001 | dev_loss: 3.582 | micro f1 on dev: 0.7666 125it [00:01, 91.65it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 472/500 [20:45<01:13, 2.64s/it] [473] train_loss: 0.001 | dev_loss: 3.543 | micro f1 on dev: 0.7672 125it [00:01, 91.70it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 473/500 [20:47<01:11, 2.63s/it] [474] train_loss: 0.002 | dev_loss: 3.566 | micro f1 on dev: 0.7662 125it [00:01, 92.36it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 474/500 [20:50<01:08, 2.64s/it] [475] train_loss: 0.001 | dev_loss: 3.634 | micro f1 on dev: 0.7628 125it [00:01, 91.30it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 475/500 [20:53<01:05, 2.63s/it] [476] train_loss: 0.001 | dev_loss: 3.693 | micro f1 on dev: 0.7624 125it [00:01, 91.98it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 476/500 [20:55<01:03, 2.63s/it] [477] train_loss: 0.002 | dev_loss: 3.640 | micro f1 on dev: 0.7622 125it [00:01, 91.08it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 477/500 [20:58<01:00, 2.63s/it] [478] train_loss: 0.001 | dev_loss: 3.635 | micro f1 on dev: 0.7642 125it [00:01, 90.69it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 478/500 [21:01<00:58, 2.64s/it] [479] train_loss: 0.001 | dev_loss: 3.563 | micro f1 on dev: 0.7687 125it [00:01, 91.59it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 479/500 [21:03<00:55, 2.65s/it] [480] train_loss: 0.001 | dev_loss: 3.607 | micro f1 on dev: 0.7688 125it [00:01, 91.57it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 480/500 [21:06<00:52, 2.65s/it] [481] train_loss: 0.001 | dev_loss: 3.532 | micro f1 on dev: 0.7674 125it [00:01, 90.23it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 481/500 [21:09<00:50, 2.64s/it] [482] train_loss: 0.001 | dev_loss: 3.606 | micro f1 on dev: 0.7714 125it [00:01, 91.32it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 482/500 [21:11<00:47, 2.65s/it] [483] train_loss: 0.002 | dev_loss: 3.573 | micro f1 on dev: 0.7689 125it [00:01, 90.71it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 483/500 [21:14<00:45, 2.65s/it] [484] train_loss: 0.001 | dev_loss: 3.534 | micro f1 on dev: 0.7704 125it [00:01, 91.12it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 484/500 [21:17<00:42, 2.65s/it] [485] train_loss: 0.003 | dev_loss: 3.540 | micro f1 on dev: 0.7655 125it [00:01, 90.58it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 485/500 [21:19<00:39, 2.65s/it] [486] train_loss: 0.002 | dev_loss: 3.533 | micro f1 on dev: 0.7610 125it [00:01, 91.35it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 486/500 [21:22<00:37, 2.65s/it] [487] train_loss: 0.001 | dev_loss: 3.556 | micro f1 on dev: 0.7661 125it [00:01, 91.92it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 487/500 [21:24<00:34, 2.65s/it] [488] train_loss: 0.001 | dev_loss: 3.533 | micro f1 on dev: 0.7650 125it [00:01, 91.90it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 488/500 [21:27<00:31, 2.64s/it] [489] train_loss: 0.002 | dev_loss: 3.597 | micro f1 on dev: 0.7590 125it [00:01, 90.40it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 489/500 [21:30<00:28, 2.63s/it] [490] train_loss: 0.003 | dev_loss: 3.524 | micro f1 on dev: 0.7665 125it [00:01, 91.52it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 490/500 [21:32<00:26, 2.64s/it] [491] train_loss: 0.001 | dev_loss: 3.568 | micro f1 on dev: 0.7617 125it [00:01, 91.35it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 491/500 [21:35<00:23, 2.63s/it] [492] train_loss: 0.001 | dev_loss: 3.574 | micro f1 on dev: 0.7619 125it [00:01, 90.90it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 492/500 [21:38<00:21, 2.64s/it] [493] train_loss: 0.001 | dev_loss: 3.536 | micro f1 on dev: 0.7673 125it [00:01, 91.73it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 493/500 [21:40<00:18, 2.65s/it] [494] train_loss: 0.002 | dev_loss: 3.542 | micro f1 on dev: 0.7645 125it [00:01, 91.76it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 494/500 [21:43<00:15, 2.64s/it] [495] train_loss: 0.002 | dev_loss: 3.509 | micro f1 on dev: 0.7662 125it [00:01, 91.15it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 495/500 [21:46<00:13, 2.64s/it] [496] train_loss: 0.001 | dev_loss: 3.584 | micro f1 on dev: 0.7671 125it [00:01, 91.37it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 496/500 [21:48<00:10, 2.63s/it] [497] train_loss: 0.001 | dev_loss: 3.549 | micro f1 on dev: 0.7625 125it [00:01, 91.07it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 497/500 [21:51<00:07, 2.63s/it] [498] train_loss: 0.001 | dev_loss: 3.578 | micro f1 on dev: 0.7593 125it [00:01, 90.88it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 498/500 [21:53<00:05, 2.64s/it] [499] train_loss: 0.001 | dev_loss: 3.546 | micro f1 on dev: 0.7663 125it [00:01, 92.01it/s]\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 499/500 [21:56<00:02, 2.64s/it] [500] train_loss: 0.001 | dev_loss: 3.600 | micro f1 on dev: 0.7644 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500/500 [21:59<00:00, 2.64s/it] -------------------------------------- start test ... test_loss: 2.797 | micro f1 on test: 0.7948","title":"\u7b2c5\u6b65: \u6a21\u578b\u7684\u8bad\u7ec3"},{"location":"14_1.html#_2","text":"\u672c\u5c0f\u8282\u5b66\u4e60\u4e86CR-CNN\u5173\u7cfb\u62bd\u53d6\u6a21\u578b\u7684\u4ee3\u7801\u5b9e\u73b0, \u5e76\u5b8c\u6210\u4e86\u6a21\u578b\u7684\u8bad\u7ec3\u4e0e\u6027\u80fd\u6d4b\u8bd5.","title":"\u5c0f\u8282\u603b\u7ed3"},{"location":"15_1.html","text":"\u4e2d\u6587NER\u7684SOTA \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u638c\u63e1FLAT\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u6838\u5fc3\u6280\u5de7. FLAT\u6a21\u578b\u7684\u67b6\u6784 \u00b6 FLAT\u6a21\u578b\u662f\u590d\u65e6\u5927\u5b66\u90b1\u9521\u9e4f\u6559\u6388\u56e2\u961f\u4e8e2020\u5e74\u63d0\u51fa\u7684\u6700\u65b0\u4e2d\u6587NER\u4efb\u52a1\u7684SOTA\u6a21\u578b, \u539f\u59cb\u8bba\u6587<< FLAT: Chinese NER Using Flat-Lattice Transformer >>. FLAT\u7684\u601d\u60f3\u6e90\u4e8eLattice LSTM, \u662f\u4e2d\u6587\u573a\u666f\u4e0bNER\u4efb\u52a1\u5f15\u5165\u5916\u90e8\u77e5\u8bc6\u7684\u5f00\u5c71\u4e4b\u4f5c. \u9996\u5148\u901a\u8fc7\u8bcd\u5178\u5339\u914d, \u5728\"\u91cd\u5e86\u4eba\u548c\u836f\u5e97\"\u5b57\u7b26\u4e32\u4e2d, \u5339\u914d\u51fa\u5b50\u4e32\"\u91cd\u5e86\", \"\u836f\u5e97\", \"\u4eba\u548c\u836f\u5e97\"\u8fd9\u4e09\u4e2a\u5b50\u8bcd, \u7ed3\u6784\u56fe\u5982\u4e0b: \u7136\u540e\u5c06\u5339\u914d\u51fa\u76843\u4e2a\u5b50\u8bcd\u878d\u5165\u5230LSTM\u4e2d, \u5982\u4e0b\u56fe\u6240\u793a: Lattice\u662f\u4e00\u4e2a\u6709\u5411\u65e0\u73af\u56fe(DAG), Lattice LSTM\u5219\u5c06\u5e8f\u5217\u4e2d\u7684\u8bcd\u6c47\u4fe1\u606f(word-level)\u878d\u5165\u5230\u4e86\u5b57\u4fe1\u606f(char-level)\u4e2d, Lattice LSTM\u4f1a\u5c06\"\u91cd\u5e86\"\u7684word embedding\u878d\u5165\u5230\u5bf9\u5e94\u5e8f\u5217\u4e2d\u7684\"\u5e86\"\u7684word embedding\u4e2d, \u4f1a\u5c06\"\u4eba\u548c\u836f\u5e97\"\u7684word embedding\u548c\"\u836f\u5e97\"\u7684word embedding\u878d\u5165\u5230\"\u5e97\"\u7684word embedding\u4e2d, \u5373\u8bcd\u8bed\u7684\u4fe1\u606f\u4f1a\u878d\u5165\u5230\u8be5\u8bcd\u8bed\u5bf9\u5e94\u7684\u6700\u540e\u4e00\u4e2a\u5b57\u7684\u5e8f\u5217\u4fe1\u606f\u4e2d! Lattice LSTM\u7684\u6838\u5fc3\u64cd\u4f5c\u662f\u91c7\u7528\u4e86\u4e24\u4e2aLSTM\u6a21\u578b\u5bf9char-level\u7684\u5b57\u4fe1\u606f\u548cword-level\u7684\u8bcd\u4fe1\u606f\u5206\u522b\u8fdb\u884c\u7f16\u7801, \u7136\u540e\u5c06\u8bcd\u4fe1\u606f\u878d\u5165\u5230\u6bcf\u4e2a\u8bcd\u6700\u540e\u4e00\u4e2a\u5b57\u7684\u7f16\u7801\u4fe1\u606f\u4e2d. \u8fd9\u91cc\u9762\u7684\u7ec6\u8282\u6ce8\u610f\u4e24\u70b9: \u7b2c\u4e00: \u5f53\u524d\u5b57(chae-level)\u6ca1\u6709\u5176\u4ed6word\u8bcd\u7684embedding\u8f93\u5165\u65f6, \u76f4\u63a5\u4f7f\u7528\u539f\u59cb\u7684LSTM\u673a\u5236\u8fdb\u884c\u4fe1\u606f\u4f20\u5bfc. \u7b2c\u4e8c: \u5f53\u524d\u5b57(char-level)\u6709\u5176\u4ed6word\u8bcd\u7684embedding\u8f93\u5165\u65f6, \u4f7f\u7528\u8bba\u6587\u4e2d\u7684\u8ba1\u7b97\u516c\u5f0f, \u4e14\u6ca1\u6709\u4f7f\u7528\u4e0a\u4e00\u4e2a\u65f6\u523b\u7684\u8bb0\u5fc6\u5411\u91cfc, \u5373\u4e0d\u4fdd\u7559\u5bf9\u8bcd\u4fe1\u606f(word-level)\u7684\u6301\u7eed\u8bb0\u5fc6. 1: Lattice LSTM\u9996\u6b21\u4f7f\u7528\u5916\u90e8\u8bcd\u6c47\u4fe1\u606f, \u6709\u91cd\u5927\u521b\u65b0\u7a81\u7834, \u4f46\u662f\u5b58\u5728\u4e00\u5b9a\u7684\u5c40\u9650\u6027, \u8fc1\u79fb\u590d\u5236\u8f83\u96be, \u53ea\u80fd\u7528\u4e8eLSTM\u6a21\u578b\u4f5c\u4e3abackbone. 2: \u8ba1\u7b97\u6027\u80fd\u4f4e\u4e0b, \u4e0d\u80fdbatch\u5e76\u884c\u5316. \u4e3b\u8981\u662f\u6bcf\u4e2a\u5b57\u4e4b\u95f4\u589e\u52a0\u7684word cell\u6570\u91cf\u4e0d\u4e00\u81f4, \u4e2d\u95f4\u7684word cell\u7684\u4e2a\u6570\u4e0d\u786e\u5b9a, \u6ca1\u529e\u6cd5\u505a\u5230\u7edf\u4e00\u5c3a\u5bf8\u7684batch\u5316. 3: \u4fe1\u606f\u4e22\u5931\u95ee\u9898, \u6bcf\u4e2a\u5b57\u53ea\u80fd\u83b7\u53d6\u4ee5\u5b83\u4e3a\u7ed3\u5c3e\u7684\u8bcd\u6c47\u4fe1\u606f, \u5bf9\u4e8e\u4e4b\u524d\u7684\u8bcd\u6c47\u4fe1\u606f\u6ca1\u6709\u6301\u7eed\u8bb0\u5fc6\u80fd\u529b. FLAT\u7684\u51fa\u53d1\u70b9\u5c31\u662f\u89e3\u51b3Lattice LSTM\u7684\u7f3a\u9677, \u67b6\u6784\u56fe\u5982\u4e0b\u6240\u793a: \u5982\u4e0a\u56fe\u6240\u793a, FLAT\u5c06\u8bcd\u4fe1\u606f(word-level)\u76f4\u63a5\u653e\u7f6e\u5728\u6587\u672c\u7684\u540e\u9762, \u5e76\u4e0d\u505a\u63d2\u5165\u5904\u7406, \u5e76\u5bf9\u6bcf\u4e00\u4e2a\u4fe1\u606f\u5757\u6dfb\u52a0head, tail\u4f4d\u7f6e\u7f16\u7801\u7684\u4fe1\u606f. \u5b57(char-level)\u7684head\u548ctail\u76f8\u540c, \u8bcd(word-level)\u7684head\u4f4d\u7f6e\u4e3a\u7b2c\u4e00\u4e2a\u5b57\u7684\u4f4d\u7f6e, tail\u4f4d\u7f6e\u4e3a\u6700\u540e\u4e00\u4e2a\u5b57\u7684\u4f4d\u7f6e. \u901a\u8fc7\u5b9a\u4e494\u79cd\u76f8\u5bf9\u8ddd\u79bb\u6765\u8868\u793ax(i)\u4e0ex(j)\u7684\u4f4d\u7f6e\u5173\u7cfb: \u4e0a\u9762\u76844\u4e2a\u77e9\u9635\u4ee3\u88684\u79cd\u8ddd\u79bb\u7684\u8868\u8fbe, \u4f8b\u5982d(hh)\u8868\u793ax(i)\u7684\u5934\u90e8\u5230x(j)\u7684\u5934\u90e8\u7684\u8ddd\u79bb. \u5176\u4ed6\u7c7b\u4f3c\u63a8\u7406. \u5bf9\u4e8eFLAT\u7684\u6838\u5fc3\u6a21\u5757transformer\u7684\u6ce8\u610f\u529b\u8ba1\u7b97, \u4f9d\u7136\u6cbf\u7528\u7ecf\u5178\u516c\u5f0f, 4\u4e2a\u76f8\u5bf9\u8ddd\u79bb\u77e9\u9635\u662f\u901a\u8fc7\u77e9\u9635A\u7684\u53d8\u6362\u878d\u5165\u516c\u5f0f\u4e2d\u7684, \u771f\u5b9e\u8ba1\u7b97\u662f\u5728position embedding\u65f6\u52a0\u5165\u7684: FLAT\u5185\u90e8\u7ec6\u8282\u7684\u5168\u5c40\u67b6\u6784\u56fe\u5982\u4e0b\u6240\u793a: \u539f\u59cb\u8bba\u6587\u4e2d\u5bf9FLAT\u7684\u8bc4\u4f30, \u663e\u793a\u76f8\u5bf9\u4e8e\u8457\u540d\u7684TENER\u6a21\u578b, \u53d6\u5f97\u4e86\u663e\u8457\u7684\u63d0\u5347. FLAT\u6a21\u578b\u4e0d\u4ec5\u4ec5\u5728\u5173\u952e\u6307\u6807\u4e0a\u8fbe\u5230\u4e86\u4e2d\u6587\u573a\u666fNER\u7684SOTA, \u53e6\u4e00\u5927\u4eae\u70b9\u662f\u5904\u7406\u901f\u5ea6\u7684\u5927\u5e45\u63d0\u5347, \u5c24\u5176\u662fFLAT\u53ef\u4ee5\u5229\u7528GPU\u7684\u5e76\u884c\u5904\u7406\u80fd\u529b\u5927\u5e45\u63d0\u5347\u6279\u91cf\u5904\u7406\u7684\u80fd\u529b. FLAT\u6a21\u578b\u7684\u8bad\u7ec3 \u00b6 FLAT\u6a21\u578b\u5e95\u5c42\u52a0\u8f7dBERT\u540e\u7684\u8bad\u7ec3\u6d41\u7a0b: python flat_main.py \u8f93\u51fa\u7ed3\u679c:","title":"15.1 \u4e2d\u6587NER\u7684SOTA"},{"location":"15_1.html#nersota","text":"","title":"\u4e2d\u6587NER\u7684SOTA"},{"location":"15_1.html#_1","text":"\u638c\u63e1FLAT\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u6838\u5fc3\u6280\u5de7.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"15_1.html#flat","text":"FLAT\u6a21\u578b\u662f\u590d\u65e6\u5927\u5b66\u90b1\u9521\u9e4f\u6559\u6388\u56e2\u961f\u4e8e2020\u5e74\u63d0\u51fa\u7684\u6700\u65b0\u4e2d\u6587NER\u4efb\u52a1\u7684SOTA\u6a21\u578b, \u539f\u59cb\u8bba\u6587<< FLAT: Chinese NER Using Flat-Lattice Transformer >>. FLAT\u7684\u601d\u60f3\u6e90\u4e8eLattice LSTM, \u662f\u4e2d\u6587\u573a\u666f\u4e0bNER\u4efb\u52a1\u5f15\u5165\u5916\u90e8\u77e5\u8bc6\u7684\u5f00\u5c71\u4e4b\u4f5c. \u9996\u5148\u901a\u8fc7\u8bcd\u5178\u5339\u914d, \u5728\"\u91cd\u5e86\u4eba\u548c\u836f\u5e97\"\u5b57\u7b26\u4e32\u4e2d, \u5339\u914d\u51fa\u5b50\u4e32\"\u91cd\u5e86\", \"\u836f\u5e97\", \"\u4eba\u548c\u836f\u5e97\"\u8fd9\u4e09\u4e2a\u5b50\u8bcd, \u7ed3\u6784\u56fe\u5982\u4e0b: \u7136\u540e\u5c06\u5339\u914d\u51fa\u76843\u4e2a\u5b50\u8bcd\u878d\u5165\u5230LSTM\u4e2d, \u5982\u4e0b\u56fe\u6240\u793a: Lattice\u662f\u4e00\u4e2a\u6709\u5411\u65e0\u73af\u56fe(DAG), Lattice LSTM\u5219\u5c06\u5e8f\u5217\u4e2d\u7684\u8bcd\u6c47\u4fe1\u606f(word-level)\u878d\u5165\u5230\u4e86\u5b57\u4fe1\u606f(char-level)\u4e2d, Lattice LSTM\u4f1a\u5c06\"\u91cd\u5e86\"\u7684word embedding\u878d\u5165\u5230\u5bf9\u5e94\u5e8f\u5217\u4e2d\u7684\"\u5e86\"\u7684word embedding\u4e2d, \u4f1a\u5c06\"\u4eba\u548c\u836f\u5e97\"\u7684word embedding\u548c\"\u836f\u5e97\"\u7684word embedding\u878d\u5165\u5230\"\u5e97\"\u7684word embedding\u4e2d, \u5373\u8bcd\u8bed\u7684\u4fe1\u606f\u4f1a\u878d\u5165\u5230\u8be5\u8bcd\u8bed\u5bf9\u5e94\u7684\u6700\u540e\u4e00\u4e2a\u5b57\u7684\u5e8f\u5217\u4fe1\u606f\u4e2d! Lattice LSTM\u7684\u6838\u5fc3\u64cd\u4f5c\u662f\u91c7\u7528\u4e86\u4e24\u4e2aLSTM\u6a21\u578b\u5bf9char-level\u7684\u5b57\u4fe1\u606f\u548cword-level\u7684\u8bcd\u4fe1\u606f\u5206\u522b\u8fdb\u884c\u7f16\u7801, \u7136\u540e\u5c06\u8bcd\u4fe1\u606f\u878d\u5165\u5230\u6bcf\u4e2a\u8bcd\u6700\u540e\u4e00\u4e2a\u5b57\u7684\u7f16\u7801\u4fe1\u606f\u4e2d. \u8fd9\u91cc\u9762\u7684\u7ec6\u8282\u6ce8\u610f\u4e24\u70b9: \u7b2c\u4e00: \u5f53\u524d\u5b57(chae-level)\u6ca1\u6709\u5176\u4ed6word\u8bcd\u7684embedding\u8f93\u5165\u65f6, \u76f4\u63a5\u4f7f\u7528\u539f\u59cb\u7684LSTM\u673a\u5236\u8fdb\u884c\u4fe1\u606f\u4f20\u5bfc. \u7b2c\u4e8c: \u5f53\u524d\u5b57(char-level)\u6709\u5176\u4ed6word\u8bcd\u7684embedding\u8f93\u5165\u65f6, \u4f7f\u7528\u8bba\u6587\u4e2d\u7684\u8ba1\u7b97\u516c\u5f0f, \u4e14\u6ca1\u6709\u4f7f\u7528\u4e0a\u4e00\u4e2a\u65f6\u523b\u7684\u8bb0\u5fc6\u5411\u91cfc, \u5373\u4e0d\u4fdd\u7559\u5bf9\u8bcd\u4fe1\u606f(word-level)\u7684\u6301\u7eed\u8bb0\u5fc6. 1: Lattice LSTM\u9996\u6b21\u4f7f\u7528\u5916\u90e8\u8bcd\u6c47\u4fe1\u606f, \u6709\u91cd\u5927\u521b\u65b0\u7a81\u7834, \u4f46\u662f\u5b58\u5728\u4e00\u5b9a\u7684\u5c40\u9650\u6027, \u8fc1\u79fb\u590d\u5236\u8f83\u96be, \u53ea\u80fd\u7528\u4e8eLSTM\u6a21\u578b\u4f5c\u4e3abackbone. 2: \u8ba1\u7b97\u6027\u80fd\u4f4e\u4e0b, \u4e0d\u80fdbatch\u5e76\u884c\u5316. \u4e3b\u8981\u662f\u6bcf\u4e2a\u5b57\u4e4b\u95f4\u589e\u52a0\u7684word cell\u6570\u91cf\u4e0d\u4e00\u81f4, \u4e2d\u95f4\u7684word cell\u7684\u4e2a\u6570\u4e0d\u786e\u5b9a, \u6ca1\u529e\u6cd5\u505a\u5230\u7edf\u4e00\u5c3a\u5bf8\u7684batch\u5316. 3: \u4fe1\u606f\u4e22\u5931\u95ee\u9898, \u6bcf\u4e2a\u5b57\u53ea\u80fd\u83b7\u53d6\u4ee5\u5b83\u4e3a\u7ed3\u5c3e\u7684\u8bcd\u6c47\u4fe1\u606f, \u5bf9\u4e8e\u4e4b\u524d\u7684\u8bcd\u6c47\u4fe1\u606f\u6ca1\u6709\u6301\u7eed\u8bb0\u5fc6\u80fd\u529b. FLAT\u7684\u51fa\u53d1\u70b9\u5c31\u662f\u89e3\u51b3Lattice LSTM\u7684\u7f3a\u9677, \u67b6\u6784\u56fe\u5982\u4e0b\u6240\u793a: \u5982\u4e0a\u56fe\u6240\u793a, FLAT\u5c06\u8bcd\u4fe1\u606f(word-level)\u76f4\u63a5\u653e\u7f6e\u5728\u6587\u672c\u7684\u540e\u9762, \u5e76\u4e0d\u505a\u63d2\u5165\u5904\u7406, \u5e76\u5bf9\u6bcf\u4e00\u4e2a\u4fe1\u606f\u5757\u6dfb\u52a0head, tail\u4f4d\u7f6e\u7f16\u7801\u7684\u4fe1\u606f. \u5b57(char-level)\u7684head\u548ctail\u76f8\u540c, \u8bcd(word-level)\u7684head\u4f4d\u7f6e\u4e3a\u7b2c\u4e00\u4e2a\u5b57\u7684\u4f4d\u7f6e, tail\u4f4d\u7f6e\u4e3a\u6700\u540e\u4e00\u4e2a\u5b57\u7684\u4f4d\u7f6e. \u901a\u8fc7\u5b9a\u4e494\u79cd\u76f8\u5bf9\u8ddd\u79bb\u6765\u8868\u793ax(i)\u4e0ex(j)\u7684\u4f4d\u7f6e\u5173\u7cfb: \u4e0a\u9762\u76844\u4e2a\u77e9\u9635\u4ee3\u88684\u79cd\u8ddd\u79bb\u7684\u8868\u8fbe, \u4f8b\u5982d(hh)\u8868\u793ax(i)\u7684\u5934\u90e8\u5230x(j)\u7684\u5934\u90e8\u7684\u8ddd\u79bb. \u5176\u4ed6\u7c7b\u4f3c\u63a8\u7406. \u5bf9\u4e8eFLAT\u7684\u6838\u5fc3\u6a21\u5757transformer\u7684\u6ce8\u610f\u529b\u8ba1\u7b97, \u4f9d\u7136\u6cbf\u7528\u7ecf\u5178\u516c\u5f0f, 4\u4e2a\u76f8\u5bf9\u8ddd\u79bb\u77e9\u9635\u662f\u901a\u8fc7\u77e9\u9635A\u7684\u53d8\u6362\u878d\u5165\u516c\u5f0f\u4e2d\u7684, \u771f\u5b9e\u8ba1\u7b97\u662f\u5728position embedding\u65f6\u52a0\u5165\u7684: FLAT\u5185\u90e8\u7ec6\u8282\u7684\u5168\u5c40\u67b6\u6784\u56fe\u5982\u4e0b\u6240\u793a: \u539f\u59cb\u8bba\u6587\u4e2d\u5bf9FLAT\u7684\u8bc4\u4f30, \u663e\u793a\u76f8\u5bf9\u4e8e\u8457\u540d\u7684TENER\u6a21\u578b, \u53d6\u5f97\u4e86\u663e\u8457\u7684\u63d0\u5347. FLAT\u6a21\u578b\u4e0d\u4ec5\u4ec5\u5728\u5173\u952e\u6307\u6807\u4e0a\u8fbe\u5230\u4e86\u4e2d\u6587\u573a\u666fNER\u7684SOTA, \u53e6\u4e00\u5927\u4eae\u70b9\u662f\u5904\u7406\u901f\u5ea6\u7684\u5927\u5e45\u63d0\u5347, \u5c24\u5176\u662fFLAT\u53ef\u4ee5\u5229\u7528GPU\u7684\u5e76\u884c\u5904\u7406\u80fd\u529b\u5927\u5e45\u63d0\u5347\u6279\u91cf\u5904\u7406\u7684\u80fd\u529b.","title":"FLAT\u6a21\u578b\u7684\u67b6\u6784"},{"location":"15_1.html#flat_1","text":"FLAT\u6a21\u578b\u5e95\u5c42\u52a0\u8f7dBERT\u540e\u7684\u8bad\u7ec3\u6d41\u7a0b: python flat_main.py \u8f93\u51fa\u7ed3\u679c:","title":"FLAT\u6a21\u578b\u7684\u8bad\u7ec3"},{"location":"1_1.html","text":"\u7ea2\u8718\u86db\u9879\u76ee\u80cc\u666f\u4ecb\u7ecd \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u7ea2\u8718\u86db\u9879\u76ee\u7684\u5f00\u53d1\u80cc\u666f. \u4e86\u89e3\u77e5\u8bc6\u56fe\u8c31\u7684\u76f8\u5173\u57fa\u7840\u6982\u5ff5. \u7ea2\u8718\u86db\u9879\u76ee\u80cc\u666f \u00b6 \u4ece2012\u5e74Google\u516c\u53f8\u63d0\u51fa\"\u77e5\u8bc6\u56fe\u8c31(Knowledge Graph)\"\u5230\u4eca\u5929, \u77e5\u8bc6\u56fe\u8c31\u6280\u672f\u53d1\u5c55\u8fc5\u901f, \u4f34\u968f\u7740\u5927\u6570\u636e\u548c\u4eba\u5de5\u667a\u80fd\u7684\u98de\u901f\u53d1\u5c55, \u6307\u793a\u56fe\u8c31\u7684\u5185\u6db5\u4e5f\u8d8a\u6765\u8d8a\u4e30\u5bcc. \u77e5\u8bc6\u56fe\u8c31\u6280\u672f\u80cc\u540e\u878d\u5408\u4e86\u4f17\u591aCV, NLP, \u63a8\u8350\u7cfb\u7edf, \u5927\u6570\u636e\u7b49\u77e5\u8bc6, \u53ef\u4ee5\u8bf4\u662f\u4eba\u5de5\u667a\u80fd\u65f6\u4ee3\u7684\u65b0\u79c0\u548c\u70ed\u70b9. \u4f20\u667a\u6559\u80b2\u7684AI\u5f15\u9886IT\u6559\u80b2\u524d\u6cbf, \u7279\u6b64\u63a8\u51fa\u7ea2\u8718\u86db\u9879\u76ee, \u5e26\u7740\u540c\u5b66\u4eec\u5b8c\u6574\u7684\u5b66\u4e60\u77e5\u8bc6\u56fe\u8c31\u76f8\u5173\u6280\u672f, \u5e76\u624e\u5b9e\u7684\u638c\u63e1\u6838\u5fc3\u5185\u5bb9\u548c\u4ee3\u7801\u80fd\u529b. \u4efb\u4f55AI\u9879\u76ee\u90fd\u662f\u57fa\u4e8e\u6570\u636e\u7684\u9879\u76ee, \u8fd9\u91cc\u9762\u6570\u636e\u7684\u6765\u6e90\u591a\u79cd\u591a\u6837. \u9879\u76ee\u4e2d\u7684\u6570\u636e\u6765\u6e90\u57fa\u672c\u5206\u4e3a3\u5927\u79cd\u7c7b: \u7b2c\u4e00\u7c7b: \u516c\u53f8\u5185\u90e8\u6570\u636e\u90e8\u95e8\u63d0\u4f9b. \u60c5\u51b51: \u6570\u636e\u5e73\u53f0\u6709\u9884\u5904\u7406, \u63d0\u4f9b\u7684\u662f\"\u6210\u54c1\u6570\u636e\". \u60c5\u51b52: \u6570\u636e\u5e73\u53f0\u6ca1\u6709\u9884\u5904\u7406, \u53ea\u544a\u8bc9\u5f00\u53d1\u4eba\u5458\"\u6570\u636e\u8def\u5f84\". \u60c5\u51b53: \u539f\u59cb\u6570\u636e\u5c31\u6ca1\u6709, \u9700\u8981\u5f00\u53d1\u4eba\u5458\u6c9f\u901a\u4e0d\u540c\u90e8\u5206, \u83b7\u53d6\"\u4e1a\u52a1\u6570\u636e\". \u7b2c\u4e8c\u7c7b: \u7532\u65b9\u63d0\u9700\u6c42, \u5e76\u63d0\u4f9b\u6570\u636e. \u60c5\u51b51: \u7532\u65b9\u6709\u9884\u5904\u7406\u6570\u636e, \u63d0\u4f9b\u7684\u57fa\u672c\u662f\"\u534a\u6210\u54c1\u6570\u636e\". \u60c5\u51b52: \u7532\u65b9\u53ea\u8d1f\u8d23\"\u57cb\u70b9\", \u540e\u7eed\u6570\u636e\u9700\u8981\u5f00\u53d1\u4eba\u5458\u5904\u7406. \u60c5\u51b53: \u7532\u65b9\u6570\u636e\"\u532e\u4e4f\", \u751a\u81f3\u6570\u636e\"\u7f3a\u5931\". \u7b2c\u4e09\u7c7b: \u9700\u6c42\u753b\u5927\u997c\u9636\u6bb5, \u6ca1\u6709\u6570\u636e, \u6ca1\u6709GPU, \u53ea\u6709\"\u84dd\u56fe\"\u548c\"\u5c55\u671b\". \u77e5\u8bc6\u56fe\u8c31\u76f8\u5173\u6982\u5ff5 \u00b6 \u77e5\u8bc6\u56fe\u8c31\u5305\u542b\u4e24\u4e2a\u5c42\u9762\u7684\u7406\u89e3, \u72ed\u4e49\u6982\u5ff5\u548c\u5e7f\u4e49\u6982\u5ff5. \u72ed\u4e49\u6982\u5ff5: \u7279\u6307\u4e00\u7c7b\u77e5\u8bc6\u8868\u793a, \u672c\u8d28\u4e0a\u662f\u4e00\u79cd\u5927\u89c4\u6a21\u8bed\u4e49\u7f51\u7edc. \u5e7f\u4e49\u6982\u5ff5: \u662f\u5927\u6570\u636e\u65f6\u4ee3\u77e5\u8bc6\u5de5\u7a0b\u4e00\u7cfb\u5217\u6280\u672f\u7684\u603b\u79f0, \u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u6307\u4ee3\u5927\u6570\u636e\u77e5\u8bc6\u5de5\u7a0b\u8fd9\u4e00\u65b0\u5174\u6280\u672f. \u77e5\u8bc6\u8868\u793a: \u77e5\u8bc6\u8868\u793a\u662f\u5bf9\u663e\u793a\u4e16\u754c\u7684\u4e00\u79cd\u62bd\u8c61\u8868\u8fbe, \u4e3b\u8981\u5206\u4e3a\u7b26\u53f7\u8868\u793a\u548c\u6570\u503c\u8868\u793a. \u6bd4\u5982\"\u67cf\u62c9\u56fe\"\u8fd9\u4e09\u4e2a\u5b57\u7b26\u6307\u4ee3\u53e4\u5e0c\u814a\u54f2\u5b66\u5bb6\u67cf\u62c9\u56fe, \u7528\"=>\"\u8868\u793a\u903b\u8f91\u8574\u542b\u5173\u7cfb; \u7528\"1.7m\"\u8868\u793a\u4eba\u7684\u8eab\u9ad8, \u7528\"520\u5143\"\u8868\u793a\u7ea2\u5305\u91d1\u989d\u7b49. \u57fa\u4e8e\u56fe\u7684\u8868\u793a: \u6709\u5411\u56fe, \u65e0\u5411\u56fe, \u90bb\u63a5\u77e9\u9635\u7b49. \u57fa\u4e8e\u4e09\u5143\u7ec4(SPO)\u7684\u8868\u793a: RDF\u662f\u7528\u4e8e\u63cf\u8ff0\u73b0\u5b9e\u4e2d\u8d44\u6e90\u7684W3C\u6807\u51c6, \u662f\u63cf\u8ff0\u4fe1\u606f\u7684\u4e00\u79cd\u901a\u7528\u65b9\u6cd5, \u4f7f\u4fe1\u606f\u53ef\u4ee5\u88ab\u8ba1\u7b97\u673a\u5e94\u7528\u7a0b\u5e8f\u8bfb\u53d6\u5e76\u7406\u89e3. RDF\u5168\u79f0Resource Description Framework. \u4e3b\u4f53: Subject \u8c13\u8bcd: Predicate \u5ba2\u4f53: Object \u5b9e\u4f53\u8bc6\u522b: \u8457\u540d\u7684NER\u4efb\u52a1. \u65b9\u6cd5: \u9664\u4e86\u540c\u5b66\u4eec\u5df2\u7ecf\u719f\u77e5\u7684\u7ecf\u5178\u57fa\u7ebf\u6a21\u578bBiLSTM + CRF\u5916, \u8fd8\u6709IDCNN, BERT, BERT + CRF, FLAT\u7b49. \u8bcd\u6c47\u6316\u6398: \u5305\u542b\u9886\u57df\u8bcd\u6316\u6398, \u540c\u4e49\u8bcd\u6316\u6398, \u7f29\u7565\u8bcd\u6316\u6398\u7b49. \u5173\u7cfb\u62bd\u53d6: \u8457\u540d\u7684RE\u4efb\u52a1. \u65b9\u6cd5: \u57fa\u4e8e\u6a21\u5f0f\u7684\u62bd\u53d6(\u89c4\u5219\u6d3e), \u57fa\u4e8e\u6a21\u578b\u7684\u62bd\u53d6(CNN, multi-head-selection\u7b49) \u5355\u6e90\u767e\u79d1\u56fe\u8c31: \u9488\u5bf9\u4e8e\u5355\u4e2a\u6570\u636e\u6e90\u6784\u5efa\u7684\u767e\u79d1\u56fe\u8c31, \u5178\u578b\u4ee3\u8868\u5305\u62ecDBpedia\u548cYAGO\u4ee5\u7ef4\u57fa\u767e\u79d1\u4f5c\u4e3a\u6570\u636e\u6e90, CN-DBpedia\u4ee5\u767e\u5ea6\u767e\u79d1\u4f5c\u4e3a\u6570\u636e\u6e90. \u591a\u6e90\u767e\u79d1\u56fe\u8c31: \u878d\u5408\u591a\u4e2a\u6570\u636e\u6e90\u6784\u5efa\u7684\u767e\u79d1\u56fe\u8c31, \u5178\u578b\u4ee3\u8868\u5305\u62ecBabelNet\u878d\u5408\u4e86284\u79cd\u4e0d\u540c\u8bed\u8a00\u7684\u6570\u636e\u6e90, zhishi.me\u878d\u5408\u4e86\u767e\u5ea6\u767e\u79d1, \u4e92\u52a8\u767e\u79d1\u4ee5\u53ca\u4e2d\u6587\u7ef4\u57fa\u767e\u79d1, XLORE\u878d\u5408\u4e86\u767e\u5ea6\u767e\u79d1, \u4e92\u52a8\u767e\u79d1\u4ee5\u53ca\u82f1\u6587\u7ef4\u57fa\u767e\u79d1. \u56fe\u6570\u636e\u5e93: \u4ee5neo4j\u4e3a\u5178\u578b\u4ee3\u8868\u7684\u56fe\u6570\u636e\u5e93, \u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u77e5\u8bc6\u56fe\u8c31\u4e2d. \u5c0f\u8282\u603b\u7ed3 \u00b6 \u4f5c\u4e3a\u672c\u9879\u76ee\u8bb2\u4e49\u7684\u7b2c\u4e00\u7ae0\u7b2c\u4e00\u5c0f\u8282, \u6211\u4eec\u5411\u540c\u5b66\u4eec\u4ecb\u7ecd\u4e86\u7ea2\u8718\u86db\u9879\u76ee\u80cc\u666f, \u6570\u636e\u6765\u6e90, \u4ee5\u53ca\u77e5\u8bc6\u56fe\u8c31\u4e2d\u6700\u91cd\u8981\u7684\u76f8\u5173\u6982\u5ff5. \u77e5\u8bc6\u56fe\u8c31\u9886\u57df\u5e7f\u6cdb, \u6d89\u53ca\u5230\u7684\u7ec6\u5206\u65b9\u5411\u548c\u77e5\u8bc6\u70b9\u975e\u5e38\u591a, \u5728\u540e\u7eed\u8bfe\u7a0b\u5b66\u4e60\u4e2d\u6211\u4eec\u4f1a\u5e26\u7740\u540c\u5b66\u4eec\u4e00\u6b65\u6b65\u638c\u63e1.","title":"1.1 \u7ea2\u8718\u86db\u9879\u76ee\u80cc\u666f"},{"location":"1_1.html#_1","text":"","title":"\u7ea2\u8718\u86db\u9879\u76ee\u80cc\u666f\u4ecb\u7ecd"},{"location":"1_1.html#_2","text":"\u4e86\u89e3\u7ea2\u8718\u86db\u9879\u76ee\u7684\u5f00\u53d1\u80cc\u666f. \u4e86\u89e3\u77e5\u8bc6\u56fe\u8c31\u7684\u76f8\u5173\u57fa\u7840\u6982\u5ff5.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"1_1.html#_3","text":"\u4ece2012\u5e74Google\u516c\u53f8\u63d0\u51fa\"\u77e5\u8bc6\u56fe\u8c31(Knowledge Graph)\"\u5230\u4eca\u5929, \u77e5\u8bc6\u56fe\u8c31\u6280\u672f\u53d1\u5c55\u8fc5\u901f, \u4f34\u968f\u7740\u5927\u6570\u636e\u548c\u4eba\u5de5\u667a\u80fd\u7684\u98de\u901f\u53d1\u5c55, \u6307\u793a\u56fe\u8c31\u7684\u5185\u6db5\u4e5f\u8d8a\u6765\u8d8a\u4e30\u5bcc. \u77e5\u8bc6\u56fe\u8c31\u6280\u672f\u80cc\u540e\u878d\u5408\u4e86\u4f17\u591aCV, NLP, \u63a8\u8350\u7cfb\u7edf, \u5927\u6570\u636e\u7b49\u77e5\u8bc6, \u53ef\u4ee5\u8bf4\u662f\u4eba\u5de5\u667a\u80fd\u65f6\u4ee3\u7684\u65b0\u79c0\u548c\u70ed\u70b9. \u4f20\u667a\u6559\u80b2\u7684AI\u5f15\u9886IT\u6559\u80b2\u524d\u6cbf, \u7279\u6b64\u63a8\u51fa\u7ea2\u8718\u86db\u9879\u76ee, \u5e26\u7740\u540c\u5b66\u4eec\u5b8c\u6574\u7684\u5b66\u4e60\u77e5\u8bc6\u56fe\u8c31\u76f8\u5173\u6280\u672f, \u5e76\u624e\u5b9e\u7684\u638c\u63e1\u6838\u5fc3\u5185\u5bb9\u548c\u4ee3\u7801\u80fd\u529b. \u4efb\u4f55AI\u9879\u76ee\u90fd\u662f\u57fa\u4e8e\u6570\u636e\u7684\u9879\u76ee, \u8fd9\u91cc\u9762\u6570\u636e\u7684\u6765\u6e90\u591a\u79cd\u591a\u6837. \u9879\u76ee\u4e2d\u7684\u6570\u636e\u6765\u6e90\u57fa\u672c\u5206\u4e3a3\u5927\u79cd\u7c7b: \u7b2c\u4e00\u7c7b: \u516c\u53f8\u5185\u90e8\u6570\u636e\u90e8\u95e8\u63d0\u4f9b. \u60c5\u51b51: \u6570\u636e\u5e73\u53f0\u6709\u9884\u5904\u7406, \u63d0\u4f9b\u7684\u662f\"\u6210\u54c1\u6570\u636e\". \u60c5\u51b52: \u6570\u636e\u5e73\u53f0\u6ca1\u6709\u9884\u5904\u7406, \u53ea\u544a\u8bc9\u5f00\u53d1\u4eba\u5458\"\u6570\u636e\u8def\u5f84\". \u60c5\u51b53: \u539f\u59cb\u6570\u636e\u5c31\u6ca1\u6709, \u9700\u8981\u5f00\u53d1\u4eba\u5458\u6c9f\u901a\u4e0d\u540c\u90e8\u5206, \u83b7\u53d6\"\u4e1a\u52a1\u6570\u636e\". \u7b2c\u4e8c\u7c7b: \u7532\u65b9\u63d0\u9700\u6c42, \u5e76\u63d0\u4f9b\u6570\u636e. \u60c5\u51b51: \u7532\u65b9\u6709\u9884\u5904\u7406\u6570\u636e, \u63d0\u4f9b\u7684\u57fa\u672c\u662f\"\u534a\u6210\u54c1\u6570\u636e\". \u60c5\u51b52: \u7532\u65b9\u53ea\u8d1f\u8d23\"\u57cb\u70b9\", \u540e\u7eed\u6570\u636e\u9700\u8981\u5f00\u53d1\u4eba\u5458\u5904\u7406. \u60c5\u51b53: \u7532\u65b9\u6570\u636e\"\u532e\u4e4f\", \u751a\u81f3\u6570\u636e\"\u7f3a\u5931\". \u7b2c\u4e09\u7c7b: \u9700\u6c42\u753b\u5927\u997c\u9636\u6bb5, \u6ca1\u6709\u6570\u636e, \u6ca1\u6709GPU, \u53ea\u6709\"\u84dd\u56fe\"\u548c\"\u5c55\u671b\".","title":"\u7ea2\u8718\u86db\u9879\u76ee\u80cc\u666f"},{"location":"1_1.html#_4","text":"\u77e5\u8bc6\u56fe\u8c31\u5305\u542b\u4e24\u4e2a\u5c42\u9762\u7684\u7406\u89e3, \u72ed\u4e49\u6982\u5ff5\u548c\u5e7f\u4e49\u6982\u5ff5. \u72ed\u4e49\u6982\u5ff5: \u7279\u6307\u4e00\u7c7b\u77e5\u8bc6\u8868\u793a, \u672c\u8d28\u4e0a\u662f\u4e00\u79cd\u5927\u89c4\u6a21\u8bed\u4e49\u7f51\u7edc. \u5e7f\u4e49\u6982\u5ff5: \u662f\u5927\u6570\u636e\u65f6\u4ee3\u77e5\u8bc6\u5de5\u7a0b\u4e00\u7cfb\u5217\u6280\u672f\u7684\u603b\u79f0, \u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u6307\u4ee3\u5927\u6570\u636e\u77e5\u8bc6\u5de5\u7a0b\u8fd9\u4e00\u65b0\u5174\u6280\u672f. \u77e5\u8bc6\u8868\u793a: \u77e5\u8bc6\u8868\u793a\u662f\u5bf9\u663e\u793a\u4e16\u754c\u7684\u4e00\u79cd\u62bd\u8c61\u8868\u8fbe, \u4e3b\u8981\u5206\u4e3a\u7b26\u53f7\u8868\u793a\u548c\u6570\u503c\u8868\u793a. \u6bd4\u5982\"\u67cf\u62c9\u56fe\"\u8fd9\u4e09\u4e2a\u5b57\u7b26\u6307\u4ee3\u53e4\u5e0c\u814a\u54f2\u5b66\u5bb6\u67cf\u62c9\u56fe, \u7528\"=>\"\u8868\u793a\u903b\u8f91\u8574\u542b\u5173\u7cfb; \u7528\"1.7m\"\u8868\u793a\u4eba\u7684\u8eab\u9ad8, \u7528\"520\u5143\"\u8868\u793a\u7ea2\u5305\u91d1\u989d\u7b49. \u57fa\u4e8e\u56fe\u7684\u8868\u793a: \u6709\u5411\u56fe, \u65e0\u5411\u56fe, \u90bb\u63a5\u77e9\u9635\u7b49. \u57fa\u4e8e\u4e09\u5143\u7ec4(SPO)\u7684\u8868\u793a: RDF\u662f\u7528\u4e8e\u63cf\u8ff0\u73b0\u5b9e\u4e2d\u8d44\u6e90\u7684W3C\u6807\u51c6, \u662f\u63cf\u8ff0\u4fe1\u606f\u7684\u4e00\u79cd\u901a\u7528\u65b9\u6cd5, \u4f7f\u4fe1\u606f\u53ef\u4ee5\u88ab\u8ba1\u7b97\u673a\u5e94\u7528\u7a0b\u5e8f\u8bfb\u53d6\u5e76\u7406\u89e3. RDF\u5168\u79f0Resource Description Framework. \u4e3b\u4f53: Subject \u8c13\u8bcd: Predicate \u5ba2\u4f53: Object \u5b9e\u4f53\u8bc6\u522b: \u8457\u540d\u7684NER\u4efb\u52a1. \u65b9\u6cd5: \u9664\u4e86\u540c\u5b66\u4eec\u5df2\u7ecf\u719f\u77e5\u7684\u7ecf\u5178\u57fa\u7ebf\u6a21\u578bBiLSTM + CRF\u5916, \u8fd8\u6709IDCNN, BERT, BERT + CRF, FLAT\u7b49. \u8bcd\u6c47\u6316\u6398: \u5305\u542b\u9886\u57df\u8bcd\u6316\u6398, \u540c\u4e49\u8bcd\u6316\u6398, \u7f29\u7565\u8bcd\u6316\u6398\u7b49. \u5173\u7cfb\u62bd\u53d6: \u8457\u540d\u7684RE\u4efb\u52a1. \u65b9\u6cd5: \u57fa\u4e8e\u6a21\u5f0f\u7684\u62bd\u53d6(\u89c4\u5219\u6d3e), \u57fa\u4e8e\u6a21\u578b\u7684\u62bd\u53d6(CNN, multi-head-selection\u7b49) \u5355\u6e90\u767e\u79d1\u56fe\u8c31: \u9488\u5bf9\u4e8e\u5355\u4e2a\u6570\u636e\u6e90\u6784\u5efa\u7684\u767e\u79d1\u56fe\u8c31, \u5178\u578b\u4ee3\u8868\u5305\u62ecDBpedia\u548cYAGO\u4ee5\u7ef4\u57fa\u767e\u79d1\u4f5c\u4e3a\u6570\u636e\u6e90, CN-DBpedia\u4ee5\u767e\u5ea6\u767e\u79d1\u4f5c\u4e3a\u6570\u636e\u6e90. \u591a\u6e90\u767e\u79d1\u56fe\u8c31: \u878d\u5408\u591a\u4e2a\u6570\u636e\u6e90\u6784\u5efa\u7684\u767e\u79d1\u56fe\u8c31, \u5178\u578b\u4ee3\u8868\u5305\u62ecBabelNet\u878d\u5408\u4e86284\u79cd\u4e0d\u540c\u8bed\u8a00\u7684\u6570\u636e\u6e90, zhishi.me\u878d\u5408\u4e86\u767e\u5ea6\u767e\u79d1, \u4e92\u52a8\u767e\u79d1\u4ee5\u53ca\u4e2d\u6587\u7ef4\u57fa\u767e\u79d1, XLORE\u878d\u5408\u4e86\u767e\u5ea6\u767e\u79d1, \u4e92\u52a8\u767e\u79d1\u4ee5\u53ca\u82f1\u6587\u7ef4\u57fa\u767e\u79d1. \u56fe\u6570\u636e\u5e93: \u4ee5neo4j\u4e3a\u5178\u578b\u4ee3\u8868\u7684\u56fe\u6570\u636e\u5e93, \u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u77e5\u8bc6\u56fe\u8c31\u4e2d.","title":"\u77e5\u8bc6\u56fe\u8c31\u76f8\u5173\u6982\u5ff5"},{"location":"1_1.html#_5","text":"\u4f5c\u4e3a\u672c\u9879\u76ee\u8bb2\u4e49\u7684\u7b2c\u4e00\u7ae0\u7b2c\u4e00\u5c0f\u8282, \u6211\u4eec\u5411\u540c\u5b66\u4eec\u4ecb\u7ecd\u4e86\u7ea2\u8718\u86db\u9879\u76ee\u80cc\u666f, \u6570\u636e\u6765\u6e90, \u4ee5\u53ca\u77e5\u8bc6\u56fe\u8c31\u4e2d\u6700\u91cd\u8981\u7684\u76f8\u5173\u6982\u5ff5. \u77e5\u8bc6\u56fe\u8c31\u9886\u57df\u5e7f\u6cdb, \u6d89\u53ca\u5230\u7684\u7ec6\u5206\u65b9\u5411\u548c\u77e5\u8bc6\u70b9\u975e\u5e38\u591a, \u5728\u540e\u7eed\u8bfe\u7a0b\u5b66\u4e60\u4e2d\u6211\u4eec\u4f1a\u5e26\u7740\u540c\u5b66\u4eec\u4e00\u6b65\u6b65\u638c\u63e1.","title":"\u5c0f\u8282\u603b\u7ed3"},{"location":"1_2.html","text":"\u77e5\u8bc6\u56fe\u8c31\u6982\u8ff0 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u638c\u63e1\u77e5\u8bc6\u56fe\u8c31\u7684\u57fa\u672c\u6982\u5ff5. \u4e86\u89e3\u77e5\u8bc6\u56fe\u8c31\u7684\u53d1\u5c55\u5386\u53f2. \u7406\u89e3\u77e5\u8bc6\u56fe\u8c31\u7684\u5e94\u7528\u4ef7\u503c. \u638c\u63e1\u77e5\u8bc6\u56fe\u8c31\u7684\u5206\u7c7b. \u57fa\u672c\u6982\u5ff5 \u00b6 \u77e5\u8bc6\u56fe\u8c31\u6700\u521d\u662f\u7279\u6307Google\u516c\u53f8\u4e3a\u4e86\u652f\u6491\u5176\u8bed\u4e49\u641c\u7d22\u800c\u5efa\u7acb\u7684\u77e5\u8bc6\u5e93. \u4f5c\u4e3a\u4e00\u79cd\u77e5\u8bc6\u8868\u793a\u5f62\u5f0f, \u77e5\u8bc6\u56fe\u8c31\u662f\u4e00\u79cd\u5927\u89c4\u6a21\u8bed\u4e49\u7f51\u7edc, \u5305\u542b\u5b9e\u4f53(Entity), \u6982\u5ff5(Concept)\u53ca\u5176\u4e4b\u95f4\u7684\u5404\u79cd\u5173\u7cfb(Relation). \u8bed\u4e49\u7f51\u7edc: \u662f\u4e00\u79cd\u4ee5\u56fe\u5f62\u5316(Graphic)\u5f62\u5f0f\u901a\u8fc7\u70b9\u548c\u8fb9\u8868\u8fbe\u77e5\u8bc6\u7684\u65b9\u5f0f, \u5176\u57fa\u672c\u7ec4\u6210\u5143\u7d20\u662f\u70b9\u548c\u8fb9. \u8bed\u4e49\u7f51\u7edc\u4e2d\u7684\u70b9\u53ef\u4ee5\u62bd\u8c61\u7684\u8868\u8fbe\u5b9e\u4f53, \u6982\u5ff5, \u503c. \u4f8b\u5982\u4e0b\u56fe: \u70b9\u53ef\u4ee5\u662f\u54fa\u4e73\u52a8\u7269, \u718a, \u810a\u690e, \u9c7c, \u6c34\u7b49; \u7ebf\u53ef\u4ee5\u8868\u660e\u662f, \u6709, \u4f4f\u5728\u7b49\u5173\u7cfb. \u5b9e\u4f53: \u5b9e\u4f53\u6709\u65f6\u4e5f\u4f1a\u88ab\u79f0\u4e3a\u5bf9\u8c61(Object), \u6216\u5b9e\u4f8b(Instance). \u5b9e\u4f53\u662f\u5c5e\u6027\u8d56\u4ee5\u5b58\u5728\u7684\u57fa\u7840, \u662f\u72ec\u7acb\u7684, \u81ea\u5728\u7684, \u4e0d\u4f9d\u9644\u5176\u4ed6\u4e1c\u897f\u7684. \u6982\u5ff5: \u6982\u5ff5\u53c8\u88ab\u79f0\u4e3a\u7c7b\u522b(Type), \u6216\u7c7b(Category, Class). \u6bd4\u5982\"\u54f2\u5b66\u5bb6\", \u8fd9\u4e2a\u6982\u5ff5\u4e0d\u662f\u6307\u67d0\u4e00\u4e2a\u7279\u5b9a\u7684\u4eba, \u6bd4\u5982\"\u67cf\u62c9\u56fe\", \u800c\u662f\u6307\u4e00\u7c7b\u4eba. \u503c: \u6bcf\u4e2a\u5b9e\u4f53\u90fd\u6709\u4e00\u5b9a\u7684\u5c5e\u6027\u503c. \u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u8fb9\u53ef\u4ee5\u5206\u4e3a\u4e24\u7c7b: \u5c5e\u6027(Property) \u5173\u7cfb(Relation) \u5c5e\u6027: \u5c5e\u6027(Property)\u63cf\u8ff0\u5b9e\u4f53\u67d0\u65b9\u9762\u7684\u7279\u6027, \u6bd4\u5982\u4eba\u7684\u51fa\u751f\u65e5\u671f, \u8eab\u9ad8, \u5e74\u9f84, \u4f53\u91cd\u7b49. \u5173\u7cfb: \u5173\u7cfb(Relation)\u53ef\u4ee5\u8ba4\u4e3a\u662f\u4e00\u7c7b\u7279\u6b8a\u7684\u5c5e\u6027, \u5f53\u5b9e\u4f53\u7684\u67d0\u4e2a\u5c5e\u6027\u503c\u4e5f\u662f\u4e00\u4e2a\u5b9e\u4f53\u65f6, \u8fd9\u4e2a\u5c5e\u6027\u5b9e\u8d28\u4e0a\u5c31\u662f\u5173\u7cfb. \u77e5\u8bc6\u56fe\u8c31\u4e0e\u4f20\u7edf\u8bed\u4e49\u7f51\u7edc\u7684\u533a\u522b: 1: \u89c4\u6a21\u5de8\u5927 2: \u8bed\u4e49\u4e30\u5bcc 3: \u8d28\u91cf\u7cbe\u826f 4: \u7ed3\u6784\u53cb\u597d \u77e5\u8bc6\u56fe\u8c31\u7684\u6311\u6218: 1: \u9ad8\u8d28\u91cf\u6a21\u5f0f\u7684\u7f3a\u5931 2: \u5c01\u95ed\u4e16\u754c\u5047\u8bbe\u4e0d\u518d\u6210\u7acb 3: \u5927\u89c4\u6a21\u81ea\u52a8\u5316\u77e5\u8bc6\u83b7\u53d6\u6210\u4e3a\u524d\u63d0 \u77e5\u8bc6\u56fe\u8c31\u4e0e\u672c\u4f53(Ontology)\u7684\u533a\u522b: \u8ba1\u7b97\u673a\u9886\u57df\u7684\u672c\u4f53\u4fa7\u91cd\u4e8e\u8868\u8fbe\u8ba4\u77e5\u7684\u6982\u5ff5\u6846\u67b6, \u8868\u8fbe\u6982\u5ff5\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u7cfb, \u5f80\u5f80\u4e5f\u4f34\u968f\u7740\u523b\u753b\u6982\u5ff5\u7684\u516c\u7406\u7cfb\u7edf. \u672c\u4f53\u523b\u753b\u4e86\u4eba\u7c7b\u8ba4\u77e5\u4e00\u4e2a\u9886\u57df\u7684\u57fa\u672c\u6846\u67b6, \u4e3a\u673a\u5668\u5b9a\u4e49\u672c\u4f53, \u5c31\u597d\u6bd4\u5c06\u6211\u4eec\u7684\u4e16\u754c\u89c2\u4f20\u9012\u7ed9\u673a\u5668. \u8fd9\u4e2a\u8fc7\u7a0b\u9700\u8981\u4eba\u7c7b\u4e13\u5bb6\u5b8c\u6210, \u5728\u5efa\u8bbe\u77e5\u8bc6\u56fe\u8c31\u7684\u521d\u671f, \u6a21\u5f0f(Schema)\u5b9a\u4e49\u672c\u8d28\u4e0a\u5c31\u662f\u5728\u5b8c\u6210\u672c\u4f53\u5b9a\u4e49\u7684\u4efb\u52a1. \u77e5\u8bc6\u56fe\u8c31\u7684\u5e7f\u4e49\u6982\u5ff5: 1: \u77e5\u8bc6\u56fe\u8c31 2: \u77e5\u8bc6\u8868\u793a 3: \u77e5\u8bc6\u5de5\u7a0b 4: \u4eba\u5de5\u667a\u80fd \u4e0a\u97624\u4e2a\u5e7f\u4e49\u6982\u5ff5, \u662f\u4f9d\u6b21\u5305\u542b\u4e8e\u7684\u5173\u7cfb. \u53d1\u5c55\u5386\u53f2 \u00b6 \u77e5\u8bc6\u56fe\u8c31\u8d77\u6e90\u4e8e20\u4e16\u7eaa70\u5e74\u4ee3, \u4e00\u76f4\u52302012\u5e74Google\u516c\u53f8\u63d0\u51fa\u9762\u5411\u4e92\u8054\u7f51\u641c\u7d22\u7684\u5927\u89c4\u6a21\u77e5\u8bc6\u56fe\u8c31, \u6b63\u5f0f\u5ba3\u544a\u77e5\u8bc6\u56fe\u8c31\u7684\u8bde\u751f. \u603b\u4f53\u53d1\u5c55\u7ecf\u5386\u4e862\u4e2a\u65f6\u4ee3: \u65e9\u671f\u77e5\u8bc6\u5de5\u7a0b\u65f6\u4ee3 \u5927\u6570\u636e\u77e5\u8bc6\u5de5\u7a0b\u65f6\u4ee3 \u65e9\u671f\u77e5\u8bc6\u5de5\u7a0b\u65f6\u4ee3: \u77e5\u8bc6\u5de5\u7a0b\u6e90\u4e8e\u7b26\u53f7\u4e3b\u4e49, \u7b26\u53f7\u4e3b\u4e49\u8ba4\u4e3a\u77e5\u8bc6\u662f\u667a\u80fd\u7684\u57fa\u7840, \u4eba\u5de5\u667a\u80fd\u7684\u6838\u5fc3\u95ee\u9898\u662f\u77e5\u8bc6\u8868\u793a, \u63a8\u7406\u548c\u5e94\u7528. \u8fd9\u4e00\u89c2\u70b9\u548c\u5f53\u4eca\u673a\u5668\u5b66\u4e60\u6210\u4e3a\u4eba\u5de5\u667a\u80fd\u7684\u70ed\u70b9\u5f62\u6210\u4e86\u9c9c\u660e\u5bf9\u7167. \u7b26\u53f7\u4e3b\u4e49\u4e3a\u4ee3\u8868\u7684\u65e9\u671f\u77e5\u8bc6\u5de5\u7a0b\u66fe\u7ecf\u89e3\u51b3\u4e86\u4e00\u7cfb\u5217\u5b9e\u9645\u95ee\u9898, \u6bd4\u5982\u8ba1\u7b97\u673a\u7cfb\u7edf\u7684\u81ea\u52a8\u914d\u7f6e, \u86cb\u767d\u8d28\u7ed3\u6784\u7684\u53d1\u73b0, \u673a\u5668\u6570\u5b66\u5b9a\u7406\u7684\u8bc1\u660e\u7b49. \u5c40\u9650\u6027: \u4f20\u7edf\u77e5\u8bc6\u5de5\u7a0b\u6240\u80fd\u6210\u529f\u89e3\u51b3\u7684\u95ee\u9898\u666e\u904d\u5177\u6709\u89c4\u5219\u660e\u786e, \u5e94\u7528\u5c01\u95ed\u7684\u7279\u70b9! \u65e9\u671f\u77e5\u8bc6\u5de5\u7a0b\u7684\u5c40\u9650\u6027: 1: \u9690\u6027\u77e5\u8bc6\u4e0e\u8fc7\u7a0b\u77e5\u8bc6\u96be\u4ee5\u8868\u8fbe 2: \u77e5\u8bc6\u8868\u8fbe\u7684\u4e3b\u89c2\u6027\u4e0e\u4e0d\u4e00\u81f4\u6027 3: \u77e5\u8bc6\u96be\u6613\u5b8c\u5907 4: \u77e5\u8bc6\u66f4\u65b0\u56f0\u96be \u5927\u6570\u636e\u77e5\u8bc6\u5de5\u7a0b\u65f6\u4ee3: \u968f\u774021\u4e16\u7eaa\u4e92\u8054\u7f51\u7684\u5174\u8d77, \u4f34\u968f\u7740\u5927\u6570\u636e\u65f6\u4ee3\u7684\u5230\u6765, \u5171\u540c\u50ac\u751f\u4e86\u5927\u6570\u636e\u77e5\u8bc6\u5de5\u7a0b\u65f6\u4ee3. \u4e92\u8054\u7f51\u573a\u666f\u4e0b\u7684\u5e94\u7528\u6709\u5982\u4e0b\u7279\u70b9: 1: \u5927\u89c4\u6a21\u5f00\u653e\u6027\u5e94\u7528 (\u5403\u9e21, \u78ca\u5931\u5355\u5200, \u5ddd\u5b9d) 2: \u7cbe\u5ea6\u8981\u6c42\u76f8\u5bf9\u4e0d\u9ad8 3: \u77e5\u8bc6\u63a8\u7406\u7b80\u5355(\u5218\u5fb7\u534e, \u59da\u660e\u8001\u5a46\u7684\u7403\u961f\u6559\u7ec3\u5bb6\u7684\u5b69\u5b50\u6709\u591a\u9ad8) \u5927\u6570\u636e\u65f6\u4ee3\u5bf9\u77e5\u8bc6\u56fe\u8c31\u53d1\u5c55\u7684\u4fc3\u8fdb\u4f5c\u7528: 1: \u6570\u636e, \u7b97\u529b, \u6a21\u578b\u7684\u98de\u901f\u53d1\u5c55\u662f\u7684\u5927\u89c4\u6a21\u81ea\u52a8\u5316\u77e5\u8bc6\u83b7\u53d6\u6210\u4e3a\u53ef\u80fd 2: \u4f17\u5305\u6280\u672f\u4f7f\u5f97\u77e5\u8bc6\u7684\u89c4\u6a21\u5316\u9a8c\u8bc1\u6210\u4e86\u53ef\u80fd 3: \u9ad8\u8d28\u91cf\u7684\u7528\u6237\u751f\u6210\u5185\u5bb9(UGC)\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u77e5\u8bc6\u5e93\u7684\u6765\u6e90 \u5e94\u7528\u4ef7\u503c \u00b6 \u4ece2015\u5e74\u8d77NLP\u8fdb\u5165\u4e86\u6df1\u5ea6\u5b66\u4e60\u65f6\u4ee3, 2018\u5e74\u8d77NLP\u8fdb\u5165\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u65f6\u4ee3, \u4f46\u662fNLP\u7684\u7ec8\u6781\u6311\u6218\u59cb\u7ec8\u90fd\u662f\"\u56fe\u7075\u6d4b\u8bd5\". \u7ad9\u57282023\u5e74, \u4ece\u5b66\u672f\u754c\u7684\u524d\u6cbf\u5230\u5de5\u4e1a\u754c\u7684\u5b9e\u8df5, \u666e\u904d\u8fbe\u6210\u4e00\u4e2a\u5171\u8bc6: \u77e5\u8bc6\u56fe\u8c31\u662f\u8ba4\u77e5\u667a\u80fd\u7684\u57fa\u77f3! 2013\u5e74\u91d1\u7403\u5956\u5f97\u4e3bC\u7f57. \u5c0f\u5170\u8bf4\u5979\u5468\u672b\u8bfb\u4e86\u6d77\u660e\u5a01\u7684\u4e66. \u8fd9\u5468\u672b\u6211\u8981\u53bb\u7f57\u5170\u52a0\u6d1b\u65af\u770b\u6bd4\u8d5b. \u968f\u7740\u63a8\u7279\u88ab\u6536\u8d2d, \u94a2\u94c1\u4fa0\u7684\u5546\u4e1a\u5e1d\u56fd\u8fdb\u4e00\u6b65\u5e9e\u5927\u4e86. \u4e3a\u4e86\u5b9e\u73b0\u673a\u5668\u5bf9\u81ea\u7136\u8bed\u8a00\u7684\u7406\u89e3, \u9700\u8981\u7684\u80cc\u666f\u77e5\u8bc6\u6709\u7740\u82db\u523b\u7684\u6761\u4ef6: 1: \u89c4\u6a21\u5fc5\u987b\u8db3\u591f\u5de8\u5927\u624d\u80fd\u7406\u89e3\u4e0d\u540c\u7684\u5b9e\u4f53\u4e0e\u6982\u5ff5 2: \u8bed\u4e49\u5173\u7cfb\u5fc5\u987b\u8db3\u591f\u4e30\u5bcc\u624d\u80fd\u7406\u89e3\u4e0d\u540c\u7684\u5173\u7cfb 3: \u7ed3\u6784\u5fc5\u987b\u8db3\u591f\u53cb\u597d\u624d\u80fd\u4e3a\u673a\u5668\u6240\u5904\u7406 4: \u8d28\u91cf\u5fc5\u987b\u8db3\u591f\u7cbe\u826f\u624d\u80fd\u8ba9\u673a\u5668\u5bf9\u73b0\u5b9e\u4e16\u754c\u4ea7\u751f\u6b63\u786e\u7684\u7406\u89e3 \u6ce8\u610f: \u5f53\u6211\u4eec\u904d\u5386\u6240\u6709\u4e3b\u6d41\u7684\u77e5\u8bc6\u8868\u793a\u6a21\u5f0f\u540e, \u80fd\u6ee1\u8db3\u4e0a\u8ff04\u4e2a\u6807\u51c6\u548c\u6761\u4ef6\u7684, \u53ea\u6709\u77e5\u8bc6\u56fe\u8c31! \u77e5\u8bc6\u56fe\u8c31\u8d4b\u80fd\u53ef\u89e3\u91caAI: \u73b0\u5728\u7684\u641c\u7d22\u5e73\u53f0\u4e0a, \"How\", \"Why\"\u4e4b\u7c7b\u7684\u641c\u7d22\u95ee\u9898\u8d8a\u6765\u8d8a\u591a, \u7528\u6237\u4e0d\u4ec5\u4ec5\u6ee1\u8db3\u4e8e\u5f97\u5230\u4e8b\u5b9e\u7c7b\u7684\u641c\u7d22\u7ed3\u679c, \u66f4\u5173\u5fc3\u63a8\u7406, \u89e3\u91ca\u7684\u7ed3\u679c. \u6bd4\u5982\"\u600e\u4e48\u505a\u5bab\u4fdd\u867e\u7403\", \"\u600e\u4e48\u53bb\u9890\u548c\u56ed\". \u53ef\u89e3\u91ca\u80fd\u529b\u7684\u6b20\u7f3a\u662fAI\u57284\u5927\u5782\u76f4\u9886\u57df\u5e94\u7528\u7684\u74f6\u9888\u6240\u5728!!! \u77e5\u8bc6\u56fe\u8c31\u53ef\u4ee5\u8fc5\u901f\u589e\u5f3a\u673a\u5668\u5b66\u4e60\u7684\u80fd\u529b: \u77e5\u8bc6\u56fe\u8c31\u76f8\u5f53\u4e8e\u63d0\u4f9b\u7ed9\u673a\u5668\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u5148\u9a8c\u77e5\u8bc6\u5e93, \u8fd9\u79cd\u77e5\u8bc6\u589e\u5f3a\u4e0b\u7684\u6a21\u578b\u5b66\u4e60, \u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u6a21\u578b\u5bf9\u4e8e\u5927\u6837\u672c\u7684\u4f9d\u8d56. \u77e5\u8bc6\u56fe\u8c31\u63d0\u4f9b\u4e86\"\u77e5\u8bc6\u5f15\u5bfc\"\u8fd9\u4e00\u91cd\u8981\u65b9\u5f0f, \u5728\u91c7\u7528\u6570\u636e\u9a71\u52a8\u7684\u4f20\u7edf\u6a21\u5f0f\u4e2d, \u4e3a\u4e86\u7edf\u8ba1\u6982\u7387\u5206\u5e03, \u6316\u6398\u6570\u636e\u89c4\u5f8b, \u6a21\u578b\u9700\u8981\u5927\u91cf\u7684\u6837\u672c. \u4f46\u5373\u4f7f\u6837\u672c\u6570\u636e\u91cf\u518d\u5927, \u5355\u7eaf\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u4ecd\u7136\u9762\u4e34\u6548\u679c\u7684\"\u5929\u82b1\u677f\". \u8981\u60f3\u7a81\u7834\u8fd9\u4e2a\u5929\u82b1\u677f, \u5c31\u9700\u8981\u77e5\u8bc6\u5f15\u5bfc. \u4f8b\u5982: \u5728\u53f8\u6cd5\u8bc9\u8bbc\u7684\u5211\u7f5a\u9884\u6d4bAI\u95ee\u9898\u4e2d, \u540c\u6837\u7684\u4e24\u4e2a\u4f24\u4eba\u6848\u60c5\u9648\u8ff0, \u4e00\u4e2a\u662f\u5acc\u7591\u72af\u9884\u5148\u8eab\u4e0a\u5e26\u4e86\u5315\u9996, \u53e6\u4e00\u4e2a\u5acc\u7591\u72af\u5728\u6848\u53d1\u73b0\u573a\u968f\u624b\u6361\u4e86\u4e00\u5757\u7816\u5934, \u5373\u4f7f\u5176\u4ed6\u6240\u6709\u7684\u9648\u8ff0\u8fc7\u7a0b\u5b8c\u5168\u4e00\u6837, \u6700\u7ec8\u7684\u5211\u7f5a\u9884\u6d4b\u7ed3\u679c\u4e5f\u5e94\u8be5\u5dee\u522b\u5f88\u5927. \u56e0\u4e3a\u524d\u8005\u66f4\u503e\u5411\u4e8e\u84c4\u610f\u8c0b\u6740, \u540e\u8005\u66f4\u503e\u5411\u4e8e\u4e34\u65f6\u8d77\u610f. \u77e5\u8bc6\u56fe\u8c31: \u53ef\u4ee5\u5229\u7528\u5148\u9a8c\u7684\u53f8\u6cd5\u77e5\u8bc6\u6765\u8f85\u52a9\u5224\u5b9a. \u6570\u636e\u9a71\u52a8: \u8bcd\u9891, \u8bed\u53e5\u5d4c\u5165\u5411\u91cf\u7b49\u6765\u8f85\u52a9\u5224\u5b9a. \u4e92\u8054\u7f51\u65f6\u4ee3\u77e5\u8bc6\u56fe\u8c31\u7684\u5de8\u5927\u5e94\u7528\u4ef7\u503c: 1: \u6570\u636e\u5206\u6790(\u738b\u5b9d\u5f3a\u79bb\u5a5a, \u738b\u5b9d\u5b9d\u79bb\u5a5a, \u50bb\u6839\u79bb\u5a5a) 2: \u667a\u6167\u641c\u7d22(iPad \u5145\u7535\u5668; toys kids, kids toys; \u591a\u6a21\u6001\u641c\u7d22; \u660e\u661f\u53d1\u5c0f\u533a\u7167\u7247\u534f\u540c\u641c\u7d22) 3: \u667a\u80fd\u63a8\u8350(\u6c99\u6ee9\u88e4-\u6cf3\u8863, \u9632\u6652\u971c; \u51b7\u542f\u52a8; \u5fae\u535a-\u4e5d\u5be8\u6c9f, \u5f20\u5bb6\u754c, \u9ec4\u5c71 VS \u6dd8\u5b9d-\u80cc\u5305, \u767b\u5c71\u978b, \u76f8\u673a) 4: \u81ea\u7136\u4eba\u673a\u4ea4\u4e92(\u5bf9\u8bdd\u5f0f\u4ea4\u4e92) 5: \u51b3\u7b56\u652f\u6301(\u738b\u5b9d\u5f3a\u79bb\u5a5a-\u5f20\u8d77\u6dee\u5f8b\u5e08; \u91d1\u878d\u4fe1\u8d37\u98ce\u9669\u8bc4\u4f30-\u5173\u8054\u4eba\u7269, \u5173\u8054\u516c\u53f8, \u6295\u8d44\u5173\u7cfb, \u503a\u52a1\u7ea0\u7eb7) \u77e5\u8bc6\u56fe\u8c31\u5206\u7c7b \u00b6 \u77e5\u8bc6\u56fe\u8c31\u4e3b\u8981\u6709\u4e24\u79cd\u5927\u7684\u7c7b\u578b: \u901a\u7528\u77e5\u8bc6\u56fe\u8c31(GKG, General-purpose Knowledge Graph) \u9886\u57df\u77e5\u8bc6\u56fe\u8c31(DKG, Domain-specific Knowledge Graph) \u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u77e5\u8bc6\u5206\u7c7b: 1: \u4e8b\u5b9e\u77e5\u8bc6(Factual Knowledge), (\u67cf\u62c9\u56fe, \u51fa\u751f\u5730, \u96c5\u5178) 2: \u6982\u5ff5\u77e5\u8bc6(Taxonomy Knowledge), (\u67cf\u62c9\u56fe isA \u54f2\u5b66\u5bb6) 3: \u8bcd\u6c47\u77e5\u8bc6(Lexical Knowledge), (Plato, \u4e2d\u6587\u540d, \u67cf\u62c9\u56fe) 4: \u5e38\u8bc6\u77e5\u8bc6(Commonsense Knowledge), (\u90a3\u53ea\u732a\u98de\u7684\u597d\u5feb\u554a; 2022\u5e7412\u670812\u65e5\u4e0a\u6d77\u5e02\u6c14\u6e29-65\u6444\u6c0f\u5ea6) DKG\u548cGKG\u4e4b\u95f4\u6709\u660e\u663e\u7684\u533a\u522b: 1: \u77e5\u8bc6\u8868\u793a 2: \u77e5\u8bc6\u83b7\u53d6 3: \u77e5\u8bc6\u5e94\u7528 DKG\u4e2aGKG\u4e4b\u95f4\u53c8\u6709\u7d27\u5bc6\u7684\u5173\u7cfb: 1: \u9886\u57df\u77e5\u8bc6\u662f\u7528\u8fc7\u9690\u55bb\u6216\u8005\u7c7b\u6bd4\u4ece\u901a\u7528\u77e5\u8bc6\u53d1\u5c55\u800c\u6765\u7684 2: DKG\u548cGKG\u76f8\u4e92\u652f\u6491 \u5de5\u4e1a\u754c\u548c\u5b66\u672f\u754c\u7684\u82e5\u5e72\u91cd\u8981\u77e5\u8bc6\u56fe\u8c31: Cyc WordNet ConceptNet Freebase GeoNames DBpedia YAGO OpenIE BabelNet WikiData Google KG Probase \u641c\u72d7\u641c\u7acb\u65b9 \u767e\u5ea6\u77e5\u5fc3 CN-DBpedia \u5c0f\u8282\u603b\u7ed3 \u00b6 \u672c\u5c0f\u8282\u6211\u4eec\u5b66\u4e60\u4e86\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u91cd\u8981\u6982\u5ff5, \u56de\u987e\u4e86\u4ece20\u4e16\u754c70\u5e74\u4ee3\u5f00\u59cb\u7684\u7b26\u53f7\u4e3b\u4e49\u65f6\u4ee3\u4e00\u76f4\u5230\u8fd1\u51e0\u5e74\u7684\u5927\u6570\u636e\u77e5\u8bc6\u5de5\u7a0b\u65f6\u4ee3\u7684\u77e5\u8bc6\u56fe\u8c31\u53d1\u5c55\u5386\u53f2, \u91cd\u70b9\u8bb2\u89e3\u4e86\u77e5\u8bc6\u56fe\u8c31\u5728\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u5e94\u7528\u4ef7\u503c, \u6700\u540e\u4ecb\u7ecd\u4e86\u77e5\u8bc6\u56fe\u8c31\u7684\u5206\u7c7b\u548c\u4e00\u4e9b\u91cd\u8981\u7684\u77e5\u8bc6\u56fe\u8c31\u4ea7\u54c1.","title":"1.2 \u77e5\u8bc6\u56fe\u8c31\u6982\u8ff0"},{"location":"1_2.html#_1","text":"","title":"\u77e5\u8bc6\u56fe\u8c31\u6982\u8ff0"},{"location":"1_2.html#_2","text":"\u638c\u63e1\u77e5\u8bc6\u56fe\u8c31\u7684\u57fa\u672c\u6982\u5ff5. \u4e86\u89e3\u77e5\u8bc6\u56fe\u8c31\u7684\u53d1\u5c55\u5386\u53f2. \u7406\u89e3\u77e5\u8bc6\u56fe\u8c31\u7684\u5e94\u7528\u4ef7\u503c. \u638c\u63e1\u77e5\u8bc6\u56fe\u8c31\u7684\u5206\u7c7b.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"1_2.html#_3","text":"\u77e5\u8bc6\u56fe\u8c31\u6700\u521d\u662f\u7279\u6307Google\u516c\u53f8\u4e3a\u4e86\u652f\u6491\u5176\u8bed\u4e49\u641c\u7d22\u800c\u5efa\u7acb\u7684\u77e5\u8bc6\u5e93. \u4f5c\u4e3a\u4e00\u79cd\u77e5\u8bc6\u8868\u793a\u5f62\u5f0f, \u77e5\u8bc6\u56fe\u8c31\u662f\u4e00\u79cd\u5927\u89c4\u6a21\u8bed\u4e49\u7f51\u7edc, \u5305\u542b\u5b9e\u4f53(Entity), \u6982\u5ff5(Concept)\u53ca\u5176\u4e4b\u95f4\u7684\u5404\u79cd\u5173\u7cfb(Relation). \u8bed\u4e49\u7f51\u7edc: \u662f\u4e00\u79cd\u4ee5\u56fe\u5f62\u5316(Graphic)\u5f62\u5f0f\u901a\u8fc7\u70b9\u548c\u8fb9\u8868\u8fbe\u77e5\u8bc6\u7684\u65b9\u5f0f, \u5176\u57fa\u672c\u7ec4\u6210\u5143\u7d20\u662f\u70b9\u548c\u8fb9. \u8bed\u4e49\u7f51\u7edc\u4e2d\u7684\u70b9\u53ef\u4ee5\u62bd\u8c61\u7684\u8868\u8fbe\u5b9e\u4f53, \u6982\u5ff5, \u503c. \u4f8b\u5982\u4e0b\u56fe: \u70b9\u53ef\u4ee5\u662f\u54fa\u4e73\u52a8\u7269, \u718a, \u810a\u690e, \u9c7c, \u6c34\u7b49; \u7ebf\u53ef\u4ee5\u8868\u660e\u662f, \u6709, \u4f4f\u5728\u7b49\u5173\u7cfb. \u5b9e\u4f53: \u5b9e\u4f53\u6709\u65f6\u4e5f\u4f1a\u88ab\u79f0\u4e3a\u5bf9\u8c61(Object), \u6216\u5b9e\u4f8b(Instance). \u5b9e\u4f53\u662f\u5c5e\u6027\u8d56\u4ee5\u5b58\u5728\u7684\u57fa\u7840, \u662f\u72ec\u7acb\u7684, \u81ea\u5728\u7684, \u4e0d\u4f9d\u9644\u5176\u4ed6\u4e1c\u897f\u7684. \u6982\u5ff5: \u6982\u5ff5\u53c8\u88ab\u79f0\u4e3a\u7c7b\u522b(Type), \u6216\u7c7b(Category, Class). \u6bd4\u5982\"\u54f2\u5b66\u5bb6\", \u8fd9\u4e2a\u6982\u5ff5\u4e0d\u662f\u6307\u67d0\u4e00\u4e2a\u7279\u5b9a\u7684\u4eba, \u6bd4\u5982\"\u67cf\u62c9\u56fe\", \u800c\u662f\u6307\u4e00\u7c7b\u4eba. \u503c: \u6bcf\u4e2a\u5b9e\u4f53\u90fd\u6709\u4e00\u5b9a\u7684\u5c5e\u6027\u503c. \u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u8fb9\u53ef\u4ee5\u5206\u4e3a\u4e24\u7c7b: \u5c5e\u6027(Property) \u5173\u7cfb(Relation) \u5c5e\u6027: \u5c5e\u6027(Property)\u63cf\u8ff0\u5b9e\u4f53\u67d0\u65b9\u9762\u7684\u7279\u6027, \u6bd4\u5982\u4eba\u7684\u51fa\u751f\u65e5\u671f, \u8eab\u9ad8, \u5e74\u9f84, \u4f53\u91cd\u7b49. \u5173\u7cfb: \u5173\u7cfb(Relation)\u53ef\u4ee5\u8ba4\u4e3a\u662f\u4e00\u7c7b\u7279\u6b8a\u7684\u5c5e\u6027, \u5f53\u5b9e\u4f53\u7684\u67d0\u4e2a\u5c5e\u6027\u503c\u4e5f\u662f\u4e00\u4e2a\u5b9e\u4f53\u65f6, \u8fd9\u4e2a\u5c5e\u6027\u5b9e\u8d28\u4e0a\u5c31\u662f\u5173\u7cfb. \u77e5\u8bc6\u56fe\u8c31\u4e0e\u4f20\u7edf\u8bed\u4e49\u7f51\u7edc\u7684\u533a\u522b: 1: \u89c4\u6a21\u5de8\u5927 2: \u8bed\u4e49\u4e30\u5bcc 3: \u8d28\u91cf\u7cbe\u826f 4: \u7ed3\u6784\u53cb\u597d \u77e5\u8bc6\u56fe\u8c31\u7684\u6311\u6218: 1: \u9ad8\u8d28\u91cf\u6a21\u5f0f\u7684\u7f3a\u5931 2: \u5c01\u95ed\u4e16\u754c\u5047\u8bbe\u4e0d\u518d\u6210\u7acb 3: \u5927\u89c4\u6a21\u81ea\u52a8\u5316\u77e5\u8bc6\u83b7\u53d6\u6210\u4e3a\u524d\u63d0 \u77e5\u8bc6\u56fe\u8c31\u4e0e\u672c\u4f53(Ontology)\u7684\u533a\u522b: \u8ba1\u7b97\u673a\u9886\u57df\u7684\u672c\u4f53\u4fa7\u91cd\u4e8e\u8868\u8fbe\u8ba4\u77e5\u7684\u6982\u5ff5\u6846\u67b6, \u8868\u8fbe\u6982\u5ff5\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u7cfb, \u5f80\u5f80\u4e5f\u4f34\u968f\u7740\u523b\u753b\u6982\u5ff5\u7684\u516c\u7406\u7cfb\u7edf. \u672c\u4f53\u523b\u753b\u4e86\u4eba\u7c7b\u8ba4\u77e5\u4e00\u4e2a\u9886\u57df\u7684\u57fa\u672c\u6846\u67b6, \u4e3a\u673a\u5668\u5b9a\u4e49\u672c\u4f53, \u5c31\u597d\u6bd4\u5c06\u6211\u4eec\u7684\u4e16\u754c\u89c2\u4f20\u9012\u7ed9\u673a\u5668. \u8fd9\u4e2a\u8fc7\u7a0b\u9700\u8981\u4eba\u7c7b\u4e13\u5bb6\u5b8c\u6210, \u5728\u5efa\u8bbe\u77e5\u8bc6\u56fe\u8c31\u7684\u521d\u671f, \u6a21\u5f0f(Schema)\u5b9a\u4e49\u672c\u8d28\u4e0a\u5c31\u662f\u5728\u5b8c\u6210\u672c\u4f53\u5b9a\u4e49\u7684\u4efb\u52a1. \u77e5\u8bc6\u56fe\u8c31\u7684\u5e7f\u4e49\u6982\u5ff5: 1: \u77e5\u8bc6\u56fe\u8c31 2: \u77e5\u8bc6\u8868\u793a 3: \u77e5\u8bc6\u5de5\u7a0b 4: \u4eba\u5de5\u667a\u80fd \u4e0a\u97624\u4e2a\u5e7f\u4e49\u6982\u5ff5, \u662f\u4f9d\u6b21\u5305\u542b\u4e8e\u7684\u5173\u7cfb.","title":"\u57fa\u672c\u6982\u5ff5"},{"location":"1_2.html#_4","text":"\u77e5\u8bc6\u56fe\u8c31\u8d77\u6e90\u4e8e20\u4e16\u7eaa70\u5e74\u4ee3, \u4e00\u76f4\u52302012\u5e74Google\u516c\u53f8\u63d0\u51fa\u9762\u5411\u4e92\u8054\u7f51\u641c\u7d22\u7684\u5927\u89c4\u6a21\u77e5\u8bc6\u56fe\u8c31, \u6b63\u5f0f\u5ba3\u544a\u77e5\u8bc6\u56fe\u8c31\u7684\u8bde\u751f. \u603b\u4f53\u53d1\u5c55\u7ecf\u5386\u4e862\u4e2a\u65f6\u4ee3: \u65e9\u671f\u77e5\u8bc6\u5de5\u7a0b\u65f6\u4ee3 \u5927\u6570\u636e\u77e5\u8bc6\u5de5\u7a0b\u65f6\u4ee3 \u65e9\u671f\u77e5\u8bc6\u5de5\u7a0b\u65f6\u4ee3: \u77e5\u8bc6\u5de5\u7a0b\u6e90\u4e8e\u7b26\u53f7\u4e3b\u4e49, \u7b26\u53f7\u4e3b\u4e49\u8ba4\u4e3a\u77e5\u8bc6\u662f\u667a\u80fd\u7684\u57fa\u7840, \u4eba\u5de5\u667a\u80fd\u7684\u6838\u5fc3\u95ee\u9898\u662f\u77e5\u8bc6\u8868\u793a, \u63a8\u7406\u548c\u5e94\u7528. \u8fd9\u4e00\u89c2\u70b9\u548c\u5f53\u4eca\u673a\u5668\u5b66\u4e60\u6210\u4e3a\u4eba\u5de5\u667a\u80fd\u7684\u70ed\u70b9\u5f62\u6210\u4e86\u9c9c\u660e\u5bf9\u7167. \u7b26\u53f7\u4e3b\u4e49\u4e3a\u4ee3\u8868\u7684\u65e9\u671f\u77e5\u8bc6\u5de5\u7a0b\u66fe\u7ecf\u89e3\u51b3\u4e86\u4e00\u7cfb\u5217\u5b9e\u9645\u95ee\u9898, \u6bd4\u5982\u8ba1\u7b97\u673a\u7cfb\u7edf\u7684\u81ea\u52a8\u914d\u7f6e, \u86cb\u767d\u8d28\u7ed3\u6784\u7684\u53d1\u73b0, \u673a\u5668\u6570\u5b66\u5b9a\u7406\u7684\u8bc1\u660e\u7b49. \u5c40\u9650\u6027: \u4f20\u7edf\u77e5\u8bc6\u5de5\u7a0b\u6240\u80fd\u6210\u529f\u89e3\u51b3\u7684\u95ee\u9898\u666e\u904d\u5177\u6709\u89c4\u5219\u660e\u786e, \u5e94\u7528\u5c01\u95ed\u7684\u7279\u70b9! \u65e9\u671f\u77e5\u8bc6\u5de5\u7a0b\u7684\u5c40\u9650\u6027: 1: \u9690\u6027\u77e5\u8bc6\u4e0e\u8fc7\u7a0b\u77e5\u8bc6\u96be\u4ee5\u8868\u8fbe 2: \u77e5\u8bc6\u8868\u8fbe\u7684\u4e3b\u89c2\u6027\u4e0e\u4e0d\u4e00\u81f4\u6027 3: \u77e5\u8bc6\u96be\u6613\u5b8c\u5907 4: \u77e5\u8bc6\u66f4\u65b0\u56f0\u96be \u5927\u6570\u636e\u77e5\u8bc6\u5de5\u7a0b\u65f6\u4ee3: \u968f\u774021\u4e16\u7eaa\u4e92\u8054\u7f51\u7684\u5174\u8d77, \u4f34\u968f\u7740\u5927\u6570\u636e\u65f6\u4ee3\u7684\u5230\u6765, \u5171\u540c\u50ac\u751f\u4e86\u5927\u6570\u636e\u77e5\u8bc6\u5de5\u7a0b\u65f6\u4ee3. \u4e92\u8054\u7f51\u573a\u666f\u4e0b\u7684\u5e94\u7528\u6709\u5982\u4e0b\u7279\u70b9: 1: \u5927\u89c4\u6a21\u5f00\u653e\u6027\u5e94\u7528 (\u5403\u9e21, \u78ca\u5931\u5355\u5200, \u5ddd\u5b9d) 2: \u7cbe\u5ea6\u8981\u6c42\u76f8\u5bf9\u4e0d\u9ad8 3: \u77e5\u8bc6\u63a8\u7406\u7b80\u5355(\u5218\u5fb7\u534e, \u59da\u660e\u8001\u5a46\u7684\u7403\u961f\u6559\u7ec3\u5bb6\u7684\u5b69\u5b50\u6709\u591a\u9ad8) \u5927\u6570\u636e\u65f6\u4ee3\u5bf9\u77e5\u8bc6\u56fe\u8c31\u53d1\u5c55\u7684\u4fc3\u8fdb\u4f5c\u7528: 1: \u6570\u636e, \u7b97\u529b, \u6a21\u578b\u7684\u98de\u901f\u53d1\u5c55\u662f\u7684\u5927\u89c4\u6a21\u81ea\u52a8\u5316\u77e5\u8bc6\u83b7\u53d6\u6210\u4e3a\u53ef\u80fd 2: \u4f17\u5305\u6280\u672f\u4f7f\u5f97\u77e5\u8bc6\u7684\u89c4\u6a21\u5316\u9a8c\u8bc1\u6210\u4e86\u53ef\u80fd 3: \u9ad8\u8d28\u91cf\u7684\u7528\u6237\u751f\u6210\u5185\u5bb9(UGC)\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u77e5\u8bc6\u5e93\u7684\u6765\u6e90","title":"\u53d1\u5c55\u5386\u53f2"},{"location":"1_2.html#_5","text":"\u4ece2015\u5e74\u8d77NLP\u8fdb\u5165\u4e86\u6df1\u5ea6\u5b66\u4e60\u65f6\u4ee3, 2018\u5e74\u8d77NLP\u8fdb\u5165\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u65f6\u4ee3, \u4f46\u662fNLP\u7684\u7ec8\u6781\u6311\u6218\u59cb\u7ec8\u90fd\u662f\"\u56fe\u7075\u6d4b\u8bd5\". \u7ad9\u57282023\u5e74, \u4ece\u5b66\u672f\u754c\u7684\u524d\u6cbf\u5230\u5de5\u4e1a\u754c\u7684\u5b9e\u8df5, \u666e\u904d\u8fbe\u6210\u4e00\u4e2a\u5171\u8bc6: \u77e5\u8bc6\u56fe\u8c31\u662f\u8ba4\u77e5\u667a\u80fd\u7684\u57fa\u77f3! 2013\u5e74\u91d1\u7403\u5956\u5f97\u4e3bC\u7f57. \u5c0f\u5170\u8bf4\u5979\u5468\u672b\u8bfb\u4e86\u6d77\u660e\u5a01\u7684\u4e66. \u8fd9\u5468\u672b\u6211\u8981\u53bb\u7f57\u5170\u52a0\u6d1b\u65af\u770b\u6bd4\u8d5b. \u968f\u7740\u63a8\u7279\u88ab\u6536\u8d2d, \u94a2\u94c1\u4fa0\u7684\u5546\u4e1a\u5e1d\u56fd\u8fdb\u4e00\u6b65\u5e9e\u5927\u4e86. \u4e3a\u4e86\u5b9e\u73b0\u673a\u5668\u5bf9\u81ea\u7136\u8bed\u8a00\u7684\u7406\u89e3, \u9700\u8981\u7684\u80cc\u666f\u77e5\u8bc6\u6709\u7740\u82db\u523b\u7684\u6761\u4ef6: 1: \u89c4\u6a21\u5fc5\u987b\u8db3\u591f\u5de8\u5927\u624d\u80fd\u7406\u89e3\u4e0d\u540c\u7684\u5b9e\u4f53\u4e0e\u6982\u5ff5 2: \u8bed\u4e49\u5173\u7cfb\u5fc5\u987b\u8db3\u591f\u4e30\u5bcc\u624d\u80fd\u7406\u89e3\u4e0d\u540c\u7684\u5173\u7cfb 3: \u7ed3\u6784\u5fc5\u987b\u8db3\u591f\u53cb\u597d\u624d\u80fd\u4e3a\u673a\u5668\u6240\u5904\u7406 4: \u8d28\u91cf\u5fc5\u987b\u8db3\u591f\u7cbe\u826f\u624d\u80fd\u8ba9\u673a\u5668\u5bf9\u73b0\u5b9e\u4e16\u754c\u4ea7\u751f\u6b63\u786e\u7684\u7406\u89e3 \u6ce8\u610f: \u5f53\u6211\u4eec\u904d\u5386\u6240\u6709\u4e3b\u6d41\u7684\u77e5\u8bc6\u8868\u793a\u6a21\u5f0f\u540e, \u80fd\u6ee1\u8db3\u4e0a\u8ff04\u4e2a\u6807\u51c6\u548c\u6761\u4ef6\u7684, \u53ea\u6709\u77e5\u8bc6\u56fe\u8c31! \u77e5\u8bc6\u56fe\u8c31\u8d4b\u80fd\u53ef\u89e3\u91caAI: \u73b0\u5728\u7684\u641c\u7d22\u5e73\u53f0\u4e0a, \"How\", \"Why\"\u4e4b\u7c7b\u7684\u641c\u7d22\u95ee\u9898\u8d8a\u6765\u8d8a\u591a, \u7528\u6237\u4e0d\u4ec5\u4ec5\u6ee1\u8db3\u4e8e\u5f97\u5230\u4e8b\u5b9e\u7c7b\u7684\u641c\u7d22\u7ed3\u679c, \u66f4\u5173\u5fc3\u63a8\u7406, \u89e3\u91ca\u7684\u7ed3\u679c. \u6bd4\u5982\"\u600e\u4e48\u505a\u5bab\u4fdd\u867e\u7403\", \"\u600e\u4e48\u53bb\u9890\u548c\u56ed\". \u53ef\u89e3\u91ca\u80fd\u529b\u7684\u6b20\u7f3a\u662fAI\u57284\u5927\u5782\u76f4\u9886\u57df\u5e94\u7528\u7684\u74f6\u9888\u6240\u5728!!! \u77e5\u8bc6\u56fe\u8c31\u53ef\u4ee5\u8fc5\u901f\u589e\u5f3a\u673a\u5668\u5b66\u4e60\u7684\u80fd\u529b: \u77e5\u8bc6\u56fe\u8c31\u76f8\u5f53\u4e8e\u63d0\u4f9b\u7ed9\u673a\u5668\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u5148\u9a8c\u77e5\u8bc6\u5e93, \u8fd9\u79cd\u77e5\u8bc6\u589e\u5f3a\u4e0b\u7684\u6a21\u578b\u5b66\u4e60, \u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u6a21\u578b\u5bf9\u4e8e\u5927\u6837\u672c\u7684\u4f9d\u8d56. \u77e5\u8bc6\u56fe\u8c31\u63d0\u4f9b\u4e86\"\u77e5\u8bc6\u5f15\u5bfc\"\u8fd9\u4e00\u91cd\u8981\u65b9\u5f0f, \u5728\u91c7\u7528\u6570\u636e\u9a71\u52a8\u7684\u4f20\u7edf\u6a21\u5f0f\u4e2d, \u4e3a\u4e86\u7edf\u8ba1\u6982\u7387\u5206\u5e03, \u6316\u6398\u6570\u636e\u89c4\u5f8b, \u6a21\u578b\u9700\u8981\u5927\u91cf\u7684\u6837\u672c. \u4f46\u5373\u4f7f\u6837\u672c\u6570\u636e\u91cf\u518d\u5927, \u5355\u7eaf\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u4ecd\u7136\u9762\u4e34\u6548\u679c\u7684\"\u5929\u82b1\u677f\". \u8981\u60f3\u7a81\u7834\u8fd9\u4e2a\u5929\u82b1\u677f, \u5c31\u9700\u8981\u77e5\u8bc6\u5f15\u5bfc. \u4f8b\u5982: \u5728\u53f8\u6cd5\u8bc9\u8bbc\u7684\u5211\u7f5a\u9884\u6d4bAI\u95ee\u9898\u4e2d, \u540c\u6837\u7684\u4e24\u4e2a\u4f24\u4eba\u6848\u60c5\u9648\u8ff0, \u4e00\u4e2a\u662f\u5acc\u7591\u72af\u9884\u5148\u8eab\u4e0a\u5e26\u4e86\u5315\u9996, \u53e6\u4e00\u4e2a\u5acc\u7591\u72af\u5728\u6848\u53d1\u73b0\u573a\u968f\u624b\u6361\u4e86\u4e00\u5757\u7816\u5934, \u5373\u4f7f\u5176\u4ed6\u6240\u6709\u7684\u9648\u8ff0\u8fc7\u7a0b\u5b8c\u5168\u4e00\u6837, \u6700\u7ec8\u7684\u5211\u7f5a\u9884\u6d4b\u7ed3\u679c\u4e5f\u5e94\u8be5\u5dee\u522b\u5f88\u5927. \u56e0\u4e3a\u524d\u8005\u66f4\u503e\u5411\u4e8e\u84c4\u610f\u8c0b\u6740, \u540e\u8005\u66f4\u503e\u5411\u4e8e\u4e34\u65f6\u8d77\u610f. \u77e5\u8bc6\u56fe\u8c31: \u53ef\u4ee5\u5229\u7528\u5148\u9a8c\u7684\u53f8\u6cd5\u77e5\u8bc6\u6765\u8f85\u52a9\u5224\u5b9a. \u6570\u636e\u9a71\u52a8: \u8bcd\u9891, \u8bed\u53e5\u5d4c\u5165\u5411\u91cf\u7b49\u6765\u8f85\u52a9\u5224\u5b9a. \u4e92\u8054\u7f51\u65f6\u4ee3\u77e5\u8bc6\u56fe\u8c31\u7684\u5de8\u5927\u5e94\u7528\u4ef7\u503c: 1: \u6570\u636e\u5206\u6790(\u738b\u5b9d\u5f3a\u79bb\u5a5a, \u738b\u5b9d\u5b9d\u79bb\u5a5a, \u50bb\u6839\u79bb\u5a5a) 2: \u667a\u6167\u641c\u7d22(iPad \u5145\u7535\u5668; toys kids, kids toys; \u591a\u6a21\u6001\u641c\u7d22; \u660e\u661f\u53d1\u5c0f\u533a\u7167\u7247\u534f\u540c\u641c\u7d22) 3: \u667a\u80fd\u63a8\u8350(\u6c99\u6ee9\u88e4-\u6cf3\u8863, \u9632\u6652\u971c; \u51b7\u542f\u52a8; \u5fae\u535a-\u4e5d\u5be8\u6c9f, \u5f20\u5bb6\u754c, \u9ec4\u5c71 VS \u6dd8\u5b9d-\u80cc\u5305, \u767b\u5c71\u978b, \u76f8\u673a) 4: \u81ea\u7136\u4eba\u673a\u4ea4\u4e92(\u5bf9\u8bdd\u5f0f\u4ea4\u4e92) 5: \u51b3\u7b56\u652f\u6301(\u738b\u5b9d\u5f3a\u79bb\u5a5a-\u5f20\u8d77\u6dee\u5f8b\u5e08; \u91d1\u878d\u4fe1\u8d37\u98ce\u9669\u8bc4\u4f30-\u5173\u8054\u4eba\u7269, \u5173\u8054\u516c\u53f8, \u6295\u8d44\u5173\u7cfb, \u503a\u52a1\u7ea0\u7eb7)","title":"\u5e94\u7528\u4ef7\u503c"},{"location":"1_2.html#_6","text":"\u77e5\u8bc6\u56fe\u8c31\u4e3b\u8981\u6709\u4e24\u79cd\u5927\u7684\u7c7b\u578b: \u901a\u7528\u77e5\u8bc6\u56fe\u8c31(GKG, General-purpose Knowledge Graph) \u9886\u57df\u77e5\u8bc6\u56fe\u8c31(DKG, Domain-specific Knowledge Graph) \u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u77e5\u8bc6\u5206\u7c7b: 1: \u4e8b\u5b9e\u77e5\u8bc6(Factual Knowledge), (\u67cf\u62c9\u56fe, \u51fa\u751f\u5730, \u96c5\u5178) 2: \u6982\u5ff5\u77e5\u8bc6(Taxonomy Knowledge), (\u67cf\u62c9\u56fe isA \u54f2\u5b66\u5bb6) 3: \u8bcd\u6c47\u77e5\u8bc6(Lexical Knowledge), (Plato, \u4e2d\u6587\u540d, \u67cf\u62c9\u56fe) 4: \u5e38\u8bc6\u77e5\u8bc6(Commonsense Knowledge), (\u90a3\u53ea\u732a\u98de\u7684\u597d\u5feb\u554a; 2022\u5e7412\u670812\u65e5\u4e0a\u6d77\u5e02\u6c14\u6e29-65\u6444\u6c0f\u5ea6) DKG\u548cGKG\u4e4b\u95f4\u6709\u660e\u663e\u7684\u533a\u522b: 1: \u77e5\u8bc6\u8868\u793a 2: \u77e5\u8bc6\u83b7\u53d6 3: \u77e5\u8bc6\u5e94\u7528 DKG\u4e2aGKG\u4e4b\u95f4\u53c8\u6709\u7d27\u5bc6\u7684\u5173\u7cfb: 1: \u9886\u57df\u77e5\u8bc6\u662f\u7528\u8fc7\u9690\u55bb\u6216\u8005\u7c7b\u6bd4\u4ece\u901a\u7528\u77e5\u8bc6\u53d1\u5c55\u800c\u6765\u7684 2: DKG\u548cGKG\u76f8\u4e92\u652f\u6491 \u5de5\u4e1a\u754c\u548c\u5b66\u672f\u754c\u7684\u82e5\u5e72\u91cd\u8981\u77e5\u8bc6\u56fe\u8c31: Cyc WordNet ConceptNet Freebase GeoNames DBpedia YAGO OpenIE BabelNet WikiData Google KG Probase \u641c\u72d7\u641c\u7acb\u65b9 \u767e\u5ea6\u77e5\u5fc3 CN-DBpedia","title":"\u77e5\u8bc6\u56fe\u8c31\u5206\u7c7b"},{"location":"1_2.html#_7","text":"\u672c\u5c0f\u8282\u6211\u4eec\u5b66\u4e60\u4e86\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u91cd\u8981\u6982\u5ff5, \u56de\u987e\u4e86\u4ece20\u4e16\u754c70\u5e74\u4ee3\u5f00\u59cb\u7684\u7b26\u53f7\u4e3b\u4e49\u65f6\u4ee3\u4e00\u76f4\u5230\u8fd1\u51e0\u5e74\u7684\u5927\u6570\u636e\u77e5\u8bc6\u5de5\u7a0b\u65f6\u4ee3\u7684\u77e5\u8bc6\u56fe\u8c31\u53d1\u5c55\u5386\u53f2, \u91cd\u70b9\u8bb2\u89e3\u4e86\u77e5\u8bc6\u56fe\u8c31\u5728\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u5e94\u7528\u4ef7\u503c, \u6700\u540e\u4ecb\u7ecd\u4e86\u77e5\u8bc6\u56fe\u8c31\u7684\u5206\u7c7b\u548c\u4e00\u4e9b\u91cd\u8981\u7684\u77e5\u8bc6\u56fe\u8c31\u4ea7\u54c1.","title":"\u5c0f\u8282\u603b\u7ed3"},{"location":"2_1.html","text":"\u77e5\u8bc6\u67e5\u8be2\u65b9\u6cd5\u4ecb\u7ecd \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u77e5\u8bc6\u67e5\u8be2\u7684\u4e3b\u6d41\u8bed\u8a00. \u7406\u89e3\u77e5\u8bc6\u67e5\u8be2\u7684\u4e3b\u6d41\u65b9\u6cd5\u548c\u539f\u7406. \u77e5\u8bc6\u67e5\u8be2\u4e3b\u6d41\u8bed\u8a00 \u00b6 \u67e5\u8be2\u4e0e\u68c0\u7d22\u662f\u77e5\u8bc6\u56fe\u8c31\u7684\u91cd\u8981\u4f7f\u7528\u65b9\u5f0f, \u4e5f\u662f\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u7ba1\u7406\u7cfb\u7edf\u7684\u6838\u5fc3\u80fd\u529b\u4e4b\u4e00. SQL \u00b6 SQL: \u8ba1\u7b97\u673a\u5de5\u7a0b\u5e08\u6700\u719f\u6089\u7684\u67e5\u8be2\u8bed\u8a00\u83ab\u8fc7\u4e8eSQL. \u5728SQL\u5e94\u7528\u4e2d, \u6570\u636e\u4ee5\u8868\u7684\u5f62\u5f0f\u5b58\u5728, \u6709\u6bd4\u8f83\u5f3a\u7684schema\u5b9a\u4e49, \u8868\u548c\u8868\u4e4b\u95f4\u7684\u6570\u636e\u5173\u8054\u4ee5join\u7684\u65b9\u5f0f\u5b9e\u73b0. \u4f46\u662fSQL\u6709\u4e00\u4e2a\u91cd\u5927\u7684\u7f3a\u9677: \u5c5e\u6027\u503c\u5e76\u4e0d\u603b\u662f\u5355\u4e00\u503c. \u9488\u5bf9\u6bcf\u4e00\u4e2a\u591a\u503c\u5c5e\u6027\u9700\u8981\u8fdb\u884c\u989d\u5916\u7684\u62c6\u8868\u64cd\u4f5c, \u8fd9\u5bf9\u4e8e\u8868\u6570\u636e\u7684\u7ba1\u7406\u5e26\u6765\u5de8\u5927\u6311\u6218. \u5c24\u5176\u662f\u9700\u8981\u9ad8\u901f\u9ad8\u9891\u7684\u8fdb\u884c\u591a\u8868\u8fde\u63a5\u64cd\u4f5c\u7684\u573a\u666f, \u5bf9\u4e8e\u6570\u636e\u5e93\u6027\u80fd\u4e5f\u662f\u6781\u5927\u7684\u6311\u6218! \u5bf9\u4e8e\u77e5\u8bc6\u56fe\u8c31\u4e2d\u6700\u4e3b\u6d41\u7684\u4e09\u5143\u7ec4\u5f62\u5f0f, \u591a\u8df3\u5173\u8054\u67e5\u8be2\u7684\u5f62\u5f0f, \u663e\u7136SQL\u4e0d\u5177\u5907\u4f18\u52bf. SPARQL \u00b6 SPARQL: \u56fd\u9645\u6807\u51c6\u5316\u7ec4\u7ec7W3C\u63d0\u51fa\u4e86\u9488\u5bf9\u4e8eRDF\u77e5\u8bc6\u56fe\u8c31\u7684\u6807\u51c6\u5316\u67e5\u8be2\u8bed\u8a00SPARQL. \u4f5c\u4e3a\u4e00\u79cd\u56fe\u6570\u636e, SPARQL\u67e5\u8be2\u7684\u6267\u884c\u53ef\u4ee5\u901a\u8fc7\u56fe\u5339\u914d\u7684\u65b9\u5f0f\u5b9e\u73b0. SPARQL\u662f\u4e00\u79cd\u9488\u5bf9RDF\u6570\u636e\u7684\u67e5\u8be2\u8bed\u8a00, 2008\u5e74\u6b63\u5f0f\u6210\u4e3aW3C\u63a8\u8350\u7684\u9488\u5bf9RDF\u6570\u636e\u7684\u6807\u51c6\u67e5\u8be2\u8bed\u8a00. \u548cSQL\u4e00\u6837, SPARQL\u4e5f\u662f\u4e00\u79cd\u58f0\u660e\u5f0f\u7684\u7ed3\u6784\u5316\u67e5\u8be2\u8bed\u8a00, \u5373\u7528\u6237\u53ea\u9700\u8981\u6309\u7167SPARQL\u5b9a\u4e49\u7684\u8bed\u6cd5\u89c4\u5219\u63cf\u8ff0\u5176\u60f3\u67e5\u8be2\u7684\u4fe1\u606f\u5373\u53ef, \u4e0d\u9700\u8981\u660e\u786e\u6307\u5b9a\u8ba1\u7b97\u673a\u5b9e\u73b0\u67e5\u8be2\u7684\u6b65\u9aa4. SPARQL\u8bed\u8a00\u501f\u9274\u4e86SQL\u7684\u90e8\u5206\u8bed\u6cd5, \u66f4\u52a0\u5173\u6ce8\u76ee\u6807\u6570\u636e\u56fe\u7684\u5339\u914d, \u603b\u4f53\u6765\u8bf4\u8bed\u8a00\u89c4\u5219\u4e0d\u7b97\u590d\u6742, \u6bd4\u8f83\u5bb9\u6613\u5b66: # \u6bd4\u5982\u5229\u7528SPARQL\u67e5\u8be2\u4ece\u4e09\u5143\u7ec4<org:book, dc:title, \"Knowledge graph\">\u4e2d\u67e5\u8be2book\u8fd9\u672c\u4e66\u7684\u540d\u5b57 Q: \u67e5\u8be2\u56fe\u4e66\u540d\u79f0 SELECT ?title WHERE { org:book dc:title ?title .} \u8003\u8651\u5230\u9879\u76ee\u540e\u7eed\u4f7f\u7528\u7684\u56fe\u6570\u636e\u5e93neo4j\u5b9e\u9645\u7528\u7684\u662fCypher\u8bed\u8a00, \u5728\u6b64\u4ec5\u4f5c\u4ecb\u7ecd, \u540e\u9762\u8bfe\u7a0b\u4e2d\u5c06\u8be6\u7ec6\u4e3a\u540c\u5b66\u4eec\u8bb2\u6388Cypher\u67e5\u8be2\u8bed\u8a00. Gremlin \u00b6 Gremlin: \u662fApache\u65d7\u4e0b\u7684Java\u9879\u76ee, \u4e5f\u662f\u4e00\u6b3e\u8457\u540d\u7684\u56fe\u6570\u636e\u5e93\u67e5\u8be2\u8bed\u8a00. \u6570\u636e\u4ee5\u5c5e\u6027\u56fe\u7684\u5f62\u5f0f\u5b58\u5728, \u53ef\u4ee5\u8ba4\u4e3a\u662fSQL\u548cSPARQL\u7684\u6df7\u5408\u4f53. \u5b9e\u4f53\u7684\u5c5e\u6027\u4ecd\u7136\u5728\u8868\u4e2d, \u4f46\u662f\u8fde\u63a5\u5173\u7cfb\u662f\u76f4\u63a5\u4ee5\u6307\u9488\u7684\u5f62\u5f0f\u5b58\u5728\u7684. Gremlin\u7684\u67e5\u8be2\u672c\u8d28\u662f\u56fe\u904d\u5386, \u64c5\u957f\u89e3\u51b3\u6c42\u56fe\u7684\u76f4\u5f84, \u70b9\u5230\u70b9\u4e4b\u95f4\u7684\u8def\u5f84\u7b49, \u6bd4\u5982\u5218\u5fb7\u534e\u8fde\u63a5\u5965\u5df4\u9a6c\u9700\u8981\u51e0\u5ea6\u5173\u7cfb. \u793a\u4f8b: \u67e5\u8be2gremlin\u7684\u670b\u53cb\u7684\u670b\u53cb\u7684\u59d3\u540d. # \u67e5\u8be2\u5f88\u76f4\u89c2: \u901a\u8fc7has\u9009\u62e9gremlin, out\u8868\u793a\u5173\u7cfb\u670b\u53cb, \u56e0\u4e3a\u4e24\u5c42\u5173\u7cfb\u6240\u4ee5\u6709\u4e24\u4e2a, values\u8868\u793a\u8fd4\u56de\u7684\u7ed3\u679c\u5c5e\u6027 g.V().has(\"name\", \"gremlin\").out(\"knows\").out(\"knows\").values(\"name\") \u5bf9Gremlin\u67e5\u8be2\u8bed\u8a00\u611f\u5174\u8da3\u7684\u540c\u5b66\u53ef\u4ee5\u76f4\u63a5\u67e5\u770b\u5b98\u7f51 http://tinkerpop.apache.org Cypher \u00b6 Cypher: Cypher\u662f\u4e00\u79cd\u58f0\u660e\u5f0f\u56fe\u5f62\u67e5\u8be2\u8bed\u8a00, \u53ef\u7528\u4e8e\u56fe\u7ed3\u6784\u9ad8\u6548\u7684\u67e5\u8be2\u66f4\u65b0\u548c\u7ba1\u7406. \u4ece\u8bed\u6cd5\u89c4\u5219\u4e0a\u770b, Cypher\u65e2\u53d7\u5230SQL\u7684\u542f\u53d1, \u53c8\u5728\u6a21\u5f0f\u5339\u914d\u4e0a\u501f\u9274\u4e86SPARQL\u7684\u8868\u8fbe\u65b9\u6cd5, \u67d0\u4e9b\u5217\u8868\u8bed\u4e49\u5219\u662f\u4eceHaskell\u548cPython\u7b49\u8bed\u8a00\u4e2d\u501f\u7528\u7684. \u7efc\u5408\u6765\u770bCypher\u662f\u4e00\u79cd\u7b80\u4ecb, \u5f3a\u5927, \u4e13\u4e3a\u56fe\u6570\u636e\u5e93\u800c\u751f\u7684\u65b0\u5174\u67e5\u8be2\u8bed\u8a00, \u662fAI\u65b0\u65f6\u4ee3\u7684\u6770\u51fa\u8bed\u8a00. Cypher\u662f\u4e13\u95e8\u4e3a\u56fe\u5f62\u6570\u636e\u800c\u904d\u5386\u8bbe\u8ba1\u548c\u4f18\u5316\u7684, \u88abneo4j\u91c7\u7528\u4e3a\u5b98\u65b9\u67e5\u8be2\u8bed\u8a00, \u5728\u540e\u7eed\u7684\u8bfe\u7a0b\u4e2d\u4f1a\u8be6\u7ec6\u8bb2\u89e3! \u77e5\u8bc6\u67e5\u8be2\u4e3b\u6d41\u65b9\u6cd5 \u00b6 \u77e5\u8bc6\u67e5\u8be2\u4ece\u5927\u7c7b\u4e0a\u67094\u79cd: \u5b50\u56fe\u67e5\u8be2 \u8def\u5f84\u67e5\u8be2 \u5173\u952e\u8bcd\u67e5\u8be2 \u793e\u56e2\u67e5\u8be2 \u5b50\u56fe\u67e5\u8be2 \u00b6 \u5b50\u56fe\u67e5\u8be2\u57fa\u7840\u77e5\u8bc6: \u5b50\u56fe\u67e5\u8be2\u53ef\u4ee5\u5efa\u6a21\u4e3a\u56fe\u8bba\u4e2d\u7ecf\u5178\u7684\u5b50\u56fe\u540c\u6784\u95ee\u9898. \u5b50\u56fe\u540c\u6784: \u8003\u8651\u4e24\u4e2a\u4e0d\u5e26\u6807\u7b7e\u7684\u56feG = (V, E)\u548cG' = (V', E'). \u5982\u679c\u5b58\u5728\u4e00\u4e2a\u53cc\u5c04\u51fd\u6570 f: V -> V', \u4f7f\u5f97e(v1, v2)\u5c5e\u4e8eE\u5f53\u4e14\u4ec5\u5f53e(f(v1), f(v2))\u5c5e\u4e8eE', \u90a3\u4e48\u56feG\u548cG'\u662f\u540c\u6784\u7684. \u6ee1\u8db3\u8fd9\u4e00\u6761\u4ef6\u7684\u6620\u5c04\u51fd\u6570f\u5c31\u662f\u56feG\u548cG'\u4e4b\u95f4\u7684\u540c\u6784\u6620\u5c04\u51fd\u6570. \u5982\u679c\u56feG\u548cG'\u7684\u8282\u70b9\u662f\u5e26\u6807\u7b7e\u7684, \u5219\u540c\u6784\u6620\u5c04\u8fd8\u9700\u8981\u4fdd\u6301\u6807\u7b7e\u76f8\u540c. \u5bf9\u4e8e\u7ed9\u5b9a\u7684\u67e5\u8be2\u56feq, \u5982\u679c\u56feG\u4e2d\u5b58\u5728\u81f3\u5c11\u4e00\u4e2a\u5b50\u56feg\u4f7f\u5f97q\u540c\u6784\u4e8eg, \u5219\u8ba4\u4e3aq\u5b50\u56fe\u540c\u6784\u4e8eG. \u4ed4\u7ec6\u89c2\u5bdf\u4e0b\u9762\u4e24\u4e2a\u56fe, \u662f\u5426\u6709\u540c\u6784\u5173\u7cfb? \u53ef\u4ee5\u53d1\u73b0\u5b58\u57282\u4e2a\u5b50\u56fe\u540c\u6784\u5173\u7cfb: \u6ce8\u610f: \u5b50\u56fe\u67e5\u8be2\u7684\u6838\u5fc3\u662f\u5b50\u56fe\u540c\u6784\u7684\u5224\u5b9a. \u5b50\u56fe\u540c\u6784\u5224\u5b9a\u662f\u56fe\u8bba\u4e2d\u7684\u57fa\u7840\u95ee\u9898, \u5df2\u7ecf\u88ab\u8bc1\u660e\u662fNP\u5b8c\u5168\u95ee\u9898\u4e4b\u4e00. \u5b50\u56fe\u67e5\u8be2\u662f\u590d\u6742\u5ea6\u8f83\u9ad8\u7684\u7b97\u6cd5, \u5982\u4f55\u63d0\u9ad8\u6548\u7387\u6210\u4e3a\u5173\u952e\u95ee\u9898. \u5b50\u56fe\u67e5\u8be2\u7684\u4e24\u4e2a\u7ecf\u5178\u7b97\u6cd5\u662fUllmann\u7b97\u6cd5\u548cVF2\u7b97\u6cd5. skyline\u7b97\u6cd5: \u4e3a\u4e86\u4ece\u5927\u91cf\u7684\u5339\u914d\u7ed3\u679c\u4e2d\u7b5b\u9009\u51fa\u5177\u6709\u4ee3\u8868\u6027\u7684\u7ed3\u679c\u5448\u73b0\u7ed9\u7528\u6237, \u5b50\u56feskyline\u6280\u672f\u662f\u4e3b\u8981\u7684\u7b97\u6cd5\u65b9\u6848. \u8fd1\u4f3c\u5b50\u56fe\u67e5\u8be2: \u57fa\u672c\u601d\u60f3\u662f\u5141\u8bb8\u4e00\u4e2a\u8282\u70b9\u6620\u5c04\u5230\u76ee\u6807\u56fe\u4e2d\u8bed\u4e49\u76f8\u540c\u6216\u76f8\u8fd1\u7684\u8282\u70b9, \u6838\u5fc3\u662f\u5982\u4f55\u5b9a\u4e49\u8ba1\u7b97\u8282\u70b9\u95f4\u8bed\u4e49\u76f8\u4f3c\u5ea6\u7684\u65b9\u6cd5. \u4e00\u4e2a\u4e3b\u6d41\u7684\u65b9\u6cd5\u662f\u57fa\u4e8e\u6709\u5411\u56fe\u7684\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u6765\u8bc4\u4f30\u8282\u70b9\u4e4b\u95f4\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6. \u4ee4sim(u, v)\u8868\u793a\u8282\u70b9u\u548c\u8282\u70b9v\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6, \u4e00\u822c\u6765\u8bf4sim(u, v) = sim(v, u). \u6839\u636eu\u548cv\u5728\u6982\u5ff5\u5c42\u7ea7\u4e2d\"\u6700\u8fd1\u516c\u5171\u7956\u5148\u8282\u70b9\"(Least Common Ancestor)\u7684\u6df1\u5ea6\u6765\u5b9a\u4e49\u8bed\u4e49\u76f8\u4f3c\u5ea6, \u8be5\u6df1\u5ea6\u503c\u8d8a\u5927\u5219\u8bed\u4e49\u8d8a\u76f8\u8fd1. \u8f66\u8f86 / | \\ / | \\ / | \\ \u6469\u6258\u8f66 \u6c7d\u8f66 \u706b\u8f66 / | \\ / | \\ / | \\ \u7535\u52a8\u8f66 \u71c3\u6cb9\u8f66 \u592a\u9633\u80fd\u6c7d\u8f66 Top-K\u67e5\u8be2: \u76ee\u6807\u662f\u8fd4\u56de\u4e0e\u7406\u60f3\u503c\u6700\u63a5\u8fd1\u7684\u524dk\u4e2a\u5339\u914d\u6216\u7b54\u6848. Top-K\u67e5\u8be2\u4e0e\u8fd1\u4f3c\u5b50\u56fe\u67e5\u8be2\u6709\u7740\u5bc6\u5207\u7684\u5173\u7cfb, \u8fd1\u4f3c\u5b50\u56fe\u67e5\u8be2\u5b9a\u4e49\u4e86\u5019\u9009\u5339\u914d\u4e0e\u67e5\u8be2\u56fe\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u6807\u51c6, \u57fa\u4e8e\u8fd9\u4e00\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u6807\u51c6\u53ef\u4ee5\u8ba1\u7b97\u51fa\u5019\u9009\u5339\u914d\u4e0e\u67e5\u8be2\u56fe\u4e4b\u95f4\u7684\u8ddd\u79bb. \u7406\u8bba\u4e0a, \u51e0\u4e4e\u6240\u6709\u7684\u5b50\u56fe\u90fd\u4e0e\u67e5\u8be2\u56fe\u6709\u4e00\u5b9a\u7684\u76f8\u4f3c\u5ea6, \u6240\u4ee5\u8fd1\u4f3c\u5b50\u56fe\u67e5\u8be2\u4e00\u822c\u9700\u8981\u8fd4\u56de\u524dk\u4e2a\u76f8\u8fd1\u7684\u5339\u914d. Topl-K\u67e5\u8be2\u7684\u6838\u5fc3\u6846\u67b6: \u5148\u8fc7\u6ee4, \u540e\u9a8c\u8bc1!!! \u5728\u8fc7\u6ee4\u9636\u6bb5, \u4e3b\u8981\u662f\u6839\u636e\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u6807\u51c6\u6784\u5efa\u6216\u641c\u7d22\u80e1\u4e00\u7cfb\u5217\u5019\u9009\u5339\u914d, \u7136\u540e\u6839\u636e\u8fc7\u6ee4\u7b56\u7565\u8fdb\u884c\u7b5b\u9009: \u8fc7\u6ee4\u7b56\u7565\u5305\u62ec\u4e0a\u754c\u8fc7\u6ee4\u548c\u4e0b\u754c\u8fc7\u6ee4\u4e24\u79cd. \u7b2c\u4e00\u6b65: \u5148\u627e\u5230k\u4e2a\u4efb\u610f\u5339\u914d\u653e\u5165\u7b54\u6848\u5217\u8868, \u540c\u65f6\u5c06\u8fd9k\u4e2a\u5339\u914d\u6309\u7167\u4e0e\u67e5\u8be2\u7684\u76f8\u4f3c\u5ea6\u7531\u9ad8\u5230\u4f4e\u6392\u5e8f. \u7b2c\u4e8c\u6b65: \u5148\u4ee5\u8f83\u5c0f\u7684\u4ee3\u4ef7\u4f30\u7b97\u5019\u9009\u5339\u914d\u4e0e\u67e5\u8be2\u56fe\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u4e0b\u754c. \u7b2c\u4e09\u6b65: \u5c06\u7b54\u6848\u5217\u8868\u4e2d\u6240\u6709\u6bd4\u4e0b\u754c\u5206\u6570\u4f4e\u7684\u5019\u9009\u7b54\u6848\u5168\u90e8\u5220\u9664. \u7b2c\u56db\u6b65: \u5bf9\u4e8e\u5269\u4f59\u7684\u5019\u9009\u5339\u914d, \u5148\u4ee5\u8f83\u5c0f\u7684\u4ee3\u4ef7\u4f30\u7b97\u5b83\u4eec\u4e0e\u67e5\u8be2\u56fe\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u4e0a\u754c. \u7b2c\u4e94\u6b65: \u5982\u679c\u8fd9\u4e2a\u4e0a\u754c\u6bd4\u5f53\u524d\u7b54\u6848\u5217\u8868\u4e2d\u6700\u540e\u4e00\u4e2a\u5339\u914d\u7684\u76f8\u4f3c\u5ea6\u5c0f, \u5219\u53ef\u4ee5\u786e\u5b9a\u5f53\u524d\u7b54\u6848\u5217\u8868\u4e2d\u7684\u5339\u914d\u5c31\u662f\u6700\u540e\u7684\u7ed3\u679c, \u4ece\u800c\u8282\u7701\u4e86\u8ba1\u7b97\u5f00\u9500. \u9664\u4e86\u4e0a\u4e0b\u754c\u526a\u679d, \u5728\u591a\u4e2a\u6392\u5e8f\u673a\u5236\u878d\u5408\u65f6\u4e5f\u5b58\u5728\u5f88\u591a\u6709\u6548\u7684Top-K\u67e5\u8be2\u526a\u679d\u7b56\u7565, \u6700\u7ecf\u5178\u7684\u4e24\u4e2a\u662f: Fagin\u7b97\u6cd5 \u9608\u503c\u7b97\u6cd5 Fagin\u7b97\u6cd5\u548c\u9608\u503c\u7b97\u6cd5\u7684\u6838\u5fc3\u4efb\u52a1\u662f\u5c06f(x) = f1(x) + f2(x)\u4e24\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u51fd\u6570\u878d\u5408\u540e\u8fdb\u884cTop-K\u67e5\u8be2, \u4e00\u822c\u5148\u57fa\u4e8ef1(x)\u4e0ef2(x)\u5206\u522b\u8fdb\u884c\u6392\u5e8f, \u7136\u540e\u6309\u7167\u7279\u5b9a\u7684\u7b56\u7565\u8fdb\u884c\u526a\u679d. \u4e3e\u4e00\u4e2a\u65c5\u6e38\u666f\u70b9\u9009\u62e9\u7684\u4f8b\u5b50: \u5c0f\u660e\u60f3\u53bb\u65c5\u6e38, \u670b\u53cb\u5c0f\u5f3a\u63a8\u8350\u4e86\u7b2c\u4e00\u7ec4\u666f\u70b9, \u670b\u53cb\u5c0f\u4e3d\u63a8\u8350\u4e86\u7b2c\u4e8c\u7ec4\u666f\u70b9, \u5047\u8bbe\u5c0f\u5f3a\u548c\u5c0f\u4e3d\u7684\u610f\u89c1\u540c\u6837\u91cd\u8981. \u540c\u5b66\u4eec\u80fd\u5426\u5148\u7ed9\u51fa\u4e00\u4e2a\u7b80\u5355\u7684\u89e3\u51b3\u65b9\u6848? \u666f\u70b9 | \u63a8\u8350\u6307\u65701 | \u666f\u70b9 | \u63a8\u8350\u6307\u65702 --------------------------------------------------------------------- \u4e5d\u5be8\u6c9f | 10 | \u5927\u7406 | 9 --------------------------------------------------------------------- \u5927\u7406 | 8 | \u897f\u6e56 | 7 --------------------------------------------------------------------- \u897f\u6e56 | 7 | \u4e5d\u5be8\u6c9f | 6 --------------------------------------------------------------------- \u9ec4\u5c71 | 6 | \u9ec4\u5c71 | 6 Fagin\u7b97\u6cd5: \u63a8\u8350\u6307\u65701 | \u63a8\u8350\u6307\u65702 || \u63a8\u8350\u6307\u65701 | \u63a8\u8350\u6307\u65702 || \u63a8\u8350\u6307\u65701 | \u63a8\u8350\u6307\u65702 --------------------------------------------------------------------------------------------------------- \u4e5d\u5be8\u6c9f(10) | || \u4e5d\u5be8\u6c9f(10) | || \u4e5d\u5be8\u6c9f(10) | --------------------------------------------------------------------------------------------------------- | \u5927\u7406(9) || | \u5927\u7406(9) || | \u5927\u7406(9) --------------------------------------------------------------------------------------------------------- | || \u5927\u7406(8) | \u897f\u6e56(7) || \u5927\u7406(8) | --------------------------------------------------------------------------------------------------------- | || | || | \u4e5d\u5be8\u6c9f(6) --------------------------------------------------------------------------------------------------------- \u628a\u5404\u81ea\u7684TOP1\u9009\u9879\u6dfb\u52a0\u8fdb\u5217\u8868\u4e2d || \u628a\u5404\u81ea\u7684TOP2\u9009\u9879\u6dfb\u52a0\u8fdb\u5217\u8868\u4e2d || f(\u4e5d\u5be8\u6c9f) = 10 + 6 = 16 || || f(\u5927\u7406) = 8 + 9 = 17 \u9608\u503c\u7b97\u6cd5: \u666f\u70b9 | \u666f\u70b9 | SUM || \u666f\u70b9 | \u666f\u70b9 | SUM || \u666f\u70b9 | \u666f\u70b9 | SUM ------------------------------------------------------------------------------------------------------- \u4e5d\u5be8\u6c9f | \u5927\u7406 | || \u4e5d\u5be8\u6c9f | \u5927\u7406 | || \u4e5d\u5be8\u6c9f | \u5927\u7406 | (10) | (9) | 19 || (10+6)| (9+8) | 19 || (10+6) | (9+8) | 19 ------------------------------------------------------------------------------------------------------- | | || | | || \u5927\u7406 | \u897f\u6e56 | | | || | | || (8) | (7) | 15 \u8def\u7ecf\u67e5\u8be2 \u00b6 \u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u4e00\u79cd\u56fe, \u53ef\u4ee5\u5728\u56fe\u4e0a\u8fdb\u884c\u8def\u5f84\u67e5\u8be2, \u5c24\u5176\u662f\u5728\u6211\u4eec\u5bf9\u67d0\u4e2a\u77e5\u8bc6\u56fe\u8c31\u4e0d\u591f\u4e86\u89e3\u7684\u60c5\u51b5\u4e0b, \u8fd9\u79cd\u6700\u77ed\u8def\u5f84\u67e5\u8be2\u63d0\u4f9b\u4e86\u4e00\u4e2a\u975e\u5e38\u7b80\u5355\u7684\u65b9\u5f0f\u6765\u63a2\u7a76\u4e24\u4e2a\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u8054\u5173\u7cfb. \u8def\u5f84\u67e5\u8be2\u4e3b\u8981\u6709\u4e24\u7c7b\u65b9\u6cd5: 1: \u5e26\u6807\u7b7e\u9650\u5236\u7684\u8def\u5f84\u67e5\u8be2 2: \u5143\u8def\u5f84\u67e5\u8be2 \u5e26\u6807\u7b7e\u9650\u5236\u7684\u8def\u5f84\u67e5\u8be2: \u4e0d\u540c\u4e8e\u4e00\u822c\u56fe, \u77e5\u8bc6\u56fe\u8c31\u4e0a\u7684\u8282\u70b9\u548c\u8fb9\u8574\u542b\u4e86\u4e30\u5bcc\u7684\u8bed\u4e49\u4fe1\u606f, \u5355\u7eaf\u8ba1\u7b97\u4e24\u4e2a\u8282\u70b9\u4e4b\u95f4\u7684\u6700\u77ed\u8def\u5f84\u7684\u5b9e\u9645\u610f\u4e49\u6709\u9650, \u66f4\u597d\u7684\u65b9\u6cd5\u662f\u5bf9\u8def\u5f84\u4e0a\u7684\u8fb9\u8fdb\u884c\u9650\u5236. \u57fa\u4e8e\u4e09\u89d2\u4e0d\u7b49\u5f0f\u53ef\u4ee5\u4f30\u8ba1\u4efb\u610f\u4e24\u4e2a\u8282\u70b9\u4e4b\u95f4\u7684\u6700\u77ed\u8def\u5f84: dist(s, t) = min{dist(s, l) + dist(l, t)} \u5143\u8def\u5f84\u67e5\u8be2: \u4e3a\u4e86\u66f4\u597d\u7684\u4f53\u73b0\u8bed\u4e49\u4fe1\u606f, \u4e00\u79cd\u66f4\u4f18\u7684\u65b9\u6cd5\u662f\u53ea\u8003\u8651\u7b26\u5408\u7279\u5b9a\u5143\u8def\u5f84(Meta Path)\u7684\u6700\u77ed\u8def\u5f84. \u5b83\u9664\u4e86\u8003\u8651\u8fb9\u4e0a\u7684\u7c7b\u578b\u9650\u5236\u5916, \u8fd8\u5bf9\u8def\u5f84\u4e0a\u8282\u70b9\u7c7b\u578b\u8fdb\u884c\u9650\u5236. \u5728\u6307\u5b9a\u4e86\u5143\u8def\u5f84\u540e, \u6700\u77ed\u8def\u5f84\u68c0\u7d22\u53ef\u4ee5\u627e\u5230\u66f4\u6709\u9488\u5bf9\u6027\u7684\u7ed3\u679c, \u8fd4\u56de\u7684\u7ed3\u679c\u4e5f\u66f4\u5177\u53ef\u89e3\u91ca\u6027. \u5173\u952e\u8bcd\u67e5\u8be2 \u00b6 \u641c\u7d22\u5f15\u64ce\u5728\u63a8\u52a8\u7f51\u7edc\u4fe1\u606f\u65f6\u4ee3\u7684\u53d1\u5c55\u4e2d\u8d77\u5230\u4e86\u5de8\u5927\u4f5c\u7528, \u5728\u641c\u7d22\u6280\u672f\u4e2d\u6700\u4e3b\u8981\u7684\u5c31\u662f\u5173\u952e\u8bcd\u67e5\u8be2. \u5173\u952e\u8bcd\u67e5\u8be2\u7279\u522b\u9002\u7528\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u573a\u666f. \u77e5\u8bc6\u56fe\u8c31\u5305\u542b\u5927\u91cf\u7684\u5b9e\u4f53\u548c\u5173\u7cfb\u5e76\u4e14\u5177\u6709\u7075\u6d3b, \u591a\u6837\u7684\u8868\u8fbe\u65b9\u5f0f, \u666e\u901a\u7528\u6237\u5f88\u96be\u6e05\u695a\u5730\u4e86\u89e3\u77e5\u8bc6\u56fe\u8c31\u4e2d\u4f7f\u7528\u7684\u5b9e\u4f53\u540d\u79f0\u548c\u8c13\u8bcd\u540d\u79f0. \u5173\u952e\u8bcd\u67e5\u8be2\u4f7f\u5f97\u7528\u6237\u65e0\u9700\u6307\u5b9a\u7cbe\u786e\u7684\u641c\u7d22\u5173\u952e\u8bcd\u5c31\u80fd\u67e5\u627e\u5230\u76f8\u5173\u77e5\u8bc6\u548c\u7ed3\u679c. \u6700\u5c0f\u65af\u5766\u7eb3\u6811(Steiner Tree): \u6700\u5c0f\u65af\u5766\u7eb3\u6811\u662f\u7ec4\u5408\u4f18\u5316\u4e2d\u7684\u4e00\u4e2a\u7ecf\u5178\u95ee\u9898, \u662f\u6307\u4ece\u8f93\u5165\u56fe\u4e2d\u627e\u5230\u4e00\u4e2a\u4f7f\u5f97\u7ed9\u5b9a\u7684\u6240\u6709\u8282\u70b9\u96c6\u5408\u8fde\u901a\u5e76\u4e14\u8fb9\u6743\u603b\u548c\u6700\u5c0f\u7684\u5b50\u6811. \u5bf9\u4e8e\u77e5\u8bc6\u56fe\u8c31\u4e0a\u7684\u5173\u952e\u8bcd\u67e5\u8be2, \u4e0e\u5173\u952e\u8bcd\u5339\u914d\u7684\u8282\u70b9\u96c6\u5408\u5c31\u662f\u8f93\u5165\u8282\u70b9\u96c6\u5408, \u8f93\u51fa\u4e3a\u7531\u8fd9\u4e9b\u8282\u70b9\u6784\u6210\u7684\u6700\u5c0f\u65af\u5766\u7eb3\u6811. \u6c42\u89e3\u7b97\u6cd5: \u679a\u4e3eV-U\u7684\u5b50\u96c6S (V\u662f\u56feG\u7684\u8282\u70b9\u96c6\u5408, U\u662f\u7ed9\u5b9a\u7684\u5173\u952e\u8bcd\u8282\u70b9\u96c6\u5408), \u7279\u522b\u6ce8\u610fS\u53ef\u80fd\u4e3a\u7a7a\u96c6, \u57fa\u4e8e\u70b9\u96c6U U S\u6c42\u89e3\u6700\u5c0f\u751f\u6210\u6811, \u5728\u6240\u6709\u7684\u6700\u5c0f\u751f\u6210\u6811\u4e2d, \u6743\u91cd\u6700\u5c0f\u7684\u90a3\u68f5\u6811\u5373\u4e3a\u6700\u5c0f\u65af\u5766\u7eb3\u6811. \u7f3a\u9677: \u5173\u952e\u8bcd\u67e5\u8be2\u867d\u7136\u7b80\u5355, \u6613\u7528, \u4f46\u662f\u5b83\u7684\u8bed\u4e49\u8868\u8fbe\u80fd\u529b\u76f8\u5bf9\u6709\u9650. \u4f20\u7edf\u7684\u5173\u952e\u8bcd\u67e5\u8be2\u7814\u7a76\u4e00\u822c\u66f4\u5173\u6ce8\u67e5\u8be2\u7684\u6548\u7387, \u5728\u610f\u56fe\u5efa\u6a21\u4e0e\u7406\u89e3\u65b9\u9762\u505a\u7684\u4e0d\u591a. \u793e\u56e2\u67e5\u8be2 \u00b6 \u793e\u56e2\u7ed3\u6784\u5e7f\u6cdb\u5b58\u5728\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7b49\u5f88\u591a\u771f\u5b9e\u7684\u590d\u6742\u7f51\u7edc\u4e2d, \u4e00\u822c\u800c\u8a00, \u793e\u56e2\u662f\u6307\u4e00\u7ec4\u5185\u90e8\u4e92\u76f8\u7d27\u5bc6\u8054\u7cfb\u7684\u8282\u70b9, \u5b83\u4eec\u4e0e\u793e\u56e2\u4e4b\u5916\u8282\u70b9\u7684\u8054\u7cfb\u76f8\u5bf9\u677e\u6563. \u901a\u5e38\u793e\u56e2\u5185\u7684\u7d27\u5bc6\u7a0b\u5ea6\u4ee5\u8be5\u5b50\u7ed3\u6784\u7684\u5e73\u5747\u5ea6\u6570\u6216\u8005\u8282\u70b9\u7684\u6700\u5c0f\u5ea6\u6570\u4f5c\u4e3a\u8861\u91cf\u4f9d\u636e. \u4f20\u7edf\u7684\u793e\u56e2\u641c\u7d22\u5206\u4e3a\u4e24\u5927\u7c7b\u4efb\u52a1: \u793e\u56e2\u6316\u6398 \u793e\u56e2\u67e5\u8be2 \u793e\u56e2\u6316\u6398: \u662f\u6307\u7ed9\u5b9a\u56feG\u548c\u7279\u5b9a\u7684\u793e\u56e2\u5ea6\u91cf\u6807\u51c6, \u627e\u51fa\u5176\u4e2d\u6240\u6709\u7684\u793e\u56e2. \u793e\u56e2\u6316\u6398\u6548\u7387\u8f83\u4f4e, \u901a\u5e38\u9700\u8981\u79bb\u7ebf\u5904\u7406. \u793e\u56e2\u67e5\u8be2: \u662f\u6307\u9884\u5148\u7ed9\u5b9a\u56feG\u548c\u7279\u5b9a\u7684\u793e\u56e2\u5ea6\u91cf\u6807\u51c6, \u4e3a\u67d0\u4e2a\u67e5\u8be2\u8282\u70b9\u627e\u5230\u5305\u542b\u8be5\u8282\u70b9\u7684\u793e\u56e2, \u4e5f\u79f0\u4e3a\u4e2a\u6027\u5316\u793e\u56e2\u53d1\u73b0. \u793e\u56e2\u67e5\u8be2\u662f\u4e00\u79cd\u5178\u578b\u7684\u6309\u9700\u670d\u52a1, \u901a\u5e38\u901a\u8fc7\u5728\u7ebf\u5904\u7406\u7684\u5f62\u5f0f\u5b8c\u6210. \u5c0f\u8282\u603b\u7ed3 \u00b6 \u9996\u5148\u5b66\u4e60\u4e86\u77e5\u8bc6\u67e5\u8be2\u76844\u4e2a\u4e3b\u6d41\u8bed\u8a00: SQL SPARQL Gremlin Cypher \u63a5\u4e0b\u6765\u6df1\u5165\u63a2\u8ba8\u4e86\u77e5\u8bc6\u67e5\u8be2\u76844\u4e2a\u4e3b\u6d41\u65b9\u6cd5: \u5b50\u56fe\u67e5\u8be2 \u8def\u5f84\u67e5\u8be2 \u5173\u952e\u8bcd\u67e5\u8be2 \u793e\u56e2\u67e5\u8be2","title":"2.1 \u77e5\u8bc6\u67e5\u8be2\u65b9\u6cd5\u4ecb\u7ecd"},{"location":"2_1.html#_1","text":"","title":"\u77e5\u8bc6\u67e5\u8be2\u65b9\u6cd5\u4ecb\u7ecd"},{"location":"2_1.html#_2","text":"\u4e86\u89e3\u77e5\u8bc6\u67e5\u8be2\u7684\u4e3b\u6d41\u8bed\u8a00. \u7406\u89e3\u77e5\u8bc6\u67e5\u8be2\u7684\u4e3b\u6d41\u65b9\u6cd5\u548c\u539f\u7406.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"2_1.html#_3","text":"\u67e5\u8be2\u4e0e\u68c0\u7d22\u662f\u77e5\u8bc6\u56fe\u8c31\u7684\u91cd\u8981\u4f7f\u7528\u65b9\u5f0f, \u4e5f\u662f\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u7ba1\u7406\u7cfb\u7edf\u7684\u6838\u5fc3\u80fd\u529b\u4e4b\u4e00.","title":"\u77e5\u8bc6\u67e5\u8be2\u4e3b\u6d41\u8bed\u8a00"},{"location":"2_1.html#sql","text":"SQL: \u8ba1\u7b97\u673a\u5de5\u7a0b\u5e08\u6700\u719f\u6089\u7684\u67e5\u8be2\u8bed\u8a00\u83ab\u8fc7\u4e8eSQL. \u5728SQL\u5e94\u7528\u4e2d, \u6570\u636e\u4ee5\u8868\u7684\u5f62\u5f0f\u5b58\u5728, \u6709\u6bd4\u8f83\u5f3a\u7684schema\u5b9a\u4e49, \u8868\u548c\u8868\u4e4b\u95f4\u7684\u6570\u636e\u5173\u8054\u4ee5join\u7684\u65b9\u5f0f\u5b9e\u73b0. \u4f46\u662fSQL\u6709\u4e00\u4e2a\u91cd\u5927\u7684\u7f3a\u9677: \u5c5e\u6027\u503c\u5e76\u4e0d\u603b\u662f\u5355\u4e00\u503c. \u9488\u5bf9\u6bcf\u4e00\u4e2a\u591a\u503c\u5c5e\u6027\u9700\u8981\u8fdb\u884c\u989d\u5916\u7684\u62c6\u8868\u64cd\u4f5c, \u8fd9\u5bf9\u4e8e\u8868\u6570\u636e\u7684\u7ba1\u7406\u5e26\u6765\u5de8\u5927\u6311\u6218. \u5c24\u5176\u662f\u9700\u8981\u9ad8\u901f\u9ad8\u9891\u7684\u8fdb\u884c\u591a\u8868\u8fde\u63a5\u64cd\u4f5c\u7684\u573a\u666f, \u5bf9\u4e8e\u6570\u636e\u5e93\u6027\u80fd\u4e5f\u662f\u6781\u5927\u7684\u6311\u6218! \u5bf9\u4e8e\u77e5\u8bc6\u56fe\u8c31\u4e2d\u6700\u4e3b\u6d41\u7684\u4e09\u5143\u7ec4\u5f62\u5f0f, \u591a\u8df3\u5173\u8054\u67e5\u8be2\u7684\u5f62\u5f0f, \u663e\u7136SQL\u4e0d\u5177\u5907\u4f18\u52bf.","title":"SQL"},{"location":"2_1.html#sparql","text":"SPARQL: \u56fd\u9645\u6807\u51c6\u5316\u7ec4\u7ec7W3C\u63d0\u51fa\u4e86\u9488\u5bf9\u4e8eRDF\u77e5\u8bc6\u56fe\u8c31\u7684\u6807\u51c6\u5316\u67e5\u8be2\u8bed\u8a00SPARQL. \u4f5c\u4e3a\u4e00\u79cd\u56fe\u6570\u636e, SPARQL\u67e5\u8be2\u7684\u6267\u884c\u53ef\u4ee5\u901a\u8fc7\u56fe\u5339\u914d\u7684\u65b9\u5f0f\u5b9e\u73b0. SPARQL\u662f\u4e00\u79cd\u9488\u5bf9RDF\u6570\u636e\u7684\u67e5\u8be2\u8bed\u8a00, 2008\u5e74\u6b63\u5f0f\u6210\u4e3aW3C\u63a8\u8350\u7684\u9488\u5bf9RDF\u6570\u636e\u7684\u6807\u51c6\u67e5\u8be2\u8bed\u8a00. \u548cSQL\u4e00\u6837, SPARQL\u4e5f\u662f\u4e00\u79cd\u58f0\u660e\u5f0f\u7684\u7ed3\u6784\u5316\u67e5\u8be2\u8bed\u8a00, \u5373\u7528\u6237\u53ea\u9700\u8981\u6309\u7167SPARQL\u5b9a\u4e49\u7684\u8bed\u6cd5\u89c4\u5219\u63cf\u8ff0\u5176\u60f3\u67e5\u8be2\u7684\u4fe1\u606f\u5373\u53ef, \u4e0d\u9700\u8981\u660e\u786e\u6307\u5b9a\u8ba1\u7b97\u673a\u5b9e\u73b0\u67e5\u8be2\u7684\u6b65\u9aa4. SPARQL\u8bed\u8a00\u501f\u9274\u4e86SQL\u7684\u90e8\u5206\u8bed\u6cd5, \u66f4\u52a0\u5173\u6ce8\u76ee\u6807\u6570\u636e\u56fe\u7684\u5339\u914d, \u603b\u4f53\u6765\u8bf4\u8bed\u8a00\u89c4\u5219\u4e0d\u7b97\u590d\u6742, \u6bd4\u8f83\u5bb9\u6613\u5b66: # \u6bd4\u5982\u5229\u7528SPARQL\u67e5\u8be2\u4ece\u4e09\u5143\u7ec4<org:book, dc:title, \"Knowledge graph\">\u4e2d\u67e5\u8be2book\u8fd9\u672c\u4e66\u7684\u540d\u5b57 Q: \u67e5\u8be2\u56fe\u4e66\u540d\u79f0 SELECT ?title WHERE { org:book dc:title ?title .} \u8003\u8651\u5230\u9879\u76ee\u540e\u7eed\u4f7f\u7528\u7684\u56fe\u6570\u636e\u5e93neo4j\u5b9e\u9645\u7528\u7684\u662fCypher\u8bed\u8a00, \u5728\u6b64\u4ec5\u4f5c\u4ecb\u7ecd, \u540e\u9762\u8bfe\u7a0b\u4e2d\u5c06\u8be6\u7ec6\u4e3a\u540c\u5b66\u4eec\u8bb2\u6388Cypher\u67e5\u8be2\u8bed\u8a00.","title":"SPARQL"},{"location":"2_1.html#gremlin","text":"Gremlin: \u662fApache\u65d7\u4e0b\u7684Java\u9879\u76ee, \u4e5f\u662f\u4e00\u6b3e\u8457\u540d\u7684\u56fe\u6570\u636e\u5e93\u67e5\u8be2\u8bed\u8a00. \u6570\u636e\u4ee5\u5c5e\u6027\u56fe\u7684\u5f62\u5f0f\u5b58\u5728, \u53ef\u4ee5\u8ba4\u4e3a\u662fSQL\u548cSPARQL\u7684\u6df7\u5408\u4f53. \u5b9e\u4f53\u7684\u5c5e\u6027\u4ecd\u7136\u5728\u8868\u4e2d, \u4f46\u662f\u8fde\u63a5\u5173\u7cfb\u662f\u76f4\u63a5\u4ee5\u6307\u9488\u7684\u5f62\u5f0f\u5b58\u5728\u7684. Gremlin\u7684\u67e5\u8be2\u672c\u8d28\u662f\u56fe\u904d\u5386, \u64c5\u957f\u89e3\u51b3\u6c42\u56fe\u7684\u76f4\u5f84, \u70b9\u5230\u70b9\u4e4b\u95f4\u7684\u8def\u5f84\u7b49, \u6bd4\u5982\u5218\u5fb7\u534e\u8fde\u63a5\u5965\u5df4\u9a6c\u9700\u8981\u51e0\u5ea6\u5173\u7cfb. \u793a\u4f8b: \u67e5\u8be2gremlin\u7684\u670b\u53cb\u7684\u670b\u53cb\u7684\u59d3\u540d. # \u67e5\u8be2\u5f88\u76f4\u89c2: \u901a\u8fc7has\u9009\u62e9gremlin, out\u8868\u793a\u5173\u7cfb\u670b\u53cb, \u56e0\u4e3a\u4e24\u5c42\u5173\u7cfb\u6240\u4ee5\u6709\u4e24\u4e2a, values\u8868\u793a\u8fd4\u56de\u7684\u7ed3\u679c\u5c5e\u6027 g.V().has(\"name\", \"gremlin\").out(\"knows\").out(\"knows\").values(\"name\") \u5bf9Gremlin\u67e5\u8be2\u8bed\u8a00\u611f\u5174\u8da3\u7684\u540c\u5b66\u53ef\u4ee5\u76f4\u63a5\u67e5\u770b\u5b98\u7f51 http://tinkerpop.apache.org","title":"Gremlin"},{"location":"2_1.html#cypher","text":"Cypher: Cypher\u662f\u4e00\u79cd\u58f0\u660e\u5f0f\u56fe\u5f62\u67e5\u8be2\u8bed\u8a00, \u53ef\u7528\u4e8e\u56fe\u7ed3\u6784\u9ad8\u6548\u7684\u67e5\u8be2\u66f4\u65b0\u548c\u7ba1\u7406. \u4ece\u8bed\u6cd5\u89c4\u5219\u4e0a\u770b, Cypher\u65e2\u53d7\u5230SQL\u7684\u542f\u53d1, \u53c8\u5728\u6a21\u5f0f\u5339\u914d\u4e0a\u501f\u9274\u4e86SPARQL\u7684\u8868\u8fbe\u65b9\u6cd5, \u67d0\u4e9b\u5217\u8868\u8bed\u4e49\u5219\u662f\u4eceHaskell\u548cPython\u7b49\u8bed\u8a00\u4e2d\u501f\u7528\u7684. \u7efc\u5408\u6765\u770bCypher\u662f\u4e00\u79cd\u7b80\u4ecb, \u5f3a\u5927, \u4e13\u4e3a\u56fe\u6570\u636e\u5e93\u800c\u751f\u7684\u65b0\u5174\u67e5\u8be2\u8bed\u8a00, \u662fAI\u65b0\u65f6\u4ee3\u7684\u6770\u51fa\u8bed\u8a00. Cypher\u662f\u4e13\u95e8\u4e3a\u56fe\u5f62\u6570\u636e\u800c\u904d\u5386\u8bbe\u8ba1\u548c\u4f18\u5316\u7684, \u88abneo4j\u91c7\u7528\u4e3a\u5b98\u65b9\u67e5\u8be2\u8bed\u8a00, \u5728\u540e\u7eed\u7684\u8bfe\u7a0b\u4e2d\u4f1a\u8be6\u7ec6\u8bb2\u89e3!","title":"Cypher"},{"location":"2_1.html#_4","text":"\u77e5\u8bc6\u67e5\u8be2\u4ece\u5927\u7c7b\u4e0a\u67094\u79cd: \u5b50\u56fe\u67e5\u8be2 \u8def\u5f84\u67e5\u8be2 \u5173\u952e\u8bcd\u67e5\u8be2 \u793e\u56e2\u67e5\u8be2","title":"\u77e5\u8bc6\u67e5\u8be2\u4e3b\u6d41\u65b9\u6cd5"},{"location":"2_1.html#_5","text":"\u5b50\u56fe\u67e5\u8be2\u57fa\u7840\u77e5\u8bc6: \u5b50\u56fe\u67e5\u8be2\u53ef\u4ee5\u5efa\u6a21\u4e3a\u56fe\u8bba\u4e2d\u7ecf\u5178\u7684\u5b50\u56fe\u540c\u6784\u95ee\u9898. \u5b50\u56fe\u540c\u6784: \u8003\u8651\u4e24\u4e2a\u4e0d\u5e26\u6807\u7b7e\u7684\u56feG = (V, E)\u548cG' = (V', E'). \u5982\u679c\u5b58\u5728\u4e00\u4e2a\u53cc\u5c04\u51fd\u6570 f: V -> V', \u4f7f\u5f97e(v1, v2)\u5c5e\u4e8eE\u5f53\u4e14\u4ec5\u5f53e(f(v1), f(v2))\u5c5e\u4e8eE', \u90a3\u4e48\u56feG\u548cG'\u662f\u540c\u6784\u7684. \u6ee1\u8db3\u8fd9\u4e00\u6761\u4ef6\u7684\u6620\u5c04\u51fd\u6570f\u5c31\u662f\u56feG\u548cG'\u4e4b\u95f4\u7684\u540c\u6784\u6620\u5c04\u51fd\u6570. \u5982\u679c\u56feG\u548cG'\u7684\u8282\u70b9\u662f\u5e26\u6807\u7b7e\u7684, \u5219\u540c\u6784\u6620\u5c04\u8fd8\u9700\u8981\u4fdd\u6301\u6807\u7b7e\u76f8\u540c. \u5bf9\u4e8e\u7ed9\u5b9a\u7684\u67e5\u8be2\u56feq, \u5982\u679c\u56feG\u4e2d\u5b58\u5728\u81f3\u5c11\u4e00\u4e2a\u5b50\u56feg\u4f7f\u5f97q\u540c\u6784\u4e8eg, \u5219\u8ba4\u4e3aq\u5b50\u56fe\u540c\u6784\u4e8eG. \u4ed4\u7ec6\u89c2\u5bdf\u4e0b\u9762\u4e24\u4e2a\u56fe, \u662f\u5426\u6709\u540c\u6784\u5173\u7cfb? \u53ef\u4ee5\u53d1\u73b0\u5b58\u57282\u4e2a\u5b50\u56fe\u540c\u6784\u5173\u7cfb: \u6ce8\u610f: \u5b50\u56fe\u67e5\u8be2\u7684\u6838\u5fc3\u662f\u5b50\u56fe\u540c\u6784\u7684\u5224\u5b9a. \u5b50\u56fe\u540c\u6784\u5224\u5b9a\u662f\u56fe\u8bba\u4e2d\u7684\u57fa\u7840\u95ee\u9898, \u5df2\u7ecf\u88ab\u8bc1\u660e\u662fNP\u5b8c\u5168\u95ee\u9898\u4e4b\u4e00. \u5b50\u56fe\u67e5\u8be2\u662f\u590d\u6742\u5ea6\u8f83\u9ad8\u7684\u7b97\u6cd5, \u5982\u4f55\u63d0\u9ad8\u6548\u7387\u6210\u4e3a\u5173\u952e\u95ee\u9898. \u5b50\u56fe\u67e5\u8be2\u7684\u4e24\u4e2a\u7ecf\u5178\u7b97\u6cd5\u662fUllmann\u7b97\u6cd5\u548cVF2\u7b97\u6cd5. skyline\u7b97\u6cd5: \u4e3a\u4e86\u4ece\u5927\u91cf\u7684\u5339\u914d\u7ed3\u679c\u4e2d\u7b5b\u9009\u51fa\u5177\u6709\u4ee3\u8868\u6027\u7684\u7ed3\u679c\u5448\u73b0\u7ed9\u7528\u6237, \u5b50\u56feskyline\u6280\u672f\u662f\u4e3b\u8981\u7684\u7b97\u6cd5\u65b9\u6848. \u8fd1\u4f3c\u5b50\u56fe\u67e5\u8be2: \u57fa\u672c\u601d\u60f3\u662f\u5141\u8bb8\u4e00\u4e2a\u8282\u70b9\u6620\u5c04\u5230\u76ee\u6807\u56fe\u4e2d\u8bed\u4e49\u76f8\u540c\u6216\u76f8\u8fd1\u7684\u8282\u70b9, \u6838\u5fc3\u662f\u5982\u4f55\u5b9a\u4e49\u8ba1\u7b97\u8282\u70b9\u95f4\u8bed\u4e49\u76f8\u4f3c\u5ea6\u7684\u65b9\u6cd5. \u4e00\u4e2a\u4e3b\u6d41\u7684\u65b9\u6cd5\u662f\u57fa\u4e8e\u6709\u5411\u56fe\u7684\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u6765\u8bc4\u4f30\u8282\u70b9\u4e4b\u95f4\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6. \u4ee4sim(u, v)\u8868\u793a\u8282\u70b9u\u548c\u8282\u70b9v\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6, \u4e00\u822c\u6765\u8bf4sim(u, v) = sim(v, u). \u6839\u636eu\u548cv\u5728\u6982\u5ff5\u5c42\u7ea7\u4e2d\"\u6700\u8fd1\u516c\u5171\u7956\u5148\u8282\u70b9\"(Least Common Ancestor)\u7684\u6df1\u5ea6\u6765\u5b9a\u4e49\u8bed\u4e49\u76f8\u4f3c\u5ea6, \u8be5\u6df1\u5ea6\u503c\u8d8a\u5927\u5219\u8bed\u4e49\u8d8a\u76f8\u8fd1. \u8f66\u8f86 / | \\ / | \\ / | \\ \u6469\u6258\u8f66 \u6c7d\u8f66 \u706b\u8f66 / | \\ / | \\ / | \\ \u7535\u52a8\u8f66 \u71c3\u6cb9\u8f66 \u592a\u9633\u80fd\u6c7d\u8f66 Top-K\u67e5\u8be2: \u76ee\u6807\u662f\u8fd4\u56de\u4e0e\u7406\u60f3\u503c\u6700\u63a5\u8fd1\u7684\u524dk\u4e2a\u5339\u914d\u6216\u7b54\u6848. Top-K\u67e5\u8be2\u4e0e\u8fd1\u4f3c\u5b50\u56fe\u67e5\u8be2\u6709\u7740\u5bc6\u5207\u7684\u5173\u7cfb, \u8fd1\u4f3c\u5b50\u56fe\u67e5\u8be2\u5b9a\u4e49\u4e86\u5019\u9009\u5339\u914d\u4e0e\u67e5\u8be2\u56fe\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u6807\u51c6, \u57fa\u4e8e\u8fd9\u4e00\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u6807\u51c6\u53ef\u4ee5\u8ba1\u7b97\u51fa\u5019\u9009\u5339\u914d\u4e0e\u67e5\u8be2\u56fe\u4e4b\u95f4\u7684\u8ddd\u79bb. \u7406\u8bba\u4e0a, \u51e0\u4e4e\u6240\u6709\u7684\u5b50\u56fe\u90fd\u4e0e\u67e5\u8be2\u56fe\u6709\u4e00\u5b9a\u7684\u76f8\u4f3c\u5ea6, \u6240\u4ee5\u8fd1\u4f3c\u5b50\u56fe\u67e5\u8be2\u4e00\u822c\u9700\u8981\u8fd4\u56de\u524dk\u4e2a\u76f8\u8fd1\u7684\u5339\u914d. Topl-K\u67e5\u8be2\u7684\u6838\u5fc3\u6846\u67b6: \u5148\u8fc7\u6ee4, \u540e\u9a8c\u8bc1!!! \u5728\u8fc7\u6ee4\u9636\u6bb5, \u4e3b\u8981\u662f\u6839\u636e\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u6807\u51c6\u6784\u5efa\u6216\u641c\u7d22\u80e1\u4e00\u7cfb\u5217\u5019\u9009\u5339\u914d, \u7136\u540e\u6839\u636e\u8fc7\u6ee4\u7b56\u7565\u8fdb\u884c\u7b5b\u9009: \u8fc7\u6ee4\u7b56\u7565\u5305\u62ec\u4e0a\u754c\u8fc7\u6ee4\u548c\u4e0b\u754c\u8fc7\u6ee4\u4e24\u79cd. \u7b2c\u4e00\u6b65: \u5148\u627e\u5230k\u4e2a\u4efb\u610f\u5339\u914d\u653e\u5165\u7b54\u6848\u5217\u8868, \u540c\u65f6\u5c06\u8fd9k\u4e2a\u5339\u914d\u6309\u7167\u4e0e\u67e5\u8be2\u7684\u76f8\u4f3c\u5ea6\u7531\u9ad8\u5230\u4f4e\u6392\u5e8f. \u7b2c\u4e8c\u6b65: \u5148\u4ee5\u8f83\u5c0f\u7684\u4ee3\u4ef7\u4f30\u7b97\u5019\u9009\u5339\u914d\u4e0e\u67e5\u8be2\u56fe\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u4e0b\u754c. \u7b2c\u4e09\u6b65: \u5c06\u7b54\u6848\u5217\u8868\u4e2d\u6240\u6709\u6bd4\u4e0b\u754c\u5206\u6570\u4f4e\u7684\u5019\u9009\u7b54\u6848\u5168\u90e8\u5220\u9664. \u7b2c\u56db\u6b65: \u5bf9\u4e8e\u5269\u4f59\u7684\u5019\u9009\u5339\u914d, \u5148\u4ee5\u8f83\u5c0f\u7684\u4ee3\u4ef7\u4f30\u7b97\u5b83\u4eec\u4e0e\u67e5\u8be2\u56fe\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u4e0a\u754c. \u7b2c\u4e94\u6b65: \u5982\u679c\u8fd9\u4e2a\u4e0a\u754c\u6bd4\u5f53\u524d\u7b54\u6848\u5217\u8868\u4e2d\u6700\u540e\u4e00\u4e2a\u5339\u914d\u7684\u76f8\u4f3c\u5ea6\u5c0f, \u5219\u53ef\u4ee5\u786e\u5b9a\u5f53\u524d\u7b54\u6848\u5217\u8868\u4e2d\u7684\u5339\u914d\u5c31\u662f\u6700\u540e\u7684\u7ed3\u679c, \u4ece\u800c\u8282\u7701\u4e86\u8ba1\u7b97\u5f00\u9500. \u9664\u4e86\u4e0a\u4e0b\u754c\u526a\u679d, \u5728\u591a\u4e2a\u6392\u5e8f\u673a\u5236\u878d\u5408\u65f6\u4e5f\u5b58\u5728\u5f88\u591a\u6709\u6548\u7684Top-K\u67e5\u8be2\u526a\u679d\u7b56\u7565, \u6700\u7ecf\u5178\u7684\u4e24\u4e2a\u662f: Fagin\u7b97\u6cd5 \u9608\u503c\u7b97\u6cd5 Fagin\u7b97\u6cd5\u548c\u9608\u503c\u7b97\u6cd5\u7684\u6838\u5fc3\u4efb\u52a1\u662f\u5c06f(x) = f1(x) + f2(x)\u4e24\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u51fd\u6570\u878d\u5408\u540e\u8fdb\u884cTop-K\u67e5\u8be2, \u4e00\u822c\u5148\u57fa\u4e8ef1(x)\u4e0ef2(x)\u5206\u522b\u8fdb\u884c\u6392\u5e8f, \u7136\u540e\u6309\u7167\u7279\u5b9a\u7684\u7b56\u7565\u8fdb\u884c\u526a\u679d. \u4e3e\u4e00\u4e2a\u65c5\u6e38\u666f\u70b9\u9009\u62e9\u7684\u4f8b\u5b50: \u5c0f\u660e\u60f3\u53bb\u65c5\u6e38, \u670b\u53cb\u5c0f\u5f3a\u63a8\u8350\u4e86\u7b2c\u4e00\u7ec4\u666f\u70b9, \u670b\u53cb\u5c0f\u4e3d\u63a8\u8350\u4e86\u7b2c\u4e8c\u7ec4\u666f\u70b9, \u5047\u8bbe\u5c0f\u5f3a\u548c\u5c0f\u4e3d\u7684\u610f\u89c1\u540c\u6837\u91cd\u8981. \u540c\u5b66\u4eec\u80fd\u5426\u5148\u7ed9\u51fa\u4e00\u4e2a\u7b80\u5355\u7684\u89e3\u51b3\u65b9\u6848? \u666f\u70b9 | \u63a8\u8350\u6307\u65701 | \u666f\u70b9 | \u63a8\u8350\u6307\u65702 --------------------------------------------------------------------- \u4e5d\u5be8\u6c9f | 10 | \u5927\u7406 | 9 --------------------------------------------------------------------- \u5927\u7406 | 8 | \u897f\u6e56 | 7 --------------------------------------------------------------------- \u897f\u6e56 | 7 | \u4e5d\u5be8\u6c9f | 6 --------------------------------------------------------------------- \u9ec4\u5c71 | 6 | \u9ec4\u5c71 | 6 Fagin\u7b97\u6cd5: \u63a8\u8350\u6307\u65701 | \u63a8\u8350\u6307\u65702 || \u63a8\u8350\u6307\u65701 | \u63a8\u8350\u6307\u65702 || \u63a8\u8350\u6307\u65701 | \u63a8\u8350\u6307\u65702 --------------------------------------------------------------------------------------------------------- \u4e5d\u5be8\u6c9f(10) | || \u4e5d\u5be8\u6c9f(10) | || \u4e5d\u5be8\u6c9f(10) | --------------------------------------------------------------------------------------------------------- | \u5927\u7406(9) || | \u5927\u7406(9) || | \u5927\u7406(9) --------------------------------------------------------------------------------------------------------- | || \u5927\u7406(8) | \u897f\u6e56(7) || \u5927\u7406(8) | --------------------------------------------------------------------------------------------------------- | || | || | \u4e5d\u5be8\u6c9f(6) --------------------------------------------------------------------------------------------------------- \u628a\u5404\u81ea\u7684TOP1\u9009\u9879\u6dfb\u52a0\u8fdb\u5217\u8868\u4e2d || \u628a\u5404\u81ea\u7684TOP2\u9009\u9879\u6dfb\u52a0\u8fdb\u5217\u8868\u4e2d || f(\u4e5d\u5be8\u6c9f) = 10 + 6 = 16 || || f(\u5927\u7406) = 8 + 9 = 17 \u9608\u503c\u7b97\u6cd5: \u666f\u70b9 | \u666f\u70b9 | SUM || \u666f\u70b9 | \u666f\u70b9 | SUM || \u666f\u70b9 | \u666f\u70b9 | SUM ------------------------------------------------------------------------------------------------------- \u4e5d\u5be8\u6c9f | \u5927\u7406 | || \u4e5d\u5be8\u6c9f | \u5927\u7406 | || \u4e5d\u5be8\u6c9f | \u5927\u7406 | (10) | (9) | 19 || (10+6)| (9+8) | 19 || (10+6) | (9+8) | 19 ------------------------------------------------------------------------------------------------------- | | || | | || \u5927\u7406 | \u897f\u6e56 | | | || | | || (8) | (7) | 15","title":"\u5b50\u56fe\u67e5\u8be2"},{"location":"2_1.html#_6","text":"\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u4e00\u79cd\u56fe, \u53ef\u4ee5\u5728\u56fe\u4e0a\u8fdb\u884c\u8def\u5f84\u67e5\u8be2, \u5c24\u5176\u662f\u5728\u6211\u4eec\u5bf9\u67d0\u4e2a\u77e5\u8bc6\u56fe\u8c31\u4e0d\u591f\u4e86\u89e3\u7684\u60c5\u51b5\u4e0b, \u8fd9\u79cd\u6700\u77ed\u8def\u5f84\u67e5\u8be2\u63d0\u4f9b\u4e86\u4e00\u4e2a\u975e\u5e38\u7b80\u5355\u7684\u65b9\u5f0f\u6765\u63a2\u7a76\u4e24\u4e2a\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u8054\u5173\u7cfb. \u8def\u5f84\u67e5\u8be2\u4e3b\u8981\u6709\u4e24\u7c7b\u65b9\u6cd5: 1: \u5e26\u6807\u7b7e\u9650\u5236\u7684\u8def\u5f84\u67e5\u8be2 2: \u5143\u8def\u5f84\u67e5\u8be2 \u5e26\u6807\u7b7e\u9650\u5236\u7684\u8def\u5f84\u67e5\u8be2: \u4e0d\u540c\u4e8e\u4e00\u822c\u56fe, \u77e5\u8bc6\u56fe\u8c31\u4e0a\u7684\u8282\u70b9\u548c\u8fb9\u8574\u542b\u4e86\u4e30\u5bcc\u7684\u8bed\u4e49\u4fe1\u606f, \u5355\u7eaf\u8ba1\u7b97\u4e24\u4e2a\u8282\u70b9\u4e4b\u95f4\u7684\u6700\u77ed\u8def\u5f84\u7684\u5b9e\u9645\u610f\u4e49\u6709\u9650, \u66f4\u597d\u7684\u65b9\u6cd5\u662f\u5bf9\u8def\u5f84\u4e0a\u7684\u8fb9\u8fdb\u884c\u9650\u5236. \u57fa\u4e8e\u4e09\u89d2\u4e0d\u7b49\u5f0f\u53ef\u4ee5\u4f30\u8ba1\u4efb\u610f\u4e24\u4e2a\u8282\u70b9\u4e4b\u95f4\u7684\u6700\u77ed\u8def\u5f84: dist(s, t) = min{dist(s, l) + dist(l, t)} \u5143\u8def\u5f84\u67e5\u8be2: \u4e3a\u4e86\u66f4\u597d\u7684\u4f53\u73b0\u8bed\u4e49\u4fe1\u606f, \u4e00\u79cd\u66f4\u4f18\u7684\u65b9\u6cd5\u662f\u53ea\u8003\u8651\u7b26\u5408\u7279\u5b9a\u5143\u8def\u5f84(Meta Path)\u7684\u6700\u77ed\u8def\u5f84. \u5b83\u9664\u4e86\u8003\u8651\u8fb9\u4e0a\u7684\u7c7b\u578b\u9650\u5236\u5916, \u8fd8\u5bf9\u8def\u5f84\u4e0a\u8282\u70b9\u7c7b\u578b\u8fdb\u884c\u9650\u5236. \u5728\u6307\u5b9a\u4e86\u5143\u8def\u5f84\u540e, \u6700\u77ed\u8def\u5f84\u68c0\u7d22\u53ef\u4ee5\u627e\u5230\u66f4\u6709\u9488\u5bf9\u6027\u7684\u7ed3\u679c, \u8fd4\u56de\u7684\u7ed3\u679c\u4e5f\u66f4\u5177\u53ef\u89e3\u91ca\u6027.","title":"\u8def\u7ecf\u67e5\u8be2"},{"location":"2_1.html#_7","text":"\u641c\u7d22\u5f15\u64ce\u5728\u63a8\u52a8\u7f51\u7edc\u4fe1\u606f\u65f6\u4ee3\u7684\u53d1\u5c55\u4e2d\u8d77\u5230\u4e86\u5de8\u5927\u4f5c\u7528, \u5728\u641c\u7d22\u6280\u672f\u4e2d\u6700\u4e3b\u8981\u7684\u5c31\u662f\u5173\u952e\u8bcd\u67e5\u8be2. \u5173\u952e\u8bcd\u67e5\u8be2\u7279\u522b\u9002\u7528\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u573a\u666f. \u77e5\u8bc6\u56fe\u8c31\u5305\u542b\u5927\u91cf\u7684\u5b9e\u4f53\u548c\u5173\u7cfb\u5e76\u4e14\u5177\u6709\u7075\u6d3b, \u591a\u6837\u7684\u8868\u8fbe\u65b9\u5f0f, \u666e\u901a\u7528\u6237\u5f88\u96be\u6e05\u695a\u5730\u4e86\u89e3\u77e5\u8bc6\u56fe\u8c31\u4e2d\u4f7f\u7528\u7684\u5b9e\u4f53\u540d\u79f0\u548c\u8c13\u8bcd\u540d\u79f0. \u5173\u952e\u8bcd\u67e5\u8be2\u4f7f\u5f97\u7528\u6237\u65e0\u9700\u6307\u5b9a\u7cbe\u786e\u7684\u641c\u7d22\u5173\u952e\u8bcd\u5c31\u80fd\u67e5\u627e\u5230\u76f8\u5173\u77e5\u8bc6\u548c\u7ed3\u679c. \u6700\u5c0f\u65af\u5766\u7eb3\u6811(Steiner Tree): \u6700\u5c0f\u65af\u5766\u7eb3\u6811\u662f\u7ec4\u5408\u4f18\u5316\u4e2d\u7684\u4e00\u4e2a\u7ecf\u5178\u95ee\u9898, \u662f\u6307\u4ece\u8f93\u5165\u56fe\u4e2d\u627e\u5230\u4e00\u4e2a\u4f7f\u5f97\u7ed9\u5b9a\u7684\u6240\u6709\u8282\u70b9\u96c6\u5408\u8fde\u901a\u5e76\u4e14\u8fb9\u6743\u603b\u548c\u6700\u5c0f\u7684\u5b50\u6811. \u5bf9\u4e8e\u77e5\u8bc6\u56fe\u8c31\u4e0a\u7684\u5173\u952e\u8bcd\u67e5\u8be2, \u4e0e\u5173\u952e\u8bcd\u5339\u914d\u7684\u8282\u70b9\u96c6\u5408\u5c31\u662f\u8f93\u5165\u8282\u70b9\u96c6\u5408, \u8f93\u51fa\u4e3a\u7531\u8fd9\u4e9b\u8282\u70b9\u6784\u6210\u7684\u6700\u5c0f\u65af\u5766\u7eb3\u6811. \u6c42\u89e3\u7b97\u6cd5: \u679a\u4e3eV-U\u7684\u5b50\u96c6S (V\u662f\u56feG\u7684\u8282\u70b9\u96c6\u5408, U\u662f\u7ed9\u5b9a\u7684\u5173\u952e\u8bcd\u8282\u70b9\u96c6\u5408), \u7279\u522b\u6ce8\u610fS\u53ef\u80fd\u4e3a\u7a7a\u96c6, \u57fa\u4e8e\u70b9\u96c6U U S\u6c42\u89e3\u6700\u5c0f\u751f\u6210\u6811, \u5728\u6240\u6709\u7684\u6700\u5c0f\u751f\u6210\u6811\u4e2d, \u6743\u91cd\u6700\u5c0f\u7684\u90a3\u68f5\u6811\u5373\u4e3a\u6700\u5c0f\u65af\u5766\u7eb3\u6811. \u7f3a\u9677: \u5173\u952e\u8bcd\u67e5\u8be2\u867d\u7136\u7b80\u5355, \u6613\u7528, \u4f46\u662f\u5b83\u7684\u8bed\u4e49\u8868\u8fbe\u80fd\u529b\u76f8\u5bf9\u6709\u9650. \u4f20\u7edf\u7684\u5173\u952e\u8bcd\u67e5\u8be2\u7814\u7a76\u4e00\u822c\u66f4\u5173\u6ce8\u67e5\u8be2\u7684\u6548\u7387, \u5728\u610f\u56fe\u5efa\u6a21\u4e0e\u7406\u89e3\u65b9\u9762\u505a\u7684\u4e0d\u591a.","title":"\u5173\u952e\u8bcd\u67e5\u8be2"},{"location":"2_1.html#_8","text":"\u793e\u56e2\u7ed3\u6784\u5e7f\u6cdb\u5b58\u5728\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7b49\u5f88\u591a\u771f\u5b9e\u7684\u590d\u6742\u7f51\u7edc\u4e2d, \u4e00\u822c\u800c\u8a00, \u793e\u56e2\u662f\u6307\u4e00\u7ec4\u5185\u90e8\u4e92\u76f8\u7d27\u5bc6\u8054\u7cfb\u7684\u8282\u70b9, \u5b83\u4eec\u4e0e\u793e\u56e2\u4e4b\u5916\u8282\u70b9\u7684\u8054\u7cfb\u76f8\u5bf9\u677e\u6563. \u901a\u5e38\u793e\u56e2\u5185\u7684\u7d27\u5bc6\u7a0b\u5ea6\u4ee5\u8be5\u5b50\u7ed3\u6784\u7684\u5e73\u5747\u5ea6\u6570\u6216\u8005\u8282\u70b9\u7684\u6700\u5c0f\u5ea6\u6570\u4f5c\u4e3a\u8861\u91cf\u4f9d\u636e. \u4f20\u7edf\u7684\u793e\u56e2\u641c\u7d22\u5206\u4e3a\u4e24\u5927\u7c7b\u4efb\u52a1: \u793e\u56e2\u6316\u6398 \u793e\u56e2\u67e5\u8be2 \u793e\u56e2\u6316\u6398: \u662f\u6307\u7ed9\u5b9a\u56feG\u548c\u7279\u5b9a\u7684\u793e\u56e2\u5ea6\u91cf\u6807\u51c6, \u627e\u51fa\u5176\u4e2d\u6240\u6709\u7684\u793e\u56e2. \u793e\u56e2\u6316\u6398\u6548\u7387\u8f83\u4f4e, \u901a\u5e38\u9700\u8981\u79bb\u7ebf\u5904\u7406. \u793e\u56e2\u67e5\u8be2: \u662f\u6307\u9884\u5148\u7ed9\u5b9a\u56feG\u548c\u7279\u5b9a\u7684\u793e\u56e2\u5ea6\u91cf\u6807\u51c6, \u4e3a\u67d0\u4e2a\u67e5\u8be2\u8282\u70b9\u627e\u5230\u5305\u542b\u8be5\u8282\u70b9\u7684\u793e\u56e2, \u4e5f\u79f0\u4e3a\u4e2a\u6027\u5316\u793e\u56e2\u53d1\u73b0. \u793e\u56e2\u67e5\u8be2\u662f\u4e00\u79cd\u5178\u578b\u7684\u6309\u9700\u670d\u52a1, \u901a\u5e38\u901a\u8fc7\u5728\u7ebf\u5904\u7406\u7684\u5f62\u5f0f\u5b8c\u6210.","title":"\u793e\u56e2\u67e5\u8be2"},{"location":"2_1.html#_9","text":"\u9996\u5148\u5b66\u4e60\u4e86\u77e5\u8bc6\u67e5\u8be2\u76844\u4e2a\u4e3b\u6d41\u8bed\u8a00: SQL SPARQL Gremlin Cypher \u63a5\u4e0b\u6765\u6df1\u5165\u63a2\u8ba8\u4e86\u77e5\u8bc6\u67e5\u8be2\u76844\u4e2a\u4e3b\u6d41\u65b9\u6cd5: \u5b50\u56fe\u67e5\u8be2 \u8def\u5f84\u67e5\u8be2 \u5173\u952e\u8bcd\u67e5\u8be2 \u793e\u56e2\u67e5\u8be2","title":"\u5c0f\u8282\u603b\u7ed3"},{"location":"2_2.html","text":"\u77e5\u8bc6\u56fe\u8c31\u7684\u6570\u503c\u8868\u793a \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u77e5\u8bc6\u56fe\u8c31\u6709\u54ea\u4e9b\u91cd\u8981\u7684\u6570\u503c\u8868\u793a\u65b9\u6cd5. \u7406\u89e3\u77e5\u8bc6\u56fe\u8c31\u76f8\u5173\u6570\u503c\u8868\u793a\u7684\u65b9\u6cd5. \u6570\u503c\u8868\u793a\u6982\u8ff0 \u00b6 \u968f\u7740\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb, \u5982\u4f55\u5c06\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u80cc\u666f\u77e5\u8bc6\u878d\u5408\u8fdb\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u6280\u672f\u95ee\u9898. \u57fa\u672c\u7684\u601d\u8def\u662f\u5c06\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u70b9\u4e0e\u8fb9\u8868\u793a\u6210\u6570\u503c\u5316\u7684\u5411\u91cf. \u4e0d\u540c\u7684\u5411\u91cf\u8868\u793a\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u6709\u7740\u4e0d\u540c\u7684\u6548\u679c, \u5982\u4f55\u5c06\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\u548c\u5173\u7cfb\u6c42\u5f97\u6700\u4f18\u7684\u5411\u91cf\u5316\u8868\u793a, \u662f\u5f53\u524d\u77e5\u8bc6\u56fe\u8c31\u8868\u793a\u5b66\u4e60\u6240\u5173\u6ce8\u7684\u6838\u5fc3\u95ee\u9898. \u77e5\u8bc6\u56fe\u8c31\u7684\u8868\u793a\u5b66\u4e60\u65e8\u5728\u5c06\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5143\u7d20(\u5305\u62ec\u5b9e\u4f53, \u5c5e\u6027, \u6982\u5ff5\u7b49)\u8868\u793a\u4e3a\u4f4e\u7ef4\u7a20\u5bc6\u5b9e\u6570\u5411\u91cf. \u77e5\u8bc6\u56fe\u8c31\u7684\u5411\u91cf\u5316\u8868\u793a\u662f\u9762\u5411\u673a\u5668\u5904\u7406\u7684, \u800c\u7b26\u53f7\u5316\u8868\u793a\u662f\u9762\u5411\u4eba\u7684\u7406\u89e3\u7684. \u76f8\u5bf9\u4e8e\u5411\u91cf\u5316\u8868\u793a, \u7b26\u53f7\u5316\u8868\u793a\u6613\u4e8e\u7406\u89e3, \u53ef\u4ee5\u5b9e\u73b0\u7b26\u53f7\u63a8\u7406. \u4e24\u79cd\u8868\u793a\u5404\u6709\u5176\u9002\u7528\u7684\u573a\u666f. \u57fa\u4e8e\u8ddd\u79bb\u7684\u6a21\u578b \u00b6 \u57fa\u4e8e\u8ddd\u79bb\u7684\u6a21\u578b\u4e2d, \u6700\u5177\u4ee3\u8868\u6027\u7684\u662fSE\u6a21\u578b, \u57fa\u672c\u601d\u60f3: \u5f53\u4e24\u4e2a\u5b9e\u4f53\u5c5e\u4e8e\u540c\u4e00\u4e2a\u4e09\u5143\u7ec4\u65f6, \u5b83\u4eec\u7684\u5411\u91cf\u8868\u793a\u5728\u6295\u5f71\u540e\u7684\u7a7a\u95f4\u4e2d\u4e5f\u5e94\u8be5\u5f7c\u6b64\u9760\u8fd1. \u56e0\u6b64\u635f\u5931\u51fd\u6570\u88ab\u5b9a\u4e49\u4e3a\u5411\u91cf\u6295\u5f71\u540e\u7684\u8ddd\u79bb. \u6ce8\u610f: SE\u6a21\u578b\u91c7\u7528\u5f62\u5f0f\u8f83\u4e3a\u7b80\u5355\u7684L1\u8303\u6570, \u4e24\u4e2a\u77e9\u9635W(r,1)\u548cW(r,2)\u7528\u4e8e\u4e09\u5143\u7ec4\u4e2d\u5934\u5b9e\u4f53\u5411\u91cfh\u548c\u5c3e\u5b9e\u4f53\u5411\u91cft\u7684\u6295\u5f71\u64cd\u4f5c. \u4f46\u7531\u4e8eSE\u6a21\u578b\u5f15\u5165\u4e86\u4e24\u4e2a\u4e0d\u540c\u7684\u6295\u5f71\u77e9\u9635, \u5bfc\u81f4\u5f88\u96be\u6355\u83b7\u5b9e\u4f53\u548c\u5173\u7cfb\u4e4b\u95f4\u7684\u8bed\u4e49\u76f8\u5173\u6027! \u57fa\u4e8e\u7ffb\u8bd1\u7684\u6a21\u578b \u00b6 TransE\u6a21\u578b \u00b6 TransE\u6a21\u578b: \u662f\u57fa\u4e8e\u7ffb\u8bd1\u601d\u60f3\u7684\u6a21\u578b. TransE\u8ba4\u4e3a\u5728\u77e5\u8bc6\u5e93\u4e2d, \u4e09\u5143\u7ec4< h, r, t >\u53ef\u4ee5\u770b\u6210\u5934\u5b9e\u4f53h\u5230\u5c3e\u5b9e\u4f53t\u5229\u7528\u5173\u7cfbr\u6240\u8fdb\u884c\u7684\u7ffb\u8bd1. \u4f8b\u5982: \u5bf9\u4e8e\u4e09\u5143\u7ec4<\u67cf\u62c9\u56fe, \u8001\u5e08, \u82cf\u683c\u62c9\u5e95>, \u5934\u5b9e\u4f53\"\u67cf\u62c9\u56fe\"\u7684\u5411\u91cf\u52a0\u4e0a\u5173\u7cfb\"\u8001\u5e08\"\u7684\u5411\u91cf, \u5e94\u8be5\u5c3d\u53ef\u80fd\u548c\u5c3e\u5b9e\u4f53\"\u82cf\u683c\u62c9\u5e95\"\u7684\u5411\u91cf\u63a5\u8fd1. \u635f\u5931\u51fd\u6570\u5373\u53ef\u5f97\u5230: \u6ce8\u610f: \u5b9e\u9645\u5e94\u7528\u4e2d, \u4e3a\u4e86\u589e\u52a0\u533a\u5206\u5ea6, TransE\u6a21\u578b\u4f7f\u7528\u4e86Hinge Loss\u76ee\u6807\u51fd\u6570, \u901a\u8fc7\u5f15\u5165Max Margin\u673a\u5236\u4f7f\u5f97\u6b63\u8d1f\u4f8b\u5c3d\u53ef\u80fd\u5206\u5f00. TransH\u6a21\u578b \u00b6 \u8003\u8651\u5230TransE\u6a21\u578b\u4e2d\u7684h + r ~ t\u5047\u8bbe\u592a\u5f3a, \u5bfc\u81f4\u5728\u81ea\u53cd, \u4e00\u5bf9\u591a, \u591a\u5bf9\u4e00\u5173\u7cfb\u4e0b\u5b9e\u4f53\u5411\u91cf\u5b66\u4e60\u7684\u9519\u8bef. \u6bd4\u5982, \u5bf9\u4e8e\u81ea\u53cd\u5173\u7cfbr, < h, r, t > \u548c < t, r, h >\u540c\u65f6\u6210\u7acb, \u5bfc\u81f4h = t. \u5bf9\u4e8e\u591a\u5bf9\u4e00\u5173\u7cfb, \u6bd4\u5982<\u67cf\u62c9\u56fe, \u6027\u522b, \u7537>, <\u7279\u6717\u666e, \u6027\u522b, \u7537>\u8fd9\u4e24\u4e2a\u4e09\u5143\u7ec4\u6709\u7740\u76f8\u540c\u7684\u5173\u7cfb\u548c\u5c3e\u5b9e\u4f53, \u4ece\u800c\u5bfc\u81f4\u67cf\u62c9\u56fe\u548c\u7279\u6717\u666e\u5411\u91cf\u975e\u5e38\u63a5\u8fd1(\u4e00\u5bf9\u591a\u7684\u5173\u7cfb\u7c7b\u4f3c). \u4f46\u662f\u67cf\u62c9\u56fe\u4e0e\u7279\u6717\u666e\u9664\u4e86\u5728\u6027\u522b\u4e0a\u76f8\u540c, \u5176\u4ed6\u65b9\u9762\u663e\u7136\u5b8c\u5168\u4e0d\u540c. TransH\u6a21\u578b: \u4e3a\u4e86\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898, TransH\u6a21\u578b\u653e\u5bbd\u4e86h + r ~ t\u8fd9\u4e00\u4e25\u683c\u5047\u8bbe, \u53ea\u8981\u6c42\u5934\u5c3e\u5b9e\u4f53\u5728\u5173\u7cfbr\u76f8\u5bf9\u5e94\u7684\u8d85\u5e73\u9762\u4e0a\u7684\u6295\u5f71\u5f7c\u6b64\u63a5\u8fd1\u5373\u53ef: \u5934\u5b9e\u4f53\u5411\u91cfh\u548c\u5c3e\u5b9e\u4f53\u5411\u91cft\u5728\u8d85\u5e73\u9762\u4e0a\u5229\u7528\u6cd5\u5411\u91cfWr\u6620\u5c04\u4e3a\u4e24\u4e2a\u65b0\u7684\u5411\u91cf: \u5173\u7cfbr\u5728\u8d85\u5e73\u9762\u4e0a\u7684\u5411\u91cf\u8868\u793a\u4e3adr, \u56e0\u6b64TransH\u7684\u76ee\u6807\u51fd\u6570\u4e3a: TransR\u6a21\u578b \u00b6 \u5728TransE\u548cTransH\u6a21\u578b\u4e2d, \u5b9e\u4f53\u548c\u5173\u7cfb\u90fd\u5728\u76f8\u540c\u7684\u7a7a\u95f4\u4e2d\u8fdb\u884c\u8868\u793a. \u8fd9\u79cd\u505a\u6cd5\u65e0\u6cd5\u533a\u5206\u4e24\u4e2a\u8bed\u4e49\u76f8\u8fd1\u7684\u5b9e\u4f53\u5728\u67d0\u4e9b\u7279\u5b9a\u65b9\u9762(\u5173\u7cfb)\u4e0a\u7684\u4e0d\u540c. \u6bd4\u5982\"\u9a6c\u514b\u601d\"\u548c\"\u6069\u683c\u65af\"\u53ef\u4ee5\u8ba4\u4e3a\u662f\u4e24\u4e2a\u76f8\u4f3c\u7684\u5b9e\u4f53, \u4f46\u662f<\u9a6c\u514b\u601d, \u6c11\u65cf, \u72b9\u592a\u65cf>\u548c<\u6069\u683c\u65af, \u6c11\u65cf, \u5fb7\u610f\u5fd7\u65cf>\u4e0d\u540c. TransR\u6a21\u578b: \u8003\u8651\u5230\u4e0a\u8ff0\u95ee\u9898, TrasnR\u6a21\u578b\u63d0\u51fa\u4e3a\u6bcf\u4e2a\u5173\u7cfb\u6784\u9020\u76f8\u5e94\u7684\u5411\u91cf\u7a7a\u95f4, \u5c06\u5b9e\u4f53\u4e0e\u5173\u7cfb\u5728\u4e0d\u540c\u7684\u5411\u91cf\u7a7a\u95f4\u4e2d\u5206\u5f00\u8868\u793a. TransR\u57fa\u672c\u601d\u60f3: \u4e0eTransH\u7684\u57fa\u672c\u601d\u60f3\u5f88\u76f8\u4f3c, \u8981\u6c42\u5934\u5c3e\u5b9e\u4f53\u5728\u5173\u7cfbr\u76f8\u5bf9\u5e94\u7684\u5411\u91cf\u7a7a\u95f4\u4e2d\u7684\u6295\u5f71\u5f7c\u6b64\u63a5\u8fd1\u5373\u53ef.(\u5728TransH\u4e2d\u662f\u8d85\u5e73\u9762) TransR\u6a21\u578b\u5c06\u5934\u5b9e\u4f53\u5411\u91cfh\u548c\u5c3e\u5b9e\u4f53\u5411\u91cft\u6620\u5c04\u4e3a\u4e24\u4e2a\u65b0\u5411\u91cf: TransR\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\u4e3a: TransD\u6a21\u578b \u00b6 TransR\u6a21\u578b\u5c06\u5b9e\u4f53\u548c\u5173\u7cfb\u5728\u4e0d\u540c\u7684\u5411\u91cf\u7a7a\u95f4\u4e2d\u8868\u793a, \u8fd9\u4e5f\u5e26\u6765\u4e86\u4e00\u4e9b\u65b0\u95ee\u9898: \u7b2c\u4e00: TransR\u6a21\u578b\u5229\u7528\u590d\u6742\u7684\u77e9\u9635\u8ba1\u7b97\u5c06\u5934\u5c3e\u5b9e\u4f53\u6620\u5c04\u5230\u5173\u7cfb\u5411\u91cf\u7a7a\u95f4\u4e2d, \u589e\u52a0\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6. \u7b2c\u4e8c: \u5bf9\u4e8e\u4e00\u4e2a\u4e09\u5143\u7ec4\u6765\u8bf4, \u5934\u5b9e\u4f53\u548c\u5c3e\u5b9e\u4f53\u5f88\u53ef\u80fd\u4e0d\u662f\u4e00\u7c7b\u5b9e\u4f53, \u6bd4\u5982<\u67cf\u62c9\u56fe, \u51fa\u751f\u5730, \u5e0c\u814a>, \u90a3\u4e48\"\u67cf\u62c9\u56fe\"\u548c\"\u5e0c\u814a\"\u662f\u4e24\u7c7b\u4e0d\u540c\u7684\u5b9e\u4f53, \u4f7f\u7528\u76f8\u540c\u7684\u6620\u5c04\u77e9\u9635Mr\u5f88\u660e\u663e\u4e0d\u5408\u7406. \u7b2c\u4e09: TransR\u6a21\u578b\u4e2d\u5b9e\u4f53\u7684\u6620\u5c04\u5173\u7cfb\u4ec5\u6709\u5173\u7cfb\u51b3\u5b9a, \u4f46\u663e\u7136\u5b9e\u4f53\u672c\u8eab\u5bf9\u6620\u5c04\u4e5f\u6709\u5f71\u54cd. TransD\u6a21\u578b: \u8003\u8651\u5230\u4e0a\u8ff0\u95ee\u9898, TransD\u6a21\u578b\u8ba4\u4e3a\u6620\u5c04\u51fd\u6570\u5e94\u8be5\u4e0e\u5b9e\u4f53, \u5173\u7cfb\u540c\u65f6\u76f8\u5173! TransD\u6a21\u578b\u4fee\u6539\u4e86\u6620\u5c04\u51fd\u6570: I(m*n)\u662f\u5355\u4f4d\u77e9\u9635, \u5934\u5b9e\u4f53\u548c\u5c3e\u5b9e\u4f53\u5206\u522b\u7528\u4e24\u4e2a\u4e0d\u540c\u7684\u6620\u5c04\u77e9\u9635M(rh)\u548cM(rt)\u8fdb\u884c\u6295\u5f71. \u5934\u5b9e\u4f53\u7684\u6620\u5c04\u77e9\u9635\u7531\u5173\u7cfb\u5411\u91cfrp\u4e0e\u5934\u5b9e\u4f53\u6620\u5c04\u5411\u91cfhp\u5171\u540c\u51b3\u5b9a; \u5c3e\u5b9e\u4f53\u7684\u6620\u5c04\u77e9\u9635\u7531\u5173\u7cfb\u5411\u91cfrp\u4e0e\u5c3e\u5b9e\u4f53\u6620\u5c04\u5411\u91cftp\u5171\u540c\u51b3\u5b9a: \u6700\u7ec8, TransD\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\u4e3a: \u5176\u4ed6\u77e5\u8bc6\u8868\u793a\u65b9\u5f0f \u00b6 \u8c13\u8bcd\u903b\u8f91 \u00b6 Predicate Logic: \u547d\u9898\u662f\u4e00\u4e2a\u975e\u771f\u5373\u5047\u7684\u9648\u8ff0. \u6bd4\u5982, \"\u4e9a\u91cc\u58eb\u591a\u5fb7\u51fa\u751f\u4e8e\u6ce2\u4f0a\u63d0\u4e4c\"\u5c31\u662f\u4e00\u4e2a\u547d\u9898. \u547d\u9898\u53ef\u4ee5\u901a\u8fc7\u8c13\u8bcd>\u6765\u8868\u8fbe, \u8c13\u8bcd\u7684\u4e00\u822c\u5f62\u5f0f\u662fP(x1, x2, ..., xn). \u5176\u4e2d, P\u662f\u8c13\u8bcd\u7684\u540d\u79f0, xi\u662f\u8c13\u8bcd\u7684\u9879. xi\u65e2\u53ef\u4ee5\u662f\u4e00\u4e2a\u5e38\u91cf(\u4e9a\u91cc\u58eb\u591a\u5fb7), \u4e5f\u53ef\u4ee5\u662f\u4e00\u4e2a\u53d8\u91cf. \u5728\u67d0\u4e2a\u7279\u5b9a\u9886\u57df, \u8c13\u8bcdP\u53ef\u4ee5\u8868\u8fbe\u9886\u57df\u5bf9\u8c61\u4e4b\u95f4\u7684\u5173\u7cfb, \u4e5f\u53ef\u4ee5\u8868\u8fbe\u51fd\u6570. \u6bd4\u5982, BirthPlace(\u4e9a\u91cc\u58eb\u591a\u5fb7, \u6ce2\u4f0a\u63d0\u4e4c)\u8868\u8fbe\u4e86\"\u4e9a\u91cc\u58eb\u591a\u5fb7\u51fa\u751f\u4e8e\u6ce2\u4f0a\u63d0\u4e4c\", \u5b9e\u8d28\u4e0a\u8868\u8fbe\u4e86\u4e9a\u91cc\u58eb\u591a\u5fb7\u548c\u6ce2\u4f0a\u63d0\u4e4c\u4e4b\u95f4\u7684\u5173\u7cfb. Philosopher(\u4e9a\u91cc\u58eb\u591a\u5fb7)\u8868\u793a\u4e9a\u91cc\u58eb\u591a\u5fb7\u662f\u4e00\u4e2a\u54f2\u5b66\u5bb6\u8fd9\u4e00\u4e8b\u5b9e, Philosopher(x)\u662f\u4e00\u4e2a\u51fd\u6570. \u5728\u8c13\u8bcd\u4e0a\u53ef\u4ee5\u65bd\u52a0\u4e0d\u540c\u7684\u64cd\u4f5c: \u5426\u5b9a(Negative) \u6790\u53d6(Disjunction) \u5408\u53d6(Conjunction) \u8574\u542b(Implication) \u4e3a\u4e86\u8fdb\u4e00\u6b65\u523b\u753b\u8c13\u8bcd\u548c\u4e2a\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb, \u5728\u8c13\u8bcd\u903b\u8f91\u4e2d\u5f15\u5165\u4e24\u4e2a\u91cf\u8bcd: \u5168\u79f0\u91cf\u8bcd (Universal Quantifier) \u5b58\u5728\u91cf\u8bcd (Existential Quantifier) \u4ea7\u751f\u5f0f\u89c4\u5219 \u00b6 Production Rule: \u4ea7\u751f\u5f0f\u89c4\u5219\u5e38\u7528\u4e8e\u8868\u793a\u4e8b\u5b9e\u4e0e\u89c4\u5219, \u4ee5\u53ca\u76f8\u5e94\u7684\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf. \u4ea7\u751f\u5f0f\u89c4\u5219\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5f62\u5f0f\u8bed\u8a00\u8bed\u6cd5\u63cf\u8ff0, \u81ea\u52a8\u89c4\u5212, \u4e13\u5bb6\u7cfb\u7edf, \u52a8\u4f5c\u9009\u62e9\u7b49. \u4ea7\u751f\u5f0f\u89c4\u5219\u662f\u4e00\u79cd\u5f62\u5982\"\u6761\u4ef6-\u52a8\u4f5c\"\u7684\u89c4\u5219, \u57fa\u672c\u5f62\u5f0f\u5982\u4e0b: IF < condition > THEN < conclusion > \u6ce8\u610f: \u4e0a\u8ff0\u516c\u5f0f\u4e2d, condition\u88ab\u79f0\u4e3a\u524d\u4ef6, \u8868\u793a\u524d\u63d0\u6761\u4ef6, \u5404\u4e2a\u6761\u4ef6\u53ef\u4ee5\u5229\u7528\u5408\u53d6, \u6790\u53d6\u7b49\u903b\u8f91\u8fde\u63a5\u8bcd\u8fdb\u884c\u4e0d\u540c\u7684\u7ec4\u5408; conclusion\u88ab\u79f0\u4e3a\u540e\u4ef6, \u8868\u793a\u5f53\u524d\u6761\u4ef6\u4e3a\u771f\u65f6, \u5e94\u91c7\u53d6\u7684\u52a8\u4f5c! R1: IF \u75c5\u4eba\u53d1\u70e7 AND \u54b3\u55fd THEN \u75c5\u4eba\u5f97\u4e86\u75c5\u6bd2\u6027\u611f\u5192 \u5f88\u591a\u4ea7\u751f\u5f0f\u89c4\u5219\u5177\u6709\u4e0d\u786e\u5b9a\u6027. \u6bd4\u5982, R2\u8868\u8fbe\u4e86\u4e00\u4e2a\u5177\u6709\u957f\u671f\u5438\u70df\u53f2\u7684\u75c5\u4eba\u7f79\u60a3\u80ba\u90e8\u75be\u75c5\u7684\u6982\u7387\u9ad8\u8fbe0.9: R2: IF \u75c5\u4eba\u5177\u6709\u957f\u671f\u5438\u70df\u53f2 THEN \u8be5\u75c5\u4eba\u7f79\u60a3\u80ba\u90e8\u75be\u75c5(0.9) \u4ea7\u751f\u5f0f\u89c4\u5219\u4e0e\u903b\u8f91\u8574\u542b\u6709\u7740\u76f8\u540c\u7684\u57fa\u672c\u5f62\u5f0f, \u4f46\u662f\u5728\u8bed\u4e49\u4e0a, \u903b\u8f91\u8574\u542bP=>Q\u53ea\u80fd\u8868\u8fbe\u5982\u679c\u547d\u9898P\u4e3a\u771f, \u5219Q\u4e00\u5b9a\u4e3a\u771f. \u4ea7\u751f\u5f0f\u89c4\u5219\u7684\u540e\u4ef6\u90e8\u5206\u4e0d\u4ec5\u53ef\u4ee5\u662f\u547d\u9898, \u8fd8\u53ef\u4ee5\u662f\u52a8\u4f5c. \u6bd4\u5982, R3\u7684\u540e\u4ef6\u5c31\u662f\u4e00\u4e2a\u52a8\u4f5c\u800c\u975e\u547d\u9898. R3: IF \u75c5\u4eba\u5f97\u4e86\u75c5\u6bd2\u6027\u611f\u5192 THEN \u7ed9\u4e88\u6297\u75c5\u6bd2\u6cbb\u7597 \u57fa\u4e8e\u7ed9\u5b9a\u7684\u4e00\u7ec4\u57fa\u672c\u4e8b\u5b9e\u548c\u4e00\u7ec4\u4ea7\u751f\u5f0f\u89c4\u5219(\u901a\u5e38\u53c8\u88ab\u79f0\u4e3a\u89c4\u5219\u5e93), \u6211\u4eec\u5c31\u53ef\u4ee5\u8fdb\u884c\u63a8\u7406\u4ee5\u6c42\u89e3\u95ee\u9898. \u8fd9\u5c31\u662f\u4ea7\u751f\u5f0f\u7cfb\u7edf\u7684\u57fa\u672c\u601d\u60f3. \u6bd4\u5982, \u53ef\u4ee5\u5b9a\u4e49\u4e00\u5957\u52a8\u7269\u8bc6\u522b\u7684\u89c4\u5219, \u4ece\u67d0\u4e2a\u52a8\u7269\u7684\u57fa\u672c\u7279\u5f81\u63cf\u8ff0\u51fa\u53d1, \u9009\u62e9\u5339\u914d\u89c4\u5219(\u4e0e\u524d\u4ef6\u90e8\u5206\u7684\u5339\u914d)\u8fdb\u884c\u63a8\u7406, \u5c06\u8fd9\u6837\u7684\u8fc7\u7a0b\u6301\u7eed\u4e0b\u53bb\u76f4\u81f3\u6ee1\u8db3\u63a8\u7406\u7684\u7ec8\u6b62\u6761\u4ef6. \u4ea7\u751f\u5f0f\u89c4\u5219\u662f\u4e00\u79cd\u81ea\u7136\u7684, \u6e05\u6670\u7684, \u53ef\u6269\u5c55\u7684\u77e5\u8bc6\u8868\u793a. \u64c5\u957f\u8868\u8fbe\u5177\u6709\u56e0\u679c\u5173\u7cfb\u7684\u8fc7\u7a0b\u6027\u77e5\u8bc6, \u5728\u533b\u7597\u8bca\u65ad, \u6545\u969c\u8bca\u65ad\u7b49\u5e94\u7528\u4e2d\u5e38\u80fd\u53d6\u5f97\u4e00\u5b9a\u7684\u6548\u679c, \u4f46\u662f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u4f1a\u78b0\u5230\u89c4\u5219\u51b2\u7a81, \u89c4\u5219\u5931\u914d\u7b49\u96be\u9898. \u603b\u4f53\u800c\u8a00, \u4ea7\u751f\u5f0f\u89c4\u5219\u6709\u5176\u4f7f\u7528\u573a\u666f, \u4f46\u4e0d\u8db3\u4ee5\u8868\u8fbe\u73b0\u5b9e\u4e16\u754c\u7684\u590d\u6742\u8bed\u4e49, \u8fd8\u9700\u8981\u540c\u5f88\u591a\u5176\u4ed6\u77e5\u8bc6\u8868\u793a\u534f\u540c\u8fd0\u7528\u624d\u80fd\u8f83\u597d\u7684\u843d\u5730. \u6846\u67b6\u8868\u793a \u00b6 Frame: \u6846\u67b6\u8868\u793a\u662f\u4ee5\u6846\u67b6\u7406\u8bba\u4e3a\u57fa\u7840\u53d1\u5c55\u8d77\u6765\u7684\u4e00\u79cd\u7ed3\u6784\u5316\u7684\u77e5\u8bc6\u8868\u793a. \u6846\u67b6\u7406\u8bba\u8ba4\u4e3a, \u4eba\u7c7b\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e2d\u5404\u7c7b\u4e8b\u7269\u7684\u8ba4\u77e5\u90fd\u662f\u4ee5\u6846\u67b6\u7684\u7ed3\u6784\u5b58\u50a8\u5728\u8bb0\u5fc6\u4e2d\u7684. \u5f53\u4eba\u9762\u4e34\u65b0\u7684\u60c5\u5883\u65f6, \u4f1a\u4ece\u8bb0\u5fc6\u4e2d\u627e\u51fa\u4e00\u4e2a\u5408\u9002\u7684\u6846\u67b6, \u5e76\u6839\u636e\u5b9e\u9645\u60c5\u51b5\u5bf9\u8fd9\u4e00\u6846\u67b6\u7684\u7ec6\u8282\u8fdb\u884c\u52a0\u5de5, \u4fee\u6539, \u8865\u5145, \u5f62\u6210\u5bf9\u65b0\u60c5\u666f\u7684\u8ba4\u8bc6\u5e76\u5b58\u5165\u4eba\u8111\u4e2d. \u6846\u67b6\u662f\u4e00\u79cd\u63cf\u8ff0\u6240\u8bba\u5bf9\u8c61(\u4e8b\u7269, \u65f6\u95f4, \u6982\u5ff5)\u5c5e\u6027\u7684\u6570\u636e\u7ed3\u6784. \u6846\u67b6\u901a\u5e38\u7531\u63cf\u8ff0\u4e8b\u7269\u7684\u5404\u4e2a\u65b9\u9762\u7684\u69fd(Slot)\u7ec4\u6210. \u69fd\u7528\u4e8e\u63cf\u8ff0\u6240\u8bba\u5bf9\u8c61\u67d0\u4e00\u65b9\u9762\u7684\u5c5e\u6027. \u6bcf\u4e00\u4e2a\u69fd\u53ef\u4ee5\u62e5\u6709\u591a\u4e2a\u4fa7\u9762(Facet). \u6bcf\u4e2a\u4fa7\u9762\u53ef\u4ee5\u63cf\u8ff0\u76f8\u5e94\u5c5e\u6027\u7684\u4e00\u4e2a\u65b9\u9762, \u800c\u4e14\u6bcf\u4e2a\u4fa7\u9762\u53ef\u4ee5\u62e5\u6709\u591a\u4e2a\u503c. \u69fd\u548c\u4fa7\u9762\u6240\u5177\u6709\u7684\u5c5e\u6027\u503c\u5206\u522b\u88ab\u79f0\u4e3a\u69fd\u503c\u548c\u4fa7\u9762\u503c. \u9664\u4e86\u69fd, \u4fa7\u9762\u53ca\u5176\u503c\u4e4b\u5916, \u5728\u6846\u67b6\u4e2d\u8fd8\u53ef\u4ee5\u5b9a\u4e49\u7ea6\u675f, \u7528\u4e8e\u7ea6\u675f\u69fd\u548c\u4fa7\u9762\u7684\u5408\u7406\u53d6\u503c: < \u6846\u67b6\u540d > < \u69fd\u540d1 > : < \u4fa7\u976211 > : < \u503c111, \u503c112, ... , \u503c11k1 > ...... < \u4fa7\u97621m > : < \u503c1m1, \u503c1m2, ... , \u503c1mkm > < \u69fd\u540d2 > : < \u4fa7\u976221 > : < \u503c211, \u503c212, ... , \u503c21k1 > ...... < \u4fa7\u97622m > : < \u503c2m1, \u503c2m2, ... , \u503c2mkm > < \u7ea6\u675f > : < \u7ea6\u675f1 > ...... < \u7ea6\u675fm > \u4e0b\u56fe\u5c55\u793a\u4e86\u4e00\u4e2a\"\u54f2\u5b66\u5bb6\"\u7684\u6846\u67b6\u793a\u4f8b: \u6846\u67b6\u540d: < \u54f2\u5b66\u5bb6 > \u7c7b\u5c5e: < \u4eba\u7269 > \u5de5\u4f5c: \u8303\u56f4: (\u6559\u5b66, \u7814\u7a76) \u9ed8\u8ba4\u503c: \u7814\u7a76 \u6027\u522b: (\u7537, \u5973) \u7c7b\u578b: (< \u552f\u7269\u4e3b\u4e49\u54f2\u5b66\u5bb6 >, < \u552f\u5fc3\u4e3b\u4e49\u54f2\u5b66\u5bb6 >) \u6ce8\u610f: \u69fd\u6216\u8005\u4fa7\u9762\u7684\u53d6\u503c\u53ef\u4ee5\u662f\u53e6\u4e00\u4e2a\u6846\u67b6. \u6846\u67b6\u4e4b\u95f4\u7684\u76f8\u4e92\u5f15\u7528\u53ef\u4ee5\u5b9e\u73b0\u6846\u67b6\u8868\u793a\u7684\u590d\u7528. \u6846\u67b6\u4e4b\u95f4\u53ef\u4ee5\u5b9a\u4e49isA\u5173\u7cfb, \u6bd4\u5982< \u54f2\u5b66\u5bb6 >\u6846\u67b6\u662f< \u804c\u4e1a >\u7684\u5b50\u6846\u67b6. \u6846\u67b6\u5728\u5f53\u524d\u7684\u5927\u6570\u636e\u77e5\u8bc6\u56fe\u8c31\u5de5\u7a0b\u80cc\u666f\u4e0b\u5bf9\u4e8e\u7406\u89e3\u6587\u672c\u63cf\u8ff0\u7684\u4e8b\u4ef6\u6570\u636e\u6781\u4e3a\u91cd\u8981. \u4e92\u8054\u7f51\u5a92\u4f53\u7684\u65b0\u95fb\u6570\u636e, \u91d1\u878d\u7684\u516c\u544a\u6570\u636e\u90fd\u662f\u5728\u8868\u8fbe\u4e8b\u4ef6, \u800c\u4e8b\u4ef6\u7684\u8bed\u4e49\u53ef\u4ee5\u5f88\u81ea\u7136\u5730\u8868\u8fbe\u4e3a\u6846\u67b6. \u4e8b\u4ef6\u6846\u67b6\u8d4b\u4e88\u673a\u5668\u8ba4\u77e5\u4e8b\u4ef6\u6570\u636e\u7684\u57fa\u672c\u6846\u67b6, \u662f\u8fd9\u7c7b\u6570\u636e\u7ed3\u6784\u5316\u5904\u7406\u7684\u5fc5\u7ecf\u8def\u5f84. \u6811\u5f62\u77e5\u8bc6\u8868\u793a \u00b6 \u6811\u5f62\u7ed3\u6784\u7684\u77e5\u8bc6\u8868\u793a, \u53ef\u4ee5\u7528\u4e8e\u8868\u8fbe\u590d\u6742\u6761\u4ef6\u7ec4\u5408\u4e0b\u7684\u51b3\u7b56\u548c\u52a8\u4f5c. \u51b3\u7b56\u6811\u5c31\u662f\u6700\u7ecf\u5178\u7684\u6811\u5f62\u77e5\u8bc6\u8868\u793a. \u51b3\u7b56\u6811: \u51b3\u7b56\u6811\u662f\u4e00\u79cd\u7528\u4e8e\u5206\u7c7b\u7684\u6811\u5f62\u7ed3\u6784, \u4e00\u68f5\u51b3\u7b56\u6811\u7531\u6839\u8282\u70b9, \u82e5\u5e72\u4e2d\u95f4\u8282\u70b9\u548c\u82e5\u5e72\u53f6\u5b50\u8282\u70b9\u7ec4\u6210. \u6839\u8282\u70b9\u548c\u4e2d\u95f4\u8282\u70b9\u5bf9\u5e94\u4e00\u4e2a\u5c5e\u6027, \u76f8\u5e94\u5c5e\u6027\u5206\u7c7b\u7684\u6837\u672c\u96c6\u5408\u5c06\u88ab\u5212\u5165\u5bf9\u5e94\u7684\u5b50\u8282\u70b9. \u53f6\u5b50\u8282\u70b9\u8868\u793a\u6700\u7ec8\u7684\u5206\u7c7b\u7ed3\u679c. \u4ece\u6839\u8282\u70b9\u5230\u53f6\u5b50\u8282\u70b9\u7684\u6bcf\u4e00\u6761\u8def\u5f84, \u5c31\u4ee3\u8868\u4e86\u4e00\u79cd\u5206\u7c7b\u65b9\u6848. \u4f8b\u5982: \u501f\u8d37\u51b3\u7b56\u6811\u8868\u8fbe\u4e86\u6839\u636e\u6536\u5165\u6c34\u5e73, \u4fe1\u7528\u5361\u5f20\u6570, \u662f\u5426\u6709\u623f, \u4ee5\u53ca\u5e74\u9f84, \u5b66\u5386\u6765\u5224\u65ad\u662f\u5426\u540c\u610f\u7ed9\u4e00\u4e2a\u7528\u6237\u501f\u8d37\u7684\u51b3\u7b56\u903b\u8f91. \u6bd4\u5982\u4e00\u4e2a\u4eba\u7684\u6536\u5165\u5c5e\u4e8e\u4e2d\u7b49\u6c34\u5e73, \u62e5\u6709\u7684\u4fe1\u7528\u5361\u6570\u5927\u4e8e\u6216\u7b49\u4e8e5\u5f20, \u5e76\u4e14\u5e74\u9f84\u5c0f\u4e8e\u6216\u7b49\u4e8e30\u5c81, \u5219\u540c\u610f\u7ed9\u4ed6\u501f\u8d37. \u53cd\u4e4b\u5982\u679c\u4e00\u4e2a\u4eba\u7684\u6536\u5165\u6c34\u5e73\u8f83\u4f4e, \u800c\u4e14\u6ca1\u6709\u623f, \u5219\u4e0d\u540c\u610f\u7ed9\u4ed6\u501f\u8d37. \u6545\u969c\u6811: \u53e6\u4e00\u7c7b\u5e38\u89c1\u7684\u6811\u5f62\u77e5\u8bc6\u8868\u793a\u662f\u6545\u969c\u6811, \u6545\u969c\u6811\u662f\u4e00\u79cd\u6811\u5f62\u7684\u903b\u8f91\u56e0\u679c\u5173\u7cfb\u56fe. \u5728\u6545\u969c\u6811\u4e2d, \u7236\u8282\u70b9\u662f\u4ea7\u751f\u6545\u969c\u7684\u7ed3\u679c, \u4e5f\u79f0\u8f93\u51fa\u4e8b\u4ef6; \u5b50\u8282\u70b9\u662f\u4ea7\u751f\u6545\u969c\u7684\u539f\u56e0, \u4e5f\u79f0\u4e3a\u8f93\u5165\u4e8b\u4ef6. \u4e3a\u4e86\u80fd\u591f\u8868\u8fbe\u56e0\u679c\u903b\u8f91\u5173\u7cfb, \u6545\u969c\u6811\u5229\u7528\u903b\u8f91\u7b26\u53f7\u8fde\u63a5\u5b50\u8282\u70b9\u548c\u7236\u8282\u70b9. \u5176\u4e2d, \"\u6216\"\u7b26\u53f7\u8868\u793a\"\u53d1\u751f\u4efb\u4f55\u4e00\u4e2a\u8f93\u5165\u4e8b\u4ef6, \u8f93\u51fa\u65f6\u95f4\u90fd\u4f1a\u53d1\u751f\"; \"\u4e0e\"\u7b26\u53f7\u8868\u793a\"\u53ea\u6709\u6240\u6709\u8f93\u5165\u4e8b\u4ef6\u53d1\u751f, \u8f93\u51fa\u4e8b\u4ef6\u624d\u4f1a\u53d1\u751f\". \u4f8b\u5982: \u7535\u5b50\u6587\u6863\u4e22\u5931\u7684\u539f\u56e0\u53ef\u80fd\u662f\u4eba\u5de5\u8bef\u64cd\u4f5c, \u4e5f\u53ef\u80fd\u662f\u975e\u4eba\u5de5\u6545\u969c. \u5982\u679c\u539f\u56e0\u662f\u975e\u4eba\u5de5\u6545\u969c, \u5219\u53ef\u80fd\u662f\u56e0\u4e3a\u7535\u8111\u65ad\u7535\u4e14\u6587\u6863\u672a\u4fdd\u5b58. \u6982\u7387\u56fe\u6a21\u578b \u00b6 Probalistic Graphical Model: \u8d1d\u53f6\u65af\u7f51\u7edc, \u4e5f\u88ab\u79f0\u4e3a\u4fe1\u5ff5\u7f51\u7edc\u6216\u6709\u5411\u65e0\u73af\u56fe\u6a21\u578b, \u662f\u4e00\u79cd\u6982\u7387\u56fe\u6a21\u578b, \u4e5f\u662f\u4e0d\u786e\u5b9a\u77e5\u8bc6\u8868\u793a\u7684\u5178\u578b\u65b9\u6cd5. \u4e00\u4e2a\u8d1d\u53f6\u65af\u7f51\u7edc\u5c31\u662f\u4e00\u4e2a\u6709\u5411\u65e0\u73af\u56fe, \u5176\u4e2d\u8282\u70b9\u662f\u4e00\u7ec4\u968f\u673a\u53d8\u91cfX={X1, X2, X3, ... , Xn}, \u8282\u70b9\u4e4b\u95f4\u7684\u6709\u5411\u8fb9(\u7531\u7236\u8282\u70b9\u6307\u5411\u5b50\u8282\u70b9)\u4ee3\u8868\u968f\u673a\u53d8\u91cf\u4e4b\u95f4\u7684\u5f71\u54cd. Xi -> Xj\u4e4b\u95f4\u7684\u6709\u5411\u8fb9\u8868\u793aXj\u7684\u5206\u5e03\u53d6\u51b3\u4e8eXi\u7684\u53d6\u503c. \u901a\u5e38, \u6211\u4eec\u53c8\u628aXi\u79f0\u4f5c\u56e0(Cause), Xj\u79f0\u4f5cXi\u7684\u679c(Effect). \u56e0\u6b64, \u8d1d\u53f6\u65af\u7f51\u7edc\u5e38\u88ab\u7528\u4e8e\u8868\u8fbe\u56e0\u679c\u5173\u7cfb. \u4f5c\u4e3a\u4e00\u79cd\u9762\u5411\u4e0d\u786e\u5b9a\u6027\u7684\u77e5\u8bc6\u8868\u793a, \u8d1d\u53f6\u65af\u7f51\u7edc\u53ef\u4ee5\u89c6\u4f5c\u57fa\u4e8e\u968f\u673a\u53d8\u91cf\u4e4b\u95f4\u7684\u6761\u4ef6\u72ec\u7acb\u6027(conditional independence)\u5bf9X\u7684\u8054\u5408\u5206\u5e03\u7684\u4e00\u79cd\u7cbe\u7b80\u8868\u793a. \u6bcf\u4e2a\u8d1d\u53f6\u65af\u7f51\u7edc\u672c\u8d28\u4e0a\u8868\u8fbe\u4e86X\u7684\u67d0\u4e2a\u8054\u5408\u6982\u7387\u5206\u5e03P\u4e0a\u7684\u82e5\u5e72\u6761\u4ef6\u72ec\u7acb\u6027\u5047\u8bbe. \u4ee4G = (I, E)\u4ee3\u8868\u4e00\u4e2a\u8d1d\u53f6\u65af\u7f51\u7edc, \u5176\u4e2dI\u8868\u793a\u56fe\u4e2d\u8282\u70b9\u7684\u96c6\u5408, E\u8868\u793a\u6709\u5411\u8fb9\u7684\u96c6\u5408, X = {Xi}\u8868\u793a\u6709\u5411\u65e0\u73af\u56fe\u4e2d\u7684\u67d0\u4e00\u4e2a\u8282\u70b9i\u6240\u4ee3\u8868\u7684\u968f\u673a\u53d8\u91cf. \u8d1d\u53f6\u65af\u7f51\u7edcG = (I, E)\u6240\u8868\u8fbe\u7684\u57fa\u672c\u8bed\u4e49\u662f: \u5bf9\u4e8e\u6bcf\u4e2a\u968f\u673a\u53d8\u91cfXi, \u7ed9\u5b9aXi\u5728G\u4e2d\u7684\u7236\u8282\u70b9\u96c6\u5408Parent(Xi), \u5219Xi\u4e0e\u6240\u6709Xi\u7684\u975e\u540e\u4ee3\u8282\u70b9\u53d8\u91cf\u6761\u4ef6\u72ec\u7acb. \u6838\u5fc3: \u4e0a\u8ff0\u57fa\u672c\u8bed\u4e49\u7684\u5185\u6db5\u5c31\u662f, \u6bcf\u4e2a\u968f\u673a\u53d8\u91cfXi\u4ec5\u76f4\u63a5\u4f9d\u8d56\u4e8e\u5176\u7236\u8282\u70b9\u96c6\u5408Parent(Xi). \u8d1d\u53f6\u65af\u7f51\u7edc\u7684\u4e24\u4e2a\u57fa\u672c\u95ee\u9898: \u5b66\u4e60 \u63a8\u7406 \u9a6c\u5c14\u53ef\u592b\u94fe \u00b6 Markov Chain (MC): \u9a6c\u5c14\u53ef\u592b\u94fe\u662f\u4e00\u79cd\u6ee1\u8db3\u9a6c\u5c14\u53ef\u592b\u6027\u7684\u79bb\u6563\u968f\u673a\u53d8\u91cf\u96c6\u5408. \u6240\u8c13\u7684\u9a6c\u5c14\u53ef\u592b\u6027, \u662f\u6307\u67d0\u4e2a\u968f\u673a\u53d8\u91cf\u5e8f\u5217\u7684\u4e0b\u4e00\u4e2a\u72b6\u6001\u4ec5\u4ec5\u4e0e\u5f53\u524d\u7684\u72b6\u6001\u6709\u5173, \u800c\u4e0e\u4e4b\u524d\u7684\u72b6\u6001\u6ca1\u6709\u5173\u7cfb. \u5c0f\u8282\u603b\u7ed3 \u00b6 \u672c\u5c0f\u8282\u5b66\u4e60\u4e86\u77e5\u8bc6\u56fe\u8c31\u7684\u6570\u503c\u8868\u793a\u6982\u5ff5, \u548c\u4eba\u5de5\u667a\u80fd\u65f6\u4ee3\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6a21\u578b\u540c\u51fa\u4e00\u8109. \u57fa\u4e8e\u8ddd\u79bb\u7684\u6a21\u578b: \u4ee3\u8868\u6027\u7684SE\u6a21\u578b, \u57fa\u672c\u601d\u60f3\u662f\u5f53\u4e24\u4e2a\u5b9e\u4f53\u5c5e\u4e8e\u540c\u4e00\u4e2a\u4e09\u5143\u7ec4\u65f6, \u5b83\u4eec\u7684\u5411\u91cf\u8868\u793a\u5728\u6295\u5f71\u540e\u7684\u7a7a\u95f4\u4e2d\u4e5f\u5e94\u8be5\u5f7c\u6b64\u9760\u8fd1. \u4f46\u7531\u4e8eSE\u6a21\u578b\u5f15\u5165\u4e86\u4e24\u4e2a\u4e0d\u540c\u7684\u6295\u5f71\u77e9\u9635, \u5bfc\u81f4\u5f88\u96be\u6355\u83b7\u5b9e\u4f53\u548c\u5173\u7cfb\u4e4b\u95f4\u7684\u8bed\u4e49\u76f8\u5173\u6027. \u57fa\u4e8e\u7ffb\u8bd1\u7684\u6a21\u578b: TransE\u6a21\u578b: TransE\u8ba4\u4e3a\u5728\u77e5\u8bc6\u5e93\u4e2d, \u4e09\u5143\u7ec4< h, r, t >\u53ef\u4ee5\u770b\u6210\u5934\u5b9e\u4f53h\u5230\u5c3e\u5b9e\u4f53t\u5229\u7528\u5173\u7cfbr\u6240\u8fdb\u884c\u7684\u7ffb\u8bd1. TransH\u6a21\u578b: TransH\u6a21\u578b\u653e\u5bbd\u4e86h + r ~ t\u8fd9\u4e00\u4e25\u683c\u5047\u8bbe, \u53ea\u8981\u6c42\u5934\u5c3e\u5b9e\u4f53\u5728\u5173\u7cfbr\u76f8\u5bf9\u5e94\u7684\u8d85\u5e73\u9762\u4e0a\u7684\u6295\u5f71\u5f7c\u6b64\u63a5\u8fd1\u5373\u53ef. TransR\u6a21\u578b: TrasnR\u6a21\u578b\u63d0\u51fa\u4e3a\u6bcf\u4e2a\u5173\u7cfb\u6784\u9020\u76f8\u5e94\u7684\u5411\u91cf\u7a7a\u95f4, \u5c06\u5b9e\u4f53\u4e0e\u5173\u7cfb\u5728\u4e0d\u540c\u7684\u5411\u91cf\u7a7a\u95f4\u4e2d\u5206\u5f00\u8868\u793a. TransD\u6a21\u578b: TransD\u6a21\u578b\u8ba4\u4e3a\u6620\u5c04\u51fd\u6570\u5e94\u8be5\u4e0e\u5b9e\u4f53, \u5173\u7cfb\u540c\u65f6\u76f8\u5173. \u5176\u4ed6\u77e5\u8bc6\u8868\u793a\u65b9\u5f0f: \u8c13\u8bcd\u903b\u8f91 \u4ea7\u751f\u5f0f\u89c4\u5219 \u6846\u67b6\u8868\u793a \u6811\u5f62\u77e5\u8bc6\u8868\u793a \u6982\u7387\u56fe\u6a21\u578b \u9a6c\u5c14\u53ef\u592b\u94fe","title":"2.2 \u77e5\u8bc6\u56fe\u8c31\u7684\u6570\u503c\u8868\u793a"},{"location":"2_2.html#_1","text":"","title":"\u77e5\u8bc6\u56fe\u8c31\u7684\u6570\u503c\u8868\u793a"},{"location":"2_2.html#_2","text":"\u4e86\u89e3\u77e5\u8bc6\u56fe\u8c31\u6709\u54ea\u4e9b\u91cd\u8981\u7684\u6570\u503c\u8868\u793a\u65b9\u6cd5. \u7406\u89e3\u77e5\u8bc6\u56fe\u8c31\u76f8\u5173\u6570\u503c\u8868\u793a\u7684\u65b9\u6cd5.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"2_2.html#_3","text":"\u968f\u7740\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb, \u5982\u4f55\u5c06\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u80cc\u666f\u77e5\u8bc6\u878d\u5408\u8fdb\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u6280\u672f\u95ee\u9898. \u57fa\u672c\u7684\u601d\u8def\u662f\u5c06\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u70b9\u4e0e\u8fb9\u8868\u793a\u6210\u6570\u503c\u5316\u7684\u5411\u91cf. \u4e0d\u540c\u7684\u5411\u91cf\u8868\u793a\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u6709\u7740\u4e0d\u540c\u7684\u6548\u679c, \u5982\u4f55\u5c06\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\u548c\u5173\u7cfb\u6c42\u5f97\u6700\u4f18\u7684\u5411\u91cf\u5316\u8868\u793a, \u662f\u5f53\u524d\u77e5\u8bc6\u56fe\u8c31\u8868\u793a\u5b66\u4e60\u6240\u5173\u6ce8\u7684\u6838\u5fc3\u95ee\u9898. \u77e5\u8bc6\u56fe\u8c31\u7684\u8868\u793a\u5b66\u4e60\u65e8\u5728\u5c06\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5143\u7d20(\u5305\u62ec\u5b9e\u4f53, \u5c5e\u6027, \u6982\u5ff5\u7b49)\u8868\u793a\u4e3a\u4f4e\u7ef4\u7a20\u5bc6\u5b9e\u6570\u5411\u91cf. \u77e5\u8bc6\u56fe\u8c31\u7684\u5411\u91cf\u5316\u8868\u793a\u662f\u9762\u5411\u673a\u5668\u5904\u7406\u7684, \u800c\u7b26\u53f7\u5316\u8868\u793a\u662f\u9762\u5411\u4eba\u7684\u7406\u89e3\u7684. \u76f8\u5bf9\u4e8e\u5411\u91cf\u5316\u8868\u793a, \u7b26\u53f7\u5316\u8868\u793a\u6613\u4e8e\u7406\u89e3, \u53ef\u4ee5\u5b9e\u73b0\u7b26\u53f7\u63a8\u7406. \u4e24\u79cd\u8868\u793a\u5404\u6709\u5176\u9002\u7528\u7684\u573a\u666f.","title":"\u6570\u503c\u8868\u793a\u6982\u8ff0"},{"location":"2_2.html#_4","text":"\u57fa\u4e8e\u8ddd\u79bb\u7684\u6a21\u578b\u4e2d, \u6700\u5177\u4ee3\u8868\u6027\u7684\u662fSE\u6a21\u578b, \u57fa\u672c\u601d\u60f3: \u5f53\u4e24\u4e2a\u5b9e\u4f53\u5c5e\u4e8e\u540c\u4e00\u4e2a\u4e09\u5143\u7ec4\u65f6, \u5b83\u4eec\u7684\u5411\u91cf\u8868\u793a\u5728\u6295\u5f71\u540e\u7684\u7a7a\u95f4\u4e2d\u4e5f\u5e94\u8be5\u5f7c\u6b64\u9760\u8fd1. \u56e0\u6b64\u635f\u5931\u51fd\u6570\u88ab\u5b9a\u4e49\u4e3a\u5411\u91cf\u6295\u5f71\u540e\u7684\u8ddd\u79bb. \u6ce8\u610f: SE\u6a21\u578b\u91c7\u7528\u5f62\u5f0f\u8f83\u4e3a\u7b80\u5355\u7684L1\u8303\u6570, \u4e24\u4e2a\u77e9\u9635W(r,1)\u548cW(r,2)\u7528\u4e8e\u4e09\u5143\u7ec4\u4e2d\u5934\u5b9e\u4f53\u5411\u91cfh\u548c\u5c3e\u5b9e\u4f53\u5411\u91cft\u7684\u6295\u5f71\u64cd\u4f5c. \u4f46\u7531\u4e8eSE\u6a21\u578b\u5f15\u5165\u4e86\u4e24\u4e2a\u4e0d\u540c\u7684\u6295\u5f71\u77e9\u9635, \u5bfc\u81f4\u5f88\u96be\u6355\u83b7\u5b9e\u4f53\u548c\u5173\u7cfb\u4e4b\u95f4\u7684\u8bed\u4e49\u76f8\u5173\u6027!","title":"\u57fa\u4e8e\u8ddd\u79bb\u7684\u6a21\u578b"},{"location":"2_2.html#_5","text":"","title":"\u57fa\u4e8e\u7ffb\u8bd1\u7684\u6a21\u578b"},{"location":"2_2.html#transe","text":"TransE\u6a21\u578b: \u662f\u57fa\u4e8e\u7ffb\u8bd1\u601d\u60f3\u7684\u6a21\u578b. TransE\u8ba4\u4e3a\u5728\u77e5\u8bc6\u5e93\u4e2d, \u4e09\u5143\u7ec4< h, r, t >\u53ef\u4ee5\u770b\u6210\u5934\u5b9e\u4f53h\u5230\u5c3e\u5b9e\u4f53t\u5229\u7528\u5173\u7cfbr\u6240\u8fdb\u884c\u7684\u7ffb\u8bd1. \u4f8b\u5982: \u5bf9\u4e8e\u4e09\u5143\u7ec4<\u67cf\u62c9\u56fe, \u8001\u5e08, \u82cf\u683c\u62c9\u5e95>, \u5934\u5b9e\u4f53\"\u67cf\u62c9\u56fe\"\u7684\u5411\u91cf\u52a0\u4e0a\u5173\u7cfb\"\u8001\u5e08\"\u7684\u5411\u91cf, \u5e94\u8be5\u5c3d\u53ef\u80fd\u548c\u5c3e\u5b9e\u4f53\"\u82cf\u683c\u62c9\u5e95\"\u7684\u5411\u91cf\u63a5\u8fd1. \u635f\u5931\u51fd\u6570\u5373\u53ef\u5f97\u5230: \u6ce8\u610f: \u5b9e\u9645\u5e94\u7528\u4e2d, \u4e3a\u4e86\u589e\u52a0\u533a\u5206\u5ea6, TransE\u6a21\u578b\u4f7f\u7528\u4e86Hinge Loss\u76ee\u6807\u51fd\u6570, \u901a\u8fc7\u5f15\u5165Max Margin\u673a\u5236\u4f7f\u5f97\u6b63\u8d1f\u4f8b\u5c3d\u53ef\u80fd\u5206\u5f00.","title":"TransE\u6a21\u578b"},{"location":"2_2.html#transh","text":"\u8003\u8651\u5230TransE\u6a21\u578b\u4e2d\u7684h + r ~ t\u5047\u8bbe\u592a\u5f3a, \u5bfc\u81f4\u5728\u81ea\u53cd, \u4e00\u5bf9\u591a, \u591a\u5bf9\u4e00\u5173\u7cfb\u4e0b\u5b9e\u4f53\u5411\u91cf\u5b66\u4e60\u7684\u9519\u8bef. \u6bd4\u5982, \u5bf9\u4e8e\u81ea\u53cd\u5173\u7cfbr, < h, r, t > \u548c < t, r, h >\u540c\u65f6\u6210\u7acb, \u5bfc\u81f4h = t. \u5bf9\u4e8e\u591a\u5bf9\u4e00\u5173\u7cfb, \u6bd4\u5982<\u67cf\u62c9\u56fe, \u6027\u522b, \u7537>, <\u7279\u6717\u666e, \u6027\u522b, \u7537>\u8fd9\u4e24\u4e2a\u4e09\u5143\u7ec4\u6709\u7740\u76f8\u540c\u7684\u5173\u7cfb\u548c\u5c3e\u5b9e\u4f53, \u4ece\u800c\u5bfc\u81f4\u67cf\u62c9\u56fe\u548c\u7279\u6717\u666e\u5411\u91cf\u975e\u5e38\u63a5\u8fd1(\u4e00\u5bf9\u591a\u7684\u5173\u7cfb\u7c7b\u4f3c). \u4f46\u662f\u67cf\u62c9\u56fe\u4e0e\u7279\u6717\u666e\u9664\u4e86\u5728\u6027\u522b\u4e0a\u76f8\u540c, \u5176\u4ed6\u65b9\u9762\u663e\u7136\u5b8c\u5168\u4e0d\u540c. TransH\u6a21\u578b: \u4e3a\u4e86\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898, TransH\u6a21\u578b\u653e\u5bbd\u4e86h + r ~ t\u8fd9\u4e00\u4e25\u683c\u5047\u8bbe, \u53ea\u8981\u6c42\u5934\u5c3e\u5b9e\u4f53\u5728\u5173\u7cfbr\u76f8\u5bf9\u5e94\u7684\u8d85\u5e73\u9762\u4e0a\u7684\u6295\u5f71\u5f7c\u6b64\u63a5\u8fd1\u5373\u53ef: \u5934\u5b9e\u4f53\u5411\u91cfh\u548c\u5c3e\u5b9e\u4f53\u5411\u91cft\u5728\u8d85\u5e73\u9762\u4e0a\u5229\u7528\u6cd5\u5411\u91cfWr\u6620\u5c04\u4e3a\u4e24\u4e2a\u65b0\u7684\u5411\u91cf: \u5173\u7cfbr\u5728\u8d85\u5e73\u9762\u4e0a\u7684\u5411\u91cf\u8868\u793a\u4e3adr, \u56e0\u6b64TransH\u7684\u76ee\u6807\u51fd\u6570\u4e3a:","title":"TransH\u6a21\u578b"},{"location":"2_2.html#transr","text":"\u5728TransE\u548cTransH\u6a21\u578b\u4e2d, \u5b9e\u4f53\u548c\u5173\u7cfb\u90fd\u5728\u76f8\u540c\u7684\u7a7a\u95f4\u4e2d\u8fdb\u884c\u8868\u793a. \u8fd9\u79cd\u505a\u6cd5\u65e0\u6cd5\u533a\u5206\u4e24\u4e2a\u8bed\u4e49\u76f8\u8fd1\u7684\u5b9e\u4f53\u5728\u67d0\u4e9b\u7279\u5b9a\u65b9\u9762(\u5173\u7cfb)\u4e0a\u7684\u4e0d\u540c. \u6bd4\u5982\"\u9a6c\u514b\u601d\"\u548c\"\u6069\u683c\u65af\"\u53ef\u4ee5\u8ba4\u4e3a\u662f\u4e24\u4e2a\u76f8\u4f3c\u7684\u5b9e\u4f53, \u4f46\u662f<\u9a6c\u514b\u601d, \u6c11\u65cf, \u72b9\u592a\u65cf>\u548c<\u6069\u683c\u65af, \u6c11\u65cf, \u5fb7\u610f\u5fd7\u65cf>\u4e0d\u540c. TransR\u6a21\u578b: \u8003\u8651\u5230\u4e0a\u8ff0\u95ee\u9898, TrasnR\u6a21\u578b\u63d0\u51fa\u4e3a\u6bcf\u4e2a\u5173\u7cfb\u6784\u9020\u76f8\u5e94\u7684\u5411\u91cf\u7a7a\u95f4, \u5c06\u5b9e\u4f53\u4e0e\u5173\u7cfb\u5728\u4e0d\u540c\u7684\u5411\u91cf\u7a7a\u95f4\u4e2d\u5206\u5f00\u8868\u793a. TransR\u57fa\u672c\u601d\u60f3: \u4e0eTransH\u7684\u57fa\u672c\u601d\u60f3\u5f88\u76f8\u4f3c, \u8981\u6c42\u5934\u5c3e\u5b9e\u4f53\u5728\u5173\u7cfbr\u76f8\u5bf9\u5e94\u7684\u5411\u91cf\u7a7a\u95f4\u4e2d\u7684\u6295\u5f71\u5f7c\u6b64\u63a5\u8fd1\u5373\u53ef.(\u5728TransH\u4e2d\u662f\u8d85\u5e73\u9762) TransR\u6a21\u578b\u5c06\u5934\u5b9e\u4f53\u5411\u91cfh\u548c\u5c3e\u5b9e\u4f53\u5411\u91cft\u6620\u5c04\u4e3a\u4e24\u4e2a\u65b0\u5411\u91cf: TransR\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\u4e3a:","title":"TransR\u6a21\u578b"},{"location":"2_2.html#transd","text":"TransR\u6a21\u578b\u5c06\u5b9e\u4f53\u548c\u5173\u7cfb\u5728\u4e0d\u540c\u7684\u5411\u91cf\u7a7a\u95f4\u4e2d\u8868\u793a, \u8fd9\u4e5f\u5e26\u6765\u4e86\u4e00\u4e9b\u65b0\u95ee\u9898: \u7b2c\u4e00: TransR\u6a21\u578b\u5229\u7528\u590d\u6742\u7684\u77e9\u9635\u8ba1\u7b97\u5c06\u5934\u5c3e\u5b9e\u4f53\u6620\u5c04\u5230\u5173\u7cfb\u5411\u91cf\u7a7a\u95f4\u4e2d, \u589e\u52a0\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6. \u7b2c\u4e8c: \u5bf9\u4e8e\u4e00\u4e2a\u4e09\u5143\u7ec4\u6765\u8bf4, \u5934\u5b9e\u4f53\u548c\u5c3e\u5b9e\u4f53\u5f88\u53ef\u80fd\u4e0d\u662f\u4e00\u7c7b\u5b9e\u4f53, \u6bd4\u5982<\u67cf\u62c9\u56fe, \u51fa\u751f\u5730, \u5e0c\u814a>, \u90a3\u4e48\"\u67cf\u62c9\u56fe\"\u548c\"\u5e0c\u814a\"\u662f\u4e24\u7c7b\u4e0d\u540c\u7684\u5b9e\u4f53, \u4f7f\u7528\u76f8\u540c\u7684\u6620\u5c04\u77e9\u9635Mr\u5f88\u660e\u663e\u4e0d\u5408\u7406. \u7b2c\u4e09: TransR\u6a21\u578b\u4e2d\u5b9e\u4f53\u7684\u6620\u5c04\u5173\u7cfb\u4ec5\u6709\u5173\u7cfb\u51b3\u5b9a, \u4f46\u663e\u7136\u5b9e\u4f53\u672c\u8eab\u5bf9\u6620\u5c04\u4e5f\u6709\u5f71\u54cd. TransD\u6a21\u578b: \u8003\u8651\u5230\u4e0a\u8ff0\u95ee\u9898, TransD\u6a21\u578b\u8ba4\u4e3a\u6620\u5c04\u51fd\u6570\u5e94\u8be5\u4e0e\u5b9e\u4f53, \u5173\u7cfb\u540c\u65f6\u76f8\u5173! TransD\u6a21\u578b\u4fee\u6539\u4e86\u6620\u5c04\u51fd\u6570: I(m*n)\u662f\u5355\u4f4d\u77e9\u9635, \u5934\u5b9e\u4f53\u548c\u5c3e\u5b9e\u4f53\u5206\u522b\u7528\u4e24\u4e2a\u4e0d\u540c\u7684\u6620\u5c04\u77e9\u9635M(rh)\u548cM(rt)\u8fdb\u884c\u6295\u5f71. \u5934\u5b9e\u4f53\u7684\u6620\u5c04\u77e9\u9635\u7531\u5173\u7cfb\u5411\u91cfrp\u4e0e\u5934\u5b9e\u4f53\u6620\u5c04\u5411\u91cfhp\u5171\u540c\u51b3\u5b9a; \u5c3e\u5b9e\u4f53\u7684\u6620\u5c04\u77e9\u9635\u7531\u5173\u7cfb\u5411\u91cfrp\u4e0e\u5c3e\u5b9e\u4f53\u6620\u5c04\u5411\u91cftp\u5171\u540c\u51b3\u5b9a: \u6700\u7ec8, TransD\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\u4e3a:","title":"TransD\u6a21\u578b"},{"location":"2_2.html#_6","text":"","title":"\u5176\u4ed6\u77e5\u8bc6\u8868\u793a\u65b9\u5f0f"},{"location":"2_2.html#_7","text":"Predicate Logic: \u547d\u9898\u662f\u4e00\u4e2a\u975e\u771f\u5373\u5047\u7684\u9648\u8ff0. \u6bd4\u5982, \"\u4e9a\u91cc\u58eb\u591a\u5fb7\u51fa\u751f\u4e8e\u6ce2\u4f0a\u63d0\u4e4c\"\u5c31\u662f\u4e00\u4e2a\u547d\u9898. \u547d\u9898\u53ef\u4ee5\u901a\u8fc7\u8c13\u8bcd>\u6765\u8868\u8fbe, \u8c13\u8bcd\u7684\u4e00\u822c\u5f62\u5f0f\u662fP(x1, x2, ..., xn). \u5176\u4e2d, P\u662f\u8c13\u8bcd\u7684\u540d\u79f0, xi\u662f\u8c13\u8bcd\u7684\u9879. xi\u65e2\u53ef\u4ee5\u662f\u4e00\u4e2a\u5e38\u91cf(\u4e9a\u91cc\u58eb\u591a\u5fb7), \u4e5f\u53ef\u4ee5\u662f\u4e00\u4e2a\u53d8\u91cf. \u5728\u67d0\u4e2a\u7279\u5b9a\u9886\u57df, \u8c13\u8bcdP\u53ef\u4ee5\u8868\u8fbe\u9886\u57df\u5bf9\u8c61\u4e4b\u95f4\u7684\u5173\u7cfb, \u4e5f\u53ef\u4ee5\u8868\u8fbe\u51fd\u6570. \u6bd4\u5982, BirthPlace(\u4e9a\u91cc\u58eb\u591a\u5fb7, \u6ce2\u4f0a\u63d0\u4e4c)\u8868\u8fbe\u4e86\"\u4e9a\u91cc\u58eb\u591a\u5fb7\u51fa\u751f\u4e8e\u6ce2\u4f0a\u63d0\u4e4c\", \u5b9e\u8d28\u4e0a\u8868\u8fbe\u4e86\u4e9a\u91cc\u58eb\u591a\u5fb7\u548c\u6ce2\u4f0a\u63d0\u4e4c\u4e4b\u95f4\u7684\u5173\u7cfb. Philosopher(\u4e9a\u91cc\u58eb\u591a\u5fb7)\u8868\u793a\u4e9a\u91cc\u58eb\u591a\u5fb7\u662f\u4e00\u4e2a\u54f2\u5b66\u5bb6\u8fd9\u4e00\u4e8b\u5b9e, Philosopher(x)\u662f\u4e00\u4e2a\u51fd\u6570. \u5728\u8c13\u8bcd\u4e0a\u53ef\u4ee5\u65bd\u52a0\u4e0d\u540c\u7684\u64cd\u4f5c: \u5426\u5b9a(Negative) \u6790\u53d6(Disjunction) \u5408\u53d6(Conjunction) \u8574\u542b(Implication) \u4e3a\u4e86\u8fdb\u4e00\u6b65\u523b\u753b\u8c13\u8bcd\u548c\u4e2a\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb, \u5728\u8c13\u8bcd\u903b\u8f91\u4e2d\u5f15\u5165\u4e24\u4e2a\u91cf\u8bcd: \u5168\u79f0\u91cf\u8bcd (Universal Quantifier) \u5b58\u5728\u91cf\u8bcd (Existential Quantifier)","title":"\u8c13\u8bcd\u903b\u8f91"},{"location":"2_2.html#_8","text":"Production Rule: \u4ea7\u751f\u5f0f\u89c4\u5219\u5e38\u7528\u4e8e\u8868\u793a\u4e8b\u5b9e\u4e0e\u89c4\u5219, \u4ee5\u53ca\u76f8\u5e94\u7684\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf. \u4ea7\u751f\u5f0f\u89c4\u5219\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5f62\u5f0f\u8bed\u8a00\u8bed\u6cd5\u63cf\u8ff0, \u81ea\u52a8\u89c4\u5212, \u4e13\u5bb6\u7cfb\u7edf, \u52a8\u4f5c\u9009\u62e9\u7b49. \u4ea7\u751f\u5f0f\u89c4\u5219\u662f\u4e00\u79cd\u5f62\u5982\"\u6761\u4ef6-\u52a8\u4f5c\"\u7684\u89c4\u5219, \u57fa\u672c\u5f62\u5f0f\u5982\u4e0b: IF < condition > THEN < conclusion > \u6ce8\u610f: \u4e0a\u8ff0\u516c\u5f0f\u4e2d, condition\u88ab\u79f0\u4e3a\u524d\u4ef6, \u8868\u793a\u524d\u63d0\u6761\u4ef6, \u5404\u4e2a\u6761\u4ef6\u53ef\u4ee5\u5229\u7528\u5408\u53d6, \u6790\u53d6\u7b49\u903b\u8f91\u8fde\u63a5\u8bcd\u8fdb\u884c\u4e0d\u540c\u7684\u7ec4\u5408; conclusion\u88ab\u79f0\u4e3a\u540e\u4ef6, \u8868\u793a\u5f53\u524d\u6761\u4ef6\u4e3a\u771f\u65f6, \u5e94\u91c7\u53d6\u7684\u52a8\u4f5c! R1: IF \u75c5\u4eba\u53d1\u70e7 AND \u54b3\u55fd THEN \u75c5\u4eba\u5f97\u4e86\u75c5\u6bd2\u6027\u611f\u5192 \u5f88\u591a\u4ea7\u751f\u5f0f\u89c4\u5219\u5177\u6709\u4e0d\u786e\u5b9a\u6027. \u6bd4\u5982, R2\u8868\u8fbe\u4e86\u4e00\u4e2a\u5177\u6709\u957f\u671f\u5438\u70df\u53f2\u7684\u75c5\u4eba\u7f79\u60a3\u80ba\u90e8\u75be\u75c5\u7684\u6982\u7387\u9ad8\u8fbe0.9: R2: IF \u75c5\u4eba\u5177\u6709\u957f\u671f\u5438\u70df\u53f2 THEN \u8be5\u75c5\u4eba\u7f79\u60a3\u80ba\u90e8\u75be\u75c5(0.9) \u4ea7\u751f\u5f0f\u89c4\u5219\u4e0e\u903b\u8f91\u8574\u542b\u6709\u7740\u76f8\u540c\u7684\u57fa\u672c\u5f62\u5f0f, \u4f46\u662f\u5728\u8bed\u4e49\u4e0a, \u903b\u8f91\u8574\u542bP=>Q\u53ea\u80fd\u8868\u8fbe\u5982\u679c\u547d\u9898P\u4e3a\u771f, \u5219Q\u4e00\u5b9a\u4e3a\u771f. \u4ea7\u751f\u5f0f\u89c4\u5219\u7684\u540e\u4ef6\u90e8\u5206\u4e0d\u4ec5\u53ef\u4ee5\u662f\u547d\u9898, \u8fd8\u53ef\u4ee5\u662f\u52a8\u4f5c. \u6bd4\u5982, R3\u7684\u540e\u4ef6\u5c31\u662f\u4e00\u4e2a\u52a8\u4f5c\u800c\u975e\u547d\u9898. R3: IF \u75c5\u4eba\u5f97\u4e86\u75c5\u6bd2\u6027\u611f\u5192 THEN \u7ed9\u4e88\u6297\u75c5\u6bd2\u6cbb\u7597 \u57fa\u4e8e\u7ed9\u5b9a\u7684\u4e00\u7ec4\u57fa\u672c\u4e8b\u5b9e\u548c\u4e00\u7ec4\u4ea7\u751f\u5f0f\u89c4\u5219(\u901a\u5e38\u53c8\u88ab\u79f0\u4e3a\u89c4\u5219\u5e93), \u6211\u4eec\u5c31\u53ef\u4ee5\u8fdb\u884c\u63a8\u7406\u4ee5\u6c42\u89e3\u95ee\u9898. \u8fd9\u5c31\u662f\u4ea7\u751f\u5f0f\u7cfb\u7edf\u7684\u57fa\u672c\u601d\u60f3. \u6bd4\u5982, \u53ef\u4ee5\u5b9a\u4e49\u4e00\u5957\u52a8\u7269\u8bc6\u522b\u7684\u89c4\u5219, \u4ece\u67d0\u4e2a\u52a8\u7269\u7684\u57fa\u672c\u7279\u5f81\u63cf\u8ff0\u51fa\u53d1, \u9009\u62e9\u5339\u914d\u89c4\u5219(\u4e0e\u524d\u4ef6\u90e8\u5206\u7684\u5339\u914d)\u8fdb\u884c\u63a8\u7406, \u5c06\u8fd9\u6837\u7684\u8fc7\u7a0b\u6301\u7eed\u4e0b\u53bb\u76f4\u81f3\u6ee1\u8db3\u63a8\u7406\u7684\u7ec8\u6b62\u6761\u4ef6. \u4ea7\u751f\u5f0f\u89c4\u5219\u662f\u4e00\u79cd\u81ea\u7136\u7684, \u6e05\u6670\u7684, \u53ef\u6269\u5c55\u7684\u77e5\u8bc6\u8868\u793a. \u64c5\u957f\u8868\u8fbe\u5177\u6709\u56e0\u679c\u5173\u7cfb\u7684\u8fc7\u7a0b\u6027\u77e5\u8bc6, \u5728\u533b\u7597\u8bca\u65ad, \u6545\u969c\u8bca\u65ad\u7b49\u5e94\u7528\u4e2d\u5e38\u80fd\u53d6\u5f97\u4e00\u5b9a\u7684\u6548\u679c, \u4f46\u662f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u4f1a\u78b0\u5230\u89c4\u5219\u51b2\u7a81, \u89c4\u5219\u5931\u914d\u7b49\u96be\u9898. \u603b\u4f53\u800c\u8a00, \u4ea7\u751f\u5f0f\u89c4\u5219\u6709\u5176\u4f7f\u7528\u573a\u666f, \u4f46\u4e0d\u8db3\u4ee5\u8868\u8fbe\u73b0\u5b9e\u4e16\u754c\u7684\u590d\u6742\u8bed\u4e49, \u8fd8\u9700\u8981\u540c\u5f88\u591a\u5176\u4ed6\u77e5\u8bc6\u8868\u793a\u534f\u540c\u8fd0\u7528\u624d\u80fd\u8f83\u597d\u7684\u843d\u5730.","title":"\u4ea7\u751f\u5f0f\u89c4\u5219"},{"location":"2_2.html#_9","text":"Frame: \u6846\u67b6\u8868\u793a\u662f\u4ee5\u6846\u67b6\u7406\u8bba\u4e3a\u57fa\u7840\u53d1\u5c55\u8d77\u6765\u7684\u4e00\u79cd\u7ed3\u6784\u5316\u7684\u77e5\u8bc6\u8868\u793a. \u6846\u67b6\u7406\u8bba\u8ba4\u4e3a, \u4eba\u7c7b\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e2d\u5404\u7c7b\u4e8b\u7269\u7684\u8ba4\u77e5\u90fd\u662f\u4ee5\u6846\u67b6\u7684\u7ed3\u6784\u5b58\u50a8\u5728\u8bb0\u5fc6\u4e2d\u7684. \u5f53\u4eba\u9762\u4e34\u65b0\u7684\u60c5\u5883\u65f6, \u4f1a\u4ece\u8bb0\u5fc6\u4e2d\u627e\u51fa\u4e00\u4e2a\u5408\u9002\u7684\u6846\u67b6, \u5e76\u6839\u636e\u5b9e\u9645\u60c5\u51b5\u5bf9\u8fd9\u4e00\u6846\u67b6\u7684\u7ec6\u8282\u8fdb\u884c\u52a0\u5de5, \u4fee\u6539, \u8865\u5145, \u5f62\u6210\u5bf9\u65b0\u60c5\u666f\u7684\u8ba4\u8bc6\u5e76\u5b58\u5165\u4eba\u8111\u4e2d. \u6846\u67b6\u662f\u4e00\u79cd\u63cf\u8ff0\u6240\u8bba\u5bf9\u8c61(\u4e8b\u7269, \u65f6\u95f4, \u6982\u5ff5)\u5c5e\u6027\u7684\u6570\u636e\u7ed3\u6784. \u6846\u67b6\u901a\u5e38\u7531\u63cf\u8ff0\u4e8b\u7269\u7684\u5404\u4e2a\u65b9\u9762\u7684\u69fd(Slot)\u7ec4\u6210. \u69fd\u7528\u4e8e\u63cf\u8ff0\u6240\u8bba\u5bf9\u8c61\u67d0\u4e00\u65b9\u9762\u7684\u5c5e\u6027. \u6bcf\u4e00\u4e2a\u69fd\u53ef\u4ee5\u62e5\u6709\u591a\u4e2a\u4fa7\u9762(Facet). \u6bcf\u4e2a\u4fa7\u9762\u53ef\u4ee5\u63cf\u8ff0\u76f8\u5e94\u5c5e\u6027\u7684\u4e00\u4e2a\u65b9\u9762, \u800c\u4e14\u6bcf\u4e2a\u4fa7\u9762\u53ef\u4ee5\u62e5\u6709\u591a\u4e2a\u503c. \u69fd\u548c\u4fa7\u9762\u6240\u5177\u6709\u7684\u5c5e\u6027\u503c\u5206\u522b\u88ab\u79f0\u4e3a\u69fd\u503c\u548c\u4fa7\u9762\u503c. \u9664\u4e86\u69fd, \u4fa7\u9762\u53ca\u5176\u503c\u4e4b\u5916, \u5728\u6846\u67b6\u4e2d\u8fd8\u53ef\u4ee5\u5b9a\u4e49\u7ea6\u675f, \u7528\u4e8e\u7ea6\u675f\u69fd\u548c\u4fa7\u9762\u7684\u5408\u7406\u53d6\u503c: < \u6846\u67b6\u540d > < \u69fd\u540d1 > : < \u4fa7\u976211 > : < \u503c111, \u503c112, ... , \u503c11k1 > ...... < \u4fa7\u97621m > : < \u503c1m1, \u503c1m2, ... , \u503c1mkm > < \u69fd\u540d2 > : < \u4fa7\u976221 > : < \u503c211, \u503c212, ... , \u503c21k1 > ...... < \u4fa7\u97622m > : < \u503c2m1, \u503c2m2, ... , \u503c2mkm > < \u7ea6\u675f > : < \u7ea6\u675f1 > ...... < \u7ea6\u675fm > \u4e0b\u56fe\u5c55\u793a\u4e86\u4e00\u4e2a\"\u54f2\u5b66\u5bb6\"\u7684\u6846\u67b6\u793a\u4f8b: \u6846\u67b6\u540d: < \u54f2\u5b66\u5bb6 > \u7c7b\u5c5e: < \u4eba\u7269 > \u5de5\u4f5c: \u8303\u56f4: (\u6559\u5b66, \u7814\u7a76) \u9ed8\u8ba4\u503c: \u7814\u7a76 \u6027\u522b: (\u7537, \u5973) \u7c7b\u578b: (< \u552f\u7269\u4e3b\u4e49\u54f2\u5b66\u5bb6 >, < \u552f\u5fc3\u4e3b\u4e49\u54f2\u5b66\u5bb6 >) \u6ce8\u610f: \u69fd\u6216\u8005\u4fa7\u9762\u7684\u53d6\u503c\u53ef\u4ee5\u662f\u53e6\u4e00\u4e2a\u6846\u67b6. \u6846\u67b6\u4e4b\u95f4\u7684\u76f8\u4e92\u5f15\u7528\u53ef\u4ee5\u5b9e\u73b0\u6846\u67b6\u8868\u793a\u7684\u590d\u7528. \u6846\u67b6\u4e4b\u95f4\u53ef\u4ee5\u5b9a\u4e49isA\u5173\u7cfb, \u6bd4\u5982< \u54f2\u5b66\u5bb6 >\u6846\u67b6\u662f< \u804c\u4e1a >\u7684\u5b50\u6846\u67b6. \u6846\u67b6\u5728\u5f53\u524d\u7684\u5927\u6570\u636e\u77e5\u8bc6\u56fe\u8c31\u5de5\u7a0b\u80cc\u666f\u4e0b\u5bf9\u4e8e\u7406\u89e3\u6587\u672c\u63cf\u8ff0\u7684\u4e8b\u4ef6\u6570\u636e\u6781\u4e3a\u91cd\u8981. \u4e92\u8054\u7f51\u5a92\u4f53\u7684\u65b0\u95fb\u6570\u636e, \u91d1\u878d\u7684\u516c\u544a\u6570\u636e\u90fd\u662f\u5728\u8868\u8fbe\u4e8b\u4ef6, \u800c\u4e8b\u4ef6\u7684\u8bed\u4e49\u53ef\u4ee5\u5f88\u81ea\u7136\u5730\u8868\u8fbe\u4e3a\u6846\u67b6. \u4e8b\u4ef6\u6846\u67b6\u8d4b\u4e88\u673a\u5668\u8ba4\u77e5\u4e8b\u4ef6\u6570\u636e\u7684\u57fa\u672c\u6846\u67b6, \u662f\u8fd9\u7c7b\u6570\u636e\u7ed3\u6784\u5316\u5904\u7406\u7684\u5fc5\u7ecf\u8def\u5f84.","title":"\u6846\u67b6\u8868\u793a"},{"location":"2_2.html#_10","text":"\u6811\u5f62\u7ed3\u6784\u7684\u77e5\u8bc6\u8868\u793a, \u53ef\u4ee5\u7528\u4e8e\u8868\u8fbe\u590d\u6742\u6761\u4ef6\u7ec4\u5408\u4e0b\u7684\u51b3\u7b56\u548c\u52a8\u4f5c. \u51b3\u7b56\u6811\u5c31\u662f\u6700\u7ecf\u5178\u7684\u6811\u5f62\u77e5\u8bc6\u8868\u793a. \u51b3\u7b56\u6811: \u51b3\u7b56\u6811\u662f\u4e00\u79cd\u7528\u4e8e\u5206\u7c7b\u7684\u6811\u5f62\u7ed3\u6784, \u4e00\u68f5\u51b3\u7b56\u6811\u7531\u6839\u8282\u70b9, \u82e5\u5e72\u4e2d\u95f4\u8282\u70b9\u548c\u82e5\u5e72\u53f6\u5b50\u8282\u70b9\u7ec4\u6210. \u6839\u8282\u70b9\u548c\u4e2d\u95f4\u8282\u70b9\u5bf9\u5e94\u4e00\u4e2a\u5c5e\u6027, \u76f8\u5e94\u5c5e\u6027\u5206\u7c7b\u7684\u6837\u672c\u96c6\u5408\u5c06\u88ab\u5212\u5165\u5bf9\u5e94\u7684\u5b50\u8282\u70b9. \u53f6\u5b50\u8282\u70b9\u8868\u793a\u6700\u7ec8\u7684\u5206\u7c7b\u7ed3\u679c. \u4ece\u6839\u8282\u70b9\u5230\u53f6\u5b50\u8282\u70b9\u7684\u6bcf\u4e00\u6761\u8def\u5f84, \u5c31\u4ee3\u8868\u4e86\u4e00\u79cd\u5206\u7c7b\u65b9\u6848. \u4f8b\u5982: \u501f\u8d37\u51b3\u7b56\u6811\u8868\u8fbe\u4e86\u6839\u636e\u6536\u5165\u6c34\u5e73, \u4fe1\u7528\u5361\u5f20\u6570, \u662f\u5426\u6709\u623f, \u4ee5\u53ca\u5e74\u9f84, \u5b66\u5386\u6765\u5224\u65ad\u662f\u5426\u540c\u610f\u7ed9\u4e00\u4e2a\u7528\u6237\u501f\u8d37\u7684\u51b3\u7b56\u903b\u8f91. \u6bd4\u5982\u4e00\u4e2a\u4eba\u7684\u6536\u5165\u5c5e\u4e8e\u4e2d\u7b49\u6c34\u5e73, \u62e5\u6709\u7684\u4fe1\u7528\u5361\u6570\u5927\u4e8e\u6216\u7b49\u4e8e5\u5f20, \u5e76\u4e14\u5e74\u9f84\u5c0f\u4e8e\u6216\u7b49\u4e8e30\u5c81, \u5219\u540c\u610f\u7ed9\u4ed6\u501f\u8d37. \u53cd\u4e4b\u5982\u679c\u4e00\u4e2a\u4eba\u7684\u6536\u5165\u6c34\u5e73\u8f83\u4f4e, \u800c\u4e14\u6ca1\u6709\u623f, \u5219\u4e0d\u540c\u610f\u7ed9\u4ed6\u501f\u8d37. \u6545\u969c\u6811: \u53e6\u4e00\u7c7b\u5e38\u89c1\u7684\u6811\u5f62\u77e5\u8bc6\u8868\u793a\u662f\u6545\u969c\u6811, \u6545\u969c\u6811\u662f\u4e00\u79cd\u6811\u5f62\u7684\u903b\u8f91\u56e0\u679c\u5173\u7cfb\u56fe. \u5728\u6545\u969c\u6811\u4e2d, \u7236\u8282\u70b9\u662f\u4ea7\u751f\u6545\u969c\u7684\u7ed3\u679c, \u4e5f\u79f0\u8f93\u51fa\u4e8b\u4ef6; \u5b50\u8282\u70b9\u662f\u4ea7\u751f\u6545\u969c\u7684\u539f\u56e0, \u4e5f\u79f0\u4e3a\u8f93\u5165\u4e8b\u4ef6. \u4e3a\u4e86\u80fd\u591f\u8868\u8fbe\u56e0\u679c\u903b\u8f91\u5173\u7cfb, \u6545\u969c\u6811\u5229\u7528\u903b\u8f91\u7b26\u53f7\u8fde\u63a5\u5b50\u8282\u70b9\u548c\u7236\u8282\u70b9. \u5176\u4e2d, \"\u6216\"\u7b26\u53f7\u8868\u793a\"\u53d1\u751f\u4efb\u4f55\u4e00\u4e2a\u8f93\u5165\u4e8b\u4ef6, \u8f93\u51fa\u65f6\u95f4\u90fd\u4f1a\u53d1\u751f\"; \"\u4e0e\"\u7b26\u53f7\u8868\u793a\"\u53ea\u6709\u6240\u6709\u8f93\u5165\u4e8b\u4ef6\u53d1\u751f, \u8f93\u51fa\u4e8b\u4ef6\u624d\u4f1a\u53d1\u751f\". \u4f8b\u5982: \u7535\u5b50\u6587\u6863\u4e22\u5931\u7684\u539f\u56e0\u53ef\u80fd\u662f\u4eba\u5de5\u8bef\u64cd\u4f5c, \u4e5f\u53ef\u80fd\u662f\u975e\u4eba\u5de5\u6545\u969c. \u5982\u679c\u539f\u56e0\u662f\u975e\u4eba\u5de5\u6545\u969c, \u5219\u53ef\u80fd\u662f\u56e0\u4e3a\u7535\u8111\u65ad\u7535\u4e14\u6587\u6863\u672a\u4fdd\u5b58.","title":"\u6811\u5f62\u77e5\u8bc6\u8868\u793a"},{"location":"2_2.html#_11","text":"Probalistic Graphical Model: \u8d1d\u53f6\u65af\u7f51\u7edc, \u4e5f\u88ab\u79f0\u4e3a\u4fe1\u5ff5\u7f51\u7edc\u6216\u6709\u5411\u65e0\u73af\u56fe\u6a21\u578b, \u662f\u4e00\u79cd\u6982\u7387\u56fe\u6a21\u578b, \u4e5f\u662f\u4e0d\u786e\u5b9a\u77e5\u8bc6\u8868\u793a\u7684\u5178\u578b\u65b9\u6cd5. \u4e00\u4e2a\u8d1d\u53f6\u65af\u7f51\u7edc\u5c31\u662f\u4e00\u4e2a\u6709\u5411\u65e0\u73af\u56fe, \u5176\u4e2d\u8282\u70b9\u662f\u4e00\u7ec4\u968f\u673a\u53d8\u91cfX={X1, X2, X3, ... , Xn}, \u8282\u70b9\u4e4b\u95f4\u7684\u6709\u5411\u8fb9(\u7531\u7236\u8282\u70b9\u6307\u5411\u5b50\u8282\u70b9)\u4ee3\u8868\u968f\u673a\u53d8\u91cf\u4e4b\u95f4\u7684\u5f71\u54cd. Xi -> Xj\u4e4b\u95f4\u7684\u6709\u5411\u8fb9\u8868\u793aXj\u7684\u5206\u5e03\u53d6\u51b3\u4e8eXi\u7684\u53d6\u503c. \u901a\u5e38, \u6211\u4eec\u53c8\u628aXi\u79f0\u4f5c\u56e0(Cause), Xj\u79f0\u4f5cXi\u7684\u679c(Effect). \u56e0\u6b64, \u8d1d\u53f6\u65af\u7f51\u7edc\u5e38\u88ab\u7528\u4e8e\u8868\u8fbe\u56e0\u679c\u5173\u7cfb. \u4f5c\u4e3a\u4e00\u79cd\u9762\u5411\u4e0d\u786e\u5b9a\u6027\u7684\u77e5\u8bc6\u8868\u793a, \u8d1d\u53f6\u65af\u7f51\u7edc\u53ef\u4ee5\u89c6\u4f5c\u57fa\u4e8e\u968f\u673a\u53d8\u91cf\u4e4b\u95f4\u7684\u6761\u4ef6\u72ec\u7acb\u6027(conditional independence)\u5bf9X\u7684\u8054\u5408\u5206\u5e03\u7684\u4e00\u79cd\u7cbe\u7b80\u8868\u793a. \u6bcf\u4e2a\u8d1d\u53f6\u65af\u7f51\u7edc\u672c\u8d28\u4e0a\u8868\u8fbe\u4e86X\u7684\u67d0\u4e2a\u8054\u5408\u6982\u7387\u5206\u5e03P\u4e0a\u7684\u82e5\u5e72\u6761\u4ef6\u72ec\u7acb\u6027\u5047\u8bbe. \u4ee4G = (I, E)\u4ee3\u8868\u4e00\u4e2a\u8d1d\u53f6\u65af\u7f51\u7edc, \u5176\u4e2dI\u8868\u793a\u56fe\u4e2d\u8282\u70b9\u7684\u96c6\u5408, E\u8868\u793a\u6709\u5411\u8fb9\u7684\u96c6\u5408, X = {Xi}\u8868\u793a\u6709\u5411\u65e0\u73af\u56fe\u4e2d\u7684\u67d0\u4e00\u4e2a\u8282\u70b9i\u6240\u4ee3\u8868\u7684\u968f\u673a\u53d8\u91cf. \u8d1d\u53f6\u65af\u7f51\u7edcG = (I, E)\u6240\u8868\u8fbe\u7684\u57fa\u672c\u8bed\u4e49\u662f: \u5bf9\u4e8e\u6bcf\u4e2a\u968f\u673a\u53d8\u91cfXi, \u7ed9\u5b9aXi\u5728G\u4e2d\u7684\u7236\u8282\u70b9\u96c6\u5408Parent(Xi), \u5219Xi\u4e0e\u6240\u6709Xi\u7684\u975e\u540e\u4ee3\u8282\u70b9\u53d8\u91cf\u6761\u4ef6\u72ec\u7acb. \u6838\u5fc3: \u4e0a\u8ff0\u57fa\u672c\u8bed\u4e49\u7684\u5185\u6db5\u5c31\u662f, \u6bcf\u4e2a\u968f\u673a\u53d8\u91cfXi\u4ec5\u76f4\u63a5\u4f9d\u8d56\u4e8e\u5176\u7236\u8282\u70b9\u96c6\u5408Parent(Xi). \u8d1d\u53f6\u65af\u7f51\u7edc\u7684\u4e24\u4e2a\u57fa\u672c\u95ee\u9898: \u5b66\u4e60 \u63a8\u7406","title":"\u6982\u7387\u56fe\u6a21\u578b"},{"location":"2_2.html#_12","text":"Markov Chain (MC): \u9a6c\u5c14\u53ef\u592b\u94fe\u662f\u4e00\u79cd\u6ee1\u8db3\u9a6c\u5c14\u53ef\u592b\u6027\u7684\u79bb\u6563\u968f\u673a\u53d8\u91cf\u96c6\u5408. \u6240\u8c13\u7684\u9a6c\u5c14\u53ef\u592b\u6027, \u662f\u6307\u67d0\u4e2a\u968f\u673a\u53d8\u91cf\u5e8f\u5217\u7684\u4e0b\u4e00\u4e2a\u72b6\u6001\u4ec5\u4ec5\u4e0e\u5f53\u524d\u7684\u72b6\u6001\u6709\u5173, \u800c\u4e0e\u4e4b\u524d\u7684\u72b6\u6001\u6ca1\u6709\u5173\u7cfb.","title":"\u9a6c\u5c14\u53ef\u592b\u94fe"},{"location":"2_2.html#_13","text":"\u672c\u5c0f\u8282\u5b66\u4e60\u4e86\u77e5\u8bc6\u56fe\u8c31\u7684\u6570\u503c\u8868\u793a\u6982\u5ff5, \u548c\u4eba\u5de5\u667a\u80fd\u65f6\u4ee3\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6a21\u578b\u540c\u51fa\u4e00\u8109. \u57fa\u4e8e\u8ddd\u79bb\u7684\u6a21\u578b: \u4ee3\u8868\u6027\u7684SE\u6a21\u578b, \u57fa\u672c\u601d\u60f3\u662f\u5f53\u4e24\u4e2a\u5b9e\u4f53\u5c5e\u4e8e\u540c\u4e00\u4e2a\u4e09\u5143\u7ec4\u65f6, \u5b83\u4eec\u7684\u5411\u91cf\u8868\u793a\u5728\u6295\u5f71\u540e\u7684\u7a7a\u95f4\u4e2d\u4e5f\u5e94\u8be5\u5f7c\u6b64\u9760\u8fd1. \u4f46\u7531\u4e8eSE\u6a21\u578b\u5f15\u5165\u4e86\u4e24\u4e2a\u4e0d\u540c\u7684\u6295\u5f71\u77e9\u9635, \u5bfc\u81f4\u5f88\u96be\u6355\u83b7\u5b9e\u4f53\u548c\u5173\u7cfb\u4e4b\u95f4\u7684\u8bed\u4e49\u76f8\u5173\u6027. \u57fa\u4e8e\u7ffb\u8bd1\u7684\u6a21\u578b: TransE\u6a21\u578b: TransE\u8ba4\u4e3a\u5728\u77e5\u8bc6\u5e93\u4e2d, \u4e09\u5143\u7ec4< h, r, t >\u53ef\u4ee5\u770b\u6210\u5934\u5b9e\u4f53h\u5230\u5c3e\u5b9e\u4f53t\u5229\u7528\u5173\u7cfbr\u6240\u8fdb\u884c\u7684\u7ffb\u8bd1. TransH\u6a21\u578b: TransH\u6a21\u578b\u653e\u5bbd\u4e86h + r ~ t\u8fd9\u4e00\u4e25\u683c\u5047\u8bbe, \u53ea\u8981\u6c42\u5934\u5c3e\u5b9e\u4f53\u5728\u5173\u7cfbr\u76f8\u5bf9\u5e94\u7684\u8d85\u5e73\u9762\u4e0a\u7684\u6295\u5f71\u5f7c\u6b64\u63a5\u8fd1\u5373\u53ef. TransR\u6a21\u578b: TrasnR\u6a21\u578b\u63d0\u51fa\u4e3a\u6bcf\u4e2a\u5173\u7cfb\u6784\u9020\u76f8\u5e94\u7684\u5411\u91cf\u7a7a\u95f4, \u5c06\u5b9e\u4f53\u4e0e\u5173\u7cfb\u5728\u4e0d\u540c\u7684\u5411\u91cf\u7a7a\u95f4\u4e2d\u5206\u5f00\u8868\u793a. TransD\u6a21\u578b: TransD\u6a21\u578b\u8ba4\u4e3a\u6620\u5c04\u51fd\u6570\u5e94\u8be5\u4e0e\u5b9e\u4f53, \u5173\u7cfb\u540c\u65f6\u76f8\u5173. \u5176\u4ed6\u77e5\u8bc6\u8868\u793a\u65b9\u5f0f: \u8c13\u8bcd\u903b\u8f91 \u4ea7\u751f\u5f0f\u89c4\u5219 \u6846\u67b6\u8868\u793a \u6811\u5f62\u77e5\u8bc6\u8868\u793a \u6982\u7387\u56fe\u6a21\u578b \u9a6c\u5c14\u53ef\u592b\u94fe","title":"\u5c0f\u8282\u603b\u7ed3"},{"location":"3_1.html","text":"IDCNN\u6a21\u578b \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u638c\u63e1IDCNN\u6a21\u578b\u7684\u7ed3\u6784\u548c\u539f\u7406. \u638c\u63e1IDCNN\u6a21\u578b\u7684\u5b9e\u73b0. IDCNN\u6a21\u578b\u7684\u7ed3\u6784\u548c\u539f\u7406 \u00b6 IDCNN\u6a21\u578b\u6e90\u4e8e\u8bba\u6587<< Fast and Accurate Entity Recognition with Iterated Dilated Convolutions >>, \u6838\u5fc3\u64cd\u4f5c\u662f\u81a8\u80c0\u5377\u79ef. \u81a8\u80c0\u5377\u79ef\u53ef\u4ee5\u8df3\u8fc7\u4e00\u90e8\u5206\u795e\u7ecf\u5143, \u540c\u65f6\u6269\u5927\u611f\u53d7\u91ce\u7684\u8303\u56f4: \u4e0b\u56fe\u5de6\u4fa7\u5c55\u793a\u81a8\u80c0\u7387\u7b49\u4e8e1\u7684\u6807\u51c6\u5377\u79ef\u64cd\u4f5c, \u4e5f\u662f\u7ecf\u5178CNN\u7684\u5b9e\u73b0\u65b9\u5f0f; \u4e0b\u56fe\u53f3\u4fa7\u5c55\u793a\u81a8\u80c0\u7387\u7b49\u4e8e2\u7684\u81a8\u80c0\u5377\u79ef, \u4e5f\u662f\u8bba\u6587\u4e2d\u8981\u91c7\u7528\u7684\u65b9\u5f0f: \u5f53\u6211\u4eec\u91c7\u7528\u4f20\u7edf\u5377\u79ef\u64cd\u4f5c, \u795e\u7ecf\u7f51\u7edc\u7684\u66f4\u9ad8\u5c42\u53ef\u4ee5\u5982\u4e0b\u56fe\u6240\u793a\u7684\u83b7\u53d6\u4e00\u5b9a\u8303\u56f4\u5185\u7684\u6587\u672c\u8bed\u4e49\u4fe1\u606f: \u5f53\u6211\u4eec\u91c7\u7528\u81a8\u80c0\u5377\u79ef\u64cd\u4f5c, \u795e\u7ecf\u7f51\u7edc\u7684\u66f4\u9ad8\u5c42\u53ef\u4ee5\u5982\u4e0b\u56fe\u6240\u793a\u7684\u83b7\u53d6\u66f4\u5927\u8303\u56f4\u5185\u7684\u6587\u672c\u8bed\u4e49\u4fe1\u606f: \u8bba\u6587\u4e2d\u5bf9\u51e0\u4e2a\u7ecf\u5178NER\u6a21\u578b\u505a\u4e86\u5bf9\u6bd4\u6d4b\u8bd5, \u663e\u793aIDCNN\u6a21\u578b\u7684\u6548\u679c\u53ef\u4ee5\u5ab2\u7f8eBiLSTM + CRF, \u5e76\u663e\u8457\u7684\u8d85\u8d8aBiLSTM\u6a21\u578b\u672c\u8eab: IDCNN\u5728\u5de5\u4e1a\u754c\u6700\u5927\u7684\u4eae\u70b9\u5728\u4e8e\u5904\u7406\u901f\u5ea6\u4e0a, \u8bba\u6587\u4e2d\u4e5f\u8fdb\u884c\u4e86\u5bf9\u6bd4\u6d4b\u8bd5, \u76f8\u6bd4\u4e8e\u6548\u679c\u76f8\u540c\u7684BiLSTM + CRF, \u53ef\u4ee5\u8fbe\u52308\u500d\u7684\u63a8\u7406\u52a0\u901f: IDCNN\u6a21\u578b\u7684\u5b9e\u73b0 \u00b6 IDCNN\u6a21\u578b\u7684\u5b9e\u73b0\u6b65\u9aa4\u5982\u4e0b: \u7b2c\u4e00\u6b65: \u914d\u7f6e\u51fd\u6570\u7684\u5b9e\u73b0 \u7b2c\u4e8c\u6b65: \u5de5\u5177\u7c7b\u51fd\u6570\u7684\u5b9e\u73b0 \u7b2c\u4e09\u6b65: \u6a21\u578b\u6838\u5fc3\u7c7b\u7684\u5b9e\u73b0 \u7b2c\u56db\u6b65: \u8bad\u7ec3\u4ee3\u7801\u7684\u5b9e\u73b0 \u7b2c\u4e94\u6b65: \u9884\u6d4b\u4ee3\u7801\u7684\u5b9e\u73b0 \u7b2c\u4e00\u6b65: \u914d\u7f6e\u51fd\u6570\u7684\u5b9e\u73b0 \u00b6 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/ner/idcnn/config.py # \u8bbe\u5b9alabel_to_id\u7684\u6620\u5c04\u5b57\u5178, \u91c7\u7528BIEO\u6807\u6ce8\u6a21\u5f0f, \u5916\u52a03\u4e2a\u7279\u6b8a\u5b57\u7b26<pad>, <start>, <eos> l2i_dic = { 'O' : 0 , u 'B-sym' : 1 , u 'B-dis' : 2 , u 'I-sym' : 3 , u 'I-dis' : 4 , u 'E-sym' : 5 , u 'E-dis' : 6 , '<pad>' : 7 , '<start>' : 8 , '<eos>' : 9 } # \u4e0a\u9762\u7684\u9006\u5411\u5b57\u5178, id_to_label i2l_dic = { 0 : 'O' , 1 : u 'B-sym' , 2 : u 'B-dis' , 3 : u 'I-sym' , 4 : u 'I-dis' , 5 : u 'E-sym' , 6 : u 'E-dis' , 7 : '<pad>' , 8 : '<start>' , 9 : '<eos>' } # \u8bad\u7ec3\u96c6, \u6d4b\u8bd5\u96c6, \u8bcd\u8868 train_file = './data/train.txt' dev_file = './data/test.txt' vocab_file = './data/vocab.txt' save_model_path = './saved_model/idcnn_crf.pt' model_path = './saved_model/idcnn_crf_1.pt' # \u8bbe\u7f6e\u5173\u952e\u7684\u8d85\u53c2\u6570 max_length = 256 batch_size = 32 epochs = 100 tagset_size = len ( l2i_dic ) dropout = 0.4 use_cuda = True \u7b2c\u4e8c\u6b65: \u5de5\u5177\u7c7b\u51fd\u6570\u7684\u5b9e\u73b0 \u00b6 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/ner/idcnn/utils.py from config import * class InputFeatures ( object ): def __init__ ( self , text , label , input_id , label_id , input_mask ): self . text = text self . label = label self . input_id = input_id self . label_id = label_id self . input_mask = input_mask # \u8bfb\u53d6\u5b57\u5178\u6587\u4ef6, \u5e76\u6784\u9020\u5b57\u5178 def load_vocab ( vocab_file ): vocab = {} index = 0 with open ( vocab_file , 'r' , encoding = 'utf-8' ) as reader : while True : token = reader . readline () if not token : break token = token . strip () vocab [ token ] = index index += 1 return vocab # \u52a0\u8f7d\u8bad\u7ec3\u96c6, \u6d4b\u8bd5\u96c6\u7684\u539f\u59cb\u6570\u636e def load_file ( file_path ): contents = open ( file_path , encoding = 'utf-8' ) . readlines () text = [] label = [] texts = [] labels = [] for line in contents : if line != ' \\n ' : line = line . strip () . split ( ' ' ) text . append ( line [ 0 ]) label . append ( line [ - 1 ]) else : texts . append ( text ) labels . append ( label ) text = [] label = [] return texts , labels # \u52a0\u8f7d\u6570\u636e def load_data ( file_path , max_length , label_dic , vocab ): texts , labels = load_file ( file_path ) assert len ( texts ) == len ( labels ) result = [] for i in range ( len ( texts )): assert len ( texts [ i ]) == len ( labels [ i ]) token = texts [ i ] label = labels [ i ] # \u6570\u636e\u88c1\u526a if len ( token ) > max_length - 2 : token = token [ 0 : ( max_length - 2 )] label = label [ 0 : ( max_length - 2 )] # \u6570\u636e\u52a0\u5de5 tokens_f = [ '[CLS]' ] + token + [ '[SEP]' ] label_f = [ '<start>' ] + label + [ '<eos>' ] # \u6570\u5b57\u5316\u5f20\u91cf\u6620\u5c04 input_ids = [ int ( vocab [ i ]) if i in vocab else int ( vocab [ '[UNK]' ]) for i in tokens_f ] label_ids = [ label_dic [ i ] for i in label_f ] # \u6784\u9020\u8f93\u5165\u6570\u636e\u548c\u63a9\u7801 input_mask = [ 1 ] * len ( input_ids ) while len ( input_ids ) < max_length : input_ids . append ( 0 ) input_mask . append ( 0 ) label_ids . append ( label_dic [ '<pad>' ]) # \u786e\u8ba4\u6570\u636e\u957f\u5ea6 assert len ( input_ids ) == max_length assert len ( input_mask ) == max_length assert len ( label_ids ) == max_length # \u5b9e\u4f8b\u5316\u7279\u5f81\u5bf9\u8c61 feature = InputFeatures ( text = tokens_f , label = label_f , input_id = input_ids , input_mask = input_mask , label_id = label_ids ) result . append ( feature ) return result # \u5229\u7528\u6807\u7b7e\u5b57\u5178\u6062\u590d\u771f\u5b9e\u7684\u9884\u6d4b\u6807\u7b7e def recover_label ( pred_var , gold_var , l2i_dic , i2l_dic ): assert len ( pred_var ) == len ( gold_var ) pred_variable = [] gold_variable = [] # \u8fdb\u884c\u6570\u636e\u622a\u53d6 for i in range ( len ( gold_var )): start_index = gold_var [ i ] . index ( l2i_dic [ '<start>' ]) end_index = gold_var [ i ] . index ( l2i_dic [ '<eos>' ]) pred_variable . append ( pred_var [ i ][ start_index : end_index ]) gold_variable . append ( gold_var [ i ][ start_index : end_index ]) pred_label = [] gold_label = [] # \u6807\u7b7e\u53cd\u5411\u6620\u5c04 for j in range ( len ( gold_variable )): pred_label . append ([ i2l_dic [ t ] for t in pred_variable [ j ] ]) gold_label . append ([ i2l_dic [ t ] for t in gold_variable [ j ] ]) return pred_label , gold_label # \u8ba1\u7b97NER\u7684\u5173\u952e\u6307\u6807 def get_ner_fmeasure ( golden_lists , predict_lists , label_type = 'BMES' ): sent_num = len ( golden_lists ) golden_full = [] predict_full = [] right_full = [] right_tag = 0 all_tag = 0 for idx in range ( 0 , sent_num ): golden_list = golden_lists [ idx ] predict_list = predict_lists [ idx ] for idy in range ( len ( golden_list )): if golden_list [ idy ] == predict_list [ idy ]: right_tag += 1 all_tag += len ( golden_list ) # \u4e0d\u540c\u7684\u6807\u6ce8\u4f53\u7cfb\u8c03\u7528\u4e0d\u540c\u7684\u5904\u7406\u51fd\u6570 if label_type == 'BMES' : gold_matrix = get_ner_BMES ( golden_list ) pred_matrix = get_ner_BMES ( predict_list ) else : gold_matrix = get_ner_BIO ( golden_list ) pred_matrix = get_ner_BIO ( predict_list ) right_ner = list ( set ( gold_matrix ) . intersection ( set ( pred_matrix ))) golden_full += gold_matrix predict_full += pred_matrix right_full += right_ner right_num = len ( right_full ) golden_num = len ( golden_full ) predict_num = len ( predict_full ) # \u9c81\u68d2\u6027\u5904\u7406 if predict_num == 0 : precision = - 1 else : precision = ( right_num + 0.0 ) / predict_num if golden_num == 0 : recall = - 1 else : recall = ( right_num + 0.0 ) / golden_num if ( precision == - 1 ) or ( recall == - 1 ) or ( precision + recall ) <= 0. : f_measure = - 1 else : f_measure = 2 * precision * recall / ( precision + recall ) accuracy = ( right_tag + 0.0 ) / all_tag print ( 'gold_num = ' , golden_num , ' pred_num = ' , predict_num , ' right_num = ' , right_num ) return accuracy , precision , recall , f_measure # \u53cd\u5411\u6620\u5c04\u7684\u63d0\u53d6\u51fd\u6570 def reverse_style ( input_string ): target_position = input_string . index ( '[' ) input_len = len ( input_string ) output_string = input_string [ target_position : input_len ] + input_string [ 0 : target_position ] return output_string # \u6309\u7167BMES\u6807\u6ce8\u6a21\u5f0f, \u8fdb\u884c\u5b9e\u4f53\u63d0\u53d6\u7684\u51fd\u6570 def get_ner_BMES ( label_list ): list_len = len ( label_list ) begin_label = 'B-' end_label = 'E-' single_label = 'S-' whole_tag = '' index_tag = '' tag_list = [] stand_matrix = [] for i in range ( 0 , list_len ): current_label = label_list [ i ] . upper () if begin_label in current_label : if index_tag != '' : tag_list . append ( whole_tag + ',' + str ( i - 1 )) whole_tag = current_label . replace ( begin_label , '' , 1 ) + '[' + str ( i ) index_tag = current_label . replace ( begin_label , '' , 1 ) elif single_label in current_label : if index_tag != '' : tag_list . append ( whole_tag + ',' + str ( i - 1 )) whole_tag = current_label . replace ( single_label , '' , 1 ) + '[' + str ( i ) tag_list . append ( whole_tag ) whole_tag = '' index_tag = '' elif end_label in current_label : if index_tag != '' : tag_list . append ( whole_tag + ',' + str ( i )) whole_tag = '' index_tag = '' else : continue if ( whole_tag != '' ) & ( index_tag != '' ): tag_list . append ( whole_tag ) tag_list_len = len ( tag_list ) for i in range ( 0 , tag_list_len ): if len ( tag_list [ i ]) > 0 : tag_list [ i ] = tag_list [ i ] + ']' insert_list = reverse_style ( tag_list [ i ]) stand_matrix . append ( insert_list ) return stand_matrix \u7b2c\u4e09\u6b65: \u6a21\u578b\u6838\u5fc3\u7c7b\u7684\u5b9e\u73b0 \u00b6 \u6a21\u578b\u7c7b\u5305\u542b3\u90e8\u5206, \u9700\u8981\u5206\u522b\u5b9e\u73b0: 1: CRF\u7c7b 2: IDCNN\u7c7b 3: IDCNN-CRF\u7c7b CRF\u7c7b\u91c7\u7528\u7ecf\u5178\u5b9e\u73b0\u5373\u53ef, \u5305\u62ec\u672a\u6765\u5728\u642d\u5efa\u81ea\u5df1\u7684\u6a21\u578b\u65f6, \u53ef\u4ee5\u76f4\u63a5\"\u5957\u7528\u8f6e\u5b50\", \u800c\u4e0d\u662f\u81ea\u5df1\u53bb\"\u9020\u8f6e\u5b50\". \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/ner/idcnn/model/crf.py IDCNN\u7c7b\u7684\u5b9e\u73b0 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/ner/idcnn/model/cnn.py import torch import torch.nn as nn import torch.nn.functional as F from collections import OrderedDict from config import * # \u6784\u5efaIDCNN\u6838\u5fc3\u7c7b\u7684\u4ee3\u7801 class IDCNN ( nn . Module ): def __init__ ( self , input_size , filters , kernel_size = 3 , num_block = 4 ): super ( IDCNN , self ) . __init__ () self . layers = [{ 'dilation' : 1 }, { 'dilation' : 1 }, { 'dilation' : 2 }] net = nn . Sequential () norms_1 = nn . ModuleList ([ LayerNorm ( 256 ) for _ in range ( len ( self . layers ))]) norms_2 = nn . ModuleList ([ LayerNorm ( 256 ) for _ in range ( num_block )]) # \u4f9d\u6b21\u6784\u5efa\u6bcf\u4e00\u5c42\u7f51\u7edc for i in range ( len ( self . layers )): dilation = self . layers [ i ][ 'dilation' ] # \u7f51\u7edc\u4e2d\u7684\u7b2c\u4e00\u5c42\u7ed3\u6784\u662fnn.Conv1d single_block = nn . Conv1d ( in_channels = filters , out_channels = filters , kernel_size = kernel_size , dilation = dilation , padding = kernel_size // 2 + dilation - 1 ) # \u6bcf\u4e00\u5c42\u7f51\u7edc\u90fd\u5305\u542b\u5377\u79ef\u5c42, \u6fc0\u6d3b\u5c42, \u6b63\u5219\u5316\u5c42, \u4f9d\u6b21\u6dfb\u52a0\u8fdbnet\u4e2d net . add_module ( 'layer %d ' % i , single_block ) net . add_module ( 'relu' , nn . ReLU ()) net . add_module ( 'layernorm' , norms_1 [ i ]) # \u6700\u540e\u5b9a\u4e49\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42 self . linear = nn . Linear ( input_size , filters ) self . idcnn = nn . Sequential () # \u4f9d\u6b21\u6784\u5efa4\u4e2aBlock for i in range ( num_block ): self . idcnn . add_module ( 'block %i ' % i , net ) self . idcnn . add_module ( 'relu' , nn . ReLU ()) self . idcnn . add_module ( 'layernorm' , norms_2 [ i ]) # \u524d\u5411\u4f20\u64ad\u51fd\u6570 def forward ( self , embeddings , length ): # 1: \u9996\u5148\u5bf9\u8bcd\u5d4c\u5165\u5f20\u91cf\u8fdb\u884c\u5168\u8fde\u63a5\u6620\u5c04\u7684\u8f6c\u6362 embeddings = self . linear ( embeddings ) # 2: \u8c03\u6574\u7b2c1, 2\u7ef4\u5ea6 embeddings = embeddings . permute ( 0 , 2 , 1 ) # 3: \u6700\u540e\u8fdb\u884cIDCNN\u7684\u7279\u5f81\u63d0\u53d6\u5e76\u5c06\u7b2c2\u6b65\u7684\u7ef4\u5ea6\u8c03\u6574\u56de\u539f\u72b6 output = self . idcnn ( embeddings ) . permute ( 0 , 2 , 1 ) return output # \u91c7\u7528\u7ecf\u5178transformer\u7684LayerNorm\u5b9e\u73b0\u7b56\u7565 class LayerNorm ( nn . Module ): def __init__ ( self , features , eps = 1e-6 ): super ( LayerNorm , self ) . __init__ () # \u521d\u59cb\u5316\u4e00\u4e2a\u51681\u7684\u5f20\u91cf, \u521d\u59cb\u5316\u4e00\u4e2a\u51680\u7684\u5f20\u91cf self . a_2 = nn . Parameter ( torch . ones ( features )) self . b_2 = nn . Parameter ( torch . zeros ( features )) self . eps = eps def forward ( self , x ): # \u8ba1\u7b97\u5f97\u5230\u5747\u503c\u548c\u65b9\u5dee, \u6ce8\u610f\u662f\u5728\u5f53\u524d\u6837\u672c\u7684\u6a2a\u5411\u7ef4\u5ea6, \u4ee5\u533a\u522b\u4e8eBatchNorm mean = x . mean ( - 1 , keepdim = True ) std = x . std ( - 1 , keepdim = True ) # \u6309\u7167\u516c\u5f0f\u8ba1\u7b97, \u5e76\u8fd4\u56de\u7ed3\u679c return self . a_2 * ( x - mean ) / ( std + self . eps ) + self . b_2 IDCNN-CRF\u7c7b \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/ner/idcnn/model/idcnn_crf.py import torch.nn as nn from model import CRF from torch.autograd import Variable from model.cnn import IDCNN import torch # \u6784\u5efaIDCNN_CRF\u6a21\u578b\u6838\u5fc3\u7c7b, \u5185\u90e8\u628aIDCNN\u548cCRF\u4e24\u4e2a\u57fa\u7840\u7c7b\u8fdb\u884c\u4e86\u878d\u5408 class IDCNN_CRF ( nn . Module ): def __init__ ( self , vocab_size , tagset_size , embedding_dim , num_filters = 64 , dropout = 0.4 , use_cuda = True ): super ( IDCNN_CRF , self ) . __init__ () # \u91cd\u8981\u53c2\u6570\u521d\u59cb\u5316 self . tagset_size = tagset_size self . embedding_dim = embedding_dim self . num_filters = num_filters self . use_cuda = use_cuda # 1: \u8bbe\u7f6e\u8bcd\u5d4c\u5165\u5c42, \u8fd9\u662f\u6240\u6709NLP\u6a21\u578b\u5fc5\u5907\u7684\u7b2c\u4e00\u6b65 self . embedding = nn . Embedding ( vocab_size , embedding_dim ) # 2: \u5b9e\u4f8b\u5316IDCNN\u7c7b, \u8f93\u5165\u7ef4\u5ea6\u662f\u5d4c\u5165\u5c42\u7684\u8f93\u51fa\u7ef4\u5ea6 self . idcnn = IDCNN ( input_size = embedding_dim , filters = num_filters ) # 3: \u5bf9\u4e8eCNN\u4e3a\u57fa\u7840\u7684\u7f51\u7edc, dropout\u662f\u6807\u51c6\u914d\u7f6e self . dropout = nn . Dropout ( p = dropout ) # 4: \u5b9e\u4f8b\u5316CRF\u5c42, \u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u53c2\u6570\u65b9\u9635, \u5bf9\u5e94\u8f6c\u79fb\u77e9\u9635 self . crf = CRF ( target_size = tagset_size , average_batch = True , use_cuda = use_cuda ) # 5: \u6700\u540e\u5b9a\u4e49\u5168\u8fde\u63a5\u6620\u5c04\u5c42, \u5c06\u5377\u79ef\u7684\u8f93\u51fa\u7ef4\u5ea6\u6620\u5c04\u5230CRF\u5c42\u7684\u8f93\u5165\u7ef4\u5ea6\u4e0a self . linear = nn . Linear ( num_filters , tagset_size + 2 ) # \u83b7\u53d6\u7f51\u7edc\u7684\u8f93\u51fa\u7279\u5f81\u5f20\u91cf def get_output_score ( self , sentence , attention_mask = None ): batch_size = sentence . size ( 0 ) seq_length = sentence . size ( 1 ) # 1: \u6267\u884c\u521d\u59cb\u5316\u51fd\u6570\u7684\u7b2c1\u5c42 embeds = self . embedding ( sentence ) # 2: \u6267\u884c\u521d\u59cb\u5316\u51fd\u6570\u7684\u7b2c2\u5c42 idcnn_out = self . idcnn ( embeds , seq_length ) # 3: \u6267\u884c\u521d\u59cb\u5316\u51fd\u6570\u7684\u7b2c3\u5c42 idcnn_out = self . dropout ( idcnn_out ) # 4: \u6267\u884c\u521d\u59cb\u5316\u51fd\u6570\u7684\u7b2c5\u5c42 out = self . linear ( idcnn_out ) # 5: \u8fdb\u884c\u5f20\u91cfshape\u7684\u8f6c\u53d8, \u4fdd\u6301\u7ecf\u5178\u7684(batch_size, seq_length, X)\u6a21\u5f0f feats = out . contiguous () . view ( batch_size , seq_length , - 1 ) return feats # \u5f53\u6a21\u578b\u5904\u4e8einference\u9636\u6bb5\u65f6, \u9ed8\u8ba4\u6267\u884c\u7684\u524d\u5411\u8ba1\u7b97\u51fd\u6570 def forward ( self , sentence , masks ): # \u9996\u5148\u83b7\u53d6\u53d1\u5c04\u77e9\u9635\u7684\u8f93\u51fa\u5f20\u91cf feats = self . get_output_score ( sentence ) # \u5229\u7528\u53d1\u5c04\u77e9\u9635\u7684\u8f93\u51fa\u5f20\u91cf, \u76f4\u63a5\u8fdb\u884c\u7ef4\u7279\u6bd4\u89e3\u7801, \u5f97\u5230\u9884\u6d4b\u5e8f\u5217 scores , tag_seq = self . crf . _viterbi_decode ( feats , masks . bool ()) return tag_seq # \u5f53\u6a21\u578b\u5904\u4e8e\u8bad\u7ec3\u9636\u6bb5\u65f6, \u771f\u6b63\u6267\u884c\u7684\u524d\u5411\u8ba1\u7b97\u51fd\u6570, \u4e3a\u4e86\u5f97\u5230\u6700\u5927\u4f3c\u7136\u635f\u5931\u503c def neg_log_likelihood_loss ( self , sentence , mask , tags ): # \u9996\u5148\u83b7\u53d6\u53d1\u5c04\u77e9\u9635\u7684\u8f93\u51fa\u5f20\u91cf feats = self . get_output_score ( sentence ) # \u5229\u7528CRF\u5c42\u7684\u6700\u5927\u4f3c\u7136\u635f\u5931\u51fd\u6570\u8ba1\u7b97\u5f53\u524d\u635f\u5931\u503c loss_value = self . crf . neg_log_likelihood_loss ( feats , mask , tags ) # \u8ba1\u7b97\u5f53\u524dbatch\u7684\u5e73\u5747\u635f\u5931\u503c batch_size = feats . size ( 0 ) loss_value /= float ( batch_size ) return loss_value \u7b2c\u56db\u6b65: \u8bad\u7ec3\u4ee3\u7801\u7684\u5b9e\u73b0 \u00b6 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/ner/idcnn/train.py from tqdm import tqdm import torch import torch.nn as nn from torch.autograd import Variable from torch.optim import Adam from torch.utils.data import TensorDataset from torch.utils.data import DataLoader from utils import load_vocab , load_data , recover_label , get_ner_fmeasure , save_model , load_model from config import * from model import IDCNN_CRF device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) use_cuda = True if torch . cuda . is_available () else False vocab = load_vocab ( vocab_file ) vocab_size = len ( vocab ) # \u8bfb\u53d6\u8bad\u7ec3\u96c6 print ( 'max_length' , max_length ) train_data = load_data ( train_file , max_length = max_length , label_dic = l2i_dic , vocab = vocab ) # \u63d0\u53d6\u8bad\u7ec3\u6570\u636e\u4e2d\u76843\u4e2a\u91cd\u8981\u5b57\u6bb5, \u5e76\u5c01\u88c5\u6210LongTensor\u7c7b\u578b train_ids = torch . LongTensor ([ temp . input_id for temp in train_data ]) train_masks = torch . LongTensor ([ temp . input_mask for temp in train_data ]) train_tags = torch . LongTensor ([ temp . label_id for temp in train_data ]) # \u6807\u51c6\"\u4e24\u6b65\u8d70\", \u5c01\u88c5\u6570\u636e\u96c6 + \u5c01\u88c5\u8fed\u4ee3\u5668 train_dataset = TensorDataset ( train_ids , train_masks , train_tags ) train_loader = DataLoader ( train_dataset , shuffle = True , batch_size = batch_size ) # \u8bfb\u53d6\u6d4b\u8bd5\u96c6 dev_data = load_data ( dev_file , max_length = max_length , label_dic = l2i_dic , vocab = vocab ) dev_ids = torch . LongTensor ([ temp . input_id for temp in dev_data ]) dev_masks = torch . LongTensor ([ temp . input_mask for temp in dev_data ]) dev_tags = torch . LongTensor ([ temp . label_id for temp in dev_data ]) dev_dataset = TensorDataset ( dev_ids , dev_masks , dev_tags ) dev_loader = DataLoader ( dev_dataset , shuffle = True , batch_size = batch_size ) # \u5b9e\u4f8b\u5316\u6a21\u578b\u5bf9\u8c61model model = IDCNN_CRF ( vocab_size , tagset_size , 300 , 64 , dropout = 0.4 , use_cuda = use_cuda ) if use_cuda : model = model . cuda () model . train () optimizer = Adam ( model . parameters (), lr = 0.00001 , weight_decay = 0.00005 ) best_f = - 100 # \u53cc\u91cdfor\u5faa\u73af\u8bad\u7ec3\u6a21\u578b for epoch in range ( epochs ): print ( 'epoch: {} \uff0ctrain' . format ( epoch )) for i , train_batch in enumerate ( tqdm ( train_loader )): sentence , masks , tags = train_batch sentence , masks , tags = Variable ( sentence ), Variable ( masks ), Variable ( tags ) if use_cuda : sentence = sentence . cuda () masks = masks . cuda () tags = tags . cuda () optimizer . zero_grad () # \u8bad\u7ec3\u65f6\u7684\u635f\u5931\u503c, \u9700\u8981\u901a\u8fc7\u8c03\u7528\u6700\u5927\u4f3c\u7136\u635f\u5931\u8ba1\u7b97\u7684\u51fd\u6570, \u800c\u4e0d\u662f\u9ed8\u8ba4\u7684forward\u51fd\u6570 loss = model . neg_log_likelihood_loss ( sentence , masks , tags ) # \"\u8001\u4e09\u6837\" loss . backward () optimizer . step () print ( 'epoch: {} \uff0closs: {} ' . format ( epoch , loss . item ())) # \u6bcf\u8bad\u7ec3\u5b8c\u4e00\u4e2aepoch, \u5bf9\u6d4b\u8bd5\u96c6\u8fdb\u884c\u4e00\u6b21\u8bc4\u4f30 acc , p , r , f = evaluate ( model , dev_loader ) # \u6bcf\u5f53\u6709\u66f4\u4f18\u7684F1\u503c\u65f6, \u66f4\u65b0\u6700\u4f18F1, \u5e76\u4fdd\u5b58\u6a21\u578b\u72b6\u6001\u5b57\u5178 if f > best_f : torch . save ( model . state_dict (), save_model_path ) best_f = f \u7b2c\u4e94\u6b65: \u8bc4\u4f30\u4ee3\u7801\u7684\u5b9e\u73b0 \u00b6 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/ner/idcnn/train.py # \u8bc4\u4f30\u51fd\u6570 def evaluate ( model , dev_loader ): # \u5c06\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f model . eval () # \u521d\u59cb\u5316\u9884\u6d4b\u5217\u8868, \u6807\u7b7e\u5217\u8868 pred = [] gold = [] print ( 'evaluate' ) # \u5faa\u73af\u904d\u5386\u6d4b\u8bd5\u96c6, \u5e76\u8bc4\u4f30\u5173\u952e\u6307\u6807 for i , dev_batch in enumerate ( dev_loader ): sentence , masks , tags = dev_batch # \u5bf9\u6570\u636e\u8fdb\u884cVariable\u5c01\u88c5 sentence , masks , tags = Variable ( sentence ), Variable ( masks ), Variable ( tags ) # \u662f\u5426\u4f7f\u7528GPU\u8fdb\u884c\u52a0\u901f\u63a8\u7406 if use_cuda : sentence = sentence . cuda () masks = masks . cuda () tags = tags . cuda () # \u5229\u7528\u6a21\u578b\u8fdb\u884c\u63a8\u7406 predict_tags = model ( sentence , masks ) # \u5c06\u9884\u6d4b\u503c\u548c\u771f\u5b9e\u6807\u7b7e\u6dfb\u52a0\u8fdb\u7ed3\u679c\u5217\u8868\u4e2d pred . extend ([ t for t in predict_tags . tolist ()]) gold . extend ([ t for t in tags . tolist ()]) # \u5c06\u6570\u5b57\u5316\u6807\u7b7e\u6620\u5c04\u56de\u771f\u5b9e\u6807\u7b7e pred_label , gold_label = recover_label ( pred , gold , l2i_dic , i2l_dic ) # \u8ba1\u7b97\u5173\u952e\u6307\u6807 acc , p , r , f = get_ner_fmeasure ( gold_label , pred_label ) print ( 'p: {} \uff0cr: {} , f: {} ' . format ( p , r , f )) # \u8bc4\u4f30\u7ed3\u675f\u540e, \u5c06\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bad\u7ec3\u6a21\u5f0f model . train () return acc , p , r , f \u8c03\u7528: python train.py \u8f93\u51fa: max_length: 256 vocab_size: 21128 /home/ec2-user/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1 \"num_layers={}\".format(dropout, num_layers)) epoch: 0\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:00<00:00, 1.04it/s] epoch: 0\uff0closs: 2.960085868835449, best_f1: -100 evaluate gold_num = 1042 pred_num = 369 right_num = 0 p: 0.0\uff0cr: 0.0, f: -1 epoch: 1\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.01s/it] epoch: 1\uff0closs: 1.3307428359985352, best_f1: -1 evaluate gold_num = 1042 pred_num = 96 right_num = 0 p: 0.0\uff0cr: 0.0, f: -1 epoch: 2\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:08<00:00, 1.03s/it] epoch: 2\uff0closs: 1.3992414474487305, best_f1: -1 evaluate gold_num = 1042 pred_num = 77 right_num = 3 p: 0.03896103896103896\uff0cr: 0.0028790786948176585, f: 0.005361930294906167 epoch: 3\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:08<00:00, 1.03s/it] epoch: 3\uff0closs: 0.9490184783935547, best_f1: 0.005361930294906167 evaluate gold_num = 1042 pred_num = 209 right_num = 2 p: 0.009569377990430622\uff0cr: 0.0019193857965451055, f: 0.0031974420463629096 epoch: 4\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:08<00:00, 1.03s/it] epoch: 4\uff0closs: 0.7577829360961914, best_f1: 0.005361930294906167 evaluate gold_num = 1042 pred_num = 390 right_num = 129 p: 0.33076923076923076\uff0cr: 0.1238003838771593, f: 0.18016759776536315 epoch: 5\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:07<00:00, 1.02s/it] epoch: 5\uff0closs: 0.6704387664794922, best_f1: 0.18016759776536315 evaluate gold_num = 1042 pred_num = 540 right_num = 260 p: 0.48148148148148145\uff0cr: 0.2495201535508637, f: 0.3286978508217446 epoch: 6\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:07<00:00, 1.02s/it] epoch: 6\uff0closs: 0.3735923767089844, best_f1: 0.3286978508217446 evaluate gold_num = 1042 pred_num = 857 right_num = 638 p: 0.7444574095682613\uff0cr: 0.6122840690978887, f: 0.6719325961032122 epoch: 7\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 7\uff0closs: 0.23816967010498047, best_f1: 0.6719325961032122 evaluate gold_num = 1042 pred_num = 1010 right_num = 733 p: 0.7257425742574257\uff0cr: 0.7034548944337812, f: 0.7144249512670564 epoch: 8\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 8\uff0closs: 0.20075607299804688, best_f1: 0.7144249512670564 evaluate gold_num = 1042 pred_num = 1023 right_num = 725 p: 0.7086999022482894\uff0cr: 0.6957773512476008, f: 0.7021791767554479 epoch: 9\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 9\uff0closs: 0.3249549865722656, best_f1: 0.7144249512670564 evaluate gold_num = 1042 pred_num = 1035 right_num = 751 p: 0.7256038647342995\uff0cr: 0.7207293666026872, f: 0.7231584015406838 epoch: 10\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 10\uff0closs: 0.38639259338378906, best_f1: 0.7231584015406838 evaluate gold_num = 1042 pred_num = 1008 right_num = 777 p: 0.7708333333333334\uff0cr: 0.7456813819577736, f: 0.758048780487805 epoch: 11\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 11\uff0closs: 0.09833717346191406, best_f1: 0.758048780487805 evaluate gold_num = 1042 pred_num = 950 right_num = 817 p: 0.86\uff0cr: 0.7840690978886756, f: 0.820281124497992 epoch: 12\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 12\uff0closs: 0.067718505859375, best_f1: 0.820281124497992 evaluate gold_num = 1042 pred_num = 966 right_num = 813 p: 0.8416149068322981\uff0cr: 0.7802303262955854, f: 0.8097609561752989 epoch: 13\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 13\uff0closs: 0.10879707336425781, best_f1: 0.820281124497992 evaluate gold_num = 1042 pred_num = 957 right_num = 827 p: 0.864158829676071\uff0cr: 0.7936660268714012, f: 0.8274137068534267 epoch: 14\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 14\uff0closs: 0.09510421752929688, best_f1: 0.8274137068534267 evaluate gold_num = 1042 pred_num = 970 right_num = 854 p: 0.8804123711340206\uff0cr: 0.8195777351247601, f: 0.848906560636183 epoch: 15\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.02s/it] epoch: 15\uff0closs: 0.1023712158203125, best_f1: 0.848906560636183 evaluate gold_num = 1042 pred_num = 997 right_num = 868 p: 0.8706118355065195\uff0cr: 0.8330134357005758, f: 0.851397743992153 epoch: 16\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:07<00:00, 1.02s/it] epoch: 16\uff0closs: 0.07217025756835938, best_f1: 0.851397743992153 evaluate gold_num = 1042 pred_num = 966 right_num = 893 p: 0.9244306418219461\uff0cr: 0.8570057581573897, f: 0.8894422310756972 epoch: 17\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 17\uff0closs: 0.05801582336425781, best_f1: 0.8894422310756972 evaluate gold_num = 1042 pred_num = 980 right_num = 928 p: 0.9469387755102041\uff0cr: 0.8905950095969289, f: 0.9179030662710188 epoch: 18\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:07<00:00, 1.02s/it] epoch: 18\uff0closs: 0.08353233337402344, best_f1: 0.9179030662710188 evaluate gold_num = 1042 pred_num = 1003 right_num = 956 p: 0.9531405782652044\uff0cr: 0.9174664107485605, f: 0.9349633251833741 epoch: 19\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 19\uff0closs: 0.04948616027832031, best_f1: 0.9349633251833741 evaluate gold_num = 1042 pred_num = 1018 right_num = 953 p: 0.9361493123772102\uff0cr: 0.9145873320537428, f: 0.9252427184466019 epoch: 20\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.01s/it] epoch: 20\uff0closs: 0.0920867919921875, best_f1: 0.9349633251833741 evaluate gold_num = 1042 pred_num = 1019 right_num = 963 p: 0.9450441609421001\uff0cr: 0.9241842610364683, f: 0.9344978165938864 epoch: 21\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.01s/it] epoch: 21\uff0closs: 0.08744049072265625, best_f1: 0.9349633251833741 evaluate gold_num = 1042 pred_num = 1026 right_num = 951 p: 0.9269005847953217\uff0cr: 0.9126679462571977, f: 0.9197292069632496 epoch: 22\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 22\uff0closs: 0.18969345092773438, best_f1: 0.9349633251833741 evaluate gold_num = 1042 pred_num = 1047 right_num = 991 p: 0.9465138490926457\uff0cr: 0.9510556621880998, f: 0.9487793202489229 epoch: 23\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 23\uff0closs: 0.0296478271484375, best_f1: 0.9487793202489229 evaluate gold_num = 1042 pred_num = 1019 right_num = 995 p: 0.9764474975466143\uff0cr: 0.95489443378119, f: 0.9655507035419698 epoch: 24\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 24\uff0closs: 0.03677558898925781, best_f1: 0.9655507035419698 evaluate gold_num = 1042 pred_num = 1030 right_num = 1012 p: 0.9825242718446602\uff0cr: 0.9712092130518234, f: 0.9768339768339768 epoch: 25\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 25\uff0closs: 0.02207183837890625, best_f1: 0.9768339768339768 evaluate gold_num = 1042 pred_num = 1032 right_num = 1016 p: 0.9844961240310077\uff0cr: 0.9750479846449136, f: 0.9797492767598842 epoch: 26\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 26\uff0closs: 0.01473236083984375, best_f1: 0.9797492767598842 evaluate gold_num = 1042 pred_num = 1031 right_num = 1014 p: 0.9835111542192047\uff0cr: 0.9731285988483686, f: 0.9782923299565847 epoch: 27\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 27\uff0closs: 0.04078865051269531, best_f1: 0.9797492767598842 evaluate gold_num = 1042 pred_num = 1028 right_num = 1014 p: 0.9863813229571985\uff0cr: 0.9731285988483686, f: 0.9797101449275363 epoch: 28\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 28\uff0closs: 0.0731048583984375, best_f1: 0.9797492767598842 evaluate gold_num = 1042 pred_num = 1134 right_num = 967 p: 0.8527336860670194\uff0cr: 0.9280230326295585, f: 0.8887867647058822 epoch: 29\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 29\uff0closs: 0.03252983093261719, best_f1: 0.9797492767598842 evaluate gold_num = 1042 pred_num = 1015 right_num = 955 p: 0.9408866995073891\uff0cr: 0.9165067178502879, f: 0.9285367039377735 epoch: 30\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 30\uff0closs: 0.09288597106933594, best_f1: 0.9797492767598842 evaluate gold_num = 1042 pred_num = 1023 right_num = 990 p: 0.967741935483871\uff0cr: 0.9500959692898272, f: 0.9588377723970944 epoch: 31\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 31\uff0closs: 0.011251449584960938, best_f1: 0.9797492767598842 evaluate gold_num = 1042 pred_num = 1025 right_num = 998 p: 0.9736585365853658\uff0cr: 0.9577735124760077, f: 0.9656507014997581 epoch: 32\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 32\uff0closs: 0.151336669921875, best_f1: 0.9797492767598842 evaluate gold_num = 1042 pred_num = 1041 right_num = 1017 p: 0.9769452449567724\uff0cr: 0.9760076775431862, f: 0.9764762361977918 epoch: 33\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 33\uff0closs: 0.008983612060546875, best_f1: 0.9797492767598842 evaluate gold_num = 1042 pred_num = 1040 right_num = 1020 p: 0.9807692307692307\uff0cr: 0.9788867562380038, f: 0.9798270893371758 epoch: 34\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 34\uff0closs: 0.010942459106445312, best_f1: 0.9798270893371758 evaluate gold_num = 1042 pred_num = 1042 right_num = 1023 p: 0.9817658349328215\uff0cr: 0.9817658349328215, f: 0.9817658349328215 epoch: 35\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 35\uff0closs: 0.0137786865234375, best_f1: 0.9817658349328215 evaluate gold_num = 1042 pred_num = 1040 right_num = 1025 p: 0.9855769230769231\uff0cr: 0.9836852207293666, f: 0.9846301633045149 epoch: 36\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.01s/it] epoch: 36\uff0closs: 0.010051727294921875, best_f1: 0.9846301633045149 evaluate gold_num = 1042 pred_num = 1040 right_num = 1030 p: 0.9903846153846154\uff0cr: 0.9884836852207294, f: 0.989433237271854 epoch: 37\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 37\uff0closs: 0.01131439208984375, best_f1: 0.989433237271854 evaluate gold_num = 1042 pred_num = 1036 right_num = 1030 p: 0.9942084942084942\uff0cr: 0.9884836852207294, f: 0.9913378248315688 epoch: 38\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 38\uff0closs: 0.008291244506835938, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1038 right_num = 1029 p: 0.9913294797687862\uff0cr: 0.9875239923224568, f: 0.989423076923077 epoch: 39\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 39\uff0closs: 0.010332107543945312, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1040 right_num = 1028 p: 0.9884615384615385\uff0cr: 0.9865642994241842, f: 0.9875120076849184 epoch: 40\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.01s/it] epoch: 40\uff0closs: 0.017686843872070312, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1040 right_num = 1030 p: 0.9903846153846154\uff0cr: 0.9884836852207294, f: 0.989433237271854 epoch: 41\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 41\uff0closs: 0.009771347045898438, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1043 right_num = 1013 p: 0.9712368168744008\uff0cr: 0.972168905950096, f: 0.9717026378896882 epoch: 42\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 42\uff0closs: 0.20522689819335938, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1023 right_num = 886 p: 0.8660801564027371\uff0cr: 0.8502879078694817, f: 0.8581113801452784 epoch: 43\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 43\uff0closs: 0.0157928466796875, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1039 right_num = 991 p: 0.9538017324350336\uff0cr: 0.9510556621880998, f: 0.9524267179240749 epoch: 44\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 44\uff0closs: 0.00662994384765625, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1024 right_num = 996 p: 0.97265625\uff0cr: 0.9558541266794626, f: 0.9641819941916748 epoch: 45\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 45\uff0closs: 0.009222030639648438, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1046 right_num = 1028 p: 0.982791586998088\uff0cr: 0.9865642994241842, f: 0.9846743295019157 epoch: 46\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.01s/it] epoch: 46\uff0closs: 0.012540817260742188, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1044 right_num = 1020 p: 0.9770114942528736\uff0cr: 0.9788867562380038, f: 0.977948226270374 epoch: 47\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.01s/it] epoch: 47\uff0closs: 0.0095062255859375, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1038 right_num = 1018 p: 0.9807321772639692\uff0cr: 0.9769673704414588, f: 0.9788461538461538 epoch: 48\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.00s/it] epoch: 48\uff0closs: 0.010555267333984375, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1036 right_num = 1026 p: 0.9903474903474904\uff0cr: 0.9846449136276392, f: 0.9874879692011549 epoch: 49\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 49\uff0closs: 0.030834197998046875, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1040 right_num = 1034 p: 0.9942307692307693\uff0cr: 0.9923224568138196, f: 0.9932756964457252 epoch: 50\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 50\uff0closs: 0.0063266754150390625, best_f1: 0.9932756964457252 evaluate gold_num = 1042 pred_num = 1038 right_num = 1036 p: 0.9980732177263969\uff0cr: 0.9942418426103646, f: 0.9961538461538462 epoch: 51\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 51\uff0closs: 0.0021381378173828125, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1040 right_num = 1030 p: 0.9903846153846154\uff0cr: 0.9884836852207294, f: 0.989433237271854 epoch: 52\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.01s/it] epoch: 52\uff0closs: 0.12633514404296875, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1153 right_num = 1006 p: 0.8725065047701648\uff0cr: 0.9654510556621881, f: 0.9166287015945331 epoch: 53\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 53\uff0closs: 0.006160736083984375, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1071 right_num = 878 p: 0.8197945845004668\uff0cr: 0.8426103646833013, f: 0.8310459062943681 epoch: 54\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 54\uff0closs: 0.004974365234375, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1025 right_num = 994 p: 0.9697560975609756\uff0cr: 0.9539347408829175, f: 0.9617803580067731 epoch: 55\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 55\uff0closs: 0.00543212890625, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1038 right_num = 1022 p: 0.9845857418111753\uff0cr: 0.980806142034549, f: 0.9826923076923078 epoch: 56\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 56\uff0closs: 0.007305145263671875, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1036 right_num = 1026 p: 0.9903474903474904\uff0cr: 0.9846449136276392, f: 0.9874879692011549 epoch: 57\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 57\uff0closs: 0.010717391967773438, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1040 right_num = 1027 p: 0.9875\uff0cr: 0.9856046065259118, f: 0.9865513928914506 epoch: 58\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 58\uff0closs: 0.0052585601806640625, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1042 right_num = 1028 p: 0.9865642994241842\uff0cr: 0.9865642994241842, f: 0.9865642994241842 epoch: 59\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 59\uff0closs: 0.0044727325439453125, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1042 right_num = 1032 p: 0.9904030710172744\uff0cr: 0.9904030710172744, f: 0.9904030710172744 epoch: 60\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 60\uff0closs: 0.0077114105224609375, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1040 right_num = 1029 p: 0.989423076923077\uff0cr: 0.9875239923224568, f: 0.9884726224783862 epoch: 61\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 61\uff0closs: 0.009601593017578125, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1042 right_num = 1034 p: 0.9923224568138196\uff0cr: 0.9923224568138196, f: 0.9923224568138196 epoch: 62\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 62\uff0closs: 0.018930435180664062, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1046 right_num = 1032 p: 0.9866156787762906\uff0cr: 0.9904030710172744, f: 0.9885057471264367 epoch: 63\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 63\uff0closs: 0.0053234100341796875, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1048 right_num = 1035 p: 0.9875954198473282\uff0cr: 0.9932821497120922, f: 0.9904306220095693 epoch: 64\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 64\uff0closs: 0.003246307373046875, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1042 right_num = 1029 p: 0.9875239923224568\uff0cr: 0.9875239923224568, f: 0.9875239923224568 epoch: 65\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 65\uff0closs: 0.004497528076171875, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1046 right_num = 1032 p: 0.9866156787762906\uff0cr: 0.9904030710172744, f: 0.9885057471264367 epoch: 66\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 66\uff0closs: 0.007976531982421875, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1033 right_num = 1010 p: 0.9777347531461762\uff0cr: 0.9692898272552783, f: 0.9734939759036145 epoch: 67\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 67\uff0closs: 0.0014057159423828125, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1034 right_num = 1032 p: 0.9980657640232108\uff0cr: 0.9904030710172744, f: 0.9942196531791907 epoch: 68\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 68\uff0closs: 0.03486824035644531, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1042 right_num = 1034 p: 0.9923224568138196\uff0cr: 0.9923224568138196, f: 0.9923224568138196 epoch: 69\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.01s/it] epoch: 69\uff0closs: 0.00244140625, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1042 right_num = 1038 p: 0.9961612284069098\uff0cr: 0.9961612284069098, f: 0.9961612284069098 epoch: 70\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 70\uff0closs: 0.0067806243896484375, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1046 right_num = 1036 p: 0.9904397705544933\uff0cr: 0.9942418426103646, f: 0.9923371647509578 epoch: 71\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 71\uff0closs: 0.0281219482421875, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1042 right_num = 1038 p: 0.9961612284069098\uff0cr: 0.9961612284069098, f: 0.9961612284069098 epoch: 72\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 72\uff0closs: 0.046474456787109375, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1044 right_num = 1030 p: 0.9865900383141762\uff0cr: 0.9884836852207294, f: 0.987535953978907 epoch: 73\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 73\uff0closs: 0.010404586791992188, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1053 right_num = 1026 p: 0.9743589743589743\uff0cr: 0.9846449136276392, f: 0.9794749403341289 epoch: 74\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 74\uff0closs: 0.00775146484375, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1040 right_num = 1023 p: 0.9836538461538461\uff0cr: 0.9817658349328215, f: 0.9827089337175792 epoch: 75\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 75\uff0closs: 0.00206756591796875, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1035 right_num = 1027 p: 0.9922705314009662\uff0cr: 0.9856046065259118, f: 0.9889263360616274 epoch: 76\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 76\uff0closs: 0.0015316009521484375, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1051 right_num = 1042 p: 0.9914367269267365\uff0cr: 1.0, f: 0.9956999522216914 epoch: 77\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 77\uff0closs: 0.0028858184814453125, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1042 right_num = 1038 p: 0.9961612284069098\uff0cr: 0.9961612284069098, f: 0.9961612284069098 epoch: 78\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 78\uff0closs: 0.02457427978515625, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1038 right_num = 1022 p: 0.9845857418111753\uff0cr: 0.980806142034549, f: 0.9826923076923078 epoch: 79\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 79\uff0closs: 0.018167495727539062, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1049 right_num = 1035 p: 0.9866539561487131\uff0cr: 0.9932821497120922, f: 0.9899569583931133 epoch: 80\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 80\uff0closs: 0.007198333740234375, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1042 right_num = 1034 p: 0.9923224568138196\uff0cr: 0.9923224568138196, f: 0.9923224568138196 Done!!! best_f = 0.9961612284069098 \u8ffd\u6eaf\u65e5\u5fd7\u53ef\u4ee5\u53d1\u73b0\u6700\u4f18\u7684\u6a21\u578b\u662f\u5728epoch = 69, \u4e5f\u5c31\u662f\u771f\u5b9e\u8bad\u7ec3\u7684\u7b2c70\u8f6e\u6b21\u540e\u4ea7\u751f\u7684!!! epoch: 69\uff0closs: 0.00244140625, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1042 right_num = 1038 p: 0.9961612284069098\uff0cr: 0.9961612284069098, f: 0.9961612284069098 \u5c0f\u8282\u603b\u7ed3 \u00b6 \u672c\u5c0f\u8282\u638c\u63e1\u4e86IDCNN\u6a21\u578b\u7684\u67b6\u6784\u548c\u539f\u7406, \u5e76\u638c\u63e1\u4e86\u5168\u90e8\u7684\u4ee3\u7801\u5b9e\u73b0.","title":"3.1 \u5feb\u901f\u90e8\u7f72\u7684IDCNN\u6a21\u578b"},{"location":"3_1.html#idcnn","text":"","title":"IDCNN\u6a21\u578b"},{"location":"3_1.html#_1","text":"\u638c\u63e1IDCNN\u6a21\u578b\u7684\u7ed3\u6784\u548c\u539f\u7406. \u638c\u63e1IDCNN\u6a21\u578b\u7684\u5b9e\u73b0.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"3_1.html#idcnn_1","text":"IDCNN\u6a21\u578b\u6e90\u4e8e\u8bba\u6587<< Fast and Accurate Entity Recognition with Iterated Dilated Convolutions >>, \u6838\u5fc3\u64cd\u4f5c\u662f\u81a8\u80c0\u5377\u79ef. \u81a8\u80c0\u5377\u79ef\u53ef\u4ee5\u8df3\u8fc7\u4e00\u90e8\u5206\u795e\u7ecf\u5143, \u540c\u65f6\u6269\u5927\u611f\u53d7\u91ce\u7684\u8303\u56f4: \u4e0b\u56fe\u5de6\u4fa7\u5c55\u793a\u81a8\u80c0\u7387\u7b49\u4e8e1\u7684\u6807\u51c6\u5377\u79ef\u64cd\u4f5c, \u4e5f\u662f\u7ecf\u5178CNN\u7684\u5b9e\u73b0\u65b9\u5f0f; \u4e0b\u56fe\u53f3\u4fa7\u5c55\u793a\u81a8\u80c0\u7387\u7b49\u4e8e2\u7684\u81a8\u80c0\u5377\u79ef, \u4e5f\u662f\u8bba\u6587\u4e2d\u8981\u91c7\u7528\u7684\u65b9\u5f0f: \u5f53\u6211\u4eec\u91c7\u7528\u4f20\u7edf\u5377\u79ef\u64cd\u4f5c, \u795e\u7ecf\u7f51\u7edc\u7684\u66f4\u9ad8\u5c42\u53ef\u4ee5\u5982\u4e0b\u56fe\u6240\u793a\u7684\u83b7\u53d6\u4e00\u5b9a\u8303\u56f4\u5185\u7684\u6587\u672c\u8bed\u4e49\u4fe1\u606f: \u5f53\u6211\u4eec\u91c7\u7528\u81a8\u80c0\u5377\u79ef\u64cd\u4f5c, \u795e\u7ecf\u7f51\u7edc\u7684\u66f4\u9ad8\u5c42\u53ef\u4ee5\u5982\u4e0b\u56fe\u6240\u793a\u7684\u83b7\u53d6\u66f4\u5927\u8303\u56f4\u5185\u7684\u6587\u672c\u8bed\u4e49\u4fe1\u606f: \u8bba\u6587\u4e2d\u5bf9\u51e0\u4e2a\u7ecf\u5178NER\u6a21\u578b\u505a\u4e86\u5bf9\u6bd4\u6d4b\u8bd5, \u663e\u793aIDCNN\u6a21\u578b\u7684\u6548\u679c\u53ef\u4ee5\u5ab2\u7f8eBiLSTM + CRF, \u5e76\u663e\u8457\u7684\u8d85\u8d8aBiLSTM\u6a21\u578b\u672c\u8eab: IDCNN\u5728\u5de5\u4e1a\u754c\u6700\u5927\u7684\u4eae\u70b9\u5728\u4e8e\u5904\u7406\u901f\u5ea6\u4e0a, \u8bba\u6587\u4e2d\u4e5f\u8fdb\u884c\u4e86\u5bf9\u6bd4\u6d4b\u8bd5, \u76f8\u6bd4\u4e8e\u6548\u679c\u76f8\u540c\u7684BiLSTM + CRF, \u53ef\u4ee5\u8fbe\u52308\u500d\u7684\u63a8\u7406\u52a0\u901f:","title":"IDCNN\u6a21\u578b\u7684\u7ed3\u6784\u548c\u539f\u7406"},{"location":"3_1.html#idcnn_2","text":"IDCNN\u6a21\u578b\u7684\u5b9e\u73b0\u6b65\u9aa4\u5982\u4e0b: \u7b2c\u4e00\u6b65: \u914d\u7f6e\u51fd\u6570\u7684\u5b9e\u73b0 \u7b2c\u4e8c\u6b65: \u5de5\u5177\u7c7b\u51fd\u6570\u7684\u5b9e\u73b0 \u7b2c\u4e09\u6b65: \u6a21\u578b\u6838\u5fc3\u7c7b\u7684\u5b9e\u73b0 \u7b2c\u56db\u6b65: \u8bad\u7ec3\u4ee3\u7801\u7684\u5b9e\u73b0 \u7b2c\u4e94\u6b65: \u9884\u6d4b\u4ee3\u7801\u7684\u5b9e\u73b0","title":"IDCNN\u6a21\u578b\u7684\u5b9e\u73b0"},{"location":"3_1.html#_2","text":"\u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/ner/idcnn/config.py # \u8bbe\u5b9alabel_to_id\u7684\u6620\u5c04\u5b57\u5178, \u91c7\u7528BIEO\u6807\u6ce8\u6a21\u5f0f, \u5916\u52a03\u4e2a\u7279\u6b8a\u5b57\u7b26<pad>, <start>, <eos> l2i_dic = { 'O' : 0 , u 'B-sym' : 1 , u 'B-dis' : 2 , u 'I-sym' : 3 , u 'I-dis' : 4 , u 'E-sym' : 5 , u 'E-dis' : 6 , '<pad>' : 7 , '<start>' : 8 , '<eos>' : 9 } # \u4e0a\u9762\u7684\u9006\u5411\u5b57\u5178, id_to_label i2l_dic = { 0 : 'O' , 1 : u 'B-sym' , 2 : u 'B-dis' , 3 : u 'I-sym' , 4 : u 'I-dis' , 5 : u 'E-sym' , 6 : u 'E-dis' , 7 : '<pad>' , 8 : '<start>' , 9 : '<eos>' } # \u8bad\u7ec3\u96c6, \u6d4b\u8bd5\u96c6, \u8bcd\u8868 train_file = './data/train.txt' dev_file = './data/test.txt' vocab_file = './data/vocab.txt' save_model_path = './saved_model/idcnn_crf.pt' model_path = './saved_model/idcnn_crf_1.pt' # \u8bbe\u7f6e\u5173\u952e\u7684\u8d85\u53c2\u6570 max_length = 256 batch_size = 32 epochs = 100 tagset_size = len ( l2i_dic ) dropout = 0.4 use_cuda = True","title":"\u7b2c\u4e00\u6b65: \u914d\u7f6e\u51fd\u6570\u7684\u5b9e\u73b0"},{"location":"3_1.html#_3","text":"\u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/ner/idcnn/utils.py from config import * class InputFeatures ( object ): def __init__ ( self , text , label , input_id , label_id , input_mask ): self . text = text self . label = label self . input_id = input_id self . label_id = label_id self . input_mask = input_mask # \u8bfb\u53d6\u5b57\u5178\u6587\u4ef6, \u5e76\u6784\u9020\u5b57\u5178 def load_vocab ( vocab_file ): vocab = {} index = 0 with open ( vocab_file , 'r' , encoding = 'utf-8' ) as reader : while True : token = reader . readline () if not token : break token = token . strip () vocab [ token ] = index index += 1 return vocab # \u52a0\u8f7d\u8bad\u7ec3\u96c6, \u6d4b\u8bd5\u96c6\u7684\u539f\u59cb\u6570\u636e def load_file ( file_path ): contents = open ( file_path , encoding = 'utf-8' ) . readlines () text = [] label = [] texts = [] labels = [] for line in contents : if line != ' \\n ' : line = line . strip () . split ( ' ' ) text . append ( line [ 0 ]) label . append ( line [ - 1 ]) else : texts . append ( text ) labels . append ( label ) text = [] label = [] return texts , labels # \u52a0\u8f7d\u6570\u636e def load_data ( file_path , max_length , label_dic , vocab ): texts , labels = load_file ( file_path ) assert len ( texts ) == len ( labels ) result = [] for i in range ( len ( texts )): assert len ( texts [ i ]) == len ( labels [ i ]) token = texts [ i ] label = labels [ i ] # \u6570\u636e\u88c1\u526a if len ( token ) > max_length - 2 : token = token [ 0 : ( max_length - 2 )] label = label [ 0 : ( max_length - 2 )] # \u6570\u636e\u52a0\u5de5 tokens_f = [ '[CLS]' ] + token + [ '[SEP]' ] label_f = [ '<start>' ] + label + [ '<eos>' ] # \u6570\u5b57\u5316\u5f20\u91cf\u6620\u5c04 input_ids = [ int ( vocab [ i ]) if i in vocab else int ( vocab [ '[UNK]' ]) for i in tokens_f ] label_ids = [ label_dic [ i ] for i in label_f ] # \u6784\u9020\u8f93\u5165\u6570\u636e\u548c\u63a9\u7801 input_mask = [ 1 ] * len ( input_ids ) while len ( input_ids ) < max_length : input_ids . append ( 0 ) input_mask . append ( 0 ) label_ids . append ( label_dic [ '<pad>' ]) # \u786e\u8ba4\u6570\u636e\u957f\u5ea6 assert len ( input_ids ) == max_length assert len ( input_mask ) == max_length assert len ( label_ids ) == max_length # \u5b9e\u4f8b\u5316\u7279\u5f81\u5bf9\u8c61 feature = InputFeatures ( text = tokens_f , label = label_f , input_id = input_ids , input_mask = input_mask , label_id = label_ids ) result . append ( feature ) return result # \u5229\u7528\u6807\u7b7e\u5b57\u5178\u6062\u590d\u771f\u5b9e\u7684\u9884\u6d4b\u6807\u7b7e def recover_label ( pred_var , gold_var , l2i_dic , i2l_dic ): assert len ( pred_var ) == len ( gold_var ) pred_variable = [] gold_variable = [] # \u8fdb\u884c\u6570\u636e\u622a\u53d6 for i in range ( len ( gold_var )): start_index = gold_var [ i ] . index ( l2i_dic [ '<start>' ]) end_index = gold_var [ i ] . index ( l2i_dic [ '<eos>' ]) pred_variable . append ( pred_var [ i ][ start_index : end_index ]) gold_variable . append ( gold_var [ i ][ start_index : end_index ]) pred_label = [] gold_label = [] # \u6807\u7b7e\u53cd\u5411\u6620\u5c04 for j in range ( len ( gold_variable )): pred_label . append ([ i2l_dic [ t ] for t in pred_variable [ j ] ]) gold_label . append ([ i2l_dic [ t ] for t in gold_variable [ j ] ]) return pred_label , gold_label # \u8ba1\u7b97NER\u7684\u5173\u952e\u6307\u6807 def get_ner_fmeasure ( golden_lists , predict_lists , label_type = 'BMES' ): sent_num = len ( golden_lists ) golden_full = [] predict_full = [] right_full = [] right_tag = 0 all_tag = 0 for idx in range ( 0 , sent_num ): golden_list = golden_lists [ idx ] predict_list = predict_lists [ idx ] for idy in range ( len ( golden_list )): if golden_list [ idy ] == predict_list [ idy ]: right_tag += 1 all_tag += len ( golden_list ) # \u4e0d\u540c\u7684\u6807\u6ce8\u4f53\u7cfb\u8c03\u7528\u4e0d\u540c\u7684\u5904\u7406\u51fd\u6570 if label_type == 'BMES' : gold_matrix = get_ner_BMES ( golden_list ) pred_matrix = get_ner_BMES ( predict_list ) else : gold_matrix = get_ner_BIO ( golden_list ) pred_matrix = get_ner_BIO ( predict_list ) right_ner = list ( set ( gold_matrix ) . intersection ( set ( pred_matrix ))) golden_full += gold_matrix predict_full += pred_matrix right_full += right_ner right_num = len ( right_full ) golden_num = len ( golden_full ) predict_num = len ( predict_full ) # \u9c81\u68d2\u6027\u5904\u7406 if predict_num == 0 : precision = - 1 else : precision = ( right_num + 0.0 ) / predict_num if golden_num == 0 : recall = - 1 else : recall = ( right_num + 0.0 ) / golden_num if ( precision == - 1 ) or ( recall == - 1 ) or ( precision + recall ) <= 0. : f_measure = - 1 else : f_measure = 2 * precision * recall / ( precision + recall ) accuracy = ( right_tag + 0.0 ) / all_tag print ( 'gold_num = ' , golden_num , ' pred_num = ' , predict_num , ' right_num = ' , right_num ) return accuracy , precision , recall , f_measure # \u53cd\u5411\u6620\u5c04\u7684\u63d0\u53d6\u51fd\u6570 def reverse_style ( input_string ): target_position = input_string . index ( '[' ) input_len = len ( input_string ) output_string = input_string [ target_position : input_len ] + input_string [ 0 : target_position ] return output_string # \u6309\u7167BMES\u6807\u6ce8\u6a21\u5f0f, \u8fdb\u884c\u5b9e\u4f53\u63d0\u53d6\u7684\u51fd\u6570 def get_ner_BMES ( label_list ): list_len = len ( label_list ) begin_label = 'B-' end_label = 'E-' single_label = 'S-' whole_tag = '' index_tag = '' tag_list = [] stand_matrix = [] for i in range ( 0 , list_len ): current_label = label_list [ i ] . upper () if begin_label in current_label : if index_tag != '' : tag_list . append ( whole_tag + ',' + str ( i - 1 )) whole_tag = current_label . replace ( begin_label , '' , 1 ) + '[' + str ( i ) index_tag = current_label . replace ( begin_label , '' , 1 ) elif single_label in current_label : if index_tag != '' : tag_list . append ( whole_tag + ',' + str ( i - 1 )) whole_tag = current_label . replace ( single_label , '' , 1 ) + '[' + str ( i ) tag_list . append ( whole_tag ) whole_tag = '' index_tag = '' elif end_label in current_label : if index_tag != '' : tag_list . append ( whole_tag + ',' + str ( i )) whole_tag = '' index_tag = '' else : continue if ( whole_tag != '' ) & ( index_tag != '' ): tag_list . append ( whole_tag ) tag_list_len = len ( tag_list ) for i in range ( 0 , tag_list_len ): if len ( tag_list [ i ]) > 0 : tag_list [ i ] = tag_list [ i ] + ']' insert_list = reverse_style ( tag_list [ i ]) stand_matrix . append ( insert_list ) return stand_matrix","title":"\u7b2c\u4e8c\u6b65: \u5de5\u5177\u7c7b\u51fd\u6570\u7684\u5b9e\u73b0"},{"location":"3_1.html#_4","text":"\u6a21\u578b\u7c7b\u5305\u542b3\u90e8\u5206, \u9700\u8981\u5206\u522b\u5b9e\u73b0: 1: CRF\u7c7b 2: IDCNN\u7c7b 3: IDCNN-CRF\u7c7b CRF\u7c7b\u91c7\u7528\u7ecf\u5178\u5b9e\u73b0\u5373\u53ef, \u5305\u62ec\u672a\u6765\u5728\u642d\u5efa\u81ea\u5df1\u7684\u6a21\u578b\u65f6, \u53ef\u4ee5\u76f4\u63a5\"\u5957\u7528\u8f6e\u5b50\", \u800c\u4e0d\u662f\u81ea\u5df1\u53bb\"\u9020\u8f6e\u5b50\". \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/ner/idcnn/model/crf.py IDCNN\u7c7b\u7684\u5b9e\u73b0 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/ner/idcnn/model/cnn.py import torch import torch.nn as nn import torch.nn.functional as F from collections import OrderedDict from config import * # \u6784\u5efaIDCNN\u6838\u5fc3\u7c7b\u7684\u4ee3\u7801 class IDCNN ( nn . Module ): def __init__ ( self , input_size , filters , kernel_size = 3 , num_block = 4 ): super ( IDCNN , self ) . __init__ () self . layers = [{ 'dilation' : 1 }, { 'dilation' : 1 }, { 'dilation' : 2 }] net = nn . Sequential () norms_1 = nn . ModuleList ([ LayerNorm ( 256 ) for _ in range ( len ( self . layers ))]) norms_2 = nn . ModuleList ([ LayerNorm ( 256 ) for _ in range ( num_block )]) # \u4f9d\u6b21\u6784\u5efa\u6bcf\u4e00\u5c42\u7f51\u7edc for i in range ( len ( self . layers )): dilation = self . layers [ i ][ 'dilation' ] # \u7f51\u7edc\u4e2d\u7684\u7b2c\u4e00\u5c42\u7ed3\u6784\u662fnn.Conv1d single_block = nn . Conv1d ( in_channels = filters , out_channels = filters , kernel_size = kernel_size , dilation = dilation , padding = kernel_size // 2 + dilation - 1 ) # \u6bcf\u4e00\u5c42\u7f51\u7edc\u90fd\u5305\u542b\u5377\u79ef\u5c42, \u6fc0\u6d3b\u5c42, \u6b63\u5219\u5316\u5c42, \u4f9d\u6b21\u6dfb\u52a0\u8fdbnet\u4e2d net . add_module ( 'layer %d ' % i , single_block ) net . add_module ( 'relu' , nn . ReLU ()) net . add_module ( 'layernorm' , norms_1 [ i ]) # \u6700\u540e\u5b9a\u4e49\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42 self . linear = nn . Linear ( input_size , filters ) self . idcnn = nn . Sequential () # \u4f9d\u6b21\u6784\u5efa4\u4e2aBlock for i in range ( num_block ): self . idcnn . add_module ( 'block %i ' % i , net ) self . idcnn . add_module ( 'relu' , nn . ReLU ()) self . idcnn . add_module ( 'layernorm' , norms_2 [ i ]) # \u524d\u5411\u4f20\u64ad\u51fd\u6570 def forward ( self , embeddings , length ): # 1: \u9996\u5148\u5bf9\u8bcd\u5d4c\u5165\u5f20\u91cf\u8fdb\u884c\u5168\u8fde\u63a5\u6620\u5c04\u7684\u8f6c\u6362 embeddings = self . linear ( embeddings ) # 2: \u8c03\u6574\u7b2c1, 2\u7ef4\u5ea6 embeddings = embeddings . permute ( 0 , 2 , 1 ) # 3: \u6700\u540e\u8fdb\u884cIDCNN\u7684\u7279\u5f81\u63d0\u53d6\u5e76\u5c06\u7b2c2\u6b65\u7684\u7ef4\u5ea6\u8c03\u6574\u56de\u539f\u72b6 output = self . idcnn ( embeddings ) . permute ( 0 , 2 , 1 ) return output # \u91c7\u7528\u7ecf\u5178transformer\u7684LayerNorm\u5b9e\u73b0\u7b56\u7565 class LayerNorm ( nn . Module ): def __init__ ( self , features , eps = 1e-6 ): super ( LayerNorm , self ) . __init__ () # \u521d\u59cb\u5316\u4e00\u4e2a\u51681\u7684\u5f20\u91cf, \u521d\u59cb\u5316\u4e00\u4e2a\u51680\u7684\u5f20\u91cf self . a_2 = nn . Parameter ( torch . ones ( features )) self . b_2 = nn . Parameter ( torch . zeros ( features )) self . eps = eps def forward ( self , x ): # \u8ba1\u7b97\u5f97\u5230\u5747\u503c\u548c\u65b9\u5dee, \u6ce8\u610f\u662f\u5728\u5f53\u524d\u6837\u672c\u7684\u6a2a\u5411\u7ef4\u5ea6, \u4ee5\u533a\u522b\u4e8eBatchNorm mean = x . mean ( - 1 , keepdim = True ) std = x . std ( - 1 , keepdim = True ) # \u6309\u7167\u516c\u5f0f\u8ba1\u7b97, \u5e76\u8fd4\u56de\u7ed3\u679c return self . a_2 * ( x - mean ) / ( std + self . eps ) + self . b_2 IDCNN-CRF\u7c7b \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/ner/idcnn/model/idcnn_crf.py import torch.nn as nn from model import CRF from torch.autograd import Variable from model.cnn import IDCNN import torch # \u6784\u5efaIDCNN_CRF\u6a21\u578b\u6838\u5fc3\u7c7b, \u5185\u90e8\u628aIDCNN\u548cCRF\u4e24\u4e2a\u57fa\u7840\u7c7b\u8fdb\u884c\u4e86\u878d\u5408 class IDCNN_CRF ( nn . Module ): def __init__ ( self , vocab_size , tagset_size , embedding_dim , num_filters = 64 , dropout = 0.4 , use_cuda = True ): super ( IDCNN_CRF , self ) . __init__ () # \u91cd\u8981\u53c2\u6570\u521d\u59cb\u5316 self . tagset_size = tagset_size self . embedding_dim = embedding_dim self . num_filters = num_filters self . use_cuda = use_cuda # 1: \u8bbe\u7f6e\u8bcd\u5d4c\u5165\u5c42, \u8fd9\u662f\u6240\u6709NLP\u6a21\u578b\u5fc5\u5907\u7684\u7b2c\u4e00\u6b65 self . embedding = nn . Embedding ( vocab_size , embedding_dim ) # 2: \u5b9e\u4f8b\u5316IDCNN\u7c7b, \u8f93\u5165\u7ef4\u5ea6\u662f\u5d4c\u5165\u5c42\u7684\u8f93\u51fa\u7ef4\u5ea6 self . idcnn = IDCNN ( input_size = embedding_dim , filters = num_filters ) # 3: \u5bf9\u4e8eCNN\u4e3a\u57fa\u7840\u7684\u7f51\u7edc, dropout\u662f\u6807\u51c6\u914d\u7f6e self . dropout = nn . Dropout ( p = dropout ) # 4: \u5b9e\u4f8b\u5316CRF\u5c42, \u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u53c2\u6570\u65b9\u9635, \u5bf9\u5e94\u8f6c\u79fb\u77e9\u9635 self . crf = CRF ( target_size = tagset_size , average_batch = True , use_cuda = use_cuda ) # 5: \u6700\u540e\u5b9a\u4e49\u5168\u8fde\u63a5\u6620\u5c04\u5c42, \u5c06\u5377\u79ef\u7684\u8f93\u51fa\u7ef4\u5ea6\u6620\u5c04\u5230CRF\u5c42\u7684\u8f93\u5165\u7ef4\u5ea6\u4e0a self . linear = nn . Linear ( num_filters , tagset_size + 2 ) # \u83b7\u53d6\u7f51\u7edc\u7684\u8f93\u51fa\u7279\u5f81\u5f20\u91cf def get_output_score ( self , sentence , attention_mask = None ): batch_size = sentence . size ( 0 ) seq_length = sentence . size ( 1 ) # 1: \u6267\u884c\u521d\u59cb\u5316\u51fd\u6570\u7684\u7b2c1\u5c42 embeds = self . embedding ( sentence ) # 2: \u6267\u884c\u521d\u59cb\u5316\u51fd\u6570\u7684\u7b2c2\u5c42 idcnn_out = self . idcnn ( embeds , seq_length ) # 3: \u6267\u884c\u521d\u59cb\u5316\u51fd\u6570\u7684\u7b2c3\u5c42 idcnn_out = self . dropout ( idcnn_out ) # 4: \u6267\u884c\u521d\u59cb\u5316\u51fd\u6570\u7684\u7b2c5\u5c42 out = self . linear ( idcnn_out ) # 5: \u8fdb\u884c\u5f20\u91cfshape\u7684\u8f6c\u53d8, \u4fdd\u6301\u7ecf\u5178\u7684(batch_size, seq_length, X)\u6a21\u5f0f feats = out . contiguous () . view ( batch_size , seq_length , - 1 ) return feats # \u5f53\u6a21\u578b\u5904\u4e8einference\u9636\u6bb5\u65f6, \u9ed8\u8ba4\u6267\u884c\u7684\u524d\u5411\u8ba1\u7b97\u51fd\u6570 def forward ( self , sentence , masks ): # \u9996\u5148\u83b7\u53d6\u53d1\u5c04\u77e9\u9635\u7684\u8f93\u51fa\u5f20\u91cf feats = self . get_output_score ( sentence ) # \u5229\u7528\u53d1\u5c04\u77e9\u9635\u7684\u8f93\u51fa\u5f20\u91cf, \u76f4\u63a5\u8fdb\u884c\u7ef4\u7279\u6bd4\u89e3\u7801, \u5f97\u5230\u9884\u6d4b\u5e8f\u5217 scores , tag_seq = self . crf . _viterbi_decode ( feats , masks . bool ()) return tag_seq # \u5f53\u6a21\u578b\u5904\u4e8e\u8bad\u7ec3\u9636\u6bb5\u65f6, \u771f\u6b63\u6267\u884c\u7684\u524d\u5411\u8ba1\u7b97\u51fd\u6570, \u4e3a\u4e86\u5f97\u5230\u6700\u5927\u4f3c\u7136\u635f\u5931\u503c def neg_log_likelihood_loss ( self , sentence , mask , tags ): # \u9996\u5148\u83b7\u53d6\u53d1\u5c04\u77e9\u9635\u7684\u8f93\u51fa\u5f20\u91cf feats = self . get_output_score ( sentence ) # \u5229\u7528CRF\u5c42\u7684\u6700\u5927\u4f3c\u7136\u635f\u5931\u51fd\u6570\u8ba1\u7b97\u5f53\u524d\u635f\u5931\u503c loss_value = self . crf . neg_log_likelihood_loss ( feats , mask , tags ) # \u8ba1\u7b97\u5f53\u524dbatch\u7684\u5e73\u5747\u635f\u5931\u503c batch_size = feats . size ( 0 ) loss_value /= float ( batch_size ) return loss_value","title":"\u7b2c\u4e09\u6b65: \u6a21\u578b\u6838\u5fc3\u7c7b\u7684\u5b9e\u73b0"},{"location":"3_1.html#_5","text":"\u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/ner/idcnn/train.py from tqdm import tqdm import torch import torch.nn as nn from torch.autograd import Variable from torch.optim import Adam from torch.utils.data import TensorDataset from torch.utils.data import DataLoader from utils import load_vocab , load_data , recover_label , get_ner_fmeasure , save_model , load_model from config import * from model import IDCNN_CRF device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) use_cuda = True if torch . cuda . is_available () else False vocab = load_vocab ( vocab_file ) vocab_size = len ( vocab ) # \u8bfb\u53d6\u8bad\u7ec3\u96c6 print ( 'max_length' , max_length ) train_data = load_data ( train_file , max_length = max_length , label_dic = l2i_dic , vocab = vocab ) # \u63d0\u53d6\u8bad\u7ec3\u6570\u636e\u4e2d\u76843\u4e2a\u91cd\u8981\u5b57\u6bb5, \u5e76\u5c01\u88c5\u6210LongTensor\u7c7b\u578b train_ids = torch . LongTensor ([ temp . input_id for temp in train_data ]) train_masks = torch . LongTensor ([ temp . input_mask for temp in train_data ]) train_tags = torch . LongTensor ([ temp . label_id for temp in train_data ]) # \u6807\u51c6\"\u4e24\u6b65\u8d70\", \u5c01\u88c5\u6570\u636e\u96c6 + \u5c01\u88c5\u8fed\u4ee3\u5668 train_dataset = TensorDataset ( train_ids , train_masks , train_tags ) train_loader = DataLoader ( train_dataset , shuffle = True , batch_size = batch_size ) # \u8bfb\u53d6\u6d4b\u8bd5\u96c6 dev_data = load_data ( dev_file , max_length = max_length , label_dic = l2i_dic , vocab = vocab ) dev_ids = torch . LongTensor ([ temp . input_id for temp in dev_data ]) dev_masks = torch . LongTensor ([ temp . input_mask for temp in dev_data ]) dev_tags = torch . LongTensor ([ temp . label_id for temp in dev_data ]) dev_dataset = TensorDataset ( dev_ids , dev_masks , dev_tags ) dev_loader = DataLoader ( dev_dataset , shuffle = True , batch_size = batch_size ) # \u5b9e\u4f8b\u5316\u6a21\u578b\u5bf9\u8c61model model = IDCNN_CRF ( vocab_size , tagset_size , 300 , 64 , dropout = 0.4 , use_cuda = use_cuda ) if use_cuda : model = model . cuda () model . train () optimizer = Adam ( model . parameters (), lr = 0.00001 , weight_decay = 0.00005 ) best_f = - 100 # \u53cc\u91cdfor\u5faa\u73af\u8bad\u7ec3\u6a21\u578b for epoch in range ( epochs ): print ( 'epoch: {} \uff0ctrain' . format ( epoch )) for i , train_batch in enumerate ( tqdm ( train_loader )): sentence , masks , tags = train_batch sentence , masks , tags = Variable ( sentence ), Variable ( masks ), Variable ( tags ) if use_cuda : sentence = sentence . cuda () masks = masks . cuda () tags = tags . cuda () optimizer . zero_grad () # \u8bad\u7ec3\u65f6\u7684\u635f\u5931\u503c, \u9700\u8981\u901a\u8fc7\u8c03\u7528\u6700\u5927\u4f3c\u7136\u635f\u5931\u8ba1\u7b97\u7684\u51fd\u6570, \u800c\u4e0d\u662f\u9ed8\u8ba4\u7684forward\u51fd\u6570 loss = model . neg_log_likelihood_loss ( sentence , masks , tags ) # \"\u8001\u4e09\u6837\" loss . backward () optimizer . step () print ( 'epoch: {} \uff0closs: {} ' . format ( epoch , loss . item ())) # \u6bcf\u8bad\u7ec3\u5b8c\u4e00\u4e2aepoch, \u5bf9\u6d4b\u8bd5\u96c6\u8fdb\u884c\u4e00\u6b21\u8bc4\u4f30 acc , p , r , f = evaluate ( model , dev_loader ) # \u6bcf\u5f53\u6709\u66f4\u4f18\u7684F1\u503c\u65f6, \u66f4\u65b0\u6700\u4f18F1, \u5e76\u4fdd\u5b58\u6a21\u578b\u72b6\u6001\u5b57\u5178 if f > best_f : torch . save ( model . state_dict (), save_model_path ) best_f = f","title":"\u7b2c\u56db\u6b65: \u8bad\u7ec3\u4ee3\u7801\u7684\u5b9e\u73b0"},{"location":"3_1.html#_6","text":"\u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/ner/idcnn/train.py # \u8bc4\u4f30\u51fd\u6570 def evaluate ( model , dev_loader ): # \u5c06\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f model . eval () # \u521d\u59cb\u5316\u9884\u6d4b\u5217\u8868, \u6807\u7b7e\u5217\u8868 pred = [] gold = [] print ( 'evaluate' ) # \u5faa\u73af\u904d\u5386\u6d4b\u8bd5\u96c6, \u5e76\u8bc4\u4f30\u5173\u952e\u6307\u6807 for i , dev_batch in enumerate ( dev_loader ): sentence , masks , tags = dev_batch # \u5bf9\u6570\u636e\u8fdb\u884cVariable\u5c01\u88c5 sentence , masks , tags = Variable ( sentence ), Variable ( masks ), Variable ( tags ) # \u662f\u5426\u4f7f\u7528GPU\u8fdb\u884c\u52a0\u901f\u63a8\u7406 if use_cuda : sentence = sentence . cuda () masks = masks . cuda () tags = tags . cuda () # \u5229\u7528\u6a21\u578b\u8fdb\u884c\u63a8\u7406 predict_tags = model ( sentence , masks ) # \u5c06\u9884\u6d4b\u503c\u548c\u771f\u5b9e\u6807\u7b7e\u6dfb\u52a0\u8fdb\u7ed3\u679c\u5217\u8868\u4e2d pred . extend ([ t for t in predict_tags . tolist ()]) gold . extend ([ t for t in tags . tolist ()]) # \u5c06\u6570\u5b57\u5316\u6807\u7b7e\u6620\u5c04\u56de\u771f\u5b9e\u6807\u7b7e pred_label , gold_label = recover_label ( pred , gold , l2i_dic , i2l_dic ) # \u8ba1\u7b97\u5173\u952e\u6307\u6807 acc , p , r , f = get_ner_fmeasure ( gold_label , pred_label ) print ( 'p: {} \uff0cr: {} , f: {} ' . format ( p , r , f )) # \u8bc4\u4f30\u7ed3\u675f\u540e, \u5c06\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bad\u7ec3\u6a21\u5f0f model . train () return acc , p , r , f \u8c03\u7528: python train.py \u8f93\u51fa: max_length: 256 vocab_size: 21128 /home/ec2-user/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1 \"num_layers={}\".format(dropout, num_layers)) epoch: 0\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:00<00:00, 1.04it/s] epoch: 0\uff0closs: 2.960085868835449, best_f1: -100 evaluate gold_num = 1042 pred_num = 369 right_num = 0 p: 0.0\uff0cr: 0.0, f: -1 epoch: 1\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.01s/it] epoch: 1\uff0closs: 1.3307428359985352, best_f1: -1 evaluate gold_num = 1042 pred_num = 96 right_num = 0 p: 0.0\uff0cr: 0.0, f: -1 epoch: 2\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:08<00:00, 1.03s/it] epoch: 2\uff0closs: 1.3992414474487305, best_f1: -1 evaluate gold_num = 1042 pred_num = 77 right_num = 3 p: 0.03896103896103896\uff0cr: 0.0028790786948176585, f: 0.005361930294906167 epoch: 3\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:08<00:00, 1.03s/it] epoch: 3\uff0closs: 0.9490184783935547, best_f1: 0.005361930294906167 evaluate gold_num = 1042 pred_num = 209 right_num = 2 p: 0.009569377990430622\uff0cr: 0.0019193857965451055, f: 0.0031974420463629096 epoch: 4\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:08<00:00, 1.03s/it] epoch: 4\uff0closs: 0.7577829360961914, best_f1: 0.005361930294906167 evaluate gold_num = 1042 pred_num = 390 right_num = 129 p: 0.33076923076923076\uff0cr: 0.1238003838771593, f: 0.18016759776536315 epoch: 5\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:07<00:00, 1.02s/it] epoch: 5\uff0closs: 0.6704387664794922, best_f1: 0.18016759776536315 evaluate gold_num = 1042 pred_num = 540 right_num = 260 p: 0.48148148148148145\uff0cr: 0.2495201535508637, f: 0.3286978508217446 epoch: 6\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:07<00:00, 1.02s/it] epoch: 6\uff0closs: 0.3735923767089844, best_f1: 0.3286978508217446 evaluate gold_num = 1042 pred_num = 857 right_num = 638 p: 0.7444574095682613\uff0cr: 0.6122840690978887, f: 0.6719325961032122 epoch: 7\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 7\uff0closs: 0.23816967010498047, best_f1: 0.6719325961032122 evaluate gold_num = 1042 pred_num = 1010 right_num = 733 p: 0.7257425742574257\uff0cr: 0.7034548944337812, f: 0.7144249512670564 epoch: 8\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 8\uff0closs: 0.20075607299804688, best_f1: 0.7144249512670564 evaluate gold_num = 1042 pred_num = 1023 right_num = 725 p: 0.7086999022482894\uff0cr: 0.6957773512476008, f: 0.7021791767554479 epoch: 9\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 9\uff0closs: 0.3249549865722656, best_f1: 0.7144249512670564 evaluate gold_num = 1042 pred_num = 1035 right_num = 751 p: 0.7256038647342995\uff0cr: 0.7207293666026872, f: 0.7231584015406838 epoch: 10\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 10\uff0closs: 0.38639259338378906, best_f1: 0.7231584015406838 evaluate gold_num = 1042 pred_num = 1008 right_num = 777 p: 0.7708333333333334\uff0cr: 0.7456813819577736, f: 0.758048780487805 epoch: 11\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 11\uff0closs: 0.09833717346191406, best_f1: 0.758048780487805 evaluate gold_num = 1042 pred_num = 950 right_num = 817 p: 0.86\uff0cr: 0.7840690978886756, f: 0.820281124497992 epoch: 12\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 12\uff0closs: 0.067718505859375, best_f1: 0.820281124497992 evaluate gold_num = 1042 pred_num = 966 right_num = 813 p: 0.8416149068322981\uff0cr: 0.7802303262955854, f: 0.8097609561752989 epoch: 13\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 13\uff0closs: 0.10879707336425781, best_f1: 0.820281124497992 evaluate gold_num = 1042 pred_num = 957 right_num = 827 p: 0.864158829676071\uff0cr: 0.7936660268714012, f: 0.8274137068534267 epoch: 14\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 14\uff0closs: 0.09510421752929688, best_f1: 0.8274137068534267 evaluate gold_num = 1042 pred_num = 970 right_num = 854 p: 0.8804123711340206\uff0cr: 0.8195777351247601, f: 0.848906560636183 epoch: 15\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.02s/it] epoch: 15\uff0closs: 0.1023712158203125, best_f1: 0.848906560636183 evaluate gold_num = 1042 pred_num = 997 right_num = 868 p: 0.8706118355065195\uff0cr: 0.8330134357005758, f: 0.851397743992153 epoch: 16\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:07<00:00, 1.02s/it] epoch: 16\uff0closs: 0.07217025756835938, best_f1: 0.851397743992153 evaluate gold_num = 1042 pred_num = 966 right_num = 893 p: 0.9244306418219461\uff0cr: 0.8570057581573897, f: 0.8894422310756972 epoch: 17\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 17\uff0closs: 0.05801582336425781, best_f1: 0.8894422310756972 evaluate gold_num = 1042 pred_num = 980 right_num = 928 p: 0.9469387755102041\uff0cr: 0.8905950095969289, f: 0.9179030662710188 epoch: 18\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:07<00:00, 1.02s/it] epoch: 18\uff0closs: 0.08353233337402344, best_f1: 0.9179030662710188 evaluate gold_num = 1042 pred_num = 1003 right_num = 956 p: 0.9531405782652044\uff0cr: 0.9174664107485605, f: 0.9349633251833741 epoch: 19\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 19\uff0closs: 0.04948616027832031, best_f1: 0.9349633251833741 evaluate gold_num = 1042 pred_num = 1018 right_num = 953 p: 0.9361493123772102\uff0cr: 0.9145873320537428, f: 0.9252427184466019 epoch: 20\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.01s/it] epoch: 20\uff0closs: 0.0920867919921875, best_f1: 0.9349633251833741 evaluate gold_num = 1042 pred_num = 1019 right_num = 963 p: 0.9450441609421001\uff0cr: 0.9241842610364683, f: 0.9344978165938864 epoch: 21\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.01s/it] epoch: 21\uff0closs: 0.08744049072265625, best_f1: 0.9349633251833741 evaluate gold_num = 1042 pred_num = 1026 right_num = 951 p: 0.9269005847953217\uff0cr: 0.9126679462571977, f: 0.9197292069632496 epoch: 22\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 22\uff0closs: 0.18969345092773438, best_f1: 0.9349633251833741 evaluate gold_num = 1042 pred_num = 1047 right_num = 991 p: 0.9465138490926457\uff0cr: 0.9510556621880998, f: 0.9487793202489229 epoch: 23\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 23\uff0closs: 0.0296478271484375, best_f1: 0.9487793202489229 evaluate gold_num = 1042 pred_num = 1019 right_num = 995 p: 0.9764474975466143\uff0cr: 0.95489443378119, f: 0.9655507035419698 epoch: 24\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 24\uff0closs: 0.03677558898925781, best_f1: 0.9655507035419698 evaluate gold_num = 1042 pred_num = 1030 right_num = 1012 p: 0.9825242718446602\uff0cr: 0.9712092130518234, f: 0.9768339768339768 epoch: 25\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 25\uff0closs: 0.02207183837890625, best_f1: 0.9768339768339768 evaluate gold_num = 1042 pred_num = 1032 right_num = 1016 p: 0.9844961240310077\uff0cr: 0.9750479846449136, f: 0.9797492767598842 epoch: 26\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 26\uff0closs: 0.01473236083984375, best_f1: 0.9797492767598842 evaluate gold_num = 1042 pred_num = 1031 right_num = 1014 p: 0.9835111542192047\uff0cr: 0.9731285988483686, f: 0.9782923299565847 epoch: 27\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 27\uff0closs: 0.04078865051269531, best_f1: 0.9797492767598842 evaluate gold_num = 1042 pred_num = 1028 right_num = 1014 p: 0.9863813229571985\uff0cr: 0.9731285988483686, f: 0.9797101449275363 epoch: 28\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 28\uff0closs: 0.0731048583984375, best_f1: 0.9797492767598842 evaluate gold_num = 1042 pred_num = 1134 right_num = 967 p: 0.8527336860670194\uff0cr: 0.9280230326295585, f: 0.8887867647058822 epoch: 29\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 29\uff0closs: 0.03252983093261719, best_f1: 0.9797492767598842 evaluate gold_num = 1042 pred_num = 1015 right_num = 955 p: 0.9408866995073891\uff0cr: 0.9165067178502879, f: 0.9285367039377735 epoch: 30\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 30\uff0closs: 0.09288597106933594, best_f1: 0.9797492767598842 evaluate gold_num = 1042 pred_num = 1023 right_num = 990 p: 0.967741935483871\uff0cr: 0.9500959692898272, f: 0.9588377723970944 epoch: 31\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 31\uff0closs: 0.011251449584960938, best_f1: 0.9797492767598842 evaluate gold_num = 1042 pred_num = 1025 right_num = 998 p: 0.9736585365853658\uff0cr: 0.9577735124760077, f: 0.9656507014997581 epoch: 32\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 32\uff0closs: 0.151336669921875, best_f1: 0.9797492767598842 evaluate gold_num = 1042 pred_num = 1041 right_num = 1017 p: 0.9769452449567724\uff0cr: 0.9760076775431862, f: 0.9764762361977918 epoch: 33\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 33\uff0closs: 0.008983612060546875, best_f1: 0.9797492767598842 evaluate gold_num = 1042 pred_num = 1040 right_num = 1020 p: 0.9807692307692307\uff0cr: 0.9788867562380038, f: 0.9798270893371758 epoch: 34\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 34\uff0closs: 0.010942459106445312, best_f1: 0.9798270893371758 evaluate gold_num = 1042 pred_num = 1042 right_num = 1023 p: 0.9817658349328215\uff0cr: 0.9817658349328215, f: 0.9817658349328215 epoch: 35\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 35\uff0closs: 0.0137786865234375, best_f1: 0.9817658349328215 evaluate gold_num = 1042 pred_num = 1040 right_num = 1025 p: 0.9855769230769231\uff0cr: 0.9836852207293666, f: 0.9846301633045149 epoch: 36\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.01s/it] epoch: 36\uff0closs: 0.010051727294921875, best_f1: 0.9846301633045149 evaluate gold_num = 1042 pred_num = 1040 right_num = 1030 p: 0.9903846153846154\uff0cr: 0.9884836852207294, f: 0.989433237271854 epoch: 37\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 37\uff0closs: 0.01131439208984375, best_f1: 0.989433237271854 evaluate gold_num = 1042 pred_num = 1036 right_num = 1030 p: 0.9942084942084942\uff0cr: 0.9884836852207294, f: 0.9913378248315688 epoch: 38\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 38\uff0closs: 0.008291244506835938, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1038 right_num = 1029 p: 0.9913294797687862\uff0cr: 0.9875239923224568, f: 0.989423076923077 epoch: 39\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 39\uff0closs: 0.010332107543945312, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1040 right_num = 1028 p: 0.9884615384615385\uff0cr: 0.9865642994241842, f: 0.9875120076849184 epoch: 40\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.01s/it] epoch: 40\uff0closs: 0.017686843872070312, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1040 right_num = 1030 p: 0.9903846153846154\uff0cr: 0.9884836852207294, f: 0.989433237271854 epoch: 41\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 41\uff0closs: 0.009771347045898438, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1043 right_num = 1013 p: 0.9712368168744008\uff0cr: 0.972168905950096, f: 0.9717026378896882 epoch: 42\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 42\uff0closs: 0.20522689819335938, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1023 right_num = 886 p: 0.8660801564027371\uff0cr: 0.8502879078694817, f: 0.8581113801452784 epoch: 43\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 43\uff0closs: 0.0157928466796875, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1039 right_num = 991 p: 0.9538017324350336\uff0cr: 0.9510556621880998, f: 0.9524267179240749 epoch: 44\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 44\uff0closs: 0.00662994384765625, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1024 right_num = 996 p: 0.97265625\uff0cr: 0.9558541266794626, f: 0.9641819941916748 epoch: 45\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 45\uff0closs: 0.009222030639648438, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1046 right_num = 1028 p: 0.982791586998088\uff0cr: 0.9865642994241842, f: 0.9846743295019157 epoch: 46\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.01s/it] epoch: 46\uff0closs: 0.012540817260742188, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1044 right_num = 1020 p: 0.9770114942528736\uff0cr: 0.9788867562380038, f: 0.977948226270374 epoch: 47\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.01s/it] epoch: 47\uff0closs: 0.0095062255859375, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1038 right_num = 1018 p: 0.9807321772639692\uff0cr: 0.9769673704414588, f: 0.9788461538461538 epoch: 48\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.00s/it] epoch: 48\uff0closs: 0.010555267333984375, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1036 right_num = 1026 p: 0.9903474903474904\uff0cr: 0.9846449136276392, f: 0.9874879692011549 epoch: 49\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 49\uff0closs: 0.030834197998046875, best_f1: 0.9913378248315688 evaluate gold_num = 1042 pred_num = 1040 right_num = 1034 p: 0.9942307692307693\uff0cr: 0.9923224568138196, f: 0.9932756964457252 epoch: 50\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 50\uff0closs: 0.0063266754150390625, best_f1: 0.9932756964457252 evaluate gold_num = 1042 pred_num = 1038 right_num = 1036 p: 0.9980732177263969\uff0cr: 0.9942418426103646, f: 0.9961538461538462 epoch: 51\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 51\uff0closs: 0.0021381378173828125, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1040 right_num = 1030 p: 0.9903846153846154\uff0cr: 0.9884836852207294, f: 0.989433237271854 epoch: 52\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.01s/it] epoch: 52\uff0closs: 0.12633514404296875, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1153 right_num = 1006 p: 0.8725065047701648\uff0cr: 0.9654510556621881, f: 0.9166287015945331 epoch: 53\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 53\uff0closs: 0.006160736083984375, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1071 right_num = 878 p: 0.8197945845004668\uff0cr: 0.8426103646833013, f: 0.8310459062943681 epoch: 54\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 54\uff0closs: 0.004974365234375, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1025 right_num = 994 p: 0.9697560975609756\uff0cr: 0.9539347408829175, f: 0.9617803580067731 epoch: 55\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 55\uff0closs: 0.00543212890625, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1038 right_num = 1022 p: 0.9845857418111753\uff0cr: 0.980806142034549, f: 0.9826923076923078 epoch: 56\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 56\uff0closs: 0.007305145263671875, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1036 right_num = 1026 p: 0.9903474903474904\uff0cr: 0.9846449136276392, f: 0.9874879692011549 epoch: 57\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 57\uff0closs: 0.010717391967773438, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1040 right_num = 1027 p: 0.9875\uff0cr: 0.9856046065259118, f: 0.9865513928914506 epoch: 58\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 58\uff0closs: 0.0052585601806640625, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1042 right_num = 1028 p: 0.9865642994241842\uff0cr: 0.9865642994241842, f: 0.9865642994241842 epoch: 59\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 59\uff0closs: 0.0044727325439453125, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1042 right_num = 1032 p: 0.9904030710172744\uff0cr: 0.9904030710172744, f: 0.9904030710172744 epoch: 60\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 60\uff0closs: 0.0077114105224609375, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1040 right_num = 1029 p: 0.989423076923077\uff0cr: 0.9875239923224568, f: 0.9884726224783862 epoch: 61\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 61\uff0closs: 0.009601593017578125, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1042 right_num = 1034 p: 0.9923224568138196\uff0cr: 0.9923224568138196, f: 0.9923224568138196 epoch: 62\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 62\uff0closs: 0.018930435180664062, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1046 right_num = 1032 p: 0.9866156787762906\uff0cr: 0.9904030710172744, f: 0.9885057471264367 epoch: 63\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 63\uff0closs: 0.0053234100341796875, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1048 right_num = 1035 p: 0.9875954198473282\uff0cr: 0.9932821497120922, f: 0.9904306220095693 epoch: 64\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 64\uff0closs: 0.003246307373046875, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1042 right_num = 1029 p: 0.9875239923224568\uff0cr: 0.9875239923224568, f: 0.9875239923224568 epoch: 65\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 65\uff0closs: 0.004497528076171875, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1046 right_num = 1032 p: 0.9866156787762906\uff0cr: 0.9904030710172744, f: 0.9885057471264367 epoch: 66\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 66\uff0closs: 0.007976531982421875, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1033 right_num = 1010 p: 0.9777347531461762\uff0cr: 0.9692898272552783, f: 0.9734939759036145 epoch: 67\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 67\uff0closs: 0.0014057159423828125, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1034 right_num = 1032 p: 0.9980657640232108\uff0cr: 0.9904030710172744, f: 0.9942196531791907 epoch: 68\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 68\uff0closs: 0.03486824035644531, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1042 right_num = 1034 p: 0.9923224568138196\uff0cr: 0.9923224568138196, f: 0.9923224568138196 epoch: 69\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:05<00:00, 1.01s/it] epoch: 69\uff0closs: 0.00244140625, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1042 right_num = 1038 p: 0.9961612284069098\uff0cr: 0.9961612284069098, f: 0.9961612284069098 epoch: 70\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 70\uff0closs: 0.0067806243896484375, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1046 right_num = 1036 p: 0.9904397705544933\uff0cr: 0.9942418426103646, f: 0.9923371647509578 epoch: 71\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 71\uff0closs: 0.0281219482421875, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1042 right_num = 1038 p: 0.9961612284069098\uff0cr: 0.9961612284069098, f: 0.9961612284069098 epoch: 72\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 72\uff0closs: 0.046474456787109375, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1044 right_num = 1030 p: 0.9865900383141762\uff0cr: 0.9884836852207294, f: 0.987535953978907 epoch: 73\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 73\uff0closs: 0.010404586791992188, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1053 right_num = 1026 p: 0.9743589743589743\uff0cr: 0.9846449136276392, f: 0.9794749403341289 epoch: 74\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 74\uff0closs: 0.00775146484375, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1040 right_num = 1023 p: 0.9836538461538461\uff0cr: 0.9817658349328215, f: 0.9827089337175792 epoch: 75\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 75\uff0closs: 0.00206756591796875, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1035 right_num = 1027 p: 0.9922705314009662\uff0cr: 0.9856046065259118, f: 0.9889263360616274 epoch: 76\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 76\uff0closs: 0.0015316009521484375, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1051 right_num = 1042 p: 0.9914367269267365\uff0cr: 1.0, f: 0.9956999522216914 epoch: 77\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 77\uff0closs: 0.0028858184814453125, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1042 right_num = 1038 p: 0.9961612284069098\uff0cr: 0.9961612284069098, f: 0.9961612284069098 epoch: 78\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 78\uff0closs: 0.02457427978515625, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1038 right_num = 1022 p: 0.9845857418111753\uff0cr: 0.980806142034549, f: 0.9826923076923078 epoch: 79\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 79\uff0closs: 0.018167495727539062, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1049 right_num = 1035 p: 0.9866539561487131\uff0cr: 0.9932821497120922, f: 0.9899569583931133 epoch: 80\uff0ctrain 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [02:06<00:00, 1.01s/it] epoch: 80\uff0closs: 0.007198333740234375, best_f1: 0.9961612284069098 evaluate gold_num = 1042 pred_num = 1042 right_num = 1034 p: 0.9923224568138196\uff0cr: 0.9923224568138196, f: 0.9923224568138196 Done!!! best_f = 0.9961612284069098 \u8ffd\u6eaf\u65e5\u5fd7\u53ef\u4ee5\u53d1\u73b0\u6700\u4f18\u7684\u6a21\u578b\u662f\u5728epoch = 69, \u4e5f\u5c31\u662f\u771f\u5b9e\u8bad\u7ec3\u7684\u7b2c70\u8f6e\u6b21\u540e\u4ea7\u751f\u7684!!! epoch: 69\uff0closs: 0.00244140625, best_f1: 0.9961538461538462 evaluate gold_num = 1042 pred_num = 1042 right_num = 1038 p: 0.9961612284069098\uff0cr: 0.9961612284069098, f: 0.9961612284069098","title":"\u7b2c\u4e94\u6b65: \u8bc4\u4f30\u4ee3\u7801\u7684\u5b9e\u73b0"},{"location":"3_1.html#_7","text":"\u672c\u5c0f\u8282\u638c\u63e1\u4e86IDCNN\u6a21\u578b\u7684\u67b6\u6784\u548c\u539f\u7406, \u5e76\u638c\u63e1\u4e86\u5168\u90e8\u7684\u4ee3\u7801\u5b9e\u73b0.","title":"\u5c0f\u8282\u603b\u7ed3"},{"location":"3_2.html","text":"FLAT\u6a21\u578b \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u638c\u63e1FLAT\u6a21\u578b\u7684\u67b6\u6784. \u7406\u89e3FLAT\u6a21\u578b\u5728\u9879\u76ee\u4e2d\u5982\u4f55\u63d0\u5347NER\u7684\u6548\u679c. FLAT\u6a21\u578b\u7684\u67b6\u6784 \u00b6 FLAT\u6a21\u578b\u662f\u590d\u65e6\u5927\u5b66\u90b1\u9521\u9e4f\u6559\u6388\u56e2\u961f\u4e8e2020\u5e74\u63d0\u51fa\u7684\u6700\u65b0\u4e2d\u6587NER\u4efb\u52a1\u7684SOTA\u6a21\u578b, \u539f\u59cb\u8bba\u6587<< FLAT: Chinese NER Using Flat-Lattice Transformer >>. FLAT\u7684\u601d\u60f3\u6e90\u4e8eLattice LSTM, \u662f\u4e2d\u6587\u573a\u666f\u4e0bNER\u4efb\u52a1\u5f15\u5165\u5916\u90e8\u77e5\u8bc6\u7684\u5f00\u5c71\u4e4b\u4f5c. \u9996\u5148\u901a\u8fc7\u8bcd\u5178\u5339\u914d, \u5728\"\u91cd\u5e86\u4eba\u548c\u836f\u5e97\"\u5b57\u7b26\u4e32\u4e2d, \u5339\u914d\u51fa\u5b50\u4e32\"\u91cd\u5e86\", \"\u836f\u5e97\", \"\u4eba\u548c\u836f\u5e97\"\u8fd9\u4e09\u4e2a\u5b50\u8bcd, \u7ed3\u6784\u56fe\u5982\u4e0b: \u7136\u540e\u5c06\u5339\u914d\u51fa\u76843\u4e2a\u5b50\u8bcd\u878d\u5165\u5230LSTM\u4e2d, \u5982\u4e0b\u56fe\u6240\u793a: Lattice\u662f\u4e00\u4e2a\u6709\u5411\u65e0\u73af\u56fe(DAG), Lattice LSTM\u5219\u5c06\u5e8f\u5217\u4e2d\u7684\u8bcd\u6c47\u4fe1\u606f(word-level)\u878d\u5165\u5230\u4e86\u5b57\u4fe1\u606f(char-level)\u4e2d, Lattice LSTM\u4f1a\u5c06\"\u91cd\u5e86\"\u7684word embedding\u878d\u5165\u5230\u5bf9\u5e94\u5e8f\u5217\u4e2d\u7684\"\u5e86\"\u7684word embedding\u4e2d, \u4f1a\u5c06\"\u4eba\u548c\u836f\u5e97\"\u7684word embedding\u548c\"\u836f\u5e97\"\u7684word embedding\u878d\u5165\u5230\"\u5e97\"\u7684word embedding\u4e2d, \u5373\u8bcd\u8bed\u7684\u4fe1\u606f\u4f1a\u878d\u5165\u5230\u8be5\u8bcd\u8bed\u5bf9\u5e94\u7684\u6700\u540e\u4e00\u4e2a\u5b57\u7684\u5e8f\u5217\u4fe1\u606f\u4e2d! Lattice LSTM\u7684\u6838\u5fc3\u64cd\u4f5c\u662f\u91c7\u7528\u4e86\u4e24\u4e2aLSTM\u6a21\u578b\u5bf9char-level\u7684\u5b57\u4fe1\u606f\u548cword-level\u7684\u8bcd\u4fe1\u606f\u5206\u522b\u8fdb\u884c\u7f16\u7801, \u7136\u540e\u5c06\u8bcd\u4fe1\u606f\u878d\u5165\u5230\u6bcf\u4e2a\u8bcd\u6700\u540e\u4e00\u4e2a\u5b57\u7684\u7f16\u7801\u4fe1\u606f\u4e2d. \u8fd9\u91cc\u9762\u7684\u7ec6\u8282\u6ce8\u610f\u4e24\u70b9: \u7b2c\u4e00: \u5f53\u524d\u5b57(chae-level)\u6ca1\u6709\u5176\u4ed6word\u8bcd\u7684embedding\u8f93\u5165\u65f6, \u76f4\u63a5\u4f7f\u7528\u539f\u59cb\u7684LSTM\u673a\u5236\u8fdb\u884c\u4fe1\u606f\u4f20\u5bfc. \u7b2c\u4e8c: \u5f53\u524d\u5b57(char-level)\u6709\u5176\u4ed6word\u8bcd\u7684embedding\u8f93\u5165\u65f6, \u4f7f\u7528\u8bba\u6587\u4e2d\u7684\u8ba1\u7b97\u516c\u5f0f, \u4e14\u6ca1\u6709\u4f7f\u7528\u4e0a\u4e00\u4e2a\u65f6\u523b\u7684\u8bb0\u5fc6\u5411\u91cfc, \u5373\u4e0d\u4fdd\u7559\u5bf9\u8bcd\u4fe1\u606f(word-level)\u7684\u6301\u7eed\u8bb0\u5fc6. 1: Lattice LSTM\u9996\u6b21\u4f7f\u7528\u5916\u90e8\u8bcd\u6c47\u4fe1\u606f, \u6709\u91cd\u5927\u521b\u65b0\u7a81\u7834, \u4f46\u662f\u5b58\u5728\u4e00\u5b9a\u7684\u5c40\u9650\u6027, \u8fc1\u79fb\u590d\u5236\u8f83\u96be, \u53ea\u80fd\u7528\u4e8eLSTM\u6a21\u578b\u4f5c\u4e3abackbone. 2: \u8ba1\u7b97\u6027\u80fd\u4f4e\u4e0b, \u4e0d\u80fdbatch\u5e76\u884c\u5316. \u4e3b\u8981\u662f\u6bcf\u4e2a\u5b57\u4e4b\u95f4\u589e\u52a0\u7684word cell\u6570\u91cf\u4e0d\u4e00\u81f4, \u4e2d\u95f4\u7684word cell\u7684\u4e2a\u6570\u4e0d\u786e\u5b9a, \u6ca1\u529e\u6cd5\u505a\u5230\u7edf\u4e00\u5c3a\u5bf8\u7684batch\u5316. 3: \u4fe1\u606f\u4e22\u5931\u95ee\u9898, \u6bcf\u4e2a\u5b57\u53ea\u80fd\u83b7\u53d6\u4ee5\u5b83\u4e3a\u7ed3\u5c3e\u7684\u8bcd\u6c47\u4fe1\u606f, \u5bf9\u4e8e\u4e4b\u524d\u7684\u8bcd\u6c47\u4fe1\u606f\u6ca1\u6709\u6301\u7eed\u8bb0\u5fc6\u80fd\u529b. FLAT\u7684\u51fa\u53d1\u70b9\u5c31\u662f\u89e3\u51b3Lattice LSTM\u7684\u7f3a\u9677, \u67b6\u6784\u56fe\u5982\u4e0b\u6240\u793a: \u5982\u4e0a\u56fe\u6240\u793a, FLAT\u5c06\u8bcd\u4fe1\u606f(word-level)\u76f4\u63a5\u653e\u7f6e\u5728\u6587\u672c\u7684\u540e\u9762, \u5e76\u4e0d\u505a\u63d2\u5165\u5904\u7406, \u5e76\u5bf9\u6bcf\u4e00\u4e2a\u4fe1\u606f\u5757\u6dfb\u52a0head, tail\u4f4d\u7f6e\u7f16\u7801\u7684\u4fe1\u606f. \u5b57(char-level)\u7684head\u548ctail\u76f8\u540c, \u8bcd(word-level)\u7684head\u4f4d\u7f6e\u4e3a\u7b2c\u4e00\u4e2a\u5b57\u7684\u4f4d\u7f6e, tail\u4f4d\u7f6e\u4e3a\u6700\u540e\u4e00\u4e2a\u5b57\u7684\u4f4d\u7f6e. \u901a\u8fc7\u5b9a\u4e494\u79cd\u76f8\u5bf9\u8ddd\u79bb\u6765\u8868\u793ax(i)\u4e0ex(j)\u7684\u4f4d\u7f6e\u5173\u7cfb: \u4e0a\u9762\u76844\u4e2a\u77e9\u9635\u4ee3\u88684\u79cd\u8ddd\u79bb\u7684\u8868\u8fbe, \u4f8b\u5982d(hh)\u8868\u793ax(i)\u7684\u5934\u90e8\u5230x(j)\u7684\u5934\u90e8\u7684\u8ddd\u79bb. \u5176\u4ed6\u7c7b\u4f3c\u63a8\u7406. \u5bf9\u4e8eFLAT\u7684\u6838\u5fc3\u6a21\u5757transformer\u7684\u6ce8\u610f\u529b\u8ba1\u7b97, \u4f9d\u7136\u6cbf\u7528\u7ecf\u5178\u516c\u5f0f, 4\u4e2a\u76f8\u5bf9\u8ddd\u79bb\u77e9\u9635\u662f\u901a\u8fc7\u77e9\u9635A\u7684\u53d8\u6362\u878d\u5165\u516c\u5f0f\u4e2d\u7684, \u771f\u5b9e\u8ba1\u7b97\u662f\u5728position embedding\u65f6\u52a0\u5165\u7684: FLAT\u5185\u90e8\u7ec6\u8282\u7684\u5168\u5c40\u67b6\u6784\u56fe\u5982\u4e0b\u6240\u793a: \u539f\u59cb\u8bba\u6587\u4e2d\u5bf9FLAT\u7684\u8bc4\u4f30, \u663e\u793a\u76f8\u5bf9\u4e8e\u8457\u540d\u7684TENER\u6a21\u578b, \u53d6\u5f97\u4e86\u663e\u8457\u7684\u63d0\u5347. FLAT\u6a21\u578b\u4e0d\u4ec5\u4ec5\u5728\u5173\u952e\u6307\u6807\u4e0a\u8fbe\u5230\u4e86\u4e2d\u6587\u573a\u666fNER\u7684SOTA, \u53e6\u4e00\u5927\u4eae\u70b9\u662f\u5904\u7406\u901f\u5ea6\u7684\u5927\u5e45\u63d0\u5347, \u5c24\u5176\u662fFLAT\u53ef\u4ee5\u5229\u7528GPU\u7684\u5e76\u884c\u5904\u7406\u80fd\u529b\u5927\u5e45\u63d0\u5347\u6279\u91cf\u5904\u7406\u7684\u80fd\u529b.","title":"3.2 FLAT\u6a21\u578b"},{"location":"3_2.html#flat","text":"","title":"FLAT\u6a21\u578b"},{"location":"3_2.html#_1","text":"\u638c\u63e1FLAT\u6a21\u578b\u7684\u67b6\u6784. \u7406\u89e3FLAT\u6a21\u578b\u5728\u9879\u76ee\u4e2d\u5982\u4f55\u63d0\u5347NER\u7684\u6548\u679c.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"3_2.html#flat_1","text":"FLAT\u6a21\u578b\u662f\u590d\u65e6\u5927\u5b66\u90b1\u9521\u9e4f\u6559\u6388\u56e2\u961f\u4e8e2020\u5e74\u63d0\u51fa\u7684\u6700\u65b0\u4e2d\u6587NER\u4efb\u52a1\u7684SOTA\u6a21\u578b, \u539f\u59cb\u8bba\u6587<< FLAT: Chinese NER Using Flat-Lattice Transformer >>. FLAT\u7684\u601d\u60f3\u6e90\u4e8eLattice LSTM, \u662f\u4e2d\u6587\u573a\u666f\u4e0bNER\u4efb\u52a1\u5f15\u5165\u5916\u90e8\u77e5\u8bc6\u7684\u5f00\u5c71\u4e4b\u4f5c. \u9996\u5148\u901a\u8fc7\u8bcd\u5178\u5339\u914d, \u5728\"\u91cd\u5e86\u4eba\u548c\u836f\u5e97\"\u5b57\u7b26\u4e32\u4e2d, \u5339\u914d\u51fa\u5b50\u4e32\"\u91cd\u5e86\", \"\u836f\u5e97\", \"\u4eba\u548c\u836f\u5e97\"\u8fd9\u4e09\u4e2a\u5b50\u8bcd, \u7ed3\u6784\u56fe\u5982\u4e0b: \u7136\u540e\u5c06\u5339\u914d\u51fa\u76843\u4e2a\u5b50\u8bcd\u878d\u5165\u5230LSTM\u4e2d, \u5982\u4e0b\u56fe\u6240\u793a: Lattice\u662f\u4e00\u4e2a\u6709\u5411\u65e0\u73af\u56fe(DAG), Lattice LSTM\u5219\u5c06\u5e8f\u5217\u4e2d\u7684\u8bcd\u6c47\u4fe1\u606f(word-level)\u878d\u5165\u5230\u4e86\u5b57\u4fe1\u606f(char-level)\u4e2d, Lattice LSTM\u4f1a\u5c06\"\u91cd\u5e86\"\u7684word embedding\u878d\u5165\u5230\u5bf9\u5e94\u5e8f\u5217\u4e2d\u7684\"\u5e86\"\u7684word embedding\u4e2d, \u4f1a\u5c06\"\u4eba\u548c\u836f\u5e97\"\u7684word embedding\u548c\"\u836f\u5e97\"\u7684word embedding\u878d\u5165\u5230\"\u5e97\"\u7684word embedding\u4e2d, \u5373\u8bcd\u8bed\u7684\u4fe1\u606f\u4f1a\u878d\u5165\u5230\u8be5\u8bcd\u8bed\u5bf9\u5e94\u7684\u6700\u540e\u4e00\u4e2a\u5b57\u7684\u5e8f\u5217\u4fe1\u606f\u4e2d! Lattice LSTM\u7684\u6838\u5fc3\u64cd\u4f5c\u662f\u91c7\u7528\u4e86\u4e24\u4e2aLSTM\u6a21\u578b\u5bf9char-level\u7684\u5b57\u4fe1\u606f\u548cword-level\u7684\u8bcd\u4fe1\u606f\u5206\u522b\u8fdb\u884c\u7f16\u7801, \u7136\u540e\u5c06\u8bcd\u4fe1\u606f\u878d\u5165\u5230\u6bcf\u4e2a\u8bcd\u6700\u540e\u4e00\u4e2a\u5b57\u7684\u7f16\u7801\u4fe1\u606f\u4e2d. \u8fd9\u91cc\u9762\u7684\u7ec6\u8282\u6ce8\u610f\u4e24\u70b9: \u7b2c\u4e00: \u5f53\u524d\u5b57(chae-level)\u6ca1\u6709\u5176\u4ed6word\u8bcd\u7684embedding\u8f93\u5165\u65f6, \u76f4\u63a5\u4f7f\u7528\u539f\u59cb\u7684LSTM\u673a\u5236\u8fdb\u884c\u4fe1\u606f\u4f20\u5bfc. \u7b2c\u4e8c: \u5f53\u524d\u5b57(char-level)\u6709\u5176\u4ed6word\u8bcd\u7684embedding\u8f93\u5165\u65f6, \u4f7f\u7528\u8bba\u6587\u4e2d\u7684\u8ba1\u7b97\u516c\u5f0f, \u4e14\u6ca1\u6709\u4f7f\u7528\u4e0a\u4e00\u4e2a\u65f6\u523b\u7684\u8bb0\u5fc6\u5411\u91cfc, \u5373\u4e0d\u4fdd\u7559\u5bf9\u8bcd\u4fe1\u606f(word-level)\u7684\u6301\u7eed\u8bb0\u5fc6. 1: Lattice LSTM\u9996\u6b21\u4f7f\u7528\u5916\u90e8\u8bcd\u6c47\u4fe1\u606f, \u6709\u91cd\u5927\u521b\u65b0\u7a81\u7834, \u4f46\u662f\u5b58\u5728\u4e00\u5b9a\u7684\u5c40\u9650\u6027, \u8fc1\u79fb\u590d\u5236\u8f83\u96be, \u53ea\u80fd\u7528\u4e8eLSTM\u6a21\u578b\u4f5c\u4e3abackbone. 2: \u8ba1\u7b97\u6027\u80fd\u4f4e\u4e0b, \u4e0d\u80fdbatch\u5e76\u884c\u5316. \u4e3b\u8981\u662f\u6bcf\u4e2a\u5b57\u4e4b\u95f4\u589e\u52a0\u7684word cell\u6570\u91cf\u4e0d\u4e00\u81f4, \u4e2d\u95f4\u7684word cell\u7684\u4e2a\u6570\u4e0d\u786e\u5b9a, \u6ca1\u529e\u6cd5\u505a\u5230\u7edf\u4e00\u5c3a\u5bf8\u7684batch\u5316. 3: \u4fe1\u606f\u4e22\u5931\u95ee\u9898, \u6bcf\u4e2a\u5b57\u53ea\u80fd\u83b7\u53d6\u4ee5\u5b83\u4e3a\u7ed3\u5c3e\u7684\u8bcd\u6c47\u4fe1\u606f, \u5bf9\u4e8e\u4e4b\u524d\u7684\u8bcd\u6c47\u4fe1\u606f\u6ca1\u6709\u6301\u7eed\u8bb0\u5fc6\u80fd\u529b. FLAT\u7684\u51fa\u53d1\u70b9\u5c31\u662f\u89e3\u51b3Lattice LSTM\u7684\u7f3a\u9677, \u67b6\u6784\u56fe\u5982\u4e0b\u6240\u793a: \u5982\u4e0a\u56fe\u6240\u793a, FLAT\u5c06\u8bcd\u4fe1\u606f(word-level)\u76f4\u63a5\u653e\u7f6e\u5728\u6587\u672c\u7684\u540e\u9762, \u5e76\u4e0d\u505a\u63d2\u5165\u5904\u7406, \u5e76\u5bf9\u6bcf\u4e00\u4e2a\u4fe1\u606f\u5757\u6dfb\u52a0head, tail\u4f4d\u7f6e\u7f16\u7801\u7684\u4fe1\u606f. \u5b57(char-level)\u7684head\u548ctail\u76f8\u540c, \u8bcd(word-level)\u7684head\u4f4d\u7f6e\u4e3a\u7b2c\u4e00\u4e2a\u5b57\u7684\u4f4d\u7f6e, tail\u4f4d\u7f6e\u4e3a\u6700\u540e\u4e00\u4e2a\u5b57\u7684\u4f4d\u7f6e. \u901a\u8fc7\u5b9a\u4e494\u79cd\u76f8\u5bf9\u8ddd\u79bb\u6765\u8868\u793ax(i)\u4e0ex(j)\u7684\u4f4d\u7f6e\u5173\u7cfb: \u4e0a\u9762\u76844\u4e2a\u77e9\u9635\u4ee3\u88684\u79cd\u8ddd\u79bb\u7684\u8868\u8fbe, \u4f8b\u5982d(hh)\u8868\u793ax(i)\u7684\u5934\u90e8\u5230x(j)\u7684\u5934\u90e8\u7684\u8ddd\u79bb. \u5176\u4ed6\u7c7b\u4f3c\u63a8\u7406. \u5bf9\u4e8eFLAT\u7684\u6838\u5fc3\u6a21\u5757transformer\u7684\u6ce8\u610f\u529b\u8ba1\u7b97, \u4f9d\u7136\u6cbf\u7528\u7ecf\u5178\u516c\u5f0f, 4\u4e2a\u76f8\u5bf9\u8ddd\u79bb\u77e9\u9635\u662f\u901a\u8fc7\u77e9\u9635A\u7684\u53d8\u6362\u878d\u5165\u516c\u5f0f\u4e2d\u7684, \u771f\u5b9e\u8ba1\u7b97\u662f\u5728position embedding\u65f6\u52a0\u5165\u7684: FLAT\u5185\u90e8\u7ec6\u8282\u7684\u5168\u5c40\u67b6\u6784\u56fe\u5982\u4e0b\u6240\u793a: \u539f\u59cb\u8bba\u6587\u4e2d\u5bf9FLAT\u7684\u8bc4\u4f30, \u663e\u793a\u76f8\u5bf9\u4e8e\u8457\u540d\u7684TENER\u6a21\u578b, \u53d6\u5f97\u4e86\u663e\u8457\u7684\u63d0\u5347. FLAT\u6a21\u578b\u4e0d\u4ec5\u4ec5\u5728\u5173\u952e\u6307\u6807\u4e0a\u8fbe\u5230\u4e86\u4e2d\u6587\u573a\u666fNER\u7684SOTA, \u53e6\u4e00\u5927\u4eae\u70b9\u662f\u5904\u7406\u901f\u5ea6\u7684\u5927\u5e45\u63d0\u5347, \u5c24\u5176\u662fFLAT\u53ef\u4ee5\u5229\u7528GPU\u7684\u5e76\u884c\u5904\u7406\u80fd\u529b\u5927\u5e45\u63d0\u5347\u6279\u91cf\u5904\u7406\u7684\u80fd\u529b.","title":"FLAT\u6a21\u578b\u7684\u67b6\u6784"},{"location":"3_3.html","text":"\u5b9e\u4f53\u6d88\u6b67\u4e0e\u5b9e\u4f53\u5bf9\u9f50 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u7406\u89e3\u5b9e\u4f53\u6d88\u6b67\u7684\u6982\u5ff5\u548c\u65b9\u6cd5. \u7406\u89e3\u5b9e\u4f53\u5bf9\u9f50\u7684\u6982\u5ff5\u548c\u65b9\u6cd5. \u5b9e\u4f53\u6d88\u6b67 \u00b6 \u5b9e\u4f53\u6d88\u6b67, \u53c8\u79f0NED\u4efb\u52a1(Named Entity Disambiguation), \u662f\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u9636\u6bb5\u7684\u4e00\u9879\u91cd\u8981\u7814\u7a76\u5185\u5bb9\u548c\u96be\u70b9. \u5b9e\u4f53\u6d88\u6b67\u4e3b\u8981\u662f\u628a\u5177\u6709\u6b67\u4e49\u7684\u547d\u540d\u6307\u79f0\u9879\u6620\u5c04\u5230\u5b83\u5b9e\u9645\u6240\u6307\u7684\u5b9e\u4f53\u6982\u5ff5\u4e0a\u53bb. \u6838\u5fc3\u4efb\u52a1\u5c31\u662f\u89e3\u51b3\"\u4e00\u8bcd\u591a\u4e49\"\u7684\u95ee\u9898! \u91cd\u8981\u7279\u70b9\u662f\u6839\u636e\"\u4e0a\u4e0b\u6587\u4fe1\u606f\"\u6765\u5b9e\u73b0\u6d88\u6b67! \u518d\u6bd4\u5982\u4e0b\u9762\u4f8b\u5b50\u4e2d\u7684\"Michael Jordan\": \u5bf9\u4e8e\u4e00\u6bb5\u81ea\u7136\u8bed\u8a00\u6587\u672c\"\u8fc8\u514b\u5c14.\u4e54\u4e39\u6559\u6388\u6628\u5929\u8bbf\u95ee\u4e86CMU\", \u5728\u8fdb\u884c\u4fe1\u606f\u62bd\u53d6\u7684\u8fc7\u7a0b\u4e2d, \u5148\u540e\u8981\u8fdb\u884c\u51e0\u4e2a\u6b65\u9aa4: \u547d\u540d\u5b9e\u4f53\u6b67\u4e49\u7684\u6839\u6e90\u6709\u4e24\u4e2a\u65b9\u9762: \u540c\u4e00\u610f\u4e49\u7684\u4e0d\u540c\u8868\u8fbe \u540c\u4e00\u8868\u8fbe\u7684\u4e0d\u540c\u610f\u4e49 \u540c\u4e00\u610f\u4e49\u7684\u4e0d\u540c\u8868\u8fbe: \u540c\u4e00\u8868\u8fbe\u7684\u4e0d\u540c\u610f\u4e49: \u5b9e\u4f53\u6d88\u6b67\u7684\u4e3b\u6d41\u65b9\u6cd5\u6709\u4e24\u79cd: \u57fa\u4e8e\u65e0\u76d1\u7763\u805a\u7c7b\u7684\u5b9e\u4f53\u6d88\u6b67 \u57fa\u4e8e\u5b9e\u4f53\u94fe\u63a5\u7684\u5b9e\u4f53\u6d88\u6b67 WePS\u8bc4\u6d4b: \u9488\u5bf9\u57fa\u4e8e\u805a\u7c7b\u7684\u547d\u540d\u5b9e\u4f53\u6d88\u6b67\u7cfb\u7edf\u8fdb\u884c\u8bc4\u6d4b. \u5728\u76ee\u6807\u5b9e\u4f53\u6ca1\u6709\u7ed9\u5b9a\u7684\u60c5\u51b5\u4e0b, \u76ee\u524d\u7edd\u5927\u591a\u6570\u7cfb\u7edf\u90fd\u91c7\u7528\u805a\u7c7b\u7684\u65b9\u6cd5\u8fdb\u884c\u5b9e\u4f53\u6d88\u6b67. \u7ed9\u5b9a\u5f85\u6d88\u6b67\u7684\u5b9e\u4f53\u6307\u79f0\u9879\u96c6\u5408O = o1, o2, o3, ... , on, \u6267\u884c\u6b65\u9aa4: 1: \u5bf9\u6bcf\u4e00\u4e2a\u5b9e\u4f53\u6307\u79f0\u9879oi, \u62bd\u53d6\u7279\u5f81(\u4e0a\u4e0b\u6587\u7684\u8bcd, \u5b9e\u4f53, \u6982\u5ff5), \u5e76\u5c06\u5176\u8868\u793a\u6210\u7279\u5f81\u5411\u91cfwi 2: \u901a\u8fc7\u7279\u5f81\u5411\u91cf, \u8ba1\u7b97\u5b9e\u4f53\u6307\u79f0\u9879\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6 3: \u91c7\u7528\u67d0\u79cd\u7b97\u6cd5\u5bf9\u5b9e\u4f53\u6307\u79f0\u9879\u805a\u7c7b \u5728\u5177\u4f53\u64cd\u4f5c\u4e2d, \u57fa\u4e8e\u805a\u7c7b\u7684\u5b9e\u4f53\u6d88\u6b67\u6280\u672f\u4e2d\u5e38\u5229\u7528Wikipedia\u4f5c\u4e3a\u8bed\u4e49\u77e5\u8bc6\u5e93. \u5177\u4f53\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u7b97\u6cd5\u6709\u5f88\u591a, \u5e38\u7528\u7684\u4e24\u4e2a: 1: \u8ba1\u7b97Google\u8ddd\u79bb 2: \u8ba1\u7b97Milne and lan H.Witten\u63d0\u51fa\u7684\u76f8\u4f3c\u5ea6\u65b9\u6cd5 \u8ba1\u7b97Google\u8ddd\u79bb \u8ba1\u7b97Milne and lan H.Witten\u63d0\u51fa\u7684\u76f8\u4f3c\u5ea6\u65b9\u6cd5 \u57fa\u4e8e\u5b9e\u4f53\u94fe\u63a5\u7684\u5b9e\u4f53\u6d88\u6b67: \u7ed9\u5b9a\u5b9e\u4f53\u6307\u79f0\u9879\u548c\u5b83\u6240\u5728\u7684\u6587\u672c, \u5c06\u5176\u8fde\u63a5\u5230\u7ed9\u5b9a\u77e5\u8bc6\u5e93\u4e2d\u7684\u5bf9\u5e94\u5b9e\u4f53\u4e0a. \u5b9e\u4f53\u94fe\u63a5\u7684\u8f93\u5165\u8f93\u51fa \u8f93\u5165: \u76ee\u6807\u5b9e\u4f53\u77e5\u8bc6\u5e93: \u76ee\u524d\u6700\u5e38\u7528\u7684\u662fWikipedia, \u5728\u5176\u4ed6\u4e00\u4e9b\u4efb\u52a1\u4e2d\u53ef\u80fd\u662f\u7279\u5b9a\u9886\u57df\u7684\u77e5\u8bc6\u5e93, \u6bd4\u5982\u793e\u4ea4\u5a92\u4f53\u7684Yelp, \u7535\u5f71\u9886\u57df\u7684IMDB, \u7b49\u7b49. \u5f85\u6d88\u6b67\u7684\u5b9e\u4f53\u6307\u79f0\u9879\u53ca\u5176\u4e0a\u4e0b\u6587\u4fe1\u606f. \u8f93\u51fa: \u6587\u672c\u4e2d\u5b9e\u4f53\u6307\u79f0\u9879\u6620\u5c04\u5230\u7684\u77e5\u8bc6\u5e93\u4e2d\u7684\u5b9e\u4f53. Wikipedia\u5728\u5b9e\u4f53\u94fe\u63a5\u4e2d\u6700\u91cd\u8981\u7684\u4f5c\u7528\u662f: \u83b7\u53d6\u6587\u672c\u7684\u8d85\u94fe\u63a5\u5173\u7cfb. \u83b7\u53d6\u5019\u9009\u5b9e\u4f53. \u7f29\u7565\u8bed\u7684\u5b9e\u4f53\u6d88\u6b67: \u7f29\u7565\u8bed\u7684\u6307\u79f0\u9879\u5177\u6709\u5f88\u5f3a\u7684\u6b67\u4e49\u6027, \u4f46\u662f\u5b83\u7684\u5168\u79f0\u5f80\u5f80\u662f\u51c6\u786e\u7684, \u65e0\u6b67\u4e49\u7684, \u4f8b\u5982ABC\u548cAmerican Broadcasting Company, AI\u548cArtificial Intelligence. \u89e3\u51b3\u65b9\u6848: \u5229\u7528\u4eba\u5de5\u89c4\u5219\u62bd\u53d6\u5b9e\u4f53\u5019\u9009!!! \u5b9e\u4f53\u5bf9\u9f50 \u00b6 \u5b9e\u4f53\u5bf9\u9f50, \u53c8\u79f0ER\u4efb\u52a1(Entity Resolution), \u65e8\u5728\u5224\u65ad\u4e24\u4e2a\u6216\u8005\u591a\u4e2a\u4e0d\u540c\u4fe1\u606f\u6765\u6e90\u7684\u5b9e\u4f53\u662f\u5426\u4e3a\u6307\u5411\u771f\u5b9e\u4e16\u754c\u4e2d\u540c\u4e00\u4e2a\u5bf9\u8c61. \u5982\u679c\u591a\u4e2a\u5b9e\u4f53\u8868\u5f81\u540c\u4e00\u4e2a\u5bf9\u8c61, \u5219\u5728\u8fd9\u4e9b\u5b9e\u4f53\u4e4b\u95f4\u6784\u5efa\u5bf9\u9f50\u5173\u7cfb, \u540c\u65f6\u5bf9\u5b9e\u4f53\u5305\u542b\u7684\u4fe1\u606f\u8fdb\u884c\u878d\u5408\u548c\u805a\u96c6. \u91cd\u5b9a\u5411\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u9875\u9762, \u4f8b\u5982: \u8bbe\u5b9a\u4e86\u540d\u79f0\u4e3a\"\u6fb3\u6d32\", \u800c\u5185\u5bb9\u6307\u5411\"\u6fb3\u5927\u5229\u4e9a\"\u7684\u91cd\u5b9a\u5411\u9875\u540e, \u4efb\u4f55\u4eba\u90fd\u53ef\u4ee5\u7528\"\u6fb3\u6d32\"\u8fd9\u4e00\u540d\u79f0\u8fdb\u5165\u5230\"\u6fb3\u5927\u5229\u4e9a\"\u7684\u6761\u76ee\u4e2d. \u5b9e\u4f53\u5bf9\u9f50\u4e2d\u7684\u4e00\u9879\u91cd\u8981\u4efb\u52a1\u662f\"\u5c5e\u6027\u5bf9\u9f50\": \u65e8\u5728\u5224\u65ad\u4e24\u4e2a\u6216\u591a\u4e2a\u5c5e\u6027\u662f\u5426\u53ef\u4ee5\u8868\u793a\u540c\u4e00\u4e2a\u5c5e\u6027, \u628a\u4e0d\u540c\u6765\u6e90\u6216\u540d\u5b57\u76f8\u540c\u4f46\u8868\u5f81\u76f8\u540c\u7684\u5c5e\u6027\u8fdb\u884c\u4fe1\u606f\u878d\u5408, \u4ece\u800c\u6216\u8005\u66f4\u4e30\u5bcc, \u66f4\u51c6\u786e\u7684\u4fe1\u606f. \u4f8b\u5982\u5728\u7ef4\u57fa\u767e\u79d1\u6d88\u606f\u76d2\u4e2d, \u660e\u661f\u5b58\u5728\u5c5e\u6027\"\u51fa\u751f\u5e74\u6708\", \"\u51fa\u751f\u65e5\u671f\", \"\u751f\u65e5\", \"\u51fa\u751f\u65f6\u95f4\"\u7b49, \u8fd9\u4e9b\u5c5e\u6027\u540d\u5b57\u4e0d\u540c\u4f46\u662f\u90fd\u8868\u793a\u540c\u4e00\u4e2a\u542b\u4e49, \u56e0\u6b64\u53ef\u4ee5\u505a\u5c5e\u6027\u5bf9\u9f50. \u5728\u4f8b\u5982\u5728\u767e\u5ea6\u767e\u79d1\u4e2d, \u666f\u70b9\"\u6545\u5bab\"\u5b58\u5728\u5c5e\u6027\"\u4e2d\u6587\u540d\u79f0\", \u800c\u5728\u4e92\u52a8\u767e\u79d1\u4e2d\u7684\u5c5e\u6027\u4e3a\"\u4e2d\u6587\u540d\", \u4e24\u8005\u6765\u81ea\u4e0d\u540c\u7684\u5728\u7ebf\u767e\u79d1, \u62e5\u6709\u4e0d\u540c\u7684\u5c5e\u6027\u540d, \u4f46\u662f\u90fd\u8868\u793a\u76f8\u540c\u7684\u542b\u4e49, \u56e0\u6b64\u4e5f\u53ef\u4ee5\u505a\u5c5e\u6027\u5bf9\u9f50. \u5c5e\u6027\u5bf9\u9f50\u7684\u4e3b\u8981\u65b9\u6cd5: \u57fa\u4e8e\u7f16\u8f91\u8ddd\u79bb\u8ba1\u7b97\u76f8\u4f3c\u5ea6. \u57fa\u4e8e\u9886\u57df\u8bcd\u5178\u5339\u914d. \u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u8ddd\u79bb.","title":"3.3 \u5b9e\u4f53\u6d88\u6b67\u4e0e\u5b9e\u4f53\u5bf9\u9f50"},{"location":"3_3.html#_1","text":"","title":"\u5b9e\u4f53\u6d88\u6b67\u4e0e\u5b9e\u4f53\u5bf9\u9f50"},{"location":"3_3.html#_2","text":"\u7406\u89e3\u5b9e\u4f53\u6d88\u6b67\u7684\u6982\u5ff5\u548c\u65b9\u6cd5. \u7406\u89e3\u5b9e\u4f53\u5bf9\u9f50\u7684\u6982\u5ff5\u548c\u65b9\u6cd5.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"3_3.html#_3","text":"\u5b9e\u4f53\u6d88\u6b67, \u53c8\u79f0NED\u4efb\u52a1(Named Entity Disambiguation), \u662f\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u9636\u6bb5\u7684\u4e00\u9879\u91cd\u8981\u7814\u7a76\u5185\u5bb9\u548c\u96be\u70b9. \u5b9e\u4f53\u6d88\u6b67\u4e3b\u8981\u662f\u628a\u5177\u6709\u6b67\u4e49\u7684\u547d\u540d\u6307\u79f0\u9879\u6620\u5c04\u5230\u5b83\u5b9e\u9645\u6240\u6307\u7684\u5b9e\u4f53\u6982\u5ff5\u4e0a\u53bb. \u6838\u5fc3\u4efb\u52a1\u5c31\u662f\u89e3\u51b3\"\u4e00\u8bcd\u591a\u4e49\"\u7684\u95ee\u9898! \u91cd\u8981\u7279\u70b9\u662f\u6839\u636e\"\u4e0a\u4e0b\u6587\u4fe1\u606f\"\u6765\u5b9e\u73b0\u6d88\u6b67! \u518d\u6bd4\u5982\u4e0b\u9762\u4f8b\u5b50\u4e2d\u7684\"Michael Jordan\": \u5bf9\u4e8e\u4e00\u6bb5\u81ea\u7136\u8bed\u8a00\u6587\u672c\"\u8fc8\u514b\u5c14.\u4e54\u4e39\u6559\u6388\u6628\u5929\u8bbf\u95ee\u4e86CMU\", \u5728\u8fdb\u884c\u4fe1\u606f\u62bd\u53d6\u7684\u8fc7\u7a0b\u4e2d, \u5148\u540e\u8981\u8fdb\u884c\u51e0\u4e2a\u6b65\u9aa4: \u547d\u540d\u5b9e\u4f53\u6b67\u4e49\u7684\u6839\u6e90\u6709\u4e24\u4e2a\u65b9\u9762: \u540c\u4e00\u610f\u4e49\u7684\u4e0d\u540c\u8868\u8fbe \u540c\u4e00\u8868\u8fbe\u7684\u4e0d\u540c\u610f\u4e49 \u540c\u4e00\u610f\u4e49\u7684\u4e0d\u540c\u8868\u8fbe: \u540c\u4e00\u8868\u8fbe\u7684\u4e0d\u540c\u610f\u4e49: \u5b9e\u4f53\u6d88\u6b67\u7684\u4e3b\u6d41\u65b9\u6cd5\u6709\u4e24\u79cd: \u57fa\u4e8e\u65e0\u76d1\u7763\u805a\u7c7b\u7684\u5b9e\u4f53\u6d88\u6b67 \u57fa\u4e8e\u5b9e\u4f53\u94fe\u63a5\u7684\u5b9e\u4f53\u6d88\u6b67 WePS\u8bc4\u6d4b: \u9488\u5bf9\u57fa\u4e8e\u805a\u7c7b\u7684\u547d\u540d\u5b9e\u4f53\u6d88\u6b67\u7cfb\u7edf\u8fdb\u884c\u8bc4\u6d4b. \u5728\u76ee\u6807\u5b9e\u4f53\u6ca1\u6709\u7ed9\u5b9a\u7684\u60c5\u51b5\u4e0b, \u76ee\u524d\u7edd\u5927\u591a\u6570\u7cfb\u7edf\u90fd\u91c7\u7528\u805a\u7c7b\u7684\u65b9\u6cd5\u8fdb\u884c\u5b9e\u4f53\u6d88\u6b67. \u7ed9\u5b9a\u5f85\u6d88\u6b67\u7684\u5b9e\u4f53\u6307\u79f0\u9879\u96c6\u5408O = o1, o2, o3, ... , on, \u6267\u884c\u6b65\u9aa4: 1: \u5bf9\u6bcf\u4e00\u4e2a\u5b9e\u4f53\u6307\u79f0\u9879oi, \u62bd\u53d6\u7279\u5f81(\u4e0a\u4e0b\u6587\u7684\u8bcd, \u5b9e\u4f53, \u6982\u5ff5), \u5e76\u5c06\u5176\u8868\u793a\u6210\u7279\u5f81\u5411\u91cfwi 2: \u901a\u8fc7\u7279\u5f81\u5411\u91cf, \u8ba1\u7b97\u5b9e\u4f53\u6307\u79f0\u9879\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6 3: \u91c7\u7528\u67d0\u79cd\u7b97\u6cd5\u5bf9\u5b9e\u4f53\u6307\u79f0\u9879\u805a\u7c7b \u5728\u5177\u4f53\u64cd\u4f5c\u4e2d, \u57fa\u4e8e\u805a\u7c7b\u7684\u5b9e\u4f53\u6d88\u6b67\u6280\u672f\u4e2d\u5e38\u5229\u7528Wikipedia\u4f5c\u4e3a\u8bed\u4e49\u77e5\u8bc6\u5e93. \u5177\u4f53\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u7b97\u6cd5\u6709\u5f88\u591a, \u5e38\u7528\u7684\u4e24\u4e2a: 1: \u8ba1\u7b97Google\u8ddd\u79bb 2: \u8ba1\u7b97Milne and lan H.Witten\u63d0\u51fa\u7684\u76f8\u4f3c\u5ea6\u65b9\u6cd5 \u8ba1\u7b97Google\u8ddd\u79bb \u8ba1\u7b97Milne and lan H.Witten\u63d0\u51fa\u7684\u76f8\u4f3c\u5ea6\u65b9\u6cd5 \u57fa\u4e8e\u5b9e\u4f53\u94fe\u63a5\u7684\u5b9e\u4f53\u6d88\u6b67: \u7ed9\u5b9a\u5b9e\u4f53\u6307\u79f0\u9879\u548c\u5b83\u6240\u5728\u7684\u6587\u672c, \u5c06\u5176\u8fde\u63a5\u5230\u7ed9\u5b9a\u77e5\u8bc6\u5e93\u4e2d\u7684\u5bf9\u5e94\u5b9e\u4f53\u4e0a. \u5b9e\u4f53\u94fe\u63a5\u7684\u8f93\u5165\u8f93\u51fa \u8f93\u5165: \u76ee\u6807\u5b9e\u4f53\u77e5\u8bc6\u5e93: \u76ee\u524d\u6700\u5e38\u7528\u7684\u662fWikipedia, \u5728\u5176\u4ed6\u4e00\u4e9b\u4efb\u52a1\u4e2d\u53ef\u80fd\u662f\u7279\u5b9a\u9886\u57df\u7684\u77e5\u8bc6\u5e93, \u6bd4\u5982\u793e\u4ea4\u5a92\u4f53\u7684Yelp, \u7535\u5f71\u9886\u57df\u7684IMDB, \u7b49\u7b49. \u5f85\u6d88\u6b67\u7684\u5b9e\u4f53\u6307\u79f0\u9879\u53ca\u5176\u4e0a\u4e0b\u6587\u4fe1\u606f. \u8f93\u51fa: \u6587\u672c\u4e2d\u5b9e\u4f53\u6307\u79f0\u9879\u6620\u5c04\u5230\u7684\u77e5\u8bc6\u5e93\u4e2d\u7684\u5b9e\u4f53. Wikipedia\u5728\u5b9e\u4f53\u94fe\u63a5\u4e2d\u6700\u91cd\u8981\u7684\u4f5c\u7528\u662f: \u83b7\u53d6\u6587\u672c\u7684\u8d85\u94fe\u63a5\u5173\u7cfb. \u83b7\u53d6\u5019\u9009\u5b9e\u4f53. \u7f29\u7565\u8bed\u7684\u5b9e\u4f53\u6d88\u6b67: \u7f29\u7565\u8bed\u7684\u6307\u79f0\u9879\u5177\u6709\u5f88\u5f3a\u7684\u6b67\u4e49\u6027, \u4f46\u662f\u5b83\u7684\u5168\u79f0\u5f80\u5f80\u662f\u51c6\u786e\u7684, \u65e0\u6b67\u4e49\u7684, \u4f8b\u5982ABC\u548cAmerican Broadcasting Company, AI\u548cArtificial Intelligence. \u89e3\u51b3\u65b9\u6848: \u5229\u7528\u4eba\u5de5\u89c4\u5219\u62bd\u53d6\u5b9e\u4f53\u5019\u9009!!!","title":"\u5b9e\u4f53\u6d88\u6b67"},{"location":"3_3.html#_4","text":"\u5b9e\u4f53\u5bf9\u9f50, \u53c8\u79f0ER\u4efb\u52a1(Entity Resolution), \u65e8\u5728\u5224\u65ad\u4e24\u4e2a\u6216\u8005\u591a\u4e2a\u4e0d\u540c\u4fe1\u606f\u6765\u6e90\u7684\u5b9e\u4f53\u662f\u5426\u4e3a\u6307\u5411\u771f\u5b9e\u4e16\u754c\u4e2d\u540c\u4e00\u4e2a\u5bf9\u8c61. \u5982\u679c\u591a\u4e2a\u5b9e\u4f53\u8868\u5f81\u540c\u4e00\u4e2a\u5bf9\u8c61, \u5219\u5728\u8fd9\u4e9b\u5b9e\u4f53\u4e4b\u95f4\u6784\u5efa\u5bf9\u9f50\u5173\u7cfb, \u540c\u65f6\u5bf9\u5b9e\u4f53\u5305\u542b\u7684\u4fe1\u606f\u8fdb\u884c\u878d\u5408\u548c\u805a\u96c6. \u91cd\u5b9a\u5411\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u9875\u9762, \u4f8b\u5982: \u8bbe\u5b9a\u4e86\u540d\u79f0\u4e3a\"\u6fb3\u6d32\", \u800c\u5185\u5bb9\u6307\u5411\"\u6fb3\u5927\u5229\u4e9a\"\u7684\u91cd\u5b9a\u5411\u9875\u540e, \u4efb\u4f55\u4eba\u90fd\u53ef\u4ee5\u7528\"\u6fb3\u6d32\"\u8fd9\u4e00\u540d\u79f0\u8fdb\u5165\u5230\"\u6fb3\u5927\u5229\u4e9a\"\u7684\u6761\u76ee\u4e2d. \u5b9e\u4f53\u5bf9\u9f50\u4e2d\u7684\u4e00\u9879\u91cd\u8981\u4efb\u52a1\u662f\"\u5c5e\u6027\u5bf9\u9f50\": \u65e8\u5728\u5224\u65ad\u4e24\u4e2a\u6216\u591a\u4e2a\u5c5e\u6027\u662f\u5426\u53ef\u4ee5\u8868\u793a\u540c\u4e00\u4e2a\u5c5e\u6027, \u628a\u4e0d\u540c\u6765\u6e90\u6216\u540d\u5b57\u76f8\u540c\u4f46\u8868\u5f81\u76f8\u540c\u7684\u5c5e\u6027\u8fdb\u884c\u4fe1\u606f\u878d\u5408, \u4ece\u800c\u6216\u8005\u66f4\u4e30\u5bcc, \u66f4\u51c6\u786e\u7684\u4fe1\u606f. \u4f8b\u5982\u5728\u7ef4\u57fa\u767e\u79d1\u6d88\u606f\u76d2\u4e2d, \u660e\u661f\u5b58\u5728\u5c5e\u6027\"\u51fa\u751f\u5e74\u6708\", \"\u51fa\u751f\u65e5\u671f\", \"\u751f\u65e5\", \"\u51fa\u751f\u65f6\u95f4\"\u7b49, \u8fd9\u4e9b\u5c5e\u6027\u540d\u5b57\u4e0d\u540c\u4f46\u662f\u90fd\u8868\u793a\u540c\u4e00\u4e2a\u542b\u4e49, \u56e0\u6b64\u53ef\u4ee5\u505a\u5c5e\u6027\u5bf9\u9f50. \u5728\u4f8b\u5982\u5728\u767e\u5ea6\u767e\u79d1\u4e2d, \u666f\u70b9\"\u6545\u5bab\"\u5b58\u5728\u5c5e\u6027\"\u4e2d\u6587\u540d\u79f0\", \u800c\u5728\u4e92\u52a8\u767e\u79d1\u4e2d\u7684\u5c5e\u6027\u4e3a\"\u4e2d\u6587\u540d\", \u4e24\u8005\u6765\u81ea\u4e0d\u540c\u7684\u5728\u7ebf\u767e\u79d1, \u62e5\u6709\u4e0d\u540c\u7684\u5c5e\u6027\u540d, \u4f46\u662f\u90fd\u8868\u793a\u76f8\u540c\u7684\u542b\u4e49, \u56e0\u6b64\u4e5f\u53ef\u4ee5\u505a\u5c5e\u6027\u5bf9\u9f50. \u5c5e\u6027\u5bf9\u9f50\u7684\u4e3b\u8981\u65b9\u6cd5: \u57fa\u4e8e\u7f16\u8f91\u8ddd\u79bb\u8ba1\u7b97\u76f8\u4f3c\u5ea6. \u57fa\u4e8e\u9886\u57df\u8bcd\u5178\u5339\u914d. \u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u8ddd\u79bb.","title":"\u5b9e\u4f53\u5bf9\u9f50"},{"location":"3_4.html","text":"\u89c4\u5219\u6d3e\u7684NER \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u7406\u89e3\u4ec0\u4e48\u662f\u89c4\u5219\u6d3e\u7684NER. \u638c\u63e1NER\u4efb\u52a1\u5e38\u89c1\u7684\u89c4\u5219\u5904\u7406\u65b9\u6cd5. \u89c4\u5219\u6d3eNER \u00b6 \u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u591a\u91c7\u7528\u8bed\u8a00\u5b66\u4e13\u5bb6\u624b\u5de5\u6784\u9020\u89c4\u5219\u6a21\u677f, \u9009\u7528\u7279\u5f81\u5305\u62ec\u7edf\u8ba1\u4fe1\u606f, \u6807\u70b9\u7b26\u53f7, \u5173\u952e\u5b57, \u6307\u793a\u8bcd\u548c\u65b9\u5411\u8bcd, \u4f4d\u7f6e\u8bcd(\u5982\u5c3e\u5b57), \u4e2d\u5fc3\u8bcd\u7b49\u65b9\u6cd5, \u4ee5\u6a21\u5f0f\u548c\u5b57\u7b26\u4e32\u76f8\u5339\u914d\u4e3a\u4e3b\u8981\u624b\u6bb5, \u8fd9\u7c7b\u7cfb\u7edf\u5927\u591a\u4f9d\u8d56\u4e8e\u77e5\u8bc6\u5e93\u548c\u8bcd\u5178\u7684\u5efa\u7acb. \u57fa\u4e8e\u89c4\u5219\u548c\u8bcd\u5178\u7684\u65b9\u6cd5\u662f\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4e2d\u6700\u65e9\u4f7f\u7528\u7684\u65b9\u6cd5. \u4e00\u822c\u800c\u8a00, \u5f53\u63d0\u53d6\u7684\u89c4\u5219\u80fd\u6bd4\u8f83\u7cbe\u786e\u5730\u53cd\u6620\u8bed\u8a00\u73b0\u8c61\u65f6, \u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u6027\u80fd\u8981\u4f18\u4e8e\u57fa\u4e8e\u7edf\u8ba1\u7684\u65b9\u6cd5. \u4f46\u662f\u8fd9\u4e9b\u89c4\u5219\u5f80\u5f80\u4f9d\u8d56\u4e8e\u5177\u4f53\u8bed\u8a00, \u9886\u57df\u548c\u6587\u672c\u98ce\u683c, \u7f16\u5236\u8fc7\u7a0b\u8017\u65f6\u4e14\u96be\u4ee5\u6db5\u76d6\u6240\u6709\u7684\u8bed\u8a00\u73b0\u8c61, \u7279\u522b\u5bb9\u6613\u4ea7\u751f\u9519\u8bef, \u7cfb\u7edf\u53ef\u79fb\u690d\u6027\u4e0d\u597d, \u5bf9\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u9700\u8981\u8bed\u8a00\u5b66\u4e13\u5bb6\u91cd\u65b0\u4e66\u5199\u89c4\u5219. \u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u7684\u53e6\u5916\u4e00\u4e2a\u7f3a\u70b9\u662f\u4ee3\u4ef7\u592a\u5927, \u5b58\u5728\u7cfb\u7edf\u5efa\u8bbe\u5468\u671f\u957f, \u79fb\u690d\u6027\u5dee\u800c\u4e14\u9700\u8981\u5efa\u7acb\u4e0d\u540c\u9886\u57df\u77e5\u8bc6\u5e93\u4f5c\u4e3a\u8f85\u52a9\u4ee5\u63d0\u9ad8\u7cfb\u7edf\u8bc6\u522b\u80fd\u529b\u7b49\u95ee\u9898. \u601d\u8003: \u89c4\u5219\u6d3e\u5904\u7406NER\u95ee\u9898, \u5728\u51c6\u786e\u7387\u548c\u53ec\u56de\u7387\u4e0a\u6709\u4ec0\u4e48\u7279\u70b9? \u5e38\u89c1\u7684\u89c4\u5219\u5904\u7406\u65b9\u6cd5 \u00b6 \u5de5\u4e1a\u754c\u5e38\u7528\u7684\u89c4\u5219\u5904\u7406\u65b9\u6cd5: \u9886\u57df\u5b57\u5178\u5339\u914d \u6b63\u5219\u8868\u8fbe\u5f0f\u5b9a\u4e49 \u9886\u57df\u5b57\u5178\u5339\u914d \u00b6 \u4f8b\u5982\u6709\u4e00\u6bb5\u6587\u672c\u5982\u4e0b: \u53ef\u5728\u63a5\u5230\u672c\u51b3\u5b9a\u4e66\u4e4b\u65e5\u8d77\u516d\u5341\u65e5\u5185\u5411\u4e2d\u56fd\u56fd\u5bb6\u5e02\u573a\u76d1\u7763\u7ba1\u7406\u603b\u5c40\u6216\u8005\u5317\u4eac\u5e02\u4eba\u6c11\u653f\u5e9c\u7533\u8bf7\u884c\u653f\u590d\u8bae,\u676d\u5dde\u6d77\u5eb7\u5a01\u89c6\u6570\u5b57\u6280\u672f\u80a1\u4efd\u6709\u9650\u516c\u53f8. \u5bf9\u4e0a\u9762\u8bed\u53e5\u8fdb\u884c\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u540e\u7684\u7ed3\u679c\u4e3a: \"\u4e2d\u56fd\u56fd\u5bb6\u5e02\u573a\u76d1\u7763\u7ba1\u7406\u603b\u5c40\", \"\u5317\u4eac\u5e02\u4eba\u6c11\u653f\u5e9c\", \"\u676d\u5dde\u6d77\u5eb7\u5a01\u89c6\u6570\u5b57\u6280\u672f\u80a1\u4efd\u6709\u9650\u516c\u53f8\". \u8bbe\u8ba1\u4e00\u4e2a\u6a21\u677f\u5f0f\u7684\u89c4\u5219: \u7ed9\u5b9a\u9996\u5b57\u7b26 + \u5c3e\u5b57\u7b26, \u4e2d\u95f4\u622a\u53d6\u7684\u5b50\u4e32\u4f5c\u4e3a\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7684\u7ed3\u679c! start_list = ['\u4e2d', '\u5317', '\u676d'] end_list = ['\u5c40', '\u5e9c', '\u53f8'] \u5177\u4f53\u5e94\u7528\u89c4\u5219\u7684\u4ee3\u7801\u5982\u4e0b: import re def getLabel ( sentence , start_index , end_index ): label = [] for i in sentence : if i in start_index : label . append ( 'S' ) elif i in end_index : label . append ( 'E' ) else : label . append ( 'O' ) return '' . join ( label ) def re_ner ( sentence , start_index , end_index ): ne_list = [] label = getLabel ( sentence , start_index , end_index ) pattern = re . compile ( 'SO*E' ) ne_label = re . finditer ( pattern , label ) for ne in ne_label : ne_list . append ( sentence [ int ( ne . start ()): int ( ne . end ())]) return ne_list sentence = '\u4e5f\u53ef\u5728\u63a5\u5230\u672c\u51b3\u5b9a\u4e66\u4e4b\u65e5\u8d77\u516d\u5341\u65e5\u5185\u5411\u4e2d\u56fd\u56fd\u5bb6\u5e02\u573a\u76d1\u7763\u7ba1\u7406\u603b\u5c40\u6216\u8005\u5317\u4eac\u5e02\u4eba\u6c11\u653f\u5e9c\u7533\u8bf7\u884c\u653f\u590d\u8bae,\u676d\u5dde\u6d77\u5eb7\u5a01\u89c6\u6570\u5b57\u6280\u672f\u80a1\u4efd\u6709\u9650\u516c\u53f8' start_list = [ '\u4e2d' , '\u5317' , '\u676d' ] end_list = [ '\u5c40' , '\u5e9c' , '\u53f8' ] start_time = time . time () result = re_ner ( sentence , start_list , end_list ) print ( 'cost time: ' , time . time () - start_time ) print ( 'result: ' , result ) \u8f93\u51fa\u7ed3\u679c: cost time: 0.0001347064971923828 result: ['\u4e2d\u56fd\u56fd\u5bb6\u5e02\u573a\u76d1\u7763\u7ba1\u7406\u603b\u5c40', '\u5317\u4eac\u5e02\u4eba\u6c11\u653f\u5e9c', '\u676d\u5dde\u6d77\u5eb7\u5a01\u89c6\u6570\u5b57\u6280\u672f\u80a1\u4efd\u6709\u9650\u516c\u53f8']","title":"3.4 \u57fa\u4e8e\u89c4\u5219\u6d3e\u7684NER"},{"location":"3_4.html#ner","text":"","title":"\u89c4\u5219\u6d3e\u7684NER"},{"location":"3_4.html#_1","text":"\u7406\u89e3\u4ec0\u4e48\u662f\u89c4\u5219\u6d3e\u7684NER. \u638c\u63e1NER\u4efb\u52a1\u5e38\u89c1\u7684\u89c4\u5219\u5904\u7406\u65b9\u6cd5.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"3_4.html#ner_1","text":"\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u591a\u91c7\u7528\u8bed\u8a00\u5b66\u4e13\u5bb6\u624b\u5de5\u6784\u9020\u89c4\u5219\u6a21\u677f, \u9009\u7528\u7279\u5f81\u5305\u62ec\u7edf\u8ba1\u4fe1\u606f, \u6807\u70b9\u7b26\u53f7, \u5173\u952e\u5b57, \u6307\u793a\u8bcd\u548c\u65b9\u5411\u8bcd, \u4f4d\u7f6e\u8bcd(\u5982\u5c3e\u5b57), \u4e2d\u5fc3\u8bcd\u7b49\u65b9\u6cd5, \u4ee5\u6a21\u5f0f\u548c\u5b57\u7b26\u4e32\u76f8\u5339\u914d\u4e3a\u4e3b\u8981\u624b\u6bb5, \u8fd9\u7c7b\u7cfb\u7edf\u5927\u591a\u4f9d\u8d56\u4e8e\u77e5\u8bc6\u5e93\u548c\u8bcd\u5178\u7684\u5efa\u7acb. \u57fa\u4e8e\u89c4\u5219\u548c\u8bcd\u5178\u7684\u65b9\u6cd5\u662f\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4e2d\u6700\u65e9\u4f7f\u7528\u7684\u65b9\u6cd5. \u4e00\u822c\u800c\u8a00, \u5f53\u63d0\u53d6\u7684\u89c4\u5219\u80fd\u6bd4\u8f83\u7cbe\u786e\u5730\u53cd\u6620\u8bed\u8a00\u73b0\u8c61\u65f6, \u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u6027\u80fd\u8981\u4f18\u4e8e\u57fa\u4e8e\u7edf\u8ba1\u7684\u65b9\u6cd5. \u4f46\u662f\u8fd9\u4e9b\u89c4\u5219\u5f80\u5f80\u4f9d\u8d56\u4e8e\u5177\u4f53\u8bed\u8a00, \u9886\u57df\u548c\u6587\u672c\u98ce\u683c, \u7f16\u5236\u8fc7\u7a0b\u8017\u65f6\u4e14\u96be\u4ee5\u6db5\u76d6\u6240\u6709\u7684\u8bed\u8a00\u73b0\u8c61, \u7279\u522b\u5bb9\u6613\u4ea7\u751f\u9519\u8bef, \u7cfb\u7edf\u53ef\u79fb\u690d\u6027\u4e0d\u597d, \u5bf9\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u9700\u8981\u8bed\u8a00\u5b66\u4e13\u5bb6\u91cd\u65b0\u4e66\u5199\u89c4\u5219. \u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u7684\u53e6\u5916\u4e00\u4e2a\u7f3a\u70b9\u662f\u4ee3\u4ef7\u592a\u5927, \u5b58\u5728\u7cfb\u7edf\u5efa\u8bbe\u5468\u671f\u957f, \u79fb\u690d\u6027\u5dee\u800c\u4e14\u9700\u8981\u5efa\u7acb\u4e0d\u540c\u9886\u57df\u77e5\u8bc6\u5e93\u4f5c\u4e3a\u8f85\u52a9\u4ee5\u63d0\u9ad8\u7cfb\u7edf\u8bc6\u522b\u80fd\u529b\u7b49\u95ee\u9898. \u601d\u8003: \u89c4\u5219\u6d3e\u5904\u7406NER\u95ee\u9898, \u5728\u51c6\u786e\u7387\u548c\u53ec\u56de\u7387\u4e0a\u6709\u4ec0\u4e48\u7279\u70b9?","title":"\u89c4\u5219\u6d3eNER"},{"location":"3_4.html#_2","text":"\u5de5\u4e1a\u754c\u5e38\u7528\u7684\u89c4\u5219\u5904\u7406\u65b9\u6cd5: \u9886\u57df\u5b57\u5178\u5339\u914d \u6b63\u5219\u8868\u8fbe\u5f0f\u5b9a\u4e49","title":"\u5e38\u89c1\u7684\u89c4\u5219\u5904\u7406\u65b9\u6cd5"},{"location":"3_4.html#_3","text":"\u4f8b\u5982\u6709\u4e00\u6bb5\u6587\u672c\u5982\u4e0b: \u53ef\u5728\u63a5\u5230\u672c\u51b3\u5b9a\u4e66\u4e4b\u65e5\u8d77\u516d\u5341\u65e5\u5185\u5411\u4e2d\u56fd\u56fd\u5bb6\u5e02\u573a\u76d1\u7763\u7ba1\u7406\u603b\u5c40\u6216\u8005\u5317\u4eac\u5e02\u4eba\u6c11\u653f\u5e9c\u7533\u8bf7\u884c\u653f\u590d\u8bae,\u676d\u5dde\u6d77\u5eb7\u5a01\u89c6\u6570\u5b57\u6280\u672f\u80a1\u4efd\u6709\u9650\u516c\u53f8. \u5bf9\u4e0a\u9762\u8bed\u53e5\u8fdb\u884c\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u540e\u7684\u7ed3\u679c\u4e3a: \"\u4e2d\u56fd\u56fd\u5bb6\u5e02\u573a\u76d1\u7763\u7ba1\u7406\u603b\u5c40\", \"\u5317\u4eac\u5e02\u4eba\u6c11\u653f\u5e9c\", \"\u676d\u5dde\u6d77\u5eb7\u5a01\u89c6\u6570\u5b57\u6280\u672f\u80a1\u4efd\u6709\u9650\u516c\u53f8\". \u8bbe\u8ba1\u4e00\u4e2a\u6a21\u677f\u5f0f\u7684\u89c4\u5219: \u7ed9\u5b9a\u9996\u5b57\u7b26 + \u5c3e\u5b57\u7b26, \u4e2d\u95f4\u622a\u53d6\u7684\u5b50\u4e32\u4f5c\u4e3a\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7684\u7ed3\u679c! start_list = ['\u4e2d', '\u5317', '\u676d'] end_list = ['\u5c40', '\u5e9c', '\u53f8'] \u5177\u4f53\u5e94\u7528\u89c4\u5219\u7684\u4ee3\u7801\u5982\u4e0b: import re def getLabel ( sentence , start_index , end_index ): label = [] for i in sentence : if i in start_index : label . append ( 'S' ) elif i in end_index : label . append ( 'E' ) else : label . append ( 'O' ) return '' . join ( label ) def re_ner ( sentence , start_index , end_index ): ne_list = [] label = getLabel ( sentence , start_index , end_index ) pattern = re . compile ( 'SO*E' ) ne_label = re . finditer ( pattern , label ) for ne in ne_label : ne_list . append ( sentence [ int ( ne . start ()): int ( ne . end ())]) return ne_list sentence = '\u4e5f\u53ef\u5728\u63a5\u5230\u672c\u51b3\u5b9a\u4e66\u4e4b\u65e5\u8d77\u516d\u5341\u65e5\u5185\u5411\u4e2d\u56fd\u56fd\u5bb6\u5e02\u573a\u76d1\u7763\u7ba1\u7406\u603b\u5c40\u6216\u8005\u5317\u4eac\u5e02\u4eba\u6c11\u653f\u5e9c\u7533\u8bf7\u884c\u653f\u590d\u8bae,\u676d\u5dde\u6d77\u5eb7\u5a01\u89c6\u6570\u5b57\u6280\u672f\u80a1\u4efd\u6709\u9650\u516c\u53f8' start_list = [ '\u4e2d' , '\u5317' , '\u676d' ] end_list = [ '\u5c40' , '\u5e9c' , '\u53f8' ] start_time = time . time () result = re_ner ( sentence , start_list , end_list ) print ( 'cost time: ' , time . time () - start_time ) print ( 'result: ' , result ) \u8f93\u51fa\u7ed3\u679c: cost time: 0.0001347064971923828 result: ['\u4e2d\u56fd\u56fd\u5bb6\u5e02\u573a\u76d1\u7763\u7ba1\u7406\u603b\u5c40', '\u5317\u4eac\u5e02\u4eba\u6c11\u653f\u5e9c', '\u676d\u5dde\u6d77\u5eb7\u5a01\u89c6\u6570\u5b57\u6280\u672f\u80a1\u4efd\u6709\u9650\u516c\u53f8']","title":"\u9886\u57df\u5b57\u5178\u5339\u914d"},{"location":"4_1.html","text":"multi-head-selection\u6a21\u578b \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u7406\u89e3multi-head-selection\u6a21\u578b\u7684\u67b6\u6784. \u638c\u63e1multi-head-selection\u6a21\u578b\u7684\u5b9e\u73b0. multi-head-selection\u6a21\u578b\u67b6\u6784 \u00b6 \u591a\u5934\u9009\u62e9\u6a21\u578b\u539f\u59cb\u8bba\u6587<< Joint entity recognition and relation extraction as a multi-head selection problem >>. multi-head-selection\u6a21\u578b\u53ef\u4ee5\u5c06NER\u4efb\u52a1\u548cRE\u4efb\u52a1\u5408\u4e8c\u4e3a\u4e00, \u4f5c\u4e3a\u4e00\u4e2a\u6574\u4f53\u6765\u770b\u5f85, \u8fd9\u4e5f\u662f\u591a\u5934\u7684\u610f\u4e49\u6240\u5728, \u6a21\u578b\u603b\u4f53\u67b6\u6784\u56fe\u5982\u4e0b: \u6838\u5fc3: \u6a21\u578b\u9996\u5148\u4f7f\u7528BiLSTM+CRF\u7ed3\u6784\u8bc6\u522b\u5934\u5b9e\u4f53, \u7136\u540e\u518d\u591a\u7c7b\u522b\u5206\u7c7b\u7684\u57fa\u7840\u4e0a, \u4e00\u6b21\u6027\u8fdb\u884c\u5c3e\u5b9e\u4f53\u63d0\u53d6\u548c\u5173\u7cfb\u62bd\u53d6!!! \u5b9e\u4f53-\u5173\u7cfb\u62bd\u53d6\u4efb\u52a1\u65e8\u5728\u8bc6\u522b\u53e5\u5b50\u4e2d\u7684\u5b9e\u4f53\u8de8\u5ea6, \u5e76\u68c0\u6d4b\u4e24\u4e2a\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb. \u4e00\u822c\u6765\u8bf4, \u5b83\u53ef\u4ee5\u5f62\u6210\u4e00\u4e2a\u4e09\u5143\u7ec4(e1, r, e2), \u8868\u793a\u5934\u5b9e\u4f53e1, \u5c3e\u5b9e\u4f53e2\u4e4b\u95f4\u5b58\u5728\u5173\u7cfbr. \u4f20\u7edf\u7684pipeline\u65b9\u6cd5\u4e00\u822c\u5c06\u4efb\u52a1\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5: \u7b2c\u4e00\u9636\u6bb5: \u547d\u540d\u5b9e\u4f53\u8bc6\u522b(NER) \u7b2c\u4e8c\u9636\u6bb5: \u5173\u7cfb\u62bd\u53d6(RE) \u601d\u8003: \u4f20\u7edfpipeline\u65b9\u6cd5\u662f\u5426\u8db3\u591f\u5b8c\u7f8e? \u6709\u4ec0\u4e48\u7f3a\u9677? \u8054\u5408\u6a21\u578b\u7684\u4e24\u79cd\u8303\u5f0f: \u8303\u5f0f\u4e00: (e1, e2) -> r , \u9996\u5148\u8bc6\u522b\u53e5\u5b50\u4e2d\u7684\u6240\u6709\u5b9e\u4f53, \u7136\u540e\u6839\u636e\u6bcf\u4e2a\u5b9e\u4f53\u5bf9\u8fdb\u884c\u5173\u7cfb\u5206\u7c7b. \u8303\u5f0f\u4e8c: e1 -> (r, e2) , \u9996\u5148\u68c0\u6d4b\u5934\u5b9e\u4f53, \u7136\u540e\u9884\u6d4b\u5bf9\u5e94\u7684\u5173\u7cfb\u548c\u5c3e\u5b9e\u4f53. \u601d\u8003: \u8303\u5f0f\u4e00\u548c\u8303\u5f0f\u4e8c\u662f\u5426\u8db3\u591f\u5b8c\u7f8e? \u6709\u4ec0\u4e48\u7f3a\u9677? \u54ea\u4e2a\u66f4\u597d? multi-head-selection\u6a21\u578b\u5b9e\u73b0 \u00b6 \u672c\u9879\u76ee\u4e2d\u7528\u4e8e\u533b\u7597\u573a\u666f\u4e0b\u7684\u6570\u636e\u653e\u57283.2\u548c3.3\u8282\u4e2d\u5e94\u7528, \u672c\u8282\u4e3a\u4e86\u540c\u65f6\u517c\u987eNER\u548cRE\u4efb\u52a1, \u91c7\u7528\u4e86\u66f4\u5927\u4f17\u5316\u7684\u975e\u5782\u76f4\u9886\u57df\u6570\u636e, \u4ee5\u6709\u5229\u4e8e\u540c\u5b66\u4eec\u7684\u5b66\u4e60\u7406\u89e3. \u672c\u9879\u76ee\u7684\u591a\u5934\u9009\u62e9\u6a21\u578b\u5728\u5b9e\u73b0\u4e0a\u5206\u5982\u4e0b\u51e0\u4e2a\u6b65\u9aa4: \u7b2c\u4e00\u6b65: \u67e5\u770b\u6570\u636e\u96c6 \u7b2c\u4e8c\u6b65: \u6784\u5efa\u6570\u636e\u8fed\u4ee3\u5668 \u7b2c\u4e09\u6b65: \u6784\u5efa\u6a21\u578b\u7c7b \u7b2c\u56db\u6b65: \u7f16\u5199\u8bc4\u4f30\u6307\u6807\u51fd\u6570 \u7b2c\u4e94\u6b65: \u7f16\u5199\u8fd0\u884c\u4e3b\u51fd\u6570 \u7b2c\u4e00\u6b65: \u67e5\u770b\u6570\u636e\u96c6 \u00b6 \u6570\u636e\u96c6\u603b\u5171\u67095\u4e2a\u6587\u4ef6: \u8bad\u7ec3\u96c6\u6570\u636etrain_data.json \u9a8c\u8bc1\u96c6\u6570\u636edev_data.json \u8bcd\u5178\u6570\u636eword_vocab.json \u5173\u7cfb\u8bcd\u5178\u6570\u636erelation_vocab.json \u6807\u6ce8\u5b57\u5178\u6570\u636ebio_vocab.json \u8bad\u7ec3\u96c6\u6570\u636e\u8def\u5f84: /home/ec2-user/information_extraction/relation/multi_head_selection/data/train_data.json {\"text\": \"\u5982\u4f55\u6f14\u597d\u81ea\u5df1\u7684\u89d2\u8272\uff0c\u8bf7\u8bfb\u300a\u6f14\u5458\u81ea\u6211\u4fee\u517b\u300b\u300a\u559c\u5267\u4e4b\u738b\u300b\u5468\u661f\u9a70\u5d1b\u8d77\u4e8e\u7a77\u56f0\u6f66\u5012\u4e4b\u4e2d\u7684\u72ec\u95e8\u79d8\u7b08\", \"spo_list\": [{\"predicate\": \"\u4e3b\u6f14\", \"object\": \"\u5468\u661f\u9a70\", \"subject\": \"\u559c\u5267\u4e4b\u738b\"}], \"bio\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"O\", \"B\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"selection\": [{\"subject\": 24, \"predicate\": 46, \"object\": 28}]} {\"text\": \"\u8336\u6811\u8336\u7f51\u877d\uff0cStephanitis chinensis Drake\uff0c\u5c5e\u534a\u7fc5\u76ee\u7f51\u877d\u79d1\u51a0\u7f51\u693f\u5c5e\u7684\u4e00\u79cd\u6606\u866b\", \"spo_list\": [{\"predicate\": \"\u76ee\", \"object\": \"\u534a\u7fc5\u76ee\", \"subject\": \"\u8336\u6811\u8336\u7f51\u877d\"}], \"bio\": [\"B\", \"I\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"selection\": [{\"subject\": 4, \"predicate\": 4, \"object\": 37}]} {\"text\": \"\u7231\u5fb7\u534e\u00b7\u5c3c\u79d1\u00b7\u57c3\u5c14\u5357\u8fea\u65af\uff081986-\uff09\uff0c\u662f\u4e00\u4f4d\u8eab\u9ad8\u53ea\u670970\u516c\u5206\u54e5\u4f26\u6bd4\u4e9a\u7537\u5b50\uff0c\u4f53\u91cd10\u516c\u65a4\uff0c\u53ea\u6bd4\u968f\u8eab\u884c\u674e\u9ad8\u4e00\u4e9b\uff0c2010\u5e74\u83b7\u5409\u5c3c\u65af\u4e16\u754c\u7eaa\u5f55\u6b63\u5f0f\u8ba4\u8bc1\uff0c\u6210\u4e3a\u5168\u7403\u5f53\u4eca\u6700\u77ee\u7684\u6210\u5e74\u7537\u4eba\", \"spo_list\": [{\"predicate\": \"\u8eab\u9ad8\", \"object\": \"70\u516c\u5206\", \"subject\": \"\u7231\u5fb7\u534e\u00b7\u5c3c\u79d1\u00b7\u57c3\u5c14\u5357\u8fea\u65af\"}, {\"predicate\": \"\u51fa\u751f\u65e5\u671f\", \"object\": \"1986\", \"subject\": \"\u7231\u5fb7\u534e\u00b7\u5c3c\u79d1\u00b7\u57c3\u5c14\u5357\u8fea\u65af\"}, {\"predicate\": \"\u56fd\u7c4d\", \"object\": \"\u54e5\u4f26\u6bd4\u4e9a\", \"subject\": \"\u7231\u5fb7\u534e\u00b7\u5c3c\u79d1\u00b7\u57c3\u5c14\u5357\u8fea\u65af\"}], \"bio\": [\"B\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"O\", \"B\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"B\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"selection\": [{\"subject\": 11, \"predicate\": 14, \"object\": 30}, {\"subject\": 11, \"predicate\": 17, \"object\": 16}, {\"subject\": 11, \"predicate\": 21, \"object\": 34}]} {\"text\": \"\u300a\u9010\u98ce\u884c\u300b\u662f\u767e\u5ea6\u6587\u5b66\u65d7\u4e0b\u7eb5\u6a2a\u4e2d\u6587\u7f51\u7b7e\u7ea6\u4f5c\u5bb6\u6e05\u6c34\u79cb\u98ce\u521b\u4f5c\u7684\u4e00\u90e8\u4e1c\u65b9\u7384\u5e7b\u5c0f\u8bf4\uff0c\u5c0f\u8bf4\u5df2\u4e8e2014-04-28\u6b63\u5f0f\u53d1\u5e03\", \"spo_list\": [{\"predicate\": \"\u8fde\u8f7d\u7f51\u7ad9\", \"object\": \"\u7eb5\u6a2a\u4e2d\u6587\u7f51\", \"subject\": \"\u9010\u98ce\u884c\"}, {\"predicate\": \"\u4f5c\u8005\", \"object\": \"\u6e05\u6c34\u79cb\u98ce\", \"subject\": \"\u9010\u98ce\u884c\"}], \"bio\": [\"O\", \"B\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"selection\": [{\"subject\": 3, \"predicate\": 23, \"object\": 16}, {\"subject\": 3, \"predicate\": 42, \"object\": 24}]} {\"text\": \"\u201d\uff08\u56fe\uff09\u5f20\u5b66\u826f\u3001\u8d75\u4e00\u837b\u53cc\u6816\", \"spo_list\": [{\"predicate\": \"\u59bb\u5b50\", \"object\": \"\u8d75\u4e00\u837b\", \"subject\": \"\u5f20\u5b66\u826f\"}, {\"predicate\": \"\u4e08\u592b\", \"object\": \"\u5f20\u5b66\u826f\", \"subject\": \"\u8d75\u4e00\u837b\"}], \"bio\": [\"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"O\", \"B\", \"I\", \"I\", \"O\", \"O\"], \"selection\": [{\"subject\": 6, \"predicate\": 8, \"object\": 10}, {\"subject\": 10, \"predicate\": 24, \"object\": 6}]} \u9a8c\u8bc1\u96c6\u6570\u636e\u8def\u5f84: /home/ec2-user/information_extraction/relation/multi_head_selection/data/dev_data.json {\"text\": \"\u67e5\u5c14\u65af\u00b7\u963f\u5170\u57fa\u65af\uff08Charles Ar\u00e1nguiz\uff09\uff0c1989\u5e744\u670817\u65e5\u51fa\u751f\u4e8e\u667a\u5229\u5723\u5730\u4e9a\u54e5\uff0c\u667a\u5229\u804c\u4e1a\u8db3\u7403\u8fd0\u52a8\u5458\uff0c\u53f8\u804c\u4e2d\u573a\uff0c\u6548\u529b\u4e8e\u5fb7\u56fd\u8db3\u7403\u7532\u7ea7\u8054\u8d5b\u52d2\u6c83\u5e93\u68ee\u8db3\u7403\u4ff1\u4e50\u90e8\", \"spo_list\": [{\"predicate\": \"\u51fa\u751f\u5730\", \"object\": \"\u5723\u5730\u4e9a\u54e5\", \"subject\": \"\u67e5\u5c14\u65af\u00b7\u963f\u5170\u57fa\u65af\"}, {\"predicate\": \"\u51fa\u751f\u65e5\u671f\", \"object\": \"1989\u5e744\u670817\u65e5\", \"subject\": \"\u67e5\u5c14\u65af\u00b7\u963f\u5170\u57fa\u65af\"}], \"bio\": [\"B\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"selection\": [{\"subject\": 7, \"predicate\": 3, \"object\": 45}, {\"subject\": 7, \"predicate\": 17, \"object\": 36}]} {\"text\": \"\u300a\u79bb\u5f00\u300b\u662f\u7531\u5f20\u5b87\u8c31\u66f2\uff0c\u6f14\u5531\", \"spo_list\": [{\"predicate\": \"\u6b4c\u624b\", \"object\": \"\u5f20\u5b87\", \"subject\": \"\u79bb\u5f00\"}, {\"predicate\": \"\u4f5c\u66f2\", \"object\": \"\u5f20\u5b87\", \"subject\": \"\u79bb\u5f00\"}], \"bio\": [\"O\", \"B\", \"I\", \"O\", \"O\", \"O\", \"B\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"selection\": [{\"subject\": 2, \"predicate\": 31, \"object\": 7}, {\"subject\": 2, \"predicate\": 43, \"object\": 7}]} {\"text\": \"\u300a\u6124\u6012\u7684\u5510\u50e7\u300b\u7531\u5317\u4eac\u5434\u610f\u6ce2\u5f71\u89c6\u6587\u5316\u5de5\u4f5c\u5ba4\u4e0e\u4f18\u9177\u7535\u89c6\u5267\u9891\u9053\u8054\u5408\u5236\u4f5c\uff0c\u6545\u4e8b\u4ee5\u559c\u5267\u5143\u7d20\u4e3a\u4e3b\uff0c\u8bb2\u8ff0\u5510\u50e7\u4e0e\u4f5b\u7956\u6253\u724c\uff0c\u5f97\u7f6a\u4e86\u4f5b\u7956\uff0c\u88ab\u8e22\u4e0b\u4eba\u95f4\u518d\u6e21\u4e5d\u4e5d\u516b\u5341\u4e00\u96be\u7684\u6545\u4e8b\", \"spo_list\": [{\"predicate\": \"\u51fa\u54c1\u516c\u53f8\", \"object\": \"\u5317\u4eac\u5434\u610f\u6ce2\u5f71\u89c6\u6587\u5316\u5de5\u4f5c\u5ba4\", \"subject\": \"\u6124\u6012\u7684\u5510\u50e7\"}, {\"predicate\": \"\u5bfc\u6f14\", \"object\": \"\u5434\u610f\u6ce2\", \"subject\": \"\u6124\u6012\u7684\u5510\u50e7\"}], \"bio\": [\"O\", \"B\", \"I\", \"I\", \"I\", \"I\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"selection\": [{\"subject\": 5, \"predicate\": 15, \"object\": 19}, {\"subject\": 5, \"predicate\": 12, \"object\": 12}]} {\"text\": \"\u674e\u6cbb\u5373\u4f4d\u540e\uff0c\u8427\u6dd1\u5983\u53d7\u5ba0\uff0c\u738b\u7687\u540e\u4e3a\u4e86\u6392\u6324\u8427\u6dd1\u5983\uff0c\u7b54\u5e94\u674e\u6cbb\u8ba9\u8eab\u5728\u611f\u4e1a\u5bfa\u7684\u6b66\u5219\u5929\u7eed\u8d77\u5934\u53d1\uff0c\u91cd\u65b0\u7eb3\u5165\u540e\u5bab\", \"spo_list\": [{\"predicate\": \"\u59bb\u5b50\", \"object\": \"\u8427\u6dd1\u5983\", \"subject\": \"\u674e\u6cbb\"}, {\"predicate\": \"\u4e08\u592b\", \"object\": \"\u674e\u6cbb\", \"subject\": \"\u8427\u6dd1\u5983\"}], \"bio\": [\"B\", \"I\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"selection\": [{\"subject\": 1, \"predicate\": 8, \"object\": 8}, {\"subject\": 8, \"predicate\": 24, \"object\": 1}]} \u8bcd\u5178\u6570\u636e\u8def\u5f84: /home/ec2-user/information_extraction/relation/multi_head_selection/data/word_vocab.json {\"<pad>\": 0, \"\u5982\": 1, \"\u4f55\": 2, \"\u6f14\": 3, \"\u597d\": 4, \"\u81ea\": 5, \"\u5df1\": 6, \"\u7684\": 7, \"\u89d2\": 8, \"\u8272\": 9, \"\uff0c\": 10, \"\u8bf7\": 11, \"\u8bfb\": 12, \"\u300a\": 13, \"\u5458\": 14, \"\u6211\": 15, \"\u4fee\": 16, \"\u517b\": 17, \"\u300b\": 18, \"\u559c\": 19, \"\u5267\": 20, \"\u4e4b\": 21, \"\u738b\": 22, \"\u5468\": 23, \"\u661f\": 24, \"\u9a70\": 25, \"\u5d1b\": 26, \"\u8d77\": 27, \"\u4e8e\": 28, \"\u7a77\": 29, \"\u56f0\": 30, \"\u6f66\": 31, \"\u5012\": 32, \"\u4e2d\": 33, \"\u72ec\": 34, \"\u95e8\": 35, \"\u79d8\": 36, \"\u7b08\": 37, \"\u8336\": 38, \"\u6811\": 39, \"\u7f51\": 40, \"\u877d\": 41, \"S\": 42, \"t\": 43, \"e\": 44, \"p\": 45, \"h\": 46, \"a\": 47, \"n\": 48, \"i\": 49, \"s\": 50, \" \": 51, \"c\": 52, \"D\": 53, \"r\": 54, \"k\": 55, \"\u5c5e\": 56, \"\u534a\": 57, \"\u7fc5\": 58, \"\u76ee\": 59, \"\u79d1\": 60, \"\u51a0\": 61, \"\u693f\": 62, \"\u4e00\": 63, \"\u79cd\": 64, \"\u6606\": 65, \"\u866b\": 66, \"\u4e1d\": 67, \"\u8757\": 68, \"O\": 69, \"d\": 70, \"o\": 71, \"\u7eb2\": 72, \"\u76f4\": 73, \"\u603b\": 74, \"\u4e2a\": 75, \"\u7231\": 76, \"\u5fb7\": 77, \"\u534e\": 78, \"\u00b7\": 79, \"\u5c3c\": 80, \"\u57c3\": 81, \"\u5c14\": 82, \"\u5357\": 83, \"\u8fea\": 84, \"\u65af\": 85, \"\uff08\": 86, \"1\": 87, \"9\": 88, \"8\": 89, \"6\": 90, \"-\": 91, \"\uff09\": 92, \"\u662f\": 93, \"\u4f4d\": 94, \"\u8eab\": 95, \"\u9ad8\": 96, \"\u53ea\": 97, \"\u6709\": 98, \"7\": 99, \"0\": 100, \"\u516c\": 101, \"\u5206\": 102, \"\u54e5\": 103, \"\u4f26\": 104, \"\u6bd4\": 105, \"\u4e9a\": 106, \"\u7537\": 107, \"\u5b50\": 108, \"\u4f53\": 109, \"\u91cd\": 110, \"\u65a4\": 111, \"\u968f\": 112, \"\u884c\": 113, \"\u674e\": 114, \"\u4e9b\": 115, \"2\": 116, \"\u5e74\": 117, \"\u83b7\": 118, \"\u5409\": 119, \"\u4e16\": 120, \"\u754c\": 121, \"\u7eaa\": 122, \"\u5f55\": 123, \"\u6b63\": 124, \"\u5f0f\": 125, \"\u8ba4\": 126, \"\u8bc1\": 127, \"\u6210\": 128, \"\u4e3a\": 129, \"\u5168\": 130, \"\u7403\": 131, \"\u5f53\": 132, \"\u4eca\": 133, \"\u6700\": 134, \"\u77ee\": 135, \"\u4eba\": 136, \"\u9010\": 137, \"\u98ce\": 138, \"\u767e\": 139, \"\u5ea6\": 140, \"\u6587\": 141, \"\u5b66\": 142, \"\u65d7\": 143, \"\u4e0b\": 144, \"\u7eb5\": 145, \"\u6a2a\": 146, \"\u7b7e\": 147, \"\u7ea6\": 148, \"\u4f5c\": 149, \"\u5bb6\": 150, \"\u6e05\": 151, \"\u6c34\": 152, \"\u79cb\": 153, \"\u521b\": 154, \"\u90e8\": 155, \"\u4e1c\": 156, \"\u65b9\": 157, \"\u7384\": 158, \"\u5e7b\": 159, \"\u5c0f\": 160, \"\u8bf4\": 161, \"\u5df2\": 162, \"4\": 163, \"\u53d1\": 164, \"\u5e03\": 165, \"\u7985\": 166, \"\u610f\": 167, \"\u6b4c\": 168, \"\u8005\": 169, \"\u5218\": 170, \"\u73c2\": 171, \"\u77e3\": 172, \"\u8896\": 173, \"\u4e91\": 174, \"\u8bc9\": 175, \"\u77e5\": 176, \"\u2026\": 177, \"\u7ef5\": 178, \"\u67d4\": 179, \"\u7eaf\": 180, \"\u51c0\": 181, \"\u5973\": 182, \"\u58f0\": 183, \"\u5c06\": 184, \"\u5fc3\": 185, \"\u4e07\": 186, \"\u5343\": 187, \"\u5c71\": 188, \"\u5c3d\": 189, \"\u52fe\": 190, \"\u52d2\": 191, \"\u8fd9\": 192, \"\u7d20\": 193, \"\u753b\": 194, \"\u97f3\": 195, \"\u8fe6\": 196, \"\u5e15\": 197, \"\u5df4\": 198, \"\u7279\": 199, \"\u5cf0\": 200, ......} \u5173\u7cfb\u8bcd\u5178\u6570\u636e\u8def\u5f84: /home/ec2-user/information_extraction/relation/multi_head_selection/data/relation_vocab.json {\"\u7956\u7c4d\": 0, \"\u7236\u4eb2\": 1, \"\u603b\u90e8\u5730\u70b9\": 2, \"\u51fa\u751f\u5730\": 3, \"\u76ee\": 4, \"\u9762\u79ef\": 5, \"\u7b80\u79f0\": 6, \"\u4e0a\u6620\u65f6\u95f4\": 7, \"\u59bb\u5b50\": 8, \"\u6240\u5c5e\u4e13\u8f91\": 9, \"\u6ce8\u518c\u8d44\u672c\": 10, \"\u9996\u90fd\": 11, \"\u5bfc\u6f14\": 12, \"\u5b57\": 13, \"\u8eab\u9ad8\": 14, \"\u51fa\u54c1\u516c\u53f8\": 15, \"\u4fee\u4e1a\u5e74\u9650\": 16, \"\u51fa\u751f\u65e5\u671f\": 17, \"\u5236\u7247\u4eba\": 18, \"\u6bcd\u4eb2\": 19, \"\u7f16\u5267\": 20, \"\u56fd\u7c4d\": 21, \"\u6d77\u62d4\": 22, \"\u8fde\u8f7d\u7f51\u7ad9\": 23, \"\u4e08\u592b\": 24, \"\u671d\u4ee3\": 25, \"\u6c11\u65cf\": 26, \"\u53f7\": 27, \"\u51fa\u7248\u793e\": 28, \"\u4e3b\u6301\u4eba\": 29, \"\u4e13\u4e1a\u4ee3\u7801\": 30, \"\u6b4c\u624b\": 31, \"\u4f5c\u8bcd\": 32, \"\u4e3b\u89d2\": 33, \"\u8463\u4e8b\u957f\": 34, \"\u6210\u7acb\u65e5\u671f\": 35, \"\u6bd5\u4e1a\u9662\u6821\": 36, \"\u5360\u5730\u9762\u79ef\": 37, \"\u5b98\u65b9\u8bed\u8a00\": 38, \"\u90ae\u653f\u7f16\u7801\": 39, \"\u4eba\u53e3\u6570\u91cf\": 40, \"\u6240\u5728\u57ce\u5e02\": 41, \"\u4f5c\u8005\": 42, \"\u4f5c\u66f2\": 43, \"\u6c14\u5019\": 44, \"\u5609\u5bbe\": 45, \"\u4e3b\u6f14\": 46, \"\u6539\u7f16\u81ea\": 47, \"\u521b\u59cb\u4eba\": 48, \"N\": 49} \u6807\u6ce8\u5b57\u5178\u6570\u636e\u8def\u5f84: /home/ec2-user/information_extraction/relation/multi_head_selection/data/bio_vocab.json {\"B\": 0, \"I\": 1, \"O\": 2} \u7b2c\u4e8c\u6b65: \u6784\u5efa\u6570\u636e\u8fed\u4ee3\u5668 \u00b6 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/multi_head_selection/dataloaders/selection_loader.py # \u5bfc\u5165\u5de5\u5177\u5305 import os import json import torch from torch.utils.data.dataloader import DataLoader from torch.utils.data import Dataset from torch.nn.utils.rnn import pad_sequence from functools import partial from typing import Dict , List , Tuple , Set , Optional from transformers import BertTokenizer # Dataset\u662f\u4e00\u4e2a\u62bd\u8c61\u7c7b, \u81ea\u5b9a\u4e49\u7684Dataset\u9700\u8981\u7ee7\u627f\u5b83\u5e76\u4e14\u5b9e\u73b0\u4e24\u4e2a\u6210\u5458\u65b9\u6cd5: # __getitem__() \u7b2c\u4e00\u4e2a\u6700\u4e3a\u91cd\u8981, \u5373\u6bcf\u6b21\u600e\u4e48\u8bfb\u6570\u636e # __len__() \u8fd4\u56de\u6574\u4e2a\u6570\u636e\u96c6\u7684\u957f\u5ea6 PAD , CLS , SEP = '[PAD]' , '[CLS]' , '[SEP]' # \u7f16\u5199\u6570\u636e\u96c6\u7684\u7c7b class Selection_Dataset ( Dataset ): def __init__ ( self , hyper , dataset ): self . hyper = hyper self . data_root = hyper [ 'data_root' ] self . bert_model = hyper [ 'bert_model' ] # \u52a0\u8f7d\u8bcd\u5178, \u5173\u7cfb, \u6807\u6ce8\u7684\u6570\u636e self . word_vocab = json . load ( open ( os . path . join ( self . data_root , 'word_vocab.json' ), 'r' )) self . relation_vocab = json . load ( open ( os . path . join ( self . data_root , 'relation_vocab.json' ), 'r' )) self . bio_vocab = json . load ( open ( os . path . join ( self . data_root , 'bio_vocab.json' ), 'r' )) self . selection_list = [] self . text_list = [] self . bio_list = [] self . spo_list = [] # bert\u5206\u8bcd\u5668 self . bert_tokenizer = BertTokenizer . from_pretrained ( self . bert_model ) # \u8bfb\u53d6\u6570\u636e\u96c6, \u5e76\u5c06\u4e0d\u540c\u7684\u5b57\u6bb5\u5206\u522b\u8fdb\u884c\u52a0\u8f7d\u5b58\u50a8 for line in open ( os . path . join ( self . data_root , dataset ), 'r' ): line = line . strip ( ' \\n ' ) instance = json . loads ( line ) self . selection_list . append ( instance [ 'selection' ]) self . text_list . append ( instance [ 'text' ]) self . bio_list . append ( instance [ 'bio' ]) self . spo_list . append ( instance [ 'spo_list' ]) def __getitem__ ( self , index ): selection = self . selection_list [ index ] text = self . text_list [ index ] bio = self . bio_list [ index ] spo = self . spo_list [ index ] if self . hyper [ 'cell_name' ] == 'bert' : # 1.\u6570\u636e\u8f7d\u5165\u90e8\u5206 # \u521d\u59cb\u5316bert\u5206\u8bcd\u5668, \u5bf9\u8f93\u5165\u53e5\u5b50\u9884\u5904\u7406, \u52a0\u4e0a\u7279\u6b8a\u6807\u8bb0\u7b26[cls],[pad],[seq], \u5206\u8bcd text , bio , selection = self . pad_bert ( text , bio , selection ) tokens_id = torch . tensor ( self . bert_tokenizer . convert_tokens_to_ids ( text )) else : tokens_id = self . text2id ( text ) bio_id = self . bio2id ( bio ) # self.relation_vocab \u4f5c\u4e3a\u8fd4\u56de\uff0c\u4ee5\u4fbf\u540e\u9762\u6279\u5904\u7406\u7684\u65f6\u5019\u5c06selection\u53d8\u6210table return tokens_id , bio_id , selection , len ( text ), spo , text , bio , self . relation_vocab def __len__ ( self ): return len ( self . text_list ) # \u5bf9\u6587\u672c\u8fdb\u884cPAD\u8865\u9f50\u7684\u51fd\u6570 def pad_bert ( self , text , bio , selection ): # for [CLS] and [SEP] text = [ '[CLS]' ] + list ( text ) + [ '[SEP]' ] bio = [ 'O' ] + bio + [ 'O' ] selection = [{ 'subject' : triplet [ 'subject' ] + 1 , 'object' : triplet [ 'object' ] + 1 , 'predicate' : triplet [ 'predicate' ]} for triplet in selection ] assert len ( text ) <= self . hyper [ 'max_text_len' ] text = text + [ '[PAD]' ] * ( self . hyper [ 'max_text_len' ] - len ( text )) bio = bio + [ 'O' ] * ( self . hyper [ 'max_text_len' ] - len ( bio )) return text , bio , selection # \u5c06\u8bcd\u8f6c\u6362\u4e3aid\u8868\u793a def text2id ( self , text ): oov = self . word_vocab [ 'oov' ] text_id_list = list ( map ( lambda x : self . word_vocab . get ( x , oov ), text )) return torch . tensor ( text_id_list ) def bio2id ( self , bio ): bio_id_list = list ( map ( lambda x : self . bio_vocab [ x ], bio )) return torch . tensor ( bio_id_list ) # \u6279\u6b21\u6570\u636e\u8bfb\u53d6\u5668, \u672c\u8d28\u4e0a\u662f\u670d\u52a1\u533acollate_fn()\u4e2a\u6027\u5316\u6570\u636e\u8fed\u4ee3\u5668\u7684\u51fd\u6570 class Batch_reader ( object ): def __init__ ( self , data ): data . sort ( key = lambda x : len ( x [ 0 ]), reverse = True ) transposed_data = list ( zip ( * data )) self . length = transposed_data [ 3 ] # tokens_id, bio_id, selection_id, spo, text, bio # word\u5b57\u5178\u4e2dpad\u7684id\u662f0\uff0cpad_sequence\u9ed8\u8ba4padding_value\u662f0\uff0c\u8fd9\u91cc\u53ef\u4ee5\u4e0d\u6307\u5b9a\u4e86 self . tokens_id = pad_sequence ( transposed_data [ 0 ], batch_first = True ) self . bio_id = pad_sequence ( transposed_data [ 1 ], batch_first = True ) batch_max_text_len = self . tokens_id . size ()[ 1 ] relation_vocab = transposed_data [ 7 ][ 0 ] self . selection_id = self . selection2table ( batch_max_text_len , transposed_data [ 2 ], relation_vocab ) self . spo_gold = transposed_data [ 4 ] self . text = transposed_data [ 5 ] self . bio = transposed_data [ 6 ] # GPU\u52a0\u901f\u529f\u80fd\u6a21\u5757 def pin_memory ( self ): self . tokens_id = self . tokens_id . pin_memory () self . bio_id = self . bio_id . pin_memory () self . selection_id = self . selection_id . pin_memory () return self # \u5c06selection\u6570\u636e\u6a21\u5757\u8fdb\u884c\u77e9\u9635\u6620\u5c04 def selection2table ( self , batch_max_text_len , selection , relation_vocab ): # s p o batch_size = len ( selection ) # \u521d\u59cb\u53164\u7ef4\u77e9\u9635, \u540e\u7eed\u7684\u5173\u7cfb\u62bd\u53d6\u90fd\u91c7\u75284\u7ef4\u77e9\u9635 result = torch . zeros ( batch_size , batch_max_text_len , len ( relation_vocab ), batch_max_text_len ) NA = relation_vocab [ 'N' ] # \u5916\u5c42for\u5faa\u73af\u904d\u5386\u6279\u6b21 for b in range ( batch_size ): # \u9ed8\u8ba4NA\u5173\u7cfb\u7b49\u4e8e1 result [ b , :, NA , :] = 1 # \u5185\u5c42for\u5faa\u73af\u904d\u5386\u4e09\u5143\u7ec4 for triplet in selection [ b ]: object = triplet [ 'object' ] subject = triplet [ 'subject' ] predicate = triplet [ 'predicate' ] # \u6709\u6548\u5173\u7cfb\u8bbe\u7f6e\u4e3a1, NA\u5173\u7cfb\u8bbe\u7f6e\u4e3a0 result [ b , subject , predicate , object ] = 1 result [ b , subject , NA , object ] = 0 return result # \u5b9a\u4e49\u4e2a\u6027\u5316\u8bfb\u53d6\u51fd\u6570 def collate_fn ( batch ): return Batch_reader ( batch ) Selection_loader = partial ( DataLoader , collate_fn = collate_fn , pin_memory = True ) \u7b2c\u4e09\u6b65: \u6784\u5efa\u6a21\u578b\u7c7b \u00b6 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/multi_head_selection/models/selection.py import torch import torch.nn as nn import torch.nn.functional as F import json import os import copy from typing import Dict , List , Tuple , Set , Optional from functools import partial from torchcrf import CRF from transformers import BertModel , BertTokenizer from torch.nn.utils.rnn import pack_padded_sequence , pad_packed_sequence # \u591a\u5934\u9009\u62e9\u7684\u6838\u5fc3\u7c7b\u4ee3\u7801 class MultiHeadSelection ( nn . Module ): def __init__ ( self , hyper ): super ( MultiHeadSelection , self ) . __init__ () self . hyper = hyper self . data_root = hyper [ 'data_root' ] self . gpu = hyper [ 'gpu' ] self . bert_model = hyper [ 'bert_model' ] # \u8bfb\u53d6\u539f\u59cb\u6587\u4ef6\u6570\u636e self . word_vocab = json . load ( open ( os . path . join ( self . data_root , 'word_vocab.json' ), 'r' )) self . relation_vocab = json . load ( open ( os . path . join ( self . data_root , 'relation_vocab.json' ), 'r' )) self . bio_vocab = json . load ( open ( os . path . join ( self . data_root , 'bio_vocab.json' ), 'r' )) self . id2bio = { v : k for k , v in self . bio_vocab . items ()} # Word, \u8bcd\u6c47\u5d4c\u5165\u5f20\u91cf self . word_embeddings = nn . Embedding ( num_embeddings = len ( self . word_vocab ), embedding_dim = hyper [ 'emb_size' ]) # Relation, \u5173\u7cfb\u5d4c\u5165\u5f20\u91cf self . relation_emb = nn . Embedding ( num_embeddings = len ( self . relation_vocab ), embedding_dim = hyper [ 'rel_emb_size' ]) # NER, \u547d\u540d\u5b9e\u4f53\u5d4c\u5165\u5f20\u91cf self . bio_emb = nn . Embedding ( num_embeddings = len ( self . bio_vocab ), embedding_dim = hyper [ 'bio_emb_size' ]) # \u7f16\u7801\u5668Encoder\u7684\u4e0d\u540c\u5b9a\u4e49, \u53ef\u4ee5\u91c7\u7528GRU, LSTM, BERT if hyper [ 'cell_name' ] == 'gru' : self . encoder = nn . GRU ( hyper [ 'emb_size' ], hyper [ 'hidden_size' ], bidirectional = True , batch_first = True ) elif hyper [ 'cell_name' ] == 'lstm' : self . encoder = nn . LSTM ( hyper [ 'emb_size' ], hyper [ 'hidden_size' ], bidirectional = True , batch_first = True ) elif hyper [ 'cell_name' ] == 'bert' : # \u5f53\u91c7\u7528BERT\u4f5c\u4e3a\u7f16\u7801\u5668\u65f6, \u76f4\u63a5\u5f15\u5165\u9884\u8bad\u7ec3\u6a21\u578b\u5373\u53ef self . encoder = BertModel . from_pretrained ( self . bert_model ) # \u6b64\u5904\u5373\u4f7f\u4e0d\u6267\u884cfor\u5faa\u73af, \u9ed8\u8ba4\u7684\u6240\u6709encoder\u53c2\u6570\u90fd\u53c2\u4e0e\u53cd\u5411\u4f20\u64ad\u548c\u53c2\u6570\u66f4\u65b0 for param in self . encoder . parameters (): param . requires_grad = True else : raise ValueError ( 'cell name should be gru/lstm/bert!' ) if hyper [ 'activation' ] . lower () == 'relu' : self . activation = nn . ReLU () elif hyper [ 'activation' ] . lower () == 'tanh' : self . activation = nn . Tanh () else : raise ValueError ( 'unexpected activation!' ) self . tagger = CRF ( len ( self . bio_vocab ), batch_first = True ) self . selection_u = nn . Linear ( hyper [ 'hidden_size' ] + hyper [ 'bio_emb_size' ], hyper [ 'rel_emb_size' ]) self . selection_v = nn . Linear ( hyper [ 'hidden_size' ] + hyper [ 'bio_emb_size' ], hyper [ 'rel_emb_size' ]) self . selection_uv = nn . Linear ( 2 * hyper [ 'rel_emb_size' ], hyper [ 'rel_emb_size' ]) # \u5b9a\u4e49NER\u4efb\u52a1\u7684\u53d1\u5c04\u77e9\u9635 self . emission = nn . Linear ( hyper [ 'hidden_size' ], len ( self . bio_vocab )) # \u63a8\u7406\u9636\u6bb5\u7684\u51fd\u6570, \u7528\u4e8e\u83b7\u53d6\u591a\u5934\u63d0\u53d6\u51fa\u6765\u7684\u4e09\u5143\u7ec4 def inference ( self , mask , text_list , decoded_tag , selection_logits ): # \u521d\u59cb\u5316MASK\u77e9\u9635 selection_mask = ( mask . unsqueeze ( 2 ) * mask . unsqueeze ( 1 )) . unsqueeze ( 2 ) selection_mask = selection_mask . expand ( - 1 , - 1 , len ( self . relation_vocab ), - 1 ) # selection_mask.shape: torch.Size([4, 200, 50, 200]) # \u5bf9\u591a\u5934\u6a21\u578b\u7684\u8f93\u51fa\u505a\u8fc7\u6ee4 selection_tags = ( torch . sigmoid ( selection_logits ) * selection_mask . float ()) > self . hyper [ 'threshold' ] # \u83b7\u53d6\u591a\u5934\u6a21\u578b\u7684\u7ed3\u679c\u4e09\u5143\u7ec4 selection_triplets = self . selection_decode ( text_list , decoded_tag , selection_tags ) return selection_triplets # \u8ba1\u7b97BCELoss\u503c def masked_BCEloss ( self , mask , selection_logits , selection_gold ): # \u5c06Mask\u77e9\u9635\u8bbe\u7f6e\u4e3a[batch_size, seq_len, relation_size, seq_len]\u7684\u5f62\u72b6 selection_mask = ( mask . unsqueeze ( 2 ) * mask . unsqueeze ( 1 )) . unsqueeze ( 2 ) selection_mask = selection_mask . expand ( - 1 , - 1 , len ( self . relation_vocab ), - 1 ) # \u8ba1\u7b97\u5f97\u51fa\u635f\u5931\u503c selection_loss = F . binary_cross_entropy_with_logits ( selection_logits , selection_gold , reduction = 'none' ) # \u8fdb\u884c\u63a9\u7801\u5f20\u91cf\u7684\u8ba1\u7b97 selection_loss = selection_loss . masked_select ( selection_mask ) . sum () selection_loss /= mask . sum () return selection_loss @staticmethod def description ( epoch , epoch_num , output ): return 'L: {:.2f} , L_crf: {:.2f} , L_selection: {:.2f} , epoch: {} / {} :' . format ( output [ 'loss' ] . item (), output [ 'crf_loss' ] . item (), output [ 'selection_loss' ] . item (), epoch , epoch_num ) def forward ( self , sample , is_train ): device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) # \u5bf9\u5e94\u4e8e\u6587\u672csentence ids tokens = sample . tokens_id . to ( device ) # \u5bf9\u5e94\u4e8e\u5173\u7cfb\u4e09\u5143\u7ec4\u7684ground truth selection_gold = sample . selection_id . to ( device ) # \u5bf9\u5e94\u4e8eNER\u7684ground truth bio_gold = sample . bio_id . to ( device ) # \u539f\u59cb\u6570\u636e\u4e2d\u7684text, spo_list, bio_list text_list = sample . text spo_gold = sample . spo_gold bio_text = sample . bio if self . hyper [ 'cell_name' ] in ( 'gru' , 'lstm' ): # mask: [batch_size, seq_len] mask = tokens != self . word_vocab [ '<pad>' ] bio_mask = mask elif self . hyper [ 'cell_name' ] in ( 'bert' ): notpad = tokens != 0 notcls = tokens != 101 notsep = tokens != 102 mask = notpad & notcls & notsep bio_mask = notpad & notsep else : raise ValueError ( 'unexpected encoder name!' ) if self . hyper [ 'cell_name' ] in ( 'lstm' , 'gru' ): # \u9996\u5148\u8fdb\u884c\u8bcd\u5d4c\u5165\u7684\u64cd\u4f5c embedded = self . word_embeddings ( tokens ) # \u5c06\u540c\u4e00\u4e2abatch\u4e2d\u4e0d\u540c\u957f\u5ea6\u7684\u8bed\u53e5\u8fdb\u884cpack_padded\u64cd\u4f5c, \u63d0\u5347Pytorch\u7684\u8fd0\u7b97\u6548\u7387 pack_padded_embedded = pack_padded_sequence ( embedded , sample . length , batch_first = True ) # \u9001\u5165\u7f16\u7801\u5668, \u5f97\u5230\u8f93\u51fa\u5f20\u91cf\u548c\u9690\u85cf\u5c42\u5f20\u91cf o , h = self . encoder ( pack_padded_embedded ) # \u518d\u5bf9\u5f20\u91cf\u7ed3\u679c\u8fdb\u884cpad_packed\u8fd8\u539f\u64cd\u4f5c o , _ = nn . utils . rnn . pad_packed_sequence ( o , batch_first = True ) # \u76f8\u5f53\u4e8e\u53cc\u5411LSTM\u7684\u4e24\u4e2a\u5f20\u91cf, \u53d6\u5e73\u5747\u503c\u7684\u7ed3\u679c\u4f5c\u4e3a\u6700\u540e\u7684o\u5f20\u91cf o = ( lambda a : sum ( a ) / 2 )( torch . split ( o , self . hyper [ 'hidden_size' ], dim = 2 )) elif self . hyper [ 'cell_name' ] == 'bert' : # 2.\u6a21\u578b\u90e8\u5206 # \u7f16\u7801\u5668\u90e8\u5206\u6539\u4e3abert, mask\u7684\u5904\u7406, last hidden of BERT o = self . encoder ( tokens , attention_mask = mask )[ 0 ] else : raise ValueError ( 'unexpected encoder name!' ) emi = self . emission ( o ) output = {} crf_loss = 0 if is_train : # \u8bad\u7ec3\u9636\u6bb5, \u76f4\u63a5\u5c06\u53d1\u5c04\u5f20\u826femi\u9001\u5165CRF\u4e2d, \u548cNER\u4efb\u52a1\u7684\u6807\u7b7e\u8ba1\u7b97\u635f\u5931 crf_loss = - self . tagger ( emi , bio_gold , mask = bio_mask , reduction = 'mean' ) else : # \u9884\u6d4b\u9636\u6bb5, \u76f4\u63a5\u5c06\u53d1\u5c04\u5f20\u91cfemi\u9001\u5165CRF\u4e2d, \u8fdb\u884cdecode\u89e3\u7801 decoded_tag = self . tagger . decode ( emissions = emi , mask = bio_mask ) # \u5c06\u6570\u5b57\u5316\u89e3\u7801\u7ed3\u679c, \u8f6c\u6362\u6210\u771f\u5b9eBIO\u6807\u7b7e output [ 'decoded_tag' ] = [ list ( map ( lambda x : self . id2bio [ x ], tags )) for tags in decoded_tag ] output [ 'gold_tags' ] = bio_text temp_tag = copy . deepcopy ( decoded_tag ) cur_len = o . size ()[ 1 ] for line in temp_tag : line . extend ([ self . bio_vocab [ 'O' ]] * ( cur_len - len ( line ))) bio_gold = torch . tensor ( temp_tag ) . to ( device ) # \u6309\u7167\u539f\u59cb\u8bba\u6587\u8fdb\u884c\u4f9d\u6b21\u8ba1\u7b97 tag_emb = self . bio_emb ( bio_gold ) o = torch . cat (( o , tag_emb ), dim = 2 ) # multi-head-selection\u7684\u6838\u5fc3\u4ee3\u7801\u6bb5 B , L , H = o . size () # \u4e0b\u9762\u4e09\u884c\u4ee3\u7801\u4f9d\u6b21\u5f97\u5230\u539f\u59cb\u516c\u5f0f\u4e2dU, W, V\u7684\u7ed3\u679c\u5f20\u91cf u = self . activation ( self . selection_u ( o )) . unsqueeze ( 1 ) . expand ( B , L , L , - 1 ) v = self . activation ( self . selection_v ( o )) . unsqueeze ( 2 ) . expand ( B , L , L , - 1 ) uv = self . activation ( self . selection_uv ( torch . cat (( u , v ), dim =- 1 ))) # \u516c\u5f0f\u4e2d\u7684V, \u548c\u5173\u7cfb\u5d4c\u5165\u5f20\u91cf, \u6267\u884c\u7231\u56e0\u65af\u5766\u6c42\u548c selection_logits = torch . einsum ( 'bijh,rh->birj' , uv , self . relation_emb . weight ) # \u63a8\u7406\u9636\u6bb5, \u5f97\u5230\u9884\u6d4b\u7684\u4e09\u5143\u7ec4\u7ed3\u679c if not is_train : output [ 'selection_triplets' ] = self . inference ( mask , text_list , decoded_tag , selection_logits ) output [ 'spo_gold' ] = spo_gold selection_loss = 0 # \u8bad\u7ec3\u9636\u6bb5, \u76f4\u63a5\u8ba1\u7b97\u5e26mask\u6548\u679c\u7684BCELoss, \u8fd9\u4e2aloss\u9488\u5bf9\u4e8e\u4e09\u5143\u7ec4\u62bd\u53d6\u4efb\u52a1 if is_train : selection_loss = self . masked_BCEloss ( mask , selection_logits , selection_gold ) # \u6a21\u578b\u8bad\u7ec3\u7684\u603b\u635f\u5931 = NER\u4efb\u52a1\u7684\u635f\u5931(crf_loss) + \u4e09\u5143\u7ec4\u62bd\u53d6\u4efb\u52a1\u7684\u635f\u5931(selection_loss) loss = crf_loss + selection_loss output [ 'crf_loss' ] = crf_loss output [ 'selection_loss' ] = selection_loss output [ 'loss' ] = loss output [ 'description' ] = partial ( self . description , output = output ) return output # \u4e09\u5143\u7ec4\u62bd\u53d6\u4efb\u52a1\u7684\u89e3\u7801\u51fd\u6570 def selection_decode ( self , text_list , sequence_tags , selection_tags ): reversed_relation_vocab = { v : k for k , v in self . relation_vocab . items ()} reversed_bio_vocab = { v : k for k , v in self . bio_vocab . items ()} text_list = list ( map ( list , text_list )) # len(text_list): 4 # \u4ece\u6587\u672c\u4e2d\u63d0\u53d6\u5b9e\u4f53\u7684\u51fd\u6570 def find_entity ( pos , text , sequence_tags ): entity = [] # print('pos:', pos) # pos: 46 - o # pos: 8 - s # \u5982\u679c\u662fB, O\u76f4\u63a5\u6dfb\u52a0, \u5982\u679c\u662fI, \u5219\u5faa\u73af\u6dfb\u52a0 if sequence_tags [ pos ] in ( 'B' , 'O' ): entity . append ( text [ pos ]) else : temp_entity = [] while sequence_tags [ pos ] == 'I' : temp_entity . append ( text [ pos ]) pos -= 1 if pos < 0 : break if sequence_tags [ pos ] == 'B' : temp_entity . append ( text [ pos ]) break entity = list ( reversed ( temp_entity )) # print('entity:', entity) # entity: ['\u667a', '\u5229', '\u5723', '\u5730', '\u4e9a', '\u54e5'] # entity: ['\u67e5', '\u5c14', '\u65af', '\u00b7', '\u963f', '\u5170', '\u57fa', '\u65af'] return '' . join ( entity ) batch_num = len ( sequence_tags ) # batch_num: 4 result = [[] for _ in range ( batch_num )] # selection_tags.shape: torch.Size([4, 200, 50, 200]) # \u57284\u7ef4\u5f20\u91cf\u4e2d\u63d0\u53d6\u6709\u6548\u6837\u672c\u9884\u6d4b\u503cidx idx = torch . nonzero ( selection_tags . cpu (), as_tuple = False ) for i in range ( idx . size ( 0 )): b , s , p , o = idx [ i ] . tolist () # print('idx[i]:', idx[i].tolist()) predicate = reversed_relation_vocab [ p ] if predicate == 'N' : continue # idx[i]: [0, 8, 3, 46] tags = list ( map ( lambda x : reversed_bio_vocab [ x ], sequence_tags [ b ])) # print('text_list[b]:', text_list[b]) object = find_entity ( o , text_list [ b ], tags ) # print('object:', object) # object: \u667a\u5229\u5723\u5730\u4e9a\u54e5 subject = find_entity ( s , text_list [ b ], tags ) # print('subject:', subject) # subject: \u67e5\u5c14\u65af\u00b7\u963f\u5170\u57fa\u65af assert object != '' and subject != '' # \u7ec4\u88c5\u4e09\u5143\u7ec4\u7ed3\u679c triplet = { 'object' : object , 'predicate' : predicate , 'subject' : subject } result [ b ] . append ( triplet ) return result \u7b2c\u56db\u6b65: \u7f16\u5199\u8bc4\u4f30\u6307\u6807\u51fd\u6570 \u00b6 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/multi_head_selection/metrics/F1_score.py from typing import Dict , List from overrides import overrides class F1_abc ( object ): def __init__ ( self ): self . A = 1e-10 self . B = 1e-10 self . C = 1e-10 def reset ( self ) -> None : self . A = 1e-10 self . B = 1e-10 self . C = 1e-10 def get_metric ( self , reset = False ): if reset : self . reset () f1 , p , r = 2 * self . A / ( self . B + self . C ), self . A / self . B , self . A / self . C result = { \"precision\" : p , \"recall\" : r , \"fscore\" : f1 } return result def __call__ ( self , predictions , gold_labels ): raise NotImplementedError # \u8ba1\u7b97\u4e09\u5143\u7ec4\u7684\u5173\u952e\u6307\u6807\u51fd\u6570 class F1_triplet ( F1_abc ): @overrides def __call__ ( self , predictions , gold_labels ): for g , p in zip ( gold_labels , predictions ): # \u4f9d\u6b21\u904d\u5386\u7ec4\u88c5\u771f\u5b9e\u4e09\u5143\u7ec4\u548c\u9884\u6d4b\u4e09\u5143\u7ec4, \u4ee5'_'\u4e3a\u5206\u9694\u7b26 try : g_set = set ( '_' . join (( gg [ 'object' ], gg [ 'predicate' ], gg [ 'subject' ])) for gg in g ) p_set = set ( '_' . join (( pp [ 'object' ], pp [ 'predicate' ], pp [ 'subject' ])) for pp in p ) except : g_set = set ( '_' . join (( '' . join ( gg [ 'object' ]), gg [ 'predicate' ], '' . join ( gg [ 'subject' ]))) for gg in g ) p_set = set ( '_' . join (( '' . join ( pp [ 'object' ]), pp [ 'predicate' ], '' . join ( pp [ 'subject' ]))) for pp in p ) self . A += len ( g_set & p_set ) self . B += len ( p_set ) self . C += len ( g_set ) # \u8ba1\u7b97NER\u7684\u5173\u952e\u6307\u6807\u51fd\u6570 class F1_ner ( F1_abc ): @overrides def __call__ ( self , predictions , gold_labels ): for g , p in zip ( gold_labels , predictions ): # NER\u4efb\u52a1\u91c7\u7528\u4e25\u683c\u5bf9\u5e94\u7684\u8ba1\u7b97\u65b9\u5f0f inter = sum ( tok_g == tok_p and tok_g in ( 'B' , 'I' ) for tok_g , tok_p in zip ( g , p )) bi_g = sum ( tok_g in ( 'B' , 'I' ) for tok_g in g ) bi_p = sum ( tok_p in ( 'B' , 'I' ) for tok_p in p ) self . A += inter self . B += bi_g self . C += bi_p \u7b2c\u4e94\u6b65: \u7f16\u5199\u8fd0\u884c\u4e3b\u51fd\u6570 \u00b6 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/multi_head_selection/main.py # \u5bfc\u5165\u5de5\u5177\u5305 import os import argparse import torch from tqdm import tqdm from config import read_config from torch.optim import Adam , SGD from preprocessings import DuIE_selection_preprocessing from models import MultiHeadSelection from dataloaders import Selection_Dataset , Selection_loader from prefetch_generator import BackgroundGenerator from metrics import F1_triplet , F1_ner from transformers import AdamW , get_linear_schedule_with_warmup # \u6dfb\u52a0\u547d\u4ee4\u884c\u53c2\u6570 parser = argparse . ArgumentParser () parser . add_argument ( '--exp_name' , '-e' , type = str , default = 'duie_selection_re' , help = 'experiments/duie_selection_re.json' ) parser . add_argument ( '--mode' , '-m' , type = str , default = 'train' , help = 'preprocessing|train|evaluation' ) args = parser . parse_args () # \u6784\u5efa\u8fd0\u884c\u4e3b\u51fd\u6570\u7684\u7c7b class Runner ( object ): def __init__ ( self , exp_name ): self . exp_name = exp_name # \u6a21\u578b\u5b58\u653e\u7684\u8def\u5f84 self . model_dir = './saved_model' # \u914d\u7f6e\u6587\u4ef6\u7684\u4f5c\u7528 self . hyper = read_config ( os . path . join ( 'experiments' , self . exp_name + '.json' )) self . gpu = self . hyper [ 'gpu' ] self . preprocessor = None self . triplet_metrics = F1_triplet () self . ner_metrics = F1_ner () self . optimizer = None self . model = None # \u4f18\u5316\u5668\u7684\u8bbe\u7f6e\u51fd\u6570 def _optimizer ( self , name , model ): no_decay = [ 'bias' , 'LayerNorm.weight' ] optimizer_grouped_parameters = [ { 'params' : [ p for n , p in self . model . named_parameters () if not any ( nd in n for nd in no_decay )], 'weight_decay' : 0.01 }, { 'params' : [ p for n , p in self . model . named_parameters () if any ( nd in n for nd in no_decay )], 'weight_decay' : 0.0 }] m = { # BERT\u4e2d\u7684\u4f18\u5316\u5668AdamW(AdamWeightDecayOptimizer), \u5fae\u8c03BERT\u65f6\u53ef\u4ee5\u52a0\u901f\u6536\u655b 'adam' : Adam ( model . parameters ()), 'sgd' : SGD ( model . parameters (), lr = 0.5 ), 'adamw' : AdamW ( optimizer_grouped_parameters , lr = 2e-5 , eps = 1e-8 ) } return m [ name ] # \u521d\u59cb\u5316\u6a21\u578b\u5e76\u653e\u7f6e\u4e8eGPU\u4e4b\u4e0a def _init_model ( self ): device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) self . model = MultiHeadSelection ( self . hyper ) . to ( device ) # \u9884\u5904\u7406\u51fd\u6570, \u4e0b\u53d1\u7ed9\u540c\u5b66\u4eec\u7684\u6570\u636e\u96c6\u662f\u5df2\u7ecf\u9884\u5904\u7406\u597d\u7684 def preprocessing ( self ): if self . exp_name == 'duie_selection_re' : self . preprocessor = DuIE_selection_preprocessing ( self . hyper ) self . preprocessor . gen_relation_vocab () self . preprocessor . gen_all_data () self . preprocessor . gen_vocab ( min_freq = 1 ) # for ner only self . preprocessor . gen_bio_vocab () # \u6309\u7167\u4e0d\u540c\u7684\u6a21\u5f0f, \u8fd0\u884c\u4e3b\u5165\u53e3\u51fd\u6570 def run ( self , mode ): if mode == 'preprocessing' : self . preprocessing () elif mode == 'train' : self . _init_model () self . optimizer = self . _optimizer ( self . hyper [ 'optimizer' ], self . model ) self . train () elif mode == 'evaluation' : self . _init_model () self . load_model ( epoch = self . hyper [ 'evaluation_epoch' ]) self . evaluation () else : raise ValueError ( 'invalid mode' ) # \u52a0\u8f7d\u5df2\u7ecf\u8bad\u7ec3\u597d\u7684\u6a21\u578b def load_model ( self , epoch ): self . model . load_state_dict ( torch . load ( os . path . join ( self . model_dir , self . exp_name + '_' + str ( epoch )))) # \u4fdd\u5b58\u6a21\u578b def save_model ( self , epoch ): if not os . path . exists ( self . model_dir ): os . mkdir ( self . model_dir ) torch . save ( self . model . state_dict (), os . path . join ( self . model_dir , self . exp_name + '_' + str ( epoch ))) # \u5728\u9a8c\u8bc1\u96c6\u4e0a\u8bc4\u4f30\u6a21\u578b\u7684\u5173\u952e\u6307\u6807 def evaluation ( self ): dev_set = Selection_Dataset ( self . hyper , self . hyper [ 'dev' ]) loader = Selection_loader ( dev_set , batch_size = self . hyper [ 'eval_batch' ], pin_memory = True ) self . triplet_metrics . reset () # \u5c06\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f self . model . eval () with torch . no_grad (): for batch_ndx , sample in enumerate ( BackgroundGenerator ( loader )): # \u6570\u636e\u9001\u5165\u6a21\u578b, \u5f97\u5230\u8f93\u51fa output = self . model ( sample , is_train = False ) # \u5206\u522b\u8fdb\u884c\u4e09\u5143\u7ec4\u7684\u6570\u636e\u5b58\u50a8, \u548cNER\u6570\u636e\u7684\u5b58\u50a8 self . triplet_metrics ( output [ 'selection_triplets' ], output [ 'spo_gold' ]) self . ner_metrics ( output [ 'gold_tags' ], output [ 'decoded_tag' ]) # \u5206\u522b\u8fdb\u884c\u4e09\u5143\u7ec4\u62bd\u53d6\u7684\u4efb\u52a1\u8bc4\u4f30, \u548cNER\u7684\u4efb\u52a1\u8bc4\u4f30 triplet_result = self . triplet_metrics . get_metric () ner_result = self . ner_metrics . get_metric () # \u6253\u5370\u9a8c\u8bc1\u96c6\u7684\u8bc4\u4f30\u7ed3\u679c print ( 'Triplets-> ' + ', ' . join ([ \" %s : %.4f \" % ( name [ 0 ], value ) for name , value in triplet_result . items () if not name . startswith ( \"_\" ) ]) + ' ||' + 'NER->' + ', ' . join ([ \" %s : %.4f \" % ( name [ 0 ], value ) for name , value in ner_result . items () if not name . startswith ( \"_\" )])) # \u8bad\u7ec3\u51fd\u6570\u7684\u4ee3\u7801 def train ( self ): # \u6570\u636e\u96c6\u6784\u5efa\u548c\u8fed\u4ee3\u5668\u7684\u521b\u5efa train_set = Selection_Dataset ( self . hyper , self . hyper [ 'train' ]) loader = Selection_loader ( train_set , batch_size = self . hyper [ 'train_batch' ], pin_memory = True ) # \u7ecf\u5178\u53cc\u91cdfor\u5faa\u73af\u7684\u8bad\u7ec3\u6a21\u5f0f\u5f00\u542f for epoch in range ( self . hyper [ 'epoch_num' ]): self . model . train () # for batch_idx, sample in tqdm(enumerate(loader), total=len(loader)): for batch_idx , sample in enumerate ( loader ): # \"\u8001\u4e09\u6837\"\u548c\u6a21\u578b\u7684\u635f\u5931\u503c\u8ba1\u7b97 self . optimizer . zero_grad () output = self . model ( sample , is_train = True ) loss = output [ 'loss' ] loss . backward () self . optimizer . step () # \u6bcf\u4e00\u8f6eepoch\u540e\u8fdb\u884c\u4e00\u6b21\u6a21\u578b\u7684\u4fdd\u5b58 self . save_model ( epoch ) # \u6bcf\u4e00\u8f6eepoch\u540e\u8fdb\u884c\u4e00\u6b21\u9a8c\u8bc1\u96c6\u6570\u636e\u7684\u8bc4\u4f30 if epoch >= 0 : self . evaluation () # \u4e3b\u51fd\u6570\u5165\u53e3 if __name__ == '__main__' : runner = Runner ( exp_name = args . exp_name ) runner . run ( mode = args . mode ) \u8c03\u7528: python main.py \u8f93\u51fa\u7ed3\u679c: Triplets-> p: 0.7824, r: 0.5375, f: 0.6372 ||NER->p: 0.8912, r: 0.9404, f: 0.9151 Triplets-> p: 0.7593, r: 0.6875, f: 0.7216 ||NER->p: 0.8948, r: 0.9413, f: 0.9175 Triplets-> p: 0.7445, r: 0.7399, f: 0.7422 ||NER->p: 0.8935, r: 0.9449, f: 0.9185 Triplets-> p: 0.7514, r: 0.7592, f: 0.7553 ||NER->p: 0.8932, r: 0.9467, f: 0.9192 Triplets-> p: 0.7325, r: 0.7870, f: 0.7587 ||NER->p: 0.8922, r: 0.9483, f: 0.9194 Triplets-> p: 0.7511, r: 0.7938, f: 0.7719 ||NER->p: 0.8916, r: 0.9494, f: 0.9196 Triplets-> p: 0.7618, r: 0.7950, f: 0.7780 ||NER->p: 0.8922, r: 0.9491, f: 0.9198 Triplets-> p: 0.7422, r: 0.8149, f: 0.7768 ||NER->p: 0.8920, r: 0.9494, f: 0.9198 Triplets-> p: 0.7658, r: 0.8037, f: 0.7843 ||NER->p: 0.8923, r: 0.9491, f: 0.9198 Triplets-> p: 0.7553, r: 0.8103, f: 0.7818 ||NER->p: 0.8921, r: 0.9490, f: 0.9197 \u601d\u8003: \u4e3a\u4ec0\u4e48NER\u4efb\u52a1\u6bd4RE\u4efb\u52a1\u6548\u679c\u66f4\u597d? \u5bf9\u4e8e\u9879\u76ee\u4e2d\u7684\u6570\u636e\u96c6\u6765\u8bf4, \u8fd9\u4e2a\u7ed3\u679c\u7b97\u597d\u7684\u5417?","title":"4.1 multi-head-selection\u6a21\u578b"},{"location":"4_1.html#multi-head-selection","text":"","title":"multi-head-selection\u6a21\u578b"},{"location":"4_1.html#_1","text":"\u7406\u89e3multi-head-selection\u6a21\u578b\u7684\u67b6\u6784. \u638c\u63e1multi-head-selection\u6a21\u578b\u7684\u5b9e\u73b0.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"4_1.html#multi-head-selection_1","text":"\u591a\u5934\u9009\u62e9\u6a21\u578b\u539f\u59cb\u8bba\u6587<< Joint entity recognition and relation extraction as a multi-head selection problem >>. multi-head-selection\u6a21\u578b\u53ef\u4ee5\u5c06NER\u4efb\u52a1\u548cRE\u4efb\u52a1\u5408\u4e8c\u4e3a\u4e00, \u4f5c\u4e3a\u4e00\u4e2a\u6574\u4f53\u6765\u770b\u5f85, \u8fd9\u4e5f\u662f\u591a\u5934\u7684\u610f\u4e49\u6240\u5728, \u6a21\u578b\u603b\u4f53\u67b6\u6784\u56fe\u5982\u4e0b: \u6838\u5fc3: \u6a21\u578b\u9996\u5148\u4f7f\u7528BiLSTM+CRF\u7ed3\u6784\u8bc6\u522b\u5934\u5b9e\u4f53, \u7136\u540e\u518d\u591a\u7c7b\u522b\u5206\u7c7b\u7684\u57fa\u7840\u4e0a, \u4e00\u6b21\u6027\u8fdb\u884c\u5c3e\u5b9e\u4f53\u63d0\u53d6\u548c\u5173\u7cfb\u62bd\u53d6!!! \u5b9e\u4f53-\u5173\u7cfb\u62bd\u53d6\u4efb\u52a1\u65e8\u5728\u8bc6\u522b\u53e5\u5b50\u4e2d\u7684\u5b9e\u4f53\u8de8\u5ea6, \u5e76\u68c0\u6d4b\u4e24\u4e2a\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb. \u4e00\u822c\u6765\u8bf4, \u5b83\u53ef\u4ee5\u5f62\u6210\u4e00\u4e2a\u4e09\u5143\u7ec4(e1, r, e2), \u8868\u793a\u5934\u5b9e\u4f53e1, \u5c3e\u5b9e\u4f53e2\u4e4b\u95f4\u5b58\u5728\u5173\u7cfbr. \u4f20\u7edf\u7684pipeline\u65b9\u6cd5\u4e00\u822c\u5c06\u4efb\u52a1\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5: \u7b2c\u4e00\u9636\u6bb5: \u547d\u540d\u5b9e\u4f53\u8bc6\u522b(NER) \u7b2c\u4e8c\u9636\u6bb5: \u5173\u7cfb\u62bd\u53d6(RE) \u601d\u8003: \u4f20\u7edfpipeline\u65b9\u6cd5\u662f\u5426\u8db3\u591f\u5b8c\u7f8e? \u6709\u4ec0\u4e48\u7f3a\u9677? \u8054\u5408\u6a21\u578b\u7684\u4e24\u79cd\u8303\u5f0f: \u8303\u5f0f\u4e00: (e1, e2) -> r , \u9996\u5148\u8bc6\u522b\u53e5\u5b50\u4e2d\u7684\u6240\u6709\u5b9e\u4f53, \u7136\u540e\u6839\u636e\u6bcf\u4e2a\u5b9e\u4f53\u5bf9\u8fdb\u884c\u5173\u7cfb\u5206\u7c7b. \u8303\u5f0f\u4e8c: e1 -> (r, e2) , \u9996\u5148\u68c0\u6d4b\u5934\u5b9e\u4f53, \u7136\u540e\u9884\u6d4b\u5bf9\u5e94\u7684\u5173\u7cfb\u548c\u5c3e\u5b9e\u4f53. \u601d\u8003: \u8303\u5f0f\u4e00\u548c\u8303\u5f0f\u4e8c\u662f\u5426\u8db3\u591f\u5b8c\u7f8e? \u6709\u4ec0\u4e48\u7f3a\u9677? \u54ea\u4e2a\u66f4\u597d?","title":"multi-head-selection\u6a21\u578b\u67b6\u6784"},{"location":"4_1.html#multi-head-selection_2","text":"\u672c\u9879\u76ee\u4e2d\u7528\u4e8e\u533b\u7597\u573a\u666f\u4e0b\u7684\u6570\u636e\u653e\u57283.2\u548c3.3\u8282\u4e2d\u5e94\u7528, \u672c\u8282\u4e3a\u4e86\u540c\u65f6\u517c\u987eNER\u548cRE\u4efb\u52a1, \u91c7\u7528\u4e86\u66f4\u5927\u4f17\u5316\u7684\u975e\u5782\u76f4\u9886\u57df\u6570\u636e, \u4ee5\u6709\u5229\u4e8e\u540c\u5b66\u4eec\u7684\u5b66\u4e60\u7406\u89e3. \u672c\u9879\u76ee\u7684\u591a\u5934\u9009\u62e9\u6a21\u578b\u5728\u5b9e\u73b0\u4e0a\u5206\u5982\u4e0b\u51e0\u4e2a\u6b65\u9aa4: \u7b2c\u4e00\u6b65: \u67e5\u770b\u6570\u636e\u96c6 \u7b2c\u4e8c\u6b65: \u6784\u5efa\u6570\u636e\u8fed\u4ee3\u5668 \u7b2c\u4e09\u6b65: \u6784\u5efa\u6a21\u578b\u7c7b \u7b2c\u56db\u6b65: \u7f16\u5199\u8bc4\u4f30\u6307\u6807\u51fd\u6570 \u7b2c\u4e94\u6b65: \u7f16\u5199\u8fd0\u884c\u4e3b\u51fd\u6570","title":"multi-head-selection\u6a21\u578b\u5b9e\u73b0"},{"location":"4_1.html#_2","text":"\u6570\u636e\u96c6\u603b\u5171\u67095\u4e2a\u6587\u4ef6: \u8bad\u7ec3\u96c6\u6570\u636etrain_data.json \u9a8c\u8bc1\u96c6\u6570\u636edev_data.json \u8bcd\u5178\u6570\u636eword_vocab.json \u5173\u7cfb\u8bcd\u5178\u6570\u636erelation_vocab.json \u6807\u6ce8\u5b57\u5178\u6570\u636ebio_vocab.json \u8bad\u7ec3\u96c6\u6570\u636e\u8def\u5f84: /home/ec2-user/information_extraction/relation/multi_head_selection/data/train_data.json {\"text\": \"\u5982\u4f55\u6f14\u597d\u81ea\u5df1\u7684\u89d2\u8272\uff0c\u8bf7\u8bfb\u300a\u6f14\u5458\u81ea\u6211\u4fee\u517b\u300b\u300a\u559c\u5267\u4e4b\u738b\u300b\u5468\u661f\u9a70\u5d1b\u8d77\u4e8e\u7a77\u56f0\u6f66\u5012\u4e4b\u4e2d\u7684\u72ec\u95e8\u79d8\u7b08\", \"spo_list\": [{\"predicate\": \"\u4e3b\u6f14\", \"object\": \"\u5468\u661f\u9a70\", \"subject\": \"\u559c\u5267\u4e4b\u738b\"}], \"bio\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"O\", \"B\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"selection\": [{\"subject\": 24, \"predicate\": 46, \"object\": 28}]} {\"text\": \"\u8336\u6811\u8336\u7f51\u877d\uff0cStephanitis chinensis Drake\uff0c\u5c5e\u534a\u7fc5\u76ee\u7f51\u877d\u79d1\u51a0\u7f51\u693f\u5c5e\u7684\u4e00\u79cd\u6606\u866b\", \"spo_list\": [{\"predicate\": \"\u76ee\", \"object\": \"\u534a\u7fc5\u76ee\", \"subject\": \"\u8336\u6811\u8336\u7f51\u877d\"}], \"bio\": [\"B\", \"I\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"selection\": [{\"subject\": 4, \"predicate\": 4, \"object\": 37}]} {\"text\": \"\u7231\u5fb7\u534e\u00b7\u5c3c\u79d1\u00b7\u57c3\u5c14\u5357\u8fea\u65af\uff081986-\uff09\uff0c\u662f\u4e00\u4f4d\u8eab\u9ad8\u53ea\u670970\u516c\u5206\u54e5\u4f26\u6bd4\u4e9a\u7537\u5b50\uff0c\u4f53\u91cd10\u516c\u65a4\uff0c\u53ea\u6bd4\u968f\u8eab\u884c\u674e\u9ad8\u4e00\u4e9b\uff0c2010\u5e74\u83b7\u5409\u5c3c\u65af\u4e16\u754c\u7eaa\u5f55\u6b63\u5f0f\u8ba4\u8bc1\uff0c\u6210\u4e3a\u5168\u7403\u5f53\u4eca\u6700\u77ee\u7684\u6210\u5e74\u7537\u4eba\", \"spo_list\": [{\"predicate\": \"\u8eab\u9ad8\", \"object\": \"70\u516c\u5206\", \"subject\": \"\u7231\u5fb7\u534e\u00b7\u5c3c\u79d1\u00b7\u57c3\u5c14\u5357\u8fea\u65af\"}, {\"predicate\": \"\u51fa\u751f\u65e5\u671f\", \"object\": \"1986\", \"subject\": \"\u7231\u5fb7\u534e\u00b7\u5c3c\u79d1\u00b7\u57c3\u5c14\u5357\u8fea\u65af\"}, {\"predicate\": \"\u56fd\u7c4d\", \"object\": \"\u54e5\u4f26\u6bd4\u4e9a\", \"subject\": \"\u7231\u5fb7\u534e\u00b7\u5c3c\u79d1\u00b7\u57c3\u5c14\u5357\u8fea\u65af\"}], \"bio\": [\"B\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"O\", \"B\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"B\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"selection\": [{\"subject\": 11, \"predicate\": 14, \"object\": 30}, {\"subject\": 11, \"predicate\": 17, \"object\": 16}, {\"subject\": 11, \"predicate\": 21, \"object\": 34}]} {\"text\": \"\u300a\u9010\u98ce\u884c\u300b\u662f\u767e\u5ea6\u6587\u5b66\u65d7\u4e0b\u7eb5\u6a2a\u4e2d\u6587\u7f51\u7b7e\u7ea6\u4f5c\u5bb6\u6e05\u6c34\u79cb\u98ce\u521b\u4f5c\u7684\u4e00\u90e8\u4e1c\u65b9\u7384\u5e7b\u5c0f\u8bf4\uff0c\u5c0f\u8bf4\u5df2\u4e8e2014-04-28\u6b63\u5f0f\u53d1\u5e03\", \"spo_list\": [{\"predicate\": \"\u8fde\u8f7d\u7f51\u7ad9\", \"object\": \"\u7eb5\u6a2a\u4e2d\u6587\u7f51\", \"subject\": \"\u9010\u98ce\u884c\"}, {\"predicate\": \"\u4f5c\u8005\", \"object\": \"\u6e05\u6c34\u79cb\u98ce\", \"subject\": \"\u9010\u98ce\u884c\"}], \"bio\": [\"O\", \"B\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"selection\": [{\"subject\": 3, \"predicate\": 23, \"object\": 16}, {\"subject\": 3, \"predicate\": 42, \"object\": 24}]} {\"text\": \"\u201d\uff08\u56fe\uff09\u5f20\u5b66\u826f\u3001\u8d75\u4e00\u837b\u53cc\u6816\", \"spo_list\": [{\"predicate\": \"\u59bb\u5b50\", \"object\": \"\u8d75\u4e00\u837b\", \"subject\": \"\u5f20\u5b66\u826f\"}, {\"predicate\": \"\u4e08\u592b\", \"object\": \"\u5f20\u5b66\u826f\", \"subject\": \"\u8d75\u4e00\u837b\"}], \"bio\": [\"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"O\", \"B\", \"I\", \"I\", \"O\", \"O\"], \"selection\": [{\"subject\": 6, \"predicate\": 8, \"object\": 10}, {\"subject\": 10, \"predicate\": 24, \"object\": 6}]} \u9a8c\u8bc1\u96c6\u6570\u636e\u8def\u5f84: /home/ec2-user/information_extraction/relation/multi_head_selection/data/dev_data.json {\"text\": \"\u67e5\u5c14\u65af\u00b7\u963f\u5170\u57fa\u65af\uff08Charles Ar\u00e1nguiz\uff09\uff0c1989\u5e744\u670817\u65e5\u51fa\u751f\u4e8e\u667a\u5229\u5723\u5730\u4e9a\u54e5\uff0c\u667a\u5229\u804c\u4e1a\u8db3\u7403\u8fd0\u52a8\u5458\uff0c\u53f8\u804c\u4e2d\u573a\uff0c\u6548\u529b\u4e8e\u5fb7\u56fd\u8db3\u7403\u7532\u7ea7\u8054\u8d5b\u52d2\u6c83\u5e93\u68ee\u8db3\u7403\u4ff1\u4e50\u90e8\", \"spo_list\": [{\"predicate\": \"\u51fa\u751f\u5730\", \"object\": \"\u5723\u5730\u4e9a\u54e5\", \"subject\": \"\u67e5\u5c14\u65af\u00b7\u963f\u5170\u57fa\u65af\"}, {\"predicate\": \"\u51fa\u751f\u65e5\u671f\", \"object\": \"1989\u5e744\u670817\u65e5\", \"subject\": \"\u67e5\u5c14\u65af\u00b7\u963f\u5170\u57fa\u65af\"}], \"bio\": [\"B\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"selection\": [{\"subject\": 7, \"predicate\": 3, \"object\": 45}, {\"subject\": 7, \"predicate\": 17, \"object\": 36}]} {\"text\": \"\u300a\u79bb\u5f00\u300b\u662f\u7531\u5f20\u5b87\u8c31\u66f2\uff0c\u6f14\u5531\", \"spo_list\": [{\"predicate\": \"\u6b4c\u624b\", \"object\": \"\u5f20\u5b87\", \"subject\": \"\u79bb\u5f00\"}, {\"predicate\": \"\u4f5c\u66f2\", \"object\": \"\u5f20\u5b87\", \"subject\": \"\u79bb\u5f00\"}], \"bio\": [\"O\", \"B\", \"I\", \"O\", \"O\", \"O\", \"B\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"selection\": [{\"subject\": 2, \"predicate\": 31, \"object\": 7}, {\"subject\": 2, \"predicate\": 43, \"object\": 7}]} {\"text\": \"\u300a\u6124\u6012\u7684\u5510\u50e7\u300b\u7531\u5317\u4eac\u5434\u610f\u6ce2\u5f71\u89c6\u6587\u5316\u5de5\u4f5c\u5ba4\u4e0e\u4f18\u9177\u7535\u89c6\u5267\u9891\u9053\u8054\u5408\u5236\u4f5c\uff0c\u6545\u4e8b\u4ee5\u559c\u5267\u5143\u7d20\u4e3a\u4e3b\uff0c\u8bb2\u8ff0\u5510\u50e7\u4e0e\u4f5b\u7956\u6253\u724c\uff0c\u5f97\u7f6a\u4e86\u4f5b\u7956\uff0c\u88ab\u8e22\u4e0b\u4eba\u95f4\u518d\u6e21\u4e5d\u4e5d\u516b\u5341\u4e00\u96be\u7684\u6545\u4e8b\", \"spo_list\": [{\"predicate\": \"\u51fa\u54c1\u516c\u53f8\", \"object\": \"\u5317\u4eac\u5434\u610f\u6ce2\u5f71\u89c6\u6587\u5316\u5de5\u4f5c\u5ba4\", \"subject\": \"\u6124\u6012\u7684\u5510\u50e7\"}, {\"predicate\": \"\u5bfc\u6f14\", \"object\": \"\u5434\u610f\u6ce2\", \"subject\": \"\u6124\u6012\u7684\u5510\u50e7\"}], \"bio\": [\"O\", \"B\", \"I\", \"I\", \"I\", \"I\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"selection\": [{\"subject\": 5, \"predicate\": 15, \"object\": 19}, {\"subject\": 5, \"predicate\": 12, \"object\": 12}]} {\"text\": \"\u674e\u6cbb\u5373\u4f4d\u540e\uff0c\u8427\u6dd1\u5983\u53d7\u5ba0\uff0c\u738b\u7687\u540e\u4e3a\u4e86\u6392\u6324\u8427\u6dd1\u5983\uff0c\u7b54\u5e94\u674e\u6cbb\u8ba9\u8eab\u5728\u611f\u4e1a\u5bfa\u7684\u6b66\u5219\u5929\u7eed\u8d77\u5934\u53d1\uff0c\u91cd\u65b0\u7eb3\u5165\u540e\u5bab\", \"spo_list\": [{\"predicate\": \"\u59bb\u5b50\", \"object\": \"\u8427\u6dd1\u5983\", \"subject\": \"\u674e\u6cbb\"}, {\"predicate\": \"\u4e08\u592b\", \"object\": \"\u674e\u6cbb\", \"subject\": \"\u8427\u6dd1\u5983\"}], \"bio\": [\"B\", \"I\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"selection\": [{\"subject\": 1, \"predicate\": 8, \"object\": 8}, {\"subject\": 8, \"predicate\": 24, \"object\": 1}]} \u8bcd\u5178\u6570\u636e\u8def\u5f84: /home/ec2-user/information_extraction/relation/multi_head_selection/data/word_vocab.json {\"<pad>\": 0, \"\u5982\": 1, \"\u4f55\": 2, \"\u6f14\": 3, \"\u597d\": 4, \"\u81ea\": 5, \"\u5df1\": 6, \"\u7684\": 7, \"\u89d2\": 8, \"\u8272\": 9, \"\uff0c\": 10, \"\u8bf7\": 11, \"\u8bfb\": 12, \"\u300a\": 13, \"\u5458\": 14, \"\u6211\": 15, \"\u4fee\": 16, \"\u517b\": 17, \"\u300b\": 18, \"\u559c\": 19, \"\u5267\": 20, \"\u4e4b\": 21, \"\u738b\": 22, \"\u5468\": 23, \"\u661f\": 24, \"\u9a70\": 25, \"\u5d1b\": 26, \"\u8d77\": 27, \"\u4e8e\": 28, \"\u7a77\": 29, \"\u56f0\": 30, \"\u6f66\": 31, \"\u5012\": 32, \"\u4e2d\": 33, \"\u72ec\": 34, \"\u95e8\": 35, \"\u79d8\": 36, \"\u7b08\": 37, \"\u8336\": 38, \"\u6811\": 39, \"\u7f51\": 40, \"\u877d\": 41, \"S\": 42, \"t\": 43, \"e\": 44, \"p\": 45, \"h\": 46, \"a\": 47, \"n\": 48, \"i\": 49, \"s\": 50, \" \": 51, \"c\": 52, \"D\": 53, \"r\": 54, \"k\": 55, \"\u5c5e\": 56, \"\u534a\": 57, \"\u7fc5\": 58, \"\u76ee\": 59, \"\u79d1\": 60, \"\u51a0\": 61, \"\u693f\": 62, \"\u4e00\": 63, \"\u79cd\": 64, \"\u6606\": 65, \"\u866b\": 66, \"\u4e1d\": 67, \"\u8757\": 68, \"O\": 69, \"d\": 70, \"o\": 71, \"\u7eb2\": 72, \"\u76f4\": 73, \"\u603b\": 74, \"\u4e2a\": 75, \"\u7231\": 76, \"\u5fb7\": 77, \"\u534e\": 78, \"\u00b7\": 79, \"\u5c3c\": 80, \"\u57c3\": 81, \"\u5c14\": 82, \"\u5357\": 83, \"\u8fea\": 84, \"\u65af\": 85, \"\uff08\": 86, \"1\": 87, \"9\": 88, \"8\": 89, \"6\": 90, \"-\": 91, \"\uff09\": 92, \"\u662f\": 93, \"\u4f4d\": 94, \"\u8eab\": 95, \"\u9ad8\": 96, \"\u53ea\": 97, \"\u6709\": 98, \"7\": 99, \"0\": 100, \"\u516c\": 101, \"\u5206\": 102, \"\u54e5\": 103, \"\u4f26\": 104, \"\u6bd4\": 105, \"\u4e9a\": 106, \"\u7537\": 107, \"\u5b50\": 108, \"\u4f53\": 109, \"\u91cd\": 110, \"\u65a4\": 111, \"\u968f\": 112, \"\u884c\": 113, \"\u674e\": 114, \"\u4e9b\": 115, \"2\": 116, \"\u5e74\": 117, \"\u83b7\": 118, \"\u5409\": 119, \"\u4e16\": 120, \"\u754c\": 121, \"\u7eaa\": 122, \"\u5f55\": 123, \"\u6b63\": 124, \"\u5f0f\": 125, \"\u8ba4\": 126, \"\u8bc1\": 127, \"\u6210\": 128, \"\u4e3a\": 129, \"\u5168\": 130, \"\u7403\": 131, \"\u5f53\": 132, \"\u4eca\": 133, \"\u6700\": 134, \"\u77ee\": 135, \"\u4eba\": 136, \"\u9010\": 137, \"\u98ce\": 138, \"\u767e\": 139, \"\u5ea6\": 140, \"\u6587\": 141, \"\u5b66\": 142, \"\u65d7\": 143, \"\u4e0b\": 144, \"\u7eb5\": 145, \"\u6a2a\": 146, \"\u7b7e\": 147, \"\u7ea6\": 148, \"\u4f5c\": 149, \"\u5bb6\": 150, \"\u6e05\": 151, \"\u6c34\": 152, \"\u79cb\": 153, \"\u521b\": 154, \"\u90e8\": 155, \"\u4e1c\": 156, \"\u65b9\": 157, \"\u7384\": 158, \"\u5e7b\": 159, \"\u5c0f\": 160, \"\u8bf4\": 161, \"\u5df2\": 162, \"4\": 163, \"\u53d1\": 164, \"\u5e03\": 165, \"\u7985\": 166, \"\u610f\": 167, \"\u6b4c\": 168, \"\u8005\": 169, \"\u5218\": 170, \"\u73c2\": 171, \"\u77e3\": 172, \"\u8896\": 173, \"\u4e91\": 174, \"\u8bc9\": 175, \"\u77e5\": 176, \"\u2026\": 177, \"\u7ef5\": 178, \"\u67d4\": 179, \"\u7eaf\": 180, \"\u51c0\": 181, \"\u5973\": 182, \"\u58f0\": 183, \"\u5c06\": 184, \"\u5fc3\": 185, \"\u4e07\": 186, \"\u5343\": 187, \"\u5c71\": 188, \"\u5c3d\": 189, \"\u52fe\": 190, \"\u52d2\": 191, \"\u8fd9\": 192, \"\u7d20\": 193, \"\u753b\": 194, \"\u97f3\": 195, \"\u8fe6\": 196, \"\u5e15\": 197, \"\u5df4\": 198, \"\u7279\": 199, \"\u5cf0\": 200, ......} \u5173\u7cfb\u8bcd\u5178\u6570\u636e\u8def\u5f84: /home/ec2-user/information_extraction/relation/multi_head_selection/data/relation_vocab.json {\"\u7956\u7c4d\": 0, \"\u7236\u4eb2\": 1, \"\u603b\u90e8\u5730\u70b9\": 2, \"\u51fa\u751f\u5730\": 3, \"\u76ee\": 4, \"\u9762\u79ef\": 5, \"\u7b80\u79f0\": 6, \"\u4e0a\u6620\u65f6\u95f4\": 7, \"\u59bb\u5b50\": 8, \"\u6240\u5c5e\u4e13\u8f91\": 9, \"\u6ce8\u518c\u8d44\u672c\": 10, \"\u9996\u90fd\": 11, \"\u5bfc\u6f14\": 12, \"\u5b57\": 13, \"\u8eab\u9ad8\": 14, \"\u51fa\u54c1\u516c\u53f8\": 15, \"\u4fee\u4e1a\u5e74\u9650\": 16, \"\u51fa\u751f\u65e5\u671f\": 17, \"\u5236\u7247\u4eba\": 18, \"\u6bcd\u4eb2\": 19, \"\u7f16\u5267\": 20, \"\u56fd\u7c4d\": 21, \"\u6d77\u62d4\": 22, \"\u8fde\u8f7d\u7f51\u7ad9\": 23, \"\u4e08\u592b\": 24, \"\u671d\u4ee3\": 25, \"\u6c11\u65cf\": 26, \"\u53f7\": 27, \"\u51fa\u7248\u793e\": 28, \"\u4e3b\u6301\u4eba\": 29, \"\u4e13\u4e1a\u4ee3\u7801\": 30, \"\u6b4c\u624b\": 31, \"\u4f5c\u8bcd\": 32, \"\u4e3b\u89d2\": 33, \"\u8463\u4e8b\u957f\": 34, \"\u6210\u7acb\u65e5\u671f\": 35, \"\u6bd5\u4e1a\u9662\u6821\": 36, \"\u5360\u5730\u9762\u79ef\": 37, \"\u5b98\u65b9\u8bed\u8a00\": 38, \"\u90ae\u653f\u7f16\u7801\": 39, \"\u4eba\u53e3\u6570\u91cf\": 40, \"\u6240\u5728\u57ce\u5e02\": 41, \"\u4f5c\u8005\": 42, \"\u4f5c\u66f2\": 43, \"\u6c14\u5019\": 44, \"\u5609\u5bbe\": 45, \"\u4e3b\u6f14\": 46, \"\u6539\u7f16\u81ea\": 47, \"\u521b\u59cb\u4eba\": 48, \"N\": 49} \u6807\u6ce8\u5b57\u5178\u6570\u636e\u8def\u5f84: /home/ec2-user/information_extraction/relation/multi_head_selection/data/bio_vocab.json {\"B\": 0, \"I\": 1, \"O\": 2}","title":"\u7b2c\u4e00\u6b65: \u67e5\u770b\u6570\u636e\u96c6"},{"location":"4_1.html#_3","text":"\u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/multi_head_selection/dataloaders/selection_loader.py # \u5bfc\u5165\u5de5\u5177\u5305 import os import json import torch from torch.utils.data.dataloader import DataLoader from torch.utils.data import Dataset from torch.nn.utils.rnn import pad_sequence from functools import partial from typing import Dict , List , Tuple , Set , Optional from transformers import BertTokenizer # Dataset\u662f\u4e00\u4e2a\u62bd\u8c61\u7c7b, \u81ea\u5b9a\u4e49\u7684Dataset\u9700\u8981\u7ee7\u627f\u5b83\u5e76\u4e14\u5b9e\u73b0\u4e24\u4e2a\u6210\u5458\u65b9\u6cd5: # __getitem__() \u7b2c\u4e00\u4e2a\u6700\u4e3a\u91cd\u8981, \u5373\u6bcf\u6b21\u600e\u4e48\u8bfb\u6570\u636e # __len__() \u8fd4\u56de\u6574\u4e2a\u6570\u636e\u96c6\u7684\u957f\u5ea6 PAD , CLS , SEP = '[PAD]' , '[CLS]' , '[SEP]' # \u7f16\u5199\u6570\u636e\u96c6\u7684\u7c7b class Selection_Dataset ( Dataset ): def __init__ ( self , hyper , dataset ): self . hyper = hyper self . data_root = hyper [ 'data_root' ] self . bert_model = hyper [ 'bert_model' ] # \u52a0\u8f7d\u8bcd\u5178, \u5173\u7cfb, \u6807\u6ce8\u7684\u6570\u636e self . word_vocab = json . load ( open ( os . path . join ( self . data_root , 'word_vocab.json' ), 'r' )) self . relation_vocab = json . load ( open ( os . path . join ( self . data_root , 'relation_vocab.json' ), 'r' )) self . bio_vocab = json . load ( open ( os . path . join ( self . data_root , 'bio_vocab.json' ), 'r' )) self . selection_list = [] self . text_list = [] self . bio_list = [] self . spo_list = [] # bert\u5206\u8bcd\u5668 self . bert_tokenizer = BertTokenizer . from_pretrained ( self . bert_model ) # \u8bfb\u53d6\u6570\u636e\u96c6, \u5e76\u5c06\u4e0d\u540c\u7684\u5b57\u6bb5\u5206\u522b\u8fdb\u884c\u52a0\u8f7d\u5b58\u50a8 for line in open ( os . path . join ( self . data_root , dataset ), 'r' ): line = line . strip ( ' \\n ' ) instance = json . loads ( line ) self . selection_list . append ( instance [ 'selection' ]) self . text_list . append ( instance [ 'text' ]) self . bio_list . append ( instance [ 'bio' ]) self . spo_list . append ( instance [ 'spo_list' ]) def __getitem__ ( self , index ): selection = self . selection_list [ index ] text = self . text_list [ index ] bio = self . bio_list [ index ] spo = self . spo_list [ index ] if self . hyper [ 'cell_name' ] == 'bert' : # 1.\u6570\u636e\u8f7d\u5165\u90e8\u5206 # \u521d\u59cb\u5316bert\u5206\u8bcd\u5668, \u5bf9\u8f93\u5165\u53e5\u5b50\u9884\u5904\u7406, \u52a0\u4e0a\u7279\u6b8a\u6807\u8bb0\u7b26[cls],[pad],[seq], \u5206\u8bcd text , bio , selection = self . pad_bert ( text , bio , selection ) tokens_id = torch . tensor ( self . bert_tokenizer . convert_tokens_to_ids ( text )) else : tokens_id = self . text2id ( text ) bio_id = self . bio2id ( bio ) # self.relation_vocab \u4f5c\u4e3a\u8fd4\u56de\uff0c\u4ee5\u4fbf\u540e\u9762\u6279\u5904\u7406\u7684\u65f6\u5019\u5c06selection\u53d8\u6210table return tokens_id , bio_id , selection , len ( text ), spo , text , bio , self . relation_vocab def __len__ ( self ): return len ( self . text_list ) # \u5bf9\u6587\u672c\u8fdb\u884cPAD\u8865\u9f50\u7684\u51fd\u6570 def pad_bert ( self , text , bio , selection ): # for [CLS] and [SEP] text = [ '[CLS]' ] + list ( text ) + [ '[SEP]' ] bio = [ 'O' ] + bio + [ 'O' ] selection = [{ 'subject' : triplet [ 'subject' ] + 1 , 'object' : triplet [ 'object' ] + 1 , 'predicate' : triplet [ 'predicate' ]} for triplet in selection ] assert len ( text ) <= self . hyper [ 'max_text_len' ] text = text + [ '[PAD]' ] * ( self . hyper [ 'max_text_len' ] - len ( text )) bio = bio + [ 'O' ] * ( self . hyper [ 'max_text_len' ] - len ( bio )) return text , bio , selection # \u5c06\u8bcd\u8f6c\u6362\u4e3aid\u8868\u793a def text2id ( self , text ): oov = self . word_vocab [ 'oov' ] text_id_list = list ( map ( lambda x : self . word_vocab . get ( x , oov ), text )) return torch . tensor ( text_id_list ) def bio2id ( self , bio ): bio_id_list = list ( map ( lambda x : self . bio_vocab [ x ], bio )) return torch . tensor ( bio_id_list ) # \u6279\u6b21\u6570\u636e\u8bfb\u53d6\u5668, \u672c\u8d28\u4e0a\u662f\u670d\u52a1\u533acollate_fn()\u4e2a\u6027\u5316\u6570\u636e\u8fed\u4ee3\u5668\u7684\u51fd\u6570 class Batch_reader ( object ): def __init__ ( self , data ): data . sort ( key = lambda x : len ( x [ 0 ]), reverse = True ) transposed_data = list ( zip ( * data )) self . length = transposed_data [ 3 ] # tokens_id, bio_id, selection_id, spo, text, bio # word\u5b57\u5178\u4e2dpad\u7684id\u662f0\uff0cpad_sequence\u9ed8\u8ba4padding_value\u662f0\uff0c\u8fd9\u91cc\u53ef\u4ee5\u4e0d\u6307\u5b9a\u4e86 self . tokens_id = pad_sequence ( transposed_data [ 0 ], batch_first = True ) self . bio_id = pad_sequence ( transposed_data [ 1 ], batch_first = True ) batch_max_text_len = self . tokens_id . size ()[ 1 ] relation_vocab = transposed_data [ 7 ][ 0 ] self . selection_id = self . selection2table ( batch_max_text_len , transposed_data [ 2 ], relation_vocab ) self . spo_gold = transposed_data [ 4 ] self . text = transposed_data [ 5 ] self . bio = transposed_data [ 6 ] # GPU\u52a0\u901f\u529f\u80fd\u6a21\u5757 def pin_memory ( self ): self . tokens_id = self . tokens_id . pin_memory () self . bio_id = self . bio_id . pin_memory () self . selection_id = self . selection_id . pin_memory () return self # \u5c06selection\u6570\u636e\u6a21\u5757\u8fdb\u884c\u77e9\u9635\u6620\u5c04 def selection2table ( self , batch_max_text_len , selection , relation_vocab ): # s p o batch_size = len ( selection ) # \u521d\u59cb\u53164\u7ef4\u77e9\u9635, \u540e\u7eed\u7684\u5173\u7cfb\u62bd\u53d6\u90fd\u91c7\u75284\u7ef4\u77e9\u9635 result = torch . zeros ( batch_size , batch_max_text_len , len ( relation_vocab ), batch_max_text_len ) NA = relation_vocab [ 'N' ] # \u5916\u5c42for\u5faa\u73af\u904d\u5386\u6279\u6b21 for b in range ( batch_size ): # \u9ed8\u8ba4NA\u5173\u7cfb\u7b49\u4e8e1 result [ b , :, NA , :] = 1 # \u5185\u5c42for\u5faa\u73af\u904d\u5386\u4e09\u5143\u7ec4 for triplet in selection [ b ]: object = triplet [ 'object' ] subject = triplet [ 'subject' ] predicate = triplet [ 'predicate' ] # \u6709\u6548\u5173\u7cfb\u8bbe\u7f6e\u4e3a1, NA\u5173\u7cfb\u8bbe\u7f6e\u4e3a0 result [ b , subject , predicate , object ] = 1 result [ b , subject , NA , object ] = 0 return result # \u5b9a\u4e49\u4e2a\u6027\u5316\u8bfb\u53d6\u51fd\u6570 def collate_fn ( batch ): return Batch_reader ( batch ) Selection_loader = partial ( DataLoader , collate_fn = collate_fn , pin_memory = True )","title":"\u7b2c\u4e8c\u6b65: \u6784\u5efa\u6570\u636e\u8fed\u4ee3\u5668"},{"location":"4_1.html#_4","text":"\u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/multi_head_selection/models/selection.py import torch import torch.nn as nn import torch.nn.functional as F import json import os import copy from typing import Dict , List , Tuple , Set , Optional from functools import partial from torchcrf import CRF from transformers import BertModel , BertTokenizer from torch.nn.utils.rnn import pack_padded_sequence , pad_packed_sequence # \u591a\u5934\u9009\u62e9\u7684\u6838\u5fc3\u7c7b\u4ee3\u7801 class MultiHeadSelection ( nn . Module ): def __init__ ( self , hyper ): super ( MultiHeadSelection , self ) . __init__ () self . hyper = hyper self . data_root = hyper [ 'data_root' ] self . gpu = hyper [ 'gpu' ] self . bert_model = hyper [ 'bert_model' ] # \u8bfb\u53d6\u539f\u59cb\u6587\u4ef6\u6570\u636e self . word_vocab = json . load ( open ( os . path . join ( self . data_root , 'word_vocab.json' ), 'r' )) self . relation_vocab = json . load ( open ( os . path . join ( self . data_root , 'relation_vocab.json' ), 'r' )) self . bio_vocab = json . load ( open ( os . path . join ( self . data_root , 'bio_vocab.json' ), 'r' )) self . id2bio = { v : k for k , v in self . bio_vocab . items ()} # Word, \u8bcd\u6c47\u5d4c\u5165\u5f20\u91cf self . word_embeddings = nn . Embedding ( num_embeddings = len ( self . word_vocab ), embedding_dim = hyper [ 'emb_size' ]) # Relation, \u5173\u7cfb\u5d4c\u5165\u5f20\u91cf self . relation_emb = nn . Embedding ( num_embeddings = len ( self . relation_vocab ), embedding_dim = hyper [ 'rel_emb_size' ]) # NER, \u547d\u540d\u5b9e\u4f53\u5d4c\u5165\u5f20\u91cf self . bio_emb = nn . Embedding ( num_embeddings = len ( self . bio_vocab ), embedding_dim = hyper [ 'bio_emb_size' ]) # \u7f16\u7801\u5668Encoder\u7684\u4e0d\u540c\u5b9a\u4e49, \u53ef\u4ee5\u91c7\u7528GRU, LSTM, BERT if hyper [ 'cell_name' ] == 'gru' : self . encoder = nn . GRU ( hyper [ 'emb_size' ], hyper [ 'hidden_size' ], bidirectional = True , batch_first = True ) elif hyper [ 'cell_name' ] == 'lstm' : self . encoder = nn . LSTM ( hyper [ 'emb_size' ], hyper [ 'hidden_size' ], bidirectional = True , batch_first = True ) elif hyper [ 'cell_name' ] == 'bert' : # \u5f53\u91c7\u7528BERT\u4f5c\u4e3a\u7f16\u7801\u5668\u65f6, \u76f4\u63a5\u5f15\u5165\u9884\u8bad\u7ec3\u6a21\u578b\u5373\u53ef self . encoder = BertModel . from_pretrained ( self . bert_model ) # \u6b64\u5904\u5373\u4f7f\u4e0d\u6267\u884cfor\u5faa\u73af, \u9ed8\u8ba4\u7684\u6240\u6709encoder\u53c2\u6570\u90fd\u53c2\u4e0e\u53cd\u5411\u4f20\u64ad\u548c\u53c2\u6570\u66f4\u65b0 for param in self . encoder . parameters (): param . requires_grad = True else : raise ValueError ( 'cell name should be gru/lstm/bert!' ) if hyper [ 'activation' ] . lower () == 'relu' : self . activation = nn . ReLU () elif hyper [ 'activation' ] . lower () == 'tanh' : self . activation = nn . Tanh () else : raise ValueError ( 'unexpected activation!' ) self . tagger = CRF ( len ( self . bio_vocab ), batch_first = True ) self . selection_u = nn . Linear ( hyper [ 'hidden_size' ] + hyper [ 'bio_emb_size' ], hyper [ 'rel_emb_size' ]) self . selection_v = nn . Linear ( hyper [ 'hidden_size' ] + hyper [ 'bio_emb_size' ], hyper [ 'rel_emb_size' ]) self . selection_uv = nn . Linear ( 2 * hyper [ 'rel_emb_size' ], hyper [ 'rel_emb_size' ]) # \u5b9a\u4e49NER\u4efb\u52a1\u7684\u53d1\u5c04\u77e9\u9635 self . emission = nn . Linear ( hyper [ 'hidden_size' ], len ( self . bio_vocab )) # \u63a8\u7406\u9636\u6bb5\u7684\u51fd\u6570, \u7528\u4e8e\u83b7\u53d6\u591a\u5934\u63d0\u53d6\u51fa\u6765\u7684\u4e09\u5143\u7ec4 def inference ( self , mask , text_list , decoded_tag , selection_logits ): # \u521d\u59cb\u5316MASK\u77e9\u9635 selection_mask = ( mask . unsqueeze ( 2 ) * mask . unsqueeze ( 1 )) . unsqueeze ( 2 ) selection_mask = selection_mask . expand ( - 1 , - 1 , len ( self . relation_vocab ), - 1 ) # selection_mask.shape: torch.Size([4, 200, 50, 200]) # \u5bf9\u591a\u5934\u6a21\u578b\u7684\u8f93\u51fa\u505a\u8fc7\u6ee4 selection_tags = ( torch . sigmoid ( selection_logits ) * selection_mask . float ()) > self . hyper [ 'threshold' ] # \u83b7\u53d6\u591a\u5934\u6a21\u578b\u7684\u7ed3\u679c\u4e09\u5143\u7ec4 selection_triplets = self . selection_decode ( text_list , decoded_tag , selection_tags ) return selection_triplets # \u8ba1\u7b97BCELoss\u503c def masked_BCEloss ( self , mask , selection_logits , selection_gold ): # \u5c06Mask\u77e9\u9635\u8bbe\u7f6e\u4e3a[batch_size, seq_len, relation_size, seq_len]\u7684\u5f62\u72b6 selection_mask = ( mask . unsqueeze ( 2 ) * mask . unsqueeze ( 1 )) . unsqueeze ( 2 ) selection_mask = selection_mask . expand ( - 1 , - 1 , len ( self . relation_vocab ), - 1 ) # \u8ba1\u7b97\u5f97\u51fa\u635f\u5931\u503c selection_loss = F . binary_cross_entropy_with_logits ( selection_logits , selection_gold , reduction = 'none' ) # \u8fdb\u884c\u63a9\u7801\u5f20\u91cf\u7684\u8ba1\u7b97 selection_loss = selection_loss . masked_select ( selection_mask ) . sum () selection_loss /= mask . sum () return selection_loss @staticmethod def description ( epoch , epoch_num , output ): return 'L: {:.2f} , L_crf: {:.2f} , L_selection: {:.2f} , epoch: {} / {} :' . format ( output [ 'loss' ] . item (), output [ 'crf_loss' ] . item (), output [ 'selection_loss' ] . item (), epoch , epoch_num ) def forward ( self , sample , is_train ): device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) # \u5bf9\u5e94\u4e8e\u6587\u672csentence ids tokens = sample . tokens_id . to ( device ) # \u5bf9\u5e94\u4e8e\u5173\u7cfb\u4e09\u5143\u7ec4\u7684ground truth selection_gold = sample . selection_id . to ( device ) # \u5bf9\u5e94\u4e8eNER\u7684ground truth bio_gold = sample . bio_id . to ( device ) # \u539f\u59cb\u6570\u636e\u4e2d\u7684text, spo_list, bio_list text_list = sample . text spo_gold = sample . spo_gold bio_text = sample . bio if self . hyper [ 'cell_name' ] in ( 'gru' , 'lstm' ): # mask: [batch_size, seq_len] mask = tokens != self . word_vocab [ '<pad>' ] bio_mask = mask elif self . hyper [ 'cell_name' ] in ( 'bert' ): notpad = tokens != 0 notcls = tokens != 101 notsep = tokens != 102 mask = notpad & notcls & notsep bio_mask = notpad & notsep else : raise ValueError ( 'unexpected encoder name!' ) if self . hyper [ 'cell_name' ] in ( 'lstm' , 'gru' ): # \u9996\u5148\u8fdb\u884c\u8bcd\u5d4c\u5165\u7684\u64cd\u4f5c embedded = self . word_embeddings ( tokens ) # \u5c06\u540c\u4e00\u4e2abatch\u4e2d\u4e0d\u540c\u957f\u5ea6\u7684\u8bed\u53e5\u8fdb\u884cpack_padded\u64cd\u4f5c, \u63d0\u5347Pytorch\u7684\u8fd0\u7b97\u6548\u7387 pack_padded_embedded = pack_padded_sequence ( embedded , sample . length , batch_first = True ) # \u9001\u5165\u7f16\u7801\u5668, \u5f97\u5230\u8f93\u51fa\u5f20\u91cf\u548c\u9690\u85cf\u5c42\u5f20\u91cf o , h = self . encoder ( pack_padded_embedded ) # \u518d\u5bf9\u5f20\u91cf\u7ed3\u679c\u8fdb\u884cpad_packed\u8fd8\u539f\u64cd\u4f5c o , _ = nn . utils . rnn . pad_packed_sequence ( o , batch_first = True ) # \u76f8\u5f53\u4e8e\u53cc\u5411LSTM\u7684\u4e24\u4e2a\u5f20\u91cf, \u53d6\u5e73\u5747\u503c\u7684\u7ed3\u679c\u4f5c\u4e3a\u6700\u540e\u7684o\u5f20\u91cf o = ( lambda a : sum ( a ) / 2 )( torch . split ( o , self . hyper [ 'hidden_size' ], dim = 2 )) elif self . hyper [ 'cell_name' ] == 'bert' : # 2.\u6a21\u578b\u90e8\u5206 # \u7f16\u7801\u5668\u90e8\u5206\u6539\u4e3abert, mask\u7684\u5904\u7406, last hidden of BERT o = self . encoder ( tokens , attention_mask = mask )[ 0 ] else : raise ValueError ( 'unexpected encoder name!' ) emi = self . emission ( o ) output = {} crf_loss = 0 if is_train : # \u8bad\u7ec3\u9636\u6bb5, \u76f4\u63a5\u5c06\u53d1\u5c04\u5f20\u826femi\u9001\u5165CRF\u4e2d, \u548cNER\u4efb\u52a1\u7684\u6807\u7b7e\u8ba1\u7b97\u635f\u5931 crf_loss = - self . tagger ( emi , bio_gold , mask = bio_mask , reduction = 'mean' ) else : # \u9884\u6d4b\u9636\u6bb5, \u76f4\u63a5\u5c06\u53d1\u5c04\u5f20\u91cfemi\u9001\u5165CRF\u4e2d, \u8fdb\u884cdecode\u89e3\u7801 decoded_tag = self . tagger . decode ( emissions = emi , mask = bio_mask ) # \u5c06\u6570\u5b57\u5316\u89e3\u7801\u7ed3\u679c, \u8f6c\u6362\u6210\u771f\u5b9eBIO\u6807\u7b7e output [ 'decoded_tag' ] = [ list ( map ( lambda x : self . id2bio [ x ], tags )) for tags in decoded_tag ] output [ 'gold_tags' ] = bio_text temp_tag = copy . deepcopy ( decoded_tag ) cur_len = o . size ()[ 1 ] for line in temp_tag : line . extend ([ self . bio_vocab [ 'O' ]] * ( cur_len - len ( line ))) bio_gold = torch . tensor ( temp_tag ) . to ( device ) # \u6309\u7167\u539f\u59cb\u8bba\u6587\u8fdb\u884c\u4f9d\u6b21\u8ba1\u7b97 tag_emb = self . bio_emb ( bio_gold ) o = torch . cat (( o , tag_emb ), dim = 2 ) # multi-head-selection\u7684\u6838\u5fc3\u4ee3\u7801\u6bb5 B , L , H = o . size () # \u4e0b\u9762\u4e09\u884c\u4ee3\u7801\u4f9d\u6b21\u5f97\u5230\u539f\u59cb\u516c\u5f0f\u4e2dU, W, V\u7684\u7ed3\u679c\u5f20\u91cf u = self . activation ( self . selection_u ( o )) . unsqueeze ( 1 ) . expand ( B , L , L , - 1 ) v = self . activation ( self . selection_v ( o )) . unsqueeze ( 2 ) . expand ( B , L , L , - 1 ) uv = self . activation ( self . selection_uv ( torch . cat (( u , v ), dim =- 1 ))) # \u516c\u5f0f\u4e2d\u7684V, \u548c\u5173\u7cfb\u5d4c\u5165\u5f20\u91cf, \u6267\u884c\u7231\u56e0\u65af\u5766\u6c42\u548c selection_logits = torch . einsum ( 'bijh,rh->birj' , uv , self . relation_emb . weight ) # \u63a8\u7406\u9636\u6bb5, \u5f97\u5230\u9884\u6d4b\u7684\u4e09\u5143\u7ec4\u7ed3\u679c if not is_train : output [ 'selection_triplets' ] = self . inference ( mask , text_list , decoded_tag , selection_logits ) output [ 'spo_gold' ] = spo_gold selection_loss = 0 # \u8bad\u7ec3\u9636\u6bb5, \u76f4\u63a5\u8ba1\u7b97\u5e26mask\u6548\u679c\u7684BCELoss, \u8fd9\u4e2aloss\u9488\u5bf9\u4e8e\u4e09\u5143\u7ec4\u62bd\u53d6\u4efb\u52a1 if is_train : selection_loss = self . masked_BCEloss ( mask , selection_logits , selection_gold ) # \u6a21\u578b\u8bad\u7ec3\u7684\u603b\u635f\u5931 = NER\u4efb\u52a1\u7684\u635f\u5931(crf_loss) + \u4e09\u5143\u7ec4\u62bd\u53d6\u4efb\u52a1\u7684\u635f\u5931(selection_loss) loss = crf_loss + selection_loss output [ 'crf_loss' ] = crf_loss output [ 'selection_loss' ] = selection_loss output [ 'loss' ] = loss output [ 'description' ] = partial ( self . description , output = output ) return output # \u4e09\u5143\u7ec4\u62bd\u53d6\u4efb\u52a1\u7684\u89e3\u7801\u51fd\u6570 def selection_decode ( self , text_list , sequence_tags , selection_tags ): reversed_relation_vocab = { v : k for k , v in self . relation_vocab . items ()} reversed_bio_vocab = { v : k for k , v in self . bio_vocab . items ()} text_list = list ( map ( list , text_list )) # len(text_list): 4 # \u4ece\u6587\u672c\u4e2d\u63d0\u53d6\u5b9e\u4f53\u7684\u51fd\u6570 def find_entity ( pos , text , sequence_tags ): entity = [] # print('pos:', pos) # pos: 46 - o # pos: 8 - s # \u5982\u679c\u662fB, O\u76f4\u63a5\u6dfb\u52a0, \u5982\u679c\u662fI, \u5219\u5faa\u73af\u6dfb\u52a0 if sequence_tags [ pos ] in ( 'B' , 'O' ): entity . append ( text [ pos ]) else : temp_entity = [] while sequence_tags [ pos ] == 'I' : temp_entity . append ( text [ pos ]) pos -= 1 if pos < 0 : break if sequence_tags [ pos ] == 'B' : temp_entity . append ( text [ pos ]) break entity = list ( reversed ( temp_entity )) # print('entity:', entity) # entity: ['\u667a', '\u5229', '\u5723', '\u5730', '\u4e9a', '\u54e5'] # entity: ['\u67e5', '\u5c14', '\u65af', '\u00b7', '\u963f', '\u5170', '\u57fa', '\u65af'] return '' . join ( entity ) batch_num = len ( sequence_tags ) # batch_num: 4 result = [[] for _ in range ( batch_num )] # selection_tags.shape: torch.Size([4, 200, 50, 200]) # \u57284\u7ef4\u5f20\u91cf\u4e2d\u63d0\u53d6\u6709\u6548\u6837\u672c\u9884\u6d4b\u503cidx idx = torch . nonzero ( selection_tags . cpu (), as_tuple = False ) for i in range ( idx . size ( 0 )): b , s , p , o = idx [ i ] . tolist () # print('idx[i]:', idx[i].tolist()) predicate = reversed_relation_vocab [ p ] if predicate == 'N' : continue # idx[i]: [0, 8, 3, 46] tags = list ( map ( lambda x : reversed_bio_vocab [ x ], sequence_tags [ b ])) # print('text_list[b]:', text_list[b]) object = find_entity ( o , text_list [ b ], tags ) # print('object:', object) # object: \u667a\u5229\u5723\u5730\u4e9a\u54e5 subject = find_entity ( s , text_list [ b ], tags ) # print('subject:', subject) # subject: \u67e5\u5c14\u65af\u00b7\u963f\u5170\u57fa\u65af assert object != '' and subject != '' # \u7ec4\u88c5\u4e09\u5143\u7ec4\u7ed3\u679c triplet = { 'object' : object , 'predicate' : predicate , 'subject' : subject } result [ b ] . append ( triplet ) return result","title":"\u7b2c\u4e09\u6b65: \u6784\u5efa\u6a21\u578b\u7c7b"},{"location":"4_1.html#_5","text":"\u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/multi_head_selection/metrics/F1_score.py from typing import Dict , List from overrides import overrides class F1_abc ( object ): def __init__ ( self ): self . A = 1e-10 self . B = 1e-10 self . C = 1e-10 def reset ( self ) -> None : self . A = 1e-10 self . B = 1e-10 self . C = 1e-10 def get_metric ( self , reset = False ): if reset : self . reset () f1 , p , r = 2 * self . A / ( self . B + self . C ), self . A / self . B , self . A / self . C result = { \"precision\" : p , \"recall\" : r , \"fscore\" : f1 } return result def __call__ ( self , predictions , gold_labels ): raise NotImplementedError # \u8ba1\u7b97\u4e09\u5143\u7ec4\u7684\u5173\u952e\u6307\u6807\u51fd\u6570 class F1_triplet ( F1_abc ): @overrides def __call__ ( self , predictions , gold_labels ): for g , p in zip ( gold_labels , predictions ): # \u4f9d\u6b21\u904d\u5386\u7ec4\u88c5\u771f\u5b9e\u4e09\u5143\u7ec4\u548c\u9884\u6d4b\u4e09\u5143\u7ec4, \u4ee5'_'\u4e3a\u5206\u9694\u7b26 try : g_set = set ( '_' . join (( gg [ 'object' ], gg [ 'predicate' ], gg [ 'subject' ])) for gg in g ) p_set = set ( '_' . join (( pp [ 'object' ], pp [ 'predicate' ], pp [ 'subject' ])) for pp in p ) except : g_set = set ( '_' . join (( '' . join ( gg [ 'object' ]), gg [ 'predicate' ], '' . join ( gg [ 'subject' ]))) for gg in g ) p_set = set ( '_' . join (( '' . join ( pp [ 'object' ]), pp [ 'predicate' ], '' . join ( pp [ 'subject' ]))) for pp in p ) self . A += len ( g_set & p_set ) self . B += len ( p_set ) self . C += len ( g_set ) # \u8ba1\u7b97NER\u7684\u5173\u952e\u6307\u6807\u51fd\u6570 class F1_ner ( F1_abc ): @overrides def __call__ ( self , predictions , gold_labels ): for g , p in zip ( gold_labels , predictions ): # NER\u4efb\u52a1\u91c7\u7528\u4e25\u683c\u5bf9\u5e94\u7684\u8ba1\u7b97\u65b9\u5f0f inter = sum ( tok_g == tok_p and tok_g in ( 'B' , 'I' ) for tok_g , tok_p in zip ( g , p )) bi_g = sum ( tok_g in ( 'B' , 'I' ) for tok_g in g ) bi_p = sum ( tok_p in ( 'B' , 'I' ) for tok_p in p ) self . A += inter self . B += bi_g self . C += bi_p","title":"\u7b2c\u56db\u6b65: \u7f16\u5199\u8bc4\u4f30\u6307\u6807\u51fd\u6570"},{"location":"4_1.html#_6","text":"\u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/multi_head_selection/main.py # \u5bfc\u5165\u5de5\u5177\u5305 import os import argparse import torch from tqdm import tqdm from config import read_config from torch.optim import Adam , SGD from preprocessings import DuIE_selection_preprocessing from models import MultiHeadSelection from dataloaders import Selection_Dataset , Selection_loader from prefetch_generator import BackgroundGenerator from metrics import F1_triplet , F1_ner from transformers import AdamW , get_linear_schedule_with_warmup # \u6dfb\u52a0\u547d\u4ee4\u884c\u53c2\u6570 parser = argparse . ArgumentParser () parser . add_argument ( '--exp_name' , '-e' , type = str , default = 'duie_selection_re' , help = 'experiments/duie_selection_re.json' ) parser . add_argument ( '--mode' , '-m' , type = str , default = 'train' , help = 'preprocessing|train|evaluation' ) args = parser . parse_args () # \u6784\u5efa\u8fd0\u884c\u4e3b\u51fd\u6570\u7684\u7c7b class Runner ( object ): def __init__ ( self , exp_name ): self . exp_name = exp_name # \u6a21\u578b\u5b58\u653e\u7684\u8def\u5f84 self . model_dir = './saved_model' # \u914d\u7f6e\u6587\u4ef6\u7684\u4f5c\u7528 self . hyper = read_config ( os . path . join ( 'experiments' , self . exp_name + '.json' )) self . gpu = self . hyper [ 'gpu' ] self . preprocessor = None self . triplet_metrics = F1_triplet () self . ner_metrics = F1_ner () self . optimizer = None self . model = None # \u4f18\u5316\u5668\u7684\u8bbe\u7f6e\u51fd\u6570 def _optimizer ( self , name , model ): no_decay = [ 'bias' , 'LayerNorm.weight' ] optimizer_grouped_parameters = [ { 'params' : [ p for n , p in self . model . named_parameters () if not any ( nd in n for nd in no_decay )], 'weight_decay' : 0.01 }, { 'params' : [ p for n , p in self . model . named_parameters () if any ( nd in n for nd in no_decay )], 'weight_decay' : 0.0 }] m = { # BERT\u4e2d\u7684\u4f18\u5316\u5668AdamW(AdamWeightDecayOptimizer), \u5fae\u8c03BERT\u65f6\u53ef\u4ee5\u52a0\u901f\u6536\u655b 'adam' : Adam ( model . parameters ()), 'sgd' : SGD ( model . parameters (), lr = 0.5 ), 'adamw' : AdamW ( optimizer_grouped_parameters , lr = 2e-5 , eps = 1e-8 ) } return m [ name ] # \u521d\u59cb\u5316\u6a21\u578b\u5e76\u653e\u7f6e\u4e8eGPU\u4e4b\u4e0a def _init_model ( self ): device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) self . model = MultiHeadSelection ( self . hyper ) . to ( device ) # \u9884\u5904\u7406\u51fd\u6570, \u4e0b\u53d1\u7ed9\u540c\u5b66\u4eec\u7684\u6570\u636e\u96c6\u662f\u5df2\u7ecf\u9884\u5904\u7406\u597d\u7684 def preprocessing ( self ): if self . exp_name == 'duie_selection_re' : self . preprocessor = DuIE_selection_preprocessing ( self . hyper ) self . preprocessor . gen_relation_vocab () self . preprocessor . gen_all_data () self . preprocessor . gen_vocab ( min_freq = 1 ) # for ner only self . preprocessor . gen_bio_vocab () # \u6309\u7167\u4e0d\u540c\u7684\u6a21\u5f0f, \u8fd0\u884c\u4e3b\u5165\u53e3\u51fd\u6570 def run ( self , mode ): if mode == 'preprocessing' : self . preprocessing () elif mode == 'train' : self . _init_model () self . optimizer = self . _optimizer ( self . hyper [ 'optimizer' ], self . model ) self . train () elif mode == 'evaluation' : self . _init_model () self . load_model ( epoch = self . hyper [ 'evaluation_epoch' ]) self . evaluation () else : raise ValueError ( 'invalid mode' ) # \u52a0\u8f7d\u5df2\u7ecf\u8bad\u7ec3\u597d\u7684\u6a21\u578b def load_model ( self , epoch ): self . model . load_state_dict ( torch . load ( os . path . join ( self . model_dir , self . exp_name + '_' + str ( epoch )))) # \u4fdd\u5b58\u6a21\u578b def save_model ( self , epoch ): if not os . path . exists ( self . model_dir ): os . mkdir ( self . model_dir ) torch . save ( self . model . state_dict (), os . path . join ( self . model_dir , self . exp_name + '_' + str ( epoch ))) # \u5728\u9a8c\u8bc1\u96c6\u4e0a\u8bc4\u4f30\u6a21\u578b\u7684\u5173\u952e\u6307\u6807 def evaluation ( self ): dev_set = Selection_Dataset ( self . hyper , self . hyper [ 'dev' ]) loader = Selection_loader ( dev_set , batch_size = self . hyper [ 'eval_batch' ], pin_memory = True ) self . triplet_metrics . reset () # \u5c06\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f self . model . eval () with torch . no_grad (): for batch_ndx , sample in enumerate ( BackgroundGenerator ( loader )): # \u6570\u636e\u9001\u5165\u6a21\u578b, \u5f97\u5230\u8f93\u51fa output = self . model ( sample , is_train = False ) # \u5206\u522b\u8fdb\u884c\u4e09\u5143\u7ec4\u7684\u6570\u636e\u5b58\u50a8, \u548cNER\u6570\u636e\u7684\u5b58\u50a8 self . triplet_metrics ( output [ 'selection_triplets' ], output [ 'spo_gold' ]) self . ner_metrics ( output [ 'gold_tags' ], output [ 'decoded_tag' ]) # \u5206\u522b\u8fdb\u884c\u4e09\u5143\u7ec4\u62bd\u53d6\u7684\u4efb\u52a1\u8bc4\u4f30, \u548cNER\u7684\u4efb\u52a1\u8bc4\u4f30 triplet_result = self . triplet_metrics . get_metric () ner_result = self . ner_metrics . get_metric () # \u6253\u5370\u9a8c\u8bc1\u96c6\u7684\u8bc4\u4f30\u7ed3\u679c print ( 'Triplets-> ' + ', ' . join ([ \" %s : %.4f \" % ( name [ 0 ], value ) for name , value in triplet_result . items () if not name . startswith ( \"_\" ) ]) + ' ||' + 'NER->' + ', ' . join ([ \" %s : %.4f \" % ( name [ 0 ], value ) for name , value in ner_result . items () if not name . startswith ( \"_\" )])) # \u8bad\u7ec3\u51fd\u6570\u7684\u4ee3\u7801 def train ( self ): # \u6570\u636e\u96c6\u6784\u5efa\u548c\u8fed\u4ee3\u5668\u7684\u521b\u5efa train_set = Selection_Dataset ( self . hyper , self . hyper [ 'train' ]) loader = Selection_loader ( train_set , batch_size = self . hyper [ 'train_batch' ], pin_memory = True ) # \u7ecf\u5178\u53cc\u91cdfor\u5faa\u73af\u7684\u8bad\u7ec3\u6a21\u5f0f\u5f00\u542f for epoch in range ( self . hyper [ 'epoch_num' ]): self . model . train () # for batch_idx, sample in tqdm(enumerate(loader), total=len(loader)): for batch_idx , sample in enumerate ( loader ): # \"\u8001\u4e09\u6837\"\u548c\u6a21\u578b\u7684\u635f\u5931\u503c\u8ba1\u7b97 self . optimizer . zero_grad () output = self . model ( sample , is_train = True ) loss = output [ 'loss' ] loss . backward () self . optimizer . step () # \u6bcf\u4e00\u8f6eepoch\u540e\u8fdb\u884c\u4e00\u6b21\u6a21\u578b\u7684\u4fdd\u5b58 self . save_model ( epoch ) # \u6bcf\u4e00\u8f6eepoch\u540e\u8fdb\u884c\u4e00\u6b21\u9a8c\u8bc1\u96c6\u6570\u636e\u7684\u8bc4\u4f30 if epoch >= 0 : self . evaluation () # \u4e3b\u51fd\u6570\u5165\u53e3 if __name__ == '__main__' : runner = Runner ( exp_name = args . exp_name ) runner . run ( mode = args . mode ) \u8c03\u7528: python main.py \u8f93\u51fa\u7ed3\u679c: Triplets-> p: 0.7824, r: 0.5375, f: 0.6372 ||NER->p: 0.8912, r: 0.9404, f: 0.9151 Triplets-> p: 0.7593, r: 0.6875, f: 0.7216 ||NER->p: 0.8948, r: 0.9413, f: 0.9175 Triplets-> p: 0.7445, r: 0.7399, f: 0.7422 ||NER->p: 0.8935, r: 0.9449, f: 0.9185 Triplets-> p: 0.7514, r: 0.7592, f: 0.7553 ||NER->p: 0.8932, r: 0.9467, f: 0.9192 Triplets-> p: 0.7325, r: 0.7870, f: 0.7587 ||NER->p: 0.8922, r: 0.9483, f: 0.9194 Triplets-> p: 0.7511, r: 0.7938, f: 0.7719 ||NER->p: 0.8916, r: 0.9494, f: 0.9196 Triplets-> p: 0.7618, r: 0.7950, f: 0.7780 ||NER->p: 0.8922, r: 0.9491, f: 0.9198 Triplets-> p: 0.7422, r: 0.8149, f: 0.7768 ||NER->p: 0.8920, r: 0.9494, f: 0.9198 Triplets-> p: 0.7658, r: 0.8037, f: 0.7843 ||NER->p: 0.8923, r: 0.9491, f: 0.9198 Triplets-> p: 0.7553, r: 0.8103, f: 0.7818 ||NER->p: 0.8921, r: 0.9490, f: 0.9197 \u601d\u8003: \u4e3a\u4ec0\u4e48NER\u4efb\u52a1\u6bd4RE\u4efb\u52a1\u6548\u679c\u66f4\u597d? \u5bf9\u4e8e\u9879\u76ee\u4e2d\u7684\u6570\u636e\u96c6\u6765\u8bf4, \u8fd9\u4e2a\u7ed3\u679c\u7b97\u597d\u7684\u5417?","title":"\u7b2c\u4e94\u6b65: \u7f16\u5199\u8fd0\u884c\u4e3b\u51fd\u6570"},{"location":"4_2.html","text":"Casrel\u6a21\u578b \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u7406\u89e3Casrel\u6a21\u578b\u662f\u5982\u4f55\u4f18\u5316RE\u95ee\u9898\u7684. \u638c\u63e1Casrel\u6a21\u578b\u7684\u67b6\u6784\u548c\u539f\u7406. Casrel\u6a21\u578b\u67b6\u6784 \u00b6 Casrel\u6a21\u578b\u662f\u4e8e2020\u5e74\u63d0\u51fa\u7684\u5173\u7cfb\u62bd\u53d6SOTA\u6a21\u578b, \u539f\u59cb\u8bba\u6587<< A Novel Cascade Binary Tagging Framework for Relational Triple Extraction >>. \u5728RE\u9886\u57df, \u67093\u79cd\u5178\u578b\u7684\u62bd\u53d6\u6a21\u5f0f, \u5982\u4e0b\u56fe\u6240\u793a: Normal\u6a21\u5f0f EPO(Entity Pair Overlap)\u6a21\u5f0f SEO(Single Entity Overlap)\u6a21\u5f0f Casrel\u6a21\u578b\u4e00\u6539\u4e4b\u524d\u7684\u5148NER, \u540eRE\u7684\u4e24\u9636\u6bb5\u6a21\u5f0f, \u91c7\u7528\u4e86\u66f4\u5148\u8fdb\u7684\u4e24\u9636\u6bb5\u6a21\u5f0f: \u5148\u62bd\u53d6\u5934\u5b9e\u4f53 \u518d\u62bd\u53d6\u5173\u7cfb + \u5c3e\u5b9e\u4f53 \u5148\u62bd\u53d6\u5934\u5b9e\u4f53 \u6ce8\u610f: \u4e0a\u9762\u516c\u5f0f\u5de6\u4fa7\u6982\u7387\u503c, \u4ee3\u8868\u8f93\u5165\u5e8f\u5217\u4e2d\u7b2ci\u4e2atoken, \u4f5c\u4e3asubject\u7684\u8d77\u59cb\u4f4d\u7f6e, \u7ed3\u675f\u4f4d\u7f6e\u7684\u6982\u7387! \u518d\u62bd\u53d6\u5173\u7cfb + \u5c3e\u5b9e\u4f53 \u6ce8\u610f: \u4e0a\u9762\u516c\u5f0f\u5de6\u4fa7\u6982\u7387\u503c, \u4ee3\u8868\u8f93\u5165\u5e8f\u5217\u4e2d\u7b2ci\u4e2atoken, \u4f5c\u4e3aobject\u7684\u8d77\u59cb\u4f4d\u7f6e, \u7ed3\u675f\u4f4d\u7f6e\u7684\u6982\u7387! Casrel\u6a21\u578b\u7684\u603b\u4f53\u67b6\u6784\u56fe\u5982\u4e0b: Casrel\u6a21\u578b\u5728\u4e3b\u6d41\u6807\u51c6\u8bc4\u6d4bNYT, \u548cWebNLG\u4e2d\u8fbe\u5230\u4e86SOTA\u7684\u6210\u7ee9: Casrel\u6a21\u578b\u7684\u5b9e\u73b0 \u00b6 Casrel\u6a21\u578b\u7684\u5b9e\u73b0\u53ef\u4ee5\u5206\u5982\u4e0b\u6b65\u9aa4\u5b8c\u6210: \u7b2c\u4e00\u6b65: \u67e5\u770b\u6570\u636e\u96c6 \u7b2c\u4e8c\u6b65: \u5b9e\u73b0\u6570\u636e\u5904\u7406\u548c\u8fed\u4ee3\u5668 \u7b2c\u4e09\u6b65: \u6a21\u578b\u7c7b\u7684\u5b9e\u73b0 \u7b2c\u56db\u6b65: \u8bc4\u4f30\u51fd\u6570\u7684\u5b9e\u73b0 \u7b2c\u4e94\u6b65: \u8bad\u7ec3\u548c\u6d4b\u8bd5\u4ee3\u7801\u7684\u5b9e\u73b0 \u7b2c\u4e00\u6b65: \u67e5\u770b\u6570\u636e\u96c6 \u00b6 \u672c\u9879\u76ee\u4e2d\u4f9d\u7136\u91c7\u7528\u533b\u7597\u9886\u57df\u7684\u5173\u7cfb\u62bd\u53d6\u6570\u636eCMeIE. \u8bad\u7ec3\u96c6\u6570\u636eCMeIE_train.json \u9a8c\u8bc1\u96c6\u6570\u636eCMeIE_dev.json \u6d4b\u8bd5\u96c6\u6570\u636eCMeIE_test.json \u8bad\u7ec3\u96c6\u6570\u636e\u8def\u5f84: /home/ec2-user/information_extraction/relation/casrel/data/CMeIE_train.json {\"text\": \"\u4ea7\u540e\u6291\u90c1\u75c7@\u533a\u5206\u4ea7\u540e\u6291\u90c1\u75c7\u4e0e\u8f7b\u5ea6\u60c5\u7eea\u5931\u8c03\uff08\u4ea7\u540e\u5fe7\u90c1\u6216\u201c\u5a74\u513f\u5fe7\u90c1\u201d\uff09\u662f\u91cd\u8981\u7684\uff0c\u56e0\u4e3a\u8f7b\u5ea6\u60c5\u7eea\u5931\u8c03\u4e0d\u9700\u8981\u6cbb\u7597\u3002\", \"spo_list\": [{\"Combined\": false, \"predicate\": \"\u9274\u522b\u8bca\u65ad\", \"subject\": \"\u4ea7\u540e\u6291\u90c1\u75c7\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u8f7b\u5ea6\u60c5\u7eea\u5931\u8c03\"}, \"object_type\": {\"@value\": \"\u75be\u75c5\"}}]} {\"text\": \"\u7c7b\u98ce\u6e7f\u5173\u8282\u708e@\u5c3a\u4fa7\u504f\u659c\u662f\u7531\u4e8eMCP\u5173\u8282\u708e\u75c7\u9020\u6210\u7684\u3002\", \"spo_list\": [{\"Combined\": false, \"predicate\": \"\u4e34\u5e8a\u8868\u73b0\", \"subject\": \"MCP\u5173\u8282\u708e\u75c7\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u5c3a\u4fa7\u504f\u659c\"}, \"object_type\": {\"@value\": \"\u75c7\u72b6\"}}]} {\"text\": \"\u5507\u816d\u88c2@ ### \u816d\u7618 | \u5b58\u5728\u5dee\u5f02 | \u4f4e \u5927\u7ea6 10% \u81f3 20% \u989a\u6210\u5f62\u672f\u53d1\u751f\u816d\u7618\u3002 \u5507\u816d\u88c2@\u816d\u7618\u53d1\u751f\u673a\u7387\u4e0e\u5a74\u513f\u4f24\u53e3\uff0c\u8425\u517b\u72b6\u51b5\uff0c\u5916\u79d1\u6280\u672f\u548c\u5176\u4ed6\u56e0\u7d20\u76f8\u5173\u3002\", \"spo_list\": [{\"Combined\": true, \"predicate\": \"\u98ce\u9669\u8bc4\u4f30\u56e0\u7d20\", \"subject\": \"\u816d\u7618\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u5a74\u513f\u4f24\u53e3\"}, \"object_type\": {\"@value\": \"\u793e\u4f1a\u5b66\"}}, {\"Combined\": true, \"predicate\": \"\u98ce\u9669\u8bc4\u4f30\u56e0\u7d20\", \"subject\": \"\u816d\u7618\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u8425\u517b\u72b6\u51b5\"}, \"object_type\": {\"@value\": \"\u793e\u4f1a\u5b66\"}}, {\"Combined\": true, \"predicate\": \"\u98ce\u9669\u8bc4\u4f30\u56e0\u7d20\", \"subject\": \"\u816d\u7618\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u5916\u79d1\u6280\u672f\"}, \"object_type\": {\"@value\": \"\u793e\u4f1a\u5b66\"}}]} {\"text\": \"\u6210\u4eba\u54ee\u5598@ \u5e94\u5728\u4f4e\u5242\u91cf ICS \u7684\u57fa\u7840\u4e0a\u52a0\u7528\u4e00\u79cd LABA\uff0c \u6216\u5c06ICS\u589e\u52a0\u5230\u4e2d\u7b49\u5242\u91cf\u3002 \u6210\u4eba\u54ee\u5598@\u7b2c 5 \u7ea7\u5c06\u4e2d\u7b49\u5242\u91cf ICS \u6539\u4e3a\u9ad8\u5242\u91cf ICS\u3002\", \"spo_list\": [{\"Combined\": true, \"predicate\": \"\u836f\u7269\u6cbb\u7597\", \"subject\": \"\u6210\u4eba\u54ee\u5598\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"ICS\"}, \"object_type\": {\"@value\": \"\u836f\u7269\"}}, {\"Combined\": true, \"predicate\": \"\u836f\u7269\u6cbb\u7597\", \"subject\": \"\u54ee\u5598\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u4e2d\u7b49\u5242\u91cf ICS\"}, \"object_type\": {\"@value\": \"\u836f\u7269\"}}]} \u9a8c\u8bc1\u96c6\u6570\u636e\u8def\u5f84: /home/ec2-user/information_extraction/relation/casrel/data/CMeIE_dev.json {\"text\": \"\u6025\u6027\u80f0\u817a\u708e@\u6709\u7814\u7a76\u663e\u793a\uff0c\u8fdb\u884c\u65e9\u671f ERCP \uff0824 \u5c0f\u65f6\u5185\uff09\u53ef\u4ee5\u964d\u4f4e\u6897\u963b\u6027\u80c6\u603b\u7ba1\u7ed3\u77f3\u60a3\u8005\u7684\u5e76\u53d1\u75c7\u53d1\u751f\u7387\u548c\u6b7b\u4ea1\u7387\uff1b \u4f46\u662f\uff0c\u5bf9\u4e8e\u65e0\u80c6\u603b\u7ba1\u6897\u963b\u7684\u80c6\u6c41\u6027\u6025\u6027\u80f0\u817a\u708e\u60a3\u8005\uff0c\u4e0d\u9700\u8981\u8fdb\u884c\u65e9\u671f ERCP\u3002\", \"spo_list\": [{\"Combined\": false, \"predicate\": \"\u5f71\u50cf\u5b66\u68c0\u67e5\", \"subject\": \"\u6025\u6027\u80f0\u817a\u708e\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"ERCP\"}, \"object_type\": {\"@value\": \"\u68c0\u67e5\"}}]} {\"text\": \"\u3010\u8bca\u65ad\u3011 \u6839\u636e\u75be\u75c5\u8bca\u65ad\u548c\u7edf\u8ba1\u624b\u518c\u7b2c4\u7248\u6807\u51c6\uff0c\u7126\u8651\u60c5\u7eea\u6301\u7eed6\u4e2a\u6708\u4ee5\u4e0a\uff0c\u5e76\u81f3\u5c11\u4e0b\u8ff04\u9879\u75c7\u72b6\uff1a 1.\u62c5\u5fe7\u5c06\u6765\u7684\u610f\u5916\u4e8b\u4ef6\uff1b 2.\u62c5\u5fe7\u81ea\u5df1\u7684\u80fd\u529b\uff1b 3.\u62c5\u5fe7\u8fc7\u53bb\u7684\u884c\u4e3a\uff1b 4.\u8eaf\u4f53\u4e0d\u9002\u75c7\u72b6\uff1b 5.\u81ea\u6211\u610f\u8bc6\uff08\u5bf9\u4e3b\u4f53\u7684\u81ea\u6211\u8ba4\u8bc6\uff09\uff1b 6.\u4e0d\u65ad\u9700\u8981\u5f97\u5230\u4ed6\u4eba\u7684\u786e\u8ba4\uff1b 7.\u6301\u7eed\u7d27\u5f20\u548c\uff08\u6216\uff09\u4e0d\u80fd\u653e\u677e\uff1b \u5e7f\u6cdb\u6027\u7126\u8651\u75c7\u5f71\u54cd\u793e\u4f1a\u4ea4\u5f80\uff0c\u4e0e\u5206\u79bb\u6027\u7126\u8651\u75c7\u6bd4\u8f83\uff0c\u66f4\u591a\u4f34\u6709\u5176\u4ed6\u7126\u8651\u75c7\uff0c\u5982\u60ca\u6050\u53d1\u4f5c\u6216\u5355\u7eaf\u6027\u6050\u6016\u75c7\u3002 \uff08\u4e8c\uff09\u793e\u4ea4\u6027\u7126\u8651 \u5c3d\u7ba1\u4e24\u79cd\u75be\u75c5\u5747\u5bb3\u6015\u5728\u516c\u4f17\u573a\u5408\u4e0b\u8bf4\u8bdd\uff0c\u4f46\u5e7f\u6cdb\u6027\u7126\u8651\u4e5f\u5bb3\u6015\u5bf9\u8fc7\u53bb\u548c\u5c06\u6765\u60c5\u5f62\u7684\u7126\u8651\u3002\", \"spo_list\": [{\"Combined\": true, \"predicate\": \"\u9274\u522b\u8bca\u65ad\", \"subject\": \"\u5e7f\u6cdb\u6027\u7126\u8651\u75c7\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u793e\u4ea4\u6027\u7126\u8651\"}, \"object_type\": {\"@value\": \"\u75be\u75c5\"}}, {\"Combined\": true, \"predicate\": \"\u9274\u522b\u8bca\u65ad\", \"subject\": \"\u5e7f\u6cdb\u6027\u7126\u8651\u75c7\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u5206\u79bb\u6027\u7126\u8651\"}, \"object_type\": {\"@value\": \"\u75be\u75c5\"}}]} {\"text\": \"\u9aa8\u6027\u5173\u8282\u708e@\u5728\u5176\u4ed6\u5173\u8282\uff08\u5982\u8e1d\u5173\u8282\u548c\u8155\u5173\u8282\uff09\uff0c\u9aa8\u6027\u5173\u8282\u708e\u6bd4\u8f83\u5c11\u89c1\uff0c\u5e76\u4e14\u4e00\u822c\u6709\u6f5c\u5728\u7684\u75c5\u56e0\uff08\u5982\u7ed3\u6676\u6027\u5173\u8282\u75c5\u3001\u521b\u4f24\uff09\u3002\", \"spo_list\": [{\"Combined\": false, \"predicate\": \"\u53d1\u75c5\u90e8\u4f4d\", \"subject\": \"\u9aa8\u6027\u5173\u8282\u708e\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u5173\u8282\"}, \"object_type\": {\"@value\": \"\u90e8\u4f4d\"}}, {\"Combined\": false, \"predicate\": \"\u53d1\u75c5\u90e8\u4f4d\", \"subject\": \"\u9aa8\u6027\u5173\u8282\u708e\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u8e1d\u5173\u8282\"}, \"object_type\": {\"@value\": \"\u90e8\u4f4d\"}}, {\"Combined\": false, \"predicate\": \"\u53d1\u75c5\u90e8\u4f4d\", \"subject\": \"\u9aa8\u6027\u5173\u8282\u708e\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u8155\u5173\u8282\"}, \"object_type\": {\"@value\": \"\u90e8\u4f4d\"}}, {\"Combined\": false, \"predicate\": \"\u75c5\u56e0\", \"subject\": \"\u9aa8\u6027\u5173\u8282\u708e\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u7ed3\u6676\u6027\u5173\u8282\u75c5\"}, \"object_type\": {\"@value\": \"\u793e\u4f1a\u5b66\"}}, {\"Combined\": false, \"predicate\": \"\u75c5\u56e0\", \"subject\": \"\u9aa8\u6027\u5173\u8282\u708e\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u521b\u4f24\"}, \"object_type\": {\"@value\": \"\u793e\u4f1a\u5b66\"}}]} \u6d4b\u8bd5\u96c6\u6570\u636e\u8def\u5f84: /home/ec2-user/information_extraction/relation/casrel/data/CMeIE_test.json {\"text\": \"\u75d4@\u809b\u955c\u68c0\u67e5\u65b9\u6cd5\u7b80\u4fbf\u5b89\u5168\uff0c\u53ef\u5168\u65b9\u4f4d\u89c2\u5bdf\u809b\u7ba1\u53ca\u6240\u6709\u75d4\u7ec4\u7ec7\u3002\u75d4@\u53e6\u4e00\u79cd\u66ff\u4ee3\u7684\u65b9\u6cd5\u4e3a\u7ea4\u7ef4\u5185\u7aa5\u955c\u53cd\u8f6c\u89c2\u5bdf\uff0c\u6b64\u6cd5\u64cd\u4f5c\u8981\u6c42\u9ad8\uff0c\u9700\u66f4\u9ad8\u7684\u6280\u5de7\u6c34\u5e73\u3002\"} {\"text\": \"\u6162\u6027\u80be\u75c5@\u8fdb\u884c\u773c\u5e95\u68c0\u67e5\u5341\u5206\u5fc5\u8981\uff0c\u56e0\u4e3a\u5176\u6709\u52a9\u4e8e\u8bca\u65ad\u7cd6\u5c3f\u75c5\u6027\u6216\u9ad8\u8840\u538b\u6027\u89c6\u7f51\u819c\u75c5\u53d8\uff0c\u6709\u52a9\u4e8e\u5224\u65ad\u5728\u80be\u810f\u5185\u53ef\u80fd\u53d1\u751f\u7684\u5fae\u8840\u7ba1\u75c5\u53d8\u3002\"} {\"text\": \"5.\u836f\u7269\u56e0\u7d20 \u5f15\u8d77\u6d88\u5316\u6027\u6e83\u75a1\u7684\u836f\u7269\u4e2d\u8f83\u91cd\u8981\u7684\u6709\u4e09\u7c7b\uff1a\u2460\u963f\u53f8\u5339\u6797\uff08ASA\uff09\uff1b\u2461\u975e\u753e\u4f53\u6297\u708e\u836f\u7269\uff08NSAIDs\uff09\uff0c\u5982\u5432\u54da\u7f8e\u8f9b\u53ca\u4fdd\u6cf0\u677e\uff1b\u2462\u80be\u4e0a\u817a\u76ae\u8d28\u6fc0\u7d20\u3002 7.\u7cbe\u795e\u56e0\u7d20 15\u5e74\u524d\uff0c\u5bf9\u80c3\u9020\u7618\u60a3\u8005\u89c2\u5bdf\u53d1\u73b0\uff0c\u4eba\u80c3\u9ecf\u819c\u968f\u4eba\u7684\u60c5\u7eea\u53d8\u5316\u800c\u51fa\u73b0\u4e0d\u540c\u7684\u53cd\u5e94\uff0c\u5174\u594b\u65f6\uff0c\u80c3\u9ecf\u819c\u5145\u8840\uff0c\u80c3\u6db2\u5206\u6ccc\u589e\u591a\uff0c\u80c3\u8fd0\u52a8\u52a0\u5f3a\uff1b\u800c\u6291\u90c1\u548c\u7edd\u671b\u65f6\uff0c\u80c3\u9ecf\u819c\u82cd\u767d\uff0c\u80c3\u8fd0\u52a8\u51cf\u6162\u3002\"} {\"text\": \"\u767b\u9769\u70ed@\u5927\u7ea6 90% \u7684\u767b\u9769\u51fa\u8840\u70ed (dengue haemorrhagic fever, DHF) \u75c5\u4f8b\u4e3a 5 \u5c81\u4ee5\u4e0b\u513f\u7ae5\u3002\u767b\u9769\u70ed@ \u5178\u578b\u7684\u767b\u9769\u70ed\u66f4\u5e38\u89c1\u4e8e\u6210\u4eba\uff0c\u800c\u975e\u513f\u7ae5\u3002\"} {\"text\": \"\u3010\u75c5\u56e0\u3011 \u7f3a\u6c27\u662fHIE\u53d1\u75c5\u7684\u6838\u5fc3,\u5176\u4e2d\u56f4\u751f\u671f\u7a92\u606f\u662f\u6700\u4e3b\u8981\u7684\u75c5\u56e0\u3002 \u3010\u53d1\u75c5\u673a\u5236\u3011 \u8111\u8840\u6d41\u6539\u53d8 \u5f53\u7f3a\u6c27\u7f3a\u8840\u4e3a\u90e8\u5206\u6216\u6162\u6027\u65f6,\u4f53\u5185\u8840\u6db2\u51fa\u73b0\u91cd\u65b0\u5206\u914d\uff0c\u4ee5\u4fdd\u8bc1\u5fc3\u3001\u8111\u7b49\u91cd\u8981\u5668\u5b98\u8840\u6db2\u4f9b\u5e94,\u800c\u80ba\u3001\u80be\u3001\u80c3\u80a0\u9053\u7b49\u76f8\u5bf9\u6b21\u91cd\u8981\u5668\u5b98\u53d7\u635f\u3002\"} {\"text\": \"\u9ad8\u8840\u538b\u6025\u75c7\u7684\u6cbb\u7597\uff0c\u539f\u5219\u662f\u5c06\u8840\u538b\u964d\u81f3\u5b89\u5168\u6c34\u5e73\u800c\u975e\u8fc5\u901f\u964d\u81f3\u6b63\u5e38\uff0c\u4fdd\u8bc1\u7ec4\u7ec7\u5668\u5b98\u7684\u704c\u6ce8\uff0c\u9632\u6b62\u5668\u5b98\u635f\u5bb3\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002 4.\u67f3\u80fa\u82c4\u5fc3\u5b9a\uff08labetalol\uff09 \u517c\u6709\u03b1\u548c\u03b2\u53d7\u4f53\u963b\u6ede\u4f5c\u7528\uff0c\u6bcf\u6b210. 25\uff5e1. 0mg/kg\uff08\u6bcf\u6b21\u6700\u591a20mg\uff09\u9759\u8109\u6ce8\u5c04\uff0c\u4f5c\u7528\u6301\u7eed\u8fbe4\u5c0f\u65f6\uff0c\u9700\u8981\u65f6\u6bcf10\u5206\u949f\u540e\u91cd\u590d1\u6b21\uff1b\u6301\u7eed\u9759\u8109\u6ef4\u6ce8\u5242\u91cf\u4e3a\u6bcf\u5c0f\u65f60. 4\uff5e1. 0mg/kg\uff0c\u6700\u9ad8\u53ef\u8fbe\u6bcf\u5c0f\u65f63mg/kg\u3002\"} {\"text\": \"\u5fc3\u623f\u6251\u52a8@ \u5fc3\u7535\u56fe\u5177\u6709\u8bca\u65ad\u610f\u4e49\uff1a * \u5178\u578b\u7684\u5f62\u5f0f\uff08\u9006\u65f6\u9488\u5fc3\u623f\u6251\u52a8\uff09\uff1a\u2161\u3001\u2162\u3001aVF \u5bfc\u8054\u53ef\u89c1\u8d1f\u5411\u952f\u9f7f\u72b6\u5fc3\u623f\u6ce2\uff08F \u6ce2\uff09\uff0c\u5728 V1 \u5bfc\u8054\u6b63\u5411\u5fc3\u623f\u6251\u52a8\u6ce2\uff0c\u5fc3\u623f\u7387\u4e3a 240-320 \u6b21/\u5206\u3002\u5fc3\u623f\u6251\u52a8@\u5f53\u6000\u7591\u6025\u6027\u5fc3\u808c\u6897\u6b7b\u65f6\uff0c\u5e94\u67e5\u5fc3\u808c\u9176\u8c31\uff0c\u82e5\u60a3\u8005\u6b63\u5728\u5e94\u7528\u6d0b\u5730\u9ec4\u7c7b\u836f\u7269\uff08\u4f8b\u5982\u5730\u9ad8\u8f9b\uff09\uff0c\u5e94\u68c0\u6d4b\u6d0b\u5730\u9ec4\u7c7b\u836f\u7269\u7684\u8840\u836f\u6d53\u5ea6\u3002\"} {\"text\": \"\u5e15\u91d1\u68ee\u75c5@ * \u52a0\u5165\u5f53\u5730\u652f\u6301\u56e2\u961f\u53ef\u80fd\u4f1a\u6709\u6240\u5e2e\u52a9\u3002\"} \u5173\u7cfb\u6620\u5c04\u8868\u6570\u636e\u8def\u5f84: /home/ec2-user/information_extraction/relation/casrel/data/relation2idx.json {\"\u9884\u9632\": 0, \"\u9636\u6bb5\": 1, \"\u5c31\u8bca\u79d1\u5ba4\": 2, \"\u540c\u4e49\u8bcd-\u5176\u4ed6\": 3, \"\u8f85\u52a9\u6cbb\u7597\": 4, \"\u5316\u7597\": 5, \"\u653e\u5c04\u6cbb\u7597\": 6, \"\u540c\u4e49\u8bcd-\u5176\u4ed6\u6cbb\u7597\": 7, \"\u624b\u672f\u6cbb\u7597\": 8, \"\u540c\u4e49\u8bcd-\u624b\u672f\u6cbb\u7597\": 9, \"\u5b9e\u9a8c\u5ba4\u68c0\u67e5\": 10, \"\u5f71\u50cf\u5b66\u68c0\u67e5\": 11, \"\u8f85\u52a9\u68c0\u67e5\": 12, \"\u7ec4\u7ec7\u5b66\u68c0\u67e5\": 13, \"\u540c\u4e49\u8bcd-\u68c0\u67e5\": 14, \"\u5185\u7aa5\u955c\u68c0\u67e5\": 15, \"\u7b5b\u67e5\": 16, \"\u591a\u53d1\u7fa4\u4f53\": 17, \"\u53d1\u75c5\u7387\": 18, \"\u53d1\u75c5\u5e74\u9f84\": 19, \"\u591a\u53d1\u5730\u533a\": 20, \"\u53d1\u75c5\u6027\u522b\u503e\u5411\": 21, \"\u6b7b\u4ea1\u7387\": 22, \"\u591a\u53d1\u5b63\u8282\": 23, \"\u4f20\u64ad\u9014\u5f84\": 24, \"\u540c\u4e49\u8bcd-\u6d41\u884c\u75c5\u5b66\": 25, \"\u540c\u4e49\u8bcd-\u75be\u75c5\": 26, \"\u5e76\u53d1\u75c7\": 27, \"\u75c5\u7406\u5206\u578b\": 28, \"\u76f8\u5173\uff08\u5bfc\u81f4\uff09\": 29, \"\u9274\u522b\u8bca\u65ad\": 30, \"\u76f8\u5173\uff08\u8f6c\u5316\uff09\": 31, \"\u76f8\u5173\uff08\u75c7\u72b6\uff09\": 32, \"\u4e34\u5e8a\u8868\u73b0\": 33, \"\u6cbb\u7597\u540e\u75c7\u72b6\": 34, \"\u4fb5\u53ca\u5468\u56f4\u7ec4\u7ec7\u8f6c\u79fb\u7684\u75c7\u72b6\": 35, \"\u540c\u4e49\u8bcd-\u75c7\u72b6\": 36, \"\u75c5\u56e0\": 37, \"\u9ad8\u5371\u56e0\u7d20\": 38, \"\u98ce\u9669\u8bc4\u4f30\u56e0\u7d20\": 39, \"\u75c5\u53f2\": 40, \"\u9057\u4f20\u56e0\u7d20\": 41, \"\u540c\u4e49\u8bcd-\u793e\u4f1a\u5b66\": 42, \"\u53d1\u75c5\u673a\u5236\": 43, \"\u75c5\u7406\u751f\u7406\": 44, \"\u836f\u7269\u6cbb\u7597\": 45, \"\u540c\u4e49\u8bcd-\u836f\u7269\": 46, \"\u53d1\u75c5\u90e8\u4f4d\": 47, \"\u8f6c\u79fb\u90e8\u4f4d\": 48, \"\u5916\u4fb5\u90e8\u4f4d\": 49, \"\u540c\u4e49\u8bcd-\u90e8\u4f4d\": 50, \"\u9884\u540e\u72b6\u51b5\": 51, \"\u9884\u540e\u751f\u5b58\u7387\": 52} \u7b2c\u4e8c\u6b65: \u5b9e\u73b0\u6570\u636e\u5904\u7406\u548c\u8fed\u4ee3\u5668 \u00b6 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/casrel/dataloader.py import json import re import torch from torch.utils.data import Dataset , DataLoader from torch.nn.utils.rnn import pad_sequence , pack_padded_sequence from transformers import BertTokenizer from random import choice import codecs device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) # \u6784\u9020\u6570\u636e\u96c6\u7684\u7c7b\u4ee3\u7801 class MyDataset ( Dataset ): # \u8bfb\u53d6\u8bad\u7ec3\u96c6\u6570\u636e def __get_train_data ( self , path ): with open ( path , 'r' , encoding = 'utf-8' ) as f : data = f . readlines () res = [ json . loads ( i ) for i in data ] return res # \u8bfb\u53d6\u9a8c\u8bc1\u96c6\u6570\u636e def __get_dev_data ( self , path ): with open ( path , 'r' , encoding = 'utf-8' ) as f : data = f . readlines () res = [ json . loads ( i ) for i in data ] return res # \u8bfb\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e def __get_test_data ( self , path ): with open ( path , 'r' , encoding = 'utf-8' ) as f : data = f . readlines () data = [ json . loads ( i ) for i in data ] res = [] for entry in data : entry [ 'spo_list' ] = [] res . append ( entry ) return res def __init__ ( self , path , config ): super ( MyDataset , self ) . __init__ () self . config = config if self . config [ 'mode' ] == 'train' : self . data = self . __get_train_data ( path ) elif self . config [ 'mode' ] == 'test' : self . data = self . __get_test_data ( path ) elif self . config [ 'mode' ] == 'dev' : self . data = self . __get_dev_data ( path ) # \u8bfb\u53d6\u5173\u7cfb\u6620\u5c04\u8868, \u5e76\u6784\u9020\u5173\u7cfb-id\u6620\u5c04\u5b57\u5178 with open ( 'data/relation2idx.json' , 'r' , encoding = 'utf-8' ) as f : self . relation2idx = json . load ( f ) self . idx2relation = dict () for key in self . relation2idx : self . idx2relation [ self . relation2idx [ key ]] = key # \u8bbe\u7f6e\u57fa\u7840\u9884\u8bad\u7ec3\u6a21\u578b bert_path = '/home/ec2-user/code/re/casrel/bert_pretrain/' self . tokenizer = BertTokenizer . from_pretrained ( bert_path ) def __len__ ( self ): return len ( self . data ) # \u6309\u7167\u7d22\u5f15\u6807\u7b7e\u83b7\u53d6\u6570\u636e\u7684\u91cd\u5199\u51fd\u6570 def __getitem__ ( self , item ): text , gold = self . data [ item ][ 'text' ], self . data [ item ][ 'spo_list' ] text = text if len ( text ) <= 512 else text [: 512 ] # \u5b8c\u6210token_to_id\u7684\u6620\u5c04 sample = list ( text ) sample = self . tokenizer . convert_tokens_to_ids ( sample ) # \u8bbe\u7f6eSubject\u548crelation\u7684\u8d77\u59cb, \u7ed3\u675f\u6807\u7b7e\u4f4d\u7f6e\u5f20\u91cf sub_start = len ( sample ) * [ 0 ] sub_end = len ( sample ) * [ 0 ] relation_start = [[ 0 for _ in range ( self . config [ 'relation_types' ])] for _ in range ( len ( sample ))] relation_end = [[ 0 for _ in range ( self . config [ 'relation_types' ])] for _ in range ( len ( sample ))] # dim = (seq_len, relation_types) sub_start_single = len ( sample ) * [ 0 ] sub_end_single = len ( sample ) * [ 0 ] s2ro_map = {} # \u89e3\u6790\u6570\u636e\u6587\u4ef6\u4e2d\u7684\u5177\u4f53\u503c for entry in gold : sub = entry [ 'subject' ] obj = entry [ 'object' ][ '@value' ] relation = '\u540c\u4e49\u8bcd-' + entry [ 'subject_type' ] if entry [ 'predicate' ] == '\u540c\u4e49\u8bcd' else entry [ 'predicate' ] # \u6b63\u5219\u8868\u8fbe\u5f0f\u65e0\u6cd5\u5904\u7406\u5c0f\u62ec\u53f7, \u6240\u4ee5\u629b\u51fa\u5f02\u5e38 try : sub_pos = re . search ( sub , text ) . span () obj_pos = re . search ( obj , text ) . span () relation_idx = self . relation2idx [ relation ] sub_start [ sub_pos [ 0 ]] = 1 sub_end [ sub_pos [ 1 ] - 1 ] = 1 if sub_pos not in s2ro_map : s2ro_map [ sub_pos ] = [] s2ro_map [ sub_pos ] . append (( obj_pos , relation_idx )) except : pass # \u5982\u679c\u80fd\u89e3\u6790\u51fa\u6709\u6548\u6570\u636e, \u5219\u586b\u5145\u5bf9\u5e94\u7684\u5f20\u91cf if s2ro_map : sub_pos = choice ( list ( s2ro_map . keys ())) sub_start_single [ sub_pos [ 0 ]] = 1 sub_end_single [ sub_pos [ 1 ] - 1 ] = 1 for obj_pos , relation_idx in s2ro_map . get ( sub_pos , []): relation_start [ obj_pos [ 0 ]][ relation_idx ] = 1 relation_end [ obj_pos [ 1 ] - 1 ][ relation_idx ] = 1 # print('****************************') # print('sample:', sample) # print('sub_start:', sub_start) # print(len(sub_start)) # print('sub_end:', sub_end) # print(len(sub_end)) # print('relation_start:', relation_start) # print('relation_end:', relation_end) # print('sub_start_single:', sub_start_single) # print('sub_end_single:', sub_end_single) # print(len(sub_start_single)) # print(len(sub_end_single)) return sample , sub_start , sub_end , relation_start , relation_end , sub_start_single , sub_end_single # \u6570\u636e\u7684\"\u4e2a\u6027\u5316\"\u5904\u7406\u51fd\u6570 def collate_fn ( data ): data . sort ( key = lambda x : len ( x [ 0 ]), reverse = True ) sample , sub_start , sub_end , relation_start , relation_end , sub_start_single , sub_end_single = zip ( * data ) # \u5bf9\u6240\u6709\u6570\u636e\u4f9d\u6b21\u8fdb\u884c\u6620\u5c04, \u5c01\u88c5, \u8f6c\u79fb\u5230GPU\u7b49 mask = [[ 1 if j < len ( i ) else 0 for j in range ( len ( sample [ 0 ]))] for i in sample ] sample = [ torch . tensor ( i ) . long () . to ( device ) for i in sample ] sub_start = [ torch . tensor ( i ) . long () . to ( device ) for i in sub_start ] sub_end = [ torch . tensor ( i ) . long () . to ( device ) for i in sub_end ] relation_start = [ torch . tensor ( i ) . long () . to ( device ) for i in relation_start ] relation_end = [ torch . tensor ( i ) . long () . to ( device ) for i in relation_end ] sub_start_single = [ torch . tensor ( i ) . long () . to ( device ) for i in sub_start_single ] sub_end_single = [ torch . tensor ( i ) . long () . to ( device ) for i in sub_end_single ] # \u5bf9\u6240\u6709\u6570\u636e\u4f9d\u6b21\u8fdb\u884cpad\u8865\u9f50\u64cd\u4f5c mask = torch . tensor ( mask ) . long () . to ( device ) sample = pad_sequence ( sample , batch_first = True , padding_value = 0 ) sub_start = pad_sequence ( sub_start , batch_first = True , padding_value = 0 ) sub_end = pad_sequence ( sub_end , batch_first = True , padding_value = 0 ) relation_start = pad_sequence ( relation_start , batch_first = True , padding_value = 0 ) relation_end = pad_sequence ( relation_end , batch_first = True , padding_value = 0 ) sub_start_single = pad_sequence ( sub_start_single , batch_first = True , padding_value = 0 ) sub_end_single = pad_sequence ( sub_end_single , batch_first = True , padding_value = 0 ) return sample , sub_start , sub_end , relation_start , relation_end , mask , sub_start_single , sub_end_single if __name__ == \"__main__\" : path = './data/CMeIE_train.json' config = { \"mode\" : \"train\" , \"relation_types\" : 53 } data = MyDataset ( path , config ) dataloader = DataLoader ( data , batch_size = 4 , shuffle = False , collate_fn = collate_fn ) batch_data = next ( iter ( dataloader )) file = codecs . open ( 'debug.txt' , 'w' , encoding = 'utf-8' ) test_idx = 30 a , b = batch_data [ 3 ][ test_idx ], batch_data [ 4 ][ test_idx ] for i in batch_data : file . write ( str ( i [ test_idx ]) + ' \\n ' ) for i in range ( a . shape [ 0 ]): file . write ( str ( i ) + str ( b [ i ]) + ' \\n ' ) \u7b2c\u4e09\u6b65: \u6a21\u578b\u7c7b\u7684\u5b9e\u73b0 \u00b6 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/casrel/casrel.py import torch import torch as t from torch import nn from transformers import BertModel , BertTokenizer , BertConfig import numpy as np device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) # Casrel\u6838\u5fc3\u7c7b\u4ee3\u7801 class CasRel ( nn . Module ): def __init__ ( self , config ): super ( CasRel , self ) . __init__ () self . config = config self . bert_dim = 768 # \u9884\u8bad\u7ec3\u6a21\u578b\u7684\u52a0\u8f7d model_name = 'bert-base-chinese' self . bert_path = \"/home/ec2-user/code/re/casrel/bert_pretrain\" self . bert_config = BertConfig . from_pretrained ( self . bert_path + '/bert_config.json' ) self . bert_encoder = BertModel . from_pretrained ( self . bert_path , config = self . bert_config ) # \u4f9d\u6b21\u521d\u59cb\u53164\u4e2a\u91cd\u8981\u7d22\u5f15 self . sub_start_tagger = nn . Linear ( self . bert_dim , 1 ) self . sub_end_tagger = nn . Linear ( self . bert_dim , 1 ) self . obj_start_tagger = nn . Linear ( self . bert_dim , config [ 'relation_types' ]) self . obj_end_tagger = nn . Linear ( self . bert_dim , config [ 'relation_types' ]) # \u83b7\u53d6BERT\u7684\u8f93\u51fa\u7f16\u7801\u5f20\u91cf def get_encoded_text ( self , data ): encoded_text = self . bert_encoder ( data [ 'token_ids' ], attention_mask = data [ 'mask' ])[ 0 ] # (batch_size, seq_len, bert_dim) return encoded_text # \u83b7\u53d6Subject\u7684\u9884\u6d4b\u5f20\u91cf def get_sub ( self , encoded_text ): # dim(pred) = (batch_size, seq_len, 1) # \u83b7\u53d6\u8d77\u59cb\u6307\u9488 pred_sub_start = self . sub_start_tagger ( encoded_text ) pred_sub_start = torch . sigmoid ( pred_sub_start ) # \u83b7\u53d6\u7ed3\u675f\u6307\u9488 pred_sub_end = self . sub_end_tagger ( encoded_text ) pred_sub_end = torch . sigmoid ( pred_sub_end ) return pred_sub_start , pred_sub_end # \u83b7\u53d6Object\u7684\u9884\u6d4b\u5f20\u91cf def get_obj ( self , sub_start_mapping , sub_end_mapping , encoded_text ): # dim(sub_start_mapping) = dim(sub_end_mapping) = (batch_size, 1, seq_len) # dim(encoded_text) = (batch_size, seq_len, bert_dim) # \u6309\u7167\u8bba\u6587\u4e2d\u7684\u516c\u5f0f\u53d8\u4f53, \u9996\u5148\u5bf9Xi, \u548cstart_mapping\u8fdb\u884c\u77e9\u9635\u4e58\u6cd5, \u5f97\u5230start\u5f20\u91cf; end\u540c\u7406 sub_start = torch . matmul ( sub_start_mapping . float (), encoded_text ) sub_end = torch . matmul ( sub_end_mapping . float (), encoded_text ) # dim(sub_start) = dim(sub_end) = (batch_size, 1, bert_dim) # \u6309\u7167\u8bba\u6587\u4e2d\u7684\u516c\u5f0f\u8ba1\u7b97 sub = ( sub_start + sub_end ) / 2 encoded_text = encoded_text + sub # \u6309\u7167\u8bba\u6587\u4e2d\u7684\u516c\u5f0f, \u8fdb\u884cW_start(r)\u7684\u77e9\u9635\u8fd0\u7b97; W_end(r)\u540c\u7406 pred_obj_start = self . obj_start_tagger ( encoded_text ) pred_obj_end = self . obj_end_tagger ( encoded_text ) pred_obj_start = torch . sigmoid ( pred_obj_start ) pred_obj_end = torch . sigmoid ( pred_obj_end ) # \u6700\u7ec8\u8fd4\u56deobject\u7684\u9996\u5c3e\u6307\u9488 return pred_obj_start , pred_obj_end def get_list ( self , start , end , text , h_bar = 0.5 , t_bar = 0.5 ): # \u521d\u59cb\u5316\u8bc6\u522b\u51fa\u6765\u7684entities\u7684\u7ed3\u679c\u5217\u8868res res = [] # \u8fdb\u884c\u5217\u8868\u957f\u5ea6\u7684\u622a\u65ad start , end = start [: 512 ], end [: 512 ] start_idxs , end_idxs = [], [] # \u521d\u59cb\u5316\u5217\u8868\u503c for idx in range ( len ( start )): if ( start [ idx ] > h_bar ): start_idxs . append ( idx ) if ( end [ idx ] > t_bar ): end_idxs . append ( idx ) # \u904d\u5386\u8d77\u59cb\u548c\u7ed3\u675f\u4f4d\u7f6e, \u5c06\u8bc6\u522b\u51fa\u6765\u7684\u5b9e\u4f53\u6dfb\u52a0\u8fdb\u7ed3\u679c\u5217\u8868 for start_idx in start_idxs : for end_idx in end_idxs : if ( end_idx >= start_idx ): # \u5c06\u8bc6\u522b\u51fa\u7684entity\u7684\u91cd\u8981\u4fe1\u606f\u4ee5\u5b57\u5178\u5f62\u5f0f\u6dfb\u52a0\u8fdb\u7ed3\u679c\u5217\u8868res entry = {} entry [ 'text' ] = text [ start_idx : end_idx + 1 ] entry [ 'start' ] = start_idx entry [ 'end' ] = end_idx res . append ( entry ) break return res # Casrel\u6a21\u578b\u7684\u524d\u5411\u8ba1\u7b97\u51fd\u6570 def forward ( self , data ): # 1: \u7b2c\u4e00\u6b65\u5c06\u539f\u59cb\u6587\u672c\u9001\u5165\u7f16\u7801\u5668BERT\u4e2d encoded_text = self . get_encoded_text ( data ) # 2: \u7b2c\u4e8c\u6b65\u8fdb\u884cSubject\u7684\u9996\u5c3e\u6307\u9488\u9884\u6d4b pred_sub_start , pred_sub_end = self . get_sub ( encoded_text ) # 3: \u5c06\u771f\u5b9e\u6570\u636e\u4e2d\u7684start, end\u6807\u7b7e\u63d0\u53d6\u51fa\u6765 sub_start_mapping = data [ 'sub_start' ] . unsqueeze ( 1 ) sub_end_mapping = data [ 'sub_end' ] . unsqueeze ( 1 ) # 4: \u8c03\u7528\u7c7b\u5185\u51fd\u6570, \u5c06\u6a21\u578b\u9884\u6d4b\u7684object\u7684start, end\u6307\u9488\u63d0\u53d6\u51fa\u6765 pred_obj_start , pred_obj_end = self . get_obj ( sub_start_mapping , sub_end_mapping , encoded_text ) return pred_sub_start , pred_sub_end , pred_obj_start , pred_obj_end # \u63a8\u7406\u9636\u6bb5\u7684\u51fd\u6570(Inference) def test ( self , data ): # \u5c06\u539f\u59cb\u6587\u672c\u6570\u636e\u9001\u5165BERT\u7f16\u7801\u5668\u4e2d encoded_text = self . get_encoded_text ( data ) # \u63d0\u53d6Subject\u7684\u9996\u5c3e\u6307\u9488 pred_sub_start , pred_sub_end = self . get_sub ( encoded_text ) # \u83b7\u53d6\u7ed3\u679c\u5217\u8868 sub_list = self . get_list ( pred_sub_start . squeeze ( 0 ) . squeeze ( - 1 ), pred_sub_end . squeeze ( 0 ) . squeeze ( - 1 ), data [ 'text' ]) if ( sub_list ): # \u521d\u59cb\u5316\u82e5\u5e72\u91cd\u8981\u5f20\u91cf repeated_encoded_text = encoded_text . repeat ( len ( sub_list ), 1 , 1 ) sub_start_mapping = torch . zeros ( len ( sub_list ), 1 , encoded_text . shape [ 1 ]) . to ( device ) sub_end_mapping = torch . zeros ( len ( sub_list ), 1 , encoded_text . shape [ 1 ]) . to ( device ) for idx , sub in enumerate ( sub_list ): sub_start_mapping [ idx ][ 0 ][ sub [ 'start' ]] = 1 sub_end_mapping [ idx ][ 0 ][ sub [ 'end' ]] = 1 # \u6309\u7167Subject, \u6a21\u578b\u63d0\u53d6\u51faObject pred_obj_start , pred_obj_end = self . get_obj ( sub_start_mapping , sub_end_mapping , repeated_encoded_text ) return sub_list , pred_obj_start , pred_obj_end # \u5982\u679c\u6ca1\u6709Subject, \u76f4\u63a5\u8fd4\u56deNone else : return None \u7b2c\u56db\u6b65: \u8bc4\u4f30\u51fd\u6570\u7684\u5b9e\u73b0 \u00b6 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/casrel/evaluate.py import json import codecs # \u8bc4\u4f30\u51fd\u6570 def evaluate (): # \u8bfb\u53d6\u8bc4\u4f30\u6570\u636e, \u5305\u62ec\u9884\u6d4b\u7ed3\u679c\u548c\u771f\u5b9e\u6807\u7b7e pred_path = './data/CMeIE_dev_result.json' # prediction gold_path = \"./data/CMeIE_dev.json\" # golden state res_path = './data/eval_dev.json' pred_file = codecs . open ( pred_path , 'r' , encoding = 'utf-8' ) gold_file = codecs . open ( gold_path , 'r' , encoding = 'utf-8' ) # \u6bcf\u4e2aepoch\u4f1a\u8c03\u7528\u4e00\u6b21\u8bc4\u4f30\u51fd\u6570, \u4f46\u53ea\u4fdd\u5b58\u6548\u679c\u6700\u597d\u7684\u6a21\u578b\u8bc4\u6d4b\u6570\u636e res_file = codecs . open ( res_path , 'w' , encoding = 'utf-8' ) # \u8bfb\u53d6\u6587\u4ef6\u4fe1\u606f\u5e76\u5b58\u5165\u5217\u8868\u683c\u5f0f pred_data = pred_file . readlines () pred_data = [ json . loads ( i ) for i in pred_data ] # \u8bfb\u53d6\u6587\u4ef6\u4fe1\u606f\u5e76\u5b58\u5165\u5217\u8868\u683c\u5f0f gold_data = gold_file . readlines () gold_data = [ json . loads ( i ) for i in gold_data ] # \u5c06\u9884\u6d4b\u503c\u548c\u771f\u5b9e\u503c\u505a\u914d\u5bf9 data = zip ( pred_data , gold_data ) correct_num = 0 pred_num = 0 gold_num = 0 # \u904d\u5386\u6570\u636e\u505a\u6b63\u8d1f\u6837\u672c\u7684\u8ba1\u6570 for pred , gold in data : # \u9884\u6d4b\u503c\u7684\u8bfb\u53d6\u548c\u96c6\u5408\u53bb\u91cd pred_spo = [( i [ 'predicate' ], i [ 'subject' ], i [ 'subject_type' ], i [ 'object' ][ '@value' ], i [ 'object_type' ][ '@value' ]) for i in pred [ 'spo_list' ]] pred_spo = set ( pred_spo ) # \u771f\u5b9e\u503c\u7684\u8bfb\u53d6\u548c\u96c6\u5408\u53bb\u91cd gold_spo = [( i [ 'predicate' ], i [ 'subject' ], i [ 'subject_type' ], i [ 'object' ][ '@value' ], i [ 'object_type' ][ '@value' ]) for i in gold [ 'spo_list' ]] gold_spo = set ( gold_spo ) # \u505a\u4ea4\u96c6\u5f97\u51fa\u9884\u6d4b\u6b63\u786e\u7684\u6570\u91cf correct_num += len ( pred_spo & gold_spo ) pred_num += len ( pred_spo ) gold_num += len ( gold_spo ) # \u4ee5\u5b57\u5178\u683c\u5f0f\u5b58\u50a8\u8bc4\u4f30\u7ed3\u679c\u5e76\u5b58\u5165\u6587\u4ef6 entry = {} entry [ 'text' ] = pred [ 'text' ] entry [ 'gold' ] = list ( gold_spo ) entry [ 'pred' ] = list ( pred_spo ) entry [ 'new' ] = list ( pred_spo - gold_spo ) entry [ 'lack' ] = list ( gold_spo - pred_spo ) json . dump ( entry , res_file , ensure_ascii = False , indent = 4 , separators = ( ',' , ':' )) # \u6309\u7167\u516c\u5f0f\u8ba1\u7b97presition, recall, f1\u7684\u503c eps = 1e-6 p = correct_num / ( pred_num + eps ) r = correct_num / ( gold_num + eps ) f1 = ( 2 * p * r ) / ( p + r + eps ) print ( 'f1: {} , precision: {} , recall: {} ' . format ( f1 , p , r )) return f1 , p , r if __name__ == '__main__' : f1 , p , r = evaluate () print ( 'f1: {} , precision: {} , recall: {} ' . format ( f1 , p , r )) \u7b2c\u4e94\u6b65: \u8bad\u7ec3\u548c\u6d4b\u8bd5\u4ee3\u7801\u7684\u5b9e\u73b0 \u00b6 \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/casrel/train.py # \u5bfc\u5165\u5de5\u5177\u5305 import time from tqdm import tqdm import torch import torch.nn.functional as F from casrel import CasRel from torch.utils.data import DataLoader from dataloader import MyDataset , collate_fn from test import test_casrel from evaluate import evaluate # \u8bbe\u5b9a\u8bad\u7ec3\u8bbe\u5907(GPU, CPU) device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) torch . set_num_threads ( 6 ) # \u635f\u5931\u8ba1\u7b97\u51fd\u6570, \u5f53\u524d\u6a21\u578b\u91c7\u7528\u4e8c\u5206\u4ea4\u53c9\u71b5\u635f\u5931 def get_loss ( pred , gold , mask ): pred = pred . squeeze ( - 1 ) # \u6309\u7167\u4e8c\u5206\u4ea4\u53c9\u71b5\u635f\u5931\u8ba1\u7b97, \u5e76\u4ee5\u5411\u91cf\u5f62\u5f0f\u8fd4\u56deloss loss = F . binary_cross_entropy ( pred , gold . float (), reduction = 'none' ) # \u5c06mask\u5f20\u91cf\u7684\u7ef4\u5ea6\u6269\u5c55\u6210\u548closs\u4e00\u81f4 if loss . shape != mask . shape : mask = mask . unsqueeze ( - 1 ) # \u5bf9\u635f\u5931\u5f20\u91cf\u8fdb\u884c\u63a9\u7801\u8ba1\u7b97, \u5e76\u5f52\u4e00\u5316 loss = torch . sum ( loss * mask ) / torch . sum ( mask ) return loss if __name__ == '__main__' : config = { 'mode' : 'train' , 'batch_size' : 16 , 'epoch' : 50 , 'relation_types' : 53 , 'sub_weight' : 1 , 'obj_weight' : 1 } model_save_path = './saved_model/model_casrel.pt' f_dev_result = open ( './data/dev_result.txt' , 'a' , encoding = 'utf-8' ) best_f1_file = open ( './data/best_f1.txt' , 'a' , encoding = 'utf-8' ) # \u5b9e\u4f8b\u5316\u6570\u636e\u96c6\u5bf9\u8c61, \u5e76\u6784\u5efa\u8bad\u7ec3\u6570\u636e\u7684\u8fed\u4ee3\u5668 path_train = './data/CMeIE_train.json' data_train = MyDataset ( path_train , config ) dataloader_train = DataLoader ( data_train , batch_size = config [ 'batch_size' ], shuffle = True , collate_fn = collate_fn ) # \u5b9e\u4f8b\u5316Casrel\u6a21\u578b\u7c7b\u5bf9\u8c61 model = CasRel ( config ) . to ( device ) # \u5b9e\u4f8b\u5316\u4f18\u5316\u5668\u5bf9\u8c61 optimizer = torch . optim . Adam ( model . parameters (), lr = 1e-5 , betas = ( 0.9 , 0.999 )) best_f1 = 0.0 # \u7ecf\u5178\u53cc\u91cdfor\u5faa\u73af\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3 for epoch_index in range ( config [ 'epoch' ]): time_start = time . time () print ( \"epoch: %d ......\" % ( epoch_index )) for batch_index , ( sample , sub_start , sub_end , relation_start , relation_end , mask , sub_start_single , sub_end_single ) in tqdm ( enumerate ( dataloader_train )): batch_data = dict () batch_data [ 'token_ids' ] = sample batch_data [ 'mask' ] = mask batch_data [ 'sub_start' ] = sub_start_single batch_data [ 'sub_end' ] = sub_end_single # \u7ecf\u5178\"\u8001\u4e09\u6837\" optimizer . zero_grad () # \u6a21\u578b\u4f1a\u8fd4\u56de4\u4e2a\u91cd\u8981\u6307\u9488\u53d8\u91cf pred_sub_start , pred_sub_end , pred_obj_start , pred_obj_end = model ( batch_data ) # \u5bf94\u4e2a\u9884\u6d4b\u6307\u9488\u5206\u522b\u8ba1\u7b97\u4e8c\u5206\u4ea4\u53c9\u71b5\u635f\u5931 sub_start_loss = get_loss ( pred_sub_start , sub_start , mask ) sub_end_loss = get_loss ( pred_sub_end , sub_end , mask ) obj_start_loss = get_loss ( pred_obj_start , relation_start , mask ) obj_end_loss = get_loss ( pred_obj_end , relation_end , mask ) # subject\u7684\u635f\u5931\u653e\u5728\u4e00\u8d77\u8ba1\u7b97, object\u7684\u635f\u5931\u653e\u5728\u4e00\u8d77\u8ba1\u7b97, \u5206\u522b\u91c7\u7528\u4e0d\u540c\u7684\u6743\u91cd loss = config [ 'sub_weight' ] * ( sub_start_loss + sub_end_loss ) + config [ 'obj_weight' ] * ( obj_start_loss + obj_end_loss ) loss . backward () optimizer . step () if batch_index % 50 == 0 : print ( \"epoch: %d batch: %d loss: %f \" % ( epoch_index , batch_index , loss )) time_end = time . time () print ( \"successfully saved! time used = %f s.\" % ( time_end - time_start )) # \u6bcf\u4e00\u8f6eepoch\u8bad\u7ec3\u7ed3\u675f\u540e, \u8fdb\u884c\u4e00\u6b21\u9a8c\u8bc1\u96c6\u7684\u6548\u679c\u8bc4\u4f30 dev_file_path = './data/CMeIE_dev.json' res_path = './data/CMeIE_dev_result.json' config_dev = { 'mode' : 'dev' , 'batch_size' : 1 , 'relation_types' : 53 } print ( 'epoch: {} , \u5f00\u59cb\u9a8c\u8bc1\u96c6\u8bc4\u4f30...' . format ( epoch_index )) test_casrel ( model , dev_file_path , res_path , config_dev ) # \u9884\u6d4b\u7ed3\u675f\u540e, \u9700\u8981\u5728\u9a8c\u8bc1\u7ed3\u679c\u6570\u636e\u4e0a\u8fdb\u884c\u8bc4\u4f30 f1 , p , r = evaluate () temp_res = 'f1: {} , precision: {} , recall: {} ' . format ( f1 , p , r ) f_dev_result . write ( temp_res + ' \\n ' ) print ( 'epoch: {} , \u9a8c\u8bc1\u96c6\u8bc4\u4f30\u7ed3\u675f... \\n ' . format ( epoch_index )) print ( 'f1: {} , precision: {} , recall: {} ' . format ( f1 , p , r )) print ( ' \\n ' ) # \u5c06\u66f4\u4f18\u7684\u7ed3\u679c\u5199\u65e5\u5fd7\u4fdd\u5b58, \u5e76\u5c06\u66f4\u4f18\u7684\u6a21\u578b\u4fdd\u5b58 if f1 > best_f1 : best_f1 = f1 best_p = p best_r = r best_res = 'f1: {} , precision: {} , recall: {} ' . format ( best_f1 , best_p , best_r ) best_f1_file . write ( best_res + ' \\n ' ) torch . save ( model . state_dict (), model_save_path ) \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/casrel/test.py import codecs import torch import torch.nn.functional as F from casrel import CasRel from torch.utils.data import DataLoader from dataloader import MyDataset , collate_fn import json import numpy as np device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) torch . set_num_threads ( 6 ) def trans_schemas ( path ): rel2sub = dict () rel2obj = dict () with open ( path , 'r' , encoding = 'utf-8' ) as f : sens = f . readlines () schemas = [] for sen in sens : schemas . append ( json . loads ( sen . strip ())) for entry in schemas : rel2sub [ entry [ 'predicate' ]] = entry [ 'subject_type' ] rel2obj [ entry [ 'predicate' ]] = entry [ 'object_type' ] return rel2sub , rel2obj def get_list ( start , end , text , h_bar = 0.5 , t_bar = 0.5 ): res = [] start , end = start [: 512 ], end [: 512 ] start_idxs , end_idxs = [], [] for idx in range ( len ( start )): if ( start [ idx ] > h_bar ): start_idxs . append ( idx ) if ( end [ idx ] > t_bar ): end_idxs . append ( idx ) for start_idx in start_idxs : for end_idx in end_idxs : if ( end_idx >= start_idx ): entry = {} entry [ 'text' ] = text [ start_idx : end_idx + 1 ] entry [ 'start' ] = start_idx entry [ 'end' ] = end_idx res . append ( entry ) break return res def get_text ( path ): with open ( path , 'r' , encoding = 'utf-8' ) as f : data = f . readlines () data = [ json . loads ( i ) for i in data ] return data def test_casrel ( model , path , res_path , config ): # \u8bbe\u7f6e\u6570\u636e\u96c6\u8def\u5f84 schemas_path = './data/53_schemas.json' res_file = codecs . open ( res_path , 'w' , encoding = 'utf-8' ) # \u8bfb\u53d6\u6d4b\u8bd5\u6587\u4ef6, \u5e76\u8bfb\u53d6schema\u6587\u4ef6\u5f97\u5230(\u5173\u7cfb-\u5b9e\u4f53)\u6620\u5c04\u5b57\u5178 raw_data = get_text ( path ) rel2sub , rel2obj = trans_schemas ( schemas_path ) # \u6784\u5efa\u6570\u636e\u8fed\u4ee3\u5668DataLoader data = MyDataset ( path , config ) dataloader = DataLoader ( data , batch_size = config [ 'batch_size' ], shuffle = False , collate_fn = collate_fn ) # \u5b9e\u4f8b\u5316CasRel\u7c7b\u5bf9\u8c61\u5e76\u52a0\u8f7d\u5df2\u8bad\u7ec3\u597d\u7684\u6a21\u578b # model = CasRel(config).to(device) # model.load_state_dict(torch.load('model_casrel.pt')) # \u5faa\u73af\u5904\u7406\u6d4b\u8bd5\u96c6\u6570\u636e, \u5e76\u5c06\u7ed3\u679c\u5199\u5165\u6587\u4ef6 # \u904d\u5386\u6d4b\u8bd5\u6570\u636e for batch_index , ( sample , sub_start , sub_end , relation_start , relation_end , mask , _ , _ ) in enumerate ( iter ( dataloader )): with torch . no_grad (): text = raw_data [ batch_index ][ 'text' ] batch_data = dict () batch_data [ 'token_ids' ] = sample batch_data [ 'mask' ] = mask batch_data [ 'text' ] = text ret = model . test ( batch_data ) spo_list = [] if ret : sub_list , pred_obj_start , pred_obj_end = ret # \u904d\u5386\u6a21\u578b\u9884\u6d4b\u7684subject\u5b9e\u4f53 for idx , sub in enumerate ( sub_list ): obj_start = pred_obj_start [ idx ] . transpose ( 0 , 1 ) obj_end = pred_obj_end [ idx ] . transpose ( 0 , 1 ) # \u904d\u538653\u79cd\u5173\u7cfb, \u5e76\u4f9d\u6b21\u7ec4\u5408\u6210\u7ed3\u679c\u5b57\u5178 for i in range ( config [ 'relation_types' ]): obj_list = get_list ( obj_start [ i ], obj_end [ i ], text ) # \u904d\u5386\u7b2ci\u79cd\u5173\u7cfb\u7684object\u5217\u8868 for obj in obj_list : entry = {} entry [ 'Combined' ] = '\u3002' in text [ sub [ 'end' ]: obj [ 'start' ]] or '\u3002' in text [ obj [ 'end' ]: sub [ 'start' ]] # \u4ee5\u4e0b5\u4e2a\u5b57\u5178\u5fc5\u987b\u6309\u7167\u56fa\u5b9a\u683c\u5f0f\u5199\u5165\u5b57\u5178 entry [ 'subject' ] = sub [ 'text' ] entry [ 'predicate' ] = data . idx2relation [ i ] entry [ 'object' ] = { '@value' : obj [ 'text' ]} entry [ 'subject_type' ] = rel2sub [ data . idx2relation [ i ]] entry [ 'object_type' ] = { '@value' : rel2obj [ data . idx2relation [ i ]]} spo_list . append ( entry ) # \u6700\u5916\u5c42for\u5faa\u73af\u7ed3\u675f, \u5c06\u5f53\u524d\u6279\u6b21\u6570\u636e(batch_size=1)\u7684\u9884\u6d4b\u7ed3\u679c\u5199\u5165\u6587\u4ef6\u4e2d. res = {} res [ 'text' ] = text res [ 'spo_list' ] = spo_list json . dump ( res , res_file , ensure_ascii = False ) res_file . write ( ' \\n ' ) if batch_index % 500 == 0 : print ( 'batch_index = ' , batch_index ) if __name__ == '__main__' : config = { 'mode' : 'test' , 'batch_size' : 1 , 'relation_types' : 53 } path = './data/CMeIE_test.json' res_path = './data/CMeIE_test_res.json' # \u5b9e\u4f8b\u5316CasRel\u7c7b\u5bf9\u8c61\u5e76\u52a0\u8f7d\u5df2\u8bad\u7ec3\u597d\u7684\u6a21\u578b model = CasRel ( config ) . to ( device ) model . load_state_dict ( torch . load ( './saved_model/model_casrel.pt' )) test_casrel ( model , path , res_path , config ) \u6ce8\u610f: \u5728Tesla T4 GPU\u73af\u5883\u4e0b, \u8fd0\u884c50\u4e2aepochs, \u5927\u7ea6\u8017\u65f612\u4e2a\u5c0f\u65f6. \u6700\u4f18\u8868\u73b0\u662fepoch=47\u65f6, F1=49.89%.","title":"4.2 Casrel\u6a21\u578b"},{"location":"4_2.html#casrel","text":"","title":"Casrel\u6a21\u578b"},{"location":"4_2.html#_1","text":"\u7406\u89e3Casrel\u6a21\u578b\u662f\u5982\u4f55\u4f18\u5316RE\u95ee\u9898\u7684. \u638c\u63e1Casrel\u6a21\u578b\u7684\u67b6\u6784\u548c\u539f\u7406.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"4_2.html#casrel_1","text":"Casrel\u6a21\u578b\u662f\u4e8e2020\u5e74\u63d0\u51fa\u7684\u5173\u7cfb\u62bd\u53d6SOTA\u6a21\u578b, \u539f\u59cb\u8bba\u6587<< A Novel Cascade Binary Tagging Framework for Relational Triple Extraction >>. \u5728RE\u9886\u57df, \u67093\u79cd\u5178\u578b\u7684\u62bd\u53d6\u6a21\u5f0f, \u5982\u4e0b\u56fe\u6240\u793a: Normal\u6a21\u5f0f EPO(Entity Pair Overlap)\u6a21\u5f0f SEO(Single Entity Overlap)\u6a21\u5f0f Casrel\u6a21\u578b\u4e00\u6539\u4e4b\u524d\u7684\u5148NER, \u540eRE\u7684\u4e24\u9636\u6bb5\u6a21\u5f0f, \u91c7\u7528\u4e86\u66f4\u5148\u8fdb\u7684\u4e24\u9636\u6bb5\u6a21\u5f0f: \u5148\u62bd\u53d6\u5934\u5b9e\u4f53 \u518d\u62bd\u53d6\u5173\u7cfb + \u5c3e\u5b9e\u4f53 \u5148\u62bd\u53d6\u5934\u5b9e\u4f53 \u6ce8\u610f: \u4e0a\u9762\u516c\u5f0f\u5de6\u4fa7\u6982\u7387\u503c, \u4ee3\u8868\u8f93\u5165\u5e8f\u5217\u4e2d\u7b2ci\u4e2atoken, \u4f5c\u4e3asubject\u7684\u8d77\u59cb\u4f4d\u7f6e, \u7ed3\u675f\u4f4d\u7f6e\u7684\u6982\u7387! \u518d\u62bd\u53d6\u5173\u7cfb + \u5c3e\u5b9e\u4f53 \u6ce8\u610f: \u4e0a\u9762\u516c\u5f0f\u5de6\u4fa7\u6982\u7387\u503c, \u4ee3\u8868\u8f93\u5165\u5e8f\u5217\u4e2d\u7b2ci\u4e2atoken, \u4f5c\u4e3aobject\u7684\u8d77\u59cb\u4f4d\u7f6e, \u7ed3\u675f\u4f4d\u7f6e\u7684\u6982\u7387! Casrel\u6a21\u578b\u7684\u603b\u4f53\u67b6\u6784\u56fe\u5982\u4e0b: Casrel\u6a21\u578b\u5728\u4e3b\u6d41\u6807\u51c6\u8bc4\u6d4bNYT, \u548cWebNLG\u4e2d\u8fbe\u5230\u4e86SOTA\u7684\u6210\u7ee9:","title":"Casrel\u6a21\u578b\u67b6\u6784"},{"location":"4_2.html#casrel_2","text":"Casrel\u6a21\u578b\u7684\u5b9e\u73b0\u53ef\u4ee5\u5206\u5982\u4e0b\u6b65\u9aa4\u5b8c\u6210: \u7b2c\u4e00\u6b65: \u67e5\u770b\u6570\u636e\u96c6 \u7b2c\u4e8c\u6b65: \u5b9e\u73b0\u6570\u636e\u5904\u7406\u548c\u8fed\u4ee3\u5668 \u7b2c\u4e09\u6b65: \u6a21\u578b\u7c7b\u7684\u5b9e\u73b0 \u7b2c\u56db\u6b65: \u8bc4\u4f30\u51fd\u6570\u7684\u5b9e\u73b0 \u7b2c\u4e94\u6b65: \u8bad\u7ec3\u548c\u6d4b\u8bd5\u4ee3\u7801\u7684\u5b9e\u73b0","title":"Casrel\u6a21\u578b\u7684\u5b9e\u73b0"},{"location":"4_2.html#_2","text":"\u672c\u9879\u76ee\u4e2d\u4f9d\u7136\u91c7\u7528\u533b\u7597\u9886\u57df\u7684\u5173\u7cfb\u62bd\u53d6\u6570\u636eCMeIE. \u8bad\u7ec3\u96c6\u6570\u636eCMeIE_train.json \u9a8c\u8bc1\u96c6\u6570\u636eCMeIE_dev.json \u6d4b\u8bd5\u96c6\u6570\u636eCMeIE_test.json \u8bad\u7ec3\u96c6\u6570\u636e\u8def\u5f84: /home/ec2-user/information_extraction/relation/casrel/data/CMeIE_train.json {\"text\": \"\u4ea7\u540e\u6291\u90c1\u75c7@\u533a\u5206\u4ea7\u540e\u6291\u90c1\u75c7\u4e0e\u8f7b\u5ea6\u60c5\u7eea\u5931\u8c03\uff08\u4ea7\u540e\u5fe7\u90c1\u6216\u201c\u5a74\u513f\u5fe7\u90c1\u201d\uff09\u662f\u91cd\u8981\u7684\uff0c\u56e0\u4e3a\u8f7b\u5ea6\u60c5\u7eea\u5931\u8c03\u4e0d\u9700\u8981\u6cbb\u7597\u3002\", \"spo_list\": [{\"Combined\": false, \"predicate\": \"\u9274\u522b\u8bca\u65ad\", \"subject\": \"\u4ea7\u540e\u6291\u90c1\u75c7\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u8f7b\u5ea6\u60c5\u7eea\u5931\u8c03\"}, \"object_type\": {\"@value\": \"\u75be\u75c5\"}}]} {\"text\": \"\u7c7b\u98ce\u6e7f\u5173\u8282\u708e@\u5c3a\u4fa7\u504f\u659c\u662f\u7531\u4e8eMCP\u5173\u8282\u708e\u75c7\u9020\u6210\u7684\u3002\", \"spo_list\": [{\"Combined\": false, \"predicate\": \"\u4e34\u5e8a\u8868\u73b0\", \"subject\": \"MCP\u5173\u8282\u708e\u75c7\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u5c3a\u4fa7\u504f\u659c\"}, \"object_type\": {\"@value\": \"\u75c7\u72b6\"}}]} {\"text\": \"\u5507\u816d\u88c2@ ### \u816d\u7618 | \u5b58\u5728\u5dee\u5f02 | \u4f4e \u5927\u7ea6 10% \u81f3 20% \u989a\u6210\u5f62\u672f\u53d1\u751f\u816d\u7618\u3002 \u5507\u816d\u88c2@\u816d\u7618\u53d1\u751f\u673a\u7387\u4e0e\u5a74\u513f\u4f24\u53e3\uff0c\u8425\u517b\u72b6\u51b5\uff0c\u5916\u79d1\u6280\u672f\u548c\u5176\u4ed6\u56e0\u7d20\u76f8\u5173\u3002\", \"spo_list\": [{\"Combined\": true, \"predicate\": \"\u98ce\u9669\u8bc4\u4f30\u56e0\u7d20\", \"subject\": \"\u816d\u7618\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u5a74\u513f\u4f24\u53e3\"}, \"object_type\": {\"@value\": \"\u793e\u4f1a\u5b66\"}}, {\"Combined\": true, \"predicate\": \"\u98ce\u9669\u8bc4\u4f30\u56e0\u7d20\", \"subject\": \"\u816d\u7618\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u8425\u517b\u72b6\u51b5\"}, \"object_type\": {\"@value\": \"\u793e\u4f1a\u5b66\"}}, {\"Combined\": true, \"predicate\": \"\u98ce\u9669\u8bc4\u4f30\u56e0\u7d20\", \"subject\": \"\u816d\u7618\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u5916\u79d1\u6280\u672f\"}, \"object_type\": {\"@value\": \"\u793e\u4f1a\u5b66\"}}]} {\"text\": \"\u6210\u4eba\u54ee\u5598@ \u5e94\u5728\u4f4e\u5242\u91cf ICS \u7684\u57fa\u7840\u4e0a\u52a0\u7528\u4e00\u79cd LABA\uff0c \u6216\u5c06ICS\u589e\u52a0\u5230\u4e2d\u7b49\u5242\u91cf\u3002 \u6210\u4eba\u54ee\u5598@\u7b2c 5 \u7ea7\u5c06\u4e2d\u7b49\u5242\u91cf ICS \u6539\u4e3a\u9ad8\u5242\u91cf ICS\u3002\", \"spo_list\": [{\"Combined\": true, \"predicate\": \"\u836f\u7269\u6cbb\u7597\", \"subject\": \"\u6210\u4eba\u54ee\u5598\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"ICS\"}, \"object_type\": {\"@value\": \"\u836f\u7269\"}}, {\"Combined\": true, \"predicate\": \"\u836f\u7269\u6cbb\u7597\", \"subject\": \"\u54ee\u5598\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u4e2d\u7b49\u5242\u91cf ICS\"}, \"object_type\": {\"@value\": \"\u836f\u7269\"}}]} \u9a8c\u8bc1\u96c6\u6570\u636e\u8def\u5f84: /home/ec2-user/information_extraction/relation/casrel/data/CMeIE_dev.json {\"text\": \"\u6025\u6027\u80f0\u817a\u708e@\u6709\u7814\u7a76\u663e\u793a\uff0c\u8fdb\u884c\u65e9\u671f ERCP \uff0824 \u5c0f\u65f6\u5185\uff09\u53ef\u4ee5\u964d\u4f4e\u6897\u963b\u6027\u80c6\u603b\u7ba1\u7ed3\u77f3\u60a3\u8005\u7684\u5e76\u53d1\u75c7\u53d1\u751f\u7387\u548c\u6b7b\u4ea1\u7387\uff1b \u4f46\u662f\uff0c\u5bf9\u4e8e\u65e0\u80c6\u603b\u7ba1\u6897\u963b\u7684\u80c6\u6c41\u6027\u6025\u6027\u80f0\u817a\u708e\u60a3\u8005\uff0c\u4e0d\u9700\u8981\u8fdb\u884c\u65e9\u671f ERCP\u3002\", \"spo_list\": [{\"Combined\": false, \"predicate\": \"\u5f71\u50cf\u5b66\u68c0\u67e5\", \"subject\": \"\u6025\u6027\u80f0\u817a\u708e\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"ERCP\"}, \"object_type\": {\"@value\": \"\u68c0\u67e5\"}}]} {\"text\": \"\u3010\u8bca\u65ad\u3011 \u6839\u636e\u75be\u75c5\u8bca\u65ad\u548c\u7edf\u8ba1\u624b\u518c\u7b2c4\u7248\u6807\u51c6\uff0c\u7126\u8651\u60c5\u7eea\u6301\u7eed6\u4e2a\u6708\u4ee5\u4e0a\uff0c\u5e76\u81f3\u5c11\u4e0b\u8ff04\u9879\u75c7\u72b6\uff1a 1.\u62c5\u5fe7\u5c06\u6765\u7684\u610f\u5916\u4e8b\u4ef6\uff1b 2.\u62c5\u5fe7\u81ea\u5df1\u7684\u80fd\u529b\uff1b 3.\u62c5\u5fe7\u8fc7\u53bb\u7684\u884c\u4e3a\uff1b 4.\u8eaf\u4f53\u4e0d\u9002\u75c7\u72b6\uff1b 5.\u81ea\u6211\u610f\u8bc6\uff08\u5bf9\u4e3b\u4f53\u7684\u81ea\u6211\u8ba4\u8bc6\uff09\uff1b 6.\u4e0d\u65ad\u9700\u8981\u5f97\u5230\u4ed6\u4eba\u7684\u786e\u8ba4\uff1b 7.\u6301\u7eed\u7d27\u5f20\u548c\uff08\u6216\uff09\u4e0d\u80fd\u653e\u677e\uff1b \u5e7f\u6cdb\u6027\u7126\u8651\u75c7\u5f71\u54cd\u793e\u4f1a\u4ea4\u5f80\uff0c\u4e0e\u5206\u79bb\u6027\u7126\u8651\u75c7\u6bd4\u8f83\uff0c\u66f4\u591a\u4f34\u6709\u5176\u4ed6\u7126\u8651\u75c7\uff0c\u5982\u60ca\u6050\u53d1\u4f5c\u6216\u5355\u7eaf\u6027\u6050\u6016\u75c7\u3002 \uff08\u4e8c\uff09\u793e\u4ea4\u6027\u7126\u8651 \u5c3d\u7ba1\u4e24\u79cd\u75be\u75c5\u5747\u5bb3\u6015\u5728\u516c\u4f17\u573a\u5408\u4e0b\u8bf4\u8bdd\uff0c\u4f46\u5e7f\u6cdb\u6027\u7126\u8651\u4e5f\u5bb3\u6015\u5bf9\u8fc7\u53bb\u548c\u5c06\u6765\u60c5\u5f62\u7684\u7126\u8651\u3002\", \"spo_list\": [{\"Combined\": true, \"predicate\": \"\u9274\u522b\u8bca\u65ad\", \"subject\": \"\u5e7f\u6cdb\u6027\u7126\u8651\u75c7\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u793e\u4ea4\u6027\u7126\u8651\"}, \"object_type\": {\"@value\": \"\u75be\u75c5\"}}, {\"Combined\": true, \"predicate\": \"\u9274\u522b\u8bca\u65ad\", \"subject\": \"\u5e7f\u6cdb\u6027\u7126\u8651\u75c7\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u5206\u79bb\u6027\u7126\u8651\"}, \"object_type\": {\"@value\": \"\u75be\u75c5\"}}]} {\"text\": \"\u9aa8\u6027\u5173\u8282\u708e@\u5728\u5176\u4ed6\u5173\u8282\uff08\u5982\u8e1d\u5173\u8282\u548c\u8155\u5173\u8282\uff09\uff0c\u9aa8\u6027\u5173\u8282\u708e\u6bd4\u8f83\u5c11\u89c1\uff0c\u5e76\u4e14\u4e00\u822c\u6709\u6f5c\u5728\u7684\u75c5\u56e0\uff08\u5982\u7ed3\u6676\u6027\u5173\u8282\u75c5\u3001\u521b\u4f24\uff09\u3002\", \"spo_list\": [{\"Combined\": false, \"predicate\": \"\u53d1\u75c5\u90e8\u4f4d\", \"subject\": \"\u9aa8\u6027\u5173\u8282\u708e\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u5173\u8282\"}, \"object_type\": {\"@value\": \"\u90e8\u4f4d\"}}, {\"Combined\": false, \"predicate\": \"\u53d1\u75c5\u90e8\u4f4d\", \"subject\": \"\u9aa8\u6027\u5173\u8282\u708e\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u8e1d\u5173\u8282\"}, \"object_type\": {\"@value\": \"\u90e8\u4f4d\"}}, {\"Combined\": false, \"predicate\": \"\u53d1\u75c5\u90e8\u4f4d\", \"subject\": \"\u9aa8\u6027\u5173\u8282\u708e\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u8155\u5173\u8282\"}, \"object_type\": {\"@value\": \"\u90e8\u4f4d\"}}, {\"Combined\": false, \"predicate\": \"\u75c5\u56e0\", \"subject\": \"\u9aa8\u6027\u5173\u8282\u708e\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u7ed3\u6676\u6027\u5173\u8282\u75c5\"}, \"object_type\": {\"@value\": \"\u793e\u4f1a\u5b66\"}}, {\"Combined\": false, \"predicate\": \"\u75c5\u56e0\", \"subject\": \"\u9aa8\u6027\u5173\u8282\u708e\", \"subject_type\": \"\u75be\u75c5\", \"object\": {\"@value\": \"\u521b\u4f24\"}, \"object_type\": {\"@value\": \"\u793e\u4f1a\u5b66\"}}]} \u6d4b\u8bd5\u96c6\u6570\u636e\u8def\u5f84: /home/ec2-user/information_extraction/relation/casrel/data/CMeIE_test.json {\"text\": \"\u75d4@\u809b\u955c\u68c0\u67e5\u65b9\u6cd5\u7b80\u4fbf\u5b89\u5168\uff0c\u53ef\u5168\u65b9\u4f4d\u89c2\u5bdf\u809b\u7ba1\u53ca\u6240\u6709\u75d4\u7ec4\u7ec7\u3002\u75d4@\u53e6\u4e00\u79cd\u66ff\u4ee3\u7684\u65b9\u6cd5\u4e3a\u7ea4\u7ef4\u5185\u7aa5\u955c\u53cd\u8f6c\u89c2\u5bdf\uff0c\u6b64\u6cd5\u64cd\u4f5c\u8981\u6c42\u9ad8\uff0c\u9700\u66f4\u9ad8\u7684\u6280\u5de7\u6c34\u5e73\u3002\"} {\"text\": \"\u6162\u6027\u80be\u75c5@\u8fdb\u884c\u773c\u5e95\u68c0\u67e5\u5341\u5206\u5fc5\u8981\uff0c\u56e0\u4e3a\u5176\u6709\u52a9\u4e8e\u8bca\u65ad\u7cd6\u5c3f\u75c5\u6027\u6216\u9ad8\u8840\u538b\u6027\u89c6\u7f51\u819c\u75c5\u53d8\uff0c\u6709\u52a9\u4e8e\u5224\u65ad\u5728\u80be\u810f\u5185\u53ef\u80fd\u53d1\u751f\u7684\u5fae\u8840\u7ba1\u75c5\u53d8\u3002\"} {\"text\": \"5.\u836f\u7269\u56e0\u7d20 \u5f15\u8d77\u6d88\u5316\u6027\u6e83\u75a1\u7684\u836f\u7269\u4e2d\u8f83\u91cd\u8981\u7684\u6709\u4e09\u7c7b\uff1a\u2460\u963f\u53f8\u5339\u6797\uff08ASA\uff09\uff1b\u2461\u975e\u753e\u4f53\u6297\u708e\u836f\u7269\uff08NSAIDs\uff09\uff0c\u5982\u5432\u54da\u7f8e\u8f9b\u53ca\u4fdd\u6cf0\u677e\uff1b\u2462\u80be\u4e0a\u817a\u76ae\u8d28\u6fc0\u7d20\u3002 7.\u7cbe\u795e\u56e0\u7d20 15\u5e74\u524d\uff0c\u5bf9\u80c3\u9020\u7618\u60a3\u8005\u89c2\u5bdf\u53d1\u73b0\uff0c\u4eba\u80c3\u9ecf\u819c\u968f\u4eba\u7684\u60c5\u7eea\u53d8\u5316\u800c\u51fa\u73b0\u4e0d\u540c\u7684\u53cd\u5e94\uff0c\u5174\u594b\u65f6\uff0c\u80c3\u9ecf\u819c\u5145\u8840\uff0c\u80c3\u6db2\u5206\u6ccc\u589e\u591a\uff0c\u80c3\u8fd0\u52a8\u52a0\u5f3a\uff1b\u800c\u6291\u90c1\u548c\u7edd\u671b\u65f6\uff0c\u80c3\u9ecf\u819c\u82cd\u767d\uff0c\u80c3\u8fd0\u52a8\u51cf\u6162\u3002\"} {\"text\": \"\u767b\u9769\u70ed@\u5927\u7ea6 90% \u7684\u767b\u9769\u51fa\u8840\u70ed (dengue haemorrhagic fever, DHF) \u75c5\u4f8b\u4e3a 5 \u5c81\u4ee5\u4e0b\u513f\u7ae5\u3002\u767b\u9769\u70ed@ \u5178\u578b\u7684\u767b\u9769\u70ed\u66f4\u5e38\u89c1\u4e8e\u6210\u4eba\uff0c\u800c\u975e\u513f\u7ae5\u3002\"} {\"text\": \"\u3010\u75c5\u56e0\u3011 \u7f3a\u6c27\u662fHIE\u53d1\u75c5\u7684\u6838\u5fc3,\u5176\u4e2d\u56f4\u751f\u671f\u7a92\u606f\u662f\u6700\u4e3b\u8981\u7684\u75c5\u56e0\u3002 \u3010\u53d1\u75c5\u673a\u5236\u3011 \u8111\u8840\u6d41\u6539\u53d8 \u5f53\u7f3a\u6c27\u7f3a\u8840\u4e3a\u90e8\u5206\u6216\u6162\u6027\u65f6,\u4f53\u5185\u8840\u6db2\u51fa\u73b0\u91cd\u65b0\u5206\u914d\uff0c\u4ee5\u4fdd\u8bc1\u5fc3\u3001\u8111\u7b49\u91cd\u8981\u5668\u5b98\u8840\u6db2\u4f9b\u5e94,\u800c\u80ba\u3001\u80be\u3001\u80c3\u80a0\u9053\u7b49\u76f8\u5bf9\u6b21\u91cd\u8981\u5668\u5b98\u53d7\u635f\u3002\"} {\"text\": \"\u9ad8\u8840\u538b\u6025\u75c7\u7684\u6cbb\u7597\uff0c\u539f\u5219\u662f\u5c06\u8840\u538b\u964d\u81f3\u5b89\u5168\u6c34\u5e73\u800c\u975e\u8fc5\u901f\u964d\u81f3\u6b63\u5e38\uff0c\u4fdd\u8bc1\u7ec4\u7ec7\u5668\u5b98\u7684\u704c\u6ce8\uff0c\u9632\u6b62\u5668\u5b98\u635f\u5bb3\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002 4.\u67f3\u80fa\u82c4\u5fc3\u5b9a\uff08labetalol\uff09 \u517c\u6709\u03b1\u548c\u03b2\u53d7\u4f53\u963b\u6ede\u4f5c\u7528\uff0c\u6bcf\u6b210. 25\uff5e1. 0mg/kg\uff08\u6bcf\u6b21\u6700\u591a20mg\uff09\u9759\u8109\u6ce8\u5c04\uff0c\u4f5c\u7528\u6301\u7eed\u8fbe4\u5c0f\u65f6\uff0c\u9700\u8981\u65f6\u6bcf10\u5206\u949f\u540e\u91cd\u590d1\u6b21\uff1b\u6301\u7eed\u9759\u8109\u6ef4\u6ce8\u5242\u91cf\u4e3a\u6bcf\u5c0f\u65f60. 4\uff5e1. 0mg/kg\uff0c\u6700\u9ad8\u53ef\u8fbe\u6bcf\u5c0f\u65f63mg/kg\u3002\"} {\"text\": \"\u5fc3\u623f\u6251\u52a8@ \u5fc3\u7535\u56fe\u5177\u6709\u8bca\u65ad\u610f\u4e49\uff1a * \u5178\u578b\u7684\u5f62\u5f0f\uff08\u9006\u65f6\u9488\u5fc3\u623f\u6251\u52a8\uff09\uff1a\u2161\u3001\u2162\u3001aVF \u5bfc\u8054\u53ef\u89c1\u8d1f\u5411\u952f\u9f7f\u72b6\u5fc3\u623f\u6ce2\uff08F \u6ce2\uff09\uff0c\u5728 V1 \u5bfc\u8054\u6b63\u5411\u5fc3\u623f\u6251\u52a8\u6ce2\uff0c\u5fc3\u623f\u7387\u4e3a 240-320 \u6b21/\u5206\u3002\u5fc3\u623f\u6251\u52a8@\u5f53\u6000\u7591\u6025\u6027\u5fc3\u808c\u6897\u6b7b\u65f6\uff0c\u5e94\u67e5\u5fc3\u808c\u9176\u8c31\uff0c\u82e5\u60a3\u8005\u6b63\u5728\u5e94\u7528\u6d0b\u5730\u9ec4\u7c7b\u836f\u7269\uff08\u4f8b\u5982\u5730\u9ad8\u8f9b\uff09\uff0c\u5e94\u68c0\u6d4b\u6d0b\u5730\u9ec4\u7c7b\u836f\u7269\u7684\u8840\u836f\u6d53\u5ea6\u3002\"} {\"text\": \"\u5e15\u91d1\u68ee\u75c5@ * \u52a0\u5165\u5f53\u5730\u652f\u6301\u56e2\u961f\u53ef\u80fd\u4f1a\u6709\u6240\u5e2e\u52a9\u3002\"} \u5173\u7cfb\u6620\u5c04\u8868\u6570\u636e\u8def\u5f84: /home/ec2-user/information_extraction/relation/casrel/data/relation2idx.json {\"\u9884\u9632\": 0, \"\u9636\u6bb5\": 1, \"\u5c31\u8bca\u79d1\u5ba4\": 2, \"\u540c\u4e49\u8bcd-\u5176\u4ed6\": 3, \"\u8f85\u52a9\u6cbb\u7597\": 4, \"\u5316\u7597\": 5, \"\u653e\u5c04\u6cbb\u7597\": 6, \"\u540c\u4e49\u8bcd-\u5176\u4ed6\u6cbb\u7597\": 7, \"\u624b\u672f\u6cbb\u7597\": 8, \"\u540c\u4e49\u8bcd-\u624b\u672f\u6cbb\u7597\": 9, \"\u5b9e\u9a8c\u5ba4\u68c0\u67e5\": 10, \"\u5f71\u50cf\u5b66\u68c0\u67e5\": 11, \"\u8f85\u52a9\u68c0\u67e5\": 12, \"\u7ec4\u7ec7\u5b66\u68c0\u67e5\": 13, \"\u540c\u4e49\u8bcd-\u68c0\u67e5\": 14, \"\u5185\u7aa5\u955c\u68c0\u67e5\": 15, \"\u7b5b\u67e5\": 16, \"\u591a\u53d1\u7fa4\u4f53\": 17, \"\u53d1\u75c5\u7387\": 18, \"\u53d1\u75c5\u5e74\u9f84\": 19, \"\u591a\u53d1\u5730\u533a\": 20, \"\u53d1\u75c5\u6027\u522b\u503e\u5411\": 21, \"\u6b7b\u4ea1\u7387\": 22, \"\u591a\u53d1\u5b63\u8282\": 23, \"\u4f20\u64ad\u9014\u5f84\": 24, \"\u540c\u4e49\u8bcd-\u6d41\u884c\u75c5\u5b66\": 25, \"\u540c\u4e49\u8bcd-\u75be\u75c5\": 26, \"\u5e76\u53d1\u75c7\": 27, \"\u75c5\u7406\u5206\u578b\": 28, \"\u76f8\u5173\uff08\u5bfc\u81f4\uff09\": 29, \"\u9274\u522b\u8bca\u65ad\": 30, \"\u76f8\u5173\uff08\u8f6c\u5316\uff09\": 31, \"\u76f8\u5173\uff08\u75c7\u72b6\uff09\": 32, \"\u4e34\u5e8a\u8868\u73b0\": 33, \"\u6cbb\u7597\u540e\u75c7\u72b6\": 34, \"\u4fb5\u53ca\u5468\u56f4\u7ec4\u7ec7\u8f6c\u79fb\u7684\u75c7\u72b6\": 35, \"\u540c\u4e49\u8bcd-\u75c7\u72b6\": 36, \"\u75c5\u56e0\": 37, \"\u9ad8\u5371\u56e0\u7d20\": 38, \"\u98ce\u9669\u8bc4\u4f30\u56e0\u7d20\": 39, \"\u75c5\u53f2\": 40, \"\u9057\u4f20\u56e0\u7d20\": 41, \"\u540c\u4e49\u8bcd-\u793e\u4f1a\u5b66\": 42, \"\u53d1\u75c5\u673a\u5236\": 43, \"\u75c5\u7406\u751f\u7406\": 44, \"\u836f\u7269\u6cbb\u7597\": 45, \"\u540c\u4e49\u8bcd-\u836f\u7269\": 46, \"\u53d1\u75c5\u90e8\u4f4d\": 47, \"\u8f6c\u79fb\u90e8\u4f4d\": 48, \"\u5916\u4fb5\u90e8\u4f4d\": 49, \"\u540c\u4e49\u8bcd-\u90e8\u4f4d\": 50, \"\u9884\u540e\u72b6\u51b5\": 51, \"\u9884\u540e\u751f\u5b58\u7387\": 52}","title":"\u7b2c\u4e00\u6b65: \u67e5\u770b\u6570\u636e\u96c6"},{"location":"4_2.html#_3","text":"\u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/casrel/dataloader.py import json import re import torch from torch.utils.data import Dataset , DataLoader from torch.nn.utils.rnn import pad_sequence , pack_padded_sequence from transformers import BertTokenizer from random import choice import codecs device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) # \u6784\u9020\u6570\u636e\u96c6\u7684\u7c7b\u4ee3\u7801 class MyDataset ( Dataset ): # \u8bfb\u53d6\u8bad\u7ec3\u96c6\u6570\u636e def __get_train_data ( self , path ): with open ( path , 'r' , encoding = 'utf-8' ) as f : data = f . readlines () res = [ json . loads ( i ) for i in data ] return res # \u8bfb\u53d6\u9a8c\u8bc1\u96c6\u6570\u636e def __get_dev_data ( self , path ): with open ( path , 'r' , encoding = 'utf-8' ) as f : data = f . readlines () res = [ json . loads ( i ) for i in data ] return res # \u8bfb\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e def __get_test_data ( self , path ): with open ( path , 'r' , encoding = 'utf-8' ) as f : data = f . readlines () data = [ json . loads ( i ) for i in data ] res = [] for entry in data : entry [ 'spo_list' ] = [] res . append ( entry ) return res def __init__ ( self , path , config ): super ( MyDataset , self ) . __init__ () self . config = config if self . config [ 'mode' ] == 'train' : self . data = self . __get_train_data ( path ) elif self . config [ 'mode' ] == 'test' : self . data = self . __get_test_data ( path ) elif self . config [ 'mode' ] == 'dev' : self . data = self . __get_dev_data ( path ) # \u8bfb\u53d6\u5173\u7cfb\u6620\u5c04\u8868, \u5e76\u6784\u9020\u5173\u7cfb-id\u6620\u5c04\u5b57\u5178 with open ( 'data/relation2idx.json' , 'r' , encoding = 'utf-8' ) as f : self . relation2idx = json . load ( f ) self . idx2relation = dict () for key in self . relation2idx : self . idx2relation [ self . relation2idx [ key ]] = key # \u8bbe\u7f6e\u57fa\u7840\u9884\u8bad\u7ec3\u6a21\u578b bert_path = '/home/ec2-user/code/re/casrel/bert_pretrain/' self . tokenizer = BertTokenizer . from_pretrained ( bert_path ) def __len__ ( self ): return len ( self . data ) # \u6309\u7167\u7d22\u5f15\u6807\u7b7e\u83b7\u53d6\u6570\u636e\u7684\u91cd\u5199\u51fd\u6570 def __getitem__ ( self , item ): text , gold = self . data [ item ][ 'text' ], self . data [ item ][ 'spo_list' ] text = text if len ( text ) <= 512 else text [: 512 ] # \u5b8c\u6210token_to_id\u7684\u6620\u5c04 sample = list ( text ) sample = self . tokenizer . convert_tokens_to_ids ( sample ) # \u8bbe\u7f6eSubject\u548crelation\u7684\u8d77\u59cb, \u7ed3\u675f\u6807\u7b7e\u4f4d\u7f6e\u5f20\u91cf sub_start = len ( sample ) * [ 0 ] sub_end = len ( sample ) * [ 0 ] relation_start = [[ 0 for _ in range ( self . config [ 'relation_types' ])] for _ in range ( len ( sample ))] relation_end = [[ 0 for _ in range ( self . config [ 'relation_types' ])] for _ in range ( len ( sample ))] # dim = (seq_len, relation_types) sub_start_single = len ( sample ) * [ 0 ] sub_end_single = len ( sample ) * [ 0 ] s2ro_map = {} # \u89e3\u6790\u6570\u636e\u6587\u4ef6\u4e2d\u7684\u5177\u4f53\u503c for entry in gold : sub = entry [ 'subject' ] obj = entry [ 'object' ][ '@value' ] relation = '\u540c\u4e49\u8bcd-' + entry [ 'subject_type' ] if entry [ 'predicate' ] == '\u540c\u4e49\u8bcd' else entry [ 'predicate' ] # \u6b63\u5219\u8868\u8fbe\u5f0f\u65e0\u6cd5\u5904\u7406\u5c0f\u62ec\u53f7, \u6240\u4ee5\u629b\u51fa\u5f02\u5e38 try : sub_pos = re . search ( sub , text ) . span () obj_pos = re . search ( obj , text ) . span () relation_idx = self . relation2idx [ relation ] sub_start [ sub_pos [ 0 ]] = 1 sub_end [ sub_pos [ 1 ] - 1 ] = 1 if sub_pos not in s2ro_map : s2ro_map [ sub_pos ] = [] s2ro_map [ sub_pos ] . append (( obj_pos , relation_idx )) except : pass # \u5982\u679c\u80fd\u89e3\u6790\u51fa\u6709\u6548\u6570\u636e, \u5219\u586b\u5145\u5bf9\u5e94\u7684\u5f20\u91cf if s2ro_map : sub_pos = choice ( list ( s2ro_map . keys ())) sub_start_single [ sub_pos [ 0 ]] = 1 sub_end_single [ sub_pos [ 1 ] - 1 ] = 1 for obj_pos , relation_idx in s2ro_map . get ( sub_pos , []): relation_start [ obj_pos [ 0 ]][ relation_idx ] = 1 relation_end [ obj_pos [ 1 ] - 1 ][ relation_idx ] = 1 # print('****************************') # print('sample:', sample) # print('sub_start:', sub_start) # print(len(sub_start)) # print('sub_end:', sub_end) # print(len(sub_end)) # print('relation_start:', relation_start) # print('relation_end:', relation_end) # print('sub_start_single:', sub_start_single) # print('sub_end_single:', sub_end_single) # print(len(sub_start_single)) # print(len(sub_end_single)) return sample , sub_start , sub_end , relation_start , relation_end , sub_start_single , sub_end_single # \u6570\u636e\u7684\"\u4e2a\u6027\u5316\"\u5904\u7406\u51fd\u6570 def collate_fn ( data ): data . sort ( key = lambda x : len ( x [ 0 ]), reverse = True ) sample , sub_start , sub_end , relation_start , relation_end , sub_start_single , sub_end_single = zip ( * data ) # \u5bf9\u6240\u6709\u6570\u636e\u4f9d\u6b21\u8fdb\u884c\u6620\u5c04, \u5c01\u88c5, \u8f6c\u79fb\u5230GPU\u7b49 mask = [[ 1 if j < len ( i ) else 0 for j in range ( len ( sample [ 0 ]))] for i in sample ] sample = [ torch . tensor ( i ) . long () . to ( device ) for i in sample ] sub_start = [ torch . tensor ( i ) . long () . to ( device ) for i in sub_start ] sub_end = [ torch . tensor ( i ) . long () . to ( device ) for i in sub_end ] relation_start = [ torch . tensor ( i ) . long () . to ( device ) for i in relation_start ] relation_end = [ torch . tensor ( i ) . long () . to ( device ) for i in relation_end ] sub_start_single = [ torch . tensor ( i ) . long () . to ( device ) for i in sub_start_single ] sub_end_single = [ torch . tensor ( i ) . long () . to ( device ) for i in sub_end_single ] # \u5bf9\u6240\u6709\u6570\u636e\u4f9d\u6b21\u8fdb\u884cpad\u8865\u9f50\u64cd\u4f5c mask = torch . tensor ( mask ) . long () . to ( device ) sample = pad_sequence ( sample , batch_first = True , padding_value = 0 ) sub_start = pad_sequence ( sub_start , batch_first = True , padding_value = 0 ) sub_end = pad_sequence ( sub_end , batch_first = True , padding_value = 0 ) relation_start = pad_sequence ( relation_start , batch_first = True , padding_value = 0 ) relation_end = pad_sequence ( relation_end , batch_first = True , padding_value = 0 ) sub_start_single = pad_sequence ( sub_start_single , batch_first = True , padding_value = 0 ) sub_end_single = pad_sequence ( sub_end_single , batch_first = True , padding_value = 0 ) return sample , sub_start , sub_end , relation_start , relation_end , mask , sub_start_single , sub_end_single if __name__ == \"__main__\" : path = './data/CMeIE_train.json' config = { \"mode\" : \"train\" , \"relation_types\" : 53 } data = MyDataset ( path , config ) dataloader = DataLoader ( data , batch_size = 4 , shuffle = False , collate_fn = collate_fn ) batch_data = next ( iter ( dataloader )) file = codecs . open ( 'debug.txt' , 'w' , encoding = 'utf-8' ) test_idx = 30 a , b = batch_data [ 3 ][ test_idx ], batch_data [ 4 ][ test_idx ] for i in batch_data : file . write ( str ( i [ test_idx ]) + ' \\n ' ) for i in range ( a . shape [ 0 ]): file . write ( str ( i ) + str ( b [ i ]) + ' \\n ' )","title":"\u7b2c\u4e8c\u6b65: \u5b9e\u73b0\u6570\u636e\u5904\u7406\u548c\u8fed\u4ee3\u5668"},{"location":"4_2.html#_4","text":"\u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/casrel/casrel.py import torch import torch as t from torch import nn from transformers import BertModel , BertTokenizer , BertConfig import numpy as np device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) # Casrel\u6838\u5fc3\u7c7b\u4ee3\u7801 class CasRel ( nn . Module ): def __init__ ( self , config ): super ( CasRel , self ) . __init__ () self . config = config self . bert_dim = 768 # \u9884\u8bad\u7ec3\u6a21\u578b\u7684\u52a0\u8f7d model_name = 'bert-base-chinese' self . bert_path = \"/home/ec2-user/code/re/casrel/bert_pretrain\" self . bert_config = BertConfig . from_pretrained ( self . bert_path + '/bert_config.json' ) self . bert_encoder = BertModel . from_pretrained ( self . bert_path , config = self . bert_config ) # \u4f9d\u6b21\u521d\u59cb\u53164\u4e2a\u91cd\u8981\u7d22\u5f15 self . sub_start_tagger = nn . Linear ( self . bert_dim , 1 ) self . sub_end_tagger = nn . Linear ( self . bert_dim , 1 ) self . obj_start_tagger = nn . Linear ( self . bert_dim , config [ 'relation_types' ]) self . obj_end_tagger = nn . Linear ( self . bert_dim , config [ 'relation_types' ]) # \u83b7\u53d6BERT\u7684\u8f93\u51fa\u7f16\u7801\u5f20\u91cf def get_encoded_text ( self , data ): encoded_text = self . bert_encoder ( data [ 'token_ids' ], attention_mask = data [ 'mask' ])[ 0 ] # (batch_size, seq_len, bert_dim) return encoded_text # \u83b7\u53d6Subject\u7684\u9884\u6d4b\u5f20\u91cf def get_sub ( self , encoded_text ): # dim(pred) = (batch_size, seq_len, 1) # \u83b7\u53d6\u8d77\u59cb\u6307\u9488 pred_sub_start = self . sub_start_tagger ( encoded_text ) pred_sub_start = torch . sigmoid ( pred_sub_start ) # \u83b7\u53d6\u7ed3\u675f\u6307\u9488 pred_sub_end = self . sub_end_tagger ( encoded_text ) pred_sub_end = torch . sigmoid ( pred_sub_end ) return pred_sub_start , pred_sub_end # \u83b7\u53d6Object\u7684\u9884\u6d4b\u5f20\u91cf def get_obj ( self , sub_start_mapping , sub_end_mapping , encoded_text ): # dim(sub_start_mapping) = dim(sub_end_mapping) = (batch_size, 1, seq_len) # dim(encoded_text) = (batch_size, seq_len, bert_dim) # \u6309\u7167\u8bba\u6587\u4e2d\u7684\u516c\u5f0f\u53d8\u4f53, \u9996\u5148\u5bf9Xi, \u548cstart_mapping\u8fdb\u884c\u77e9\u9635\u4e58\u6cd5, \u5f97\u5230start\u5f20\u91cf; end\u540c\u7406 sub_start = torch . matmul ( sub_start_mapping . float (), encoded_text ) sub_end = torch . matmul ( sub_end_mapping . float (), encoded_text ) # dim(sub_start) = dim(sub_end) = (batch_size, 1, bert_dim) # \u6309\u7167\u8bba\u6587\u4e2d\u7684\u516c\u5f0f\u8ba1\u7b97 sub = ( sub_start + sub_end ) / 2 encoded_text = encoded_text + sub # \u6309\u7167\u8bba\u6587\u4e2d\u7684\u516c\u5f0f, \u8fdb\u884cW_start(r)\u7684\u77e9\u9635\u8fd0\u7b97; W_end(r)\u540c\u7406 pred_obj_start = self . obj_start_tagger ( encoded_text ) pred_obj_end = self . obj_end_tagger ( encoded_text ) pred_obj_start = torch . sigmoid ( pred_obj_start ) pred_obj_end = torch . sigmoid ( pred_obj_end ) # \u6700\u7ec8\u8fd4\u56deobject\u7684\u9996\u5c3e\u6307\u9488 return pred_obj_start , pred_obj_end def get_list ( self , start , end , text , h_bar = 0.5 , t_bar = 0.5 ): # \u521d\u59cb\u5316\u8bc6\u522b\u51fa\u6765\u7684entities\u7684\u7ed3\u679c\u5217\u8868res res = [] # \u8fdb\u884c\u5217\u8868\u957f\u5ea6\u7684\u622a\u65ad start , end = start [: 512 ], end [: 512 ] start_idxs , end_idxs = [], [] # \u521d\u59cb\u5316\u5217\u8868\u503c for idx in range ( len ( start )): if ( start [ idx ] > h_bar ): start_idxs . append ( idx ) if ( end [ idx ] > t_bar ): end_idxs . append ( idx ) # \u904d\u5386\u8d77\u59cb\u548c\u7ed3\u675f\u4f4d\u7f6e, \u5c06\u8bc6\u522b\u51fa\u6765\u7684\u5b9e\u4f53\u6dfb\u52a0\u8fdb\u7ed3\u679c\u5217\u8868 for start_idx in start_idxs : for end_idx in end_idxs : if ( end_idx >= start_idx ): # \u5c06\u8bc6\u522b\u51fa\u7684entity\u7684\u91cd\u8981\u4fe1\u606f\u4ee5\u5b57\u5178\u5f62\u5f0f\u6dfb\u52a0\u8fdb\u7ed3\u679c\u5217\u8868res entry = {} entry [ 'text' ] = text [ start_idx : end_idx + 1 ] entry [ 'start' ] = start_idx entry [ 'end' ] = end_idx res . append ( entry ) break return res # Casrel\u6a21\u578b\u7684\u524d\u5411\u8ba1\u7b97\u51fd\u6570 def forward ( self , data ): # 1: \u7b2c\u4e00\u6b65\u5c06\u539f\u59cb\u6587\u672c\u9001\u5165\u7f16\u7801\u5668BERT\u4e2d encoded_text = self . get_encoded_text ( data ) # 2: \u7b2c\u4e8c\u6b65\u8fdb\u884cSubject\u7684\u9996\u5c3e\u6307\u9488\u9884\u6d4b pred_sub_start , pred_sub_end = self . get_sub ( encoded_text ) # 3: \u5c06\u771f\u5b9e\u6570\u636e\u4e2d\u7684start, end\u6807\u7b7e\u63d0\u53d6\u51fa\u6765 sub_start_mapping = data [ 'sub_start' ] . unsqueeze ( 1 ) sub_end_mapping = data [ 'sub_end' ] . unsqueeze ( 1 ) # 4: \u8c03\u7528\u7c7b\u5185\u51fd\u6570, \u5c06\u6a21\u578b\u9884\u6d4b\u7684object\u7684start, end\u6307\u9488\u63d0\u53d6\u51fa\u6765 pred_obj_start , pred_obj_end = self . get_obj ( sub_start_mapping , sub_end_mapping , encoded_text ) return pred_sub_start , pred_sub_end , pred_obj_start , pred_obj_end # \u63a8\u7406\u9636\u6bb5\u7684\u51fd\u6570(Inference) def test ( self , data ): # \u5c06\u539f\u59cb\u6587\u672c\u6570\u636e\u9001\u5165BERT\u7f16\u7801\u5668\u4e2d encoded_text = self . get_encoded_text ( data ) # \u63d0\u53d6Subject\u7684\u9996\u5c3e\u6307\u9488 pred_sub_start , pred_sub_end = self . get_sub ( encoded_text ) # \u83b7\u53d6\u7ed3\u679c\u5217\u8868 sub_list = self . get_list ( pred_sub_start . squeeze ( 0 ) . squeeze ( - 1 ), pred_sub_end . squeeze ( 0 ) . squeeze ( - 1 ), data [ 'text' ]) if ( sub_list ): # \u521d\u59cb\u5316\u82e5\u5e72\u91cd\u8981\u5f20\u91cf repeated_encoded_text = encoded_text . repeat ( len ( sub_list ), 1 , 1 ) sub_start_mapping = torch . zeros ( len ( sub_list ), 1 , encoded_text . shape [ 1 ]) . to ( device ) sub_end_mapping = torch . zeros ( len ( sub_list ), 1 , encoded_text . shape [ 1 ]) . to ( device ) for idx , sub in enumerate ( sub_list ): sub_start_mapping [ idx ][ 0 ][ sub [ 'start' ]] = 1 sub_end_mapping [ idx ][ 0 ][ sub [ 'end' ]] = 1 # \u6309\u7167Subject, \u6a21\u578b\u63d0\u53d6\u51faObject pred_obj_start , pred_obj_end = self . get_obj ( sub_start_mapping , sub_end_mapping , repeated_encoded_text ) return sub_list , pred_obj_start , pred_obj_end # \u5982\u679c\u6ca1\u6709Subject, \u76f4\u63a5\u8fd4\u56deNone else : return None","title":"\u7b2c\u4e09\u6b65: \u6a21\u578b\u7c7b\u7684\u5b9e\u73b0"},{"location":"4_2.html#_5","text":"\u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/casrel/evaluate.py import json import codecs # \u8bc4\u4f30\u51fd\u6570 def evaluate (): # \u8bfb\u53d6\u8bc4\u4f30\u6570\u636e, \u5305\u62ec\u9884\u6d4b\u7ed3\u679c\u548c\u771f\u5b9e\u6807\u7b7e pred_path = './data/CMeIE_dev_result.json' # prediction gold_path = \"./data/CMeIE_dev.json\" # golden state res_path = './data/eval_dev.json' pred_file = codecs . open ( pred_path , 'r' , encoding = 'utf-8' ) gold_file = codecs . open ( gold_path , 'r' , encoding = 'utf-8' ) # \u6bcf\u4e2aepoch\u4f1a\u8c03\u7528\u4e00\u6b21\u8bc4\u4f30\u51fd\u6570, \u4f46\u53ea\u4fdd\u5b58\u6548\u679c\u6700\u597d\u7684\u6a21\u578b\u8bc4\u6d4b\u6570\u636e res_file = codecs . open ( res_path , 'w' , encoding = 'utf-8' ) # \u8bfb\u53d6\u6587\u4ef6\u4fe1\u606f\u5e76\u5b58\u5165\u5217\u8868\u683c\u5f0f pred_data = pred_file . readlines () pred_data = [ json . loads ( i ) for i in pred_data ] # \u8bfb\u53d6\u6587\u4ef6\u4fe1\u606f\u5e76\u5b58\u5165\u5217\u8868\u683c\u5f0f gold_data = gold_file . readlines () gold_data = [ json . loads ( i ) for i in gold_data ] # \u5c06\u9884\u6d4b\u503c\u548c\u771f\u5b9e\u503c\u505a\u914d\u5bf9 data = zip ( pred_data , gold_data ) correct_num = 0 pred_num = 0 gold_num = 0 # \u904d\u5386\u6570\u636e\u505a\u6b63\u8d1f\u6837\u672c\u7684\u8ba1\u6570 for pred , gold in data : # \u9884\u6d4b\u503c\u7684\u8bfb\u53d6\u548c\u96c6\u5408\u53bb\u91cd pred_spo = [( i [ 'predicate' ], i [ 'subject' ], i [ 'subject_type' ], i [ 'object' ][ '@value' ], i [ 'object_type' ][ '@value' ]) for i in pred [ 'spo_list' ]] pred_spo = set ( pred_spo ) # \u771f\u5b9e\u503c\u7684\u8bfb\u53d6\u548c\u96c6\u5408\u53bb\u91cd gold_spo = [( i [ 'predicate' ], i [ 'subject' ], i [ 'subject_type' ], i [ 'object' ][ '@value' ], i [ 'object_type' ][ '@value' ]) for i in gold [ 'spo_list' ]] gold_spo = set ( gold_spo ) # \u505a\u4ea4\u96c6\u5f97\u51fa\u9884\u6d4b\u6b63\u786e\u7684\u6570\u91cf correct_num += len ( pred_spo & gold_spo ) pred_num += len ( pred_spo ) gold_num += len ( gold_spo ) # \u4ee5\u5b57\u5178\u683c\u5f0f\u5b58\u50a8\u8bc4\u4f30\u7ed3\u679c\u5e76\u5b58\u5165\u6587\u4ef6 entry = {} entry [ 'text' ] = pred [ 'text' ] entry [ 'gold' ] = list ( gold_spo ) entry [ 'pred' ] = list ( pred_spo ) entry [ 'new' ] = list ( pred_spo - gold_spo ) entry [ 'lack' ] = list ( gold_spo - pred_spo ) json . dump ( entry , res_file , ensure_ascii = False , indent = 4 , separators = ( ',' , ':' )) # \u6309\u7167\u516c\u5f0f\u8ba1\u7b97presition, recall, f1\u7684\u503c eps = 1e-6 p = correct_num / ( pred_num + eps ) r = correct_num / ( gold_num + eps ) f1 = ( 2 * p * r ) / ( p + r + eps ) print ( 'f1: {} , precision: {} , recall: {} ' . format ( f1 , p , r )) return f1 , p , r if __name__ == '__main__' : f1 , p , r = evaluate () print ( 'f1: {} , precision: {} , recall: {} ' . format ( f1 , p , r ))","title":"\u7b2c\u56db\u6b65: \u8bc4\u4f30\u51fd\u6570\u7684\u5b9e\u73b0"},{"location":"4_2.html#_6","text":"\u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/casrel/train.py # \u5bfc\u5165\u5de5\u5177\u5305 import time from tqdm import tqdm import torch import torch.nn.functional as F from casrel import CasRel from torch.utils.data import DataLoader from dataloader import MyDataset , collate_fn from test import test_casrel from evaluate import evaluate # \u8bbe\u5b9a\u8bad\u7ec3\u8bbe\u5907(GPU, CPU) device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) torch . set_num_threads ( 6 ) # \u635f\u5931\u8ba1\u7b97\u51fd\u6570, \u5f53\u524d\u6a21\u578b\u91c7\u7528\u4e8c\u5206\u4ea4\u53c9\u71b5\u635f\u5931 def get_loss ( pred , gold , mask ): pred = pred . squeeze ( - 1 ) # \u6309\u7167\u4e8c\u5206\u4ea4\u53c9\u71b5\u635f\u5931\u8ba1\u7b97, \u5e76\u4ee5\u5411\u91cf\u5f62\u5f0f\u8fd4\u56deloss loss = F . binary_cross_entropy ( pred , gold . float (), reduction = 'none' ) # \u5c06mask\u5f20\u91cf\u7684\u7ef4\u5ea6\u6269\u5c55\u6210\u548closs\u4e00\u81f4 if loss . shape != mask . shape : mask = mask . unsqueeze ( - 1 ) # \u5bf9\u635f\u5931\u5f20\u91cf\u8fdb\u884c\u63a9\u7801\u8ba1\u7b97, \u5e76\u5f52\u4e00\u5316 loss = torch . sum ( loss * mask ) / torch . sum ( mask ) return loss if __name__ == '__main__' : config = { 'mode' : 'train' , 'batch_size' : 16 , 'epoch' : 50 , 'relation_types' : 53 , 'sub_weight' : 1 , 'obj_weight' : 1 } model_save_path = './saved_model/model_casrel.pt' f_dev_result = open ( './data/dev_result.txt' , 'a' , encoding = 'utf-8' ) best_f1_file = open ( './data/best_f1.txt' , 'a' , encoding = 'utf-8' ) # \u5b9e\u4f8b\u5316\u6570\u636e\u96c6\u5bf9\u8c61, \u5e76\u6784\u5efa\u8bad\u7ec3\u6570\u636e\u7684\u8fed\u4ee3\u5668 path_train = './data/CMeIE_train.json' data_train = MyDataset ( path_train , config ) dataloader_train = DataLoader ( data_train , batch_size = config [ 'batch_size' ], shuffle = True , collate_fn = collate_fn ) # \u5b9e\u4f8b\u5316Casrel\u6a21\u578b\u7c7b\u5bf9\u8c61 model = CasRel ( config ) . to ( device ) # \u5b9e\u4f8b\u5316\u4f18\u5316\u5668\u5bf9\u8c61 optimizer = torch . optim . Adam ( model . parameters (), lr = 1e-5 , betas = ( 0.9 , 0.999 )) best_f1 = 0.0 # \u7ecf\u5178\u53cc\u91cdfor\u5faa\u73af\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3 for epoch_index in range ( config [ 'epoch' ]): time_start = time . time () print ( \"epoch: %d ......\" % ( epoch_index )) for batch_index , ( sample , sub_start , sub_end , relation_start , relation_end , mask , sub_start_single , sub_end_single ) in tqdm ( enumerate ( dataloader_train )): batch_data = dict () batch_data [ 'token_ids' ] = sample batch_data [ 'mask' ] = mask batch_data [ 'sub_start' ] = sub_start_single batch_data [ 'sub_end' ] = sub_end_single # \u7ecf\u5178\"\u8001\u4e09\u6837\" optimizer . zero_grad () # \u6a21\u578b\u4f1a\u8fd4\u56de4\u4e2a\u91cd\u8981\u6307\u9488\u53d8\u91cf pred_sub_start , pred_sub_end , pred_obj_start , pred_obj_end = model ( batch_data ) # \u5bf94\u4e2a\u9884\u6d4b\u6307\u9488\u5206\u522b\u8ba1\u7b97\u4e8c\u5206\u4ea4\u53c9\u71b5\u635f\u5931 sub_start_loss = get_loss ( pred_sub_start , sub_start , mask ) sub_end_loss = get_loss ( pred_sub_end , sub_end , mask ) obj_start_loss = get_loss ( pred_obj_start , relation_start , mask ) obj_end_loss = get_loss ( pred_obj_end , relation_end , mask ) # subject\u7684\u635f\u5931\u653e\u5728\u4e00\u8d77\u8ba1\u7b97, object\u7684\u635f\u5931\u653e\u5728\u4e00\u8d77\u8ba1\u7b97, \u5206\u522b\u91c7\u7528\u4e0d\u540c\u7684\u6743\u91cd loss = config [ 'sub_weight' ] * ( sub_start_loss + sub_end_loss ) + config [ 'obj_weight' ] * ( obj_start_loss + obj_end_loss ) loss . backward () optimizer . step () if batch_index % 50 == 0 : print ( \"epoch: %d batch: %d loss: %f \" % ( epoch_index , batch_index , loss )) time_end = time . time () print ( \"successfully saved! time used = %f s.\" % ( time_end - time_start )) # \u6bcf\u4e00\u8f6eepoch\u8bad\u7ec3\u7ed3\u675f\u540e, \u8fdb\u884c\u4e00\u6b21\u9a8c\u8bc1\u96c6\u7684\u6548\u679c\u8bc4\u4f30 dev_file_path = './data/CMeIE_dev.json' res_path = './data/CMeIE_dev_result.json' config_dev = { 'mode' : 'dev' , 'batch_size' : 1 , 'relation_types' : 53 } print ( 'epoch: {} , \u5f00\u59cb\u9a8c\u8bc1\u96c6\u8bc4\u4f30...' . format ( epoch_index )) test_casrel ( model , dev_file_path , res_path , config_dev ) # \u9884\u6d4b\u7ed3\u675f\u540e, \u9700\u8981\u5728\u9a8c\u8bc1\u7ed3\u679c\u6570\u636e\u4e0a\u8fdb\u884c\u8bc4\u4f30 f1 , p , r = evaluate () temp_res = 'f1: {} , precision: {} , recall: {} ' . format ( f1 , p , r ) f_dev_result . write ( temp_res + ' \\n ' ) print ( 'epoch: {} , \u9a8c\u8bc1\u96c6\u8bc4\u4f30\u7ed3\u675f... \\n ' . format ( epoch_index )) print ( 'f1: {} , precision: {} , recall: {} ' . format ( f1 , p , r )) print ( ' \\n ' ) # \u5c06\u66f4\u4f18\u7684\u7ed3\u679c\u5199\u65e5\u5fd7\u4fdd\u5b58, \u5e76\u5c06\u66f4\u4f18\u7684\u6a21\u578b\u4fdd\u5b58 if f1 > best_f1 : best_f1 = f1 best_p = p best_r = r best_res = 'f1: {} , precision: {} , recall: {} ' . format ( best_f1 , best_p , best_r ) best_f1_file . write ( best_res + ' \\n ' ) torch . save ( model . state_dict (), model_save_path ) \u4ee3\u7801\u8def\u5f84: /home/ec2-user/information_extraction/relation/casrel/test.py import codecs import torch import torch.nn.functional as F from casrel import CasRel from torch.utils.data import DataLoader from dataloader import MyDataset , collate_fn import json import numpy as np device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) torch . set_num_threads ( 6 ) def trans_schemas ( path ): rel2sub = dict () rel2obj = dict () with open ( path , 'r' , encoding = 'utf-8' ) as f : sens = f . readlines () schemas = [] for sen in sens : schemas . append ( json . loads ( sen . strip ())) for entry in schemas : rel2sub [ entry [ 'predicate' ]] = entry [ 'subject_type' ] rel2obj [ entry [ 'predicate' ]] = entry [ 'object_type' ] return rel2sub , rel2obj def get_list ( start , end , text , h_bar = 0.5 , t_bar = 0.5 ): res = [] start , end = start [: 512 ], end [: 512 ] start_idxs , end_idxs = [], [] for idx in range ( len ( start )): if ( start [ idx ] > h_bar ): start_idxs . append ( idx ) if ( end [ idx ] > t_bar ): end_idxs . append ( idx ) for start_idx in start_idxs : for end_idx in end_idxs : if ( end_idx >= start_idx ): entry = {} entry [ 'text' ] = text [ start_idx : end_idx + 1 ] entry [ 'start' ] = start_idx entry [ 'end' ] = end_idx res . append ( entry ) break return res def get_text ( path ): with open ( path , 'r' , encoding = 'utf-8' ) as f : data = f . readlines () data = [ json . loads ( i ) for i in data ] return data def test_casrel ( model , path , res_path , config ): # \u8bbe\u7f6e\u6570\u636e\u96c6\u8def\u5f84 schemas_path = './data/53_schemas.json' res_file = codecs . open ( res_path , 'w' , encoding = 'utf-8' ) # \u8bfb\u53d6\u6d4b\u8bd5\u6587\u4ef6, \u5e76\u8bfb\u53d6schema\u6587\u4ef6\u5f97\u5230(\u5173\u7cfb-\u5b9e\u4f53)\u6620\u5c04\u5b57\u5178 raw_data = get_text ( path ) rel2sub , rel2obj = trans_schemas ( schemas_path ) # \u6784\u5efa\u6570\u636e\u8fed\u4ee3\u5668DataLoader data = MyDataset ( path , config ) dataloader = DataLoader ( data , batch_size = config [ 'batch_size' ], shuffle = False , collate_fn = collate_fn ) # \u5b9e\u4f8b\u5316CasRel\u7c7b\u5bf9\u8c61\u5e76\u52a0\u8f7d\u5df2\u8bad\u7ec3\u597d\u7684\u6a21\u578b # model = CasRel(config).to(device) # model.load_state_dict(torch.load('model_casrel.pt')) # \u5faa\u73af\u5904\u7406\u6d4b\u8bd5\u96c6\u6570\u636e, \u5e76\u5c06\u7ed3\u679c\u5199\u5165\u6587\u4ef6 # \u904d\u5386\u6d4b\u8bd5\u6570\u636e for batch_index , ( sample , sub_start , sub_end , relation_start , relation_end , mask , _ , _ ) in enumerate ( iter ( dataloader )): with torch . no_grad (): text = raw_data [ batch_index ][ 'text' ] batch_data = dict () batch_data [ 'token_ids' ] = sample batch_data [ 'mask' ] = mask batch_data [ 'text' ] = text ret = model . test ( batch_data ) spo_list = [] if ret : sub_list , pred_obj_start , pred_obj_end = ret # \u904d\u5386\u6a21\u578b\u9884\u6d4b\u7684subject\u5b9e\u4f53 for idx , sub in enumerate ( sub_list ): obj_start = pred_obj_start [ idx ] . transpose ( 0 , 1 ) obj_end = pred_obj_end [ idx ] . transpose ( 0 , 1 ) # \u904d\u538653\u79cd\u5173\u7cfb, \u5e76\u4f9d\u6b21\u7ec4\u5408\u6210\u7ed3\u679c\u5b57\u5178 for i in range ( config [ 'relation_types' ]): obj_list = get_list ( obj_start [ i ], obj_end [ i ], text ) # \u904d\u5386\u7b2ci\u79cd\u5173\u7cfb\u7684object\u5217\u8868 for obj in obj_list : entry = {} entry [ 'Combined' ] = '\u3002' in text [ sub [ 'end' ]: obj [ 'start' ]] or '\u3002' in text [ obj [ 'end' ]: sub [ 'start' ]] # \u4ee5\u4e0b5\u4e2a\u5b57\u5178\u5fc5\u987b\u6309\u7167\u56fa\u5b9a\u683c\u5f0f\u5199\u5165\u5b57\u5178 entry [ 'subject' ] = sub [ 'text' ] entry [ 'predicate' ] = data . idx2relation [ i ] entry [ 'object' ] = { '@value' : obj [ 'text' ]} entry [ 'subject_type' ] = rel2sub [ data . idx2relation [ i ]] entry [ 'object_type' ] = { '@value' : rel2obj [ data . idx2relation [ i ]]} spo_list . append ( entry ) # \u6700\u5916\u5c42for\u5faa\u73af\u7ed3\u675f, \u5c06\u5f53\u524d\u6279\u6b21\u6570\u636e(batch_size=1)\u7684\u9884\u6d4b\u7ed3\u679c\u5199\u5165\u6587\u4ef6\u4e2d. res = {} res [ 'text' ] = text res [ 'spo_list' ] = spo_list json . dump ( res , res_file , ensure_ascii = False ) res_file . write ( ' \\n ' ) if batch_index % 500 == 0 : print ( 'batch_index = ' , batch_index ) if __name__ == '__main__' : config = { 'mode' : 'test' , 'batch_size' : 1 , 'relation_types' : 53 } path = './data/CMeIE_test.json' res_path = './data/CMeIE_test_res.json' # \u5b9e\u4f8b\u5316CasRel\u7c7b\u5bf9\u8c61\u5e76\u52a0\u8f7d\u5df2\u8bad\u7ec3\u597d\u7684\u6a21\u578b model = CasRel ( config ) . to ( device ) model . load_state_dict ( torch . load ( './saved_model/model_casrel.pt' )) test_casrel ( model , path , res_path , config ) \u6ce8\u610f: \u5728Tesla T4 GPU\u73af\u5883\u4e0b, \u8fd0\u884c50\u4e2aepochs, \u5927\u7ea6\u8017\u65f612\u4e2a\u5c0f\u65f6. \u6700\u4f18\u8868\u73b0\u662fepoch=47\u65f6, F1=49.89%.","title":"\u7b2c\u4e94\u6b65: \u8bad\u7ec3\u548c\u6d4b\u8bd5\u4ee3\u7801\u7684\u5b9e\u73b0"},{"location":"4_3.html","text":"\u57fa\u4e8e\u89c4\u5219\u7684\u5173\u7cfb\u62bd\u53d6 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u7406\u89e3\u4ec0\u4e48\u662f\u89c4\u5219\u5316\u7684\u5173\u7cfb\u62bd\u53d6. \u638c\u63e1\u57fa\u4e8e\u89c4\u5219\u7684\u5173\u7cfb\u62bd\u53d6\u7684\u65b9\u6cd5. \u57fa\u4e8e\u89c4\u5219\u7684\u5173\u7cfb\u62bd\u53d6 \u00b6 \u9996\u5148\u57fa\u4e8e\u89c4\u5219\u548c\u4eba\u5de5\u62bd\u53d6\u5173\u7cfb\u8bcd, \u7136\u540e\u57fa\u4e8e\u62bd\u53d6\u7684\u5173\u7cfb\u8bcd\u62bd\u53d6\u5173\u7cfb\u53e5, \u6700\u540e\u57fa\u4e8e\u4eba\u5de5\u603b\u7ed3\u7684\u6a21\u677f\u7ed3\u5408\u540c\u4e49\u8bcd\u548cRE\u6a21\u5757\u8fdb\u884c\u6a21\u677f\u5339\u914d\u62bd\u53d6\u4e09\u5143\u7ec4. \u89c4\u5219\u62bd\u53d6\u6d41\u7a0b: \u5173\u7cfb\u8bcd\u62bd\u53d6 \u5173\u7cfb\u53e5\u62bd\u53d6 \u5173\u7cfb\u4e09\u5143\u7ec4\u62bd\u53d6 \u5173\u7cfb\u8bcd\u62bd\u53d6 \u00b6 \u5173\u7cfb\u8bcd\u62bd\u53d6: \u6240\u8c13\u7684\u5173\u7cfb\u8bcd\u5c31\u662f\u542b\u6709\u67d0\u4e2a\u5173\u7cfb\u7684\u53e5\u5b50, \u7ecf\u5e38\u51fa\u73b0\u5e76\u4e14\u7279\u5b9a\u7684\u8bcd. \u8fd9\u4e9b\u8bcd\u8981\u6709\u533a\u5206\u5ea6, \u4e0e\u5168\u5c40\u666e\u901a\u53e5\u5b50\u7684\u533a\u5206\u5ea6, \u4e0e\u5176\u4ed6\u5173\u7cfb\u53e5\u5b50\u7684\u533a\u5206\u5ea6. \u7b2c\u4e00\u6b65: \u5229\u7528TF-IDF\u7b97\u6cd5(\u6216\u8005TextRank)\u6bcf\u7c7b\u5173\u7cfb\u7684\u5173\u7cfb\u8bcd. \u7edf\u8ba1\u6bcf\u7c7b\u53e5\u5b50\u7684\u8bcd\u9891, \u5e76\u8fdb\u884c\u6392\u5e8f, \u62bd\u53d6\u5176\u4e2d\u5c40\u90e8\u5e38\u89c1\u4e14\u5168\u5c40\u5c11\u89c1\u7684\u8bcd. \u4eba\u5de5\u62bd\u53d6, \u5bf9\u4e1a\u52a1\u7684\u719f\u6089, \u7ecf\u9a8c\u4e3a\u4e3b. \u5305\u542b \u5305\u542b \u90e8\u5206 \u5305\u62ec \u6784\u6210 \u5206\u89e3\u6210 \u7ec4\u5408 \u7eb3\u5165 \u5206\u91cf \u6709\u4ee5\u4e0b \u6700\u91cd\u8981\u7684\u662f \u51b3\u5b9a \u51b3\u5b9a \u6b63\u76f8\u5173 \u9ad8 \u63d0\u9ad8 \u6b63\u76f8\u5173 \u8d8a\u5927 \u8d8a\u597d \u589e\u52a0 \u589e\u9ad8 \u8d8a\u5229\u4e8e \u6d89\u53ca \u6d89\u53ca \u5f71\u54cd \u5f71\u54cd \u4f9d\u636e \u4f9d\u636e \u800c\u5b9a \u53d6\u51b3\u4e8e \u57fa\u4e8e \u7b49\u4ef7 \u5373 \u53c8\u79f0 \u5b9a\u4e49\u4e3a \u4e5f\u53eb \u53c8\u53eb \u4e5f\u79f0\u4e4b\u4e3a \u987e\u53ca \u987e\u53ca \u524d\u63d0\u6761\u4ef6 \u6761\u4ef6 \u5236\u7ea6 \u5236\u7ea6 \u5173\u8054 \u5173\u8054 \u8054\u7cfb \u76f8\u5173 \u6709\u5173 \u8861\u91cf \u8861\u91cf \u540c\u5c5e \u5206\u4e3a \u7c7b\u578b \u8d1f\u76f8\u5173 \u8d1f\u76f8\u5173 \u8d8a\u5c11 \u8d8a\u591a \u8d8a\u5c0f \u8d8a\u5927 \u964d\u4f4e \u63d0\u9ad8 \u8f85\u52a9 \u8f85\u52a9 \u9a71\u52a8 \u9a71\u52a8 \u6302\u94a9 \u6302\u94a9 \u56e0\u679c \u539f\u56e0 \u7f18\u7531 \u968f\u7740 \u652f\u4ed8 \u652f\u4ed8 \u4ed8\u6b3e \u4ed8\u94b1 \u5173\u7cfb\u53e5\u62bd\u53d6 \u00b6 \u7b2c\u4e8c\u6b65: \u5173\u7cfb\u53e5\u7684\u63d0\u53d6(\u57fa\u4e8e\u7b2c\u4e00\u6b65\u7684\u5173\u7cfb\u8bcd) \u6839\u636e\u6bcf\u7c7b\u5173\u7cfb\u8bcd, \u8bbe\u7f6e\u9608\u503c\u62bd\u53d6\u6bcf\u7c7b\u5173\u7cfb\u7684\u5173\u7cfb\u53e5(\u5bf9\u5173\u7cfb\u8bcd\u9ad8\u5ea6\u4f9d\u8d56) \u6839\u636e\u89c4\u5219, \u542b\u6709\u67d0\u4e2a\u5173\u7cfb\u7684\u5173\u7cfb\u8bcd\u7684\u53e5\u5b50\u5224\u5b9a\u4e3a\u8be5\u5173\u7cfb\u7684\u5173\u7cfb\u53e5 # \u4e0b\u9762\u5c55\u793a\u7684\u662f\"\u5305\u542b\"\u5173\u7cfb\u8bcd\u5bf9\u5e94\u7684\u5173\u7cfb\u53e5 \u6839\u636e\u8fd9\u4e2a\u7cfb\u7edf, \u6240\u6709\u804c\u52a1\u6240\u5305\u542b\u7684\u6700\u4e3b\u8981\u7684\u4ed8\u916c\u56e0\u7d20\u6709\u4e09\u79cd. \u5e38\u7528\u7684\u65b9\u6cd5\u65f6\u5229\u7528\u59d4\u5458\u4f1a\u6216\u7531\u6765\u81ea\u91cd\u8981\u804c\u80fd\u90e8\u95e8\u7684\u4ee3\u8868\u7ec4\u6210\u7684\u56e2\u4f53, \u8fd9\u4e9b\u4ee3\u8868\u5305\u62ec\u7ba1\u7406\u4eba\u5458\u548c\u666e\u901a\u5458\u5de5. \u8c03\u67e5\u5185\u5bb9\u53d6\u51b3\u4e8e\u8c03\u67e5\u76ee\u7684\u548c\u8c03\u67e5\u4e2d\u6240\u5305\u62ec\u7684\u804c\u4f4d. \u5e94\u6839\u636e\u4e00\u5b9a\u7684\u6807\u51c6\u5c06\u5458\u5de5\u6216\u4eba\u529b\u8d44\u672c\u5206\u89e3\u6210\u4e0d\u540c\u79cd\u7c7b, \u5bf9\u6bcf\u4e00\u7c7b\u522b\u7684\u4eba\u5458\u91c7\u53d6\u4e0d\u540c\u7684\u4eba\u529b\u8d44\u6e90\u7ba1\u7406\u6a21\u5f0f. \u786e\u5b9a\u4f01\u4e1a\u7684\u85aa\u916c\u7ed3\u6784\u4e3b\u8981\u6709\u4ee5\u4e0b\u4e09\u65b9\u9762\u7684\u5de5\u4f5c: \u5206\u7b49; \u786e\u5b9a\u6bcf\u7b49\u5bf9\u5e94\u7684\u85aa\u916c\u533a\u95f4; \u786e\u5b9a\u76f8\u90bb\u7b49\u4e4b\u95f4\u7684\u4ea4\u53c9\u8303\u56f4. \u5173\u7cfb\u4e09\u5143\u7ec4\u62bd\u53d6 \u00b6 \u7b2c\u4e09\u6b65: \u5173\u7cfb\u4e09\u5143\u7ec4\u62bd\u53d6(\u57fa\u4e8e\u7b2c\u4e8c\u6b65\u7684\u5173\u7cfb\u53e5\u603b\u7ed3\u6a21\u677f) \u4eba\u5de5\u5b9a\u4e49\u6a21\u677f: A-\u5934\u5b9e\u4f53, B-\u5c3e\u5b9e\u4f53 # \u4e0b\u9762\u5c55\u793a\u7684\u662f\"\u5305\u542b\"\u5173\u7cfb\u53e5\u6240\u5bf9\u5e94\u7684\u6a21\u677f, \u5168\u90e8\u7531\u4eba\u5de5\u89c2\u5bdf\u603b\u7ed3\u5f97\u51fa B \u662f\u4f5c\u4e3a A \u90e8\u5206 A \u5305\u542b B A \u7531 B \u7ec4\u6210 A \u662f B \u7ec4\u6210 A \u7531 B \u6784\u6210 A \u662f B \u6784\u6210 A \u7531\u4ee5\u4e0b B A \u5f62\u5f0f\u6709 B A \u5206\u89e3\u6210 B A \u4e3b\u8981\u6709 B A \u4e3b\u8981\u6709 B \u6784\u6210 B \u662f A \u7684\u96be\u70b9 A \u6700\u91cd\u8981\u7684\u662f B A ( B , \u6709\u4e86\u4e0a\u9762\u7b2c\u4e09\u6b65\u603b\u7ed3\u7684\u4eba\u5de5\u6a21\u677f, \u63a5\u4e0b\u6765\u57fa\u4e8ere\u6b63\u5219\u8868\u8fbe\u5f0f\u8fdb\u884c\u5339\u914d\u5373\u53ef! \u4f8b\u5982: re = (.*) [\u662f|\u7531] (.*)\u7ec4\u6210 ; re = (.*)\u7531\u4ee5\u4e0b(.*) \u89c4\u5219\u6d3e\u5173\u7cfb\u62bd\u53d6\u7684\u53e6\u4e00\u79cd\u5b9e\u73b0 \u00b6 \u5728\u7ea2\u8718\u86db\u9879\u76ee\u4e2d, \u56e0\u4e3a\u6709\u4e00\u4e9b\u6570\u636e\u662f\u722c\u866b\u5f97\u6765\u7684, \u90a3\u4e48\u6211\u4eec\u57fa\u4e8e\u722c\u866b\u89c4\u5219\u7684\u4fbf\u5229, \u53ef\u4ee5\u76f4\u63a5\"\u9501\u5b9a\"\u4e00\u4e9b\u5173\u7cfb. \u5728\u672c\u9879\u76ee\u4e2d, \u6bd4\u5982\u6211\u4eec\u8bbe\u5b9a\u4ee5\"\u75be\u75c5\u540d\u79f0\"\u4e3a\u722c\u53d6\u6570\u636e\u7684\u6587\u4ef6\u540d\u79f0, \u5bf9\u540c\u4e00\u79cd\u75be\u75c5\u540d\u79f0\u4e0b\u7684\u7f51\u9875\u4e2d\u5c55\u793a\u7684\u6240\u6709\"\u75be\u75c5\u75c7\u72b6\"\u5168\u90e8\u5b58\u5165\u8fd9\u4e2a\u6587\u4ef6\u4e2d. \u8fd9\u6837(\u75be\u75c5\u540d\u79f0, \u5177\u6709, \u75be\u75c5\u75c7\u72b6)\u8fd9\u6837\u7684\u4e09\u5143\u7ec4\u4fbf\u5929\u7136\u7684\u5b58\u5728\u4e86, \u800c\u4e14\u5177\u5907\u9ad8\u5ea6\u53ef\u4fe1\u7684\u7279\u70b9.","title":"4.3 \u57fa\u4e8e\u89c4\u5219\u6d3e\u7684RE"},{"location":"4_3.html#_1","text":"","title":"\u57fa\u4e8e\u89c4\u5219\u7684\u5173\u7cfb\u62bd\u53d6"},{"location":"4_3.html#_2","text":"\u7406\u89e3\u4ec0\u4e48\u662f\u89c4\u5219\u5316\u7684\u5173\u7cfb\u62bd\u53d6. \u638c\u63e1\u57fa\u4e8e\u89c4\u5219\u7684\u5173\u7cfb\u62bd\u53d6\u7684\u65b9\u6cd5.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"4_3.html#_3","text":"\u9996\u5148\u57fa\u4e8e\u89c4\u5219\u548c\u4eba\u5de5\u62bd\u53d6\u5173\u7cfb\u8bcd, \u7136\u540e\u57fa\u4e8e\u62bd\u53d6\u7684\u5173\u7cfb\u8bcd\u62bd\u53d6\u5173\u7cfb\u53e5, \u6700\u540e\u57fa\u4e8e\u4eba\u5de5\u603b\u7ed3\u7684\u6a21\u677f\u7ed3\u5408\u540c\u4e49\u8bcd\u548cRE\u6a21\u5757\u8fdb\u884c\u6a21\u677f\u5339\u914d\u62bd\u53d6\u4e09\u5143\u7ec4. \u89c4\u5219\u62bd\u53d6\u6d41\u7a0b: \u5173\u7cfb\u8bcd\u62bd\u53d6 \u5173\u7cfb\u53e5\u62bd\u53d6 \u5173\u7cfb\u4e09\u5143\u7ec4\u62bd\u53d6","title":"\u57fa\u4e8e\u89c4\u5219\u7684\u5173\u7cfb\u62bd\u53d6"},{"location":"4_3.html#_4","text":"\u5173\u7cfb\u8bcd\u62bd\u53d6: \u6240\u8c13\u7684\u5173\u7cfb\u8bcd\u5c31\u662f\u542b\u6709\u67d0\u4e2a\u5173\u7cfb\u7684\u53e5\u5b50, \u7ecf\u5e38\u51fa\u73b0\u5e76\u4e14\u7279\u5b9a\u7684\u8bcd. \u8fd9\u4e9b\u8bcd\u8981\u6709\u533a\u5206\u5ea6, \u4e0e\u5168\u5c40\u666e\u901a\u53e5\u5b50\u7684\u533a\u5206\u5ea6, \u4e0e\u5176\u4ed6\u5173\u7cfb\u53e5\u5b50\u7684\u533a\u5206\u5ea6. \u7b2c\u4e00\u6b65: \u5229\u7528TF-IDF\u7b97\u6cd5(\u6216\u8005TextRank)\u6bcf\u7c7b\u5173\u7cfb\u7684\u5173\u7cfb\u8bcd. \u7edf\u8ba1\u6bcf\u7c7b\u53e5\u5b50\u7684\u8bcd\u9891, \u5e76\u8fdb\u884c\u6392\u5e8f, \u62bd\u53d6\u5176\u4e2d\u5c40\u90e8\u5e38\u89c1\u4e14\u5168\u5c40\u5c11\u89c1\u7684\u8bcd. \u4eba\u5de5\u62bd\u53d6, \u5bf9\u4e1a\u52a1\u7684\u719f\u6089, \u7ecf\u9a8c\u4e3a\u4e3b. \u5305\u542b \u5305\u542b \u90e8\u5206 \u5305\u62ec \u6784\u6210 \u5206\u89e3\u6210 \u7ec4\u5408 \u7eb3\u5165 \u5206\u91cf \u6709\u4ee5\u4e0b \u6700\u91cd\u8981\u7684\u662f \u51b3\u5b9a \u51b3\u5b9a \u6b63\u76f8\u5173 \u9ad8 \u63d0\u9ad8 \u6b63\u76f8\u5173 \u8d8a\u5927 \u8d8a\u597d \u589e\u52a0 \u589e\u9ad8 \u8d8a\u5229\u4e8e \u6d89\u53ca \u6d89\u53ca \u5f71\u54cd \u5f71\u54cd \u4f9d\u636e \u4f9d\u636e \u800c\u5b9a \u53d6\u51b3\u4e8e \u57fa\u4e8e \u7b49\u4ef7 \u5373 \u53c8\u79f0 \u5b9a\u4e49\u4e3a \u4e5f\u53eb \u53c8\u53eb \u4e5f\u79f0\u4e4b\u4e3a \u987e\u53ca \u987e\u53ca \u524d\u63d0\u6761\u4ef6 \u6761\u4ef6 \u5236\u7ea6 \u5236\u7ea6 \u5173\u8054 \u5173\u8054 \u8054\u7cfb \u76f8\u5173 \u6709\u5173 \u8861\u91cf \u8861\u91cf \u540c\u5c5e \u5206\u4e3a \u7c7b\u578b \u8d1f\u76f8\u5173 \u8d1f\u76f8\u5173 \u8d8a\u5c11 \u8d8a\u591a \u8d8a\u5c0f \u8d8a\u5927 \u964d\u4f4e \u63d0\u9ad8 \u8f85\u52a9 \u8f85\u52a9 \u9a71\u52a8 \u9a71\u52a8 \u6302\u94a9 \u6302\u94a9 \u56e0\u679c \u539f\u56e0 \u7f18\u7531 \u968f\u7740 \u652f\u4ed8 \u652f\u4ed8 \u4ed8\u6b3e \u4ed8\u94b1","title":"\u5173\u7cfb\u8bcd\u62bd\u53d6"},{"location":"4_3.html#_5","text":"\u7b2c\u4e8c\u6b65: \u5173\u7cfb\u53e5\u7684\u63d0\u53d6(\u57fa\u4e8e\u7b2c\u4e00\u6b65\u7684\u5173\u7cfb\u8bcd) \u6839\u636e\u6bcf\u7c7b\u5173\u7cfb\u8bcd, \u8bbe\u7f6e\u9608\u503c\u62bd\u53d6\u6bcf\u7c7b\u5173\u7cfb\u7684\u5173\u7cfb\u53e5(\u5bf9\u5173\u7cfb\u8bcd\u9ad8\u5ea6\u4f9d\u8d56) \u6839\u636e\u89c4\u5219, \u542b\u6709\u67d0\u4e2a\u5173\u7cfb\u7684\u5173\u7cfb\u8bcd\u7684\u53e5\u5b50\u5224\u5b9a\u4e3a\u8be5\u5173\u7cfb\u7684\u5173\u7cfb\u53e5 # \u4e0b\u9762\u5c55\u793a\u7684\u662f\"\u5305\u542b\"\u5173\u7cfb\u8bcd\u5bf9\u5e94\u7684\u5173\u7cfb\u53e5 \u6839\u636e\u8fd9\u4e2a\u7cfb\u7edf, \u6240\u6709\u804c\u52a1\u6240\u5305\u542b\u7684\u6700\u4e3b\u8981\u7684\u4ed8\u916c\u56e0\u7d20\u6709\u4e09\u79cd. \u5e38\u7528\u7684\u65b9\u6cd5\u65f6\u5229\u7528\u59d4\u5458\u4f1a\u6216\u7531\u6765\u81ea\u91cd\u8981\u804c\u80fd\u90e8\u95e8\u7684\u4ee3\u8868\u7ec4\u6210\u7684\u56e2\u4f53, \u8fd9\u4e9b\u4ee3\u8868\u5305\u62ec\u7ba1\u7406\u4eba\u5458\u548c\u666e\u901a\u5458\u5de5. \u8c03\u67e5\u5185\u5bb9\u53d6\u51b3\u4e8e\u8c03\u67e5\u76ee\u7684\u548c\u8c03\u67e5\u4e2d\u6240\u5305\u62ec\u7684\u804c\u4f4d. \u5e94\u6839\u636e\u4e00\u5b9a\u7684\u6807\u51c6\u5c06\u5458\u5de5\u6216\u4eba\u529b\u8d44\u672c\u5206\u89e3\u6210\u4e0d\u540c\u79cd\u7c7b, \u5bf9\u6bcf\u4e00\u7c7b\u522b\u7684\u4eba\u5458\u91c7\u53d6\u4e0d\u540c\u7684\u4eba\u529b\u8d44\u6e90\u7ba1\u7406\u6a21\u5f0f. \u786e\u5b9a\u4f01\u4e1a\u7684\u85aa\u916c\u7ed3\u6784\u4e3b\u8981\u6709\u4ee5\u4e0b\u4e09\u65b9\u9762\u7684\u5de5\u4f5c: \u5206\u7b49; \u786e\u5b9a\u6bcf\u7b49\u5bf9\u5e94\u7684\u85aa\u916c\u533a\u95f4; \u786e\u5b9a\u76f8\u90bb\u7b49\u4e4b\u95f4\u7684\u4ea4\u53c9\u8303\u56f4.","title":"\u5173\u7cfb\u53e5\u62bd\u53d6"},{"location":"4_3.html#_6","text":"\u7b2c\u4e09\u6b65: \u5173\u7cfb\u4e09\u5143\u7ec4\u62bd\u53d6(\u57fa\u4e8e\u7b2c\u4e8c\u6b65\u7684\u5173\u7cfb\u53e5\u603b\u7ed3\u6a21\u677f) \u4eba\u5de5\u5b9a\u4e49\u6a21\u677f: A-\u5934\u5b9e\u4f53, B-\u5c3e\u5b9e\u4f53 # \u4e0b\u9762\u5c55\u793a\u7684\u662f\"\u5305\u542b\"\u5173\u7cfb\u53e5\u6240\u5bf9\u5e94\u7684\u6a21\u677f, \u5168\u90e8\u7531\u4eba\u5de5\u89c2\u5bdf\u603b\u7ed3\u5f97\u51fa B \u662f\u4f5c\u4e3a A \u90e8\u5206 A \u5305\u542b B A \u7531 B \u7ec4\u6210 A \u662f B \u7ec4\u6210 A \u7531 B \u6784\u6210 A \u662f B \u6784\u6210 A \u7531\u4ee5\u4e0b B A \u5f62\u5f0f\u6709 B A \u5206\u89e3\u6210 B A \u4e3b\u8981\u6709 B A \u4e3b\u8981\u6709 B \u6784\u6210 B \u662f A \u7684\u96be\u70b9 A \u6700\u91cd\u8981\u7684\u662f B A ( B , \u6709\u4e86\u4e0a\u9762\u7b2c\u4e09\u6b65\u603b\u7ed3\u7684\u4eba\u5de5\u6a21\u677f, \u63a5\u4e0b\u6765\u57fa\u4e8ere\u6b63\u5219\u8868\u8fbe\u5f0f\u8fdb\u884c\u5339\u914d\u5373\u53ef! \u4f8b\u5982: re = (.*) [\u662f|\u7531] (.*)\u7ec4\u6210 ; re = (.*)\u7531\u4ee5\u4e0b(.*)","title":"\u5173\u7cfb\u4e09\u5143\u7ec4\u62bd\u53d6"},{"location":"4_3.html#_7","text":"\u5728\u7ea2\u8718\u86db\u9879\u76ee\u4e2d, \u56e0\u4e3a\u6709\u4e00\u4e9b\u6570\u636e\u662f\u722c\u866b\u5f97\u6765\u7684, \u90a3\u4e48\u6211\u4eec\u57fa\u4e8e\u722c\u866b\u89c4\u5219\u7684\u4fbf\u5229, \u53ef\u4ee5\u76f4\u63a5\"\u9501\u5b9a\"\u4e00\u4e9b\u5173\u7cfb. \u5728\u672c\u9879\u76ee\u4e2d, \u6bd4\u5982\u6211\u4eec\u8bbe\u5b9a\u4ee5\"\u75be\u75c5\u540d\u79f0\"\u4e3a\u722c\u53d6\u6570\u636e\u7684\u6587\u4ef6\u540d\u79f0, \u5bf9\u540c\u4e00\u79cd\u75be\u75c5\u540d\u79f0\u4e0b\u7684\u7f51\u9875\u4e2d\u5c55\u793a\u7684\u6240\u6709\"\u75be\u75c5\u75c7\u72b6\"\u5168\u90e8\u5b58\u5165\u8fd9\u4e2a\u6587\u4ef6\u4e2d. \u8fd9\u6837(\u75be\u75c5\u540d\u79f0, \u5177\u6709, \u75be\u75c5\u75c7\u72b6)\u8fd9\u6837\u7684\u4e09\u5143\u7ec4\u4fbf\u5929\u7136\u7684\u5b58\u5728\u4e86, \u800c\u4e14\u5177\u5907\u9ad8\u5ea6\u53ef\u4fe1\u7684\u7279\u70b9.","title":"\u89c4\u5219\u6d3e\u5173\u7cfb\u62bd\u53d6\u7684\u53e6\u4e00\u79cd\u5b9e\u73b0"},{"location":"4_4.html","text":"\u5173\u7cfb\u62bd\u53d6\u7684\u4f18\u5316\u548c\u524d\u6cbf\u4ecb\u7ecd \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u7406\u89e3RE\u95ee\u9898\u7684\u4f18\u5316\u601d\u8def. \u4e86\u89e3\u5173\u7cfb\u62bd\u53d6\u7684\u524d\u6cbf\u8fdb\u5c55. \u5173\u7cfb\u62bd\u53d6\u7684\u4f18\u5316 \u00b6 \u5173\u7cfb\u62bd\u53d6\u7684\u524d\u6cbf\u8fdb\u5c55 \u00b6 \u5c0f\u8282\u603b\u7ed3 \u00b6","title":"4 4"},{"location":"4_4.html#_1","text":"","title":"\u5173\u7cfb\u62bd\u53d6\u7684\u4f18\u5316\u548c\u524d\u6cbf\u4ecb\u7ecd"},{"location":"4_4.html#_2","text":"\u7406\u89e3RE\u95ee\u9898\u7684\u4f18\u5316\u601d\u8def. \u4e86\u89e3\u5173\u7cfb\u62bd\u53d6\u7684\u524d\u6cbf\u8fdb\u5c55.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"4_4.html#_3","text":"","title":"\u5173\u7cfb\u62bd\u53d6\u7684\u4f18\u5316"},{"location":"4_4.html#_4","text":"","title":"\u5173\u7cfb\u62bd\u53d6\u7684\u524d\u6cbf\u8fdb\u5c55"},{"location":"4_4.html#_5","text":"","title":"\u5c0f\u8282\u603b\u7ed3"},{"location":"5_1.html","text":"\u4e8b\u4ef6\u62bd\u53d6 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u7406\u89e3\u4e2d\u6587\u573a\u666f\u4e0b\u4e8b\u4ef6\u62bd\u53d6\u7684\u6982\u5ff5. \u7406\u89e3\u4e8b\u4ef6\u62bd\u53d6\u7684\u4e3b\u6d41\u65b9\u6cd5. \u4e8b\u4ef6\u62bd\u53d6\u6982\u5ff5 \u00b6 \u4e8b\u4ef6\u62bd\u53d6: \u662f\u5c06\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u7684\u4e8b\u4ef6\u4fe1\u606f\u5c55\u73b0\u4e3a\u7ed3\u6784\u5316\u7684\u5f62\u5f0f, \u5728\u8206\u60c5\u76d1\u6d4b, \u6587\u672c\u6458\u8981, \u81ea\u52a8\u95ee\u7b54, \u4e8b\u7406\u56fe\u8c31\u81ea\u52a8\u6784\u5efa\u7b49\u9886\u57df\u6709\u7740\u91cd\u8981\u5e94\u7528. \u4e8b\u4ef6\u62bd\u53d6\u4efb\u52a1\u65e8\u5728\u4ece\u901a\u7528\u6587\u672c(\u6216\u5782\u76f4\u9886\u57df\u4e13\u4e1a\u6587\u672c)\u4e2d\u62bd\u53d63\u4ef6\u5173\u952e\u4fe1\u606f: 1: \u4e8b\u4ef6\u89e6\u53d1\u8bcd 2: \u4e8b\u4ef6\u8bba\u5143 3: \u4e8b\u4ef6\u5c5e\u6027 \u5728\u4f20\u7edf\u7684\u4e8b\u4ef6\u5b9a\u4e49\u4e2d, \u4e8b\u4ef6\u7531\u4e8b\u4ef6\u89e6\u53d1\u8bcd(Trigger)\u548c\u63cf\u8ff0\u4e8b\u4ef6\u7ed3\u6784\u7684\u5143\u7d20(Argument)\u6784\u6210. \u4e8b\u4ef6\u89e6\u53d1\u8bcd\u6807\u8bc6\u7740\u4e8b\u4ef6\u7684\u53d1\u751f, \u4e8b\u4ef6\u8bba\u5143\u4e3a\u4e8b\u4ef6\u4e3b\u4f53(Subject), \u5ba2\u4f53(Object), \u65f6\u95f4(Time), \u5730\u70b9(Location)\u7b49, \u662f\u8868\u8fbe\u4e8b\u4ef6\u91cd\u8981\u4fe1\u606f\u7684\u8f7d\u4f53. \u4e8b\u4ef6\u5c5e\u6027: \u5305\u62ec\u4e8b\u4ef6\u6781\u6027(Polarity), \u65f6\u6001(Tense), \u662f\u8861\u91cf\u4e8b\u4ef6\u662f\u5426\u771f\u5b9e\u53d1\u751f\u7684\u91cd\u8981\u4f9d\u636e. \u6781\u6027: \u4e8b\u4ef6\u5206\u4e3a\u80af\u5b9a, \u5426\u5b9a, \u53ef\u80fd\u4e8b\u4ef6. \u65f6\u6001: \u4e8b\u4ef6\u5206\u4e3a\u8fc7\u53bb\u65f6, \u73b0\u5728\u65f6, \u5c06\u6765\u65f6, \u5176\u4ed6\u65e0\u6cd5\u786e\u5b9a\u65f6\u6001\u7684\u4e8b\u4ef6. \u6ce8\u610f: \u5728\u771f\u5b9e\u4e16\u754c\u7684\u6587\u672c\u4e2d(\u901a\u7528, \u4e13\u4e1a), \u7531\u4e8e\u6587\u672c\u4e2d\u53ef\u80fd\u5b58\u5728\u53e5\u5f0f\u590d\u6742, \u4e3b\u88ab\u52a8\u8f6c\u6362, \u591a\u4e8b\u4ef6\u4e3b\u5ba2\u4f53\u5171\u4eab\u7b49\u96be\u70b9, \u56e0\u6b64\"\u4e8b\u4ef6\u62bd\u53d6\"\u662fNLP\u4e2d\u4e00\u9879\u6781\u5177\u6311\u6218\u7684\u4efb\u52a1!!! \u793a\u4f8b1: \u5317\u4eac\u65f6\u95f43\u670827\u65e5\u665a\u4e0a7\u70b915\u5206, \u82f1\u56fd\u9996\u76f8\u9c8d\u91cc\u65af.\u7ea6\u7ff0\u900a\u786e\u8bca\u611f\u67d3\u4e86\u65b0\u51a0\u80ba\u708e. \u89e6\u53d1\u8bcd \u4e3b\u4f53 \u5ba2\u4f53 \u65f6\u95f4 \u5730\u70b9 \u611f\u67d3 \u82f1\u56fd\u9996\u5148\u9c8d\u91cc\u65af \u65b0\u51a0\u80ba\u708e \u5317\u4eac\u65f6\u95f43\u670827\u65e5 \u65e0 \u793a\u4f8b2: \u8fc7\u6e21\u653f\u5e9c\u90e8\u961f\u53d1\u8a00\u4eba\u79f0, \u5317\u7ea6\u6218\u673a16\u65e5\u5728\u82cf\u5c14\u7279\u9644\u8fd1\u51fb\u4e2d\u4e86\u4e00\u5ea7\u5efa\u7b51, \u70b8\u6b7b\u5927\u6279\u5361\u624e\u83f2\u90e8\u961f\u58eb\u5175. \u89e6\u53d1\u8bcd \u4e3b\u4f53 \u5ba2\u4f53 \u65f6\u95f4 \u5730\u70b9 \u51fb\u4e2d \u5317\u7ea6\u6218\u673a \u4e00\u5ea7\u5efa\u7b51 16\u65e5 \u82cf\u5c14\u7279\u9644\u8fd1 \u70b8\u6b7b \u5317\u7ea6\u6218\u673a \u5927\u6279\u5361\u624e\u83f2\u90e8\u961f\u58eb\u5175 16\u65e5 \u82cf\u5c14\u7279\u9644\u8fd1 \u793a\u4f8b3: \u8fc7\u5f80\u4e16\u536b\u7ec4\u7ec7\u66fe5\u5ea6\u5ba3\u5e03\"\u56fd\u9645\u5173\u6ce8\u516c\u5171\u536b\u751f\u7d27\u6025\u4e8b\u4ef6\". \u89e6\u53d1\u8bcd \u6781\u6027 \u65f6\u6001 \u5ba3\u5e03 \u80af\u5b9a \u8fc7\u53bb\u65f6 \u793a\u4f8b4: \u82f1\u56fd\u5f88\u53ef\u80fd\u5c06\u6062\u590d\u63a5\u53d7\u4e16\u754c\u8d38\u6613\u7ec4\u7ec7\u6761\u6b3e\u7684\u89c4\u8303. \u89e6\u53d1\u8bcd \u6781\u6027 \u65f6\u6001 \u6062\u590d\u63a5\u53d7 \u53ef\u80fd \u5c06\u6765\u65f6 \u4e8b\u4ef6\u62bd\u53d6\u65b9\u6cd5 \u00b6 \u4e8b\u4ef6\u62bd\u53d6\u5efa\u7acb\u5728NER\u4efb\u52a1, RE\u4efb\u52a1\u4e4b\u4e0a, \u65b9\u6cd5\u4e5f\u53ef\u4ee5\u4e92\u76f8\u501f\u9274: pipeline\u65b9\u6cd5: \u4e24\u9636\u6bb5\u5904\u7406, \u5148\u62bd\u53d6\u89e6\u53d1\u8bcd, \u518d\u5229\u7528\u89e6\u53d1\u8bcd\u5bf9\u4e8b\u4ef6\u8bba\u5143\u8fdb\u884c\u69fd\u586b\u5145. joint\u65b9\u6cd5: \u4ee5\u6587\u672c\u4f5c\u4e3a\u8f93\u5165, \u5145\u5206\u8003\u8651\u89e6\u53d1\u8bcd\u4e0e\u8bba\u5143\u4e4b\u95f4\u7684\u4f9d\u8d56\u6027, \u7efc\u5408\u62bd\u53d6\u51fa\u89e6\u53d1\u8bcd\u548c\u5bf9\u5e94\u7684\u8bba\u5143. pipeline\u65b9\u6cd5: \u4f18\u70b9: \u7b80\u5355, \u53ef\u4ee5\u72ec\u7acb\u4f18\u5316\u4e0d\u540c\u7684\u6a21\u5757. \u7f3a\u70b9: \u548cRE\u4efb\u52a1\u7c7b\u4f3c, \u6a21\u578b\u5177\u6709\u4f20\u64ad\u8bef\u5dee. joint\u65b9\u6cd5: \u4f18\u70b9: \u907f\u514d\u4f20\u64ad\u8bef\u5dee, \u5145\u5206\u8003\u8651\u89e6\u53d1\u8bcd\u4e0e\u8bba\u5143\u4e4b\u95f4\u7684\u4f9d\u8d56\u6027. \u7f3a\u70b9: \u6a21\u578b\u590d\u6742, \u8bbe\u8ba1\u56f0\u96be, \u65e0\u6cd5\u8fdb\u884c\u6a21\u5757\u5316\u4f18\u5316. \u76ee\u524d\u5de5\u4e1a\u754c\u7684\u4e3b\u6d41\u65b9\u6cd5\u662fjoint\u65b9\u6cd5, \u5177\u4f53\u65b9\u6848\u6bd4\u5982\u91c7\u7528\u57fa\u4e8eBERT\u7684EE\u65b9\u6cd5, \u6216\u8005\u57fa\u4e8e\u7ea7\u8054\u7684EE\u65b9\u6cd5.","title":"5.1 \u4e2d\u6587\u573a\u666f\u4e0b\u7684\u4e8b\u4ef6\u62bd\u53d6"},{"location":"5_1.html#_1","text":"","title":"\u4e8b\u4ef6\u62bd\u53d6"},{"location":"5_1.html#_2","text":"\u7406\u89e3\u4e2d\u6587\u573a\u666f\u4e0b\u4e8b\u4ef6\u62bd\u53d6\u7684\u6982\u5ff5. \u7406\u89e3\u4e8b\u4ef6\u62bd\u53d6\u7684\u4e3b\u6d41\u65b9\u6cd5.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"5_1.html#_3","text":"\u4e8b\u4ef6\u62bd\u53d6: \u662f\u5c06\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u7684\u4e8b\u4ef6\u4fe1\u606f\u5c55\u73b0\u4e3a\u7ed3\u6784\u5316\u7684\u5f62\u5f0f, \u5728\u8206\u60c5\u76d1\u6d4b, \u6587\u672c\u6458\u8981, \u81ea\u52a8\u95ee\u7b54, \u4e8b\u7406\u56fe\u8c31\u81ea\u52a8\u6784\u5efa\u7b49\u9886\u57df\u6709\u7740\u91cd\u8981\u5e94\u7528. \u4e8b\u4ef6\u62bd\u53d6\u4efb\u52a1\u65e8\u5728\u4ece\u901a\u7528\u6587\u672c(\u6216\u5782\u76f4\u9886\u57df\u4e13\u4e1a\u6587\u672c)\u4e2d\u62bd\u53d63\u4ef6\u5173\u952e\u4fe1\u606f: 1: \u4e8b\u4ef6\u89e6\u53d1\u8bcd 2: \u4e8b\u4ef6\u8bba\u5143 3: \u4e8b\u4ef6\u5c5e\u6027 \u5728\u4f20\u7edf\u7684\u4e8b\u4ef6\u5b9a\u4e49\u4e2d, \u4e8b\u4ef6\u7531\u4e8b\u4ef6\u89e6\u53d1\u8bcd(Trigger)\u548c\u63cf\u8ff0\u4e8b\u4ef6\u7ed3\u6784\u7684\u5143\u7d20(Argument)\u6784\u6210. \u4e8b\u4ef6\u89e6\u53d1\u8bcd\u6807\u8bc6\u7740\u4e8b\u4ef6\u7684\u53d1\u751f, \u4e8b\u4ef6\u8bba\u5143\u4e3a\u4e8b\u4ef6\u4e3b\u4f53(Subject), \u5ba2\u4f53(Object), \u65f6\u95f4(Time), \u5730\u70b9(Location)\u7b49, \u662f\u8868\u8fbe\u4e8b\u4ef6\u91cd\u8981\u4fe1\u606f\u7684\u8f7d\u4f53. \u4e8b\u4ef6\u5c5e\u6027: \u5305\u62ec\u4e8b\u4ef6\u6781\u6027(Polarity), \u65f6\u6001(Tense), \u662f\u8861\u91cf\u4e8b\u4ef6\u662f\u5426\u771f\u5b9e\u53d1\u751f\u7684\u91cd\u8981\u4f9d\u636e. \u6781\u6027: \u4e8b\u4ef6\u5206\u4e3a\u80af\u5b9a, \u5426\u5b9a, \u53ef\u80fd\u4e8b\u4ef6. \u65f6\u6001: \u4e8b\u4ef6\u5206\u4e3a\u8fc7\u53bb\u65f6, \u73b0\u5728\u65f6, \u5c06\u6765\u65f6, \u5176\u4ed6\u65e0\u6cd5\u786e\u5b9a\u65f6\u6001\u7684\u4e8b\u4ef6. \u6ce8\u610f: \u5728\u771f\u5b9e\u4e16\u754c\u7684\u6587\u672c\u4e2d(\u901a\u7528, \u4e13\u4e1a), \u7531\u4e8e\u6587\u672c\u4e2d\u53ef\u80fd\u5b58\u5728\u53e5\u5f0f\u590d\u6742, \u4e3b\u88ab\u52a8\u8f6c\u6362, \u591a\u4e8b\u4ef6\u4e3b\u5ba2\u4f53\u5171\u4eab\u7b49\u96be\u70b9, \u56e0\u6b64\"\u4e8b\u4ef6\u62bd\u53d6\"\u662fNLP\u4e2d\u4e00\u9879\u6781\u5177\u6311\u6218\u7684\u4efb\u52a1!!! \u793a\u4f8b1: \u5317\u4eac\u65f6\u95f43\u670827\u65e5\u665a\u4e0a7\u70b915\u5206, \u82f1\u56fd\u9996\u76f8\u9c8d\u91cc\u65af.\u7ea6\u7ff0\u900a\u786e\u8bca\u611f\u67d3\u4e86\u65b0\u51a0\u80ba\u708e. \u89e6\u53d1\u8bcd \u4e3b\u4f53 \u5ba2\u4f53 \u65f6\u95f4 \u5730\u70b9 \u611f\u67d3 \u82f1\u56fd\u9996\u5148\u9c8d\u91cc\u65af \u65b0\u51a0\u80ba\u708e \u5317\u4eac\u65f6\u95f43\u670827\u65e5 \u65e0 \u793a\u4f8b2: \u8fc7\u6e21\u653f\u5e9c\u90e8\u961f\u53d1\u8a00\u4eba\u79f0, \u5317\u7ea6\u6218\u673a16\u65e5\u5728\u82cf\u5c14\u7279\u9644\u8fd1\u51fb\u4e2d\u4e86\u4e00\u5ea7\u5efa\u7b51, \u70b8\u6b7b\u5927\u6279\u5361\u624e\u83f2\u90e8\u961f\u58eb\u5175. \u89e6\u53d1\u8bcd \u4e3b\u4f53 \u5ba2\u4f53 \u65f6\u95f4 \u5730\u70b9 \u51fb\u4e2d \u5317\u7ea6\u6218\u673a \u4e00\u5ea7\u5efa\u7b51 16\u65e5 \u82cf\u5c14\u7279\u9644\u8fd1 \u70b8\u6b7b \u5317\u7ea6\u6218\u673a \u5927\u6279\u5361\u624e\u83f2\u90e8\u961f\u58eb\u5175 16\u65e5 \u82cf\u5c14\u7279\u9644\u8fd1 \u793a\u4f8b3: \u8fc7\u5f80\u4e16\u536b\u7ec4\u7ec7\u66fe5\u5ea6\u5ba3\u5e03\"\u56fd\u9645\u5173\u6ce8\u516c\u5171\u536b\u751f\u7d27\u6025\u4e8b\u4ef6\". \u89e6\u53d1\u8bcd \u6781\u6027 \u65f6\u6001 \u5ba3\u5e03 \u80af\u5b9a \u8fc7\u53bb\u65f6 \u793a\u4f8b4: \u82f1\u56fd\u5f88\u53ef\u80fd\u5c06\u6062\u590d\u63a5\u53d7\u4e16\u754c\u8d38\u6613\u7ec4\u7ec7\u6761\u6b3e\u7684\u89c4\u8303. \u89e6\u53d1\u8bcd \u6781\u6027 \u65f6\u6001 \u6062\u590d\u63a5\u53d7 \u53ef\u80fd \u5c06\u6765\u65f6","title":"\u4e8b\u4ef6\u62bd\u53d6\u6982\u5ff5"},{"location":"5_1.html#_4","text":"\u4e8b\u4ef6\u62bd\u53d6\u5efa\u7acb\u5728NER\u4efb\u52a1, RE\u4efb\u52a1\u4e4b\u4e0a, \u65b9\u6cd5\u4e5f\u53ef\u4ee5\u4e92\u76f8\u501f\u9274: pipeline\u65b9\u6cd5: \u4e24\u9636\u6bb5\u5904\u7406, \u5148\u62bd\u53d6\u89e6\u53d1\u8bcd, \u518d\u5229\u7528\u89e6\u53d1\u8bcd\u5bf9\u4e8b\u4ef6\u8bba\u5143\u8fdb\u884c\u69fd\u586b\u5145. joint\u65b9\u6cd5: \u4ee5\u6587\u672c\u4f5c\u4e3a\u8f93\u5165, \u5145\u5206\u8003\u8651\u89e6\u53d1\u8bcd\u4e0e\u8bba\u5143\u4e4b\u95f4\u7684\u4f9d\u8d56\u6027, \u7efc\u5408\u62bd\u53d6\u51fa\u89e6\u53d1\u8bcd\u548c\u5bf9\u5e94\u7684\u8bba\u5143. pipeline\u65b9\u6cd5: \u4f18\u70b9: \u7b80\u5355, \u53ef\u4ee5\u72ec\u7acb\u4f18\u5316\u4e0d\u540c\u7684\u6a21\u5757. \u7f3a\u70b9: \u548cRE\u4efb\u52a1\u7c7b\u4f3c, \u6a21\u578b\u5177\u6709\u4f20\u64ad\u8bef\u5dee. joint\u65b9\u6cd5: \u4f18\u70b9: \u907f\u514d\u4f20\u64ad\u8bef\u5dee, \u5145\u5206\u8003\u8651\u89e6\u53d1\u8bcd\u4e0e\u8bba\u5143\u4e4b\u95f4\u7684\u4f9d\u8d56\u6027. \u7f3a\u70b9: \u6a21\u578b\u590d\u6742, \u8bbe\u8ba1\u56f0\u96be, \u65e0\u6cd5\u8fdb\u884c\u6a21\u5757\u5316\u4f18\u5316. \u76ee\u524d\u5de5\u4e1a\u754c\u7684\u4e3b\u6d41\u65b9\u6cd5\u662fjoint\u65b9\u6cd5, \u5177\u4f53\u65b9\u6848\u6bd4\u5982\u91c7\u7528\u57fa\u4e8eBERT\u7684EE\u65b9\u6cd5, \u6216\u8005\u57fa\u4e8e\u7ea7\u8054\u7684EE\u65b9\u6cd5.","title":"\u4e8b\u4ef6\u62bd\u53d6\u65b9\u6cd5"},{"location":"6_1.html","text":"\u6982\u5ff5\u56fe\u8c31\u7684\u6784\u5efa \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u6982\u5ff5\u56fe\u8c31\u7684\u542b\u4e49. \u4e86\u89e3\u6709\u54ea\u4e9b\u6982\u5ff5\u56fe\u8c31. \u4e86\u89e3\u6982\u5ff5\u56fe\u8c31\u6709\u4ec0\u4e48\u4ef7\u503c\u4e0e\u5e94\u7528. \u4e86\u89e3\u5982\u4f55\u81ea\u52a8\u5316\u6784\u5efa\u4e0e\u5b8c\u5584\u4e00\u4e2a\u5927\u89c4\u6a21\u6982\u5ff5\u56fe\u8c31. \u6982\u5ff5\u56fe\u8c31\u7684\u5185\u6db5 \u00b6 \u6982\u5ff5\u662f\u8ba4\u77e5\u7684\u57fa\u77f3, \u6784\u5efa\u6982\u5ff5\u56fe\u8c31\u662f\u8ba9\u673a\u5668\u5177\u5907\u6982\u5ff5\u8ba4\u77e5\u80fd\u529b, \u8fdb\u800c\u5f62\u6210\u8ba4\u77e5\u80fd\u529b\u7684\u5173\u952e\u4e00\u73af. \u6240\u8c13\u673a\u5668\u7684\u6982\u5ff5\u8ba4\u77e5, \u4ece\u8ba1\u7b97\u673a\u4fe1\u606f\u5904\u7406\u7684\u89d2\u5ea6\u6765\u8bf4, \u662f\u5bf9\u67d0\u4e2a\u5f62\u6001\u7684\u6570\u636e\u8f93\u5165\u4ea7\u751f\u7b26\u53f7\u5316\u6982\u5ff5\u8f93\u51fa\u7684\u8fc7\u7a0b. \u7b26\u53f7\u5316\u6982\u5ff5\u7684\u53d1\u5c55\u53ef\u80fd\u662f\u4eba\u7c7b\u4ece\u52a8\u7269\u5b9e\u73b0\u667a\u80fd\u8dc3\u8fc1\u800c\u6210\u4e3a\u667a\u4eba\u7684\u9769\u547d\u6027\u4e00\u6b65. \u6b63\u662f\u6982\u5ff5\u7684\u51fa\u73b0, \u4f7f\u5f97\u62bd\u8c61\u601d\u7ef4\u6210\u4e3a\u53ef\u80fd. \u56e0\u6b64\u5c06\u6982\u5ff5\u77e5\u8bc6\u4ee5\u53ca\u76f8\u5e94\u7684\u8ba4\u77e5\u80fd\u529b\u8d4b\u4e88\u673a\u5668, \u4e5f\u5fc5\u5c06\u662f\u673a\u5668\u667a\u80fd\u53d1\u5c55\u5386\u7a0b\u4e2d\u7684\u91cd\u8981\u4e00\u6b65, \u662f\u8ba9\u673a\u5668\u5f62\u6210\u8ba4\u77e5\u7684\u5173\u952e\u6027\u57fa\u7840\u5de5\u4f5c. \u5efa\u8bbe\u6982\u5ff5\u56fe\u8c31\u5c31\u662f\u4e3a\u4e86\u8ba9\u673a\u5668\u4e5f\u80fd\u62e5\u6709\u4eba\u7c7b\u7684\u6982\u5ff5\u77e5\u8bc6, \u8fdb\u800c\u5f62\u6210\u6982\u5ff5\u8ba4\u77e5\u80fd\u529b. \u6982\u5ff5\u56fe\u8c31(Concept Graph)\u662f\u4e00\u7c7b\u4e13\u6ce8\u4e8e\u5b9e\u4f53\u4e0e\u6982\u5ff5\u4e4b\u95f4\u7684isA\u5173\u7cfb\u7684\u77e5\u8bc6\u56fe\u8c31, \u4ece\u8ba4\u77e5\u548c\u8bed\u8a00\u4e24\u4e2a\u89d2\u5ea6, \u6982\u5ff5\u56fe\u8c31\u53ef\u4ee5\u5206\u4e3a\u4e24\u4e2a\u4f53\u7cfb: \u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb (Taxonomy) \u8bcd\u6c47\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb (Lexical Taxonomy) \u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb (Taxonomy): \u5305\u542b\u4e09\u79cd\u5143\u7d20, \u5b9e\u4f53, \u6982\u5ff5, isA\u5173\u7cfb, \u6bd4\u5982\u5728isA\u5173\u7cfb\"apple isA fruit\"\u4e2d, apple\u662f\u5b9e\u4f53, fruit\u662f\u6982\u5ff5. isA\u5173\u7cfb\u53c8\u53ef\u4ee5\u7ec6\u5206\u4e3a\u5b9e\u4f53\u4e0e\u6982\u5ff5\u4e4b\u95f4\u7684instanceOf\u5173\u7cfb\u4ee5\u53ca\u6982\u5ff5\u4e4b\u95f4\u7684subclassOf\u5173\u7cfb. instanceOf\u5173\u7cfb: \u6bd4\u5982\"dog isA animal\"\u8868\u8fbe\u7684\u662f\u5b9e\u4f53\u4e0e\u6982\u5ff5\u4e4b\u95f4\u7684\u5173\u7cfb. subclassOf\u5173\u7cfb: \u6bd4\u5982\"fruit isA food\"\u8868\u8fbe\u7684\u662f\u6982\u5ff5\u5728\u4e4b\u95f4\u7684\u5173\u7cfb.(\u6c34\u679c\u662f\u5b50\u6982\u5ff5, \u98df\u7269\u662f\u7236\u6982\u5ff5) \u4efb\u4f55\u5b9e\u4f53\u6216\u8005\u6982\u5ff5\u90fd\u8981\u901a\u8fc7\u8bed\u8a00\u8868\u8fbe, \u56e0\u6b64\u5b9e\u9645\u5e94\u7528\u4e2d\u901a\u5e38\u4f7f\u7528\u8bcd\u6c47\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb, \u5176\u4e2d\u7684\u8282\u70b9\u662f\u6ca1\u6709\u7ecf\u8fc7\u6d88\u6b67\u7684\u8bcd. \u8bcd\u6c47\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u4e2d\u7684\u57fa\u672c\u5173\u7cfb\u662f\u8bcd\u6c47\u4e4b\u95f4\u7684\u4e0a\u4e0b\u4f4d\u5173\u7cfb. \u6bd4\u5982\"apple isA fruit\", apple\u662ffruit\u7684\u4e0b\u4f4d\u8bcd, fruit\u662fapple\u7684\u4e0a\u4f4d\u8bcd. \u5728\u8bcd\u6c47\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u4e2d, apple\u53ea\u662f\u4e00\u4e2a\u8bcd\u6c47, \u5728\u5f88\u591a\u60c5\u51b5\u4e0b\u5e76\u4e0d\u4e25\u683c\u533a\u5206\u5176\u8bed\u4e49, \u56e0\u6b64apple\u540c\u65f6\u5177\u6709\"\u516c\u53f8\"\u548c\"\u6c34\u679c\"\u4e24\u4e2a\u4e0a\u4f4d\u8bcd. \u601d\u8003: \u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u662f\u5426\u662f\u4e00\u4e2a\u6709\u5411\u65e0\u73af\u56fe? \u5e38\u89c1\u7684\u6982\u5ff5\u56fe\u8c31 \u00b6 \u5728\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u7684\u65e9\u671f, \u4eba\u4eec\u5c31\u5df2\u7ecf\u610f\u8bc6\u5230\u6982\u5ff5\u7684\u91cd\u8981\u6027, \u5e76\u5f00\u5c55\u8fc7\u4e00\u7cfb\u5217\u6982\u5ff5\u83b7\u53d6, \u6982\u5ff5\u77e5\u8bc6\u5e93\u6784\u5efa\u7684\u5de5\u4f5c. \u65f6\u81f3\u4eca\u65e5, \u5de5\u4e1a\u754c\u5df2\u7ecf\u6709\u5927\u91cf\u7684\u6982\u5ff5\u56fe\u8c31, \u5b83\u4eec\u5728\u5404\u79cd\u5e94\u7528\u4e2d\u53d1\u6325\u7740\u79ef\u6781\u7684\u4f5c\u7528, \u5e76\u4e14\u5927\u90e8\u5206\u6982\u5ff5\u56fe\u8c31\u662f\u516c\u5f00, \u53ef\u7528\u7684. WordNet \u00b6 WordNet\u662f\u666e\u6797\u65af\u987f\u8ba4\u77e5\u79d1\u5b66\u5b9e\u9a8c\u5ba4\u4e8e1985\u5e74\u5f00\u59cb\u521b\u5efa\u7684\u82f1\u6587\u8bcd\u5178, \u65e8\u5728\u4ece\u5fc3\u7406\u8bed\u8a00\u5b66\u89d2\u5ea6\u5efa\u7acb\u82f1\u6587\u8bcd\u6c47\u57fa\u672c\u8bed\u4e49\u5173\u7cfb\u7684\u5b9e\u7528\u6a21\u578b, \u5176\u76ee\u7684\u5728\u4e8e\u901a\u8fc7\u6982\u5ff5\u6765\u5e2e\u52a9\u7528\u6237\u83b7\u53d6\u8bed\u4e49\u77e5\u8bc6. WordNet\u7528\u5355\u8bcd\u7684\u5e38\u89c1\u62fc\u5199\u6765\u8868\u793a\u8bcd\u5f62, \u7528\u540c\u4e49\u8bcd\u8bcd\u96c6\u6765\u8868\u793a\u8bcd\u4e49. WordNet\u5305\u542b\u4e24\u79cd\u7c7b\u578b\u7684\u5173\u7cfb: \u7b2c\u4e00\u79cd: \u8bcd\u6c47\u5173\u7cfb, \u8fd9\u79cd\u5173\u7cfb\u5b58\u5728\u4e8e\u8bcd\u5f62\u4e4b\u95f4. \u7b2c\u4e8c\u79cd: \u8bed\u4e49\u5173\u7cfb, \u8fd9\u79cd\u5173\u7cfb\u5b58\u5728\u4e8e\u8bcd\u4e49\u4e4b\u95f4. \u6ce8\u610f: WordNet\u5229\u7528\u8bcd\u4e49\u800c\u4e0d\u662f\u8bcd\u5f62\u6765\u7ec4\u7ec7\u8bcd\u6c47. WordNet\u7684\u8bed\u4e49\u5173\u7cfb\u5305\u542b: \u540c\u4e49, \u53cd\u4e49, \u4e0a\u4e0b\u4f4d, \u6574\u4f53-\u90e8\u5206. WordNet\u7684\u8bcd\u6c47\u5206\u4e3a5\u7c7b: \u540d\u8bcd, \u52a8\u8bcd, \u5f62\u5bb9\u8bcd, \u526f\u8bcd, \u529f\u80fd\u8bcd. \u4f8b\u5982: \u5f53\u6211\u4eec\u67e5\u8be2\"car\"\u8fd9\u4e2a\u5355\u8bcd\u7684\u65f6\u5019, \"car.n.01\"\u8868\u793acar\u7684\u7b2c\u4e00\u4e2a\u8bcd\u4e49\u5bf9\u5e94\u9879, \u800c\u6839\u636e\u8fb9\u6240\u8868\u8fbe\u7684\u4e0a\u4e0b\u4f4d\u5173\u7cfb, \u53ef\u77e5\"car.n.01\"\u7684\u4e0a\u4f4d\u8bcd\u662f\"motor_vehicle.n.01\". WikiTaxonomy \u00b6 2008\u5e74, Ponzetto\u548cStrube\u63d0\u51fa\u4e86WikiTaxonomy\u6982\u5ff5\u56fe\u8c31, \u5176\u6570\u636e\u6765\u6e90\u4e8e2006\u5e749\u670825\u65e5\u7684\u7ef4\u57fa\u767e\u79d1\u6570\u636e\u5feb\u7167, \u5e76\u5c06\u62bd\u53d6\u51fa\u6765\u7684isA\u77e5\u8bc6\u4ee5RDF\u5f62\u5f0f\u8868\u793a. \u5177\u4f53\u6765\u8bf4, WikiTaxonomy\u4ece127325\u4e2a\u7c7b\u548c267707\u4e2a\u94fe\u63a5\u4e2d\u4ea7\u751f\u4e86105418\u6761isA\u5173\u7cfb, \u5176F1\u503c\u8fbe\u5230\u4e8687.9%. Probase \u00b6 Probase\u662f2012\u5e74\u5fae\u8f6f\u4e9a\u6d32\u7814\u7a76\u9662\u63d0\u51fa\u7684\u7814\u7a76\u539f\u578b, \u5176\u76ee\u6807\u662f\u4ece\u7f51\u9875\u6570\u636e\u548c\u641c\u7d22\u8bb0\u5f55\u6570\u636e\u4e2d\u6784\u9020\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u5206\u7c7b\u77e5\u8bc6\u4f53\u7cfb. Probase\u662f\u4ece16\u4ebf\u4e2a\u7f51\u9875\u4e2d\u8fdb\u884c\u81ea\u52a8\u62bd\u53d6\u6784\u9020\u800c\u6210\u7684. \u4f8b\u5982: \"X such as Y\"\u8fd9\u4e00\u6a21\u5f0f\u53ef\u4ee5\u4ece\"household pets such as cats\"\u4e2d\u62bd\u53d6\u51fa\"cats isA household pets\". Probase\u65e9\u671f\u7248\u672c\u5305\u542b\u4e861600\u4e07\u6761isA\u5173\u7cfb, \u51c6\u786e\u7387\u8fbe\u5230\u4e8692%, \u5e76\u4e14\u6bcf\u6761\u5173\u7cfb\u7686\u542b\u6709\u9891\u6570, \u8868\u793a\u8be5\u6761\u5173\u7cfb\u5728\u603b\u4f53\u8bed\u6599\u4e2d\u51fa\u73b0\u7684\u6b21\u6570. \u4f8b\u5982, (Google, isA, Company, 7816), (Apple, isA, Fruit, 6315). \u8fd9\u4e9b\u9891\u6570\u5bf9\u4e8e\u523b\u753b\u5b9e\u4f53\u6216\u8005\u6982\u5ff5\u7684\u5178\u578b\u6027\u5177\u6709\u91cd\u8981\u610f\u4e49. Probase\u7ecf\u8fc7\u540e\u7eed\u51e0\u8f6e\u6269\u5bb9\u540e\u66f4\u540d\u4e3aMicrosoft Concept Graph, \u73b0\u5df2\u5305\u542b\u8d85\u8fc7500\u4e07\u4e2a\u6982\u5ff5, 1200\u591a\u4e07\u4e2a\u5b9e\u4f8b, 8000\u591a\u4e07\u6761isA\u5173\u7cfb. \u5927\u8bcd\u6797 \u00b6 \u5927\u8bcd\u6797\u662f\u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66\u793e\u4f1a\u8ba1\u7b97\u4e0e\u4fe1\u606f\u68c0\u7d22\u7814\u7a76\u4e2d\u5fc3\u6784\u5efa\u7684\u4e2d\u6587\u6982\u5ff5\u56fe\u8c31. \u5927\u8bcd\u6797\u662f\u57fa\u4e8e\u5f31\u76d1\u7763\u6846\u67b6\u81ea\u52a8\u6784\u5efa\u800c\u6210\u7684. \u5927\u8bcd\u6797\u5bf9\u6bcf\u4e2a\u5b9e\u4f53\u5206\u522b\u4ece\u641c\u7d22\u5f15\u64ce\u7684\u7ed3\u679c, \u767e\u79d1\u9875\u9762\u548c\u5b9e\u4f53\u540d\u79f0\u8fd9\u4e09\u4e2a\u6570\u636e\u6e90\u4e2d\u83b7\u53d6\u4e0a\u4e0b\u4f4d\u5173\u7cfb, \u7136\u540e\u901a\u8fc7\u6392\u5e8f\u6a21\u5757\u5bf9\u5b9e\u4f53\u7684\u4e0a\u4f4d\u8bcd\u8fdb\u884c\u6392\u5e8f. CN-Probase \u00b6 CN-Probase\u662f\u590d\u65e6\u5927\u5b66\u77e5\u8bc6\u5de5\u573a\u5b9e\u9a8c\u5ba4\u7814\u53d1\u5e76\u7ef4\u62a4\u7684\u5927\u89c4\u6a21\u4e2d\u6587\u6982\u5ff5\u56fe\u8c31, \u5176isA\u5173\u7cfb\u7684\u51c6\u786e\u7387\u572895%\u4ee5\u4e0a. \u4e0e\u5176\u4ed6\u6982\u5ff5\u56fe\u8c31\u76f8\u6bd4, CN-Probase\u5177\u6709\u4e24\u4e2a\u663e\u8457\u4f18\u70b9: \u7b2c\u4e00\u70b9: \u89c4\u6a21\u5de8\u5927, \u57fa\u672c\u6db5\u76d6\u5e38\u89c1\u7684\u4e2d\u6587\u5b9e\u4f53\u548c\u6982\u5ff5, \u5305\u542b\u7ea61700\u4e07\u4e2a\u5b9e\u4f53, 27\u4e07\u4e2a\u6982\u5ff5\u548c3300\u4e07\u6761isA\u5173\u7cfb. \u7b2c\u4e8c\u70b9: \u4e25\u683c\u6309\u7167\u5b9e\u4f53\u8fdb\u884c\u7ec4\u7ec7, \u6709\u5229\u4e8e\u7cbe\u51c6\u7406\u89e3\u5b9e\u4f53\u7684\u6982\u5ff5. \u5173\u4e8e\u4e0a\u8ff0\u7b2c\u4e8c\u70b9, \u53ef\u4ee5\u4e3e\u4f8b\u5982\u4e0b: \"\u5218\u5fb7\u534e\"\u8fd9\u4e2a\u540d\u5b57\u53ef\u80fd\u5bf9\u5e94\u5f88\u591a\u53eb\"\u5218\u5fb7\u534e\"\u7684\u4eba, \u5728CN-Probase\u91cc\u641c\u7d22\"\u5218\u5fb7\u534e\", \u4f1a\u5c06\u6240\u6709\u5339\u914d\u7684\u5b9e\u4f53\u6309\u7167\u5178\u578b\u6027\u8fdb\u884c\u6392\u5e8f, \u6392\u5728\u7b2c\u4e00\u7684\u662f\u4f17\u6240\u5468\u77e5\u7684\u9999\u6e2f\u6d41\u884c\u5929\u738b\"\u5218\u5fb7\u534e\". \u5218\u5fb7\u534e (\u4e2d\u56fd\u9999\u6e2f\u7537\u6f14\u5458, \u6b4c\u624b, \u5236\u7247\u4eba) \u5218\u5fb7\u534e (\u6e05\u534e\u5927\u5b66\u6559\u6388) \u5218\u5fb7\u534e (\u539f\u6c11\u822a\u5c40\u7a7a\u4e2d\u4ea4\u901a\u7ba1\u7406\u5c40\u5c40\u957f) \u5218\u5fb7\u534e (\u5c71\u4e1c\u94a2\u94c1\u96c6\u56e2\u6709\u9650\u516c\u53f8\u8d22\u52a1\u603b\u76d1) \u5218\u5fb7\u534e (\u65b0\u7586\u9752\u5c11\u5e74\u51fa\u7248\u793e\u51fa\u7248\u7684\u8457\u4f5c) \u5218\u5fb7\u534e (\u6e56\u5317\u7c4d\u70c8\u58eb) \u5218\u5fb7\u534e (\u56db\u5ddd\u7701\u5e7f\u5b89\u7ecf\u6d4e\u6280\u672f\u5f00\u53d1\u533a\u56fd\u5bb6\u7a0e\u52a1\u5c40\u5c40\u957f) \u5218\u5fb7\u534e (\u6c5f\u897f\u7c4d\u70c8\u58eb) \u5218\u5fb7\u534e (\u901a\u5ddd\u533a\u5b66\u751f\u81ea\u4e3b\u4e2d\u5fc3\u4e3b\u4efb) \u6982\u5ff5\u56fe\u8c31\u7684\u5e94\u7528 \u00b6 \u6982\u5ff5\u56fe\u8c31\u5bf9\u4e8e\u673a\u5668\u8ba4\u77e5\u667a\u80fd\u7684\u5b9e\u73b0\u81f3\u5173\u91cd\u8981, \u8fd9\u79cd\u91cd\u8981\u6027\u4f53\u73b0\u5728\u4e00\u7cfb\u5217\u5b9e\u9645\u5e94\u7528\u4e2d, \u8fd9\u4e9b\u5e94\u7528\u6d89\u53ca\u6982\u5ff5\u56fe\u8c31\u7684\u7b80\u5355\u67e5\u8be2\u4ee5\u53ca\u76f8\u5bf9\u590d\u6742\u7684\u63a8\u7406. \u4e0d\u7ba1\u5e94\u7528\u7684\u5f62\u5f0f\u5982\u4f55, \u90fd\u53ef\u4ee5\u5f52\u7ed3\u4e3a\u5b9e\u4f8b\u5316\u548c\u6982\u5ff5\u5316\u8fd9\u4e24\u4e2a\u6700\u57fa\u672c\u7684\u529f\u80fd. \u5b9e\u4f53\u641c\u7d22: \u7ed9\u5b9a\u4e00\u4e2a\u6982\u5ff5\u4f5c\u4e3a\u67e5\u8be2, \u68c0\u7d22\u8be5\u6982\u5ff5\u7684\u5178\u578b\u5b9e\u4f53. \u4f8b\u5982: \u641c\u7d22\"\u4e0a\u6d77985\u9ad8\u6821\", \u8fd4\u56de\"\u590d\u65e6\u5927\u5b66\", \"\u4e0a\u6d77\u4ea4\u901a\u5927\u5b66\". \u6837\u672c\u589e\u5f3a: \u5229\u7528\u6982\u5ff5\u4e0b\u7684\u5b9e\u4f8b, \u589e\u5f3a\u6837\u672c. \u4f8b\u5982: \u5bf9\u6837\u672c\"\u9890\u548c\u56ed\u5728\u54ea\u91cc?\", \u66ff\u6362\u5b9e\u4f53, \u751f\u6210\"\u5706\u660e\u56ed\u5728\u54ea\u91cc?\", \u4f5c\u4e3a\u65b0\u7684\u6837\u672c. \u6587\u672c\u5206\u7c7b: \u6839\u636e\u6587\u672c\u4e2d\u5b9e\u4f53\u7684\u6982\u5ff5, \u5c06\u6587\u672c\u5206\u4e3a\u4e0d\u540c\u7c7b\u522b. \u4f8b\u5982: \u5305\u542b\"\u8db3\u7403\", \"\u7bee\u7403\"\u7684\u6587\u672c\u5e94\u8be5\u4e0e\u5305\u542b\"\u5b9d\u9a6c\", \"\u5954\u9a70\"\u7684\u6587\u672c\u5c5e\u4e8e\u4e0d\u540c\u7684\u7c7b\u522b. \u4e3b\u9898\u5206\u6790: \u7ed9\u5b9a\u6587\u672c, \u5206\u6790\u6587\u672c\u5c5e\u4e8e\u4ec0\u4e48\u4e3b\u9898. \u4f8b\u5982: \u5305\u542b\"\u8db3\u7403\", \"\u7bee\u7403\"\u7684\u6587\u672c\u5e94\u8be5\u5c5e\u4e8e\u4f53\u80b2\u7c7b\u4e3b\u9898. \u7ed9\u6587\u6863\u6253\u6807\u7b7e: \u7ed9\u5b9a\u6587\u672c, \u7ed9\u6587\u672c\u6253\u4e0a\u82e5\u5e72\u4e2a\u6982\u5ff5\u4f5c\u4e3a\u6807\u7b7e. \u4f8b\u5982: \u5bf9\u6587\u672c\"iPhone\u8fdb\u6c34\u4e86\u600e\u4e48\u529e?\", \u53ef\u4ee5\u6253\u4e0a\"\u624b\u673a, \u7ef4\u4fee\"\u7b49\u6807\u7b7e. \u7528\u6237\u753b\u50cf: \u7ed9\u5b9a\u7528\u6237\u4fe1\u606f, \u4e3a\u7528\u6237\u751f\u6210\u663e\u5f0f\u7684\u6982\u5ff5. \u4f8b\u5982: \u6839\u636e\u63cf\u8ff0\u6587\u672c\"\u7cbe\u901aJava, Android\u5f00\u53d1\", \u53ef\u4ee5\u4e3a\u7528\u6237\u6253\u4e0a\"\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\", \"\u624b\u673aAPP\u5f00\u53d1\", \"Java\u7a0b\u5e8f\u5458\"\u7b49\u6807\u7b7e. \u57fa\u4e8e\u6982\u5ff5\u7684\u89e3\u91ca: \u6839\u636e\u6982\u5ff5\u4fe1\u606f, \u4e3a\u4e8b\u4ef6\u63d0\u4f9b\u89e3\u91ca. \u4f8b\u5982: \u5bf9\u4e8e\u6587\u672c\"\u7279\u65af\u62c9Model S\u7684\u52a0\u901f\u6027\u80fd\u5f88\u597d\", \u53ef\u4ee5\u901a\u8fc7\u5173\u952e\u6982\u5ff5\"\u7279\u65af\u62c9Model S\u662f\u7535\u52a8\u8f66\", \u4ee5\u53ca\"\u7535\u52a8\u8f66\u52a0\u901f\u6027\u80fd\u901a\u5e38\u8f83\u597d\", \u6765\u7ed9\u51fa\u5408\u7406\u53ef\u4fe1\u7684\u89e3\u91ca. \u6982\u5ff5\u5f52\u7eb3: \u4ece\u5b9e\u4f53\u96c6\u5408\u6216\u8005\u8bcd\u888b\u5f52\u7eb3\u6982\u5ff5\u6807\u7b7e. \u4f8b\u5982: \u7ed9\u5b9a\"\u6e05\u534e\u5927\u5b66\", \"\u5317\u4eac\u5927\u5b66\", \u53ef\u4ee5\u5f52\u7eb3\u51fa\"\u4e2d\u56fd\u9ad8\u6821\", \"985\"\u7b49\u6982\u5ff5. \u8bed\u4e49\u8868\u793a: \u5229\u7528\u6982\u5ff5\u96c6\u5408\u8868\u8fbe\u5b9e\u4f53, \u8bcd\u6c47\u7684\u8bed\u4e49. \u4f8b\u5982: \"iPhone X\"\u7684\u8bed\u4e49\u8bfe\u8868\u8fbe\u4e3a\u5176\u6982\u5ff5\u96c6\u5408 {\"\u5168\u9762\u5c4f\u624b\u673a\", \"\u667a\u80fd\u624b\u673a\", \"\u65d7\u8230\u624b\u673a\"}. \u5b9e\u4f53\u63a8\u8350: \u6839\u636e\u4e00\u4e9b\u5b9e\u4f53\u7684\u6982\u5ff5\u4fe1\u606f\u4e3a\u5176\u63a8\u8350\u5176\u4ed6\u5b9e\u4f53. \u4f8b\u5982: \u5f53\u7528\u6237\u641c\u7d22\"iPhone XS\"\u65f6, \u4e3a\u5176\u63a8\u8350\"\u534e\u4e3a P30\"\u7b49\u9ad8\u7aef\u624b\u673a. \u89c4\u5219\u6316\u6398: \u5229\u7528\u6982\u5ff5\u4ece\u5927\u91cf\u6570\u636e\u4e2d\u6316\u6398\u51fa\u5177\u6709\u4e00\u5b9a\u6cdb\u5316\u80fd\u529b\u7684\u89c4\u5219. \u4f8b\u5982: \u4ece\u5065\u8eab\u7684\u4eba\u5403\u852c\u83dc, \u5403\u71d5\u9ea6\u7b49\u98df\u7269, \u53ef\u4ee5\u6316\u6398\u51fa\u5065\u8eab\u7684\u4eba\u4e3b\u8981\u5403\"\u9ad8\u7ea4\u7ef4\u98df\u7269\". \u603b\u7ed3: \u4e0a\u8ff0\u5e94\u7528\u7684\u672c\u8d28\u90fd\u662f\u7528\u6982\u5ff5\u4f5c\u4e3a\u5b9e\u4f53, \u8bcd\u6c47\u6216\u8005\u5176\u4ed6\u5bf9\u8c61\u7684\u8bed\u4e49\u8868\u793a. \u4e0d\u540c\u4e8e\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e2d\u5e38\u7528\u7684\u57fa\u4e8e\u5411\u91cf\u7684\u9690\u5f0f\u8868\u793a, \u57fa\u4e8e\u6982\u5ff5\u7684\u8bed\u4e49\u8868\u793a\u662f\u4e00\u79cd\u663e\u793a\u8868\u793a. \u6982\u5ff5\u662f\u7b26\u53f7, \u662f\u4eba\u7c7b\u53ef\u7406\u89e3\u7684, \u56e0\u6b64\u57fa\u4e8e\u6982\u5ff5\u56fe\u8c31\u7684\u8bed\u4e49\u8868\u793a\u5177\u6709\u53ef\u63a7\u6027, \u53ef\u89e3\u91ca\u6027\u7b49\u4f18\u70b9, \u8fd9\u5728\u5f88\u591a\u573a\u666f\u4e0b\u662f\u975e\u5e38\u6709\u610f\u4e49\u7684! \u6982\u5ff5\u56fe\u8c31\u7684\u6784\u5efa \u00b6 \u77e5\u8bc6\u56fe\u8c31\u7684\u89c4\u6a21\u548c\u8d28\u91cf\u662f\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u7684\u91cd\u8981\u56e0\u7d20, \u5bf9\u4e8e\u6982\u5ff5\u56fe\u8c31\u4e5f\u4e0d\u4f8b\u5916. \u4eba\u5de5\u6784\u5efa\u7684\u6982\u5ff5\u56fe\u8c31(\u6bd4\u5982WordNet)\u8d28\u91cf\u7cbe\u826f, \u5df2\u7ecf\u5728\u5f88\u591a\u9886\u57df\u5f97\u4ee5\u5e94\u7528\u5e76\u5f97\u5230\u68c0\u9a8c, \u4f46\u662f\u4eba\u5de5\u6784\u5efa\u7684\u6982\u5ff5\u56fe\u8c31\u89c4\u6a21\u6709\u9650. \u6982\u5ff5\u56fe\u8c31\u5bf9\u4e8e\u5b9e\u4f53\u548c\u6982\u5ff5\u7684\u8986\u76d6\u7387\u76f4\u63a5\u51b3\u5b9a\u4e86\u5176\u80fd\u5426\u80dc\u4efb\u81ea\u7136\u8bed\u8a00\u4e2d\u6d77\u91cf\u5b9e\u4f53\u548c\u6982\u5ff5\u7684\u7406\u89e3\u4efb\u52a1. \u53e6\u5916, \u5927\u89c4\u6a21\u6587\u672c\u4e2d\u4e5f\u8574\u542b\u7740\u4e30\u5bcc\u7684isA\u5173\u7cfb. \u56e0\u6b64, \u4ece\u5927\u89c4\u6a21\u6587\u672c\u4e2d\u81ea\u52a8\u62bd\u53d6isA\u5173\u7cfb\u8fdb\u800c\u6784\u5efa\u5927\u89c4\u6a21\u6982\u5ff5\u56fe\u8c31\u662f\u53ef\u80fd\u7684. \u6838\u5fc3: \u5982\u4f55\u786e\u4fdd\u81ea\u52a8\u5316\u6784\u5efa\u7684\u5927\u89c4\u6a21\u6982\u5ff5\u56fe\u8c31\u7684\u51c6\u786e\u7387? \u8fd9\u662f\u6574\u4e2a\u81ea\u52a8\u5316\u6784\u5efa\u4e2d\u7684\u6838\u5fc3\u95ee\u9898! isA\u5173\u7cfb\u62bd\u53d6\u5f0f\u6784\u5efa\u6982\u5ff5\u56fe\u8c31\u7684\u6838\u5fc3. isA\u5173\u7cfb\u62bd\u53d6\u7684\u65b9\u6cd5\u4e3b\u8981\u5206\u4e3a\u4e09\u79cd: \u57fa\u4e8e\u5728\u7ebf\u767e\u79d1\u7684\u65b9\u6cd5 \u57fa\u4e8e\u6a21\u5f0f\u5339\u914d\u7684\u65b9\u6cd5 \u57fa\u4e8e\u8bcd\u5411\u91cf\u7684\u65b9\u6cd5 \u57fa\u4e8e\u8bcd\u5411\u91cf\u7684\u65b9\u6cd5\u5c06\u8bcd\u6c47\u8868\u4e2d\u7684\u5355\u8bcd\u6216\u77ed\u8bed\u6620\u5c04\u5230\u5411\u91cf\u7a7a\u95f4, \u57fa\u4e8e\u5411\u91cf\u8fd0\u7b97\u53d1\u73b0\u4e0a\u4e0b\u4f4d\u5173\u7cfb. \u901a\u8fc7\u5927\u91cf\u7684\u7814\u7a76\u9a8c\u8bc1, \u53d1\u73b0\u8bcd\u5411\u91cf\u80fd\u591f\u57fa\u672c\u4fdd\u6301\u4e0a\u4e0b\u4f4d\u5173\u7cfb, \u6bd4\u5982\"vector(\u867e) - vector(\u5bf9\u867e)\"\u7ea6\u7b49\u4e8e\"vector(\u9c7c) - vector(\u91d1\u9c7c)\". \u8fd9\u7c7b\u65b9\u6cd5\u601d\u8def\u4e0a\u6bd4\u8f83\u7b80\u5355, \u4f46\u662f\u7531\u4e8e\u5411\u91cf\u5316\u8fc7\u7a0b\u4e2d\u635f\u5931\u4e86\u77e5\u8bc6\u56fe\u8c31\u539f\u6709\u7684\u8bed\u4e49\u4fe1\u606f, \u56e0\u6b64\u76f4\u63a5\u4f7f\u7528\u5411\u91cf\u63a8\u65adisA\u5173\u7cfb\u7684\u6548\u679c\u6bd4\u8f83\u6709\u9650. \u4e00\u822c\u800c\u8a00, \u9700\u8981\u5728\u57fa\u4e8e\u5411\u91cf\u63a8\u65ad\u7684\u57fa\u7840\u4e0a\u8f85\u4ee5\u5176\u4ed6\u8bc1\u636e, \u624d\u80fd\u8fdb\u884cisA\u5173\u7cfb\u7684\u51c6\u786e\u63a8\u65ad, \u8fdb\u800c\u5b8c\u6210\u6982\u5ff5\u56fe\u8c31\u7684\u6784\u5efa. \u5728\u7ebf\u767e\u79d1\u7684\u65b9\u6cd5 \u00b6 \u57fa\u4e8e\u5728\u7ebf\u767e\u79d1\u7684\u65b9\u6cd5\u4e3b\u8981\u662f\u4ece\u767e\u79d1\u7f51\u7ad9\u7684\u6807\u7b7e\u7cfb\u7edf\u4e2d\u62bd\u53d6\u51fa\u6765\u6982\u5ff5\u4e4b\u95f4\u7684isA\u5173\u7cfb. \u6807\u7b7e\u7cfb\u7edf\u7528\u4e8e\u7ec4\u7ec7\u767e\u79d1\u7f51\u7ad9\u4e0a\u7684\u6240\u6709\u5b9e\u4f53, \u4e3a\u6784\u5efa\u6982\u5ff5\u56fe\u8c31\u63d0\u4f9b\u4e86\u7406\u60f3\u7684\u6570\u636e\u6765\u6e90. \u53ea\u9700\u4ece\u6807\u7b7e\u7cfb\u7edf\u4e2d\u7b5b\u9009\u51fa\u9ad8\u8d28\u91cf\u7684\u6982\u5ff5, \u5e76\u5efa\u7acb\u8d77\u6982\u5ff5\u4e4b\u95f4\u7684\u5c42\u7ea7\u5173\u7cfb, \u5c31\u80fd\u5c06\u7528\u6237\u81ea\u53d1\u8d21\u732e\u7684\u6807\u7b7e\u7cfb\u7edf\u8f6c\u6362\u6210\u6709\u7ed3\u6784\u7684\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb. \u4f8b\u5982: \u82f1\u6587\u6982\u5ff5\u56fe\u8c31WikiTaxonomy\u548cYAGO\u90fd\u662f\u57fa\u4e8e\u8fd9\u4e00\u601d\u8def\u6784\u5efa\u800c\u6210\u7684. \u7b2c\u4e00\u6b65: \u6982\u5ff5\u6807\u7b7e\u8bc6\u522b \u6839\u636e\u6807\u7b7e\u7684\u529f\u80fd, \u7ef4\u57fa\u767e\u79d1\u4e2d\u7684\u6807\u7b7e\u53ef\u5206\u4e3a\u6982\u5ff5\u578b\u6807\u7b7e, \u4e3b\u9898\u578b\u6807\u7b7e, \u5c5e\u6027\u578b\u6807\u7b7e\u4ee5\u53ca\u7ba1\u7406\u578b\u6807\u7b7e. \u6982\u5ff5\u578b\u6807\u7b7e: \u6982\u5ff5\u578b\u6807\u7b7e\u7528\u6765\u63cf\u8ff0\u5b9e\u4f53\u6240\u5c5e\u7684\u7c7b\u578b, \u5982\"American male film actors\". \u6982\u5ff5\u6807\u7b7e\u662f\u6982\u5ff5\u56fe\u8c31\u4e2d\u7684\u7406\u60f3\u8282\u70b9. \u4e3b\u9898\u578b\u6807\u7b7e: \u4e3b\u9898\u578b\u6807\u7b7e\u7528\u6765\u63cf\u8ff0\u5b9e\u4f53\u6240\u5c5e\u7684\u4e3b\u9898, \u5982\"Chemistry\". \u5c5e\u6027\u578b\u6807\u7b7e: \u5c5e\u6027\u578b\u6807\u7b7e\u7528\u4e8e\u63cf\u8ff0\u5b9e\u4f53\u7684\u76f8\u5173\u5c5e\u6027\u4fe1\u606f, \u5982\"1989 births\". \u7ba1\u7406\u578b\u6807\u7b7e: \u7ba1\u7406\u578b\u6807\u7b7e\u4e3b\u8981\u7528\u4e8e\u7ba1\u7406\u7ef4\u57fa\u767e\u79d1\u8bcd\u6761, \u6bd4\u5982\"Articles with unsourced statements\". \u65b9\u6cd5: \u5c5e\u6027\u578b\u6807\u7b7e\u548c\u7ba1\u7406\u578b\u6807\u7b7e\u4e00\u822c\u6765\u8bf4\u6bd4\u8f83\u5c11, \u53ef\u4ee5\u901a\u8fc7\u4eba\u5de5\u6216\u8005\u8bbe\u5b9a\u7b80\u5355\u89c4\u5219\u6765\u5254\u9664. \u5269\u4e0b\u7684\u6807\u7b7e\u4e3b\u8981\u662f\u6982\u5ff5\u578b\u6807\u7b7e\u548c\u4e3b\u9898\u578b\u6807\u7b7e. YAGO\u4f7f\u7528\u4e86\u6d45\u5c42\u8bed\u8a00\u5206\u6790\u6765\u8bc6\u522b\u6982\u5ff5\u578b\u6807\u7b7e, \u5176\u57fa\u672c\u601d\u8def\u4e3a\u8bc6\u522b\u51fa\u6807\u7b7e\u540d\u79f0\u4e2d\u7684\u4e2d\u5fc3\u8bcd. \u5982\u679c\u8fd9\u4e2a\u4e2d\u5fc3\u8bcd\u4e3a\u590d\u6570(\u6bd4\u5982\"American male film actors\"\u4e2d\u7684\"actors\"), \u5219\u8ba4\u4e3a\u8be5\u6807\u7b7e\u4e3a\u6982\u5ff5\u578b\u6807\u7b7e; \u5982\u679c\u4e2d\u5fc3\u8bcd\u4e3a\u5355\u6570(\u6bd4\u5982\"Chemistry\"), \u5219\u8ba4\u4e3a\u8fd9\u4e2a\u6807\u7b7e\u4e3a\u4e3b\u9898\u578b\u6807\u7b7e. \u7b2c\u4e8c\u6b65: \u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u6784\u5efa \u5728\u8bc6\u522b\u51fa\u7ef4\u57fa\u767e\u79d1\u4e2d\u7684\u6982\u5ff5\u578b\u6807\u7b7e\u540e, YAGO\u63d0\u51fa\u4e86\u5c06\u8fd9\u4e9b\u6982\u5ff5\u578b\u6807\u7b7e\u4e0eWordNet\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u6982\u5ff5\u5efa\u7acbisA\u5173\u7cfb, \u8fdb\u800c\u6784\u5efa\u4e00\u4e2a\u6bd4WordNet\u66f4\u5927\u7684\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb. \u6a21\u5f0f\u5339\u914d\u7684\u65b9\u6cd5 \u00b6 \u7ef4\u57fa\u767e\u79d1\u7684\u6807\u7b7e\u7cfb\u7edf\u89c4\u6a21\u6709\u9650, \u8fd9\u51b3\u5b9a\u4e86\u57fa\u4e8e\u7ef4\u57fa\u767e\u79d1\u6784\u5efa\u7684\u6982\u5ff5\u56fe\u8c31\u89c4\u6a21\u6709\u9650, \u96be\u6613\u6ee1\u8db3\u5927\u89c4\u6a21\u5e94\u7528\u7684\u9700\u8981. \u7a81\u7834\u89c4\u6a21\u74f6\u9888\u7684\u4e00\u4e2a\u91cd\u8981\u601d\u8def\u662f\u5c06\u4e92\u8054\u7f51\u4e0a\u7684\u81ea\u7531\u6587\u672c\u4f5c\u4e3a\u6784\u5efa\u6982\u5ff5\u56fe\u8c31\u7684\u6570\u636e\u6e90. \u4e92\u8054\u7f51\u4e0a\u7684\u81ea\u7531\u6587\u672c\u7684\u89c4\u6a21\u51e0\u4e4e\u662f\u65e0\u9650\u7684, \u7531\u6b64\u6784\u5efa\u7684\u6982\u5ff5\u56fe\u8c31\u53ef\u4ee5\u8986\u76d6\u5e38\u89c1\u7684\u5b9e\u4f53\u548c\u6982\u5ff5. \u4ece\u6587\u672c\u4e2d\u62bd\u53d6isA\u5173\u7cfb\u6700\u5e38\u89c1\u7684\u65b9\u6cd5\u662f\u57fa\u4e8e\u6a21\u5f0f(Pattern)\u7684\u62bd\u53d6\u65b9\u6cd5. \u4f8b\u5982: \u5bf9\u4e8e\u6a21\u5f0f\u7279\u5f81\u8bcd\"such as\"\u524d\u540e\u7684\u540d\u8bcd\u77ed\u8bed\u4f5c\u4e3a\u4e0a\u4e0b\u4f4d\u8bcd, \u5bf9\u4e8e\u4e0e\u6b64\u6a21\u5f0f\u5339\u914d\u7684\"companies such as IBM, Apple\", \u4e0d\u96be\u62bd\u53d6\u51fa\"IBM isA Company\", \"Apple isA Company\". \u4f46\u662f\u7c7b\u4f3c\u4e0a\u9762\"such as\"\u6a21\u5f0f\u7279\u5f81\u8bcd\u7684\u505a\u6cd5\u4ecd\u7136\u5b58\u5728\u4e00\u4e9b\u95ee\u9898: \u566a\u58f0\u8bcd\u9519\u8bef: \u6a21\u5f0f\u524d\u540e\u7684\u566a\u58f0\u8bcd\u6c47\u4f1a\u5bfc\u81f4\u62bd\u53d6\u9519\u8bef. \u4f8b\u5982, \u5bf9\"animals other than dogs such as cats\"\u7684\u62bd\u53d6\u4f1a\u5f97\u5230\u9519\u8bef\u7684isA\u5173\u7cfb, \"cats isA dogs\", \u4e3b\u8981\u539f\u56e0\u662f\u56e0\u4e3a\u566a\u58f0\u8bcd\"other than\"\u7684\u5e72\u6270\u6240\u81f4. \u5206\u8bcd\u9519\u8bef: \u5206\u8bcd\u9519\u8bef\u4f1a\u5bfc\u81f4\u62bd\u53d6\u9519\u8bef. \u4f8b\u5982, \u5bf9\"algorithms including SVM, LR and RF\", \u5206\u8bcd\u6a21\u578b\u96be\u6613\u786e\u5b9a\"LR and RF\"\u5230\u5e95\u662f\u4e00\u4e2a\u5b9e\u4f53\u8fd8\u662f\u4e24\u4e2a\u5b9e\u4f53, \u4ece\u800c\u5bfc\u81f4\u62bd\u53d6\u9519\u8bef. \u7531\u4e8e\u5b58\u5728\u4e0a\u8ff0\u7684\u566a\u58f0\u8bcd\u9519\u8bef, \u5206\u8bcd\u9519\u8bef\u7b49\u95ee\u9898, \u57fa\u4e8e\u6a21\u5f0f\u5339\u914d\u7684\u62bd\u53d6\u4ecd\u7136\u9700\u8981\u91c7\u53d6\u989d\u5916\u7684\u624b\u6bb5\u6765\u63d0\u5347\u62bd\u53d6\u7684\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387. \u5145\u5206\u5229\u7528\u5927\u89c4\u6a21\u8bed\u6599\u4ee5\u53ca\u62bd\u53d6\u8fc7\u7a0b\u4e2d\u95f4\u7ed3\u679c\u7684\u7edf\u8ba1\u6570\u636e\u53ef\u4ee5\u5e2e\u52a9\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898. \u6bd4\u5982\u5bf9\u4e8e\u566a\u58f0\u8bcd\u9519\u8bef, \u53ef\u4ee5\u8bbe\u5b9a3\u4e2a\u5173\u7cfbt1 = \"cats isA dogs\", t2 = \"cats isA animal\", t3 = \"dogs isA animal\"\u4e09\u8005\u7684\u7edf\u8ba1\u4fe1\u606f\u52a0\u4ee5\u7ea0\u9519. \u663e\u7136\u4ece\u5927\u89c4\u6a21\u4e92\u8054\u7f51\u8bed\u6599\u4e2d\u62bd\u53d6\u51fat2\u548ct3\u7684\u9891\u6b21\u8981\u663e\u8457\u9ad8\u4e8et1(\u9891\u6b21\u8d8a\u9ad8\u8d8a\u53ef\u4fe1, \u53cd\u4e4b\u5219\u8d8a\u4e0d\u53ef\u4fe1), \u7ed3\u5408\"\u540c\u4e00\u4e2a\u8bcd\u6c47\u7684\u4e24\u4e2a\u4e0b\u4f4d\u8bcd\u4e0d\u53ef\u80fd\u6ee1\u8db3\u4e0a\u4e0b\u4f4d\u5173\u7cfb\"\u7684\u89c4\u5219, \u53ef\u4ee5\u8bc6\u522b\u51fat1\u662f\u9519\u8bef\u7684. \u57fa\u4e8e\u4e2d\u6587\u56fe\u8c31\u7684\u65b9\u6cd5 \u00b6 \u57fa\u4e8e\u6a21\u5f0f\u7684\u65b9\u6cd5\u4f9d\u8d56\u9ad8\u8d28\u91cf\u7684\u62bd\u53d6\u6a21\u5f0f, \u4f46\u662f\u4e2d\u6587\u7684\u9ad8\u8d28\u91cf\u53e5\u6cd5\u6a21\u5f0f\u8f83\u5c11, \u8fd9\u662f\u56e0\u4e3a\u4e2d\u6587\u7684\u8bed\u6cd5\u76f8\u5bf9\u82f1\u6587\u800c\u8a00>\u66f4\u52a0\u590d\u6742\u548c\u7075\u6d3b. \u4f8b\u5982, \"such as\", \"or | and\"\u7684\u6a21\u5f0f\u5728\u82f1\u6587\u4e2d\u670995.7%\u7684\u51c6\u786e\u7387, \u4f46\u5728\u4e2d\u6587\u573a\u666f\u4e0b\u53ea\u670975.3%\u7684 \u51c6\u786e\u7387. \u5927\u90e8\u5206\u4e2d\u6587\u6a21\u5f0f\u6bd4\u76f8\u5e94\u7684\u82f1\u6587\u6a21\u5f0f\u51c6\u786e\u7387\u4f4e. \u8fd9\u5bfc\u81f4\u57fa\u4e8e\u6a21\u5f0f\u7684\u65b9\u6cd5\u5f88\u96be\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u4e2d\u6587\u6982\u5ff5\u56fe\u8c31, \u800c\u57fa\u4e8e\u5728\u7ebf\u767e\u79d1\u7684\u65b9\u6cd5\u4ec5\u4ece\u767e\u79d1\u7684\u7c7b\u522b\u7cfb\u7edf\u4e2d\u83b7\u53d6isA \u5173\u7cfb, \u8fd9\u79cd\u65b9\u6cd5\u6784\u5efa\u7684\u6982\u5ff5\u56fe\u8c31\u8986\u76d6\u7387\u5f80\u5f80\u4e0d\u9ad8. \u53e6\u4e00\u7c7b\u5178\u578b\u7684\u601d\u8def\u662f\u5c06\u5176\u4ed6\u8bed\u8a00\u7684\u6982\u5ff5\u56fe\u8c31\u7ffb\u8bd1\u6210\u4e2d\u6587. \u4f46\u662f\u8fd9\u4e2a\u601d\u8def\u5b58\u5728\u4e24\u4e2a\u6311\u6218: * \u7b2c\u4e00: \u8bd1\u6cd5\u5b58\u5728\u6b67\u4e49. \u9700\u8981\u5728\u5404\u79cd\u53ef\u80fd\u7684\u8bd1\u6cd5\u4e2d\u9009\u62e9\u5408\u9002\u7684\u8bd1\u6cd5. \u6bd4\u5982, \u5bf9\u4e8e\"China isA country\", China\u53ef\u4ee5\u7ffb\u8bd1\u6210\"\u4e2d\u56fd\", \u6216\u8005\"\u74f7\u5668\", country\u53ef\u4ee5\u7ffb\u8bd1\u6210\"\u56fd\u5bb6\", \u6216\u8005\"\u4e61\u6751\", \u800c\u663e\u7136\u53ea\u6709\"\u4e2d\u56fdisA \u56fd\u5bb6\"\u662f\u6b63\u786e\u7684. \u56e0\u6b64\u4ecd\u7136\u9700\u8981\u5229\u7528\u4e00\u4e9b\u7279\u5f81\u6765\u8bc6\u522b\u6b63\u786e\u7684\u8bd1\u6cd5. \u6bd4\u5982, \u5229\u7528\u8bcd\u5bf9\u7684\u5171\u73b0\u9891\u6b21, \"\u4e2d\u56fd\"\u4e0e\"\u56fd\u5bb6\"\u7684\u5171\u73b0\u9891\u6b21\u8981\u8fdc\u9ad8\u4e8e\u5176\u4ed6\u4e0d\u51c6\u786e\u7684\u7ffb\u8bd1\u8bcd\u5bf9. \u7b2c\u4e8c: \u4e0d\u540c\u8bed\u79cd\u503e\u5411\u4e8e\u8868\u8fbe\u4e0d\u540c\u7684\u77e5\u8bc6. \u4e0d\u540c\u8bed\u79cd\u8868\u8fbe\u7684\u77e5\u8bc6\u76f8\u4ea4\u90e8\u5206\u4e0d\u591a. \u6bd4\u5982, \u4e2d\u6587\u767e\u5ea6\u767e\u79d1\u4e0e\u82f1\u6587\u7ef4\u57fa\u767e\u79d1\u4e2d\u7684\u5b9e\u4f53\u76f8\u4ea4\u6570\u91cf\u53ea\u670940\u4e07\u4e2a\u5de6\u53f3, \u800c\u5b83\u4eec\u7684\u603b\u5b9e\u4f53\u6570\u90fd\u8d85\u8fc7\u4e86400\u4e07\u4e2a. \u4e0d\u540c\u7684\u8bed\u79cd\u5bf9\u5e94\u4e0d\u540c\u7684\u6587\u5316, \u4e0d\u540c\u6587\u5316\u7684\u4eba\u4eec\u5bf9\u4e16\u754c\u7684\u8ba4\u77e5\u662f\u4e0d\u540c\u7684, \u81ea\u7136\u5c31\u6709\u5f88\u591a\u77e5\u8bc6\u53ea\u5728\u7279\u5b9a\u8bed\u8a00\u4e2d\u5b58\u5728\u8868\u8fbe. \u6bd4\u5982, \u4e2d\u56fd\u8bb2\u7a76\u996e\u98df\u6587\u5316, \u70f9\u996a\u65b9\u5f0f\u6709\u62cc, \u814c, \u5364, \u7092, \u7198, \u70e7, \u7116, \u84b8, \u70e4, \u714e, \u70b8, \u7096, \u716e, \u7172, \u70e9\u7b49, \u800c\u5728\u82f1\u6587\u4e2d\u53ea\u6709stew, fry, steam\u7b49\u51e0\u79cd\u6709\u9650\u7684\u70f9\u996a\u65b9\u5f0f, \u65e0\u6cd5\u53cd\u6620\u4e2d\u56fd\u70f9\u996a\u65b9\u5f0f\u7684\u5dee\u522b\u4e0e\u591a\u6837\u6027. \u56e0\u6b64, \u57fa\u4e8e\u7ffb\u8bd1\u7684\u65b9\u6cd5\u6784\u9020\u4e2d\u6587\u6982\u5ff5\u56fe\u8c31, \u5728\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u65b9\u9762\u5747\u9762\u4e34\u5de8\u5927\u6311\u6218!!!","title":"6.1 \u6982\u5ff5\u56fe\u8c31\u7684\u6784\u5efa"},{"location":"6_1.html#_1","text":"","title":"\u6982\u5ff5\u56fe\u8c31\u7684\u6784\u5efa"},{"location":"6_1.html#_2","text":"\u4e86\u89e3\u6982\u5ff5\u56fe\u8c31\u7684\u542b\u4e49. \u4e86\u89e3\u6709\u54ea\u4e9b\u6982\u5ff5\u56fe\u8c31. \u4e86\u89e3\u6982\u5ff5\u56fe\u8c31\u6709\u4ec0\u4e48\u4ef7\u503c\u4e0e\u5e94\u7528. \u4e86\u89e3\u5982\u4f55\u81ea\u52a8\u5316\u6784\u5efa\u4e0e\u5b8c\u5584\u4e00\u4e2a\u5927\u89c4\u6a21\u6982\u5ff5\u56fe\u8c31.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"6_1.html#_3","text":"\u6982\u5ff5\u662f\u8ba4\u77e5\u7684\u57fa\u77f3, \u6784\u5efa\u6982\u5ff5\u56fe\u8c31\u662f\u8ba9\u673a\u5668\u5177\u5907\u6982\u5ff5\u8ba4\u77e5\u80fd\u529b, \u8fdb\u800c\u5f62\u6210\u8ba4\u77e5\u80fd\u529b\u7684\u5173\u952e\u4e00\u73af. \u6240\u8c13\u673a\u5668\u7684\u6982\u5ff5\u8ba4\u77e5, \u4ece\u8ba1\u7b97\u673a\u4fe1\u606f\u5904\u7406\u7684\u89d2\u5ea6\u6765\u8bf4, \u662f\u5bf9\u67d0\u4e2a\u5f62\u6001\u7684\u6570\u636e\u8f93\u5165\u4ea7\u751f\u7b26\u53f7\u5316\u6982\u5ff5\u8f93\u51fa\u7684\u8fc7\u7a0b. \u7b26\u53f7\u5316\u6982\u5ff5\u7684\u53d1\u5c55\u53ef\u80fd\u662f\u4eba\u7c7b\u4ece\u52a8\u7269\u5b9e\u73b0\u667a\u80fd\u8dc3\u8fc1\u800c\u6210\u4e3a\u667a\u4eba\u7684\u9769\u547d\u6027\u4e00\u6b65. \u6b63\u662f\u6982\u5ff5\u7684\u51fa\u73b0, \u4f7f\u5f97\u62bd\u8c61\u601d\u7ef4\u6210\u4e3a\u53ef\u80fd. \u56e0\u6b64\u5c06\u6982\u5ff5\u77e5\u8bc6\u4ee5\u53ca\u76f8\u5e94\u7684\u8ba4\u77e5\u80fd\u529b\u8d4b\u4e88\u673a\u5668, \u4e5f\u5fc5\u5c06\u662f\u673a\u5668\u667a\u80fd\u53d1\u5c55\u5386\u7a0b\u4e2d\u7684\u91cd\u8981\u4e00\u6b65, \u662f\u8ba9\u673a\u5668\u5f62\u6210\u8ba4\u77e5\u7684\u5173\u952e\u6027\u57fa\u7840\u5de5\u4f5c. \u5efa\u8bbe\u6982\u5ff5\u56fe\u8c31\u5c31\u662f\u4e3a\u4e86\u8ba9\u673a\u5668\u4e5f\u80fd\u62e5\u6709\u4eba\u7c7b\u7684\u6982\u5ff5\u77e5\u8bc6, \u8fdb\u800c\u5f62\u6210\u6982\u5ff5\u8ba4\u77e5\u80fd\u529b. \u6982\u5ff5\u56fe\u8c31(Concept Graph)\u662f\u4e00\u7c7b\u4e13\u6ce8\u4e8e\u5b9e\u4f53\u4e0e\u6982\u5ff5\u4e4b\u95f4\u7684isA\u5173\u7cfb\u7684\u77e5\u8bc6\u56fe\u8c31, \u4ece\u8ba4\u77e5\u548c\u8bed\u8a00\u4e24\u4e2a\u89d2\u5ea6, \u6982\u5ff5\u56fe\u8c31\u53ef\u4ee5\u5206\u4e3a\u4e24\u4e2a\u4f53\u7cfb: \u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb (Taxonomy) \u8bcd\u6c47\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb (Lexical Taxonomy) \u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb (Taxonomy): \u5305\u542b\u4e09\u79cd\u5143\u7d20, \u5b9e\u4f53, \u6982\u5ff5, isA\u5173\u7cfb, \u6bd4\u5982\u5728isA\u5173\u7cfb\"apple isA fruit\"\u4e2d, apple\u662f\u5b9e\u4f53, fruit\u662f\u6982\u5ff5. isA\u5173\u7cfb\u53c8\u53ef\u4ee5\u7ec6\u5206\u4e3a\u5b9e\u4f53\u4e0e\u6982\u5ff5\u4e4b\u95f4\u7684instanceOf\u5173\u7cfb\u4ee5\u53ca\u6982\u5ff5\u4e4b\u95f4\u7684subclassOf\u5173\u7cfb. instanceOf\u5173\u7cfb: \u6bd4\u5982\"dog isA animal\"\u8868\u8fbe\u7684\u662f\u5b9e\u4f53\u4e0e\u6982\u5ff5\u4e4b\u95f4\u7684\u5173\u7cfb. subclassOf\u5173\u7cfb: \u6bd4\u5982\"fruit isA food\"\u8868\u8fbe\u7684\u662f\u6982\u5ff5\u5728\u4e4b\u95f4\u7684\u5173\u7cfb.(\u6c34\u679c\u662f\u5b50\u6982\u5ff5, \u98df\u7269\u662f\u7236\u6982\u5ff5) \u4efb\u4f55\u5b9e\u4f53\u6216\u8005\u6982\u5ff5\u90fd\u8981\u901a\u8fc7\u8bed\u8a00\u8868\u8fbe, \u56e0\u6b64\u5b9e\u9645\u5e94\u7528\u4e2d\u901a\u5e38\u4f7f\u7528\u8bcd\u6c47\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb, \u5176\u4e2d\u7684\u8282\u70b9\u662f\u6ca1\u6709\u7ecf\u8fc7\u6d88\u6b67\u7684\u8bcd. \u8bcd\u6c47\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u4e2d\u7684\u57fa\u672c\u5173\u7cfb\u662f\u8bcd\u6c47\u4e4b\u95f4\u7684\u4e0a\u4e0b\u4f4d\u5173\u7cfb. \u6bd4\u5982\"apple isA fruit\", apple\u662ffruit\u7684\u4e0b\u4f4d\u8bcd, fruit\u662fapple\u7684\u4e0a\u4f4d\u8bcd. \u5728\u8bcd\u6c47\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u4e2d, apple\u53ea\u662f\u4e00\u4e2a\u8bcd\u6c47, \u5728\u5f88\u591a\u60c5\u51b5\u4e0b\u5e76\u4e0d\u4e25\u683c\u533a\u5206\u5176\u8bed\u4e49, \u56e0\u6b64apple\u540c\u65f6\u5177\u6709\"\u516c\u53f8\"\u548c\"\u6c34\u679c\"\u4e24\u4e2a\u4e0a\u4f4d\u8bcd. \u601d\u8003: \u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u662f\u5426\u662f\u4e00\u4e2a\u6709\u5411\u65e0\u73af\u56fe?","title":"\u6982\u5ff5\u56fe\u8c31\u7684\u5185\u6db5"},{"location":"6_1.html#_4","text":"\u5728\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u7684\u65e9\u671f, \u4eba\u4eec\u5c31\u5df2\u7ecf\u610f\u8bc6\u5230\u6982\u5ff5\u7684\u91cd\u8981\u6027, \u5e76\u5f00\u5c55\u8fc7\u4e00\u7cfb\u5217\u6982\u5ff5\u83b7\u53d6, \u6982\u5ff5\u77e5\u8bc6\u5e93\u6784\u5efa\u7684\u5de5\u4f5c. \u65f6\u81f3\u4eca\u65e5, \u5de5\u4e1a\u754c\u5df2\u7ecf\u6709\u5927\u91cf\u7684\u6982\u5ff5\u56fe\u8c31, \u5b83\u4eec\u5728\u5404\u79cd\u5e94\u7528\u4e2d\u53d1\u6325\u7740\u79ef\u6781\u7684\u4f5c\u7528, \u5e76\u4e14\u5927\u90e8\u5206\u6982\u5ff5\u56fe\u8c31\u662f\u516c\u5f00, \u53ef\u7528\u7684.","title":"\u5e38\u89c1\u7684\u6982\u5ff5\u56fe\u8c31"},{"location":"6_1.html#wordnet","text":"WordNet\u662f\u666e\u6797\u65af\u987f\u8ba4\u77e5\u79d1\u5b66\u5b9e\u9a8c\u5ba4\u4e8e1985\u5e74\u5f00\u59cb\u521b\u5efa\u7684\u82f1\u6587\u8bcd\u5178, \u65e8\u5728\u4ece\u5fc3\u7406\u8bed\u8a00\u5b66\u89d2\u5ea6\u5efa\u7acb\u82f1\u6587\u8bcd\u6c47\u57fa\u672c\u8bed\u4e49\u5173\u7cfb\u7684\u5b9e\u7528\u6a21\u578b, \u5176\u76ee\u7684\u5728\u4e8e\u901a\u8fc7\u6982\u5ff5\u6765\u5e2e\u52a9\u7528\u6237\u83b7\u53d6\u8bed\u4e49\u77e5\u8bc6. WordNet\u7528\u5355\u8bcd\u7684\u5e38\u89c1\u62fc\u5199\u6765\u8868\u793a\u8bcd\u5f62, \u7528\u540c\u4e49\u8bcd\u8bcd\u96c6\u6765\u8868\u793a\u8bcd\u4e49. WordNet\u5305\u542b\u4e24\u79cd\u7c7b\u578b\u7684\u5173\u7cfb: \u7b2c\u4e00\u79cd: \u8bcd\u6c47\u5173\u7cfb, \u8fd9\u79cd\u5173\u7cfb\u5b58\u5728\u4e8e\u8bcd\u5f62\u4e4b\u95f4. \u7b2c\u4e8c\u79cd: \u8bed\u4e49\u5173\u7cfb, \u8fd9\u79cd\u5173\u7cfb\u5b58\u5728\u4e8e\u8bcd\u4e49\u4e4b\u95f4. \u6ce8\u610f: WordNet\u5229\u7528\u8bcd\u4e49\u800c\u4e0d\u662f\u8bcd\u5f62\u6765\u7ec4\u7ec7\u8bcd\u6c47. WordNet\u7684\u8bed\u4e49\u5173\u7cfb\u5305\u542b: \u540c\u4e49, \u53cd\u4e49, \u4e0a\u4e0b\u4f4d, \u6574\u4f53-\u90e8\u5206. WordNet\u7684\u8bcd\u6c47\u5206\u4e3a5\u7c7b: \u540d\u8bcd, \u52a8\u8bcd, \u5f62\u5bb9\u8bcd, \u526f\u8bcd, \u529f\u80fd\u8bcd. \u4f8b\u5982: \u5f53\u6211\u4eec\u67e5\u8be2\"car\"\u8fd9\u4e2a\u5355\u8bcd\u7684\u65f6\u5019, \"car.n.01\"\u8868\u793acar\u7684\u7b2c\u4e00\u4e2a\u8bcd\u4e49\u5bf9\u5e94\u9879, \u800c\u6839\u636e\u8fb9\u6240\u8868\u8fbe\u7684\u4e0a\u4e0b\u4f4d\u5173\u7cfb, \u53ef\u77e5\"car.n.01\"\u7684\u4e0a\u4f4d\u8bcd\u662f\"motor_vehicle.n.01\".","title":"WordNet"},{"location":"6_1.html#wikitaxonomy","text":"2008\u5e74, Ponzetto\u548cStrube\u63d0\u51fa\u4e86WikiTaxonomy\u6982\u5ff5\u56fe\u8c31, \u5176\u6570\u636e\u6765\u6e90\u4e8e2006\u5e749\u670825\u65e5\u7684\u7ef4\u57fa\u767e\u79d1\u6570\u636e\u5feb\u7167, \u5e76\u5c06\u62bd\u53d6\u51fa\u6765\u7684isA\u77e5\u8bc6\u4ee5RDF\u5f62\u5f0f\u8868\u793a. \u5177\u4f53\u6765\u8bf4, WikiTaxonomy\u4ece127325\u4e2a\u7c7b\u548c267707\u4e2a\u94fe\u63a5\u4e2d\u4ea7\u751f\u4e86105418\u6761isA\u5173\u7cfb, \u5176F1\u503c\u8fbe\u5230\u4e8687.9%.","title":"WikiTaxonomy"},{"location":"6_1.html#probase","text":"Probase\u662f2012\u5e74\u5fae\u8f6f\u4e9a\u6d32\u7814\u7a76\u9662\u63d0\u51fa\u7684\u7814\u7a76\u539f\u578b, \u5176\u76ee\u6807\u662f\u4ece\u7f51\u9875\u6570\u636e\u548c\u641c\u7d22\u8bb0\u5f55\u6570\u636e\u4e2d\u6784\u9020\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u5206\u7c7b\u77e5\u8bc6\u4f53\u7cfb. Probase\u662f\u4ece16\u4ebf\u4e2a\u7f51\u9875\u4e2d\u8fdb\u884c\u81ea\u52a8\u62bd\u53d6\u6784\u9020\u800c\u6210\u7684. \u4f8b\u5982: \"X such as Y\"\u8fd9\u4e00\u6a21\u5f0f\u53ef\u4ee5\u4ece\"household pets such as cats\"\u4e2d\u62bd\u53d6\u51fa\"cats isA household pets\". Probase\u65e9\u671f\u7248\u672c\u5305\u542b\u4e861600\u4e07\u6761isA\u5173\u7cfb, \u51c6\u786e\u7387\u8fbe\u5230\u4e8692%, \u5e76\u4e14\u6bcf\u6761\u5173\u7cfb\u7686\u542b\u6709\u9891\u6570, \u8868\u793a\u8be5\u6761\u5173\u7cfb\u5728\u603b\u4f53\u8bed\u6599\u4e2d\u51fa\u73b0\u7684\u6b21\u6570. \u4f8b\u5982, (Google, isA, Company, 7816), (Apple, isA, Fruit, 6315). \u8fd9\u4e9b\u9891\u6570\u5bf9\u4e8e\u523b\u753b\u5b9e\u4f53\u6216\u8005\u6982\u5ff5\u7684\u5178\u578b\u6027\u5177\u6709\u91cd\u8981\u610f\u4e49. Probase\u7ecf\u8fc7\u540e\u7eed\u51e0\u8f6e\u6269\u5bb9\u540e\u66f4\u540d\u4e3aMicrosoft Concept Graph, \u73b0\u5df2\u5305\u542b\u8d85\u8fc7500\u4e07\u4e2a\u6982\u5ff5, 1200\u591a\u4e07\u4e2a\u5b9e\u4f8b, 8000\u591a\u4e07\u6761isA\u5173\u7cfb.","title":"Probase"},{"location":"6_1.html#_5","text":"\u5927\u8bcd\u6797\u662f\u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66\u793e\u4f1a\u8ba1\u7b97\u4e0e\u4fe1\u606f\u68c0\u7d22\u7814\u7a76\u4e2d\u5fc3\u6784\u5efa\u7684\u4e2d\u6587\u6982\u5ff5\u56fe\u8c31. \u5927\u8bcd\u6797\u662f\u57fa\u4e8e\u5f31\u76d1\u7763\u6846\u67b6\u81ea\u52a8\u6784\u5efa\u800c\u6210\u7684. \u5927\u8bcd\u6797\u5bf9\u6bcf\u4e2a\u5b9e\u4f53\u5206\u522b\u4ece\u641c\u7d22\u5f15\u64ce\u7684\u7ed3\u679c, \u767e\u79d1\u9875\u9762\u548c\u5b9e\u4f53\u540d\u79f0\u8fd9\u4e09\u4e2a\u6570\u636e\u6e90\u4e2d\u83b7\u53d6\u4e0a\u4e0b\u4f4d\u5173\u7cfb, \u7136\u540e\u901a\u8fc7\u6392\u5e8f\u6a21\u5757\u5bf9\u5b9e\u4f53\u7684\u4e0a\u4f4d\u8bcd\u8fdb\u884c\u6392\u5e8f.","title":"\u5927\u8bcd\u6797"},{"location":"6_1.html#cn-probase","text":"CN-Probase\u662f\u590d\u65e6\u5927\u5b66\u77e5\u8bc6\u5de5\u573a\u5b9e\u9a8c\u5ba4\u7814\u53d1\u5e76\u7ef4\u62a4\u7684\u5927\u89c4\u6a21\u4e2d\u6587\u6982\u5ff5\u56fe\u8c31, \u5176isA\u5173\u7cfb\u7684\u51c6\u786e\u7387\u572895%\u4ee5\u4e0a. \u4e0e\u5176\u4ed6\u6982\u5ff5\u56fe\u8c31\u76f8\u6bd4, CN-Probase\u5177\u6709\u4e24\u4e2a\u663e\u8457\u4f18\u70b9: \u7b2c\u4e00\u70b9: \u89c4\u6a21\u5de8\u5927, \u57fa\u672c\u6db5\u76d6\u5e38\u89c1\u7684\u4e2d\u6587\u5b9e\u4f53\u548c\u6982\u5ff5, \u5305\u542b\u7ea61700\u4e07\u4e2a\u5b9e\u4f53, 27\u4e07\u4e2a\u6982\u5ff5\u548c3300\u4e07\u6761isA\u5173\u7cfb. \u7b2c\u4e8c\u70b9: \u4e25\u683c\u6309\u7167\u5b9e\u4f53\u8fdb\u884c\u7ec4\u7ec7, \u6709\u5229\u4e8e\u7cbe\u51c6\u7406\u89e3\u5b9e\u4f53\u7684\u6982\u5ff5. \u5173\u4e8e\u4e0a\u8ff0\u7b2c\u4e8c\u70b9, \u53ef\u4ee5\u4e3e\u4f8b\u5982\u4e0b: \"\u5218\u5fb7\u534e\"\u8fd9\u4e2a\u540d\u5b57\u53ef\u80fd\u5bf9\u5e94\u5f88\u591a\u53eb\"\u5218\u5fb7\u534e\"\u7684\u4eba, \u5728CN-Probase\u91cc\u641c\u7d22\"\u5218\u5fb7\u534e\", \u4f1a\u5c06\u6240\u6709\u5339\u914d\u7684\u5b9e\u4f53\u6309\u7167\u5178\u578b\u6027\u8fdb\u884c\u6392\u5e8f, \u6392\u5728\u7b2c\u4e00\u7684\u662f\u4f17\u6240\u5468\u77e5\u7684\u9999\u6e2f\u6d41\u884c\u5929\u738b\"\u5218\u5fb7\u534e\". \u5218\u5fb7\u534e (\u4e2d\u56fd\u9999\u6e2f\u7537\u6f14\u5458, \u6b4c\u624b, \u5236\u7247\u4eba) \u5218\u5fb7\u534e (\u6e05\u534e\u5927\u5b66\u6559\u6388) \u5218\u5fb7\u534e (\u539f\u6c11\u822a\u5c40\u7a7a\u4e2d\u4ea4\u901a\u7ba1\u7406\u5c40\u5c40\u957f) \u5218\u5fb7\u534e (\u5c71\u4e1c\u94a2\u94c1\u96c6\u56e2\u6709\u9650\u516c\u53f8\u8d22\u52a1\u603b\u76d1) \u5218\u5fb7\u534e (\u65b0\u7586\u9752\u5c11\u5e74\u51fa\u7248\u793e\u51fa\u7248\u7684\u8457\u4f5c) \u5218\u5fb7\u534e (\u6e56\u5317\u7c4d\u70c8\u58eb) \u5218\u5fb7\u534e (\u56db\u5ddd\u7701\u5e7f\u5b89\u7ecf\u6d4e\u6280\u672f\u5f00\u53d1\u533a\u56fd\u5bb6\u7a0e\u52a1\u5c40\u5c40\u957f) \u5218\u5fb7\u534e (\u6c5f\u897f\u7c4d\u70c8\u58eb) \u5218\u5fb7\u534e (\u901a\u5ddd\u533a\u5b66\u751f\u81ea\u4e3b\u4e2d\u5fc3\u4e3b\u4efb)","title":"CN-Probase"},{"location":"6_1.html#_6","text":"\u6982\u5ff5\u56fe\u8c31\u5bf9\u4e8e\u673a\u5668\u8ba4\u77e5\u667a\u80fd\u7684\u5b9e\u73b0\u81f3\u5173\u91cd\u8981, \u8fd9\u79cd\u91cd\u8981\u6027\u4f53\u73b0\u5728\u4e00\u7cfb\u5217\u5b9e\u9645\u5e94\u7528\u4e2d, \u8fd9\u4e9b\u5e94\u7528\u6d89\u53ca\u6982\u5ff5\u56fe\u8c31\u7684\u7b80\u5355\u67e5\u8be2\u4ee5\u53ca\u76f8\u5bf9\u590d\u6742\u7684\u63a8\u7406. \u4e0d\u7ba1\u5e94\u7528\u7684\u5f62\u5f0f\u5982\u4f55, \u90fd\u53ef\u4ee5\u5f52\u7ed3\u4e3a\u5b9e\u4f8b\u5316\u548c\u6982\u5ff5\u5316\u8fd9\u4e24\u4e2a\u6700\u57fa\u672c\u7684\u529f\u80fd. \u5b9e\u4f53\u641c\u7d22: \u7ed9\u5b9a\u4e00\u4e2a\u6982\u5ff5\u4f5c\u4e3a\u67e5\u8be2, \u68c0\u7d22\u8be5\u6982\u5ff5\u7684\u5178\u578b\u5b9e\u4f53. \u4f8b\u5982: \u641c\u7d22\"\u4e0a\u6d77985\u9ad8\u6821\", \u8fd4\u56de\"\u590d\u65e6\u5927\u5b66\", \"\u4e0a\u6d77\u4ea4\u901a\u5927\u5b66\". \u6837\u672c\u589e\u5f3a: \u5229\u7528\u6982\u5ff5\u4e0b\u7684\u5b9e\u4f8b, \u589e\u5f3a\u6837\u672c. \u4f8b\u5982: \u5bf9\u6837\u672c\"\u9890\u548c\u56ed\u5728\u54ea\u91cc?\", \u66ff\u6362\u5b9e\u4f53, \u751f\u6210\"\u5706\u660e\u56ed\u5728\u54ea\u91cc?\", \u4f5c\u4e3a\u65b0\u7684\u6837\u672c. \u6587\u672c\u5206\u7c7b: \u6839\u636e\u6587\u672c\u4e2d\u5b9e\u4f53\u7684\u6982\u5ff5, \u5c06\u6587\u672c\u5206\u4e3a\u4e0d\u540c\u7c7b\u522b. \u4f8b\u5982: \u5305\u542b\"\u8db3\u7403\", \"\u7bee\u7403\"\u7684\u6587\u672c\u5e94\u8be5\u4e0e\u5305\u542b\"\u5b9d\u9a6c\", \"\u5954\u9a70\"\u7684\u6587\u672c\u5c5e\u4e8e\u4e0d\u540c\u7684\u7c7b\u522b. \u4e3b\u9898\u5206\u6790: \u7ed9\u5b9a\u6587\u672c, \u5206\u6790\u6587\u672c\u5c5e\u4e8e\u4ec0\u4e48\u4e3b\u9898. \u4f8b\u5982: \u5305\u542b\"\u8db3\u7403\", \"\u7bee\u7403\"\u7684\u6587\u672c\u5e94\u8be5\u5c5e\u4e8e\u4f53\u80b2\u7c7b\u4e3b\u9898. \u7ed9\u6587\u6863\u6253\u6807\u7b7e: \u7ed9\u5b9a\u6587\u672c, \u7ed9\u6587\u672c\u6253\u4e0a\u82e5\u5e72\u4e2a\u6982\u5ff5\u4f5c\u4e3a\u6807\u7b7e. \u4f8b\u5982: \u5bf9\u6587\u672c\"iPhone\u8fdb\u6c34\u4e86\u600e\u4e48\u529e?\", \u53ef\u4ee5\u6253\u4e0a\"\u624b\u673a, \u7ef4\u4fee\"\u7b49\u6807\u7b7e. \u7528\u6237\u753b\u50cf: \u7ed9\u5b9a\u7528\u6237\u4fe1\u606f, \u4e3a\u7528\u6237\u751f\u6210\u663e\u5f0f\u7684\u6982\u5ff5. \u4f8b\u5982: \u6839\u636e\u63cf\u8ff0\u6587\u672c\"\u7cbe\u901aJava, Android\u5f00\u53d1\", \u53ef\u4ee5\u4e3a\u7528\u6237\u6253\u4e0a\"\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\", \"\u624b\u673aAPP\u5f00\u53d1\", \"Java\u7a0b\u5e8f\u5458\"\u7b49\u6807\u7b7e. \u57fa\u4e8e\u6982\u5ff5\u7684\u89e3\u91ca: \u6839\u636e\u6982\u5ff5\u4fe1\u606f, \u4e3a\u4e8b\u4ef6\u63d0\u4f9b\u89e3\u91ca. \u4f8b\u5982: \u5bf9\u4e8e\u6587\u672c\"\u7279\u65af\u62c9Model S\u7684\u52a0\u901f\u6027\u80fd\u5f88\u597d\", \u53ef\u4ee5\u901a\u8fc7\u5173\u952e\u6982\u5ff5\"\u7279\u65af\u62c9Model S\u662f\u7535\u52a8\u8f66\", \u4ee5\u53ca\"\u7535\u52a8\u8f66\u52a0\u901f\u6027\u80fd\u901a\u5e38\u8f83\u597d\", \u6765\u7ed9\u51fa\u5408\u7406\u53ef\u4fe1\u7684\u89e3\u91ca. \u6982\u5ff5\u5f52\u7eb3: \u4ece\u5b9e\u4f53\u96c6\u5408\u6216\u8005\u8bcd\u888b\u5f52\u7eb3\u6982\u5ff5\u6807\u7b7e. \u4f8b\u5982: \u7ed9\u5b9a\"\u6e05\u534e\u5927\u5b66\", \"\u5317\u4eac\u5927\u5b66\", \u53ef\u4ee5\u5f52\u7eb3\u51fa\"\u4e2d\u56fd\u9ad8\u6821\", \"985\"\u7b49\u6982\u5ff5. \u8bed\u4e49\u8868\u793a: \u5229\u7528\u6982\u5ff5\u96c6\u5408\u8868\u8fbe\u5b9e\u4f53, \u8bcd\u6c47\u7684\u8bed\u4e49. \u4f8b\u5982: \"iPhone X\"\u7684\u8bed\u4e49\u8bfe\u8868\u8fbe\u4e3a\u5176\u6982\u5ff5\u96c6\u5408 {\"\u5168\u9762\u5c4f\u624b\u673a\", \"\u667a\u80fd\u624b\u673a\", \"\u65d7\u8230\u624b\u673a\"}. \u5b9e\u4f53\u63a8\u8350: \u6839\u636e\u4e00\u4e9b\u5b9e\u4f53\u7684\u6982\u5ff5\u4fe1\u606f\u4e3a\u5176\u63a8\u8350\u5176\u4ed6\u5b9e\u4f53. \u4f8b\u5982: \u5f53\u7528\u6237\u641c\u7d22\"iPhone XS\"\u65f6, \u4e3a\u5176\u63a8\u8350\"\u534e\u4e3a P30\"\u7b49\u9ad8\u7aef\u624b\u673a. \u89c4\u5219\u6316\u6398: \u5229\u7528\u6982\u5ff5\u4ece\u5927\u91cf\u6570\u636e\u4e2d\u6316\u6398\u51fa\u5177\u6709\u4e00\u5b9a\u6cdb\u5316\u80fd\u529b\u7684\u89c4\u5219. \u4f8b\u5982: \u4ece\u5065\u8eab\u7684\u4eba\u5403\u852c\u83dc, \u5403\u71d5\u9ea6\u7b49\u98df\u7269, \u53ef\u4ee5\u6316\u6398\u51fa\u5065\u8eab\u7684\u4eba\u4e3b\u8981\u5403\"\u9ad8\u7ea4\u7ef4\u98df\u7269\". \u603b\u7ed3: \u4e0a\u8ff0\u5e94\u7528\u7684\u672c\u8d28\u90fd\u662f\u7528\u6982\u5ff5\u4f5c\u4e3a\u5b9e\u4f53, \u8bcd\u6c47\u6216\u8005\u5176\u4ed6\u5bf9\u8c61\u7684\u8bed\u4e49\u8868\u793a. \u4e0d\u540c\u4e8e\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e2d\u5e38\u7528\u7684\u57fa\u4e8e\u5411\u91cf\u7684\u9690\u5f0f\u8868\u793a, \u57fa\u4e8e\u6982\u5ff5\u7684\u8bed\u4e49\u8868\u793a\u662f\u4e00\u79cd\u663e\u793a\u8868\u793a. \u6982\u5ff5\u662f\u7b26\u53f7, \u662f\u4eba\u7c7b\u53ef\u7406\u89e3\u7684, \u56e0\u6b64\u57fa\u4e8e\u6982\u5ff5\u56fe\u8c31\u7684\u8bed\u4e49\u8868\u793a\u5177\u6709\u53ef\u63a7\u6027, \u53ef\u89e3\u91ca\u6027\u7b49\u4f18\u70b9, \u8fd9\u5728\u5f88\u591a\u573a\u666f\u4e0b\u662f\u975e\u5e38\u6709\u610f\u4e49\u7684!","title":"\u6982\u5ff5\u56fe\u8c31\u7684\u5e94\u7528"},{"location":"6_1.html#_7","text":"\u77e5\u8bc6\u56fe\u8c31\u7684\u89c4\u6a21\u548c\u8d28\u91cf\u662f\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u7684\u91cd\u8981\u56e0\u7d20, \u5bf9\u4e8e\u6982\u5ff5\u56fe\u8c31\u4e5f\u4e0d\u4f8b\u5916. \u4eba\u5de5\u6784\u5efa\u7684\u6982\u5ff5\u56fe\u8c31(\u6bd4\u5982WordNet)\u8d28\u91cf\u7cbe\u826f, \u5df2\u7ecf\u5728\u5f88\u591a\u9886\u57df\u5f97\u4ee5\u5e94\u7528\u5e76\u5f97\u5230\u68c0\u9a8c, \u4f46\u662f\u4eba\u5de5\u6784\u5efa\u7684\u6982\u5ff5\u56fe\u8c31\u89c4\u6a21\u6709\u9650. \u6982\u5ff5\u56fe\u8c31\u5bf9\u4e8e\u5b9e\u4f53\u548c\u6982\u5ff5\u7684\u8986\u76d6\u7387\u76f4\u63a5\u51b3\u5b9a\u4e86\u5176\u80fd\u5426\u80dc\u4efb\u81ea\u7136\u8bed\u8a00\u4e2d\u6d77\u91cf\u5b9e\u4f53\u548c\u6982\u5ff5\u7684\u7406\u89e3\u4efb\u52a1. \u53e6\u5916, \u5927\u89c4\u6a21\u6587\u672c\u4e2d\u4e5f\u8574\u542b\u7740\u4e30\u5bcc\u7684isA\u5173\u7cfb. \u56e0\u6b64, \u4ece\u5927\u89c4\u6a21\u6587\u672c\u4e2d\u81ea\u52a8\u62bd\u53d6isA\u5173\u7cfb\u8fdb\u800c\u6784\u5efa\u5927\u89c4\u6a21\u6982\u5ff5\u56fe\u8c31\u662f\u53ef\u80fd\u7684. \u6838\u5fc3: \u5982\u4f55\u786e\u4fdd\u81ea\u52a8\u5316\u6784\u5efa\u7684\u5927\u89c4\u6a21\u6982\u5ff5\u56fe\u8c31\u7684\u51c6\u786e\u7387? \u8fd9\u662f\u6574\u4e2a\u81ea\u52a8\u5316\u6784\u5efa\u4e2d\u7684\u6838\u5fc3\u95ee\u9898! isA\u5173\u7cfb\u62bd\u53d6\u5f0f\u6784\u5efa\u6982\u5ff5\u56fe\u8c31\u7684\u6838\u5fc3. isA\u5173\u7cfb\u62bd\u53d6\u7684\u65b9\u6cd5\u4e3b\u8981\u5206\u4e3a\u4e09\u79cd: \u57fa\u4e8e\u5728\u7ebf\u767e\u79d1\u7684\u65b9\u6cd5 \u57fa\u4e8e\u6a21\u5f0f\u5339\u914d\u7684\u65b9\u6cd5 \u57fa\u4e8e\u8bcd\u5411\u91cf\u7684\u65b9\u6cd5 \u57fa\u4e8e\u8bcd\u5411\u91cf\u7684\u65b9\u6cd5\u5c06\u8bcd\u6c47\u8868\u4e2d\u7684\u5355\u8bcd\u6216\u77ed\u8bed\u6620\u5c04\u5230\u5411\u91cf\u7a7a\u95f4, \u57fa\u4e8e\u5411\u91cf\u8fd0\u7b97\u53d1\u73b0\u4e0a\u4e0b\u4f4d\u5173\u7cfb. \u901a\u8fc7\u5927\u91cf\u7684\u7814\u7a76\u9a8c\u8bc1, \u53d1\u73b0\u8bcd\u5411\u91cf\u80fd\u591f\u57fa\u672c\u4fdd\u6301\u4e0a\u4e0b\u4f4d\u5173\u7cfb, \u6bd4\u5982\"vector(\u867e) - vector(\u5bf9\u867e)\"\u7ea6\u7b49\u4e8e\"vector(\u9c7c) - vector(\u91d1\u9c7c)\". \u8fd9\u7c7b\u65b9\u6cd5\u601d\u8def\u4e0a\u6bd4\u8f83\u7b80\u5355, \u4f46\u662f\u7531\u4e8e\u5411\u91cf\u5316\u8fc7\u7a0b\u4e2d\u635f\u5931\u4e86\u77e5\u8bc6\u56fe\u8c31\u539f\u6709\u7684\u8bed\u4e49\u4fe1\u606f, \u56e0\u6b64\u76f4\u63a5\u4f7f\u7528\u5411\u91cf\u63a8\u65adisA\u5173\u7cfb\u7684\u6548\u679c\u6bd4\u8f83\u6709\u9650. \u4e00\u822c\u800c\u8a00, \u9700\u8981\u5728\u57fa\u4e8e\u5411\u91cf\u63a8\u65ad\u7684\u57fa\u7840\u4e0a\u8f85\u4ee5\u5176\u4ed6\u8bc1\u636e, \u624d\u80fd\u8fdb\u884cisA\u5173\u7cfb\u7684\u51c6\u786e\u63a8\u65ad, \u8fdb\u800c\u5b8c\u6210\u6982\u5ff5\u56fe\u8c31\u7684\u6784\u5efa.","title":"\u6982\u5ff5\u56fe\u8c31\u7684\u6784\u5efa"},{"location":"6_1.html#_8","text":"\u57fa\u4e8e\u5728\u7ebf\u767e\u79d1\u7684\u65b9\u6cd5\u4e3b\u8981\u662f\u4ece\u767e\u79d1\u7f51\u7ad9\u7684\u6807\u7b7e\u7cfb\u7edf\u4e2d\u62bd\u53d6\u51fa\u6765\u6982\u5ff5\u4e4b\u95f4\u7684isA\u5173\u7cfb. \u6807\u7b7e\u7cfb\u7edf\u7528\u4e8e\u7ec4\u7ec7\u767e\u79d1\u7f51\u7ad9\u4e0a\u7684\u6240\u6709\u5b9e\u4f53, \u4e3a\u6784\u5efa\u6982\u5ff5\u56fe\u8c31\u63d0\u4f9b\u4e86\u7406\u60f3\u7684\u6570\u636e\u6765\u6e90. \u53ea\u9700\u4ece\u6807\u7b7e\u7cfb\u7edf\u4e2d\u7b5b\u9009\u51fa\u9ad8\u8d28\u91cf\u7684\u6982\u5ff5, \u5e76\u5efa\u7acb\u8d77\u6982\u5ff5\u4e4b\u95f4\u7684\u5c42\u7ea7\u5173\u7cfb, \u5c31\u80fd\u5c06\u7528\u6237\u81ea\u53d1\u8d21\u732e\u7684\u6807\u7b7e\u7cfb\u7edf\u8f6c\u6362\u6210\u6709\u7ed3\u6784\u7684\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb. \u4f8b\u5982: \u82f1\u6587\u6982\u5ff5\u56fe\u8c31WikiTaxonomy\u548cYAGO\u90fd\u662f\u57fa\u4e8e\u8fd9\u4e00\u601d\u8def\u6784\u5efa\u800c\u6210\u7684. \u7b2c\u4e00\u6b65: \u6982\u5ff5\u6807\u7b7e\u8bc6\u522b \u6839\u636e\u6807\u7b7e\u7684\u529f\u80fd, \u7ef4\u57fa\u767e\u79d1\u4e2d\u7684\u6807\u7b7e\u53ef\u5206\u4e3a\u6982\u5ff5\u578b\u6807\u7b7e, \u4e3b\u9898\u578b\u6807\u7b7e, \u5c5e\u6027\u578b\u6807\u7b7e\u4ee5\u53ca\u7ba1\u7406\u578b\u6807\u7b7e. \u6982\u5ff5\u578b\u6807\u7b7e: \u6982\u5ff5\u578b\u6807\u7b7e\u7528\u6765\u63cf\u8ff0\u5b9e\u4f53\u6240\u5c5e\u7684\u7c7b\u578b, \u5982\"American male film actors\". \u6982\u5ff5\u6807\u7b7e\u662f\u6982\u5ff5\u56fe\u8c31\u4e2d\u7684\u7406\u60f3\u8282\u70b9. \u4e3b\u9898\u578b\u6807\u7b7e: \u4e3b\u9898\u578b\u6807\u7b7e\u7528\u6765\u63cf\u8ff0\u5b9e\u4f53\u6240\u5c5e\u7684\u4e3b\u9898, \u5982\"Chemistry\". \u5c5e\u6027\u578b\u6807\u7b7e: \u5c5e\u6027\u578b\u6807\u7b7e\u7528\u4e8e\u63cf\u8ff0\u5b9e\u4f53\u7684\u76f8\u5173\u5c5e\u6027\u4fe1\u606f, \u5982\"1989 births\". \u7ba1\u7406\u578b\u6807\u7b7e: \u7ba1\u7406\u578b\u6807\u7b7e\u4e3b\u8981\u7528\u4e8e\u7ba1\u7406\u7ef4\u57fa\u767e\u79d1\u8bcd\u6761, \u6bd4\u5982\"Articles with unsourced statements\". \u65b9\u6cd5: \u5c5e\u6027\u578b\u6807\u7b7e\u548c\u7ba1\u7406\u578b\u6807\u7b7e\u4e00\u822c\u6765\u8bf4\u6bd4\u8f83\u5c11, \u53ef\u4ee5\u901a\u8fc7\u4eba\u5de5\u6216\u8005\u8bbe\u5b9a\u7b80\u5355\u89c4\u5219\u6765\u5254\u9664. \u5269\u4e0b\u7684\u6807\u7b7e\u4e3b\u8981\u662f\u6982\u5ff5\u578b\u6807\u7b7e\u548c\u4e3b\u9898\u578b\u6807\u7b7e. YAGO\u4f7f\u7528\u4e86\u6d45\u5c42\u8bed\u8a00\u5206\u6790\u6765\u8bc6\u522b\u6982\u5ff5\u578b\u6807\u7b7e, \u5176\u57fa\u672c\u601d\u8def\u4e3a\u8bc6\u522b\u51fa\u6807\u7b7e\u540d\u79f0\u4e2d\u7684\u4e2d\u5fc3\u8bcd. \u5982\u679c\u8fd9\u4e2a\u4e2d\u5fc3\u8bcd\u4e3a\u590d\u6570(\u6bd4\u5982\"American male film actors\"\u4e2d\u7684\"actors\"), \u5219\u8ba4\u4e3a\u8be5\u6807\u7b7e\u4e3a\u6982\u5ff5\u578b\u6807\u7b7e; \u5982\u679c\u4e2d\u5fc3\u8bcd\u4e3a\u5355\u6570(\u6bd4\u5982\"Chemistry\"), \u5219\u8ba4\u4e3a\u8fd9\u4e2a\u6807\u7b7e\u4e3a\u4e3b\u9898\u578b\u6807\u7b7e. \u7b2c\u4e8c\u6b65: \u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u6784\u5efa \u5728\u8bc6\u522b\u51fa\u7ef4\u57fa\u767e\u79d1\u4e2d\u7684\u6982\u5ff5\u578b\u6807\u7b7e\u540e, YAGO\u63d0\u51fa\u4e86\u5c06\u8fd9\u4e9b\u6982\u5ff5\u578b\u6807\u7b7e\u4e0eWordNet\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u6982\u5ff5\u5efa\u7acbisA\u5173\u7cfb, \u8fdb\u800c\u6784\u5efa\u4e00\u4e2a\u6bd4WordNet\u66f4\u5927\u7684\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb.","title":"\u5728\u7ebf\u767e\u79d1\u7684\u65b9\u6cd5"},{"location":"6_1.html#_9","text":"\u7ef4\u57fa\u767e\u79d1\u7684\u6807\u7b7e\u7cfb\u7edf\u89c4\u6a21\u6709\u9650, \u8fd9\u51b3\u5b9a\u4e86\u57fa\u4e8e\u7ef4\u57fa\u767e\u79d1\u6784\u5efa\u7684\u6982\u5ff5\u56fe\u8c31\u89c4\u6a21\u6709\u9650, \u96be\u6613\u6ee1\u8db3\u5927\u89c4\u6a21\u5e94\u7528\u7684\u9700\u8981. \u7a81\u7834\u89c4\u6a21\u74f6\u9888\u7684\u4e00\u4e2a\u91cd\u8981\u601d\u8def\u662f\u5c06\u4e92\u8054\u7f51\u4e0a\u7684\u81ea\u7531\u6587\u672c\u4f5c\u4e3a\u6784\u5efa\u6982\u5ff5\u56fe\u8c31\u7684\u6570\u636e\u6e90. \u4e92\u8054\u7f51\u4e0a\u7684\u81ea\u7531\u6587\u672c\u7684\u89c4\u6a21\u51e0\u4e4e\u662f\u65e0\u9650\u7684, \u7531\u6b64\u6784\u5efa\u7684\u6982\u5ff5\u56fe\u8c31\u53ef\u4ee5\u8986\u76d6\u5e38\u89c1\u7684\u5b9e\u4f53\u548c\u6982\u5ff5. \u4ece\u6587\u672c\u4e2d\u62bd\u53d6isA\u5173\u7cfb\u6700\u5e38\u89c1\u7684\u65b9\u6cd5\u662f\u57fa\u4e8e\u6a21\u5f0f(Pattern)\u7684\u62bd\u53d6\u65b9\u6cd5. \u4f8b\u5982: \u5bf9\u4e8e\u6a21\u5f0f\u7279\u5f81\u8bcd\"such as\"\u524d\u540e\u7684\u540d\u8bcd\u77ed\u8bed\u4f5c\u4e3a\u4e0a\u4e0b\u4f4d\u8bcd, \u5bf9\u4e8e\u4e0e\u6b64\u6a21\u5f0f\u5339\u914d\u7684\"companies such as IBM, Apple\", \u4e0d\u96be\u62bd\u53d6\u51fa\"IBM isA Company\", \"Apple isA Company\". \u4f46\u662f\u7c7b\u4f3c\u4e0a\u9762\"such as\"\u6a21\u5f0f\u7279\u5f81\u8bcd\u7684\u505a\u6cd5\u4ecd\u7136\u5b58\u5728\u4e00\u4e9b\u95ee\u9898: \u566a\u58f0\u8bcd\u9519\u8bef: \u6a21\u5f0f\u524d\u540e\u7684\u566a\u58f0\u8bcd\u6c47\u4f1a\u5bfc\u81f4\u62bd\u53d6\u9519\u8bef. \u4f8b\u5982, \u5bf9\"animals other than dogs such as cats\"\u7684\u62bd\u53d6\u4f1a\u5f97\u5230\u9519\u8bef\u7684isA\u5173\u7cfb, \"cats isA dogs\", \u4e3b\u8981\u539f\u56e0\u662f\u56e0\u4e3a\u566a\u58f0\u8bcd\"other than\"\u7684\u5e72\u6270\u6240\u81f4. \u5206\u8bcd\u9519\u8bef: \u5206\u8bcd\u9519\u8bef\u4f1a\u5bfc\u81f4\u62bd\u53d6\u9519\u8bef. \u4f8b\u5982, \u5bf9\"algorithms including SVM, LR and RF\", \u5206\u8bcd\u6a21\u578b\u96be\u6613\u786e\u5b9a\"LR and RF\"\u5230\u5e95\u662f\u4e00\u4e2a\u5b9e\u4f53\u8fd8\u662f\u4e24\u4e2a\u5b9e\u4f53, \u4ece\u800c\u5bfc\u81f4\u62bd\u53d6\u9519\u8bef. \u7531\u4e8e\u5b58\u5728\u4e0a\u8ff0\u7684\u566a\u58f0\u8bcd\u9519\u8bef, \u5206\u8bcd\u9519\u8bef\u7b49\u95ee\u9898, \u57fa\u4e8e\u6a21\u5f0f\u5339\u914d\u7684\u62bd\u53d6\u4ecd\u7136\u9700\u8981\u91c7\u53d6\u989d\u5916\u7684\u624b\u6bb5\u6765\u63d0\u5347\u62bd\u53d6\u7684\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387. \u5145\u5206\u5229\u7528\u5927\u89c4\u6a21\u8bed\u6599\u4ee5\u53ca\u62bd\u53d6\u8fc7\u7a0b\u4e2d\u95f4\u7ed3\u679c\u7684\u7edf\u8ba1\u6570\u636e\u53ef\u4ee5\u5e2e\u52a9\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898. \u6bd4\u5982\u5bf9\u4e8e\u566a\u58f0\u8bcd\u9519\u8bef, \u53ef\u4ee5\u8bbe\u5b9a3\u4e2a\u5173\u7cfbt1 = \"cats isA dogs\", t2 = \"cats isA animal\", t3 = \"dogs isA animal\"\u4e09\u8005\u7684\u7edf\u8ba1\u4fe1\u606f\u52a0\u4ee5\u7ea0\u9519. \u663e\u7136\u4ece\u5927\u89c4\u6a21\u4e92\u8054\u7f51\u8bed\u6599\u4e2d\u62bd\u53d6\u51fat2\u548ct3\u7684\u9891\u6b21\u8981\u663e\u8457\u9ad8\u4e8et1(\u9891\u6b21\u8d8a\u9ad8\u8d8a\u53ef\u4fe1, \u53cd\u4e4b\u5219\u8d8a\u4e0d\u53ef\u4fe1), \u7ed3\u5408\"\u540c\u4e00\u4e2a\u8bcd\u6c47\u7684\u4e24\u4e2a\u4e0b\u4f4d\u8bcd\u4e0d\u53ef\u80fd\u6ee1\u8db3\u4e0a\u4e0b\u4f4d\u5173\u7cfb\"\u7684\u89c4\u5219, \u53ef\u4ee5\u8bc6\u522b\u51fat1\u662f\u9519\u8bef\u7684.","title":"\u6a21\u5f0f\u5339\u914d\u7684\u65b9\u6cd5"},{"location":"6_1.html#_10","text":"\u57fa\u4e8e\u6a21\u5f0f\u7684\u65b9\u6cd5\u4f9d\u8d56\u9ad8\u8d28\u91cf\u7684\u62bd\u53d6\u6a21\u5f0f, \u4f46\u662f\u4e2d\u6587\u7684\u9ad8\u8d28\u91cf\u53e5\u6cd5\u6a21\u5f0f\u8f83\u5c11, \u8fd9\u662f\u56e0\u4e3a\u4e2d\u6587\u7684\u8bed\u6cd5\u76f8\u5bf9\u82f1\u6587\u800c\u8a00>\u66f4\u52a0\u590d\u6742\u548c\u7075\u6d3b. \u4f8b\u5982, \"such as\", \"or | and\"\u7684\u6a21\u5f0f\u5728\u82f1\u6587\u4e2d\u670995.7%\u7684\u51c6\u786e\u7387, \u4f46\u5728\u4e2d\u6587\u573a\u666f\u4e0b\u53ea\u670975.3%\u7684 \u51c6\u786e\u7387. \u5927\u90e8\u5206\u4e2d\u6587\u6a21\u5f0f\u6bd4\u76f8\u5e94\u7684\u82f1\u6587\u6a21\u5f0f\u51c6\u786e\u7387\u4f4e. \u8fd9\u5bfc\u81f4\u57fa\u4e8e\u6a21\u5f0f\u7684\u65b9\u6cd5\u5f88\u96be\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u4e2d\u6587\u6982\u5ff5\u56fe\u8c31, \u800c\u57fa\u4e8e\u5728\u7ebf\u767e\u79d1\u7684\u65b9\u6cd5\u4ec5\u4ece\u767e\u79d1\u7684\u7c7b\u522b\u7cfb\u7edf\u4e2d\u83b7\u53d6isA \u5173\u7cfb, \u8fd9\u79cd\u65b9\u6cd5\u6784\u5efa\u7684\u6982\u5ff5\u56fe\u8c31\u8986\u76d6\u7387\u5f80\u5f80\u4e0d\u9ad8. \u53e6\u4e00\u7c7b\u5178\u578b\u7684\u601d\u8def\u662f\u5c06\u5176\u4ed6\u8bed\u8a00\u7684\u6982\u5ff5\u56fe\u8c31\u7ffb\u8bd1\u6210\u4e2d\u6587. \u4f46\u662f\u8fd9\u4e2a\u601d\u8def\u5b58\u5728\u4e24\u4e2a\u6311\u6218: * \u7b2c\u4e00: \u8bd1\u6cd5\u5b58\u5728\u6b67\u4e49. \u9700\u8981\u5728\u5404\u79cd\u53ef\u80fd\u7684\u8bd1\u6cd5\u4e2d\u9009\u62e9\u5408\u9002\u7684\u8bd1\u6cd5. \u6bd4\u5982, \u5bf9\u4e8e\"China isA country\", China\u53ef\u4ee5\u7ffb\u8bd1\u6210\"\u4e2d\u56fd\", \u6216\u8005\"\u74f7\u5668\", country\u53ef\u4ee5\u7ffb\u8bd1\u6210\"\u56fd\u5bb6\", \u6216\u8005\"\u4e61\u6751\", \u800c\u663e\u7136\u53ea\u6709\"\u4e2d\u56fdisA \u56fd\u5bb6\"\u662f\u6b63\u786e\u7684. \u56e0\u6b64\u4ecd\u7136\u9700\u8981\u5229\u7528\u4e00\u4e9b\u7279\u5f81\u6765\u8bc6\u522b\u6b63\u786e\u7684\u8bd1\u6cd5. \u6bd4\u5982, \u5229\u7528\u8bcd\u5bf9\u7684\u5171\u73b0\u9891\u6b21, \"\u4e2d\u56fd\"\u4e0e\"\u56fd\u5bb6\"\u7684\u5171\u73b0\u9891\u6b21\u8981\u8fdc\u9ad8\u4e8e\u5176\u4ed6\u4e0d\u51c6\u786e\u7684\u7ffb\u8bd1\u8bcd\u5bf9. \u7b2c\u4e8c: \u4e0d\u540c\u8bed\u79cd\u503e\u5411\u4e8e\u8868\u8fbe\u4e0d\u540c\u7684\u77e5\u8bc6. \u4e0d\u540c\u8bed\u79cd\u8868\u8fbe\u7684\u77e5\u8bc6\u76f8\u4ea4\u90e8\u5206\u4e0d\u591a. \u6bd4\u5982, \u4e2d\u6587\u767e\u5ea6\u767e\u79d1\u4e0e\u82f1\u6587\u7ef4\u57fa\u767e\u79d1\u4e2d\u7684\u5b9e\u4f53\u76f8\u4ea4\u6570\u91cf\u53ea\u670940\u4e07\u4e2a\u5de6\u53f3, \u800c\u5b83\u4eec\u7684\u603b\u5b9e\u4f53\u6570\u90fd\u8d85\u8fc7\u4e86400\u4e07\u4e2a. \u4e0d\u540c\u7684\u8bed\u79cd\u5bf9\u5e94\u4e0d\u540c\u7684\u6587\u5316, \u4e0d\u540c\u6587\u5316\u7684\u4eba\u4eec\u5bf9\u4e16\u754c\u7684\u8ba4\u77e5\u662f\u4e0d\u540c\u7684, \u81ea\u7136\u5c31\u6709\u5f88\u591a\u77e5\u8bc6\u53ea\u5728\u7279\u5b9a\u8bed\u8a00\u4e2d\u5b58\u5728\u8868\u8fbe. \u6bd4\u5982, \u4e2d\u56fd\u8bb2\u7a76\u996e\u98df\u6587\u5316, \u70f9\u996a\u65b9\u5f0f\u6709\u62cc, \u814c, \u5364, \u7092, \u7198, \u70e7, \u7116, \u84b8, \u70e4, \u714e, \u70b8, \u7096, \u716e, \u7172, \u70e9\u7b49, \u800c\u5728\u82f1\u6587\u4e2d\u53ea\u6709stew, fry, steam\u7b49\u51e0\u79cd\u6709\u9650\u7684\u70f9\u996a\u65b9\u5f0f, \u65e0\u6cd5\u53cd\u6620\u4e2d\u56fd\u70f9\u996a\u65b9\u5f0f\u7684\u5dee\u522b\u4e0e\u591a\u6837\u6027. \u56e0\u6b64, \u57fa\u4e8e\u7ffb\u8bd1\u7684\u65b9\u6cd5\u6784\u9020\u4e2d\u6587\u6982\u5ff5\u56fe\u8c31, \u5728\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u65b9\u9762\u5747\u9762\u4e34\u5de8\u5927\u6311\u6218!!!","title":"\u57fa\u4e8e\u4e2d\u6587\u56fe\u8c31\u7684\u65b9\u6cd5"},{"location":"6_2.html","text":"\u767e\u79d1\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u767e\u79d1\u77e5\u8bc6\u56fe\u8c31\u7684\u5185\u6db5. \u4e86\u89e3\u767e\u79d1\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u65b9\u6cd5. \u767e\u79d1\u77e5\u8bc6\u56fe\u8c31\u6982\u5ff5 \u00b6 \u767e\u79d1\u56fe\u8c31\u7684\u6982\u5ff5 \u00b6 \u767e\u79d1\u56fe\u8c31\u662f\u4e00\u7c7b\u4ee5\u767e\u79d1\u7c7b\u7f51\u7ad9\u4f5c\u4e3a\u4e3b\u8981\u6570\u636e\u6e90\u6784\u5efa\u800c\u6210\u7684\u77e5\u8bc6\u56fe\u8c31. \u4e0e\u7eaf\u6587\u672c\u9875\u9762\u4e0d\u540c, \u767e\u79d1\u7c7b\u7f51\u7ad9\u7684\u9875\u9762\u4e2d\u5305\u542b\u4e30\u5bcc\u7684\u7ed3\u6784\u5316\u4fe1\u606f. \u6bd4\u5982, \u9875\u9762A\u662f\u6765\u81ea\u65b0\u95fb\u7f51\u7ad9\u7684\u7eaf\u6587\u672c\u9875\u9762, \u4f7f\u7528\u6587\u672c\u6587\u5b57\u5bf9\u7535\u5f71\u8fdb\u884c\u4ecb\u7ecd, \u7528\u6237\u9700\u8981\u4ed4\u7ec6\u9605\u8bfb\u6587\u5b57\u624d\u80fd\u5bf9\u7535\u5f71\u6709\u6240\u4e86\u89e3. \u9875\u9762B\u662f\u767e\u79d1\u9875\u9762, \u5176\u4e2d\u5305\u542b\u4e86\u4e30\u5bcc\u7684\u683c\u5f0f\u6807\u8bb0, \u5305\u62ec\u6807\u9898, \u6458\u8981, Infobox, \u4e3b\u8981\u6f14\u5458\u7b49\u533a\u57df\u6807\u8bb0, \u5bf9\u5185\u5bb9\u5206\u95e8\u522b\u7c7b\u7684\u8fdb\u884c\u7ec4\u7ec7, \u65b9\u4fbf\u7528\u6237\u7406\u89e3\u8fd9\u90e8\u7535\u5f71. \u603b\u800c\u8a00\u4e4b, \u767e\u79d1\u7c7b\u7f51\u7ad9\u9875\u9762\u4e2d\u7684\u4fe1\u606f\u7ec4\u7ec7\u66f4\u52a0\u7ed3\u6784\u5316, \u4fbf\u4e8e\u7528\u6237\u9605\u8bfb\u548c\u7406\u89e3, \u4e3b\u8981\u6709\u4ee5\u4e0b\u7279\u70b9: \u77e5\u8bc6\u5168\u9762: \u6839\u636e\u4e2d\u56fd\u5927\u767e\u79d1\u5168\u4e66\u7684\u5b9a\u4e49, \u767e\u79d1\u662f\u6982\u8981\u4ecb\u7ecd\u4eba\u7c7b\u4e00\u5207\u95e8\u7c7b\u77e5\u8bc6\u6216\u67d0\u4e00\u95e8\u7c7b\u77e5\u8bc6\u7684\u5de5\u5177\u4e66. \u4ece\u7406\u8bba\u4e0a\u6765\u8bf4, \u767e\u79d1\u7c7b\u7f51\u7ad9\u80fd\u8986\u76d6\u5168\u90e8\u77e5\u8bc6. \u5b9e\u4f53\u72ec\u7acb: \u6bcf\u4e2a\u5b9e\u4f53\u5bf9\u5e94\u4e00\u4e2a\u9875\u9762, \u6bcf\u4e2a\u9875\u9762\u5747\u56f4\u7ed5\u4e00\u4e2a\u72ec\u7acb\u7684\u5b9e\u4f53\u8fdb\u884c\u5168\u9762\u7684\u4ecb\u7ecd. \u683c\u5f0f\u7edf\u4e00: \u6bcf\u4e2a\u9875\u9762\u90fd\u7531\u7edf\u4e00\u7684\u7f51\u9875\u6a21\u677f\u81ea\u52a8\u751f\u6210, \u5305\u542b\u56fa\u5b9a\u683c\u5f0f\u7684\u534a\u7ed3\u6784\u5316\u6587\u672c. \u8d28\u91cf\u4f18\u826f: \u6bcf\u4e2a\u9875\u9762\u7684\u5185\u5bb9\u90fd\u7531\u4f17\u5305\u5de5\u4eba\u6216\u8005\u4e13\u4e1a\u4eba\u5458\u7f16\u8f91, \u800c\u4e14\u901a\u5e38\u6709\u7740\u4e25\u683c\u7684\u5ba1\u6838\u673a\u5236, \u51c6\u786e\u7387\u8f83\u9ad8. \u6838\u5fc3: \u4ee5\u767e\u79d1\u7c7b\u7f51\u7ad9\u4f5c\u4e3a\u6570\u636e\u6e90\u7684\u767e\u79d1\u56fe\u8c31\u5177\u6709\u77e5\u8bc6\u5b8c\u5907, \u83b7\u53d6\u5bb9\u6613, \u62bd\u53d6\u7b80\u5355, \u8d28\u91cf\u4f18\u826f\u7b49\u4f18\u70b9. \u767e\u79d1\u56fe\u8c31\u7684\u610f\u4e49 \u00b6 \u767e\u79d1\u56fe\u8c31\u7684\u7814\u7a76\u5177\u6709\u91cd\u5927\u610f\u4e49, \u5176\u4e3b\u8981\u8868\u73b0\u5728\u4e00\u4e0b\u51e0\u4e2a\u65b9\u9762: 1: \u652f\u6491\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa 2: \u4e3a\u673a\u5668\u8bed\u8a00\u7406\u89e3\u63d0\u4f9b\u901a\u7528\u77e5\u8bc6 3: \u652f\u6491\u8bed\u6599\u81ea\u52a8\u6807\u6ce8 \u7b2c\u4e00: \u652f\u6491\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa \u5f88\u591a\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u662f\u5efa\u7acb\u5728\u901a\u7528\u77e5\u8bc6\u56fe\u8c31\u57fa\u7840\u4e4b\u4e0a\u7684. \u767e\u79d1\u56fe\u8c31\u5bf9\u9886\u57df\u56fe\u8c31\u8d77\u7740\u91cd\u8981\u7684\u652f\u6491\u4f5c\u7528. \u767e\u79d1\u56fe\u8c31\u662f\u4e00\u7c7b\u5178\u578b\u7684\u901a\u7528\u77e5\u8bc6\u56fe\u8c31. \u767e\u79d1\u56fe\u8c31\u4e00\u65b9\u9762\u53ef\u4ee5\u7ed9\u5f88\u591a\u9886\u57df\u56fe\u8c31\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7684\u79cd\u5b50\u4e8b\u5b9e, \u53e6\u4e00\u65b9\u9762\u53ef\u4ee5\u63d0\u4f9b\u9886\u57df\u6a21\u5f0f. \u6b64\u5916, \u5f88\u591a\u9886\u57df\u77e5\u8bc6\u5c31\u662f\u4ee5\u9886\u57df\u767e\u79d1\u7684\u5f62\u5f0f\u5b58\u5728, \u6bd4\u5982\u7535\u5f71\u7f51\u7ad9, \u97f3\u4e50\u7f51\u7ad9\u7b49. \u53e6\u5916, \u4e00\u4e9b\u4f01\u4e1a\u7684\u77e5\u8bc6\u5206\u4eab\u5e73\u53f0\u4e5f\u662f\u767e\u79d1\u5f62\u5f0f\u7684. \u56e0\u6b64, \u9762\u5411\u767e\u79d1\u7c7b\u578b\u6570\u636e\u6e90\u7684\u77e5\u8bc6\u83b7\u53d6\u6280\u672f\u5bf9\u4e8e\u9886\u57df\u56fe\u8c31\u7684\u6784\u5efa\u5177\u6709\u79ef\u6781\u610f\u4e49. \u7b2c\u4e8c: \u4e3a\u673a\u5668\u8bed\u8a00\u7406\u89e3\u63d0\u4f9b\u901a\u7528\u77e5\u8bc6 \u673a\u5668\u7406\u89e3\u81ea\u7136\u8bed\u8a00\u9700\u8981\u4e30\u5bcc\u7684\u80cc\u666f\u77e5\u8bc6, \u5176\u4e2d\u7684\u5173\u952e\u4e4b\u4e00\u662f\u901a\u7528\u77e5\u8bc6(Common Knowledge). \u6bd4\u5982, \u4e2d\u56fd\u7684\u9996\u90fd\u662f\u5317\u4eac, \u5730\u7403\u7684\u536b\u661f\u662f\u6708\u7403. \u901a\u7528\u77e5\u8bc6\u7684\u91cd\u8981\u8f7d\u4f53\u5c31\u662f\u767e\u79d1. \u767e\u79d1\u56fe\u8c31\u5b58\u50a8\u4e86\u6d77\u91cf\u5b9e\u4f53\u7684\u77e5\u8bc6, \u8fd9\u4e9b\u77e5\u8bc6\u53ef\u4ee5\u4f5c\u4e3a\u80cc\u666f\u77e5\u8bc6\u652f\u6491\u673a\u5668\u8bed\u8a00\u7406\u89e3, \u63d0\u5347\u673a\u5668\u5b66\u4e60\u6548\u679c\u7684\u91cd\u8981\u80cc\u666f\u77e5\u8bc6. \u7b2c\u4e09: \u652f\u6491\u8bed\u6599\u81ea\u52a8\u6807\u6ce8 \u5f53\u524d\u7684\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4efb\u52a1\u5927\u91cf\u91c7\u7528\u76d1\u7763\u5b66\u4e60\u6a21\u578b, \u800c\u8fd9\u5f80\u5f80\u9700\u8981\u5927\u91cf\u7684\u6807\u6ce8\u6837\u672c. \u4eba\u5de5\u6807\u6ce8\u8bed\u6599\u8d39\u65f6, \u8d39\u529b, \u5e76\u4e14\u8bed\u6599\u89c4\u6a21\u6709\u9650, \u96be\u6613\u6709\u6548\u652f\u6301\u6a21\u578b\u7684\u8bad\u7ec3. \u767e\u79d1\u56fe\u8c31\u5305\u542b\u4e30\u5bcc\u7684\u5b9e\u4f53\u548c\u5173\u7cfb\u77e5\u8bc6, \u53ef\u4ee5\u81ea\u52a8\u6807\u6ce8\u5927\u91cf\u8bed\u6599. \u8bcd\u6c47\u6316\u6398, \u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4ee5\u53ca\u5173\u7cfb\u62bd\u53d6\u7b49\u4efb\u52a1\u90fd\u53ef\u4ee5\u4f7f\u7528\u767e\u79d1\u4e2d\u7684\u7ed3\u6784\u5316\u77e5\u8bc6\u4e0e\u6587\u672c\u7684\u81ea\u52a8\u6bd4\u5bf9\u5b9e\u73b0\u81ea\u52a8\u6807\u6ce8. \u8fd9\u7c7b\u65b9\u6cd5\u88ab\u79f0\u4e3a\u8fdc\u7a0b\u76d1\u7763\u5b66\u4e60(Distant Supervision), \u95f4\u63a5\u76d1\u7763\u5b66\u4e60(Indirect Supervision)\u7b49. \u767e\u79d1\u56fe\u8c31\u7684\u5206\u7c7b \u00b6 \u767e\u79d1\u56fe\u8c31(\u6570\u636e\u6e90): \u901a\u7528\u767e\u79d1\u56fe\u8c31 \u9886\u57df\u767e\u79d1\u56fe\u8c31 \u767e\u79d1\u56fe\u8c31\u6839\u636e\u5176\u6570\u636e\u6e90\u7684\u7279\u70b9\u53ef\u4ee5\u5206\u4e3a\u901a\u7528\u767e\u79d1\u56fe\u8c31\u548c\u9886\u57df\u767e\u79d1\u56fe\u8c31. \u901a\u7528\u767e\u79d1\u56fe\u8c31\u6765\u81ea\u901a\u7528\u767e\u79d1\u7c7b\u7f51\u7ad9, \u5305\u542b\u6765\u81ea\u5404\u4e2a\u9886\u57df\u7684\u5b9e\u4f53. \u9886\u57df\u767e\u79d1\u56fe\u8c31\u6765\u81ea\u9886\u57df\u767e\u79d1\u7c7b\u7f51\u7ad9, \u4ec5\u5305\u542b\u7279\u5b9a\u9886\u57df\u7684\u5b9e\u4f53, \u5982\u7535\u5f71\u7f51\u7ad9, \u8d2d\u7269\u7f51\u7ad9, \u5de5\u5546\u7f51\u7ad9\u548c\u6cd5\u5f8b\u7f51\u7ad9\u7b49. \u8fd9\u4e9b\u7f51\u7ad9\u4e5f\u662f\u6bcf\u4e2a\u9875\u9762\u4ecb\u7ecd\u4e00\u4e2a\u5b9e\u4f53, \u540c\u65f6\u6bcf\u4e2a\u9875\u9762\u4e2d\u90fd\u5305\u542b\u5927\u91cf\u7684\u673a\u6784\u5316\u5185\u5bb9. \u767e\u79d1\u56fe\u8c31(\u6784\u5efa\u65b9\u6cd5): \u5355\u4e2a\u6570\u636e\u6e90 \u591a\u4e2a\u6570\u636e\u6e90 \u767e\u79d1\u56fe\u8c31\u6839\u636e\u6784\u5efa\u7684\u65b9\u6cd5\u5206\u4e3a\u4e24\u7c7b, \u4e00\u7c7b\u662f\u9488\u5bf9\u5355\u4e2a\u6570\u636e\u6e90(\u5355\u6e90)\u800c\u6784\u5efa\u7684\u767e\u79d1\u56fe\u8c31, \u5178\u578b\u4ee3\u8868\u6709DBPedia, YAGO, CN-DBPedia\u7b49. \u5176\u4e2d, DBPedia\u548cYAGO\u4ee5\u7ef4\u57fa\u767e\u79d1\u4f5c\u4e3a\u6570\u636e\u6e90, CN-DBPedia\u4ee5\u767e\u5ea6\u767e\u79d1\u4f5c\u4e3a\u6570\u636e\u6e90. \u53e6\u4e00\u7c7b\u662f\u878d\u5408\u591a\u4e2a\u6570\u636e\u6e90(\u591a\u6e90)\u800c\u6784\u5efa\u7684\u767e\u79d1\u56fe\u8c31, \u5178\u578b\u4ee3\u8868\u6709BabelNet, zhishi.me\u548cXLORE\u7b49. BabelNet\u878d\u5408\u4e86284\u79cd\u4e0d\u540c\u8bed\u8a00\u7684\u6570\u636e\u6e90, zhishi.me\u878d\u5408\u4e86\u767e\u5ea6\u767e\u79d1, \u4e92\u52a8\u767e\u79d1\u4ee5\u53ca\u4e2d\u6587\u7ef4\u57fa\u767e\u79d1, XLORE\u878d\u5408\u4e86\u767e\u5ea6\u767e\u79d1, \u4e92\u52a8\u767e\u79d1\u4ee5\u53ca\u82f1\u6587\u7ef4\u57fa\u767e\u79d1. \u6b64\u5916, \u6700\u65b0\u7248\u672c\u7684DBPedia\u548cYAGO\u4e5f\u878d\u5408\u4e86\u4e0d\u540c\u8bed\u8a00\u7248\u672c\u7684\u7ef4\u57fa\u767e\u79d1\u5e76\u6784\u5efa\u4e86\u8de8\u8bed\u8a00\u7684\u767e\u79d1\u56fe\u8c31. \u603b\u7ed3: \u5355\u6e90\u767e\u79d1\u56fe\u8c31\u7684\u6784\u5efa\u65b9\u6cd5\u4fa7\u91cd\u4e8e\u62bd\u53d6, \u591a\u6e90\u767e\u79d1\u56fe\u8c31\u7684\u6784\u5efa\u65b9\u6cd5\u4fa7\u91cd\u4e8e\u878d\u5408! \u57fa\u4e8e\u5355\u6e90\u7684\u767e\u79d1\u56fe\u8c31\u6784\u5efa \u00b6 \u57fa\u4e8e\u5355\u6e90\u7684\u767e\u79d1\u56fe\u8c31\u662f\u4ee5\u5355\u4e2a\u767e\u79d1\u767e\u79d1\u7c7b\u7f51\u7ad9\u4f5c\u4e3a\u6570\u636e\u6e90\u6784\u5efa\u800c\u6210\u7684\u767e\u79d1\u56fe\u8c31. \u5176\u8f93\u5165\u662f\u4e00\u4e2a\u767e\u79d1\u7c7b\u7f51\u7ad9, \u8f93>\u51fa\u662f\u4e00\u4e2a\u767e\u79d1\u56fe\u8c31. \u4f8b\u5982, \u8f93\u5165\u7ef4\u57fa\u767e\u79d1, \u8f93\u51faDBPedia; \u8f93\u5165\u767e\u5ea6\u767e\u79d1, \u8f93\u51faCN-DBPedia. \u57fa\u4e8e\u5355\u6e90\u7684\u767e\u79d1\u56fe\u8c31\u6784\u5efa\u4e3b\u8981\u52065\u4e2a\u6b65\u9aa4: 1: \u6570\u636e\u83b7\u53d6, \u76ee\u6807\u662f\u627e\u5230\u4e00\u4e2a\u767e\u79d1\u7c7b\u7f51\u7ad9\u6240\u6709\u5b9e\u4f53\u7684\u4ecb\u7ecd\u9875\u9762. 2: \u5c5e\u6027\u62bd\u53d6, \u76ee\u6807\u662f\u4ece\u767e\u79d1\u9875\u9762\u7684\u534a\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u62bd\u53d6\u51fa\u5b9e\u4f53\u7684\u5c5e\u6027\u77e5\u8bc6. 3: \u5173\u7cfb\u6784\u5efa, \u76ee\u6807\u662f\u5efa\u7acb\u5b9e\u4f53\u4e0e\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u8054. 4: \u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u6784\u5efa, \u76ee\u6807\u662f\u5efa\u7acb\u4e00\u4e2a\u6982\u5ff5\u96c6\u5408\u4ee5\u53ca\u6982\u5ff5\u4e4b\u95f4\u7684\u5c42\u7ea7\u5173\u7cfb. 5: \u5b9e\u4f53\u5206\u7c7b, \u76ee\u6807\u662f\u5c06\u5b9e\u4f53\u5206\u7c7b\u5230\u4e0a\u4e00\u6b65\u5efa\u7acb\u7684\u6982\u5ff5\u96c6\u5408\u4e2d. \u6570\u636e\u83b7\u53d6 \u00b6 \u767e\u79d1\u7c7b\u7f51\u7ad9\u4e0d\u4ec5\u5305\u542b\u5b9e\u4f53\u9875\u9762, \u8fd8\u5305\u542b\u5f88\u591a\u5176\u4ed6\u7684\u8f85\u52a9\u9875\u9762, \u5305\u62ec\u5fd7\u613f\u8005\u9875\u9762, \u6807\u7b7e\u9875\u9762, \u4e3b\u9898\u9875\u9762\u7b49 \u7b2c\u4e00\u6b65: \u83b7\u53d6\u4e00\u4e2a\u767e\u79d1\u7c7b\u7f51\u7ad9\u7684\u5168\u90e8\u9875\u9762. \u7b2c\u4e8c\u6b65: \u4ece\u5168\u90e8\u9875\u9762\u4e2d\u8bc6\u522b\u51fa\u5b9e\u4f53\u7684\u4ecb\u7ecd\u9875\u9762. \u83b7\u53d6\u4e00\u4e2a\u767e\u79d1\u7c7b\u7f51\u7ad9\u7684\u5168\u90e8\u9875\u9762\u6709\u4e09\u79cd\u7b56\u7565: \u57fa\u4e8e\u5907\u4efd\u6587\u4ef6\u7684\u4e0b\u8f7d: \u6709\u4e9b\u5728\u7ebf\u767e\u79d1\u7c7b\u7f51\u7ad9\u4f1a\u5b9a\u671f\u5bf9\u5916\u53d1\u5e03\u5168\u90e8\u9875\u9762\u7684\u5907\u4efd\u6587\u4ef6. \u7528\u6237\u53ea\u9700\u8981\u4e0b\u8f7d\u6700>\u65b0\u7684\u5907\u4efd\u6587\u4ef6, \u5373\u53ef\u83b7\u5f97\u8be5\u7f51\u7ad9\u7684\u5168\u90e8\u9875\u9762. \u4f8b\u5982, \u7ef4\u57fa\u767e\u79d1\u6bcf\u9694\u4e00\u6bb5\u65f6\u95f4\u5c31\u4f1a\u53d1\u5e03\u7f51\u7ad9\u7684\u5907\u4efd\u6587\u4ef6\u4f9b\u7528\u6237\u4e0b\u8f7d, \u8fd9\u79cd\u7b56\u7565\u6700\u4e3a\u7b80\u5355, \u4f46\u76ee\u524d\u63d0\u4f9b\u5907\u4efd\u6587\u4ef6\u7684\u767e\u79d1\u7c7b\u7f51\u7ad9\u4e0d\u591a. \u57fa\u4e8e\u8d85\u94fe\u63a5\u7684\u904d\u5386: \u8fd9\u662f\u641c\u7d22\u5f15\u64ce\u83b7\u53d6\u7f51\u9875\u7684\u65b9\u6cd5. \u767e\u79d1\u7c7b\u7f51\u7ad9\u7684\u7f51\u9875\u4e4b\u95f4\u901a\u5e38\u662f\u901a\u8fc7\u8d85\u94fe\u63a5\u8fde\u63a5\u8d77>\u6765\u7684, \u901a\u8fc7\u8d85\u94fe\u63a5, \u7406\u8bba\u4e0a\u53ef\u4ee5\u904d\u5386\u7f51\u7ad9\u4e2d\u7684\u6240\u6709\u7f51\u9875, \u901a\u8fc7\u8fd9\u79cd\u7b56\u7565\u53ef\u4ee5\u627e\u5230\u6240\u6709\u5173\u8054\u7684\u767e\u79d1\u9875\u9762. \u5e94\u7528\u8fd9\u79cd>\u7b56\u7565\u53ef\u4ee5\u627e\u5230\u5927\u91cf\u7684\u7f51\u9875, \u4f46\u5728\u771f\u5b9e\u5e94\u7528\u4e2d, \u53ec\u56de\u7387\u4ecd\u7136\u5b58\u5728\u4e00\u5b9a\u7684\u95ee\u9898, \u56e0\u4e3a\u4f1a\u5b58\u5728\u90e8\u5206\u767e\u79d1\u9875\u9762\u672a\u88ab\u5176\u4ed6\u4efb>\u4f55\u9875\u9762\u94fe\u63a5\u7684\u60c5\u51b5, \u8fd9\u4f1a\u5bfc\u81f4\u5176\u65e0\u6cd5\u88ab\u83b7\u53d6. \u57fa\u4e8e\u679a\u4e3e\u7684\u904d\u5386: \u8fd9\u79cd\u7b56\u7565\u7684\u57fa\u672c\u5047\u8bbe\u662f\u767e\u79d1\u7c7b\u7f51\u7ad9\u7684\u9875\u9762URL\u5177\u6709\u53ef\u679a\u4e3e\u6027. \u53ef\u679a\u4e3e\u6027\u662f\u6307\u53ef\u4ee5\u6839\u636e\u767e\u79d1\u7c7b\u7f51\u7ad9\u9875\u9762URL\u7684\u683c\u5f0f\u679a\u4e3e\u51fa\u6240\u6709\u767e\u79d1\u9875\u9762\u7684URL. \u9875\u9762\u8bc6\u522b: \u767e\u79d1\u56fe\u8c31\u4e3b\u8981\u5173\u6ce8\u5b9e\u4f53\u76f8\u5173\u7684\u77e5\u8bc6, \u56e0\u6b64\u9700\u8981\u4ece\u6240\u6709\u7f51\u9875\u4e2d\u8bc6\u522b\u51fa\u4ecb\u7ecd\u5b9e\u4f53\u7684\u9875\u9762, \u53ef\u4ee5\u5145\u5206\u5229\u7528\u767e\u79d1\u9875\u9762\u7684\u7279\u6b8a\u6027\u6765\u5b8c\u6210\u8fd9\u4e00\u4efb\u52a1. \u4e0e\u666e\u901a\u7684\u9875\u9762\u4e0d\u4e00\u6837, \u767e\u79d1\u7c7b\u7f51\u7ad9\u662f\u4ee5\u8bcd\u6761\u7684\u65b9\u5f0f\u5bf9\u5185\u5bb9\u8fdb\u884c\u7f16\u6392\u7684, \u6bcf\u4e2a\u9875\u9762\u5747\u56f4\u7ed5\u4e00\u4e2a\u8bcd\u6761\u8fdb\u884c\u5168\u9762\u7684\u4ecb\u7ecd. \u56e0\u6b64, \u5b9e\u4f53\u53d1\u73b0\u8fc7\u7a0b\u7b49\u4ef7\u4e8e\u8bcd\u6761\u9875\u9762\u53d1\u73b0\u8fc7\u7a0b. \u4e00\u822c\u800c\u8a00, \u6bcf\u4e2a\u767e\u79d1\u7c7b\u7f51\u7ad9\u7684\u8bcd\u6761\u9875\u9762URL\u90fd\u5177\u6709\u4e00\u5b9a\u7684\u547d\u540d\u89c4\u5f8b, \u6839\u636e\u5176\u547d\u540d\u89c4\u5f8b\u4e0d\u96be\u679a\u4e3e\u51fa\u6240\u6709\u5b9e\u4f53\u7684URL: **\u767e\u79d1 http://baike.**.com/view/1.htm **\u97f3\u4e50 https://music.**.com/#/song?id=30953009 **\u7535\u5f71 https://movie.**.com/subject/26213252/ **\u767e\u79d1 http://baike.**.com/item/\u4e00\u51fa\u597d\u620f \u5c5e\u6027\u62bd\u53d6 \u00b6 \u767e\u79d1\u7c7b\u7f51\u7ad9\u7684\u6bcf\u4e2a\u9875\u9762\u90fd\u56f4\u7ed5\u4e00\u4e2a\u72ec\u7acb\u7684\u5b9e\u4f53\u8fdb\u884c\u5168\u9762\u7684\u4ecb\u7ecd. \u56e0\u6b64, \u53ea\u9700\u8981\u89e3\u6790\u4e00\u4e2a\u767e\u79d1\u9875\u9762, \u5c31\u80fd\u5f97\u5230\u4e00\u4e2a\u5b9e\u4f53\u7684\u5168\u90e8\u5c5e\u6027\u548c\u5c5e\u6027\u503c. \u767e\u79d1\u7c7b\u7f51\u7ad9\u7684\u9875\u9762\u683c\u5f0f\u57fa\u672c\u56fa\u5b9a, \u5305\u542b\u5927\u91cf\u534a\u7ed3\u6784\u5316\u7684\u4fe1\u606f, \u5e38\u7528\u7684\u6709\u51e0\u4e0b\u51e0\u7c7b: \u591a\u4e49\u8bcd: \u53c8\u79f0\u6d88\u6b67\u9879, \u4e00\u822c\u51fa\u73b0\u5728\u8bcd\u6761\u540d\u79f0\u5b58\u5728\u6b67\u4e49\u7684\u9875\u9762\u4e2d. \u4f8b\u5982, \u6709\u591a\u4e2a\u767e\u79d1\u8bcd\u6761\u7684\u540d\u79f0\u90fd\u53eb\"\u5218\u5fb7\u534e\", \u70b9\u51fb\u4e0d\u540c\u7684\u8d85\u94fe\u63a5, \u53ef\u4ee5\u8df3\u8f6c\u5230\u76f8\u5e94\u7684\u8bcd\u6761\u9875\u9762. \u6807\u9898: \u6bcf\u4e2a\u9875\u9762\u90fd\u6709\u7684\u8bcd\u6761\u540d\u79f0, \u53ef\u80fd\u5b58\u5728\u540d\u79f0\u91cd\u590d\u7684\u60c5\u51b5. \u540c\u4e49\u8bcd: \u5f53\u7528\u6237\u641c\u7d22\u4e00\u4e2a\u8bcd\u6761\u7684\u522b\u540d\u65f6\u624d\u4f1a\u51fa\u73b0. \u4f8b\u5982, \u641c\u7d22\"\u534e\u4ed4\"\u4f1a\u8df3\u8f6c\u5230\"\u4e2d\u56fd\u9999\u6e2f\u7537\u6f14\u5458, \u6b4c\u624b, \u5236\u7247\u4eba\"\u5bf9\u5e94\u7684\"\u5218\u5fb7\u534e\"\u8bcd\u6761. \u6458\u8981: \u662f\u6587\u672c\u5f62\u5f0f\u7684\u8bcd\u6761\u6982\u8ff0, \u5927\u90e8\u5206\u9875\u9762\u90fd\u6709\u6458\u8981\u4fe1\u606f. \u76ee\u5f55: \u662f\u8bcd\u6761\u8be6\u7ec6\u9762\u719f\u5185\u5bb9\u7684\u5927\u7eb2, \u5927\u90e8\u5206\u9875\u9762\u90fd\u6709\u76ee\u5f55. \u57fa\u672c\u4fe1\u606f\u8868\u683c: \u53c8\u79f0Infobox, \u662f\u4e00\u7ec4\u5305\u542b\u5c5e\u6027\u53ca\u5c5e\u6027\u503c\u7684\u8868\u683c, \u662f\u5bf9\u5b9e\u4f53\u7684\u7ed3\u6784\u5316\u603b\u7ed3. \u8d85\u94fe\u63a5: \u4e0e\u5f53\u524d\u8bcd\u6761\u76f8\u5173\u7684\u5176\u4ed6\u8bcd\u6761\u4f1a\u901a\u8fc7\u8d85\u94fe\u63a5\u7684\u5f62\u5f0f\u4e0e\u5f53\u524d\u8bcd\u6761\u8fdb\u884c\u5173\u8054. \u6807\u7b7e: \u7531\u5e7f\u5927\u7528\u6237\u521b\u5efa\u7684\u6807\u7b7e, \u7528\u4e8e\u5bf9\u8bcd\u6761\u8fdb\u884c\u7ec4\u7ec7\u548c\u5206\u7c7b, \u65b9\u4fbf\u7528\u6237\u5bfc\u822a, \u6d4f\u89c8\u7b49. \u6807\u7b7e\u4e2d\u65e2\u6709\u4e3b\u9898\u578b\u6807\u7b7e(\u519b\u4e8b, \u5386\u53f2, \u751f\u7269), \u4e5f\u6709\u6982\u5ff5\u578b\u6807\u7b7e(\u6f14\u5458, \u884c\u653f\u533a\u57df). \u6ce8\u610f: \u4e0d\u540c\u7684\u767e\u79d1\u7c7b\u7f51\u7ad9\u5305\u542b\u7684\u534a\u7ed3\u6784\u5316\u4fe1\u606f\u4e0d\u5c3d\u76f8\u540c. \u4f8b\u5982, \u7ef4\u57fa\u767e\u79d1\u4e2d\u5c31\u5b58\u5728\u4e00\u4e9b\u767e\u5ea6\u767e\u79d1\u4e2d\u6ca1\u6709\u7684\u77e5\u8bc6, \u5982\u6982\u5ff5\u7684\u5c42\u7ea7\u7ed3\u6784\u4fe1\u606f, \u8bcd\u6761\u7684\u5730\u7406\u4fe1\u606f\u4ee5\u53ca\u591a\u8bed\u8a00\u7248\u672c\u94fe\u63a5\u4fe1\u606f\u7b49. \u534a\u7ed3\u6784\u5316\u77e5\u8bc6\u62bd\u53d6 \u00b6 \u534a\u7ed3\u6784\u5316\u77e5\u8bc6\u62bd\u53d6: \u9488\u5bf9\u767e\u79d1\u9875\u9762\u7684\u77e5\u8bc6\u62bd\u53d6, \u672c\u8d28\u4e0a\u662f\u9488\u5bf9\u5176\u4e2d\u534a\u7ed3\u6784\u5316\u5185\u5bb9\u8fdb\u884c\u89e3\u6790. \u767e\u79d1\u7c7b\u7f51\u7ad9\u4e2d\u7684\u6bcf\u4e2a\u8bcd\u6761\u90fd\u88ab\u770b\u4f5c\u4e00\u4e2a\u5b9e\u4f53, \u9488\u5bf9\u6bcf\u4e2a\u8bcd\u6761\u9875\u9762\u7684\u4e0d\u540c\u7c7b\u578b\u7684\u534a\u7ed3\u6784\u5316\u4fe1\u606f, \u53ef\u4ee5\u4f7f\u7528\u4e0d\u540c\u7684\u62bd\u53d6\u5668\u6765\u62bd\u53d6\u77e5\u8bc6, \u6700\u7ec8\u4f1a\u5f97\u5230\u4e00\u4e2a\u5b9e\u4f53\u7684\u5168\u90e8\u5c5e\u6027\u53ca\u90e8\u5206\u9690\u6027\u5173\u7cfb. \u540d\u79f0\u5c5e\u6027: \u77e5\u8bc6\u56fe\u8c31\u6240\u63cf\u8ff0\u7684\u5b9e\u4f53\u90fd\u662f\u552f\u4e00\u6027\u7684, \u5728\u6570\u636e\u5e93\u4e2d\u5b58\u50a8\u65f6\u5176\u901a\u5e38\u4f7f\u7528\u552f\u4e00\u6807\u8bc6\u7b26(Unique ID, UID)\u8fdb\u884c\u6807\u8bb0, \u4f46\u662fUID\u663e\u7136\u5bf9\u7528\u6237\u4e0d\u591f\u53cb\u597d. \u56e0\u6b64, \u767e\u79d1\u56fe\u8c31\u901a\u5e38\u91c7\u7528\u5b57\u7b26\u578b\u540d\u79f0\u5bf9\u5b9e\u4f53\u8fdb\u884c\u8868\u793a. \u4f46\u662f\u4e2d\u6587\u5b9e\u4f53\u540d\u53c8\u7ecf\u5e38\u4f1a\u51fa\u73b0\u91cd\u590d\u7684\u60c5\u51b5, \u56e0\u6b64\u767e\u79d1\u56fe\u8c31\u901a\u5e38\u4f1a\u901a\u8fc7\u989d\u5916\u7684\u5907\u6ce8\u5bf9\u5b9e\u4f53\u8fdb\u884c\u6d88\u6b67. \u7528\u4e8e\u6d88\u6b67\u7684\u5907\u6ce8\u53ef\u4ee5\u662f\u5b9e\u4f53\u7c7b\u578b, \u5173\u952e\u7279\u5f81. \u4f8b\u5982, \u5b9e\u4f53\u540d\u79f0\u4e3a\"\u5218\u5fb7\u534e\", \u5219\u53ef\u4ee5\u6dfb\u52a0\u5907\u6ce8\u4fe1\u606f(\u4e2d\u56fd\u9999\u6e2f\u7537\u6f14\u5458, \u6b4c\u624b, \u5236\u7247\u4eba). \u5b9e\u4f53\u6307\u4ee3: \u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\u4f1a\u4ee5\u591a\u79cd\u4e0d\u540c\u7684\u6307\u4ee3(Mention)\u5f62\u5f0f\u51fa\u73b0\u5728\u6587\u672c\u8bed\u6599\u4e2d. \u5982\"\u5218\u5fb7\u534e\"\u6709\u65f6\u4f1a\u4ee5\"\u534e\u4ed4\"\u7684\u5f62\u5f0f\u51fa\u73b0, \u6709\u65f6\u53c8\u4f1a\u4ee5\"\u5218\u5929\u738b\"\u7b49\u5f62\u5f0f\u51fa\u73b0. \u8bc6\u522b\u4e00\u4e2a\u5b9e\u4f53\u7684\u4e0d\u540c\u6307\u4ee3\u5f62\u5f0f\u6709\u52a9\u4e8e\u673a\u5668\u7406\u89e3\u6587\u672c. \u83b7\u53d6\u5b9e\u4f53\u7684\u6307\u4ee3\u6709\u4e09\u79cd\u65b9\u5f0f. \u7b2c\u4e00\u79cd: \u6839\u636e\u540c\u4e49\u8bcd\u4fe1\u606f\u83b7\u53d6, \u4f8b\u5982, \u641c\u7d22\"\u534e\u4ed4\"\u5c06\u8df3\u8f6c\u5230\"\u5218\u5fb7\u534e(\u4e2d\u56fd\u9999\u6e2f\u7537\u6f14\u5458, \u6b4c\u624b, \u5236\u7247\u4eba)\". \u7b2c\u4e8c\u79cd: \u6839\u57fa\u591a\u4e49\u8bcd\u4fe1\u606f\u83b7\u53d6, \u6bcf\u4e2a\u5305\u542b\u6b67\u4e49\u9879\u7684\u5b9e\u4f53\u7684\u6807\u9898\u5c31\u662f\u8fd9\u4e2a\u5b9e\u4f53\u7684\u6307\u4ee3. \u7b2c\u4e09\u79cd: \u6839\u636e\u57fa\u672c\u4fe1\u606f\u8868\u683c\u83b7\u53d6, \u8868\u683c\u4e2d\u53ef\u80fd\u5305\u542b\u4e00\u4e9b\u6307\u793a\u5b9e\u4f53\u6307\u4ee3\u7684\u5c5e\u6027, \u5982\u82f1\u6587\u540d, \u522b\u540d, \u5b66\u540d\u7b49, \u8fd9\u4e9b\u5c5e\u6027\u7684\u503c\u5747\u662f\u5b9e\u4f53\u7684\u6307\u4ee3. \u4f8b\u5982, \u5218\u5fb7\u534e\u7684\u82f1\u6587\u540d\"Andy Lau\"\u4e5f\u662f\u5176\u6307\u4ee3\u4e4b\u4e00. \u6458\u8981\u5c5e\u6027: \u6458\u8981\u5c5e\u6027\u662f\u5bf9\u5b9e\u4f53\u7684\u6982\u8ff0\u6027\u63cf\u8ff0, \u5305\u542b\u7684\u4fe1\u606f\u975e\u5e38\u4e30\u5bcc, \u53ef\u7528\u4e8e\u5b9e\u4f53\u5c55\u793a, \u76f8\u4f3c\u5ea6\u8ba1\u7b97\u548c\u5b9e\u4f53\u7684\u8868\u793a\u5b66\u4e60\u7b49. \u57fa\u672c\u5c5e\u6027: \u6765\u6e90\u4e8e\u57fa\u672c\u5c5e\u6027\u8868\u683c, \u5b83\u4eec\u523b\u753b\u4e86\u5b9e\u4f53\u7684\u57fa\u672c\u4fe1\u606f, \u662f\u767e\u79d1\u56fe\u8c31\u6700\u91cd\u8981\u7684\u77e5\u8bc6\u6765\u6e90\u4e4b\u4e00, \u5bf9\u6700\u7ec8\u7684\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u77e5\u8bc6\u8d21\u732e\u6700\u5927. \u5b9e\u4f53\u7684\u5c5e\u6027\u53ca\u5c5e\u6027\u503c\u76f4\u63a5\u6765\u81ea\u8fd9\u4e9b\u8868\u683c\u7684\u5c5e\u6027\u5217\u548c\u5c5e\u6027\u503c\u5217. \u76f8\u5173\u5173\u7cfb: \u76f8\u5173\u5173\u7cfb\u662f\u901a\u8fc7\u8d85\u94fe\u63a5\u4fe1\u606f\u83b7\u53d6\u7684, \u662f\u5b9e\u4f53\u4e4b\u95f4\u7684\u4e00\u79cd\u9690\u6027\u5173\u7cfb. \u4f8b\u5982, \"\u5218\u5fb7\u534e\"\u548c\"\u6768\u8fc7\"\u4e4b\u95f4\u5b58\u5728\u8d85\u94fe\u63a5, \u8868\u660e\u4e24\u8005\u4e4b\u95f4\u5b58\u5728\u5173\u7cfb, \u4f46\u8fd9\u79cd\u5173\u7cfb\u96be\u4ee5\u7528\u7b80\u5355\u7684\u57fa\u672c\u5173\u7cfb\u8fdb\u884c\u8868\u793a(\u5218\u5fb7\u534e\u4e8e1983\u5e74\u5728\u7535\u5f71\u795e\u96d5\u4fa0\u4fa3\u4e2d\u9970\u6f14\u6768\u8fc7), \u76ee\u524d\u7528\u76f8\u5173\u5173\u7cfb\u8868\u793a. \u5206\u7c7b\u5173\u7cfb: \u5206\u7c7b\u5173\u7cfb\u901a\u8fc7\u6807\u7b7e\u4fe1\u606f\u83b7\u53d6, \u5305\u542b\u5b9e\u4f53\u4e0e\u6982\u5ff5\u4e4b\u95f4\u7684\u5b9e\u4f8b\u5173\u7cfb(instanceOf), \u4ee5\u53ca\u5b9e\u4f53\u4e0e\u4e3b\u9898\u4e4b\u95f4\u7684\u5173\u7cfb. \u77e5\u8bc6\u6e05\u6d17 \u00b6 \u77e5\u8bc6\u6e05\u6d17: \u7531\u4e8e\u767e\u79d1\u7c7b\u7f51\u7ad9\u662f\u901a\u8fc7\u4f17\u5305\u7684\u65b9\u5f0f\u7f16\u5199\u7684, \u56e0\u6b64\u901a\u5e38\u6ca1\u6709\u7edf\u4e00\u7684\u7f16\u5199\u6807\u51c6. \u5229\u7528\u534a\u7ed3\u6784\u5316\u7684\u77e5\u8bc6\u62bd\u53d6\u65b9\u6cd5\u5f97\u5230\u7684\u5b9e\u4f53\u77e5\u8bc6(\u4e3b\u8981\u6765\u6e90\u4e8e\u57fa\u672c\u4fe1\u606f\u8868\u683c\u4e2d\u7684\u57fa\u672c\u5c5e\u6027)\u4f1a\u5b58\u5728\u5f88\u591a\u8d28\u91cf\u95ee\u9898: \u5c5e\u6027\u8868\u8ff0\u4e0d\u4e00\u81f4: \u4e0d\u540c\u8bcd\u6761\u5bf9\u540c\u4e00\u5c5e\u6027\u7684\u8868\u8ff0\u4e0d\u540c, \u6709\u4e9b\u8bcd\u6761\u63cf\u8ff0\u4eba\u7269\u65f6\u4f7f\u7528\u4e86\"\u82f1\u6587\u540d\"\u5c5e\u6027, \u800c\u53e6\u4e00\u4e9b\u8bcd\u6761\u5219\u4f7f\u7528\u7684\u662f\"\u82f1\u6587\u540d\u79f0\"\u5c5e\u6027. \u6570\u503c\u5c5e\u6027\u503c\u683c\u5f0f\u4e0d\u7edf\u4e00: \u5728\u586b\u5199\u65e5\u671f\u5c5e\u6027\u65f6, \u5f88\u591a\u7528\u6237\u4e60\u60ef\u4f7f\u7528\"YYYY\u5e74MM\u6708DD\u65e5\"\u7684\u683c\u5f0f, \u800c\u53e6\u5916\u4e00\u90e8\u5206\u7528\u6237\u4e60\u60ef\u4f7f\u7528\"YYYYMMDD\"\u7684\u683c\u5f0f. \u53e6\u5916, \u6709\u4e9b\u5c5e\u6027\u503c\u7684\u5355\u4f4d\u4e0d\u7edf\u4e00, \u4f8b\u5982, \u5728\u63cf\u8ff0\u8eab\u9ad8\u65f6, \u6709\u4e9b\u4f7f\u7528\"\u7c73\"\u4f5c\u4e3a\u5355\u4f4d, \u6709\u4e9b\u4f7f\u7528\"\u5398\u7c73\", \u6216\u8005\"X\u5c3aY\u5bf8\". \u5bf9\u8c61\u5c5e\u6027\u7684\u591a\u4e2a\u5c5e\u6027\u503c\u5408\u5e76\u8868\u793a: \u5bf9\u8c61\u5c5e\u6027(Object Property)\u662f\u6307\u90a3\u4e9b\u5c5e\u6027\u503c\u662f\u5b9e\u4f53\u6216\u5b9e\u4f53\u6307\u4ee3\u7684\u5c5e\u6027, \u672c\u8d28\u4e0a\u8868\u8fbe\u4e86\u5b9e\u4f53\u95f4\u7684\u5173\u7cfb. \u5bf9\u8c61\u5c5e\u6027\u662f\u53ef\u679a\u4e3e\u7684, \u53ef\u80fd\u5b58\u5728\u591a\u4e2a\u4e0d\u540c\u7684\u5c5e\u6027\u503c. \u5728\u767e\u79d1\u7c7b\u7f51\u7ad9\u4e2d, \u8fd9\u4e9b\u5c5e\u6027\u503c\u5f80\u5f80\u4f1a\u901a\u8fc7\u5404\u79cd\u8fde\u63a5\u7b26\u53f7\u5408\u5e76\u6210\u4e00\u4e2a\u5b57\u7b26\u4e32. \u4f8b\u5982, \"\u5218\u5fb7\u534e\"\u6709\u4e00\u4e2a\u5bf9\u8c61\u5c5e\u6027\"\u4ee3\u8868\u4f5c\u54c1\", \u5176\u5c5e\u6027\u503c\u4e3a\"\u65e0\u95f4\u9053, \u5929\u82e5\u6709\u60c5, \u65fa\u89d2\u5361\u95e8......\", \u6bcf\u4e2a\u9017\u53f7\u5206\u9694\u7684\u662f\u4e00\u90e8\u4f5c\u54c1(\u5b9e\u4f53)\u7684\u540d\u79f0. \u8fd9\u79cd\u5408\u5e76\u8868\u793a\u4f1a\u5bfc\u81f4\u540e\u7eed\u5173\u7cfb\u6784\u5efa\u6b65\u9aa4\u96be\u4ee5\u5efa\u7acb\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb, \u56e0\u4e3a\u9700\u8981\u5408\u9002\u7684\u65b9\u6cd5\u8bc6\u522b\u5c5e\u6027\u503c\u63d0\u53ca\u4e86\u54ea\u4e9b\u5b9e\u4f53. \u6bd4\u5982, \u9700\u8981\u8bc6\u522b\u51fa\"\u65e0\u95f4\u9053\"\u662f\u4e00\u4e2a\u5b9e\u4f53\u5e76\u4e14\u94fe\u63a5\u5230\u77e5\u8bc6\u5e93\u4e2d\u540d\u4e3a\"\u65e0\u95f4\u9053(2022\u5e74\u5218\u4f1f\u5f3a\u6307\u5bfc\u7684\u7535\u5f71)\"\u7684\u5b9e\u4f53. \u4e0a\u8ff0\u76843\u79cd\u8d28\u91cf\u95ee\u9898\u4f1a\u964d\u4f4e\u77e5\u8bc6\u56fe\u8c31\u7684\u53ef\u7528\u6027, \u56e0\u6b64\u9700\u8981\u5bf9\u62bd\u53d6\u51fa\u6765\u7684\u77e5\u8bc6\u8fdb\u884c\u6e05\u6d17! \u77e5\u8bc6\u6e05\u6d17\u4e3b\u8981\u5206\u4e3a\u4e09\u4e2a\u90e8\u5206: \u5c5e\u6027\u5bf9\u9f50 \u6570\u503c\u5c5e\u6027\u503c\u5f52\u4e00\u5316 \u5bf9\u8c61\u5c5e\u6027\u503c\u5206\u5272 \u5c5e\u6027\u5bf9\u9f50: \u5c5e\u6027\u5bf9\u9f50\u7684\u76ee\u6807\u662f\u5c06\u5355\u6570\u636e\u6e90\u4e2d\u7684\u6240\u6709\u7b49\u4ef7\u5c5e\u6027\u5408\u5e76, \u7528\u7edf\u4e00\u7684\u5c5e\u6027\u540d\u79f0\u8868\u793a. \u4f8b\u5982, \u5c06\u767e\u5ea6\u767e\u79d1\u4e2d\u8bcd\u6761\u7684\u5c5e\u6027\"\u82f1\u6587\u540d\"\u548c\u5c5e\u6027\"\u82f1\u6587\u540d\u79f0\"\u7edf\u4e00\u7528\"\u82f1\u6587\u540d\u79f0\"\u6765\u8868\u793a. \u5c5e\u6027\u5bf9\u9f50\u901a\u5e38\u91c7\u7528\"\u751f\u6210 + \u8fc7\u6ee4 + \u9a8c\u8bc1\"\u7684\u57fa\u672c\u601d\u8def. \u751f\u6210: \u5728\u751f\u6210\u9636\u6bb5, \u4e3a\u5168\u90e8\u5c5e\u6027\u4e24\u4e24\u8ba1\u7b97\u76f8\u4f3c\u5ea6, \u5f97\u5230\u5019\u9009\u7684\u7b49\u4ef7\u5c5e\u6027\u5bf9. \u8fc7\u6ee4: \u5728\u8fc7\u6ee4\u9636\u6bb5, \u9700\u8981\u8bbe\u8ba1\u89c4\u5219, \u8fc7\u6ee4\u6389\u5176\u4e2d\u7684\u9519\u8bef\u7b49\u4ef7\u5c5e\u6027\u5bf9. \u9a8c\u8bc1: \u5728\u9a8c\u8bc1\u9636\u6bb5, \u4ea4\u7531\u4eba\u5de5\u5bf9\u6700\u7ec8\u7ed3\u679c\u8fdb\u884c\u9a8c\u8bc1. \u6ce8\u610f: \u5bf9\u4e8e\u6bcf\u4e2a\u7b49\u4ef7\u5c5e\u6027\u5bf9, \u4f7f\u7528\u4e24\u8005\u4e2d\u51fa\u73b0\u9891\u6b21\u8f83\u9ad8\u7684\u90a3\u4e2a\u5c5e\u6027\u7684\u540d\u79f0\u6765\u8868\u793a\u8fd9\u5bf9\u7b49\u4ef7\u5c5e\u6027. \u751f\u6210\u9636\u6bb5: \u6700\u91cd\u8981\u7684\u5c31\u662f\u5c5e\u6027\u76f8\u4f3c\u5ea6\u7684\u8ba1\u7b97\u65b9\u6cd5, \u4e3b\u6d41\u67093\u79cd\u65b9\u6cd5. * \u57fa\u4e8e\u5c5e\u6027\u540d\u79f0\u76f8\u4f3c\u6027\u7684\u65b9\u6cd5: \u5c06\u6bcf\u4e2a\u5c5e\u6027\u540d\u79f0\u5f53\u505a\u4e00\u4e2a\u5b57\u7b26\u4e32, \u5ea6\u91cf\u5b57\u7b26\u4e32\u76f8\u4f3c\u5ea6\u7684\u6307\u6807\u5305\u62ecJaccard\u7cfb\u6570, \u7f16\u8f91\u8ddd\u79bb\u7b49. \u4f8b\u5982, Jaccard\u7cfb\u6570\u5c06\u5c5e\u6027\u540d\u79f0\u5f53\u505a\u5b57\u7b26\u96c6\u5408, \u901a\u8fc7\u6bd4\u8f83\u4e24\u4e2a\u5c5e\u6027\u540d\u79f0\u7684\u5b57\u7b26\u96c6\u5408\u7684\u76f8\u4ea4\u7a0b\u5ea6 \u8bc4\u4f30\u5c5e\u6027\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6, \"\u82f1\u6587\u540d\"\u548c\"\u82f1\u6587\u540d\u79f0\"\u76f8\u5e94\u7684\u5b57\u7b26\u96c6\u5408\u7684Jaccard\u76f8\u4f3c\u5ea6\u4e3a\u00be=0.75. * \u4f7f\u7528\u5916\u90e8\u540c\u4e49\u8bcd\u77e5\u8bc6\u5e93\u7684\u65b9\u6cd5: \u4f8b\u5982, \u5f15\u5165\u540c\u4e49\u8bcd\u8bcd\u5178, \u767e\u5ea6\u6c49\u8bed\u8bcd\u5178\u7b49, \u5904\u7406\u90a3\u4e9b\u8bed\u4e49\u76f8\u4f3c\u4f46\u662f\u540d>\u79f0\u76f8\u53bb\u751a\u8fdc\u7684\u5c5e\u6027, \u6bd4\u5982\"\u59bb\u5b50\"\u548c\"\u8001\u5a46\", \"\u897f\u4f2f\u5229\u4e9a\u96ea\u6a47\u72ac\"\u548c\"\u4e8c\u54c8\". * \u57fa\u4e8e\u5c5e\u6027\u53d6\u503c\u76f8\u4f3c\u5ea6\u7684\u65b9\u6cd5: \u5305\u62ec\u5c5e\u6027\u503c\u96c6\u5408\u7684\u76f8\u4f3c\u5ea6\u548c\u5c5e\u6027\u503c\u7c7b\u578b\u7684\u76f8\u4f3c\u5ea6. \u8fc7\u6ee4\u9636\u6bb5: \u6700\u91cd\u8981\u7684\u5c31\u662f\u91c7\u7528\u4e00\u4e9b\u542f\u53d1\u5f0f\u89c4\u5219, \u5982\"\u4e24\u4e2a\u7b49\u4ef7\u5c5e\u6027\u4e0d\u4f1a\u540c\u65f6\u51fa\u73b0\u5728\u4e00\u4e2a\u767e\u79d1\u8bcd\u6761\u9875\u9762\u4e2d\", \u5982\u679c>\u4e00\u4e2a\u8bcd\u6761\u4e2d\u540c\u65f6\u51fa\u73b0\u4e86\u4e24\u4e2a\u5019\u9009\u7684\u7b49\u4ef7\u5c5e\u6027, \u90a3\u4e48\u8fd9\u4e24\u4e2a\u5c5e\u6027\u4e0d\u662f\u7b49\u4ef7\u5c5e\u6027. \u6570\u503c\u5c5e\u6027\u503c\u5f52\u4e00\u5316: \u6570\u503c\u5c5e\u6027\u503c\u5f52\u4e00\u5316\u7684\u76ee\u6807\u662f\u5c06\u6240\u6709\u7684\u6570\u503c\u5c5e\u6027\u503c\u7edf\u4e00\u8868\u793a. \u6570\u503c\u5c5e\u6027\u503c\u5f80\u5f80\u662f\u7531\"\u6570\u5b57+\u5355>\u4f4d\"\u6784\u6210\u7684, \u6240\u4ee5\u6570\u503c\u5c5e\u6027\u503c\u5f52\u4e00\u5316\u53ef\u4ee5\u5206\u4e3a\u6570\u503c\u62bd\u53d6\u548c\u5355\u4f4d\u7edf\u4e00\u4e24\u4e2a\u6b65\u9aa4. \u4f8b\u5982, \u5bf9\u4e8e\u65e5\u671f\u5c5e\u6027, \u53ef\u4ee5\u901a\u8fc7\u6b63\u5219 \u8868\u8fbe\u5f0f\u62bd\u53d6\u51fa\u5e74, \u6708, \u65e5\u7b49\u6570\u503c\u4fe1\u606f, \u518d\u901a\u8fc7\u8f6c\u6362\u6765\u7edf\u4e00\u5355\u4f4d. \u5bf9\u8c61\u5c5e\u6027\u503c\u5206\u5272: \u5bf9\u8c61\u5c5e\u6027\u503c\u5206\u5272\u7684\u76ee\u6807\u662f\u5c06\u4e00\u4e2a\u5bf9\u8c61\u5c5e\u6027\u7684\u591a\u4e2a\u5c5e\u6027\u503c\u5408\u5e76\u800c\u6210\u7684\u5b57\u7b26\u4e32\u62c6\u5206\u6210\u591a\u7ec4\"\u5c5e\u6027->\u5c5e\u6027\u503c\"\u5bf9, \u4ee5\u4fbf\u540e\u7eed\u8fdb\u884c\u5173\u7cfb\u6784\u5efa. \u6bd4\u5982, \u5c06\u5218\u5fb7\u534e\u7684\u5c5e\u6027\"\u4ee3\u8868\u4f5c\u54c1\"\u7684\u503c\"\u65e0\u95f4\u9053, \u5929\u82e5\u6709\u60c5, \u65fa\u89d2\u5361\u95e8......\"\u62c6\u5206\u6210\u591a\u7ec4\u5c5e\u6027-\u5c5e\u6027\u503c\u5bf9(\"\u4ee3\u8868\u4f5c\u54c1\", \"\u65e0\u95f4\u9053\"), (\"\u4ee3\u8868\u4f5c\u54c1\", \"\u5929\u82e5\u6709\u60c5\"), (\"\u4ee3\u8868\u4f5c\u54c1\", \"\u65fa\u89d2\u5361\u95e8\")\u7b49. \u6ce8\u610f: \u8fd9\u4e00\u62c6\u5206\u7684\u96be\u70b9\u5728\u4e8e\u5e76\u975e\u6240\u6709\u7531\u5206\u9694\u7b26\u8fde\u63a5\u800c\u6210\u7684\u5c5e\u6027\u503c\u90fd\u662f\u9700\u8981\u5206\u5272\u7684\u591a\u503c\u5bf9\u8c61\u5c5e\u6027. \u4f8b\u5982, \u6e05\u534e\u5927\u5b66\u7684\u5c5e\u6027\"\u6821\u8bad\"\u7684\u5c5e\u6027\u503c\u4e3a\"\u81ea\u5f3a\u4e0d\u606f, \u539a\u5fb7\u8f7d\u7269\". \u5c3d\u7ba1\u8be5\u5c5e\u6027\u503c\u662f\u901a\u8fc7\u5206\u9694\u7b26\u9017\u53f7\u7ec4\u5408\u800c\u6210\u7684, \u4f46\u662f\"\u6821\u8bad\"\u662f\u4e0d\u53ef\u62c6\u5206\u7684\u5355\u503c\u5c5e\u6027, \u4e0d\u5e94\u8be5\u62c6\u5206. \u5bf9\u8c61\u5c5e\u6027\u503c\u5206\u5272\u7684\u57fa\u672c\u601d\u8def: \u5bf9\u4e8e\u4efb\u610f\u4e00\u4e2a\u5c5e\u6027, \u5982\u679c\u5206\u5272\u540e\u7684\u5c5e\u6027\u503c\u96c6\u5408\u4e2d\u7684\u5927\u90e8\u5206\u5c5e\u6027\u503c\u90fd\u6307\u4ee3\u7279\u5b9a\u5b9e\u4f53, \u90a3\u4e48\u8fd9\u4e2a\u5c5e\u6027\u5f88\u53ef\u80fd\u662f\u591a\u6c41\u7684\u5bf9\u8c61\u5c5e\u6027, \u5bf9\u76f8\u5e94\u5c5e\u6027\u503c\u8fdb\u884c\u5206\u5272\u662f\u5408\u7406\u7684\u5c1d\u8bd5. \u4e00\u4e2a\u5b9e\u73b0\u65b9\u6cd5: \u5bf9\u4e8e\u4e00\u4e2a\u5c5e\u6027\u503c, \u9996\u5148\u5224\u65ad\u5176\u4e2d\u662f\u5426\u5b58\u5728\u5206\u9694\u7b26, \u5982\u679c\u4e0d\u5b58\u5728\u4efb\u4f55\u4e00\u79cd\u5206\u9694\u7b26, \u5c31\u8ba4\u4e3a\u4e0d\u9700\u8981\u5206\u5272; \u5982\u679c\u5b58\u5728\u4e00\u79cd\u6216\u591a\u79cd\u5206\u9694\u7b26, \u5219\u8ba1\u7b97\u5c5e\u6027\u503c\u5b57\u7b26\u4e32\u6309\u7167\u51fa\u73b0\u7684\u6bcf\u79cd\u5206\u9694\u7b26\u8fdb\u884c\u5206\u5272\u540e\u7684\u5f97\u5206(\u6bd4\u5982\u5c5e\u6027\u503c\u96c6\u5408\u4e2d\u80fd\u591f\u94fe\u63a5\u4e0a\u5b9e\u4f53\u7684\u5c5e\u6027\u503c\u7684\u6570\u91cf\u6216\u6bd4\u4f8b), \u6700\u540e\u5c06\u5f97\u5206\u6700\u9ad8\u7684\u65b9\u6848\u4f5c\u4e3a\u6700\u7ec8\u7684\u5206\u5272\u65b9\u6848. \u5173\u7cfb\u6784\u5efa \u00b6 \u901a\u8fc7\u4e0a\u9762\u4e00\u6b65\u5c5e\u6027\u62bd\u53d6\u7684\u6b65\u9aa4, \u53ef\u4ee5\u83b7\u5f97\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5b9e\u4f53\u7684\u5c5e\u6027\u548c\u5c5e\u6027\u503c. \u5f53\u5c5e\u6027\u662f\u5bf9\u8c61\u5c5e\u6027\u65f6, \u901a\u8fc7\u5c06\u5b9e\u4f53\u7684\u5c5e\u6027\u503c\u94fe\u63a5\u5230\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5df2\u6709\u7684\u5b9e\u4f53, \u5c31\u53ef\u4ee5\u5efa\u7acb\u8d77\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb. \u5173\u7cfb\u540d\u5373\u57fa\u672c\u5c5e\u6027\u7684\u540d\u79f0. \u4f8b\u5982, \u5218\u5fb7\u534e\"\u4ee3\u8868\u4f5c\u54c1\"\u7684\u503c\u4e3a\"\u65e0\u95f4\u9053\"\u53ef\u4ee5\u94fe\u63a5\u5230\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\"\u65e0\u95f4\u9053(2002\u5e74\u5218\u4f1f\u5f3a\u6267\u5bfc\u7684\u7535\u5f71)\", \u7531\u6b64\u53ef\u4ee5\u5efa\u7acb\u8d77\"\u5218\u5fb7\u534e\"\u4e0e\u5b9e\u4f53\"\u65e0\u95f4\u9053(2002\u5e74\u5218\u4f1f\u5f3a\u6267\u5bfc\u7684\u7535\u5f71)\"\u4e4b\u95f4\u5173\u7cfb\u540d\u4e3a\"\u4ee3\u8868\u4f5c\u54c1\"\u7684\u5173\u7cfb. \u5173\u7cfb\u6784\u5efa\u7684\u6838\u5fc3\u64cd\u4f5c\u662f\u5c06\u5c5e\u6027\u503c\u94fe\u63a5\u5230\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53. \u6839\u636e\u5c5e\u6027\u503c\u662f\u5426\u5b58\u5728\u6307\u5411\u5176\u4ed6\u8bcd\u6761\u7684\u8d85\u94fe\u63a5, \u5206\u4e24\u79cd\u60c5\u5f62\u8fdb\u884c\u5904\u7406: \u5f53\u5c5e\u6027\u503c\u5b58\u5728\u6307\u5411\u5176\u4ed6\u8bcd\u6761\u7684\u8d85\u94fe\u63a5\u65f6, \u53ea\u9700\u89e3\u6790\u51fa\u8fd9\u4e2a\u8d85\u94fe\u63a5\u6240\u6307\u5411\u7684\u5b9e\u4f53. \u4f8b\u5982, \u5728\u5218\u5fb7\u534e\u7684\u767e\u79d1\u9875\u9762\u4e2d, \"\u65e0\u95f4\u9053\"\u5b58\u5728\u4e00\u4e2a\u8d85\u94fe\u63a5\u6307\u5411\"\u65e0\u95f4\u9053(2002\u5e74\u5218\u4f1f\u5f3a\u6267\u5bfc\u7684\u7535\u5f71)\"\u8fd9\u4e2a\u5b9e\u4f53\u9875\u9762, \u56e0\u6b64\u53ef\u4ee5\u76f4\u63a5\u5f97\u5230\u8be5\u5c5e\u6027\u503c\u5bf9\u5e94\u7684\u5b9e\u4f53. \u5f53\u5c5e\u6027\u503c\u4e0d\u5b58\u5728\u8d85\u94fe\u63a5\u65f6, \u9700\u8981\u7528\u5230\u5b9e\u4f53\u7684\u6307\u4ee3\u4fe1\u606f\u6765\u8fdb\u884c\u5b9e\u4f53\u94fe\u63a5. \u5982\u679c\u4e00\u4e2a\u5c5e\u6027\u503c\u4e0d\u662f\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u4efb\u4f55\u5b9e\u4f53\u7684\u6307\u4ee3, \u5219\u8ba4\u4e3a\u8be5\u5c5e\u6027\u503c\u4e0d\u80fd\u6307\u5411\u4efb\u4f55\u5b9e\u4f53. \u5982\u679c\u4e00\u4e2a\u5c5e\u6027\u503c\u662f\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u4e00\u4e2a\u6216\u591a\u4e2a\u5b9e\u4f53\u7684\u6307\u4ee3, \u5219\u9700\u8981\u4f7f\u7528\u5206\u7c7b\u5668\u6765\u8fdb\u884c\u5224\u65ad. \u5177\u4f53\u6765\u8bf4, \u5206\u7c7b\u5668\u7684\u8f93\u5165\u662f\u4e00\u4e2a(\u5b9e\u4f53, \u5c5e\u6027, \u5c5e\u6027\u503c)\u4e09\u5143\u7ec4\u548c\u4e0e\u8fd9\u4e2a\u5c5e\u6027\u503c\u5bf9\u5e94\u7684\u67d0\u4e2a\u5019\u9009\u5b9e\u4f53; \u8f93\u51fa\u662f0\u548c1\u4e4b\u95f4\u7684\u5b9e\u6570\u503c, \u8868\u793a\u8be5\u5c5e\u6027\u6307\u5411\u8fd9\u4e2a\u5019\u9009\u5b9e\u4f53\u7684\u6982\u7387. \u5206\u7c7b\u5668\u7684\u6027\u80fd\u53d6\u51b3\u4e8e\u7279\u5f81\u7684\u9009\u62e9, \u6bd4\u8f83\u6709\u6548\u7684\u7279\u5f81\u6709\u4e24\u4e2a: \u767e\u79d1\u4e2d\u5c5e\u6027\u503c\u94fe\u63a5\u5230\u5019\u9009\u5b9e\u4f53\u7684\u6b21\u6570. \u5728\u7ebf\u767e\u79d1\u4e2d\u5b58\u5728\u5927\u91cf\u7684\u8d85\u94fe\u63a5, \u5728\u951a\u6587\u672c\u4e3a\u5c5e\u6027\u503c\u7684\u6240\u6709\u8d85\u94fe\u63a5\u4e2d, \u94fe\u63a5\u6b21\u6570\u6700\u591a\u7684\u5019\u9009\u5b9e\u4f53\u6700\u6709\u53ef\u80fd\u662f\u5c5e\u6027\u503c\u6240\u8868\u8fbe\u7684\u771f\u5b9e\u5b9e\u4f53. \u53cd\u6307\u7279\u5f81. \u5728\u5019\u9009\u5b9e\u4f53\u7684\u9875\u9762\u4e2d, \u5982\u679c\u5b58\u5728\u8d85\u94fe\u63a5\u6307\u5411\u8be5\u5c5e\u6027\u503c\u7684\u4e3b\u4f53\u5b9e\u4f53, \u5219\u8bf4\u660e\u4e3b\u4f53\u5b9e\u4f53\u4e0e\u5019\u9009\u5b9e\u4f53\u5b58\u5728\u5173\u7cfb, \u8be5\u5c5e\u6027\u503c\u5f88\u53ef\u80fd\u6307\u5411\u8fd9\u4e2a\u5019\u9009\u5b9e\u4f53. \u6bd4\u5982, \u5218\u5fb7\u534e\u7684\u4ee3\u8868\u4f5c\u54c1\"\u65e0\u95f4\u9053\"\u53ef\u80fd\u5b58\u5728\u5f88\u591a\u5019\u9009\u5b9e\u4f53, \u5305\u62ec\u7535\u5f71, \u7535\u89c6\u5267, \u5c0f\u8bf4, \u6b4c\u66f2, \u4f46\u53ea\u6709\u5218\u5fb7\u534e(\u4e3b\u4f53\u5b9e\u4f53)\u6240\u51fa\u6f14\u7684\u7535\u5f71\u5b58\u5728\u8d85\u94fe\u63a5\u6307\u5411\u5218\u5fb7\u534e, \u56e0\u6b64\u5176\u662f\u5c5e\u6027\u503c\u6240\u6307\u7684\u5b9e\u4f53. \u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u6784\u5efa \u00b6 \u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u6784\u5efa\u4fbf\u4e8e\u5bf9\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\u8fdb\u884c\u7ec4\u7ec7\u548c\u7ba1\u7406, \u76ee\u524d\u4e3b\u8981\u5305\u62ec\u4eba\u5de5\u6784\u5efa\u548c\u534a\u81ea\u52a8\u6784\u5efa\u4e24\u79cd\u65b9\u5f0f: \u4eba\u5de5\u6784\u5efa\u7684\u5178\u578b\u4ee3\u8868\u662fDBPedia, \u5b83\u901a\u8fc7\u4f17\u5305\u7684\u65b9\u5f0f\u5c06\u6765\u81ea\u7ef4\u57fa\u767e\u79d1\u6570\u636e\u6e90\u7684\u6240\u6709\u5b9e\u4f53\u7528320\u4e2a\u6982\u5ff5\u8fdb\u884c\u6709\u6548\u7ec4\u7ec7, \u5176\u4e2d\u6982\u5ff5\u4e4b\u95f4\u901a\u8fc7\u7c7b\u5c5e(subclassOf)\u5173\u7cfb\u8fdb\u884c\u8fde\u63a5, \u6784\u6210\u4e00\u4e2a\u6700\u5927\u6df1\u5ea6\u4e3a5\u7684\u6982\u5ff5\u5c42\u7ea7\u7ed3\u6784. \u534a\u81ea\u52a8\u6784\u5efa\u7684\u5178\u578b\u4ee3\u8868\u4e3aYAGO, \u5b83\u7684\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u7531\u4e13\u5bb6\u6784\u5efa\u7684\u5c42\u7ea7\u4f53\u7cfb(WordNet)\u548c\u7528\u6237\u4f17\u5305\u6784\u5efa\u7684\u6807\u7b7e\u4f53\u7cfb(\u7ef4\u57fa\u767e\u79d1\u6807\u7b7e\u4f53\u7cfb)\u4e24\u90e8\u5206\u7ec4\u6210, \u6ce8\u610f: \u767e\u79d1\u56fe\u8c31\u5bf9\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u7684\u8d28\u91cf\u8981\u6c42\u8f83\u9ad8, \u4e00\u822c\u4e0d\u91c7\u7528\u5168\u81ea\u52a8\u7684\u65b9\u5f0f\u6784\u5efa. \u5b9e\u4f53\u5206\u7c7b \u00b6 \u5b9e\u4f53\u5206\u7c7b\u7684\u76ee\u6807\u662f\u5c06\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\u5206\u7c7b\u5230\u4e00\u7ec4\u9884\u5b9a\u4e49\u7684\u6982\u5ff5\u96c6\u5408\u4e2d, \u8fd9\u7ec4\u9884\u5b9a\u4e49\u7684\u6982\u5ff5\u96c6\u5408\u6765\u81ea\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb. \u5b9e\u4f53\u5206\u7c7b\u548cNER\u4efb\u52a1\u4e0d\u540c: NER: \u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7684\u7814\u7a76\u5bf9\u8c61\u662f\u53e5\u5b50\u4e2d\u7684\u5b9e\u4f53\u6307\u4ee3, \u5206\u7c7b\u4f9d\u636e\u4ec5\u6765\u81ea\u53e5\u5b50\u7684\u4e0a\u4e0b\u6587\u6587\u672c\u4fe1\u606f. \u5b9e\u4f53\u5206\u7c7b: \u5b9e\u4f53\u5206\u7c7b\u7684\u7814\u7a76\u5bf9\u8c61\u662f\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53, \u5206\u7c7b\u4f9d\u636e\u6765\u81ea\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5168\u90e8\u6570\u636e(\u5305\u62ec\u7ed3\u6784\u5316\u6570\u636e\u548c\u975e\u7ed3\u6784\u5316\u6587\u672c). \u5b9e\u4f53\u5206\u7c7b\u7684\u65b9\u6cd5\u4e3b\u8981\u6709\u4e09\u79cd: \u4eba\u5de5\u65b9\u6cd5 \u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5 \u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5 \u4eba\u5de5\u65b9\u6cd5 \u00b6 \u57fa\u4e8e\u4eba\u5de5\u7684\u5b9e\u4f53\u5206\u7c7b\u65b9\u6cd5\u501f\u52a9\u9886\u57df\u4e13\u5bb6\u548c\u5e7f\u5927\u5fd7\u613f\u8005\u5bf9\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\u8fdb\u884c\u7c7b\u522b\u6807\u6ce8. \u65e9\u671f\u7684\u8bed\u4e49\u7f51\u7edc\u89c4\u6a21\u4e0d\u5927, \u5b9e\u4f53\u6570\u91cf\u4e0d\u591a, \u5f80\u5f80\u7531\u9886\u57df\u4e13\u5bb6\u76f4\u63a5\u6807\u6ce8. \u968f\u7740\u77e5\u8bc6\u56fe\u8c31\u7684\u5b9e\u4f53\u89c4\u6a21\u4e0d\u65ad\u6269\u5927, \u4eba\u5de5\u65b9\u5f0f\u9010\u6e10\u7531\u4e13\u5bb6\u6784\u5efa\u8f6c\u4e3a\u7531\u5e7f\u5927\u5fd7\u613f\u8005\u5171\u540c\u534f\u4f5c\u6784\u5efa, \u4e0d\u540c\u7684\u573a\u666f\u4e0b\u4eba\u5de5\u53c2\u4e0e\u7684\u7a0b\u5ea6\u4e0d\u540c. \u4f8b\u5982, \u7ef4\u57fa\u767e\u79d1\u4e2d\u7684\u5fd7\u613f\u8005\u9700\u8981\u4e3a\u6bcf\u4e2a\u8bcd\u6761\u6309\u7167\u6807\u7b7e\u7cfb\u7edf\u4e2d\u7684\u6807\u7b7e\u8fdb\u884c\u5206\u7c7b, \u800cDBPedia\u7684\u5fd7\u613f\u8005\u5229\u7528\u7ef4\u57fa\u767e\u79d1\u7684Infobox\u6a21\u677f\u6765\u8fdb\u884c\u6279\u91cf\u4eba\u5de5\u6807\u6ce8. \u7ef4\u57fa\u767e\u79d1\u7684Infobox\u7c7b\u4f3c\u4e8e\u767e\u5ea6\u767e\u79d1\u4e2d\u7684\u57fa\u672c\u4fe1\u606f\u8868\u683c, \u4e3a\u4e86\u65b9\u4fbf\u7528\u6237\u6dfb\u52a0\u4fe1\u606f, \u7ef4\u57fa\u767e\u79d1\u4e3a\u4e0d\u540c\u7c7b\u578b\u7684\u5b9e\u4f53\u8bbe\u8ba1\u4e86\u4e0d\u540c\u7684Infobox\u6a21\u677f, \u6bcf\u4e2aInfobox\u6a21\u677f\u63cf\u8ff0\u4e86\u8be5\u7c7b\u5b9e\u4f53\u7684\u57fa\u672c\u5c5e\u6027. \u4f8b\u5982, \"\u7535\u5f71\"\u7c7b\u578b\u8bcd\u6761\u7684Infobox\u6a21\u677f\u4f1a\u5305\u62ec\"\u5bfc\u6f14\", \"\u6f14\u5458\", \"\u4e0a\u6620\u65f6\u95f4\"\u7b49\u5c5e\u6027. \u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5 \u00b6 \u57fa\u4e8e\u89c4\u5219\u7684\u5b9e\u4f53\u5206\u7c7b\u65b9\u6cd5\u4f7f\u7528\u4e00\u7ec4IF-THEN\u89c4\u5219\u6765\u5bf9\u5b9e\u4f53\u8fdb\u884c\u5206\u7c7b. \u901a\u7528\u7684\u63a8\u7406\u89c4\u5219 \u542f\u53d1\u5f0f\u7684\u63a8\u7406\u89c4\u5219 \u901a\u7528\u7684\u63a8\u7406\u89c4\u5219: \u6307\u90a3\u4e9b\u80fd\u9002\u7528\u4e8e\u5168\u90e8\u6982\u5ff5\u7684\u5b9e\u4f53\u5206\u7c7b\u89c4\u5219, \u5305\u62ec\u57fa\u4e8e\u7b49\u4ef7\u5b9e\u4f53\u5173\u7cfb\u548c\u57fa\u4e8e\u6982\u5ff5\u5b50\u7c7b\u5173\u7cfb\u7684\u63a8\u7406\u89c4\u5219. \u57fa\u4e8e\u7b49\u4ef7\u5b9e\u4f53\u5173\u7cfb\u7684\u63a8\u7406: # \u5177\u4f53\u542b\u4e49: \u5982\u679c\u5b9e\u4f53e1\u5c5e\u4e8e\u67d0\u4e00\u6982\u5ff5c, \u5e76\u4e14\u5b9e\u4f53e1\u548c\u5b9e\u4f53e2\u7b49\u4ef7, \u5219\u53ef\u4ee5\u63a8\u7406\u51fa\u5b9e\u4f53e2\u4e5f\u5c5e\u4e8e\u6982\u5ff5c (e1 \u2208 c) and (e1 = e2) => (e2 \u2208 c) \u4f8b\u5982: \"\u5218\u5fb7\u534e\"\u548c\"Andy Lau\"\u662f\u5df2\u7ecf\u5efa\u7acb\u8d77\u767e\u5ea6\u767e\u79d1\u4e2d\u6587\u5b9e\u4f53\u4e0eDBPedia\u82f1\u6587\u5b9e\u4f53\u4e4b\u95f4\u7684\u7b49\u4ef7\u5173\u7cfb, \u8fdb\u800c\u5c31\u53ef\u4ee5\u5f97\u5230\u90e8\u5206\u4e2d\u6587\u5b9e\u4f53\u7684\u82f1\u6587\u5206\u7c7b, \"\u5218\u5fb7\u534e\"\u7684\u82f1\u6587\u7c7b\u522b\u5c31\u5305\u62ecPerson, Actor, Singer\u7b49. \u57fa\u4e8e\u6982\u5ff5\u5b50\u7c7b\u5173\u7cfb\u7684\u63a8\u7406: # \u5177\u4f53\u542b\u4e49: \u5982\u679c\u5b9e\u4f53e\u5c5e\u4e8e\u6982\u5ff5c1, \u5e76\u4e14\u6982\u5ff5c1\u662f\u6982\u5ff5c2\u7684\u5b50\u7c7b, \u5219\u53ef\u4ee5\u63a8\u7406\u51fa\u5b9e\u4f53e\u4e5f\u5c5e\u4e8e\u6982\u5ff5c2 (e \u2208 c1) and (c1 \u2208 c2) => (e \u2208 c2) \u6ce8\u610f: YAGO\u5c31\u662f\u901a\u8fc7\u8fd9\u79cd\u89c4\u5219\u5c06\u7ef4\u57fa\u767e\u79d1\u4e2d\u7684\u5b9e\u4f53\u5206\u7c7b\u5230WordNet\u7684\u6982\u5ff5\u96c6\u5408\u4e2d\u7684. \u542f\u53d1\u5f0f\u7684\u63a8\u7406\u89c4\u5219: \u4ec5\u9002\u7528\u4e8e\u90e8\u5206\u6982\u5ff5, \u5305\u62ec\u57fa\u4e8e\u5b9e\u4f53\u540d\u79f0, \u57fa\u4e8e\u5c5e\u6027\u548c\u57fa\u4e8e\u5c5e\u6027\u503c\u7684\u63a8\u7406\u89c4\u5219. \u57fa\u4e8e\u5b9e\u4f53\u540d\u79f0\u7684\u63a8\u7406: \u5b9e\u4f53\u540d\u79f0\u540e\u7f00\u4e3a\"\u533b\u9662\", \"\u5927\u5b66\"\u7684\u5f88\u53ef\u80fd\u5206\u522b\u5c5e\u4e8e\u6982\u5ff5\"\u533b\u9662\"\u548c\"\u5927\u5b66\". \u57fa\u4e8e\u5c5e\u6027\u7684\u63a8\u7406: \u5b9e\u4f53\u5305\u542b\u5c5e\u6027\"\u6027\u522b\"\u7684, \u5f88\u53ef\u80fd\u5c5e\u4e8e\u6982\u5ff5\"\u4eba\u7269\". \u57fa\u4e8e\u5c5e\u6027\u503c\u7684\u63a8\u7406: \u5982\u679c\u5b9e\u4f53\u5305\u542b\u5c5e\u6027\u503c\u5bf9(\u804c\u4e1a, \u6f14\u5458), \u5f88\u53ef\u80fd\u5c5e\u4e8e\u6982\u5ff5\"\u6f14\u5458\". \u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5 \u00b6 \u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u5b9e\u4f53\u5206\u7c7b\u65b9\u6cd5\u5f80\u5f80\u5c06\u5b9e\u4f53\u5206\u7c7b\u95ee\u9898\u5efa\u6a21\u4e3a\u4e00\u4e2a\u591a\u6807\u7b7e\u5206\u7c7b\u95ee\u9898(Multi-label Classification). \u6bcf\u4e2a\u6807\u8bb0\u7c7b\u4ee3\u8868\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u4e00\u4e2a\u6982\u5ff5, \u4e00\u4e2a\u5b9e\u4f53\u53ef\u4ee5\u5c5e\u4e8e\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u591a\u4e2a\u6982\u5ff5. \u5de5\u4e1a\u754c\u7684\u4e3b\u6d41\u65b9\u6cd5\u662f\u57fa\u4e8e\u76d1\u7763\u5b66\u4e60\u7684\u65b9\u6cd5, \u7f3a\u70b9\u662f\u8fd9\u7c7b\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u7684\u6709\u6807\u7b7e\u7684\u8bad\u7ec3\u6837\u672c. \u7279\u5f81\u8868\u793a: \u79bb\u6563\u5316\u7279\u5f81, \u5d4c\u5165\u5f0f\u7279\u5f81. \u5206\u7c7b\u6a21\u578b: \u903b\u8f91\u56de\u5f52, \u51b3\u7b56\u6811, LSTM, BERT. \u57fa\u4e8e\u591a\u6e90\u7684\u767e\u79d1\u56fe\u8c31\u878d\u5408 \u00b6 \u73b0\u5b9e\u4e2d\u9664\u4e86\u524d\u9762\u4ecb\u7ecd\u7684\u5355\u6e90\u7684\u767e\u79d1\u56fe\u8c31\u7684\u6784\u5efa, \u8fd8\u6709\u901a\u8fc7\u591a\u4e2a\u4e0d\u540c\u6570\u636e\u6e90\u6765\u6784\u5efa\u66f4\u5b8c\u6574, \u66f4\u51c6\u786e\u7684\u767e\u79d1\u56fe\u8c31\u7684\u65b9\u6cd5. \u672c\u8d28\u4e0a, \u9996\u5148\u6839\u636e\u6bcf\u4e2a\u6570\u636e\u6e90\u5355\u72ec\u6784\u5efa\u4e00\u4e2a\u77e5\u8bc6\u56fe\u8c31, \u518d\u5c06\u8fd9\u4e9b\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u878d\u5408. \u5177\u4f53\u6784\u5efa\u5206\u4e3a4\u4e2a\u8fc7\u7a0b: \u6982\u5ff5\u878d\u5408 \u5b9e\u4f53\u5bf9\u9f50 \u5c5e\u6027\u5bf9\u9f50 \u5c5e\u6027\u503c\u878d\u5408 \u6982\u5ff5\u878d\u5408 \u00b6 \u4e0d\u540c\u77e5\u8bc6\u56fe\u8c31\u7684\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u5404\u4e0d\u76f8\u540c, \u800c\u878d\u5408\u540e\u7684\u77e5\u8bc6\u56fe\u8c31\u53ea\u80fd\u6709\u4e00\u4e2a\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb. \u6982\u5ff5\u878d\u5408\u7684\u5173\u952e\u662f\u627e\u7b49\u4ef7\u5173\u7cfb. \u7531\u4e8e\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u975e\u5e38\u91cd\u8981\u5e76\u4e14\u89c4\u6a21\u53ef\u63a7, \u76ee\u524d\u4e3b\u6d41\u7684\u7cfb\u7edf\u4e3b\u8981\u91c7\u7528\u4eba\u5de5\u65b9\u6cd5\u8fdb\u884c\u5339\u914d\u4ee5\u4fdd\u8bc1\u878d\u5408\u7684\u8d28\u91cf. \u4f8b\u5982, DBPedia\u901a\u8fc7\u4f17\u5305\u7684\u65b9\u5f0f\u4e3a\u4e0d\u540c\u8bed\u79cd\u7684\u77e5\u8bc6\u56fe\u8c31\u4e0a\u7684\u6982\u5ff5\u5efa\u7acb\u7b49\u4ef7\u5173\u7cfb, \u5982\u82f1\u6587\u6982\u5ff5\"Book\"\u548c\u5e0c\u814a\u6587\u6982\u5ff5\"Bi\u03b2\u03b3io\". \u4e0d\u540c\u77e5\u8bc6\u56fe\u8c31\u7684\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u9664\u4e86\u5305\u542b\u7b49\u4ef7\u6982\u5ff5\u5916, \u8fd8\u5305\u542b\u5404\u81ea\u56fe\u8c31\u7279\u6709\u7684\u6982\u5ff5. \u4f8b\u5982, \"\u7384\u5e7b\u5c0f\u8bf4\"\u53ea\u5728\u4e2d\u6587\u6982\u5ff5\u4e2d\u51fa\u73b0, \u800c\u4e0d\u4f1a\u5728\u5176\u4ed6\u8bed\u8a00\u7684\u6982\u5ff5\u96c6\u5408\u4e2d\u51fa\u73b0. \u6709\u4e24\u79cd\u878d\u5408\u7b56\u7565\u5904\u7406\u4e0a\u8ff0\u60c5\u5f62: 1: \u4ee5DBPedia\u4e3a\u4ee3\u8868, \u53ea\u4ee5\u5176\u4e2d\u7684\u4e00\u4e2a\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u4e3a\u4e3b, \u53e6\u4e00\u4e2a\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u4e2d\u7279\u6709\u7684\u6982\u5ff5\u5c06\u88ab\u8fc7\u6ee4\u6389. 2: \u4ee5XLORE\u4e3a\u4ee3\u8868, \u4fdd\u7559\u6240\u6709\u7684\u6982\u5ff5, \u53ea\u5c06\u7b49\u4ef7\u7684\u6982\u5ff5\u5408\u5e76. \u5b9e\u4f53\u5bf9\u9f50 \u00b6 \u5b9e\u4f53\u5bf9\u9f50\u662f\u77e5\u8bc6\u56fe\u8c31\u878d\u5408\u7684\u6700\u5173\u952e\u6b65\u9aa4, \u5b83\u51b3\u5b9a\u4e86\u77e5\u8bc6\u56fe\u8c31\u4e4b\u95f4\u662f\u5426\u80fd\u591f\u878d\u5408. \u5b9e\u4f53\u5bf9\u9f50\u7684\u4e3b\u8981\u4efb\u52a1\u4efb\u52a1\u662f\u5224\u65ad\u6765\u81ea\u4e24\u4e2a\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\u662f\u5426\u7b49\u4ef7, \u5bf9\u9f50\u7684\u65b9\u6cd5\u4e3b\u8981\u5206\u4e3a\u56db\u4e2a\u6b65\u9aa4: \u6570\u636e\u9884\u5904\u7406 \u5206\u5757 \u6210\u5bf9\u5bf9\u9f50 \u96c6\u4f53\u5bf9\u9f50 \u6570\u636e\u9884\u5904\u7406 \u00b6 \u6570\u636e\u9884\u5904\u7406\u7684\u76ee\u6807\u662f\u89e3\u51b3\u5b9e\u4f53\u547d\u540d\u4e0d\u7edf\u4e00\u7684\u95ee\u9898, \u4e3b\u8981\u65b9\u6cd5\u5305\u62ec: \u53bb\u9664\u5b9e\u4f53\u540d\u79f0\u4e0a\u7684\u6807\u70b9\u7b26\u53f7 \u8fdb\u884c\u540c\u4e49\u8bcd\u6269\u5c55 \u5206\u5757 \u00b6 \u5206\u5757\u7684\u76ee\u6807\u662f\u51cf\u5c11\u9700\u8981\u4e24\u4e24\u6bd4\u5bf9\u7684\u5b9e\u4f53\u5bf9\u7684\u6570\u91cf. \u5177\u4f53\u505a\u6cd5\u662f\u6839\u636e\u4e00\u4e9b\u542f\u53d1\u5f0f\u7b56\u7565, \u5c06\u4e24\u4e2a\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u76f8\u4f3c\u5b9e\u4f53\u5206\u914d\u5230\u76f8\u540c\u7684\u533a\u5757\u4e2d. \u5728\u8fdb\u884c\u5b9e\u4f53\u5bf9\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u65f6, \u53ea\u9700\u8981\u8ba1\u7b97\u76f8\u540c\u533a\u5757\u4e2d\u7684\u5b9e\u4f53\u5bf9\u5373\u53ef. \u4f8b\u5982: \u53ef\u4ee5\u6839\u636e\u5b9e\u4f53\u7684\u6982\u5ff5\u8fdb\u884c\u5206\u5757, \u53ea\u6709\u5c5e\u4e8e\u540c\u4e00\u6982\u5ff5\u5206\u5757\u4e2d\u7684\u5b9e\u4f53\u624d\u53ef\u80fd\u5f7c\u6b64\u5bf9\u9f50. \u6bd4\u5982, \"\u4eba\u7269\"\u548c\"\u5efa\u7b51\"\u4e24\u4e2a\u6982\u5ff5\u5206\u5757\u4e2d\u7684\u5b9e\u4f53\u662f\u4e0d\u53ef\u80fd\u7b49\u4ef7\u7684. \u5b9e\u4f53\u5bf9\u9f50\u7684\u65b9\u6cd5\u53c8\u5206\u4e3a\u4e24\u79cd: \u6210\u5bf9\u5bf9\u9f50: \u53ea\u6839\u636e\u4e00\u4e2a\u5b9e\u4f53\u5bf9\u4e2d\u7684\u4e24\u4e2a\u5b9e\u4f53\u672c\u8eab\u7684\u4fe1\u606f\u8fdb\u884c\u5339\u914d. \u96c6\u4f53\u5bf9\u9f50: \u4f1a\u8003\u8651\u6574\u4e2a\u77e5\u8bc6\u56fe\u8c31\u7684\u4fe1\u606f\u8fdb\u884c\u5339\u914d. \u6210\u5bf9\u5bf9\u9f50 \u00b6 \u6210\u5bf9\u5b9e\u4f53\u7684\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u4e3b\u8981\u6709\u4e24\u7c7b\u65b9\u6cd5: \u65e0\u76d1\u7763\u5b66\u4e60: 1: \u6839\u636e\u73b0\u6709\u7684\u77e5\u8bc6\u5f97\u5230\u7b49\u4ef7\u5173\u7cfb\u8fdb\u884c\u5224\u65ad, \u5982DBPedia\u901a\u8fc7\u7ef4\u57fa\u767e\u79d1\u4e2d\u7684\u5b9e\u4f53\u7684\u591a\u8bed\u8a00\u7248\u672c\u4fe1\u606f, \u5f97\u5230\u4e0d\u540c\u8bed\u8a00\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\u7684\u7b49\u4ef7\u5173\u7cfb. 2: \u6839\u636e\u5b9e\u4f53\u540d\u79f0\u7684\u76f8\u4f3c\u5ea6\u8fdb\u884c\u5224\u65ad, \u76f8\u4f3c\u5ea6\u8ba1\u7b97\u7684\u65b9\u6cd5\u5305\u62ecJaccard\u7cfb\u6570, \u7f16\u8f91\u8ddd\u79bb\u7b49. \u76f8\u4f3c\u5ea6\u5927\u4e8e\u67d0\u4e2a\u9608\u503c\u5373\u8ba4\u4e3a\u7b49\u4ef7, \u53cd\u4e4b\u5219\u8ba4\u4e3a\u4e0d\u7b49\u4ef7. 3: \u6839\u636e\u5b9e\u4f53\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u8fdb\u884c\u5224\u65ad, \u5982\u540c\u4e49\u5173\u7cfb\u6216\u6982\u5ff5\u76f8\u8fd1\u7b49. \u6709\u76d1\u7763\u5b66\u4e60: \u5373\u6784\u5efa\u4e8c\u5206\u7c7b\u6a21\u578b, \u5224\u65ad\u6765\u81ea\u4e24\u4e2a\u4e0d\u540c\u77e5\u8bc6\u56fe\u8c31\u7684\u5b9e\u4f53\u662f\u5426\u7b49\u4ef7. \u8fd9\u7c7b\u65b9\u6cd5\u7684\u57fa\u672c\u601d\u8def\u662f\u5229\u7528\u5df2\u6709\u7684\u90e8\u5206\u77e5\u8bc6\u56fe\u8c31\u95f4\u7684\u7b49\u4ef7\u5b9e\u4f53\u4f5c\u4e3a\u8bad\u7ec3\u96c6, \u518d\u901a\u8fc7\u4e8c\u5206\u7c7b\u6a21\u578b\u5f97\u5230\u66f4\u591a\u7684\u7b49\u4ef7\u5173\u7cfb. \u5176\u4e2d\u7684\u7279\u5f81\u5f80\u5f80\u901a\u8fc7\u4eba\u5de5\u65b9\u5f0f\u5b9a\u4e49, \u6765\u81ea\u5b9e\u4f53\u7684\u540d\u79f0, \u6b63\u6587, \u76f8\u5173\u5b9e\u4f53, \u6807\u7b7e, Infobox\u7b49\u4fe1\u606f. \u96c6\u4f53\u5bf9\u9f50 \u00b6 \u96c6\u4f53\u5bf9\u9f50\u4f1a\u628a\u5b9e\u4f53\u6240\u5728\u7684\u56fe\u8c31\u7684\u4fe1\u606f\u4e5f\u8003\u8651\u8fdb\u6765, \u53ef\u4ee5\u7ec6\u5206\u4e3a\u4e24\u7c7b: \u5c40\u90e8\u96c6\u4f53\u5bf9\u9f50 \u5168\u5c40\u96c6\u4f53\u5bf9\u9f50 \u5c40\u90e8\u96c6\u4f53\u5bf9\u9f50: \u8981\u5339\u914d\u4e24\u4e2a\u5b9e\u4f53, \u4e0d\u4ec5\u8981\u8003\u8651\u4e24\u4e2a\u5b9e\u4f53\u672c\u8eab\u7684\u76f8\u4f3c\u5ea6, \u8fd8\u8981\u8003\u8651\u4e24\u4e2a\u5b9e\u4f53\u7684\u90bb\u5c45\u8282\u70b9\u7684\u76f8\u4f3c\u5ea6. # \u5177\u4f53\u542b\u4e49: sim_attr(e1,e2)\u662f\u5b9e\u4f53\u5bf9\u672c\u8eab\u7684\u76f8\u4f3c\u5ea6, sim_NB(e1,e2)\u662f\u5b9e\u4f53\u7684\u90bb\u5c45\u8282\u70b9\u7684\u76f8\u4f3c\u5ea6. sim(e1,e2) = \u03b1 * sim_attr(e1,e2) + (1 - \u03b1) * sim_NB(e1,e2) \u5168\u5c40\u96c6\u4f53\u5bf9\u9f50: \u4ece\u5168\u5c40\u7684\u89d2\u5ea6\u6765\u8ba1\u7b97\u6240\u6709\u5b9e\u4f53\u7684\u5339\u914d\u5173\u7cfb, \u4e3b\u8981\u6709\u4e24\u79cd\u65b9\u6cd5: \u57fa\u4e8e\u76f8\u4f3c\u5ea6\u4f20\u64ad\u7684\u65b9\u6cd5: \u57fa\u672c\u601d\u8def\u662f\u57fa\u4e8e\u521d\u59cb\u5339\u914d\u901a\u8fc7\u8fed\u4ee3\u8ba1\u7b97\u4ea7\u751f\u65b0\u7684\u5339\u914d. \u57fa\u4e8e\u6982\u7387\u6a21\u578b\u7684\u65b9\u6cd5: \u57fa\u672c\u601d\u8def\u662f\u5c06\u5168\u5c40\u5b9e\u4f53\u5339\u914d\u7684\u6982\u7387\u6700\u5927\u5316, \u5e38\u7528\u7684\u65b9\u6cd5\u5305\u62ec\u8d1d\u53f6\u65af\u7f51\u7edc, LDA, \u6761\u4ef6\u968f\u673a\u573a, \u9a6c\u5c14\u53ef\u592b\u7f51\u7edc\u7b49. \u5c5e\u6027\u5bf9\u9f50 \u00b6 \u5c5e\u6027\u5bf9\u9f50\u662f\u6307\u5c06\u4e0d\u540c\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u7b49\u4ef7\u5c5e\u6027\u5408\u5e76\u4e3a\u540c\u4e00\u4e2a\u5c5e\u6027. \u7531\u4e8e\u591a\u6570\u636e\u6e90\u4e2d\u5b58\u5728\u7740\u5927\u91cf\u7684\u7b49\u4ef7\u5b9e\u4f53, \u8fd8\u53ef\u4ee5\u5145\u5206\u5229\u7528\u4e00\u4e9b\u7edf\u8ba1\u4fe1\u606f\u6765\u5bf9\u9f50\u5c5e\u6027. \u4e00\u4e2a\u5e38\u7528\u7684\u7edf\u8ba1\u4fe1\u606f\u662f\u5c5e\u6027\u5bf9\u5e94\u7684\"\u5b9e\u4f53-\u5c5e\u6027\u503c\"\u96c6\u5408\u7684\u91cd\u53e0\u7a0b\u5ea6, \u4e3e\u4f8b\u5982\u4e0b: \u77e5\u8bc6\u56fe\u8c31 \u5b9e\u4f53 \u5c5e\u6027 \u5c5e\u6027\u503c K1 AAA \u51fa\u751f\u65e5\u671f 1988-09-01 K1 BBB \u51fa\u751f\u65e5\u671f 1996-06-11 K1 CCC \u51fa\u751f\u65e5\u671f 1995-11-22 K1 DDD \u51fa\u751f\u65e5\u671f 1999-08-18 \u77e5\u8bc6\u56fe\u8c31 \u5b9e\u4f53 \u5c5e\u6027 \u5c5e\u6027\u503c K2 AAA \u751f\u65e5 1988-09-01 K2 BBB \u751f\u65e5 1996-06-11 K2 CCC \u751f\u65e5 1995-11-22 K2 DDD \u751f\u65e5 1999-08-18 \u7ed3\u8bba: \u4e0a\u9762\u4e24\u4e2a\u56fe\u8c31K1, K2, \u901a\u8fc7Jaccard\u7cfb\u6570\u8ba1\u7b97\u51fa\u4e24\u4e2a\u5c5e\u6027\u7684\"\u5b9e\u4f53-\u5c5e\u6027\u503c\"\u96c6\u5408\u7684\u91cd\u53e0\u7a0b\u5ea6\u662f100%, \u56e0\u6b64\u53ef\u4ee5\u63a8\u65ad\u51fa\u8fd9\u4e24\u4e2a\u5c5e\u6027(\"\u51fa\u751f\u65e5\u671f\"\u548c\"\u751f\u65e5\")\u662f\u7b49\u4ef7\u7684!!! \u5c5e\u6027\u503c\u878d\u5408 \u00b6 \u5728\u5bf9\u9f50\u5c5e\u6027\u540e, \u9700\u8981\u5bf9\u6765\u81ea\u4e0d\u540c\u77e5\u8bc6\u56fe\u8c31\u7684\u540c\u4e00\u5b9e\u4f53\u7684\u540c\u4e00\u5c5e\u6027\u7684\u5c5e\u6027\u503c\u8fdb\u884c\u5408\u5e76. \u5c5e\u6027\u503c\u878d\u5408\u7684\u4efb\u52a1\u5305\u62ec\u5220\u9664\u91cd\u590d\u77e5\u8bc6\u548c\u53bb\u9664\u9519\u8bef\u77e5\u8bc6. \u5220\u9664\u91cd\u590d\u77e5\u8bc6: \u6700\u9700\u8981\u89e3\u51b3\u7684\u95ee\u9898\u662f\u5c5e\u6027\u503c\u7684\u89c4\u8303\u5316, \u6bd4\u5982\u6570\u503c\u7c7b\u578b\u7684\u5c5e\u6027\u503c\u4f7f\u7528\u540c\u4e00\u4e2a\u6807\u51c6\u6765\u8868\u793a, \u5305\u62ec\u5355\u4f4d\u7edf\u4e00, \u65e5\u671f\u7edf\u4e00\u7b49. \u5982\u679c\u5c5e\u6027\u503c\u5bf9\u5e94\u4e00\u4e2a\u5b9e\u4f53\u4e14\u8be5\u5b9e\u4f53\u5b58\u5728\u591a\u4e2a\u540d\u79f0, \u5219\u4f7f\u7528\u7edf\u4e00\u7684\u5b9e\u4f53\u540d\u79f0\u8868\u793a. \u53bb\u9664\u9519\u8bef\u77e5\u8bc6: \u4e3b\u8981\u662f\u5229\u7528\u4e0d\u540c\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5df2\u77e5\u77e5\u8bc6\u6765\u5b9e\u73b0\u7684. \u6839\u636e\u5c5e\u6027\u662f\u5355\u503c\u8fd8\u662f\u591a\u503c\u7684, \u53ef\u4ee5\u5206\u4e3a\u5355\u503c\u5c5e\u6027\u878d\u5408\u548c\u591a\u503c\u5c5e\u6027\u878d\u5408. \u5355\u503c\u5c5e\u6027\u53ea\u6709\u552f\u4e00\u7684\u5c5e\u6027\u503c, \u6839\u636e\u8fd9\u4e00\u6027\u8d28, \u53ef\u4ee5\u5229\u7528\u6295\u7968\u673a\u5236\u5f97\u5230\u6700\u53ef\u80fd\u7684\u7ed3\u679c. \u6bcf\u4e2a\u77e5\u8bc6\u56fe\u8c31\u90fd\u5b58\u5728\u5927\u91cf\u7684(\u5b9e\u4f53, \u5c5e\u6027, \u5c5e\u6027\u503c)\u4e09\u5143\u7ec4, \u53ef\u4ee5\u4e3a\u591a\u4e2a\u5bf9\u8c61\u63d0\u4f9b\u5c5e\u6027\u503c. \u8fd9\u4e9b\u4e09\u5143\u7ec4\u7684\u5e73\u5747\u51c6\u786e\u7387\u51b3\u5b9a\u4e86\u77e5\u8bc6\u56fe\u8c31\u7684\u8d28\u91cf, \u540c\u7406\u77e5\u8bc6\u56fe\u8c31\u7684\u8d28\u91cf\u4e5f\u53ef\u4ee5\u7528\u6765\u4f30\u8ba1\u4e09\u5143\u7ec4\u7684\u51c6\u786e\u7387. \u5f53\u4e00\u4e2a\u5bf9\u8c61\u5b58\u5728\u591a\u4e2a\u5c5e\u6027\u503c\u65f6, \u5982\u679c\u5927\u591a\u6570\u9ad8\u8d28\u91cf\u7684\u77e5\u8bc6\u56fe\u8c31\u90fd\u652f\u6301\u5176\u4e2d\u67d0\u4e00\u4e2a\u5c5e\u6027\u503c, \u90a3\u4e48\u8fd9\u4e2a\u5c5e\u6027\u503c\u5f88\u6709\u53ef\u80fd\u5c31\u662f\u8fd9\u4e2a\u5bf9\u8c61\u7684\u771f\u503c. \u4f8b\u5982: \u76ee\u524d\u603b\u5171\u67094\u4e2a\u77e5\u8bc6\u56fe\u8c31\u9700\u8981\u878d\u5408, \u5176\u4e2d3\u4e2a\u62e5\u6709(\u5218\u5fb7\u534e, \u8eab\u9ad8, 174cm), \u53e6\u5916\u4e00\u4e2a\u62e5\u6709(\u5218\u5fb7\u534e, \u8eab\u9ad8, 173cm), \u5219\u53ef\u4ee5\u8ba4\u4e3a\u524d\u9762\u7684\u4fe1\u606f\u662f\u771f\u5b9e\u4fe1\u606f. \u9664\u4e86\u4e0a\u8ff0\u65b9\u6cd5, \u5bf9\u4e8e\u591a\u503c\u5c5e\u6027\u7684\u60c5\u51b5, \u53ef\u4ee5\u8003\u8651\u591a\u7b56\u7565\u878d\u5408\u7684\u65b9\u6cd5: 1: \u76f4\u63a5\u5408\u5e76\u7b56\u7565, \u8be5\u7b56\u7565\u8ba4\u4e3a\u6240\u6709\u5c5e\u6027\u503c\u90fd\u662f\u6b63\u786e\u7684, \u76f4\u63a5\u5408\u5e76\u6240\u6709\u7ed3\u679c\u5373\u53ef. 2: \u6295\u7968\u7b56\u7565, \u5305\u62ec\u591a\u6570\u6295\u7968, \u4e00\u81f4\u6027\u6295\u7968, \u52a0\u6743\u6295\u7968. 2.1: \u591a\u6570\u6295\u7968, \u53ea\u6709\u5f53\u8d85\u8fc7\u534a\u6570\u7684\u77e5\u8bc6\u56fe\u8c31\u90fd\u5305\u542b\u8be5\u5c5e\u6027\u503c\u65f6, \u624d\u8ba4\u4e3a\u8fd9\u4e2a\u5c5e\u6027\u503c\u662f\u6b63\u786e\u7684. 2.2: \u4e00\u81f4\u6027\u6295\u7968, \u53ea\u6709\u5f53\u6240\u6709\u77e5\u8bc6\u56fe\u8c31\u90fd\u5305\u542b\u8be5\u5c5e\u6027\u503c\u65f6, \u624d\u8ba4\u4e3a\u8fd9\u4e2a\u5c5e\u6027\u503c\u662f\u6b63\u786e\u7684. 2.3: \u52a0\u6743\u6295\u7968, \u5bf9\u4e0d\u540c\u7684\u77e5\u8bc6\u56fe\u8c31\u8bbe\u7f6e\u4e0d\u540c\u7684\u6743\u503c\u8fdb\u884c\u5408\u5e76. 3: \u81ea\u5b9a\u4e49\u878d\u5408\u7b56\u7565, \u67d0\u4e00\u77e5\u8bc6\u56fe\u8c31\u7684\u53ef\u4fe1\u5ea6\u8fdc\u9ad8\u4e8e\u5176\u4ed6\u77e5\u8bc6\u56fe\u8c31, \u53ef\u4ee5\u5c06\u8fd9\u4e2a\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5c5e\u6027\u7684\u5c5e\u6027\u503c\u4f5c\u4e3a\u57fa\u51c6, \u800c\u5c06\u5176\u4ed6\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5c5e\u6027\u7684\u5c5e\u6027\u503c\u901a\u8fc7\u542f\u53d1\u5f0f\u7684\u65b9\u5f0f\u52a0\u5165\u8fdb\u6765.","title":"6.2 \u767e\u79d1\u56fe\u8c31\u7684\u6784\u5efa"},{"location":"6_2.html#_1","text":"","title":"\u767e\u79d1\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa"},{"location":"6_2.html#_2","text":"\u4e86\u89e3\u767e\u79d1\u77e5\u8bc6\u56fe\u8c31\u7684\u5185\u6db5. \u4e86\u89e3\u767e\u79d1\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u65b9\u6cd5.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"6_2.html#_3","text":"","title":"\u767e\u79d1\u77e5\u8bc6\u56fe\u8c31\u6982\u5ff5"},{"location":"6_2.html#_4","text":"\u767e\u79d1\u56fe\u8c31\u662f\u4e00\u7c7b\u4ee5\u767e\u79d1\u7c7b\u7f51\u7ad9\u4f5c\u4e3a\u4e3b\u8981\u6570\u636e\u6e90\u6784\u5efa\u800c\u6210\u7684\u77e5\u8bc6\u56fe\u8c31. \u4e0e\u7eaf\u6587\u672c\u9875\u9762\u4e0d\u540c, \u767e\u79d1\u7c7b\u7f51\u7ad9\u7684\u9875\u9762\u4e2d\u5305\u542b\u4e30\u5bcc\u7684\u7ed3\u6784\u5316\u4fe1\u606f. \u6bd4\u5982, \u9875\u9762A\u662f\u6765\u81ea\u65b0\u95fb\u7f51\u7ad9\u7684\u7eaf\u6587\u672c\u9875\u9762, \u4f7f\u7528\u6587\u672c\u6587\u5b57\u5bf9\u7535\u5f71\u8fdb\u884c\u4ecb\u7ecd, \u7528\u6237\u9700\u8981\u4ed4\u7ec6\u9605\u8bfb\u6587\u5b57\u624d\u80fd\u5bf9\u7535\u5f71\u6709\u6240\u4e86\u89e3. \u9875\u9762B\u662f\u767e\u79d1\u9875\u9762, \u5176\u4e2d\u5305\u542b\u4e86\u4e30\u5bcc\u7684\u683c\u5f0f\u6807\u8bb0, \u5305\u62ec\u6807\u9898, \u6458\u8981, Infobox, \u4e3b\u8981\u6f14\u5458\u7b49\u533a\u57df\u6807\u8bb0, \u5bf9\u5185\u5bb9\u5206\u95e8\u522b\u7c7b\u7684\u8fdb\u884c\u7ec4\u7ec7, \u65b9\u4fbf\u7528\u6237\u7406\u89e3\u8fd9\u90e8\u7535\u5f71. \u603b\u800c\u8a00\u4e4b, \u767e\u79d1\u7c7b\u7f51\u7ad9\u9875\u9762\u4e2d\u7684\u4fe1\u606f\u7ec4\u7ec7\u66f4\u52a0\u7ed3\u6784\u5316, \u4fbf\u4e8e\u7528\u6237\u9605\u8bfb\u548c\u7406\u89e3, \u4e3b\u8981\u6709\u4ee5\u4e0b\u7279\u70b9: \u77e5\u8bc6\u5168\u9762: \u6839\u636e\u4e2d\u56fd\u5927\u767e\u79d1\u5168\u4e66\u7684\u5b9a\u4e49, \u767e\u79d1\u662f\u6982\u8981\u4ecb\u7ecd\u4eba\u7c7b\u4e00\u5207\u95e8\u7c7b\u77e5\u8bc6\u6216\u67d0\u4e00\u95e8\u7c7b\u77e5\u8bc6\u7684\u5de5\u5177\u4e66. \u4ece\u7406\u8bba\u4e0a\u6765\u8bf4, \u767e\u79d1\u7c7b\u7f51\u7ad9\u80fd\u8986\u76d6\u5168\u90e8\u77e5\u8bc6. \u5b9e\u4f53\u72ec\u7acb: \u6bcf\u4e2a\u5b9e\u4f53\u5bf9\u5e94\u4e00\u4e2a\u9875\u9762, \u6bcf\u4e2a\u9875\u9762\u5747\u56f4\u7ed5\u4e00\u4e2a\u72ec\u7acb\u7684\u5b9e\u4f53\u8fdb\u884c\u5168\u9762\u7684\u4ecb\u7ecd. \u683c\u5f0f\u7edf\u4e00: \u6bcf\u4e2a\u9875\u9762\u90fd\u7531\u7edf\u4e00\u7684\u7f51\u9875\u6a21\u677f\u81ea\u52a8\u751f\u6210, \u5305\u542b\u56fa\u5b9a\u683c\u5f0f\u7684\u534a\u7ed3\u6784\u5316\u6587\u672c. \u8d28\u91cf\u4f18\u826f: \u6bcf\u4e2a\u9875\u9762\u7684\u5185\u5bb9\u90fd\u7531\u4f17\u5305\u5de5\u4eba\u6216\u8005\u4e13\u4e1a\u4eba\u5458\u7f16\u8f91, \u800c\u4e14\u901a\u5e38\u6709\u7740\u4e25\u683c\u7684\u5ba1\u6838\u673a\u5236, \u51c6\u786e\u7387\u8f83\u9ad8. \u6838\u5fc3: \u4ee5\u767e\u79d1\u7c7b\u7f51\u7ad9\u4f5c\u4e3a\u6570\u636e\u6e90\u7684\u767e\u79d1\u56fe\u8c31\u5177\u6709\u77e5\u8bc6\u5b8c\u5907, \u83b7\u53d6\u5bb9\u6613, \u62bd\u53d6\u7b80\u5355, \u8d28\u91cf\u4f18\u826f\u7b49\u4f18\u70b9.","title":"\u767e\u79d1\u56fe\u8c31\u7684\u6982\u5ff5"},{"location":"6_2.html#_5","text":"\u767e\u79d1\u56fe\u8c31\u7684\u7814\u7a76\u5177\u6709\u91cd\u5927\u610f\u4e49, \u5176\u4e3b\u8981\u8868\u73b0\u5728\u4e00\u4e0b\u51e0\u4e2a\u65b9\u9762: 1: \u652f\u6491\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa 2: \u4e3a\u673a\u5668\u8bed\u8a00\u7406\u89e3\u63d0\u4f9b\u901a\u7528\u77e5\u8bc6 3: \u652f\u6491\u8bed\u6599\u81ea\u52a8\u6807\u6ce8 \u7b2c\u4e00: \u652f\u6491\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa \u5f88\u591a\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u662f\u5efa\u7acb\u5728\u901a\u7528\u77e5\u8bc6\u56fe\u8c31\u57fa\u7840\u4e4b\u4e0a\u7684. \u767e\u79d1\u56fe\u8c31\u5bf9\u9886\u57df\u56fe\u8c31\u8d77\u7740\u91cd\u8981\u7684\u652f\u6491\u4f5c\u7528. \u767e\u79d1\u56fe\u8c31\u662f\u4e00\u7c7b\u5178\u578b\u7684\u901a\u7528\u77e5\u8bc6\u56fe\u8c31. \u767e\u79d1\u56fe\u8c31\u4e00\u65b9\u9762\u53ef\u4ee5\u7ed9\u5f88\u591a\u9886\u57df\u56fe\u8c31\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7684\u79cd\u5b50\u4e8b\u5b9e, \u53e6\u4e00\u65b9\u9762\u53ef\u4ee5\u63d0\u4f9b\u9886\u57df\u6a21\u5f0f. \u6b64\u5916, \u5f88\u591a\u9886\u57df\u77e5\u8bc6\u5c31\u662f\u4ee5\u9886\u57df\u767e\u79d1\u7684\u5f62\u5f0f\u5b58\u5728, \u6bd4\u5982\u7535\u5f71\u7f51\u7ad9, \u97f3\u4e50\u7f51\u7ad9\u7b49. \u53e6\u5916, \u4e00\u4e9b\u4f01\u4e1a\u7684\u77e5\u8bc6\u5206\u4eab\u5e73\u53f0\u4e5f\u662f\u767e\u79d1\u5f62\u5f0f\u7684. \u56e0\u6b64, \u9762\u5411\u767e\u79d1\u7c7b\u578b\u6570\u636e\u6e90\u7684\u77e5\u8bc6\u83b7\u53d6\u6280\u672f\u5bf9\u4e8e\u9886\u57df\u56fe\u8c31\u7684\u6784\u5efa\u5177\u6709\u79ef\u6781\u610f\u4e49. \u7b2c\u4e8c: \u4e3a\u673a\u5668\u8bed\u8a00\u7406\u89e3\u63d0\u4f9b\u901a\u7528\u77e5\u8bc6 \u673a\u5668\u7406\u89e3\u81ea\u7136\u8bed\u8a00\u9700\u8981\u4e30\u5bcc\u7684\u80cc\u666f\u77e5\u8bc6, \u5176\u4e2d\u7684\u5173\u952e\u4e4b\u4e00\u662f\u901a\u7528\u77e5\u8bc6(Common Knowledge). \u6bd4\u5982, \u4e2d\u56fd\u7684\u9996\u90fd\u662f\u5317\u4eac, \u5730\u7403\u7684\u536b\u661f\u662f\u6708\u7403. \u901a\u7528\u77e5\u8bc6\u7684\u91cd\u8981\u8f7d\u4f53\u5c31\u662f\u767e\u79d1. \u767e\u79d1\u56fe\u8c31\u5b58\u50a8\u4e86\u6d77\u91cf\u5b9e\u4f53\u7684\u77e5\u8bc6, \u8fd9\u4e9b\u77e5\u8bc6\u53ef\u4ee5\u4f5c\u4e3a\u80cc\u666f\u77e5\u8bc6\u652f\u6491\u673a\u5668\u8bed\u8a00\u7406\u89e3, \u63d0\u5347\u673a\u5668\u5b66\u4e60\u6548\u679c\u7684\u91cd\u8981\u80cc\u666f\u77e5\u8bc6. \u7b2c\u4e09: \u652f\u6491\u8bed\u6599\u81ea\u52a8\u6807\u6ce8 \u5f53\u524d\u7684\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4efb\u52a1\u5927\u91cf\u91c7\u7528\u76d1\u7763\u5b66\u4e60\u6a21\u578b, \u800c\u8fd9\u5f80\u5f80\u9700\u8981\u5927\u91cf\u7684\u6807\u6ce8\u6837\u672c. \u4eba\u5de5\u6807\u6ce8\u8bed\u6599\u8d39\u65f6, \u8d39\u529b, \u5e76\u4e14\u8bed\u6599\u89c4\u6a21\u6709\u9650, \u96be\u6613\u6709\u6548\u652f\u6301\u6a21\u578b\u7684\u8bad\u7ec3. \u767e\u79d1\u56fe\u8c31\u5305\u542b\u4e30\u5bcc\u7684\u5b9e\u4f53\u548c\u5173\u7cfb\u77e5\u8bc6, \u53ef\u4ee5\u81ea\u52a8\u6807\u6ce8\u5927\u91cf\u8bed\u6599. \u8bcd\u6c47\u6316\u6398, \u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4ee5\u53ca\u5173\u7cfb\u62bd\u53d6\u7b49\u4efb\u52a1\u90fd\u53ef\u4ee5\u4f7f\u7528\u767e\u79d1\u4e2d\u7684\u7ed3\u6784\u5316\u77e5\u8bc6\u4e0e\u6587\u672c\u7684\u81ea\u52a8\u6bd4\u5bf9\u5b9e\u73b0\u81ea\u52a8\u6807\u6ce8. \u8fd9\u7c7b\u65b9\u6cd5\u88ab\u79f0\u4e3a\u8fdc\u7a0b\u76d1\u7763\u5b66\u4e60(Distant Supervision), \u95f4\u63a5\u76d1\u7763\u5b66\u4e60(Indirect Supervision)\u7b49.","title":"\u767e\u79d1\u56fe\u8c31\u7684\u610f\u4e49"},{"location":"6_2.html#_6","text":"\u767e\u79d1\u56fe\u8c31(\u6570\u636e\u6e90): \u901a\u7528\u767e\u79d1\u56fe\u8c31 \u9886\u57df\u767e\u79d1\u56fe\u8c31 \u767e\u79d1\u56fe\u8c31\u6839\u636e\u5176\u6570\u636e\u6e90\u7684\u7279\u70b9\u53ef\u4ee5\u5206\u4e3a\u901a\u7528\u767e\u79d1\u56fe\u8c31\u548c\u9886\u57df\u767e\u79d1\u56fe\u8c31. \u901a\u7528\u767e\u79d1\u56fe\u8c31\u6765\u81ea\u901a\u7528\u767e\u79d1\u7c7b\u7f51\u7ad9, \u5305\u542b\u6765\u81ea\u5404\u4e2a\u9886\u57df\u7684\u5b9e\u4f53. \u9886\u57df\u767e\u79d1\u56fe\u8c31\u6765\u81ea\u9886\u57df\u767e\u79d1\u7c7b\u7f51\u7ad9, \u4ec5\u5305\u542b\u7279\u5b9a\u9886\u57df\u7684\u5b9e\u4f53, \u5982\u7535\u5f71\u7f51\u7ad9, \u8d2d\u7269\u7f51\u7ad9, \u5de5\u5546\u7f51\u7ad9\u548c\u6cd5\u5f8b\u7f51\u7ad9\u7b49. \u8fd9\u4e9b\u7f51\u7ad9\u4e5f\u662f\u6bcf\u4e2a\u9875\u9762\u4ecb\u7ecd\u4e00\u4e2a\u5b9e\u4f53, \u540c\u65f6\u6bcf\u4e2a\u9875\u9762\u4e2d\u90fd\u5305\u542b\u5927\u91cf\u7684\u673a\u6784\u5316\u5185\u5bb9. \u767e\u79d1\u56fe\u8c31(\u6784\u5efa\u65b9\u6cd5): \u5355\u4e2a\u6570\u636e\u6e90 \u591a\u4e2a\u6570\u636e\u6e90 \u767e\u79d1\u56fe\u8c31\u6839\u636e\u6784\u5efa\u7684\u65b9\u6cd5\u5206\u4e3a\u4e24\u7c7b, \u4e00\u7c7b\u662f\u9488\u5bf9\u5355\u4e2a\u6570\u636e\u6e90(\u5355\u6e90)\u800c\u6784\u5efa\u7684\u767e\u79d1\u56fe\u8c31, \u5178\u578b\u4ee3\u8868\u6709DBPedia, YAGO, CN-DBPedia\u7b49. \u5176\u4e2d, DBPedia\u548cYAGO\u4ee5\u7ef4\u57fa\u767e\u79d1\u4f5c\u4e3a\u6570\u636e\u6e90, CN-DBPedia\u4ee5\u767e\u5ea6\u767e\u79d1\u4f5c\u4e3a\u6570\u636e\u6e90. \u53e6\u4e00\u7c7b\u662f\u878d\u5408\u591a\u4e2a\u6570\u636e\u6e90(\u591a\u6e90)\u800c\u6784\u5efa\u7684\u767e\u79d1\u56fe\u8c31, \u5178\u578b\u4ee3\u8868\u6709BabelNet, zhishi.me\u548cXLORE\u7b49. BabelNet\u878d\u5408\u4e86284\u79cd\u4e0d\u540c\u8bed\u8a00\u7684\u6570\u636e\u6e90, zhishi.me\u878d\u5408\u4e86\u767e\u5ea6\u767e\u79d1, \u4e92\u52a8\u767e\u79d1\u4ee5\u53ca\u4e2d\u6587\u7ef4\u57fa\u767e\u79d1, XLORE\u878d\u5408\u4e86\u767e\u5ea6\u767e\u79d1, \u4e92\u52a8\u767e\u79d1\u4ee5\u53ca\u82f1\u6587\u7ef4\u57fa\u767e\u79d1. \u6b64\u5916, \u6700\u65b0\u7248\u672c\u7684DBPedia\u548cYAGO\u4e5f\u878d\u5408\u4e86\u4e0d\u540c\u8bed\u8a00\u7248\u672c\u7684\u7ef4\u57fa\u767e\u79d1\u5e76\u6784\u5efa\u4e86\u8de8\u8bed\u8a00\u7684\u767e\u79d1\u56fe\u8c31. \u603b\u7ed3: \u5355\u6e90\u767e\u79d1\u56fe\u8c31\u7684\u6784\u5efa\u65b9\u6cd5\u4fa7\u91cd\u4e8e\u62bd\u53d6, \u591a\u6e90\u767e\u79d1\u56fe\u8c31\u7684\u6784\u5efa\u65b9\u6cd5\u4fa7\u91cd\u4e8e\u878d\u5408!","title":"\u767e\u79d1\u56fe\u8c31\u7684\u5206\u7c7b"},{"location":"6_2.html#_7","text":"\u57fa\u4e8e\u5355\u6e90\u7684\u767e\u79d1\u56fe\u8c31\u662f\u4ee5\u5355\u4e2a\u767e\u79d1\u767e\u79d1\u7c7b\u7f51\u7ad9\u4f5c\u4e3a\u6570\u636e\u6e90\u6784\u5efa\u800c\u6210\u7684\u767e\u79d1\u56fe\u8c31. \u5176\u8f93\u5165\u662f\u4e00\u4e2a\u767e\u79d1\u7c7b\u7f51\u7ad9, \u8f93>\u51fa\u662f\u4e00\u4e2a\u767e\u79d1\u56fe\u8c31. \u4f8b\u5982, \u8f93\u5165\u7ef4\u57fa\u767e\u79d1, \u8f93\u51faDBPedia; \u8f93\u5165\u767e\u5ea6\u767e\u79d1, \u8f93\u51faCN-DBPedia. \u57fa\u4e8e\u5355\u6e90\u7684\u767e\u79d1\u56fe\u8c31\u6784\u5efa\u4e3b\u8981\u52065\u4e2a\u6b65\u9aa4: 1: \u6570\u636e\u83b7\u53d6, \u76ee\u6807\u662f\u627e\u5230\u4e00\u4e2a\u767e\u79d1\u7c7b\u7f51\u7ad9\u6240\u6709\u5b9e\u4f53\u7684\u4ecb\u7ecd\u9875\u9762. 2: \u5c5e\u6027\u62bd\u53d6, \u76ee\u6807\u662f\u4ece\u767e\u79d1\u9875\u9762\u7684\u534a\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u62bd\u53d6\u51fa\u5b9e\u4f53\u7684\u5c5e\u6027\u77e5\u8bc6. 3: \u5173\u7cfb\u6784\u5efa, \u76ee\u6807\u662f\u5efa\u7acb\u5b9e\u4f53\u4e0e\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u8054. 4: \u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u6784\u5efa, \u76ee\u6807\u662f\u5efa\u7acb\u4e00\u4e2a\u6982\u5ff5\u96c6\u5408\u4ee5\u53ca\u6982\u5ff5\u4e4b\u95f4\u7684\u5c42\u7ea7\u5173\u7cfb. 5: \u5b9e\u4f53\u5206\u7c7b, \u76ee\u6807\u662f\u5c06\u5b9e\u4f53\u5206\u7c7b\u5230\u4e0a\u4e00\u6b65\u5efa\u7acb\u7684\u6982\u5ff5\u96c6\u5408\u4e2d.","title":"\u57fa\u4e8e\u5355\u6e90\u7684\u767e\u79d1\u56fe\u8c31\u6784\u5efa"},{"location":"6_2.html#_8","text":"\u767e\u79d1\u7c7b\u7f51\u7ad9\u4e0d\u4ec5\u5305\u542b\u5b9e\u4f53\u9875\u9762, \u8fd8\u5305\u542b\u5f88\u591a\u5176\u4ed6\u7684\u8f85\u52a9\u9875\u9762, \u5305\u62ec\u5fd7\u613f\u8005\u9875\u9762, \u6807\u7b7e\u9875\u9762, \u4e3b\u9898\u9875\u9762\u7b49 \u7b2c\u4e00\u6b65: \u83b7\u53d6\u4e00\u4e2a\u767e\u79d1\u7c7b\u7f51\u7ad9\u7684\u5168\u90e8\u9875\u9762. \u7b2c\u4e8c\u6b65: \u4ece\u5168\u90e8\u9875\u9762\u4e2d\u8bc6\u522b\u51fa\u5b9e\u4f53\u7684\u4ecb\u7ecd\u9875\u9762. \u83b7\u53d6\u4e00\u4e2a\u767e\u79d1\u7c7b\u7f51\u7ad9\u7684\u5168\u90e8\u9875\u9762\u6709\u4e09\u79cd\u7b56\u7565: \u57fa\u4e8e\u5907\u4efd\u6587\u4ef6\u7684\u4e0b\u8f7d: \u6709\u4e9b\u5728\u7ebf\u767e\u79d1\u7c7b\u7f51\u7ad9\u4f1a\u5b9a\u671f\u5bf9\u5916\u53d1\u5e03\u5168\u90e8\u9875\u9762\u7684\u5907\u4efd\u6587\u4ef6. \u7528\u6237\u53ea\u9700\u8981\u4e0b\u8f7d\u6700>\u65b0\u7684\u5907\u4efd\u6587\u4ef6, \u5373\u53ef\u83b7\u5f97\u8be5\u7f51\u7ad9\u7684\u5168\u90e8\u9875\u9762. \u4f8b\u5982, \u7ef4\u57fa\u767e\u79d1\u6bcf\u9694\u4e00\u6bb5\u65f6\u95f4\u5c31\u4f1a\u53d1\u5e03\u7f51\u7ad9\u7684\u5907\u4efd\u6587\u4ef6\u4f9b\u7528\u6237\u4e0b\u8f7d, \u8fd9\u79cd\u7b56\u7565\u6700\u4e3a\u7b80\u5355, \u4f46\u76ee\u524d\u63d0\u4f9b\u5907\u4efd\u6587\u4ef6\u7684\u767e\u79d1\u7c7b\u7f51\u7ad9\u4e0d\u591a. \u57fa\u4e8e\u8d85\u94fe\u63a5\u7684\u904d\u5386: \u8fd9\u662f\u641c\u7d22\u5f15\u64ce\u83b7\u53d6\u7f51\u9875\u7684\u65b9\u6cd5. \u767e\u79d1\u7c7b\u7f51\u7ad9\u7684\u7f51\u9875\u4e4b\u95f4\u901a\u5e38\u662f\u901a\u8fc7\u8d85\u94fe\u63a5\u8fde\u63a5\u8d77>\u6765\u7684, \u901a\u8fc7\u8d85\u94fe\u63a5, \u7406\u8bba\u4e0a\u53ef\u4ee5\u904d\u5386\u7f51\u7ad9\u4e2d\u7684\u6240\u6709\u7f51\u9875, \u901a\u8fc7\u8fd9\u79cd\u7b56\u7565\u53ef\u4ee5\u627e\u5230\u6240\u6709\u5173\u8054\u7684\u767e\u79d1\u9875\u9762. \u5e94\u7528\u8fd9\u79cd>\u7b56\u7565\u53ef\u4ee5\u627e\u5230\u5927\u91cf\u7684\u7f51\u9875, \u4f46\u5728\u771f\u5b9e\u5e94\u7528\u4e2d, \u53ec\u56de\u7387\u4ecd\u7136\u5b58\u5728\u4e00\u5b9a\u7684\u95ee\u9898, \u56e0\u4e3a\u4f1a\u5b58\u5728\u90e8\u5206\u767e\u79d1\u9875\u9762\u672a\u88ab\u5176\u4ed6\u4efb>\u4f55\u9875\u9762\u94fe\u63a5\u7684\u60c5\u51b5, \u8fd9\u4f1a\u5bfc\u81f4\u5176\u65e0\u6cd5\u88ab\u83b7\u53d6. \u57fa\u4e8e\u679a\u4e3e\u7684\u904d\u5386: \u8fd9\u79cd\u7b56\u7565\u7684\u57fa\u672c\u5047\u8bbe\u662f\u767e\u79d1\u7c7b\u7f51\u7ad9\u7684\u9875\u9762URL\u5177\u6709\u53ef\u679a\u4e3e\u6027. \u53ef\u679a\u4e3e\u6027\u662f\u6307\u53ef\u4ee5\u6839\u636e\u767e\u79d1\u7c7b\u7f51\u7ad9\u9875\u9762URL\u7684\u683c\u5f0f\u679a\u4e3e\u51fa\u6240\u6709\u767e\u79d1\u9875\u9762\u7684URL. \u9875\u9762\u8bc6\u522b: \u767e\u79d1\u56fe\u8c31\u4e3b\u8981\u5173\u6ce8\u5b9e\u4f53\u76f8\u5173\u7684\u77e5\u8bc6, \u56e0\u6b64\u9700\u8981\u4ece\u6240\u6709\u7f51\u9875\u4e2d\u8bc6\u522b\u51fa\u4ecb\u7ecd\u5b9e\u4f53\u7684\u9875\u9762, \u53ef\u4ee5\u5145\u5206\u5229\u7528\u767e\u79d1\u9875\u9762\u7684\u7279\u6b8a\u6027\u6765\u5b8c\u6210\u8fd9\u4e00\u4efb\u52a1. \u4e0e\u666e\u901a\u7684\u9875\u9762\u4e0d\u4e00\u6837, \u767e\u79d1\u7c7b\u7f51\u7ad9\u662f\u4ee5\u8bcd\u6761\u7684\u65b9\u5f0f\u5bf9\u5185\u5bb9\u8fdb\u884c\u7f16\u6392\u7684, \u6bcf\u4e2a\u9875\u9762\u5747\u56f4\u7ed5\u4e00\u4e2a\u8bcd\u6761\u8fdb\u884c\u5168\u9762\u7684\u4ecb\u7ecd. \u56e0\u6b64, \u5b9e\u4f53\u53d1\u73b0\u8fc7\u7a0b\u7b49\u4ef7\u4e8e\u8bcd\u6761\u9875\u9762\u53d1\u73b0\u8fc7\u7a0b. \u4e00\u822c\u800c\u8a00, \u6bcf\u4e2a\u767e\u79d1\u7c7b\u7f51\u7ad9\u7684\u8bcd\u6761\u9875\u9762URL\u90fd\u5177\u6709\u4e00\u5b9a\u7684\u547d\u540d\u89c4\u5f8b, \u6839\u636e\u5176\u547d\u540d\u89c4\u5f8b\u4e0d\u96be\u679a\u4e3e\u51fa\u6240\u6709\u5b9e\u4f53\u7684URL: **\u767e\u79d1 http://baike.**.com/view/1.htm **\u97f3\u4e50 https://music.**.com/#/song?id=30953009 **\u7535\u5f71 https://movie.**.com/subject/26213252/ **\u767e\u79d1 http://baike.**.com/item/\u4e00\u51fa\u597d\u620f","title":"\u6570\u636e\u83b7\u53d6"},{"location":"6_2.html#_9","text":"\u767e\u79d1\u7c7b\u7f51\u7ad9\u7684\u6bcf\u4e2a\u9875\u9762\u90fd\u56f4\u7ed5\u4e00\u4e2a\u72ec\u7acb\u7684\u5b9e\u4f53\u8fdb\u884c\u5168\u9762\u7684\u4ecb\u7ecd. \u56e0\u6b64, \u53ea\u9700\u8981\u89e3\u6790\u4e00\u4e2a\u767e\u79d1\u9875\u9762, \u5c31\u80fd\u5f97\u5230\u4e00\u4e2a\u5b9e\u4f53\u7684\u5168\u90e8\u5c5e\u6027\u548c\u5c5e\u6027\u503c. \u767e\u79d1\u7c7b\u7f51\u7ad9\u7684\u9875\u9762\u683c\u5f0f\u57fa\u672c\u56fa\u5b9a, \u5305\u542b\u5927\u91cf\u534a\u7ed3\u6784\u5316\u7684\u4fe1\u606f, \u5e38\u7528\u7684\u6709\u51e0\u4e0b\u51e0\u7c7b: \u591a\u4e49\u8bcd: \u53c8\u79f0\u6d88\u6b67\u9879, \u4e00\u822c\u51fa\u73b0\u5728\u8bcd\u6761\u540d\u79f0\u5b58\u5728\u6b67\u4e49\u7684\u9875\u9762\u4e2d. \u4f8b\u5982, \u6709\u591a\u4e2a\u767e\u79d1\u8bcd\u6761\u7684\u540d\u79f0\u90fd\u53eb\"\u5218\u5fb7\u534e\", \u70b9\u51fb\u4e0d\u540c\u7684\u8d85\u94fe\u63a5, \u53ef\u4ee5\u8df3\u8f6c\u5230\u76f8\u5e94\u7684\u8bcd\u6761\u9875\u9762. \u6807\u9898: \u6bcf\u4e2a\u9875\u9762\u90fd\u6709\u7684\u8bcd\u6761\u540d\u79f0, \u53ef\u80fd\u5b58\u5728\u540d\u79f0\u91cd\u590d\u7684\u60c5\u51b5. \u540c\u4e49\u8bcd: \u5f53\u7528\u6237\u641c\u7d22\u4e00\u4e2a\u8bcd\u6761\u7684\u522b\u540d\u65f6\u624d\u4f1a\u51fa\u73b0. \u4f8b\u5982, \u641c\u7d22\"\u534e\u4ed4\"\u4f1a\u8df3\u8f6c\u5230\"\u4e2d\u56fd\u9999\u6e2f\u7537\u6f14\u5458, \u6b4c\u624b, \u5236\u7247\u4eba\"\u5bf9\u5e94\u7684\"\u5218\u5fb7\u534e\"\u8bcd\u6761. \u6458\u8981: \u662f\u6587\u672c\u5f62\u5f0f\u7684\u8bcd\u6761\u6982\u8ff0, \u5927\u90e8\u5206\u9875\u9762\u90fd\u6709\u6458\u8981\u4fe1\u606f. \u76ee\u5f55: \u662f\u8bcd\u6761\u8be6\u7ec6\u9762\u719f\u5185\u5bb9\u7684\u5927\u7eb2, \u5927\u90e8\u5206\u9875\u9762\u90fd\u6709\u76ee\u5f55. \u57fa\u672c\u4fe1\u606f\u8868\u683c: \u53c8\u79f0Infobox, \u662f\u4e00\u7ec4\u5305\u542b\u5c5e\u6027\u53ca\u5c5e\u6027\u503c\u7684\u8868\u683c, \u662f\u5bf9\u5b9e\u4f53\u7684\u7ed3\u6784\u5316\u603b\u7ed3. \u8d85\u94fe\u63a5: \u4e0e\u5f53\u524d\u8bcd\u6761\u76f8\u5173\u7684\u5176\u4ed6\u8bcd\u6761\u4f1a\u901a\u8fc7\u8d85\u94fe\u63a5\u7684\u5f62\u5f0f\u4e0e\u5f53\u524d\u8bcd\u6761\u8fdb\u884c\u5173\u8054. \u6807\u7b7e: \u7531\u5e7f\u5927\u7528\u6237\u521b\u5efa\u7684\u6807\u7b7e, \u7528\u4e8e\u5bf9\u8bcd\u6761\u8fdb\u884c\u7ec4\u7ec7\u548c\u5206\u7c7b, \u65b9\u4fbf\u7528\u6237\u5bfc\u822a, \u6d4f\u89c8\u7b49. \u6807\u7b7e\u4e2d\u65e2\u6709\u4e3b\u9898\u578b\u6807\u7b7e(\u519b\u4e8b, \u5386\u53f2, \u751f\u7269), \u4e5f\u6709\u6982\u5ff5\u578b\u6807\u7b7e(\u6f14\u5458, \u884c\u653f\u533a\u57df). \u6ce8\u610f: \u4e0d\u540c\u7684\u767e\u79d1\u7c7b\u7f51\u7ad9\u5305\u542b\u7684\u534a\u7ed3\u6784\u5316\u4fe1\u606f\u4e0d\u5c3d\u76f8\u540c. \u4f8b\u5982, \u7ef4\u57fa\u767e\u79d1\u4e2d\u5c31\u5b58\u5728\u4e00\u4e9b\u767e\u5ea6\u767e\u79d1\u4e2d\u6ca1\u6709\u7684\u77e5\u8bc6, \u5982\u6982\u5ff5\u7684\u5c42\u7ea7\u7ed3\u6784\u4fe1\u606f, \u8bcd\u6761\u7684\u5730\u7406\u4fe1\u606f\u4ee5\u53ca\u591a\u8bed\u8a00\u7248\u672c\u94fe\u63a5\u4fe1\u606f\u7b49.","title":"\u5c5e\u6027\u62bd\u53d6"},{"location":"6_2.html#_10","text":"\u534a\u7ed3\u6784\u5316\u77e5\u8bc6\u62bd\u53d6: \u9488\u5bf9\u767e\u79d1\u9875\u9762\u7684\u77e5\u8bc6\u62bd\u53d6, \u672c\u8d28\u4e0a\u662f\u9488\u5bf9\u5176\u4e2d\u534a\u7ed3\u6784\u5316\u5185\u5bb9\u8fdb\u884c\u89e3\u6790. \u767e\u79d1\u7c7b\u7f51\u7ad9\u4e2d\u7684\u6bcf\u4e2a\u8bcd\u6761\u90fd\u88ab\u770b\u4f5c\u4e00\u4e2a\u5b9e\u4f53, \u9488\u5bf9\u6bcf\u4e2a\u8bcd\u6761\u9875\u9762\u7684\u4e0d\u540c\u7c7b\u578b\u7684\u534a\u7ed3\u6784\u5316\u4fe1\u606f, \u53ef\u4ee5\u4f7f\u7528\u4e0d\u540c\u7684\u62bd\u53d6\u5668\u6765\u62bd\u53d6\u77e5\u8bc6, \u6700\u7ec8\u4f1a\u5f97\u5230\u4e00\u4e2a\u5b9e\u4f53\u7684\u5168\u90e8\u5c5e\u6027\u53ca\u90e8\u5206\u9690\u6027\u5173\u7cfb. \u540d\u79f0\u5c5e\u6027: \u77e5\u8bc6\u56fe\u8c31\u6240\u63cf\u8ff0\u7684\u5b9e\u4f53\u90fd\u662f\u552f\u4e00\u6027\u7684, \u5728\u6570\u636e\u5e93\u4e2d\u5b58\u50a8\u65f6\u5176\u901a\u5e38\u4f7f\u7528\u552f\u4e00\u6807\u8bc6\u7b26(Unique ID, UID)\u8fdb\u884c\u6807\u8bb0, \u4f46\u662fUID\u663e\u7136\u5bf9\u7528\u6237\u4e0d\u591f\u53cb\u597d. \u56e0\u6b64, \u767e\u79d1\u56fe\u8c31\u901a\u5e38\u91c7\u7528\u5b57\u7b26\u578b\u540d\u79f0\u5bf9\u5b9e\u4f53\u8fdb\u884c\u8868\u793a. \u4f46\u662f\u4e2d\u6587\u5b9e\u4f53\u540d\u53c8\u7ecf\u5e38\u4f1a\u51fa\u73b0\u91cd\u590d\u7684\u60c5\u51b5, \u56e0\u6b64\u767e\u79d1\u56fe\u8c31\u901a\u5e38\u4f1a\u901a\u8fc7\u989d\u5916\u7684\u5907\u6ce8\u5bf9\u5b9e\u4f53\u8fdb\u884c\u6d88\u6b67. \u7528\u4e8e\u6d88\u6b67\u7684\u5907\u6ce8\u53ef\u4ee5\u662f\u5b9e\u4f53\u7c7b\u578b, \u5173\u952e\u7279\u5f81. \u4f8b\u5982, \u5b9e\u4f53\u540d\u79f0\u4e3a\"\u5218\u5fb7\u534e\", \u5219\u53ef\u4ee5\u6dfb\u52a0\u5907\u6ce8\u4fe1\u606f(\u4e2d\u56fd\u9999\u6e2f\u7537\u6f14\u5458, \u6b4c\u624b, \u5236\u7247\u4eba). \u5b9e\u4f53\u6307\u4ee3: \u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\u4f1a\u4ee5\u591a\u79cd\u4e0d\u540c\u7684\u6307\u4ee3(Mention)\u5f62\u5f0f\u51fa\u73b0\u5728\u6587\u672c\u8bed\u6599\u4e2d. \u5982\"\u5218\u5fb7\u534e\"\u6709\u65f6\u4f1a\u4ee5\"\u534e\u4ed4\"\u7684\u5f62\u5f0f\u51fa\u73b0, \u6709\u65f6\u53c8\u4f1a\u4ee5\"\u5218\u5929\u738b\"\u7b49\u5f62\u5f0f\u51fa\u73b0. \u8bc6\u522b\u4e00\u4e2a\u5b9e\u4f53\u7684\u4e0d\u540c\u6307\u4ee3\u5f62\u5f0f\u6709\u52a9\u4e8e\u673a\u5668\u7406\u89e3\u6587\u672c. \u83b7\u53d6\u5b9e\u4f53\u7684\u6307\u4ee3\u6709\u4e09\u79cd\u65b9\u5f0f. \u7b2c\u4e00\u79cd: \u6839\u636e\u540c\u4e49\u8bcd\u4fe1\u606f\u83b7\u53d6, \u4f8b\u5982, \u641c\u7d22\"\u534e\u4ed4\"\u5c06\u8df3\u8f6c\u5230\"\u5218\u5fb7\u534e(\u4e2d\u56fd\u9999\u6e2f\u7537\u6f14\u5458, \u6b4c\u624b, \u5236\u7247\u4eba)\". \u7b2c\u4e8c\u79cd: \u6839\u57fa\u591a\u4e49\u8bcd\u4fe1\u606f\u83b7\u53d6, \u6bcf\u4e2a\u5305\u542b\u6b67\u4e49\u9879\u7684\u5b9e\u4f53\u7684\u6807\u9898\u5c31\u662f\u8fd9\u4e2a\u5b9e\u4f53\u7684\u6307\u4ee3. \u7b2c\u4e09\u79cd: \u6839\u636e\u57fa\u672c\u4fe1\u606f\u8868\u683c\u83b7\u53d6, \u8868\u683c\u4e2d\u53ef\u80fd\u5305\u542b\u4e00\u4e9b\u6307\u793a\u5b9e\u4f53\u6307\u4ee3\u7684\u5c5e\u6027, \u5982\u82f1\u6587\u540d, \u522b\u540d, \u5b66\u540d\u7b49, \u8fd9\u4e9b\u5c5e\u6027\u7684\u503c\u5747\u662f\u5b9e\u4f53\u7684\u6307\u4ee3. \u4f8b\u5982, \u5218\u5fb7\u534e\u7684\u82f1\u6587\u540d\"Andy Lau\"\u4e5f\u662f\u5176\u6307\u4ee3\u4e4b\u4e00. \u6458\u8981\u5c5e\u6027: \u6458\u8981\u5c5e\u6027\u662f\u5bf9\u5b9e\u4f53\u7684\u6982\u8ff0\u6027\u63cf\u8ff0, \u5305\u542b\u7684\u4fe1\u606f\u975e\u5e38\u4e30\u5bcc, \u53ef\u7528\u4e8e\u5b9e\u4f53\u5c55\u793a, \u76f8\u4f3c\u5ea6\u8ba1\u7b97\u548c\u5b9e\u4f53\u7684\u8868\u793a\u5b66\u4e60\u7b49. \u57fa\u672c\u5c5e\u6027: \u6765\u6e90\u4e8e\u57fa\u672c\u5c5e\u6027\u8868\u683c, \u5b83\u4eec\u523b\u753b\u4e86\u5b9e\u4f53\u7684\u57fa\u672c\u4fe1\u606f, \u662f\u767e\u79d1\u56fe\u8c31\u6700\u91cd\u8981\u7684\u77e5\u8bc6\u6765\u6e90\u4e4b\u4e00, \u5bf9\u6700\u7ec8\u7684\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u77e5\u8bc6\u8d21\u732e\u6700\u5927. \u5b9e\u4f53\u7684\u5c5e\u6027\u53ca\u5c5e\u6027\u503c\u76f4\u63a5\u6765\u81ea\u8fd9\u4e9b\u8868\u683c\u7684\u5c5e\u6027\u5217\u548c\u5c5e\u6027\u503c\u5217. \u76f8\u5173\u5173\u7cfb: \u76f8\u5173\u5173\u7cfb\u662f\u901a\u8fc7\u8d85\u94fe\u63a5\u4fe1\u606f\u83b7\u53d6\u7684, \u662f\u5b9e\u4f53\u4e4b\u95f4\u7684\u4e00\u79cd\u9690\u6027\u5173\u7cfb. \u4f8b\u5982, \"\u5218\u5fb7\u534e\"\u548c\"\u6768\u8fc7\"\u4e4b\u95f4\u5b58\u5728\u8d85\u94fe\u63a5, \u8868\u660e\u4e24\u8005\u4e4b\u95f4\u5b58\u5728\u5173\u7cfb, \u4f46\u8fd9\u79cd\u5173\u7cfb\u96be\u4ee5\u7528\u7b80\u5355\u7684\u57fa\u672c\u5173\u7cfb\u8fdb\u884c\u8868\u793a(\u5218\u5fb7\u534e\u4e8e1983\u5e74\u5728\u7535\u5f71\u795e\u96d5\u4fa0\u4fa3\u4e2d\u9970\u6f14\u6768\u8fc7), \u76ee\u524d\u7528\u76f8\u5173\u5173\u7cfb\u8868\u793a. \u5206\u7c7b\u5173\u7cfb: \u5206\u7c7b\u5173\u7cfb\u901a\u8fc7\u6807\u7b7e\u4fe1\u606f\u83b7\u53d6, \u5305\u542b\u5b9e\u4f53\u4e0e\u6982\u5ff5\u4e4b\u95f4\u7684\u5b9e\u4f8b\u5173\u7cfb(instanceOf), \u4ee5\u53ca\u5b9e\u4f53\u4e0e\u4e3b\u9898\u4e4b\u95f4\u7684\u5173\u7cfb.","title":"\u534a\u7ed3\u6784\u5316\u77e5\u8bc6\u62bd\u53d6"},{"location":"6_2.html#_11","text":"\u77e5\u8bc6\u6e05\u6d17: \u7531\u4e8e\u767e\u79d1\u7c7b\u7f51\u7ad9\u662f\u901a\u8fc7\u4f17\u5305\u7684\u65b9\u5f0f\u7f16\u5199\u7684, \u56e0\u6b64\u901a\u5e38\u6ca1\u6709\u7edf\u4e00\u7684\u7f16\u5199\u6807\u51c6. \u5229\u7528\u534a\u7ed3\u6784\u5316\u7684\u77e5\u8bc6\u62bd\u53d6\u65b9\u6cd5\u5f97\u5230\u7684\u5b9e\u4f53\u77e5\u8bc6(\u4e3b\u8981\u6765\u6e90\u4e8e\u57fa\u672c\u4fe1\u606f\u8868\u683c\u4e2d\u7684\u57fa\u672c\u5c5e\u6027)\u4f1a\u5b58\u5728\u5f88\u591a\u8d28\u91cf\u95ee\u9898: \u5c5e\u6027\u8868\u8ff0\u4e0d\u4e00\u81f4: \u4e0d\u540c\u8bcd\u6761\u5bf9\u540c\u4e00\u5c5e\u6027\u7684\u8868\u8ff0\u4e0d\u540c, \u6709\u4e9b\u8bcd\u6761\u63cf\u8ff0\u4eba\u7269\u65f6\u4f7f\u7528\u4e86\"\u82f1\u6587\u540d\"\u5c5e\u6027, \u800c\u53e6\u4e00\u4e9b\u8bcd\u6761\u5219\u4f7f\u7528\u7684\u662f\"\u82f1\u6587\u540d\u79f0\"\u5c5e\u6027. \u6570\u503c\u5c5e\u6027\u503c\u683c\u5f0f\u4e0d\u7edf\u4e00: \u5728\u586b\u5199\u65e5\u671f\u5c5e\u6027\u65f6, \u5f88\u591a\u7528\u6237\u4e60\u60ef\u4f7f\u7528\"YYYY\u5e74MM\u6708DD\u65e5\"\u7684\u683c\u5f0f, \u800c\u53e6\u5916\u4e00\u90e8\u5206\u7528\u6237\u4e60\u60ef\u4f7f\u7528\"YYYYMMDD\"\u7684\u683c\u5f0f. \u53e6\u5916, \u6709\u4e9b\u5c5e\u6027\u503c\u7684\u5355\u4f4d\u4e0d\u7edf\u4e00, \u4f8b\u5982, \u5728\u63cf\u8ff0\u8eab\u9ad8\u65f6, \u6709\u4e9b\u4f7f\u7528\"\u7c73\"\u4f5c\u4e3a\u5355\u4f4d, \u6709\u4e9b\u4f7f\u7528\"\u5398\u7c73\", \u6216\u8005\"X\u5c3aY\u5bf8\". \u5bf9\u8c61\u5c5e\u6027\u7684\u591a\u4e2a\u5c5e\u6027\u503c\u5408\u5e76\u8868\u793a: \u5bf9\u8c61\u5c5e\u6027(Object Property)\u662f\u6307\u90a3\u4e9b\u5c5e\u6027\u503c\u662f\u5b9e\u4f53\u6216\u5b9e\u4f53\u6307\u4ee3\u7684\u5c5e\u6027, \u672c\u8d28\u4e0a\u8868\u8fbe\u4e86\u5b9e\u4f53\u95f4\u7684\u5173\u7cfb. \u5bf9\u8c61\u5c5e\u6027\u662f\u53ef\u679a\u4e3e\u7684, \u53ef\u80fd\u5b58\u5728\u591a\u4e2a\u4e0d\u540c\u7684\u5c5e\u6027\u503c. \u5728\u767e\u79d1\u7c7b\u7f51\u7ad9\u4e2d, \u8fd9\u4e9b\u5c5e\u6027\u503c\u5f80\u5f80\u4f1a\u901a\u8fc7\u5404\u79cd\u8fde\u63a5\u7b26\u53f7\u5408\u5e76\u6210\u4e00\u4e2a\u5b57\u7b26\u4e32. \u4f8b\u5982, \"\u5218\u5fb7\u534e\"\u6709\u4e00\u4e2a\u5bf9\u8c61\u5c5e\u6027\"\u4ee3\u8868\u4f5c\u54c1\", \u5176\u5c5e\u6027\u503c\u4e3a\"\u65e0\u95f4\u9053, \u5929\u82e5\u6709\u60c5, \u65fa\u89d2\u5361\u95e8......\", \u6bcf\u4e2a\u9017\u53f7\u5206\u9694\u7684\u662f\u4e00\u90e8\u4f5c\u54c1(\u5b9e\u4f53)\u7684\u540d\u79f0. \u8fd9\u79cd\u5408\u5e76\u8868\u793a\u4f1a\u5bfc\u81f4\u540e\u7eed\u5173\u7cfb\u6784\u5efa\u6b65\u9aa4\u96be\u4ee5\u5efa\u7acb\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb, \u56e0\u4e3a\u9700\u8981\u5408\u9002\u7684\u65b9\u6cd5\u8bc6\u522b\u5c5e\u6027\u503c\u63d0\u53ca\u4e86\u54ea\u4e9b\u5b9e\u4f53. \u6bd4\u5982, \u9700\u8981\u8bc6\u522b\u51fa\"\u65e0\u95f4\u9053\"\u662f\u4e00\u4e2a\u5b9e\u4f53\u5e76\u4e14\u94fe\u63a5\u5230\u77e5\u8bc6\u5e93\u4e2d\u540d\u4e3a\"\u65e0\u95f4\u9053(2022\u5e74\u5218\u4f1f\u5f3a\u6307\u5bfc\u7684\u7535\u5f71)\"\u7684\u5b9e\u4f53. \u4e0a\u8ff0\u76843\u79cd\u8d28\u91cf\u95ee\u9898\u4f1a\u964d\u4f4e\u77e5\u8bc6\u56fe\u8c31\u7684\u53ef\u7528\u6027, \u56e0\u6b64\u9700\u8981\u5bf9\u62bd\u53d6\u51fa\u6765\u7684\u77e5\u8bc6\u8fdb\u884c\u6e05\u6d17! \u77e5\u8bc6\u6e05\u6d17\u4e3b\u8981\u5206\u4e3a\u4e09\u4e2a\u90e8\u5206: \u5c5e\u6027\u5bf9\u9f50 \u6570\u503c\u5c5e\u6027\u503c\u5f52\u4e00\u5316 \u5bf9\u8c61\u5c5e\u6027\u503c\u5206\u5272 \u5c5e\u6027\u5bf9\u9f50: \u5c5e\u6027\u5bf9\u9f50\u7684\u76ee\u6807\u662f\u5c06\u5355\u6570\u636e\u6e90\u4e2d\u7684\u6240\u6709\u7b49\u4ef7\u5c5e\u6027\u5408\u5e76, \u7528\u7edf\u4e00\u7684\u5c5e\u6027\u540d\u79f0\u8868\u793a. \u4f8b\u5982, \u5c06\u767e\u5ea6\u767e\u79d1\u4e2d\u8bcd\u6761\u7684\u5c5e\u6027\"\u82f1\u6587\u540d\"\u548c\u5c5e\u6027\"\u82f1\u6587\u540d\u79f0\"\u7edf\u4e00\u7528\"\u82f1\u6587\u540d\u79f0\"\u6765\u8868\u793a. \u5c5e\u6027\u5bf9\u9f50\u901a\u5e38\u91c7\u7528\"\u751f\u6210 + \u8fc7\u6ee4 + \u9a8c\u8bc1\"\u7684\u57fa\u672c\u601d\u8def. \u751f\u6210: \u5728\u751f\u6210\u9636\u6bb5, \u4e3a\u5168\u90e8\u5c5e\u6027\u4e24\u4e24\u8ba1\u7b97\u76f8\u4f3c\u5ea6, \u5f97\u5230\u5019\u9009\u7684\u7b49\u4ef7\u5c5e\u6027\u5bf9. \u8fc7\u6ee4: \u5728\u8fc7\u6ee4\u9636\u6bb5, \u9700\u8981\u8bbe\u8ba1\u89c4\u5219, \u8fc7\u6ee4\u6389\u5176\u4e2d\u7684\u9519\u8bef\u7b49\u4ef7\u5c5e\u6027\u5bf9. \u9a8c\u8bc1: \u5728\u9a8c\u8bc1\u9636\u6bb5, \u4ea4\u7531\u4eba\u5de5\u5bf9\u6700\u7ec8\u7ed3\u679c\u8fdb\u884c\u9a8c\u8bc1. \u6ce8\u610f: \u5bf9\u4e8e\u6bcf\u4e2a\u7b49\u4ef7\u5c5e\u6027\u5bf9, \u4f7f\u7528\u4e24\u8005\u4e2d\u51fa\u73b0\u9891\u6b21\u8f83\u9ad8\u7684\u90a3\u4e2a\u5c5e\u6027\u7684\u540d\u79f0\u6765\u8868\u793a\u8fd9\u5bf9\u7b49\u4ef7\u5c5e\u6027. \u751f\u6210\u9636\u6bb5: \u6700\u91cd\u8981\u7684\u5c31\u662f\u5c5e\u6027\u76f8\u4f3c\u5ea6\u7684\u8ba1\u7b97\u65b9\u6cd5, \u4e3b\u6d41\u67093\u79cd\u65b9\u6cd5. * \u57fa\u4e8e\u5c5e\u6027\u540d\u79f0\u76f8\u4f3c\u6027\u7684\u65b9\u6cd5: \u5c06\u6bcf\u4e2a\u5c5e\u6027\u540d\u79f0\u5f53\u505a\u4e00\u4e2a\u5b57\u7b26\u4e32, \u5ea6\u91cf\u5b57\u7b26\u4e32\u76f8\u4f3c\u5ea6\u7684\u6307\u6807\u5305\u62ecJaccard\u7cfb\u6570, \u7f16\u8f91\u8ddd\u79bb\u7b49. \u4f8b\u5982, Jaccard\u7cfb\u6570\u5c06\u5c5e\u6027\u540d\u79f0\u5f53\u505a\u5b57\u7b26\u96c6\u5408, \u901a\u8fc7\u6bd4\u8f83\u4e24\u4e2a\u5c5e\u6027\u540d\u79f0\u7684\u5b57\u7b26\u96c6\u5408\u7684\u76f8\u4ea4\u7a0b\u5ea6 \u8bc4\u4f30\u5c5e\u6027\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6, \"\u82f1\u6587\u540d\"\u548c\"\u82f1\u6587\u540d\u79f0\"\u76f8\u5e94\u7684\u5b57\u7b26\u96c6\u5408\u7684Jaccard\u76f8\u4f3c\u5ea6\u4e3a\u00be=0.75. * \u4f7f\u7528\u5916\u90e8\u540c\u4e49\u8bcd\u77e5\u8bc6\u5e93\u7684\u65b9\u6cd5: \u4f8b\u5982, \u5f15\u5165\u540c\u4e49\u8bcd\u8bcd\u5178, \u767e\u5ea6\u6c49\u8bed\u8bcd\u5178\u7b49, \u5904\u7406\u90a3\u4e9b\u8bed\u4e49\u76f8\u4f3c\u4f46\u662f\u540d>\u79f0\u76f8\u53bb\u751a\u8fdc\u7684\u5c5e\u6027, \u6bd4\u5982\"\u59bb\u5b50\"\u548c\"\u8001\u5a46\", \"\u897f\u4f2f\u5229\u4e9a\u96ea\u6a47\u72ac\"\u548c\"\u4e8c\u54c8\". * \u57fa\u4e8e\u5c5e\u6027\u53d6\u503c\u76f8\u4f3c\u5ea6\u7684\u65b9\u6cd5: \u5305\u62ec\u5c5e\u6027\u503c\u96c6\u5408\u7684\u76f8\u4f3c\u5ea6\u548c\u5c5e\u6027\u503c\u7c7b\u578b\u7684\u76f8\u4f3c\u5ea6. \u8fc7\u6ee4\u9636\u6bb5: \u6700\u91cd\u8981\u7684\u5c31\u662f\u91c7\u7528\u4e00\u4e9b\u542f\u53d1\u5f0f\u89c4\u5219, \u5982\"\u4e24\u4e2a\u7b49\u4ef7\u5c5e\u6027\u4e0d\u4f1a\u540c\u65f6\u51fa\u73b0\u5728\u4e00\u4e2a\u767e\u79d1\u8bcd\u6761\u9875\u9762\u4e2d\", \u5982\u679c>\u4e00\u4e2a\u8bcd\u6761\u4e2d\u540c\u65f6\u51fa\u73b0\u4e86\u4e24\u4e2a\u5019\u9009\u7684\u7b49\u4ef7\u5c5e\u6027, \u90a3\u4e48\u8fd9\u4e24\u4e2a\u5c5e\u6027\u4e0d\u662f\u7b49\u4ef7\u5c5e\u6027. \u6570\u503c\u5c5e\u6027\u503c\u5f52\u4e00\u5316: \u6570\u503c\u5c5e\u6027\u503c\u5f52\u4e00\u5316\u7684\u76ee\u6807\u662f\u5c06\u6240\u6709\u7684\u6570\u503c\u5c5e\u6027\u503c\u7edf\u4e00\u8868\u793a. \u6570\u503c\u5c5e\u6027\u503c\u5f80\u5f80\u662f\u7531\"\u6570\u5b57+\u5355>\u4f4d\"\u6784\u6210\u7684, \u6240\u4ee5\u6570\u503c\u5c5e\u6027\u503c\u5f52\u4e00\u5316\u53ef\u4ee5\u5206\u4e3a\u6570\u503c\u62bd\u53d6\u548c\u5355\u4f4d\u7edf\u4e00\u4e24\u4e2a\u6b65\u9aa4. \u4f8b\u5982, \u5bf9\u4e8e\u65e5\u671f\u5c5e\u6027, \u53ef\u4ee5\u901a\u8fc7\u6b63\u5219 \u8868\u8fbe\u5f0f\u62bd\u53d6\u51fa\u5e74, \u6708, \u65e5\u7b49\u6570\u503c\u4fe1\u606f, \u518d\u901a\u8fc7\u8f6c\u6362\u6765\u7edf\u4e00\u5355\u4f4d. \u5bf9\u8c61\u5c5e\u6027\u503c\u5206\u5272: \u5bf9\u8c61\u5c5e\u6027\u503c\u5206\u5272\u7684\u76ee\u6807\u662f\u5c06\u4e00\u4e2a\u5bf9\u8c61\u5c5e\u6027\u7684\u591a\u4e2a\u5c5e\u6027\u503c\u5408\u5e76\u800c\u6210\u7684\u5b57\u7b26\u4e32\u62c6\u5206\u6210\u591a\u7ec4\"\u5c5e\u6027->\u5c5e\u6027\u503c\"\u5bf9, \u4ee5\u4fbf\u540e\u7eed\u8fdb\u884c\u5173\u7cfb\u6784\u5efa. \u6bd4\u5982, \u5c06\u5218\u5fb7\u534e\u7684\u5c5e\u6027\"\u4ee3\u8868\u4f5c\u54c1\"\u7684\u503c\"\u65e0\u95f4\u9053, \u5929\u82e5\u6709\u60c5, \u65fa\u89d2\u5361\u95e8......\"\u62c6\u5206\u6210\u591a\u7ec4\u5c5e\u6027-\u5c5e\u6027\u503c\u5bf9(\"\u4ee3\u8868\u4f5c\u54c1\", \"\u65e0\u95f4\u9053\"), (\"\u4ee3\u8868\u4f5c\u54c1\", \"\u5929\u82e5\u6709\u60c5\"), (\"\u4ee3\u8868\u4f5c\u54c1\", \"\u65fa\u89d2\u5361\u95e8\")\u7b49. \u6ce8\u610f: \u8fd9\u4e00\u62c6\u5206\u7684\u96be\u70b9\u5728\u4e8e\u5e76\u975e\u6240\u6709\u7531\u5206\u9694\u7b26\u8fde\u63a5\u800c\u6210\u7684\u5c5e\u6027\u503c\u90fd\u662f\u9700\u8981\u5206\u5272\u7684\u591a\u503c\u5bf9\u8c61\u5c5e\u6027. \u4f8b\u5982, \u6e05\u534e\u5927\u5b66\u7684\u5c5e\u6027\"\u6821\u8bad\"\u7684\u5c5e\u6027\u503c\u4e3a\"\u81ea\u5f3a\u4e0d\u606f, \u539a\u5fb7\u8f7d\u7269\". \u5c3d\u7ba1\u8be5\u5c5e\u6027\u503c\u662f\u901a\u8fc7\u5206\u9694\u7b26\u9017\u53f7\u7ec4\u5408\u800c\u6210\u7684, \u4f46\u662f\"\u6821\u8bad\"\u662f\u4e0d\u53ef\u62c6\u5206\u7684\u5355\u503c\u5c5e\u6027, \u4e0d\u5e94\u8be5\u62c6\u5206. \u5bf9\u8c61\u5c5e\u6027\u503c\u5206\u5272\u7684\u57fa\u672c\u601d\u8def: \u5bf9\u4e8e\u4efb\u610f\u4e00\u4e2a\u5c5e\u6027, \u5982\u679c\u5206\u5272\u540e\u7684\u5c5e\u6027\u503c\u96c6\u5408\u4e2d\u7684\u5927\u90e8\u5206\u5c5e\u6027\u503c\u90fd\u6307\u4ee3\u7279\u5b9a\u5b9e\u4f53, \u90a3\u4e48\u8fd9\u4e2a\u5c5e\u6027\u5f88\u53ef\u80fd\u662f\u591a\u6c41\u7684\u5bf9\u8c61\u5c5e\u6027, \u5bf9\u76f8\u5e94\u5c5e\u6027\u503c\u8fdb\u884c\u5206\u5272\u662f\u5408\u7406\u7684\u5c1d\u8bd5. \u4e00\u4e2a\u5b9e\u73b0\u65b9\u6cd5: \u5bf9\u4e8e\u4e00\u4e2a\u5c5e\u6027\u503c, \u9996\u5148\u5224\u65ad\u5176\u4e2d\u662f\u5426\u5b58\u5728\u5206\u9694\u7b26, \u5982\u679c\u4e0d\u5b58\u5728\u4efb\u4f55\u4e00\u79cd\u5206\u9694\u7b26, \u5c31\u8ba4\u4e3a\u4e0d\u9700\u8981\u5206\u5272; \u5982\u679c\u5b58\u5728\u4e00\u79cd\u6216\u591a\u79cd\u5206\u9694\u7b26, \u5219\u8ba1\u7b97\u5c5e\u6027\u503c\u5b57\u7b26\u4e32\u6309\u7167\u51fa\u73b0\u7684\u6bcf\u79cd\u5206\u9694\u7b26\u8fdb\u884c\u5206\u5272\u540e\u7684\u5f97\u5206(\u6bd4\u5982\u5c5e\u6027\u503c\u96c6\u5408\u4e2d\u80fd\u591f\u94fe\u63a5\u4e0a\u5b9e\u4f53\u7684\u5c5e\u6027\u503c\u7684\u6570\u91cf\u6216\u6bd4\u4f8b), \u6700\u540e\u5c06\u5f97\u5206\u6700\u9ad8\u7684\u65b9\u6848\u4f5c\u4e3a\u6700\u7ec8\u7684\u5206\u5272\u65b9\u6848.","title":"\u77e5\u8bc6\u6e05\u6d17"},{"location":"6_2.html#_12","text":"\u901a\u8fc7\u4e0a\u9762\u4e00\u6b65\u5c5e\u6027\u62bd\u53d6\u7684\u6b65\u9aa4, \u53ef\u4ee5\u83b7\u5f97\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5b9e\u4f53\u7684\u5c5e\u6027\u548c\u5c5e\u6027\u503c. \u5f53\u5c5e\u6027\u662f\u5bf9\u8c61\u5c5e\u6027\u65f6, \u901a\u8fc7\u5c06\u5b9e\u4f53\u7684\u5c5e\u6027\u503c\u94fe\u63a5\u5230\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5df2\u6709\u7684\u5b9e\u4f53, \u5c31\u53ef\u4ee5\u5efa\u7acb\u8d77\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb. \u5173\u7cfb\u540d\u5373\u57fa\u672c\u5c5e\u6027\u7684\u540d\u79f0. \u4f8b\u5982, \u5218\u5fb7\u534e\"\u4ee3\u8868\u4f5c\u54c1\"\u7684\u503c\u4e3a\"\u65e0\u95f4\u9053\"\u53ef\u4ee5\u94fe\u63a5\u5230\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\"\u65e0\u95f4\u9053(2002\u5e74\u5218\u4f1f\u5f3a\u6267\u5bfc\u7684\u7535\u5f71)\", \u7531\u6b64\u53ef\u4ee5\u5efa\u7acb\u8d77\"\u5218\u5fb7\u534e\"\u4e0e\u5b9e\u4f53\"\u65e0\u95f4\u9053(2002\u5e74\u5218\u4f1f\u5f3a\u6267\u5bfc\u7684\u7535\u5f71)\"\u4e4b\u95f4\u5173\u7cfb\u540d\u4e3a\"\u4ee3\u8868\u4f5c\u54c1\"\u7684\u5173\u7cfb. \u5173\u7cfb\u6784\u5efa\u7684\u6838\u5fc3\u64cd\u4f5c\u662f\u5c06\u5c5e\u6027\u503c\u94fe\u63a5\u5230\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53. \u6839\u636e\u5c5e\u6027\u503c\u662f\u5426\u5b58\u5728\u6307\u5411\u5176\u4ed6\u8bcd\u6761\u7684\u8d85\u94fe\u63a5, \u5206\u4e24\u79cd\u60c5\u5f62\u8fdb\u884c\u5904\u7406: \u5f53\u5c5e\u6027\u503c\u5b58\u5728\u6307\u5411\u5176\u4ed6\u8bcd\u6761\u7684\u8d85\u94fe\u63a5\u65f6, \u53ea\u9700\u89e3\u6790\u51fa\u8fd9\u4e2a\u8d85\u94fe\u63a5\u6240\u6307\u5411\u7684\u5b9e\u4f53. \u4f8b\u5982, \u5728\u5218\u5fb7\u534e\u7684\u767e\u79d1\u9875\u9762\u4e2d, \"\u65e0\u95f4\u9053\"\u5b58\u5728\u4e00\u4e2a\u8d85\u94fe\u63a5\u6307\u5411\"\u65e0\u95f4\u9053(2002\u5e74\u5218\u4f1f\u5f3a\u6267\u5bfc\u7684\u7535\u5f71)\"\u8fd9\u4e2a\u5b9e\u4f53\u9875\u9762, \u56e0\u6b64\u53ef\u4ee5\u76f4\u63a5\u5f97\u5230\u8be5\u5c5e\u6027\u503c\u5bf9\u5e94\u7684\u5b9e\u4f53. \u5f53\u5c5e\u6027\u503c\u4e0d\u5b58\u5728\u8d85\u94fe\u63a5\u65f6, \u9700\u8981\u7528\u5230\u5b9e\u4f53\u7684\u6307\u4ee3\u4fe1\u606f\u6765\u8fdb\u884c\u5b9e\u4f53\u94fe\u63a5. \u5982\u679c\u4e00\u4e2a\u5c5e\u6027\u503c\u4e0d\u662f\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u4efb\u4f55\u5b9e\u4f53\u7684\u6307\u4ee3, \u5219\u8ba4\u4e3a\u8be5\u5c5e\u6027\u503c\u4e0d\u80fd\u6307\u5411\u4efb\u4f55\u5b9e\u4f53. \u5982\u679c\u4e00\u4e2a\u5c5e\u6027\u503c\u662f\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u4e00\u4e2a\u6216\u591a\u4e2a\u5b9e\u4f53\u7684\u6307\u4ee3, \u5219\u9700\u8981\u4f7f\u7528\u5206\u7c7b\u5668\u6765\u8fdb\u884c\u5224\u65ad. \u5177\u4f53\u6765\u8bf4, \u5206\u7c7b\u5668\u7684\u8f93\u5165\u662f\u4e00\u4e2a(\u5b9e\u4f53, \u5c5e\u6027, \u5c5e\u6027\u503c)\u4e09\u5143\u7ec4\u548c\u4e0e\u8fd9\u4e2a\u5c5e\u6027\u503c\u5bf9\u5e94\u7684\u67d0\u4e2a\u5019\u9009\u5b9e\u4f53; \u8f93\u51fa\u662f0\u548c1\u4e4b\u95f4\u7684\u5b9e\u6570\u503c, \u8868\u793a\u8be5\u5c5e\u6027\u6307\u5411\u8fd9\u4e2a\u5019\u9009\u5b9e\u4f53\u7684\u6982\u7387. \u5206\u7c7b\u5668\u7684\u6027\u80fd\u53d6\u51b3\u4e8e\u7279\u5f81\u7684\u9009\u62e9, \u6bd4\u8f83\u6709\u6548\u7684\u7279\u5f81\u6709\u4e24\u4e2a: \u767e\u79d1\u4e2d\u5c5e\u6027\u503c\u94fe\u63a5\u5230\u5019\u9009\u5b9e\u4f53\u7684\u6b21\u6570. \u5728\u7ebf\u767e\u79d1\u4e2d\u5b58\u5728\u5927\u91cf\u7684\u8d85\u94fe\u63a5, \u5728\u951a\u6587\u672c\u4e3a\u5c5e\u6027\u503c\u7684\u6240\u6709\u8d85\u94fe\u63a5\u4e2d, \u94fe\u63a5\u6b21\u6570\u6700\u591a\u7684\u5019\u9009\u5b9e\u4f53\u6700\u6709\u53ef\u80fd\u662f\u5c5e\u6027\u503c\u6240\u8868\u8fbe\u7684\u771f\u5b9e\u5b9e\u4f53. \u53cd\u6307\u7279\u5f81. \u5728\u5019\u9009\u5b9e\u4f53\u7684\u9875\u9762\u4e2d, \u5982\u679c\u5b58\u5728\u8d85\u94fe\u63a5\u6307\u5411\u8be5\u5c5e\u6027\u503c\u7684\u4e3b\u4f53\u5b9e\u4f53, \u5219\u8bf4\u660e\u4e3b\u4f53\u5b9e\u4f53\u4e0e\u5019\u9009\u5b9e\u4f53\u5b58\u5728\u5173\u7cfb, \u8be5\u5c5e\u6027\u503c\u5f88\u53ef\u80fd\u6307\u5411\u8fd9\u4e2a\u5019\u9009\u5b9e\u4f53. \u6bd4\u5982, \u5218\u5fb7\u534e\u7684\u4ee3\u8868\u4f5c\u54c1\"\u65e0\u95f4\u9053\"\u53ef\u80fd\u5b58\u5728\u5f88\u591a\u5019\u9009\u5b9e\u4f53, \u5305\u62ec\u7535\u5f71, \u7535\u89c6\u5267, \u5c0f\u8bf4, \u6b4c\u66f2, \u4f46\u53ea\u6709\u5218\u5fb7\u534e(\u4e3b\u4f53\u5b9e\u4f53)\u6240\u51fa\u6f14\u7684\u7535\u5f71\u5b58\u5728\u8d85\u94fe\u63a5\u6307\u5411\u5218\u5fb7\u534e, \u56e0\u6b64\u5176\u662f\u5c5e\u6027\u503c\u6240\u6307\u7684\u5b9e\u4f53.","title":"\u5173\u7cfb\u6784\u5efa"},{"location":"6_2.html#_13","text":"\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u6784\u5efa\u4fbf\u4e8e\u5bf9\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\u8fdb\u884c\u7ec4\u7ec7\u548c\u7ba1\u7406, \u76ee\u524d\u4e3b\u8981\u5305\u62ec\u4eba\u5de5\u6784\u5efa\u548c\u534a\u81ea\u52a8\u6784\u5efa\u4e24\u79cd\u65b9\u5f0f: \u4eba\u5de5\u6784\u5efa\u7684\u5178\u578b\u4ee3\u8868\u662fDBPedia, \u5b83\u901a\u8fc7\u4f17\u5305\u7684\u65b9\u5f0f\u5c06\u6765\u81ea\u7ef4\u57fa\u767e\u79d1\u6570\u636e\u6e90\u7684\u6240\u6709\u5b9e\u4f53\u7528320\u4e2a\u6982\u5ff5\u8fdb\u884c\u6709\u6548\u7ec4\u7ec7, \u5176\u4e2d\u6982\u5ff5\u4e4b\u95f4\u901a\u8fc7\u7c7b\u5c5e(subclassOf)\u5173\u7cfb\u8fdb\u884c\u8fde\u63a5, \u6784\u6210\u4e00\u4e2a\u6700\u5927\u6df1\u5ea6\u4e3a5\u7684\u6982\u5ff5\u5c42\u7ea7\u7ed3\u6784. \u534a\u81ea\u52a8\u6784\u5efa\u7684\u5178\u578b\u4ee3\u8868\u4e3aYAGO, \u5b83\u7684\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u7531\u4e13\u5bb6\u6784\u5efa\u7684\u5c42\u7ea7\u4f53\u7cfb(WordNet)\u548c\u7528\u6237\u4f17\u5305\u6784\u5efa\u7684\u6807\u7b7e\u4f53\u7cfb(\u7ef4\u57fa\u767e\u79d1\u6807\u7b7e\u4f53\u7cfb)\u4e24\u90e8\u5206\u7ec4\u6210, \u6ce8\u610f: \u767e\u79d1\u56fe\u8c31\u5bf9\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u7684\u8d28\u91cf\u8981\u6c42\u8f83\u9ad8, \u4e00\u822c\u4e0d\u91c7\u7528\u5168\u81ea\u52a8\u7684\u65b9\u5f0f\u6784\u5efa.","title":"\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u6784\u5efa"},{"location":"6_2.html#_14","text":"\u5b9e\u4f53\u5206\u7c7b\u7684\u76ee\u6807\u662f\u5c06\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\u5206\u7c7b\u5230\u4e00\u7ec4\u9884\u5b9a\u4e49\u7684\u6982\u5ff5\u96c6\u5408\u4e2d, \u8fd9\u7ec4\u9884\u5b9a\u4e49\u7684\u6982\u5ff5\u96c6\u5408\u6765\u81ea\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb. \u5b9e\u4f53\u5206\u7c7b\u548cNER\u4efb\u52a1\u4e0d\u540c: NER: \u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7684\u7814\u7a76\u5bf9\u8c61\u662f\u53e5\u5b50\u4e2d\u7684\u5b9e\u4f53\u6307\u4ee3, \u5206\u7c7b\u4f9d\u636e\u4ec5\u6765\u81ea\u53e5\u5b50\u7684\u4e0a\u4e0b\u6587\u6587\u672c\u4fe1\u606f. \u5b9e\u4f53\u5206\u7c7b: \u5b9e\u4f53\u5206\u7c7b\u7684\u7814\u7a76\u5bf9\u8c61\u662f\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53, \u5206\u7c7b\u4f9d\u636e\u6765\u81ea\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5168\u90e8\u6570\u636e(\u5305\u62ec\u7ed3\u6784\u5316\u6570\u636e\u548c\u975e\u7ed3\u6784\u5316\u6587\u672c). \u5b9e\u4f53\u5206\u7c7b\u7684\u65b9\u6cd5\u4e3b\u8981\u6709\u4e09\u79cd: \u4eba\u5de5\u65b9\u6cd5 \u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5 \u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5","title":"\u5b9e\u4f53\u5206\u7c7b"},{"location":"6_2.html#_15","text":"\u57fa\u4e8e\u4eba\u5de5\u7684\u5b9e\u4f53\u5206\u7c7b\u65b9\u6cd5\u501f\u52a9\u9886\u57df\u4e13\u5bb6\u548c\u5e7f\u5927\u5fd7\u613f\u8005\u5bf9\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\u8fdb\u884c\u7c7b\u522b\u6807\u6ce8. \u65e9\u671f\u7684\u8bed\u4e49\u7f51\u7edc\u89c4\u6a21\u4e0d\u5927, \u5b9e\u4f53\u6570\u91cf\u4e0d\u591a, \u5f80\u5f80\u7531\u9886\u57df\u4e13\u5bb6\u76f4\u63a5\u6807\u6ce8. \u968f\u7740\u77e5\u8bc6\u56fe\u8c31\u7684\u5b9e\u4f53\u89c4\u6a21\u4e0d\u65ad\u6269\u5927, \u4eba\u5de5\u65b9\u5f0f\u9010\u6e10\u7531\u4e13\u5bb6\u6784\u5efa\u8f6c\u4e3a\u7531\u5e7f\u5927\u5fd7\u613f\u8005\u5171\u540c\u534f\u4f5c\u6784\u5efa, \u4e0d\u540c\u7684\u573a\u666f\u4e0b\u4eba\u5de5\u53c2\u4e0e\u7684\u7a0b\u5ea6\u4e0d\u540c. \u4f8b\u5982, \u7ef4\u57fa\u767e\u79d1\u4e2d\u7684\u5fd7\u613f\u8005\u9700\u8981\u4e3a\u6bcf\u4e2a\u8bcd\u6761\u6309\u7167\u6807\u7b7e\u7cfb\u7edf\u4e2d\u7684\u6807\u7b7e\u8fdb\u884c\u5206\u7c7b, \u800cDBPedia\u7684\u5fd7\u613f\u8005\u5229\u7528\u7ef4\u57fa\u767e\u79d1\u7684Infobox\u6a21\u677f\u6765\u8fdb\u884c\u6279\u91cf\u4eba\u5de5\u6807\u6ce8. \u7ef4\u57fa\u767e\u79d1\u7684Infobox\u7c7b\u4f3c\u4e8e\u767e\u5ea6\u767e\u79d1\u4e2d\u7684\u57fa\u672c\u4fe1\u606f\u8868\u683c, \u4e3a\u4e86\u65b9\u4fbf\u7528\u6237\u6dfb\u52a0\u4fe1\u606f, \u7ef4\u57fa\u767e\u79d1\u4e3a\u4e0d\u540c\u7c7b\u578b\u7684\u5b9e\u4f53\u8bbe\u8ba1\u4e86\u4e0d\u540c\u7684Infobox\u6a21\u677f, \u6bcf\u4e2aInfobox\u6a21\u677f\u63cf\u8ff0\u4e86\u8be5\u7c7b\u5b9e\u4f53\u7684\u57fa\u672c\u5c5e\u6027. \u4f8b\u5982, \"\u7535\u5f71\"\u7c7b\u578b\u8bcd\u6761\u7684Infobox\u6a21\u677f\u4f1a\u5305\u62ec\"\u5bfc\u6f14\", \"\u6f14\u5458\", \"\u4e0a\u6620\u65f6\u95f4\"\u7b49\u5c5e\u6027.","title":"\u4eba\u5de5\u65b9\u6cd5"},{"location":"6_2.html#_16","text":"\u57fa\u4e8e\u89c4\u5219\u7684\u5b9e\u4f53\u5206\u7c7b\u65b9\u6cd5\u4f7f\u7528\u4e00\u7ec4IF-THEN\u89c4\u5219\u6765\u5bf9\u5b9e\u4f53\u8fdb\u884c\u5206\u7c7b. \u901a\u7528\u7684\u63a8\u7406\u89c4\u5219 \u542f\u53d1\u5f0f\u7684\u63a8\u7406\u89c4\u5219 \u901a\u7528\u7684\u63a8\u7406\u89c4\u5219: \u6307\u90a3\u4e9b\u80fd\u9002\u7528\u4e8e\u5168\u90e8\u6982\u5ff5\u7684\u5b9e\u4f53\u5206\u7c7b\u89c4\u5219, \u5305\u62ec\u57fa\u4e8e\u7b49\u4ef7\u5b9e\u4f53\u5173\u7cfb\u548c\u57fa\u4e8e\u6982\u5ff5\u5b50\u7c7b\u5173\u7cfb\u7684\u63a8\u7406\u89c4\u5219. \u57fa\u4e8e\u7b49\u4ef7\u5b9e\u4f53\u5173\u7cfb\u7684\u63a8\u7406: # \u5177\u4f53\u542b\u4e49: \u5982\u679c\u5b9e\u4f53e1\u5c5e\u4e8e\u67d0\u4e00\u6982\u5ff5c, \u5e76\u4e14\u5b9e\u4f53e1\u548c\u5b9e\u4f53e2\u7b49\u4ef7, \u5219\u53ef\u4ee5\u63a8\u7406\u51fa\u5b9e\u4f53e2\u4e5f\u5c5e\u4e8e\u6982\u5ff5c (e1 \u2208 c) and (e1 = e2) => (e2 \u2208 c) \u4f8b\u5982: \"\u5218\u5fb7\u534e\"\u548c\"Andy Lau\"\u662f\u5df2\u7ecf\u5efa\u7acb\u8d77\u767e\u5ea6\u767e\u79d1\u4e2d\u6587\u5b9e\u4f53\u4e0eDBPedia\u82f1\u6587\u5b9e\u4f53\u4e4b\u95f4\u7684\u7b49\u4ef7\u5173\u7cfb, \u8fdb\u800c\u5c31\u53ef\u4ee5\u5f97\u5230\u90e8\u5206\u4e2d\u6587\u5b9e\u4f53\u7684\u82f1\u6587\u5206\u7c7b, \"\u5218\u5fb7\u534e\"\u7684\u82f1\u6587\u7c7b\u522b\u5c31\u5305\u62ecPerson, Actor, Singer\u7b49. \u57fa\u4e8e\u6982\u5ff5\u5b50\u7c7b\u5173\u7cfb\u7684\u63a8\u7406: # \u5177\u4f53\u542b\u4e49: \u5982\u679c\u5b9e\u4f53e\u5c5e\u4e8e\u6982\u5ff5c1, \u5e76\u4e14\u6982\u5ff5c1\u662f\u6982\u5ff5c2\u7684\u5b50\u7c7b, \u5219\u53ef\u4ee5\u63a8\u7406\u51fa\u5b9e\u4f53e\u4e5f\u5c5e\u4e8e\u6982\u5ff5c2 (e \u2208 c1) and (c1 \u2208 c2) => (e \u2208 c2) \u6ce8\u610f: YAGO\u5c31\u662f\u901a\u8fc7\u8fd9\u79cd\u89c4\u5219\u5c06\u7ef4\u57fa\u767e\u79d1\u4e2d\u7684\u5b9e\u4f53\u5206\u7c7b\u5230WordNet\u7684\u6982\u5ff5\u96c6\u5408\u4e2d\u7684. \u542f\u53d1\u5f0f\u7684\u63a8\u7406\u89c4\u5219: \u4ec5\u9002\u7528\u4e8e\u90e8\u5206\u6982\u5ff5, \u5305\u62ec\u57fa\u4e8e\u5b9e\u4f53\u540d\u79f0, \u57fa\u4e8e\u5c5e\u6027\u548c\u57fa\u4e8e\u5c5e\u6027\u503c\u7684\u63a8\u7406\u89c4\u5219. \u57fa\u4e8e\u5b9e\u4f53\u540d\u79f0\u7684\u63a8\u7406: \u5b9e\u4f53\u540d\u79f0\u540e\u7f00\u4e3a\"\u533b\u9662\", \"\u5927\u5b66\"\u7684\u5f88\u53ef\u80fd\u5206\u522b\u5c5e\u4e8e\u6982\u5ff5\"\u533b\u9662\"\u548c\"\u5927\u5b66\". \u57fa\u4e8e\u5c5e\u6027\u7684\u63a8\u7406: \u5b9e\u4f53\u5305\u542b\u5c5e\u6027\"\u6027\u522b\"\u7684, \u5f88\u53ef\u80fd\u5c5e\u4e8e\u6982\u5ff5\"\u4eba\u7269\". \u57fa\u4e8e\u5c5e\u6027\u503c\u7684\u63a8\u7406: \u5982\u679c\u5b9e\u4f53\u5305\u542b\u5c5e\u6027\u503c\u5bf9(\u804c\u4e1a, \u6f14\u5458), \u5f88\u53ef\u80fd\u5c5e\u4e8e\u6982\u5ff5\"\u6f14\u5458\".","title":"\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5"},{"location":"6_2.html#_17","text":"\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u5b9e\u4f53\u5206\u7c7b\u65b9\u6cd5\u5f80\u5f80\u5c06\u5b9e\u4f53\u5206\u7c7b\u95ee\u9898\u5efa\u6a21\u4e3a\u4e00\u4e2a\u591a\u6807\u7b7e\u5206\u7c7b\u95ee\u9898(Multi-label Classification). \u6bcf\u4e2a\u6807\u8bb0\u7c7b\u4ee3\u8868\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u4e00\u4e2a\u6982\u5ff5, \u4e00\u4e2a\u5b9e\u4f53\u53ef\u4ee5\u5c5e\u4e8e\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u591a\u4e2a\u6982\u5ff5. \u5de5\u4e1a\u754c\u7684\u4e3b\u6d41\u65b9\u6cd5\u662f\u57fa\u4e8e\u76d1\u7763\u5b66\u4e60\u7684\u65b9\u6cd5, \u7f3a\u70b9\u662f\u8fd9\u7c7b\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u7684\u6709\u6807\u7b7e\u7684\u8bad\u7ec3\u6837\u672c. \u7279\u5f81\u8868\u793a: \u79bb\u6563\u5316\u7279\u5f81, \u5d4c\u5165\u5f0f\u7279\u5f81. \u5206\u7c7b\u6a21\u578b: \u903b\u8f91\u56de\u5f52, \u51b3\u7b56\u6811, LSTM, BERT.","title":"\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5"},{"location":"6_2.html#_18","text":"\u73b0\u5b9e\u4e2d\u9664\u4e86\u524d\u9762\u4ecb\u7ecd\u7684\u5355\u6e90\u7684\u767e\u79d1\u56fe\u8c31\u7684\u6784\u5efa, \u8fd8\u6709\u901a\u8fc7\u591a\u4e2a\u4e0d\u540c\u6570\u636e\u6e90\u6765\u6784\u5efa\u66f4\u5b8c\u6574, \u66f4\u51c6\u786e\u7684\u767e\u79d1\u56fe\u8c31\u7684\u65b9\u6cd5. \u672c\u8d28\u4e0a, \u9996\u5148\u6839\u636e\u6bcf\u4e2a\u6570\u636e\u6e90\u5355\u72ec\u6784\u5efa\u4e00\u4e2a\u77e5\u8bc6\u56fe\u8c31, \u518d\u5c06\u8fd9\u4e9b\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u878d\u5408. \u5177\u4f53\u6784\u5efa\u5206\u4e3a4\u4e2a\u8fc7\u7a0b: \u6982\u5ff5\u878d\u5408 \u5b9e\u4f53\u5bf9\u9f50 \u5c5e\u6027\u5bf9\u9f50 \u5c5e\u6027\u503c\u878d\u5408","title":"\u57fa\u4e8e\u591a\u6e90\u7684\u767e\u79d1\u56fe\u8c31\u878d\u5408"},{"location":"6_2.html#_19","text":"\u4e0d\u540c\u77e5\u8bc6\u56fe\u8c31\u7684\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u5404\u4e0d\u76f8\u540c, \u800c\u878d\u5408\u540e\u7684\u77e5\u8bc6\u56fe\u8c31\u53ea\u80fd\u6709\u4e00\u4e2a\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb. \u6982\u5ff5\u878d\u5408\u7684\u5173\u952e\u662f\u627e\u7b49\u4ef7\u5173\u7cfb. \u7531\u4e8e\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u975e\u5e38\u91cd\u8981\u5e76\u4e14\u89c4\u6a21\u53ef\u63a7, \u76ee\u524d\u4e3b\u6d41\u7684\u7cfb\u7edf\u4e3b\u8981\u91c7\u7528\u4eba\u5de5\u65b9\u6cd5\u8fdb\u884c\u5339\u914d\u4ee5\u4fdd\u8bc1\u878d\u5408\u7684\u8d28\u91cf. \u4f8b\u5982, DBPedia\u901a\u8fc7\u4f17\u5305\u7684\u65b9\u5f0f\u4e3a\u4e0d\u540c\u8bed\u79cd\u7684\u77e5\u8bc6\u56fe\u8c31\u4e0a\u7684\u6982\u5ff5\u5efa\u7acb\u7b49\u4ef7\u5173\u7cfb, \u5982\u82f1\u6587\u6982\u5ff5\"Book\"\u548c\u5e0c\u814a\u6587\u6982\u5ff5\"Bi\u03b2\u03b3io\". \u4e0d\u540c\u77e5\u8bc6\u56fe\u8c31\u7684\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u9664\u4e86\u5305\u542b\u7b49\u4ef7\u6982\u5ff5\u5916, \u8fd8\u5305\u542b\u5404\u81ea\u56fe\u8c31\u7279\u6709\u7684\u6982\u5ff5. \u4f8b\u5982, \"\u7384\u5e7b\u5c0f\u8bf4\"\u53ea\u5728\u4e2d\u6587\u6982\u5ff5\u4e2d\u51fa\u73b0, \u800c\u4e0d\u4f1a\u5728\u5176\u4ed6\u8bed\u8a00\u7684\u6982\u5ff5\u96c6\u5408\u4e2d\u51fa\u73b0. \u6709\u4e24\u79cd\u878d\u5408\u7b56\u7565\u5904\u7406\u4e0a\u8ff0\u60c5\u5f62: 1: \u4ee5DBPedia\u4e3a\u4ee3\u8868, \u53ea\u4ee5\u5176\u4e2d\u7684\u4e00\u4e2a\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u4e3a\u4e3b, \u53e6\u4e00\u4e2a\u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u4e2d\u7279\u6709\u7684\u6982\u5ff5\u5c06\u88ab\u8fc7\u6ee4\u6389. 2: \u4ee5XLORE\u4e3a\u4ee3\u8868, \u4fdd\u7559\u6240\u6709\u7684\u6982\u5ff5, \u53ea\u5c06\u7b49\u4ef7\u7684\u6982\u5ff5\u5408\u5e76.","title":"\u6982\u5ff5\u878d\u5408"},{"location":"6_2.html#_20","text":"\u5b9e\u4f53\u5bf9\u9f50\u662f\u77e5\u8bc6\u56fe\u8c31\u878d\u5408\u7684\u6700\u5173\u952e\u6b65\u9aa4, \u5b83\u51b3\u5b9a\u4e86\u77e5\u8bc6\u56fe\u8c31\u4e4b\u95f4\u662f\u5426\u80fd\u591f\u878d\u5408. \u5b9e\u4f53\u5bf9\u9f50\u7684\u4e3b\u8981\u4efb\u52a1\u4efb\u52a1\u662f\u5224\u65ad\u6765\u81ea\u4e24\u4e2a\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\u662f\u5426\u7b49\u4ef7, \u5bf9\u9f50\u7684\u65b9\u6cd5\u4e3b\u8981\u5206\u4e3a\u56db\u4e2a\u6b65\u9aa4: \u6570\u636e\u9884\u5904\u7406 \u5206\u5757 \u6210\u5bf9\u5bf9\u9f50 \u96c6\u4f53\u5bf9\u9f50","title":"\u5b9e\u4f53\u5bf9\u9f50"},{"location":"6_2.html#_21","text":"\u6570\u636e\u9884\u5904\u7406\u7684\u76ee\u6807\u662f\u89e3\u51b3\u5b9e\u4f53\u547d\u540d\u4e0d\u7edf\u4e00\u7684\u95ee\u9898, \u4e3b\u8981\u65b9\u6cd5\u5305\u62ec: \u53bb\u9664\u5b9e\u4f53\u540d\u79f0\u4e0a\u7684\u6807\u70b9\u7b26\u53f7 \u8fdb\u884c\u540c\u4e49\u8bcd\u6269\u5c55","title":"\u6570\u636e\u9884\u5904\u7406"},{"location":"6_2.html#_22","text":"\u5206\u5757\u7684\u76ee\u6807\u662f\u51cf\u5c11\u9700\u8981\u4e24\u4e24\u6bd4\u5bf9\u7684\u5b9e\u4f53\u5bf9\u7684\u6570\u91cf. \u5177\u4f53\u505a\u6cd5\u662f\u6839\u636e\u4e00\u4e9b\u542f\u53d1\u5f0f\u7b56\u7565, \u5c06\u4e24\u4e2a\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u76f8\u4f3c\u5b9e\u4f53\u5206\u914d\u5230\u76f8\u540c\u7684\u533a\u5757\u4e2d. \u5728\u8fdb\u884c\u5b9e\u4f53\u5bf9\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u65f6, \u53ea\u9700\u8981\u8ba1\u7b97\u76f8\u540c\u533a\u5757\u4e2d\u7684\u5b9e\u4f53\u5bf9\u5373\u53ef. \u4f8b\u5982: \u53ef\u4ee5\u6839\u636e\u5b9e\u4f53\u7684\u6982\u5ff5\u8fdb\u884c\u5206\u5757, \u53ea\u6709\u5c5e\u4e8e\u540c\u4e00\u6982\u5ff5\u5206\u5757\u4e2d\u7684\u5b9e\u4f53\u624d\u53ef\u80fd\u5f7c\u6b64\u5bf9\u9f50. \u6bd4\u5982, \"\u4eba\u7269\"\u548c\"\u5efa\u7b51\"\u4e24\u4e2a\u6982\u5ff5\u5206\u5757\u4e2d\u7684\u5b9e\u4f53\u662f\u4e0d\u53ef\u80fd\u7b49\u4ef7\u7684. \u5b9e\u4f53\u5bf9\u9f50\u7684\u65b9\u6cd5\u53c8\u5206\u4e3a\u4e24\u79cd: \u6210\u5bf9\u5bf9\u9f50: \u53ea\u6839\u636e\u4e00\u4e2a\u5b9e\u4f53\u5bf9\u4e2d\u7684\u4e24\u4e2a\u5b9e\u4f53\u672c\u8eab\u7684\u4fe1\u606f\u8fdb\u884c\u5339\u914d. \u96c6\u4f53\u5bf9\u9f50: \u4f1a\u8003\u8651\u6574\u4e2a\u77e5\u8bc6\u56fe\u8c31\u7684\u4fe1\u606f\u8fdb\u884c\u5339\u914d.","title":"\u5206\u5757"},{"location":"6_2.html#_23","text":"\u6210\u5bf9\u5b9e\u4f53\u7684\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u4e3b\u8981\u6709\u4e24\u7c7b\u65b9\u6cd5: \u65e0\u76d1\u7763\u5b66\u4e60: 1: \u6839\u636e\u73b0\u6709\u7684\u77e5\u8bc6\u5f97\u5230\u7b49\u4ef7\u5173\u7cfb\u8fdb\u884c\u5224\u65ad, \u5982DBPedia\u901a\u8fc7\u7ef4\u57fa\u767e\u79d1\u4e2d\u7684\u5b9e\u4f53\u7684\u591a\u8bed\u8a00\u7248\u672c\u4fe1\u606f, \u5f97\u5230\u4e0d\u540c\u8bed\u8a00\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\u7684\u7b49\u4ef7\u5173\u7cfb. 2: \u6839\u636e\u5b9e\u4f53\u540d\u79f0\u7684\u76f8\u4f3c\u5ea6\u8fdb\u884c\u5224\u65ad, \u76f8\u4f3c\u5ea6\u8ba1\u7b97\u7684\u65b9\u6cd5\u5305\u62ecJaccard\u7cfb\u6570, \u7f16\u8f91\u8ddd\u79bb\u7b49. \u76f8\u4f3c\u5ea6\u5927\u4e8e\u67d0\u4e2a\u9608\u503c\u5373\u8ba4\u4e3a\u7b49\u4ef7, \u53cd\u4e4b\u5219\u8ba4\u4e3a\u4e0d\u7b49\u4ef7. 3: \u6839\u636e\u5b9e\u4f53\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u8fdb\u884c\u5224\u65ad, \u5982\u540c\u4e49\u5173\u7cfb\u6216\u6982\u5ff5\u76f8\u8fd1\u7b49. \u6709\u76d1\u7763\u5b66\u4e60: \u5373\u6784\u5efa\u4e8c\u5206\u7c7b\u6a21\u578b, \u5224\u65ad\u6765\u81ea\u4e24\u4e2a\u4e0d\u540c\u77e5\u8bc6\u56fe\u8c31\u7684\u5b9e\u4f53\u662f\u5426\u7b49\u4ef7. \u8fd9\u7c7b\u65b9\u6cd5\u7684\u57fa\u672c\u601d\u8def\u662f\u5229\u7528\u5df2\u6709\u7684\u90e8\u5206\u77e5\u8bc6\u56fe\u8c31\u95f4\u7684\u7b49\u4ef7\u5b9e\u4f53\u4f5c\u4e3a\u8bad\u7ec3\u96c6, \u518d\u901a\u8fc7\u4e8c\u5206\u7c7b\u6a21\u578b\u5f97\u5230\u66f4\u591a\u7684\u7b49\u4ef7\u5173\u7cfb. \u5176\u4e2d\u7684\u7279\u5f81\u5f80\u5f80\u901a\u8fc7\u4eba\u5de5\u65b9\u5f0f\u5b9a\u4e49, \u6765\u81ea\u5b9e\u4f53\u7684\u540d\u79f0, \u6b63\u6587, \u76f8\u5173\u5b9e\u4f53, \u6807\u7b7e, Infobox\u7b49\u4fe1\u606f.","title":"\u6210\u5bf9\u5bf9\u9f50"},{"location":"6_2.html#_24","text":"\u96c6\u4f53\u5bf9\u9f50\u4f1a\u628a\u5b9e\u4f53\u6240\u5728\u7684\u56fe\u8c31\u7684\u4fe1\u606f\u4e5f\u8003\u8651\u8fdb\u6765, \u53ef\u4ee5\u7ec6\u5206\u4e3a\u4e24\u7c7b: \u5c40\u90e8\u96c6\u4f53\u5bf9\u9f50 \u5168\u5c40\u96c6\u4f53\u5bf9\u9f50 \u5c40\u90e8\u96c6\u4f53\u5bf9\u9f50: \u8981\u5339\u914d\u4e24\u4e2a\u5b9e\u4f53, \u4e0d\u4ec5\u8981\u8003\u8651\u4e24\u4e2a\u5b9e\u4f53\u672c\u8eab\u7684\u76f8\u4f3c\u5ea6, \u8fd8\u8981\u8003\u8651\u4e24\u4e2a\u5b9e\u4f53\u7684\u90bb\u5c45\u8282\u70b9\u7684\u76f8\u4f3c\u5ea6. # \u5177\u4f53\u542b\u4e49: sim_attr(e1,e2)\u662f\u5b9e\u4f53\u5bf9\u672c\u8eab\u7684\u76f8\u4f3c\u5ea6, sim_NB(e1,e2)\u662f\u5b9e\u4f53\u7684\u90bb\u5c45\u8282\u70b9\u7684\u76f8\u4f3c\u5ea6. sim(e1,e2) = \u03b1 * sim_attr(e1,e2) + (1 - \u03b1) * sim_NB(e1,e2) \u5168\u5c40\u96c6\u4f53\u5bf9\u9f50: \u4ece\u5168\u5c40\u7684\u89d2\u5ea6\u6765\u8ba1\u7b97\u6240\u6709\u5b9e\u4f53\u7684\u5339\u914d\u5173\u7cfb, \u4e3b\u8981\u6709\u4e24\u79cd\u65b9\u6cd5: \u57fa\u4e8e\u76f8\u4f3c\u5ea6\u4f20\u64ad\u7684\u65b9\u6cd5: \u57fa\u672c\u601d\u8def\u662f\u57fa\u4e8e\u521d\u59cb\u5339\u914d\u901a\u8fc7\u8fed\u4ee3\u8ba1\u7b97\u4ea7\u751f\u65b0\u7684\u5339\u914d. \u57fa\u4e8e\u6982\u7387\u6a21\u578b\u7684\u65b9\u6cd5: \u57fa\u672c\u601d\u8def\u662f\u5c06\u5168\u5c40\u5b9e\u4f53\u5339\u914d\u7684\u6982\u7387\u6700\u5927\u5316, \u5e38\u7528\u7684\u65b9\u6cd5\u5305\u62ec\u8d1d\u53f6\u65af\u7f51\u7edc, LDA, \u6761\u4ef6\u968f\u673a\u573a, \u9a6c\u5c14\u53ef\u592b\u7f51\u7edc\u7b49.","title":"\u96c6\u4f53\u5bf9\u9f50"},{"location":"6_2.html#_25","text":"\u5c5e\u6027\u5bf9\u9f50\u662f\u6307\u5c06\u4e0d\u540c\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u7b49\u4ef7\u5c5e\u6027\u5408\u5e76\u4e3a\u540c\u4e00\u4e2a\u5c5e\u6027. \u7531\u4e8e\u591a\u6570\u636e\u6e90\u4e2d\u5b58\u5728\u7740\u5927\u91cf\u7684\u7b49\u4ef7\u5b9e\u4f53, \u8fd8\u53ef\u4ee5\u5145\u5206\u5229\u7528\u4e00\u4e9b\u7edf\u8ba1\u4fe1\u606f\u6765\u5bf9\u9f50\u5c5e\u6027. \u4e00\u4e2a\u5e38\u7528\u7684\u7edf\u8ba1\u4fe1\u606f\u662f\u5c5e\u6027\u5bf9\u5e94\u7684\"\u5b9e\u4f53-\u5c5e\u6027\u503c\"\u96c6\u5408\u7684\u91cd\u53e0\u7a0b\u5ea6, \u4e3e\u4f8b\u5982\u4e0b: \u77e5\u8bc6\u56fe\u8c31 \u5b9e\u4f53 \u5c5e\u6027 \u5c5e\u6027\u503c K1 AAA \u51fa\u751f\u65e5\u671f 1988-09-01 K1 BBB \u51fa\u751f\u65e5\u671f 1996-06-11 K1 CCC \u51fa\u751f\u65e5\u671f 1995-11-22 K1 DDD \u51fa\u751f\u65e5\u671f 1999-08-18 \u77e5\u8bc6\u56fe\u8c31 \u5b9e\u4f53 \u5c5e\u6027 \u5c5e\u6027\u503c K2 AAA \u751f\u65e5 1988-09-01 K2 BBB \u751f\u65e5 1996-06-11 K2 CCC \u751f\u65e5 1995-11-22 K2 DDD \u751f\u65e5 1999-08-18 \u7ed3\u8bba: \u4e0a\u9762\u4e24\u4e2a\u56fe\u8c31K1, K2, \u901a\u8fc7Jaccard\u7cfb\u6570\u8ba1\u7b97\u51fa\u4e24\u4e2a\u5c5e\u6027\u7684\"\u5b9e\u4f53-\u5c5e\u6027\u503c\"\u96c6\u5408\u7684\u91cd\u53e0\u7a0b\u5ea6\u662f100%, \u56e0\u6b64\u53ef\u4ee5\u63a8\u65ad\u51fa\u8fd9\u4e24\u4e2a\u5c5e\u6027(\"\u51fa\u751f\u65e5\u671f\"\u548c\"\u751f\u65e5\")\u662f\u7b49\u4ef7\u7684!!!","title":"\u5c5e\u6027\u5bf9\u9f50"},{"location":"6_2.html#_26","text":"\u5728\u5bf9\u9f50\u5c5e\u6027\u540e, \u9700\u8981\u5bf9\u6765\u81ea\u4e0d\u540c\u77e5\u8bc6\u56fe\u8c31\u7684\u540c\u4e00\u5b9e\u4f53\u7684\u540c\u4e00\u5c5e\u6027\u7684\u5c5e\u6027\u503c\u8fdb\u884c\u5408\u5e76. \u5c5e\u6027\u503c\u878d\u5408\u7684\u4efb\u52a1\u5305\u62ec\u5220\u9664\u91cd\u590d\u77e5\u8bc6\u548c\u53bb\u9664\u9519\u8bef\u77e5\u8bc6. \u5220\u9664\u91cd\u590d\u77e5\u8bc6: \u6700\u9700\u8981\u89e3\u51b3\u7684\u95ee\u9898\u662f\u5c5e\u6027\u503c\u7684\u89c4\u8303\u5316, \u6bd4\u5982\u6570\u503c\u7c7b\u578b\u7684\u5c5e\u6027\u503c\u4f7f\u7528\u540c\u4e00\u4e2a\u6807\u51c6\u6765\u8868\u793a, \u5305\u62ec\u5355\u4f4d\u7edf\u4e00, \u65e5\u671f\u7edf\u4e00\u7b49. \u5982\u679c\u5c5e\u6027\u503c\u5bf9\u5e94\u4e00\u4e2a\u5b9e\u4f53\u4e14\u8be5\u5b9e\u4f53\u5b58\u5728\u591a\u4e2a\u540d\u79f0, \u5219\u4f7f\u7528\u7edf\u4e00\u7684\u5b9e\u4f53\u540d\u79f0\u8868\u793a. \u53bb\u9664\u9519\u8bef\u77e5\u8bc6: \u4e3b\u8981\u662f\u5229\u7528\u4e0d\u540c\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5df2\u77e5\u77e5\u8bc6\u6765\u5b9e\u73b0\u7684. \u6839\u636e\u5c5e\u6027\u662f\u5355\u503c\u8fd8\u662f\u591a\u503c\u7684, \u53ef\u4ee5\u5206\u4e3a\u5355\u503c\u5c5e\u6027\u878d\u5408\u548c\u591a\u503c\u5c5e\u6027\u878d\u5408. \u5355\u503c\u5c5e\u6027\u53ea\u6709\u552f\u4e00\u7684\u5c5e\u6027\u503c, \u6839\u636e\u8fd9\u4e00\u6027\u8d28, \u53ef\u4ee5\u5229\u7528\u6295\u7968\u673a\u5236\u5f97\u5230\u6700\u53ef\u80fd\u7684\u7ed3\u679c. \u6bcf\u4e2a\u77e5\u8bc6\u56fe\u8c31\u90fd\u5b58\u5728\u5927\u91cf\u7684(\u5b9e\u4f53, \u5c5e\u6027, \u5c5e\u6027\u503c)\u4e09\u5143\u7ec4, \u53ef\u4ee5\u4e3a\u591a\u4e2a\u5bf9\u8c61\u63d0\u4f9b\u5c5e\u6027\u503c. \u8fd9\u4e9b\u4e09\u5143\u7ec4\u7684\u5e73\u5747\u51c6\u786e\u7387\u51b3\u5b9a\u4e86\u77e5\u8bc6\u56fe\u8c31\u7684\u8d28\u91cf, \u540c\u7406\u77e5\u8bc6\u56fe\u8c31\u7684\u8d28\u91cf\u4e5f\u53ef\u4ee5\u7528\u6765\u4f30\u8ba1\u4e09\u5143\u7ec4\u7684\u51c6\u786e\u7387. \u5f53\u4e00\u4e2a\u5bf9\u8c61\u5b58\u5728\u591a\u4e2a\u5c5e\u6027\u503c\u65f6, \u5982\u679c\u5927\u591a\u6570\u9ad8\u8d28\u91cf\u7684\u77e5\u8bc6\u56fe\u8c31\u90fd\u652f\u6301\u5176\u4e2d\u67d0\u4e00\u4e2a\u5c5e\u6027\u503c, \u90a3\u4e48\u8fd9\u4e2a\u5c5e\u6027\u503c\u5f88\u6709\u53ef\u80fd\u5c31\u662f\u8fd9\u4e2a\u5bf9\u8c61\u7684\u771f\u503c. \u4f8b\u5982: \u76ee\u524d\u603b\u5171\u67094\u4e2a\u77e5\u8bc6\u56fe\u8c31\u9700\u8981\u878d\u5408, \u5176\u4e2d3\u4e2a\u62e5\u6709(\u5218\u5fb7\u534e, \u8eab\u9ad8, 174cm), \u53e6\u5916\u4e00\u4e2a\u62e5\u6709(\u5218\u5fb7\u534e, \u8eab\u9ad8, 173cm), \u5219\u53ef\u4ee5\u8ba4\u4e3a\u524d\u9762\u7684\u4fe1\u606f\u662f\u771f\u5b9e\u4fe1\u606f. \u9664\u4e86\u4e0a\u8ff0\u65b9\u6cd5, \u5bf9\u4e8e\u591a\u503c\u5c5e\u6027\u7684\u60c5\u51b5, \u53ef\u4ee5\u8003\u8651\u591a\u7b56\u7565\u878d\u5408\u7684\u65b9\u6cd5: 1: \u76f4\u63a5\u5408\u5e76\u7b56\u7565, \u8be5\u7b56\u7565\u8ba4\u4e3a\u6240\u6709\u5c5e\u6027\u503c\u90fd\u662f\u6b63\u786e\u7684, \u76f4\u63a5\u5408\u5e76\u6240\u6709\u7ed3\u679c\u5373\u53ef. 2: \u6295\u7968\u7b56\u7565, \u5305\u62ec\u591a\u6570\u6295\u7968, \u4e00\u81f4\u6027\u6295\u7968, \u52a0\u6743\u6295\u7968. 2.1: \u591a\u6570\u6295\u7968, \u53ea\u6709\u5f53\u8d85\u8fc7\u534a\u6570\u7684\u77e5\u8bc6\u56fe\u8c31\u90fd\u5305\u542b\u8be5\u5c5e\u6027\u503c\u65f6, \u624d\u8ba4\u4e3a\u8fd9\u4e2a\u5c5e\u6027\u503c\u662f\u6b63\u786e\u7684. 2.2: \u4e00\u81f4\u6027\u6295\u7968, \u53ea\u6709\u5f53\u6240\u6709\u77e5\u8bc6\u56fe\u8c31\u90fd\u5305\u542b\u8be5\u5c5e\u6027\u503c\u65f6, \u624d\u8ba4\u4e3a\u8fd9\u4e2a\u5c5e\u6027\u503c\u662f\u6b63\u786e\u7684. 2.3: \u52a0\u6743\u6295\u7968, \u5bf9\u4e0d\u540c\u7684\u77e5\u8bc6\u56fe\u8c31\u8bbe\u7f6e\u4e0d\u540c\u7684\u6743\u503c\u8fdb\u884c\u5408\u5e76. 3: \u81ea\u5b9a\u4e49\u878d\u5408\u7b56\u7565, \u67d0\u4e00\u77e5\u8bc6\u56fe\u8c31\u7684\u53ef\u4fe1\u5ea6\u8fdc\u9ad8\u4e8e\u5176\u4ed6\u77e5\u8bc6\u56fe\u8c31, \u53ef\u4ee5\u5c06\u8fd9\u4e2a\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5c5e\u6027\u7684\u5c5e\u6027\u503c\u4f5c\u4e3a\u57fa\u51c6, \u800c\u5c06\u5176\u4ed6\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5c5e\u6027\u7684\u5c5e\u6027\u503c\u901a\u8fc7\u542f\u53d1\u5f0f\u7684\u65b9\u5f0f\u52a0\u5165\u8fdb\u6765.","title":"\u5c5e\u6027\u503c\u878d\u5408"},{"location":"6_3.html","text":"\u77e5\u8bc6\u56fe\u8c31\u4f17\u5305 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u4ec0\u4e48\u662f\u77e5\u8bc6\u56fe\u8c31\u7684\u4f17\u5305. \u7406\u89e3\u77e5\u8bc6\u56fe\u8c31\u4f17\u5305\u4e2d\u7684\u95ee\u9898\u548c\u65b9\u6cd5. \u7406\u89e3\u4f17\u5305\u7684\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u4e0e\u4f18\u5316\u7684\u65b9\u6cd5. \u77e5\u8bc6\u56fe\u8c31\u7684\u4f17\u5305\u6982\u8ff0 \u00b6 \u76ee\u524d\u77e5\u8bc6\u56fe\u8c31\u4e3b\u8981\u662f\u4ee5\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u6765\u6784\u5efa\u7684, \u5373\u673a\u5668\u5229\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u65b9\u6cd5\u81ea\u52a8\u4ece\u5927\u89c4\u6a21\u6587\u672c\u4e2d\u62bd\u53d6\u77e5\u8bc6, \u8fd9\u79cd\u65b9\u6cd5\u514b\u670d\u4e86\u5b8c\u5168\u4f9d\u9760\u4eba\u5de5\u4e13\u5bb6\u6784\u5efa\u77e5\u8bc6\u5e93\u6240\u5e26\u6765\u7684\u9ad8\u6602\u6210\u672c, \u4f7f\u77e5\u8bc6\u56fe\u8c31\u7684\u89c4\u6a21\u5448\u51e0\u4f55\u7ea7\u6570\u589e\u957f. \u5f53\u524d\u9636\u6bb5(2023\u5e74, \u5927\u6570\u636e\u77e5\u8bc6\u5de5\u7a0b\u65f6\u4ee3\u53d1\u5c5510\u5e74\u540e), \u77e5\u8bc6\u7684\u83b7\u53d6\u4ecd\u7136\u9700\u8981\u4eba\u529b\u4ecb\u5165, \u4e3b\u8981\u6709\u4e09\u4e2a\u539f\u56e0: \u7b2c\u4e00: \u4eba\u673a\u6df7\u5408\u667a\u80fd\u4ecd\u7136\u662f\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u7684\u4e3b\u8981\u5f62\u6001. \u603b\u4f53\u6765\u8bf4, \u5f53\u524d\u4eba\u5de5\u667a\u80fd\u662f\u4eba\u673a\u6df7\u5408\u667a\u80fd\u7684\u521d\u7ea7\u9636\u6bb5, \u8ddd\u79bb\u673a\u5668\u81ea\u4e3b\u667a\u80fd\u9636\u6bb5\u4ecd\u7136\u76f8\u8ddd\u751a\u8fdc. \u8fd9\u610f\u5473\u7740, \u5927\u90e8\u5206\u4eba\u5de5\u667a\u80fd\u8fc7\u7a0b\u4ecd\u7136\u9700\u8981\u6765\u81ea\u4e13\u5bb6\u7684\u7ecf\u9a8c\u548c\u77e5\u8bc6, \u5927\u90e8\u5206\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u4ecd\u7136\u663e\u8457\u4f9d\u8d56\u4e8e\u4eba\u5de5\u6807\u6ce8\u7684\u6837\u672c, \u667a\u80fd\u8fc7\u7a0b\u7684\u8f93\u51fa\u7ed3\u679c\u8fd8\u662f\u9700\u8981\u4eba\u7c7b\u7684\u53cd\u9988, \u673a\u5668\u7684\u4ef7\u503c\u89c2\u4e0e\u8ba4\u77e5\u6846\u67b6\u8fd8\u9700\u8981\u4eba\u7c7b\u6765\u5efa\u7acb. \u4eba\u673a\u6df7\u5408\u667a\u80fd\u65e2\u662f\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u6280\u672f\u53d1\u5c55\u7684\u5c40\u9650\u6240\u81f4, \u4e5f\u662f\u4eba\u5de5\u667a\u80fd\u6280\u672f\u53d1\u5c55\u7684\u53ef\u63a7\u6027\u8981\u6c42\u7684\u7ed3\u679c. \u56e0\u6b64, \u6574\u4e2a\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u8fc7\u7a0b, \u4ece\u62bd\u53d6\u6a21\u578b\u7684\u6837\u672c\u6807\u6ce8, \u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u7684\u8bbe\u8ba1\u5230\u77e5\u8bc6\u7684\u9a8c\u8bc1\u7b49\u73af\u8282, \u4ecd\u7136\u9700\u8981\u4eba\u7c7b\u7684\u79ef\u6781\u53c2\u4e0e. \u7b2c\u4e8c: \u77e5\u8bc6\u662f\u4eba\u7c7b\u8ba4\u77e5\u4e16\u754c\u7684\u7ed3\u679c, \u77e5\u8bc6\u7684\u5bf9\u9519\u5176\u8d23\u4efb\u4e3b\u4f53\u8fd8\u662f\u4eba\u7c7b\u81ea\u8eab. \u5f53\u524d\u901a\u8fc7\u81ea\u52a8\u5316\u65b9\u6cd5\u83b7\u53d6\u77e5\u8bc6\u4ea7\u751f\u7684\u9519\u8bef\u5728\u6240\u96be\u514d. \u7531\u4e8e\u4eba\u5de5\u667a\u80fd, \u6a21\u5f0f\u8bc6\u522b, \u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u6280\u672f\u7684\u9650\u5236, \u4ee5\u53ca\u7f51\u7edc\u6587\u6863\u4e0d\u89c4\u8303, \u566a\u58f0\u6570\u636e\u591a\u7b49\u6761\u4ef6\u7684\u5236\u7ea6, \u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7684\u6bcf\u4e00\u4e2a\u91cd\u8981\u6b65\u9aa4(\u547d\u540d\u5b9e\u4f53\u8bc6\u522b, \u5173\u7cfb\u62bd\u53d6, \u77e5\u8bc6\u878d\u5408)\u90fd\u4e0d\u53ef\u80fd\u7528\u81ea\u52a8\u5316\u7684\u624b\u6bb5\u5b8c\u5168, \u51c6\u786e\u7684\u5b8c\u6210, \u800c\u5728\u8fd9\u4e9b\u4e2d\u95f4\u6b65\u9aa4\u4e2d\u4ea7\u751f\u7684\u8bef\u5dee\u7ecf\u8fc7\u7d2f\u52a0\u4f1a\u5bfc\u81f4\u77e5\u8bc6\u56fe\u8c31\u5c06\u9519\u8bef\u7684\u77e5\u8bc6\u4e5f\u5438\u7eb3\u8fdb\u6765. \u81ea\u52a8\u5316\u77e5\u8bc6\u83b7\u53d6\u6240\u4ea7\u751f\u7684\u9519\u8bef\u5fc5\u987b\u7531\u4eba\u6765\u9a8c\u8bc1, \u56e0\u4e3a\"\u77e5\u8bc6\"\u672c\u8d28\u4e0a\u662f\u4eba\u7c7b\u5bf9\u4e16\u754c\u7684\u8ba4\u77e5\u7ed3\u679c, \"\u77e5\u8bc6\"\u7684\u5bf9\u9519\u662f\u4eba\u7c7b\u793e\u4f1a\u7684\u547d\u9898, \u4e0e\u673a\u5668\u65e0\u5173. \u56e0\u6b64, \u7531\u673a\u5668\u81ea\u52a8\u62bd\u53d6\u7684\u4efb\u4f55\u77e5\u8bc6, \u5176\u6700\u7ec8\u7684\u9a8c\u8bc1\u8005\u8fd8\u662f\u4eba, \u800c\u4e14\u53ea\u6709\u4eba\u624d\u80fd\u5bf9\u77e5\u8bc6\u7684\u5bf9\u9519\u8d1f\u8d23, \u6ca1\u6709\u529e\u6cd5\u5bf9\u673a\u5668\u8ffd\u8d23. \u7b2c\u4e09: \u6570\u636e\u53ea\u662f\u4eba\u7c7b\u77e5\u8bc6\u7684\u6709\u9650\u8f7d\u4f53, \u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u83b7\u53d6\u65b9\u6cd5\u53ea\u80fd\u83b7\u53d6\u77e5\u8bc6\u7684\u6709\u9650\u96c6\u5408, \u4eba\u7c7b\u5bf9\u77e5\u8bc6\u7684\u8865\u5145\u4e0d\u53ef\u6216\u7f3a. \u4eba\u7c7b\u7684\u77e5\u8bc6\u662f\u5341\u5206\u5e9e\u5927\u7684, \u901a\u8fc7\u53e3\u53e3\u76f8\u4f20, \u901a\u8fc7\u4e66\u7c4d\u8bb0\u8f7d\u6216\u8005\u6570\u5b57\u5316\u8bb0\u5f55\u7684\u77e5\u8bc6\u53ea\u662f\u4eba\u7c7b\u77e5\u8bc6\u603b\u4f53\u4e2d\u76f8\u5f53\u6709\u9650\u7684\u5b50\u96c6. \u666e\u901a\u4eba\u5bf9\u4e16\u754c\u8ba4\u77e5\u4ea7\u751f\u7684\u5e38\u8bc6, \u4ee5\u53ca\u4e13\u5bb6\u7684\u9690\u6027\u77e5\u8bc6\u90fd\u662f\u6781\u96be\u4ece\u6570\u636e\u4e2d\u4f7f\u7528\u81ea\u52a8\u5316\u65b9\u6cd5\u83b7\u53d6\u7684, \u56e0\u6b64\u5f88\u96be\u88ab\u73b0\u6709\u7684\u5927\u578b\u77e5\u8bc6\u56fe\u8c31\u6240\u8986\u76d6. \u56e0\u6b64, \u6211\u4eec\u4ecd\u7136\u9700\u8981\u5c06\u6765\u81ea\u4e13\u5bb6\u7684\u9690\u77e5\u8bc6, \u9ed8\u77e5\u8bc6\u5c3d\u91cf\u5916\u663e, \u628a\u5b83\u4eec\u663e\u5f0f\u7684\u8868\u8fbe\u51fa\u6765, \u8fde\u540c\u4eba\u7c7b\u7684\u5e38\u8bc6\u4e00\u5e76\u7531\u4eba\u704c\u8f93\u7ed9\u673a\u5668. \u7efc\u4e0a\u6240\u8ff0, \u4ec5\u4ec5\u4f9d\u9760\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u96be\u4ee5\u4f7f\u77e5\u8bc6\u56fe\u8c31\u8fbe\u5230\u9ad8\u51c6\u786e\u7387\u548c\u9ad8\u8986\u76d6\u5ea6, \u800c\u9002\u5f53\u7684\u4eba\u529b\u4ecb\u5165\u5219\u53ef\u4ee5\u7f13\u89e3\u4e0a\u8ff0\u95ee\u9898. \u7136\u800c, \u9ad8\u6602\u7684\u4eba\u5de5\u6210\u672c\u548c\u77e5\u8bc6\u56fe\u8c31\u5e9e\u5927\u7684\u89c4\u6a21\u4f7f\u5f97\u4f20\u7edf\u7684\u7531\u4e13\u5bb6\u4ecb\u5165\u77e5\u8bc6\u5e93\u6784\u5efa\u7684\u65b9\u6848\u65e0\u6cd5\u5c55\u5f00. \u4f17\u5305\u5e73\u53f0(Crowdsourcing Platform)\u7684\u51fa\u73b0\u4f7f\u8fd9\u79cd\u7531\u4eba\u529b\u4ecb\u5165\u53c2\u4e0e\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7684\u65b9\u5f0f\u6210\u4e3a\u53ef\u80fd. \u7531\u4e8e\u4f17\u5305\u65b9\u5f0f\u5229\u7528\u7684\u662f\u5927\u4f17\u7684\u95f2\u6687\u65f6\u95f4, \u5176\u6ca1\u6709\u4f20\u7edf\u7684\u516c\u53f8\u57f9\u8bad\u5f00\u9500\u548c\u56e2\u961f\u7ef4\u62a4\u5f00\u9500, \u4e5f\u907f\u514d\u4e86\u96c7\u4f63\u4e13\u5bb6\u6240\u4ea7\u751f\u7684\u6602\u8d35\u8d39\u7528, \u56e0\u6b64\u53ef\u4ee5\u5927\u5e45\u964d\u4f4e\u5355\u4e2a\u4efb\u52a1\u7684\u4eba\u5de5\u6210\u672c. \u4f17\u5305\u53ef\u4ee5\u5728\u4ee5\u4e0b\u4e09\u4e2a\u9636\u6bb5\u4ecb\u5165\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u8fc7\u7a0b: 1: \u5143\u77e5\u8bc6\u521b\u5efa\u9636\u6bb5. \u8fd9\u4e2a\u9636\u6bb5\u4e3b\u8981\u5b9e\u73b0\u5143\u77e5\u8bc6(\u57fa\u672c\u7684\u8ba4\u77e5\u6846\u67b6)\u7684\u642d\u5efa, \u539f\u56e0\u5728\u4e8e\u57fa\u672c\u7684\u77e5\u8bc6\u4f53\u7cfb\u6d89\u53ca\u6df1\u5c42\u6b21\u8bed\u4e49\u7406\u89e3, \u96be\u4ee5\u4ece\u5927\u6570\u636e\u4e2d\u81ea\u52a8\u5f52\u7eb3\u5f97\u5230. \u53e6\u5916, \u5404\u7c7b\u77e5\u8bc6\u83b7\u53d6\u6a21\u578b\u6240\u7528\u5230\u7684\u7279\u5f81\u548c\u89c4\u5219\u4e5f\u9700\u8981\u7531\u4eba\u5236\u5b9a, \u56e0\u6b64\u8fd9\u90e8\u5206\u5de5\u4f5c\u4e3b\u8981\u7531\u4e13\u5bb6\u5b8c\u6210. 2: \u77e5\u8bc6\u83b7\u53d6\u9636\u6bb5. \u8fd9\u4e2a\u9636\u6bb5\u9700\u8981\u5229\u7528\u4f17\u5305\u5b9e\u73b0\u6570\u636e\u6807\u6ce8, \u518d\u5c06\u8fd9\u4e9b\u6807\u6ce8\u6570\u636e\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e, \u8fdb\u800c\u6784\u5efa\u77e5\u8bc6\u83b7\u53d6\u6a21\u578b(\u547d\u540d\u5b9e\u4f53\u8bc6\u522b, \u5173\u7cfb\u62bd\u53d6, \u77e5\u8bc6\u878d\u5408\u7b49\u7ecf\u5178\u4efb\u52a1, \u5927\u90e8\u5206\u57fa\u4e8e\u76d1\u7763\u5b66\u4e60), \u901a\u8fc7\u8fd9\u4e9b\u6a21\u578b\u4ece\u6587\u672c\u6216\u6570\u636e\u4e2d\u81ea\u52a8\u83b7\u53d6\u77e5\u8bc6. 3: \u77e5\u8bc6\u7cbe\u5316\u9636\u6bb5. \u5728\u5b8c\u6210\u81ea\u52a8\u5316\u77e5\u8bc6\u83b7\u53d6\u540e, \u9700\u8981\u901a\u8fc7\u4f17\u5305\u624b\u6bb5\u6765\u9a8c\u8bc1\u77e5\u8bc6, \u7ea0\u9519\u8865\u6f0f. \u6838\u5fc3: \u4f17\u5305\u5bf9\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u5341\u5206\u91cd\u8981, \u4eba\u529b\u7684\u53c2\u4e0e\u5fc5\u4e0d\u53ef\u5c11. \u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u662f\u4e00\u9879\u4e0e\u77e5\u8bc6\u548c\u667a\u6167\u5bc6\u5207\u76f8\u5173\u7684\u4efb\u52a1, \u5176\u4f17\u5305\u4efb\u52a1\u5c5e\u4e8e\u77e5\u8bc6\u578b\u4f17\u5305. \u77e5\u8bc6\u578b\u4f17\u5305\u7684\u57fa\u672c\u6982\u5ff5 \u00b6 \u4f17\u5305(Crowdsourcing)\u662f\u4e00\u79cd\u65b0\u578b\u7684\u5916\u5305\u6a21\u5f0f, \u5b83\u5c06\u4e00\u7fa4\u677e\u6563\u7684\u4efb\u52a1\u53d1\u5305\u65b9(Requester)\u548c\u4efb\u52a1\u5b8c\u6210\u8005(Worker)\u8054\u7cfb\u8d77\u6765, \u5b9e\u73b0\u4efb\u52a1\u53d1\u5305, \u5339\u914d, \u5b8c\u6210, \u4ed8\u6b3e\u7b49\u4e00\u7cfb\u5217\u64cd\u4f5c. \u6ce8\u610f: \u5728\u6570\u5b57\u5316\u65f6\u4ee3\u5230\u6765\u4ee5\u524d\u4f17\u5305\u5c31\u51fa\u73b0\u4e86, \u53ea\u4e0d\u8fc7\u5f53\u65f6\u4e3b\u8981\u91c7\u7528\"\u7ebf\u4e0b\"\u7684\u5f62\u5f0f\u5b8c\u6210\u4f17\u5305. \u4e0e\u4f20\u7edf\u5916\u5305\u6a21\u5f0f\u4e0d\u540c\u7684\u662f, \u4f17\u5305\u6240\u8054\u7cfb\u7684\u7fa4\u4f53\u662f\u4e00\u7fa4\u677e\u6563\u7684\u65e0\u7ec4\u7ec7\u4eba\u7fa4, \u800c\u4f20\u7edf\u627f\u63a5\u5916\u5305\u4efb\u52a1\u7684\u5bf9\u8c61\u662f\u4e00\u4e2a\u76f8\u5bf9\u56fa\u5b9a\u7684\u7ec4\u7ec7. \u4e92\u8054\u7f512.0\u4f7f\u5f97\u4eba\u4eec\u4ea4\u4e92, \u652f\u4ed8\u548c\u7ec4\u7ec7\u7684\u4fbf\u6377\u6027\u5927\u5927\u63d0\u9ad8, \u4f17\u5305\u56e0\u6b64\u4e5f\u5f97\u5230\u4e86\u63a8\u5e7f, \u76ee\u524d\u5df2\u7ecf\u6709\u4e0d\u5c11\u6bd4\u8f83\u6210\u529f\u7684\u4f17\u5305\u5e73\u53f0: \u6ef4\u6ef4\u51fa\u884c Uber \u7f8e\u56e2\u5916\u5356 \u997f\u4e86\u5417 \u8fbe\u8fbe\u7269\u6d41 \u6ce8\u610f: \u4e0a\u9762\u7684\u51e0\u4e2a\u6210\u529f\u7684\u4f17\u5305\u5e73\u53f0\u504f\u5411\u4e8e\u52b3\u52a8\u5bc6\u96c6\u578b\u884c\u4e1a, \u5982\u5feb\u9012, \u5916\u5356, \u51fa\u79df\u8f66\u7b49, \u4e3b\u8981\u662f\u5c06\u95f2\u6563\u7684\u52b3\u52a8\u529b\u7ec4\u7ec7\u8d77\u6765\u4e3a\u5927\u4f17\u670d\u52a1. \u8fd1\u5e74\u6765, \u6d8c\u73b0\u51fa\u4e00\u7c7b\u65b0\u578b\u7684\u4f17\u5305\u5e73\u53f0-\u77e5\u8bc6\u578b\u4f17\u5305\u5e73\u53f0(Knowledge-Intensive Crowdsourcing). \u8fd9\u7c7b\u4f17\u5305\u5e73\u53f0\u4e3b\u8981\u5c06\u5927\u4f17\u7684\u667a\u6167\u548c\u65f6\u95f4\u5408\u7406\u7ec4\u7ec7, \u4e3a\u5e7f\u5927\u7528\u6237\u63d0\u4f9b\u667a\u529b\u652f\u6301. \u4f8b\u5982: \u5f53\u524d\u5178\u578b\u7684\u77e5\u8bc6\u578b\u4f17\u5305\u5e73\u53f0\u6709\u4e9a\u9a6c\u900a\u7684Mechanical Turk, \u963f\u91cc\u4f17\u5305, \u732a\u516b\u6212\u7b49. \u5728\u5176\u4e0a\u4ea7\u751f\u4e86\u5404\u79cd\u5404\u6837\u7684\u667a\u529b\u578b\u4efb\u52a1\u9700\u6c42, \u5982\u8bed\u6599\u6807\u6ce8, \u5b57\u5e55\u7ffb\u8bd1, Logo\u8bbe\u8ba1\u548c\u95ee\u5377\u8c03\u67e5\u7b49. \u76f8\u6bd4\u4e8e\u52b3\u52a8\u5bc6\u96c6\u578b\u4f17\u5305, \u77e5\u8bc6\u578b\u4f17\u5305\u6709\u4ee5\u4e0b\u7279\u70b9: \u4efb\u52a1\u591a\u6837\u6027\u5f3a \u5de5\u4eba\u591a\u6837\u6027\u5f3a \u4efb\u52a1\u8d28\u91cf\u96be\u4ee5\u8bc4\u4ef7 \u4efb\u52a1\u5b8c\u6210\u8d28\u91cf\u7684\u5f71\u54cd\u9762\u5927 \u603b\u7ed3: \u53ef\u4ee5\u770b\u51fa\u52b3\u52a8\u5bc6\u96c6\u578b\u4f17\u5305\u7684\u6838\u5fc3\u95ee\u9898\u662f\u5982\u4f55\u4f18\u5316\u4efb\u52a1\u4e0e\u5de5\u4eba\u7684\u5339\u914d, \u63d0\u5347\u7528\u6237\u4f53\u9a8c; \u800c\u77e5\u8bc6\u578b\u4f17\u5305\u5219\u9700\u8981\u5728\u6b64\u57fa\u7840\u4e0a\u8fdb\u4e00\u6b65\u8003\u8651\u4e00\u7cfb\u5217\u6280\u672f\u95ee\u9898. \u4f17\u5305\u7684\u95ee\u9898\u548c\u65b9\u6cd5 \u00b6 \u603b\u4f53\u6765\u8bf4, \u77e5\u8bc6\u578b\u4f17\u5305\u9700\u8981\u9762\u4e34\u7684\u95ee\u9898\u53ef\u4ee5\u5f52\u7ed3\u4e3aWWH(What, Whom, How): What: \u5bf9\u4ec0\u4e48\u4efb\u52a1\u8fdb\u884c\u4f17\u5305 Whom: \u5c06\u4efb\u52a1\u4ea4\u7ed9\u8c01\u5b8c\u6210 How: \u5982\u4f55\u5b8c\u6210\u4f17\u5305 What(\u5bf9\u4ec0\u4e48\u4efb\u52a1\u8fdb\u884c\u4f17\u5305) \u00b6 \u9996\u5148, \u9700\u8981\u7cbe\u5fc3\u6311\u9009\u5177\u6709\u6700\u4f73\u6536\u76ca\u7684\u4e00\u6279\u95ee\u9898\u4ea4\u4e88\u4f17\u5305\u5e73\u53f0, \u6311\u9009\u7684\u539f\u5219\u6709\u4e24\u6761: \u6311\u9009\u6700\u91cd\u8981\u7684\u4efb\u52a1: \u867d\u7136\u4f17\u5305\u5355\u4e2a\u4efb\u52a1\u7684\u82b1\u8d39\u5f88\u5c11, \u4f46\u77e5\u8bc6\u578b\u4efb\u52a1\u5f80\u5f80\u9700\u8981\u5c06\u5927\u91cf\u7684\u5c0f\u578b\u4efb\u52a1\u62fc\u63a5\u5728\u4e00\u8d77, \u6bd4\u5982, \u6570\u636e\u6807\u6ce8\u901a\u5e38\u8981\u8fbe\u5230\u4e00\u5b9a\u7684\u6570\u91cf\u624d\u80fd\u83b7\u5f97\u5408\u9002\u7684\u8bad\u7ec3\u6570\u636e\u96c6. \u77e5\u8bc6\u56fe\u8c31\u7684\u878d\u5408\u4e0e\u6e05\u6d17\u4e5f\u5f80\u5f80\u9762\u4e34\u77e5\u8bc6\u56fe\u8c31\u89c4\u6a21\u8d85\u5927\u7684\u95ee\u9898, \u8fd9\u4f1a\u9020\u6210\u6574\u4f53\u5f00\u9500\u5341\u5206\u5de8\u5927. \u53e6\u4e00\u65b9\u9762, \u6570\u636e\u6e90\u7684\u5f02\u6784\u4ee5\u53ca\u6837\u672c\u5206\u5e03\u4e0d\u5747\u8861\u5f80\u5f80\u5bfc\u81f4\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7684\u7ed3\u679c\u8d28\u91cf\u4e0d\u4e00. \u6311\u9009\u673a\u5668\u6700\u4e0d\u64c5\u957f\u800c\u4eba\u6700\u64c5\u957f\u7684\u4efb\u52a1: \u4eba\u673a\u667a\u80fd\u662f\u6709\u7740\u663e\u8457\u5dee\u5f02\u7684, \u4eba\u64c5\u957f\u7406\u89e3\u5e38\u8bc6\u800c\u673a\u5668\u4e0d\u64c5\u957f; \u4eba\u64c5\u957f\u7406\u89e3\u4f3c\u662f\u800c\u975e\u7684\u4e8b\u5b9e, \u673a\u5668\u64c5\u957f\u5904\u7406\u7cbe\u786e\u7684\u77e5\u8bc6; \u4eba\u64c5\u957f\u7406\u89e3\u6982\u5ff5\u6027, \u6846\u67b6\u6027\u7684\u5143\u77e5\u8bc6, \u800c\u673a\u5668\u5728\u8fd9\u4e00\u65b9\u9762\u7684\u80fd\u529b\u4ecd\u7136\u5341\u5206\u6709\u9650. \u8865\u5145: \u5728\u4efb\u52a1\u6311\u9009\u4e2d, \u53ef\u4ee5\u901a\u8fc7\"\u4e0d\u786e\u5b9a\u56fe\"(Uncertain Graph)\u7684\u5efa\u6a21, \u5c06\u8282\u70b9\u4e4b\u95f4\u7684\u5173\u7cfb\u5efa\u6a21\u4e3a\u5e26\u6709\u7f6e\u4fe1\u5ea6\u7684\u8fb9, \u6700\u540e\u901a\u8fc7\u8fb9\u6982\u7387\u7684\u9009\u53d6\u6765\u6311\u9009\u51fa\u54ea\u4e9b\u4efb\u52a1\u9700\u8981\u88ab\u4f17\u5305. Whom(\u5c06\u4efb\u52a1\u4ea4\u7ed9\u8c01\u5b8c\u6210) \u00b6 \u4f17\u5305\u4efb\u52a1\u6709\u4e24\u79cd\u4e0d\u540c\u7684\u53d1\u5305\u65b9\u5f0f: \u88ab\u52a8\u4f17\u5305: \u662f\u6307\u53d1\u5305\u65b9\u5c06\u4efb\u52a1\u6302\u5728\u4f17\u5305\u5e73\u53f0\u4e0a, \u7531\u5de5\u4eba\u6765\u8ba4\u9886\u4efb\u52a1\u5e76\u5b8c\u6210, \u53d1\u5305\u65b9\u4e0d\u5bf9\u5de5\u4eba\u505a\u8fc7\u591a\u9009\u62e9, \u6700\u591a\u8bbe\u8ba1\u4e00\u5957\u6d4b\u8bd5\u9898\u6765\u9a8c\u8bc1\u5de5\u4eba\u7684\u8d44\u683c. \u4e3b\u52a8\u4f17\u5305: \u662f\u6307\u7531\u53d1\u5305\u65b9\u901a\u8fc7\u4e00\u7cfb\u5217\u7b97\u6cd5\u7cbe\u5fc3\u6311\u9009\u5de5\u4eba\u5b9e\u73b0\u4efb\u52a1\u7684\u5206\u914d. \u5f53\u524d\u5927\u89c4\u6a21\u7684\u4f17\u5305\u5e73\u53f0, \u5982\u4e9a\u9a6c\u900a\u7684Mechanical Turk, \u963f\u91cc\u4f17\u5305\u7b49, \u5747\u91c7\u7528\u88ab\u52a8\u4f17\u5305\u7684\u65b9\u5f0f\u5206\u914d\u4efb\u52a1. \u4e3b\u8981\u539f\u56e0\u662f\u5176\u4e0a\u7684\u5927\u90e8\u5206\u4efb\u52a1\u7684\u5b8c\u6210\u95e8\u69db\u8f83\u4f4e, \u4e14\u5e73\u53f0\u7528\u6237\u6570\u91cf\u5e9e\u5927, \u96be\u4ee5\u6709\u6548\u7b5b\u9009. \u53cd\u4e4b, \u5728\u67d0\u4e9b\u8d28\u91cf\u6538\u5173\u4e14\u6240\u9700\u5de5\u4eba\u8f83\u5c11\u7684\u7279\u6b8a\u4efb\u52a1\u4e2d, \u9700\u8981\u91c7\u7528\u4e3b\u52a8\u4f17\u5305\u7684\u65b9\u5f0f, \u5bf9\u5de5\u4eba\u7cbe\u6311\u7ec6\u9009, \u5982\u9879\u76ee\u8bc4\u5ba1, \u4ee3\u7801\u4f17\u5305\u7b49. \u76ee\u524d\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u7814\u7a76\u70ed\u70b9\u4e3b\u8981\u96c6\u4e2d\u5728\u4e3b\u52a8\u4f17\u5305\u4e0a. \u51b7\u542f\u52a8\u95ee\u9898: \u4e0e\u63a8\u8350\u7cfb\u7edf\u4e00\u6837, \u4e3b\u52a8\u4f17\u5305\u7684\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u662f\u51b7\u542f\u52a8\u95ee\u9898. \u53ef\u4ee5\u91c7\u7528\u8fc1\u79fb\u5b66\u4e60\u7684\u65b9\u6cd5\u5c06\u5de5\u4eba\u5728\u67d0\u4e00\u9886\u57df\u7684\u7ecf\u9a8c\u8fc1\u79fb\u5230\u6570\u636e\u7a00\u7f3a\u7684\u9886\u57df, \u6bd4\u5982, \u5bf9\"\u53e3\u7ea2\"\u719f\u6089\u7684\u5de5\u4eba\u4e5f\u8bb8\u5bf9\"\u9ad8\u8ddf\u978b\"\u4e5f\u719f\u6089, \u56e0\u6b64\u53ef\u4ee5\u5c06\u5de5\u4eba\u5bf9\"\u53e3\u7ea2\"\u76f8\u5173\u95ee\u9898\u7684\u56de\u7b54\u8fc1\u79fb\u5230\u5bf9\"\u9ad8\u8ddf\u978b\"\u76f8\u5173\u95ee\u9898\u7684\u56de\u7b54\u4e2d. \u8fd9\u79cd\u65b9\u6cd5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u89e3\u51b3\u4e86\u51b7\u542f\u52a8\u95ee\u9898, \u53ef\u4ee5\u5e94\u7528\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u4f17\u5305\u6784\u5efa. How(\u5982\u4f55\u5b8c\u6210\u4f17\u5305) \u00b6 \u5f53\u524d\u5de5\u4e1a\u754c\u7ecf\u8fc7\u591a\u5e74\u7684\u5b9e\u8df5\u7ecf\u9a8c, \u5df2\u7ecf\u5c06\u4f17\u5305\u8fc7\u7a0b\u8fdb\u884c\u4e86\u9ad8\u6548\u7684\u8c03\u6574, \u4e3b\u8981\u5305\u62ec3\u4e2a\u65b9\u9762: \u5982\u4f55\u8bbe\u8ba1\u4efb\u52a1 \u5982\u4f55\u6fc0\u52b1\u5de5\u4eba \u5982\u4f55\u63a7\u5236\u8d28\u91cf \u5982\u4f55\u8bbe\u8ba1\u4efb\u52a1 \u00b6 \u4ece\u5de5\u4eba\u7684\u89c6\u89d2\u6765\u770b, \u4f17\u5305\u4efb\u52a1\u53ef\u4ee5\u5206\u4e3a\u663e\u5f0f\u4f17\u5305\u548c\u9690\u5f0f\u4f17\u5305: \u663e\u5f0f\u4f17\u5305: \u662f\u6307\u5de5\u4eba\u5728\u5b8c\u6210\u4f17\u5305\u4efb\u52a1\u65f6\u77e5\u6653\u81ea\u5df1\u6b63\u5728\u5b8c\u6210\u4f17\u5305\u4efb\u52a1. \u9690\u5f0f\u4f17\u5305: \u662f\u6307\u5de5\u4eba\u5728\u4e0d\u77e5\u4e0d\u89c9\u4e2d\u5b8c\u6210\u4f17\u5305\u4efb\u52a1. \u76ee\u524d\u5de5\u4e1a\u754c\u7684\u4f17\u5305\u5e73\u53f0\u5927\u591a\u6570\u91c7\u7528\u663e\u5f0f\u4f17\u5305, \u5de5\u4eba\u5b8c\u6210\u4efb\u52a1\u7684\u76ee\u7684\u4e5f\u4e3b\u8981\u662f\u4e3a\u4e86\u83b7\u5f97\u91d1\u94b1\u62a5\u916c. \u663e\u5f0f\u4f17\u5305\u9886\u57df\u6709\u4e00\u4e9b\u516c\u8ba4\u7684\u8bbe\u8ba1\u539f\u5219: \u504f\u597d\u66f4\u5c0f\u7684\u4efb\u52a1 \u5224\u65ad\u9898\u4f18\u4e8e\u9009\u62e9\u9898 \u5de5\u4eba\u4e0d\u559c\u6b22\u6709\u5927\u91cf\u4ea4\u4e92\u5408\u4f5c\u7684\u4efb\u52a1 \u5982\u4f55\u6fc0\u52b1\u5de5\u4eba \u00b6 \u76ee\u524d\u5de5\u4e1a\u754c\u5e38\u7528\u7684\u6fc0\u52b1\u673a\u5236\u6709\u4ee5\u4e0b\u56db\u79cd: \u540d\u8a89\u5ea6 \u5feb\u4e50\u611f \u91d1\u94b1\u6fc0\u52b1 \u793e\u4ea4\u5f71\u54cd \u6700\u91cd\u8981\u7684\u91d1\u94b1\u6fc0\u52b1\u6709\u4e09\u7c7b: \u9759\u6001\u5956\u52b1 \u52a8\u6001\u5956\u52b1 \u6761\u4ef6\u5956\u52b1 \u7814\u7a76\u8f83\u591a\u7684\u793e\u4ea4\u5f71\u54cd\u6709\u4e24\u7c7b: \u5f3a\u8fde\u63a5\u7f51\u7edc: \u5fae\u4fe1, Facebook \u5f31\u8fde\u63a5\u7f51\u7edc: \u767e\u5ea6\u8d34\u5427, \u8bba\u575b \u7efc\u4e0a\u6240\u8ff0: \u4e3a\u4e86\u66f4\u6709\u6548\u7684\u6fc0\u53d1\u5de5\u4eba\u4e3b\u89c2\u80fd\u52a8\u6027, \u53ef\u4ee5\u6df7\u5408\u4f7f\u7528\u4e0a\u8ff0\u591a\u79cd\u6fc0\u52b1\u673a\u5236. \u6bd4\u5982, \u4efb\u52a1\u5f00\u59cb\u9636\u6bb5, \u4f7f\u7528\u5f3a\u8fde\u63a5\u7f51\u7edc\u548c\u91d1\u94b1\u6fc0\u52b1\u5438\u5f15\u5927\u91cf\u5de5\u4eba\u6ce8\u610f\u5230\u6b64\u4efb\u52a1. \u540e\u7eed\u53ef\u4ee5\u901a\u8fc7\u7559\u5b58\u7528\u6237, \u91c7\u7528\u540d\u8a89\u5ea6, \u5feb\u4e50\u611f\u7b49\u865a\u62df\u673a\u5236\u8282\u7701\u5f00\u9500. \u5982\u4f55\u63a7\u5236\u8d28\u91cf \u00b6 \u77e5\u8bc6\u578b\u4f17\u5305\u6700\u5927\u7684\u95ee\u9898\u4e4b\u4e00\u5c31\u662f\u8d28\u91cf\u63a7\u5236, \u56e0\u4e3a\u53d1\u5305\u65b9\u4e5f\u6ca1\u6709\u4efb\u52a1\u7684\u6807\u51c6\u7b54\u6848, \u53ea\u80fd\u51ed\u501f\u5de5\u4eba\u8fd4\u56de\u7684\u7ed3\u679c\u63a8\u65ad\u51fa\u771f\u5b9e\u7684\u7b54\u6848. \u800c\u540c\u65f6\u5de5\u4eba\u7684\u7d20\u8d28\u548c\u6c34\u5e73\u53c8\u53c2\u5dee\u4e0d\u9f50, \u6240\u4ee5\u8d28\u91cf\u63a7\u5236\u5c31\u6210\u4e86\u5f88\u96be\u7684\u95ee\u9898. \u4e3b\u8981\u5206\u62103\u9636\u6bb5\u6765\u63a7\u5236: \u4f17\u5305\u524d\u7684\u8d28\u91cf\u63a7\u5236: \u4e3b\u8981\u662f\u5728\u4efb\u52a1\u53d1\u5305\u524d\u5236\u5b9a\u597d\u7684\u4efb\u52a1\u8bbe\u8ba1\u7b56\u7565\u548c\u6fc0\u52b1\u5206\u914d\u7b56\u7565. \u4f17\u5305\u8fc7\u7a0b\u4e2d\u7684\u8d28\u91cf\u63a7\u5236: \u662f\u6307\u5728\u4f17\u5305\u8fc7\u7a0b\u4e2d\u901a\u8fc7\u8bbe\u8ba1\u4e00\u4e9b\u7cbe\u7ec6\u7684\u8fc7\u7a0b\u63d0\u5347\u4f17\u5305\u4efb\u52a1\u5b8c\u6210\u7684\u8d28\u91cf. \u4f17\u5305\u540e\u7684\u8d28\u91cf\u63a7\u5236: \u662f\u6307\u5728\u83b7\u53d6\u4eba\u5de5\u8fd4\u56de\u7684\u7b54\u6848\u540e\u7efc\u5408\u63a8\u65ad\u51fa\u771f\u5b9e\u7684\u7ed3\u679c. \u57fa\u4e8e\u4f17\u5305\u7684\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa \u00b6 \u5728\u6784\u5efa\u4e0e\u7cbe\u5316\u77e5\u8bc6\u56fe\u8c31\u7684\u8fc7\u7a0b\u4e2d, \u6709\u4e09\u4e2a\u9636\u6bb5\u662f\u9700\u8981\u4eba\u5de5\u4ecb\u5165\u7684: \u672c\u4f53\u6784\u5efa\u9636\u6bb5 \u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u9636\u6bb5 \u77e5\u8bc6\u56fe\u8c31\u7cbe\u5316\u9636\u6bb5 \u672c\u4f53\u6784\u5efa\u9636\u6bb5 \u00b6 \u5728\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u4e4b\u521d, \u672c\u4f53\u8bbe\u8ba1\u662f\u4e0d\u53ef\u6216\u7f3a\u7684\u73af\u8282, \u6784\u5efa\u597d\u672c\u4f53\u540e, \u518d\u4ece\u6570\u636e\u4e2d\u62bd\u53d6\u5b9e\u4f8b\u6302\u63a5\u5230\u6982\u5ff5\u4e4b\u4e0b. \u5b9e\u4f8b\u4e4b\u95f4\u8fd8\u53ef\u4ee5\u7ee7\u627f\u672c\u4f53\u4e2d\u5bf9\u5e94\u7684\u6982\u5ff5\u4e0e\u6982\u5ff5\u4e4b\u95f4\u7684\u5173\u7cfb. \u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u9636\u6bb5 \u00b6 \u672c\u4f53\u8bbe\u8ba1\u5b8c\u6210\u540e, \u9700\u8981\u7528\u81ea\u52a8\u5316\u7684\u624b\u6bb5\u4ece\u5927\u89c4\u6a21\u6587\u672c\u4e2d\u62bd\u53d6\u77e5\u8bc6, \u4eba\u5de5\u4ecb\u5165\u7684\u4e24\u4e2a\u4f18\u52bf\u4efb\u52a1: \u4e09\u5143\u7ec4\u62bd\u53d6 \u5b9e\u4f53\u5bf9\u9f50 \u4e09\u5143\u7ec4\u62bd\u53d6: \u76ee\u524d\u5b66\u672f\u754c, \u5de5\u4e1a\u754c\u5173\u4e8e\u4e09\u5143\u7ec4\u62bd\u53d6\u4efb\u52a1, \u4e3b\u8981\u67092\u79cd\u65b9\u6cd5, \u57fa\u4e8e\u89c4\u5219\u6d3e\u7684\u65b9\u6cd5\u548c\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5, \u4f46\u90fd\u65e0\u6cd5\u907f\u514d\u9519\u8bef. \u4f17\u5305\u5e73\u53f0\u5c06\u4e0e\u771f\u5b9e\u4e09\u5143\u7ec4\u76f8\u5173\u7684\u4e0a\u4e0b\u6587\u878d\u5165\u95ee\u9898\u4e2d, \u5e76\u751f\u6210\u9009\u62e9\u9898\u7684\u9898\u76ee, \u5e76\u7ed9\u51fa\u82e5\u5e72\u4e2a\u5019\u9009\u7b54\u6848. \u6ce8\u610f: \u4e4b\u6240\u4ee5\u91c7\u7528\u9009\u62e9\u9898\u7684\u65b9\u5f0f\u8fdb\u884c\u4f17\u5305, \u662f\u4e3a\u4e86\u9632\u6b62\u5f00\u653e\u6027\u95ee\u9898\u9020\u6210\u4f17\u5305\u7b54\u6848\u4e94\u82b1\u516b\u95e8\u800c\u96be\u4ee5\u7edf\u4e00! \u5b9e\u4f53\u5bf9\u9f50: \u5b9e\u4f53\u5bf9\u9f50\u662f\u77e5\u8bc6\u578b\u4f17\u5305\u4e2d\u6700\u5e38\u89c1\u7684\u4efb\u52a1\u4e4b\u4e00, \u662f\u4e00\u9879\u5178\u578b\u7684\u4eba\u64c5\u957f\u800c\u673a\u5668\u4e0d\u5bb9\u6613\u51c6\u786e\u5b8c\u6210\u7684\u4efb\u52a1. \u6bd4\u5982, \u4eba\u53ef\u4ee5\u5f88\u5bb9\u6613\u7684\u628a\"\u82f9\u679c iPad 4\"\u548c\"\u82f9\u679c\u5e73\u677f\u7535\u81114\u4ee3\"\u5bf9\u5e94\u8d77\u6765, \u800c\u673a\u5668\u5374\u5f88\u96be\u505a\u5230. \u5b9e\u4f53\u5bf9\u9f50\u4efb\u52a1\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u96be\u70b9: \u4e92\u8054\u7f51\u4e2d\u65b0\u7684\u5b9e\u4f53\u5c42\u51fa\u4e0d\u7a77, \u8bad\u7ec3\u96c6\u5f88\u96be\u8986\u76d6\u8fd9\u4e9b\u65b0\u5b9e\u4f53. \u5b9e\u4f53\u7684\u7ed3\u6784\u590d\u6742, \u4e0d\u89c4\u8303, \u5f88\u96be\u7528\u89c4\u5219\u6a21\u677f\u6765\u9002\u914d. \u5b9e\u4f53\u8868\u8ff0\u4e00\u822c\u8f83\u77ed, \u9700\u8981\u7ed3\u5408\u4e0a\u4e0b\u6587\u6765\u5224\u65ad\u548c\u8bc6\u522b. \u4eba\u8111\u7531\u4e8e\u6709\u66f4\u5f3a\u5927\u7684\u8ba4\u77e5\u80fd\u529b\u548c\u66f4\u4e30\u5bcc\u7684\u5e38\u8bc6\u50a8\u5907, \u6240\u4ee5\u53ef\u4ee5\u975e\u5e38\u8f7b\u677e, \u51c6\u786e\u7684\u5b8c\u6210\u5b9e\u4f53\u5bf9\u9f50\u4efb\u52a1. \u77e5\u8bc6\u56fe\u8c31\u7cbe\u5316\u9636\u6bb5 \u00b6 \u5728\u77e5\u8bc6\u56fe\u8c31\u7cbe\u5316\u8fc7\u7a0b\u4e2d\u5f15\u5165\u4f17\u5305, \u53ef\u4ee5\u63d0\u9ad8\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u8fc7\u7a0b\u7684\u51c6\u786e\u5ea6\u548c\u8986\u76d6\u5ea6. \u67d0\u4e9b\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u9519\u8bef\u6216\u8005\u7f3a\u5931, \u53ef\u4ee5\u501f\u52a9\u7528\u6237\u5728\u5e94\u7528\u540e\u7684\u53cd\u9988\u6765\u5b8c\u6210. \u5229\u7528\u4f17\u5305\u65b9\u5f0f\u5b9e\u73b0\u77e5\u8bc6\u7cbe\u5316\u7684\u5178\u578b\u6848\u4f8b: Cyc OpenMind","title":"6.3 \u77e5\u8bc6\u56fe\u8c31\u7684\u4f17\u5305"},{"location":"6_3.html#_1","text":"","title":"\u77e5\u8bc6\u56fe\u8c31\u4f17\u5305"},{"location":"6_3.html#_2","text":"\u4e86\u89e3\u4ec0\u4e48\u662f\u77e5\u8bc6\u56fe\u8c31\u7684\u4f17\u5305. \u7406\u89e3\u77e5\u8bc6\u56fe\u8c31\u4f17\u5305\u4e2d\u7684\u95ee\u9898\u548c\u65b9\u6cd5. \u7406\u89e3\u4f17\u5305\u7684\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u4e0e\u4f18\u5316\u7684\u65b9\u6cd5.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"6_3.html#_3","text":"\u76ee\u524d\u77e5\u8bc6\u56fe\u8c31\u4e3b\u8981\u662f\u4ee5\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u6765\u6784\u5efa\u7684, \u5373\u673a\u5668\u5229\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u65b9\u6cd5\u81ea\u52a8\u4ece\u5927\u89c4\u6a21\u6587\u672c\u4e2d\u62bd\u53d6\u77e5\u8bc6, \u8fd9\u79cd\u65b9\u6cd5\u514b\u670d\u4e86\u5b8c\u5168\u4f9d\u9760\u4eba\u5de5\u4e13\u5bb6\u6784\u5efa\u77e5\u8bc6\u5e93\u6240\u5e26\u6765\u7684\u9ad8\u6602\u6210\u672c, \u4f7f\u77e5\u8bc6\u56fe\u8c31\u7684\u89c4\u6a21\u5448\u51e0\u4f55\u7ea7\u6570\u589e\u957f. \u5f53\u524d\u9636\u6bb5(2023\u5e74, \u5927\u6570\u636e\u77e5\u8bc6\u5de5\u7a0b\u65f6\u4ee3\u53d1\u5c5510\u5e74\u540e), \u77e5\u8bc6\u7684\u83b7\u53d6\u4ecd\u7136\u9700\u8981\u4eba\u529b\u4ecb\u5165, \u4e3b\u8981\u6709\u4e09\u4e2a\u539f\u56e0: \u7b2c\u4e00: \u4eba\u673a\u6df7\u5408\u667a\u80fd\u4ecd\u7136\u662f\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u7684\u4e3b\u8981\u5f62\u6001. \u603b\u4f53\u6765\u8bf4, \u5f53\u524d\u4eba\u5de5\u667a\u80fd\u662f\u4eba\u673a\u6df7\u5408\u667a\u80fd\u7684\u521d\u7ea7\u9636\u6bb5, \u8ddd\u79bb\u673a\u5668\u81ea\u4e3b\u667a\u80fd\u9636\u6bb5\u4ecd\u7136\u76f8\u8ddd\u751a\u8fdc. \u8fd9\u610f\u5473\u7740, \u5927\u90e8\u5206\u4eba\u5de5\u667a\u80fd\u8fc7\u7a0b\u4ecd\u7136\u9700\u8981\u6765\u81ea\u4e13\u5bb6\u7684\u7ecf\u9a8c\u548c\u77e5\u8bc6, \u5927\u90e8\u5206\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u4ecd\u7136\u663e\u8457\u4f9d\u8d56\u4e8e\u4eba\u5de5\u6807\u6ce8\u7684\u6837\u672c, \u667a\u80fd\u8fc7\u7a0b\u7684\u8f93\u51fa\u7ed3\u679c\u8fd8\u662f\u9700\u8981\u4eba\u7c7b\u7684\u53cd\u9988, \u673a\u5668\u7684\u4ef7\u503c\u89c2\u4e0e\u8ba4\u77e5\u6846\u67b6\u8fd8\u9700\u8981\u4eba\u7c7b\u6765\u5efa\u7acb. \u4eba\u673a\u6df7\u5408\u667a\u80fd\u65e2\u662f\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u6280\u672f\u53d1\u5c55\u7684\u5c40\u9650\u6240\u81f4, \u4e5f\u662f\u4eba\u5de5\u667a\u80fd\u6280\u672f\u53d1\u5c55\u7684\u53ef\u63a7\u6027\u8981\u6c42\u7684\u7ed3\u679c. \u56e0\u6b64, \u6574\u4e2a\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u8fc7\u7a0b, \u4ece\u62bd\u53d6\u6a21\u578b\u7684\u6837\u672c\u6807\u6ce8, \u6982\u5ff5\u5c42\u7ea7\u4f53\u7cfb\u7684\u8bbe\u8ba1\u5230\u77e5\u8bc6\u7684\u9a8c\u8bc1\u7b49\u73af\u8282, \u4ecd\u7136\u9700\u8981\u4eba\u7c7b\u7684\u79ef\u6781\u53c2\u4e0e. \u7b2c\u4e8c: \u77e5\u8bc6\u662f\u4eba\u7c7b\u8ba4\u77e5\u4e16\u754c\u7684\u7ed3\u679c, \u77e5\u8bc6\u7684\u5bf9\u9519\u5176\u8d23\u4efb\u4e3b\u4f53\u8fd8\u662f\u4eba\u7c7b\u81ea\u8eab. \u5f53\u524d\u901a\u8fc7\u81ea\u52a8\u5316\u65b9\u6cd5\u83b7\u53d6\u77e5\u8bc6\u4ea7\u751f\u7684\u9519\u8bef\u5728\u6240\u96be\u514d. \u7531\u4e8e\u4eba\u5de5\u667a\u80fd, \u6a21\u5f0f\u8bc6\u522b, \u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u6280\u672f\u7684\u9650\u5236, \u4ee5\u53ca\u7f51\u7edc\u6587\u6863\u4e0d\u89c4\u8303, \u566a\u58f0\u6570\u636e\u591a\u7b49\u6761\u4ef6\u7684\u5236\u7ea6, \u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7684\u6bcf\u4e00\u4e2a\u91cd\u8981\u6b65\u9aa4(\u547d\u540d\u5b9e\u4f53\u8bc6\u522b, \u5173\u7cfb\u62bd\u53d6, \u77e5\u8bc6\u878d\u5408)\u90fd\u4e0d\u53ef\u80fd\u7528\u81ea\u52a8\u5316\u7684\u624b\u6bb5\u5b8c\u5168, \u51c6\u786e\u7684\u5b8c\u6210, \u800c\u5728\u8fd9\u4e9b\u4e2d\u95f4\u6b65\u9aa4\u4e2d\u4ea7\u751f\u7684\u8bef\u5dee\u7ecf\u8fc7\u7d2f\u52a0\u4f1a\u5bfc\u81f4\u77e5\u8bc6\u56fe\u8c31\u5c06\u9519\u8bef\u7684\u77e5\u8bc6\u4e5f\u5438\u7eb3\u8fdb\u6765. \u81ea\u52a8\u5316\u77e5\u8bc6\u83b7\u53d6\u6240\u4ea7\u751f\u7684\u9519\u8bef\u5fc5\u987b\u7531\u4eba\u6765\u9a8c\u8bc1, \u56e0\u4e3a\"\u77e5\u8bc6\"\u672c\u8d28\u4e0a\u662f\u4eba\u7c7b\u5bf9\u4e16\u754c\u7684\u8ba4\u77e5\u7ed3\u679c, \"\u77e5\u8bc6\"\u7684\u5bf9\u9519\u662f\u4eba\u7c7b\u793e\u4f1a\u7684\u547d\u9898, \u4e0e\u673a\u5668\u65e0\u5173. \u56e0\u6b64, \u7531\u673a\u5668\u81ea\u52a8\u62bd\u53d6\u7684\u4efb\u4f55\u77e5\u8bc6, \u5176\u6700\u7ec8\u7684\u9a8c\u8bc1\u8005\u8fd8\u662f\u4eba, \u800c\u4e14\u53ea\u6709\u4eba\u624d\u80fd\u5bf9\u77e5\u8bc6\u7684\u5bf9\u9519\u8d1f\u8d23, \u6ca1\u6709\u529e\u6cd5\u5bf9\u673a\u5668\u8ffd\u8d23. \u7b2c\u4e09: \u6570\u636e\u53ea\u662f\u4eba\u7c7b\u77e5\u8bc6\u7684\u6709\u9650\u8f7d\u4f53, \u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u83b7\u53d6\u65b9\u6cd5\u53ea\u80fd\u83b7\u53d6\u77e5\u8bc6\u7684\u6709\u9650\u96c6\u5408, \u4eba\u7c7b\u5bf9\u77e5\u8bc6\u7684\u8865\u5145\u4e0d\u53ef\u6216\u7f3a. \u4eba\u7c7b\u7684\u77e5\u8bc6\u662f\u5341\u5206\u5e9e\u5927\u7684, \u901a\u8fc7\u53e3\u53e3\u76f8\u4f20, \u901a\u8fc7\u4e66\u7c4d\u8bb0\u8f7d\u6216\u8005\u6570\u5b57\u5316\u8bb0\u5f55\u7684\u77e5\u8bc6\u53ea\u662f\u4eba\u7c7b\u77e5\u8bc6\u603b\u4f53\u4e2d\u76f8\u5f53\u6709\u9650\u7684\u5b50\u96c6. \u666e\u901a\u4eba\u5bf9\u4e16\u754c\u8ba4\u77e5\u4ea7\u751f\u7684\u5e38\u8bc6, \u4ee5\u53ca\u4e13\u5bb6\u7684\u9690\u6027\u77e5\u8bc6\u90fd\u662f\u6781\u96be\u4ece\u6570\u636e\u4e2d\u4f7f\u7528\u81ea\u52a8\u5316\u65b9\u6cd5\u83b7\u53d6\u7684, \u56e0\u6b64\u5f88\u96be\u88ab\u73b0\u6709\u7684\u5927\u578b\u77e5\u8bc6\u56fe\u8c31\u6240\u8986\u76d6. \u56e0\u6b64, \u6211\u4eec\u4ecd\u7136\u9700\u8981\u5c06\u6765\u81ea\u4e13\u5bb6\u7684\u9690\u77e5\u8bc6, \u9ed8\u77e5\u8bc6\u5c3d\u91cf\u5916\u663e, \u628a\u5b83\u4eec\u663e\u5f0f\u7684\u8868\u8fbe\u51fa\u6765, \u8fde\u540c\u4eba\u7c7b\u7684\u5e38\u8bc6\u4e00\u5e76\u7531\u4eba\u704c\u8f93\u7ed9\u673a\u5668. \u7efc\u4e0a\u6240\u8ff0, \u4ec5\u4ec5\u4f9d\u9760\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u96be\u4ee5\u4f7f\u77e5\u8bc6\u56fe\u8c31\u8fbe\u5230\u9ad8\u51c6\u786e\u7387\u548c\u9ad8\u8986\u76d6\u5ea6, \u800c\u9002\u5f53\u7684\u4eba\u529b\u4ecb\u5165\u5219\u53ef\u4ee5\u7f13\u89e3\u4e0a\u8ff0\u95ee\u9898. \u7136\u800c, \u9ad8\u6602\u7684\u4eba\u5de5\u6210\u672c\u548c\u77e5\u8bc6\u56fe\u8c31\u5e9e\u5927\u7684\u89c4\u6a21\u4f7f\u5f97\u4f20\u7edf\u7684\u7531\u4e13\u5bb6\u4ecb\u5165\u77e5\u8bc6\u5e93\u6784\u5efa\u7684\u65b9\u6848\u65e0\u6cd5\u5c55\u5f00. \u4f17\u5305\u5e73\u53f0(Crowdsourcing Platform)\u7684\u51fa\u73b0\u4f7f\u8fd9\u79cd\u7531\u4eba\u529b\u4ecb\u5165\u53c2\u4e0e\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7684\u65b9\u5f0f\u6210\u4e3a\u53ef\u80fd. \u7531\u4e8e\u4f17\u5305\u65b9\u5f0f\u5229\u7528\u7684\u662f\u5927\u4f17\u7684\u95f2\u6687\u65f6\u95f4, \u5176\u6ca1\u6709\u4f20\u7edf\u7684\u516c\u53f8\u57f9\u8bad\u5f00\u9500\u548c\u56e2\u961f\u7ef4\u62a4\u5f00\u9500, \u4e5f\u907f\u514d\u4e86\u96c7\u4f63\u4e13\u5bb6\u6240\u4ea7\u751f\u7684\u6602\u8d35\u8d39\u7528, \u56e0\u6b64\u53ef\u4ee5\u5927\u5e45\u964d\u4f4e\u5355\u4e2a\u4efb\u52a1\u7684\u4eba\u5de5\u6210\u672c. \u4f17\u5305\u53ef\u4ee5\u5728\u4ee5\u4e0b\u4e09\u4e2a\u9636\u6bb5\u4ecb\u5165\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u8fc7\u7a0b: 1: \u5143\u77e5\u8bc6\u521b\u5efa\u9636\u6bb5. \u8fd9\u4e2a\u9636\u6bb5\u4e3b\u8981\u5b9e\u73b0\u5143\u77e5\u8bc6(\u57fa\u672c\u7684\u8ba4\u77e5\u6846\u67b6)\u7684\u642d\u5efa, \u539f\u56e0\u5728\u4e8e\u57fa\u672c\u7684\u77e5\u8bc6\u4f53\u7cfb\u6d89\u53ca\u6df1\u5c42\u6b21\u8bed\u4e49\u7406\u89e3, \u96be\u4ee5\u4ece\u5927\u6570\u636e\u4e2d\u81ea\u52a8\u5f52\u7eb3\u5f97\u5230. \u53e6\u5916, \u5404\u7c7b\u77e5\u8bc6\u83b7\u53d6\u6a21\u578b\u6240\u7528\u5230\u7684\u7279\u5f81\u548c\u89c4\u5219\u4e5f\u9700\u8981\u7531\u4eba\u5236\u5b9a, \u56e0\u6b64\u8fd9\u90e8\u5206\u5de5\u4f5c\u4e3b\u8981\u7531\u4e13\u5bb6\u5b8c\u6210. 2: \u77e5\u8bc6\u83b7\u53d6\u9636\u6bb5. \u8fd9\u4e2a\u9636\u6bb5\u9700\u8981\u5229\u7528\u4f17\u5305\u5b9e\u73b0\u6570\u636e\u6807\u6ce8, \u518d\u5c06\u8fd9\u4e9b\u6807\u6ce8\u6570\u636e\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e, \u8fdb\u800c\u6784\u5efa\u77e5\u8bc6\u83b7\u53d6\u6a21\u578b(\u547d\u540d\u5b9e\u4f53\u8bc6\u522b, \u5173\u7cfb\u62bd\u53d6, \u77e5\u8bc6\u878d\u5408\u7b49\u7ecf\u5178\u4efb\u52a1, \u5927\u90e8\u5206\u57fa\u4e8e\u76d1\u7763\u5b66\u4e60), \u901a\u8fc7\u8fd9\u4e9b\u6a21\u578b\u4ece\u6587\u672c\u6216\u6570\u636e\u4e2d\u81ea\u52a8\u83b7\u53d6\u77e5\u8bc6. 3: \u77e5\u8bc6\u7cbe\u5316\u9636\u6bb5. \u5728\u5b8c\u6210\u81ea\u52a8\u5316\u77e5\u8bc6\u83b7\u53d6\u540e, \u9700\u8981\u901a\u8fc7\u4f17\u5305\u624b\u6bb5\u6765\u9a8c\u8bc1\u77e5\u8bc6, \u7ea0\u9519\u8865\u6f0f. \u6838\u5fc3: \u4f17\u5305\u5bf9\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u5341\u5206\u91cd\u8981, \u4eba\u529b\u7684\u53c2\u4e0e\u5fc5\u4e0d\u53ef\u5c11. \u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u662f\u4e00\u9879\u4e0e\u77e5\u8bc6\u548c\u667a\u6167\u5bc6\u5207\u76f8\u5173\u7684\u4efb\u52a1, \u5176\u4f17\u5305\u4efb\u52a1\u5c5e\u4e8e\u77e5\u8bc6\u578b\u4f17\u5305.","title":"\u77e5\u8bc6\u56fe\u8c31\u7684\u4f17\u5305\u6982\u8ff0"},{"location":"6_3.html#_4","text":"\u4f17\u5305(Crowdsourcing)\u662f\u4e00\u79cd\u65b0\u578b\u7684\u5916\u5305\u6a21\u5f0f, \u5b83\u5c06\u4e00\u7fa4\u677e\u6563\u7684\u4efb\u52a1\u53d1\u5305\u65b9(Requester)\u548c\u4efb\u52a1\u5b8c\u6210\u8005(Worker)\u8054\u7cfb\u8d77\u6765, \u5b9e\u73b0\u4efb\u52a1\u53d1\u5305, \u5339\u914d, \u5b8c\u6210, \u4ed8\u6b3e\u7b49\u4e00\u7cfb\u5217\u64cd\u4f5c. \u6ce8\u610f: \u5728\u6570\u5b57\u5316\u65f6\u4ee3\u5230\u6765\u4ee5\u524d\u4f17\u5305\u5c31\u51fa\u73b0\u4e86, \u53ea\u4e0d\u8fc7\u5f53\u65f6\u4e3b\u8981\u91c7\u7528\"\u7ebf\u4e0b\"\u7684\u5f62\u5f0f\u5b8c\u6210\u4f17\u5305. \u4e0e\u4f20\u7edf\u5916\u5305\u6a21\u5f0f\u4e0d\u540c\u7684\u662f, \u4f17\u5305\u6240\u8054\u7cfb\u7684\u7fa4\u4f53\u662f\u4e00\u7fa4\u677e\u6563\u7684\u65e0\u7ec4\u7ec7\u4eba\u7fa4, \u800c\u4f20\u7edf\u627f\u63a5\u5916\u5305\u4efb\u52a1\u7684\u5bf9\u8c61\u662f\u4e00\u4e2a\u76f8\u5bf9\u56fa\u5b9a\u7684\u7ec4\u7ec7. \u4e92\u8054\u7f512.0\u4f7f\u5f97\u4eba\u4eec\u4ea4\u4e92, \u652f\u4ed8\u548c\u7ec4\u7ec7\u7684\u4fbf\u6377\u6027\u5927\u5927\u63d0\u9ad8, \u4f17\u5305\u56e0\u6b64\u4e5f\u5f97\u5230\u4e86\u63a8\u5e7f, \u76ee\u524d\u5df2\u7ecf\u6709\u4e0d\u5c11\u6bd4\u8f83\u6210\u529f\u7684\u4f17\u5305\u5e73\u53f0: \u6ef4\u6ef4\u51fa\u884c Uber \u7f8e\u56e2\u5916\u5356 \u997f\u4e86\u5417 \u8fbe\u8fbe\u7269\u6d41 \u6ce8\u610f: \u4e0a\u9762\u7684\u51e0\u4e2a\u6210\u529f\u7684\u4f17\u5305\u5e73\u53f0\u504f\u5411\u4e8e\u52b3\u52a8\u5bc6\u96c6\u578b\u884c\u4e1a, \u5982\u5feb\u9012, \u5916\u5356, \u51fa\u79df\u8f66\u7b49, \u4e3b\u8981\u662f\u5c06\u95f2\u6563\u7684\u52b3\u52a8\u529b\u7ec4\u7ec7\u8d77\u6765\u4e3a\u5927\u4f17\u670d\u52a1. \u8fd1\u5e74\u6765, \u6d8c\u73b0\u51fa\u4e00\u7c7b\u65b0\u578b\u7684\u4f17\u5305\u5e73\u53f0-\u77e5\u8bc6\u578b\u4f17\u5305\u5e73\u53f0(Knowledge-Intensive Crowdsourcing). \u8fd9\u7c7b\u4f17\u5305\u5e73\u53f0\u4e3b\u8981\u5c06\u5927\u4f17\u7684\u667a\u6167\u548c\u65f6\u95f4\u5408\u7406\u7ec4\u7ec7, \u4e3a\u5e7f\u5927\u7528\u6237\u63d0\u4f9b\u667a\u529b\u652f\u6301. \u4f8b\u5982: \u5f53\u524d\u5178\u578b\u7684\u77e5\u8bc6\u578b\u4f17\u5305\u5e73\u53f0\u6709\u4e9a\u9a6c\u900a\u7684Mechanical Turk, \u963f\u91cc\u4f17\u5305, \u732a\u516b\u6212\u7b49. \u5728\u5176\u4e0a\u4ea7\u751f\u4e86\u5404\u79cd\u5404\u6837\u7684\u667a\u529b\u578b\u4efb\u52a1\u9700\u6c42, \u5982\u8bed\u6599\u6807\u6ce8, \u5b57\u5e55\u7ffb\u8bd1, Logo\u8bbe\u8ba1\u548c\u95ee\u5377\u8c03\u67e5\u7b49. \u76f8\u6bd4\u4e8e\u52b3\u52a8\u5bc6\u96c6\u578b\u4f17\u5305, \u77e5\u8bc6\u578b\u4f17\u5305\u6709\u4ee5\u4e0b\u7279\u70b9: \u4efb\u52a1\u591a\u6837\u6027\u5f3a \u5de5\u4eba\u591a\u6837\u6027\u5f3a \u4efb\u52a1\u8d28\u91cf\u96be\u4ee5\u8bc4\u4ef7 \u4efb\u52a1\u5b8c\u6210\u8d28\u91cf\u7684\u5f71\u54cd\u9762\u5927 \u603b\u7ed3: \u53ef\u4ee5\u770b\u51fa\u52b3\u52a8\u5bc6\u96c6\u578b\u4f17\u5305\u7684\u6838\u5fc3\u95ee\u9898\u662f\u5982\u4f55\u4f18\u5316\u4efb\u52a1\u4e0e\u5de5\u4eba\u7684\u5339\u914d, \u63d0\u5347\u7528\u6237\u4f53\u9a8c; \u800c\u77e5\u8bc6\u578b\u4f17\u5305\u5219\u9700\u8981\u5728\u6b64\u57fa\u7840\u4e0a\u8fdb\u4e00\u6b65\u8003\u8651\u4e00\u7cfb\u5217\u6280\u672f\u95ee\u9898.","title":"\u77e5\u8bc6\u578b\u4f17\u5305\u7684\u57fa\u672c\u6982\u5ff5"},{"location":"6_3.html#_5","text":"\u603b\u4f53\u6765\u8bf4, \u77e5\u8bc6\u578b\u4f17\u5305\u9700\u8981\u9762\u4e34\u7684\u95ee\u9898\u53ef\u4ee5\u5f52\u7ed3\u4e3aWWH(What, Whom, How): What: \u5bf9\u4ec0\u4e48\u4efb\u52a1\u8fdb\u884c\u4f17\u5305 Whom: \u5c06\u4efb\u52a1\u4ea4\u7ed9\u8c01\u5b8c\u6210 How: \u5982\u4f55\u5b8c\u6210\u4f17\u5305","title":"\u4f17\u5305\u7684\u95ee\u9898\u548c\u65b9\u6cd5"},{"location":"6_3.html#what","text":"\u9996\u5148, \u9700\u8981\u7cbe\u5fc3\u6311\u9009\u5177\u6709\u6700\u4f73\u6536\u76ca\u7684\u4e00\u6279\u95ee\u9898\u4ea4\u4e88\u4f17\u5305\u5e73\u53f0, \u6311\u9009\u7684\u539f\u5219\u6709\u4e24\u6761: \u6311\u9009\u6700\u91cd\u8981\u7684\u4efb\u52a1: \u867d\u7136\u4f17\u5305\u5355\u4e2a\u4efb\u52a1\u7684\u82b1\u8d39\u5f88\u5c11, \u4f46\u77e5\u8bc6\u578b\u4efb\u52a1\u5f80\u5f80\u9700\u8981\u5c06\u5927\u91cf\u7684\u5c0f\u578b\u4efb\u52a1\u62fc\u63a5\u5728\u4e00\u8d77, \u6bd4\u5982, \u6570\u636e\u6807\u6ce8\u901a\u5e38\u8981\u8fbe\u5230\u4e00\u5b9a\u7684\u6570\u91cf\u624d\u80fd\u83b7\u5f97\u5408\u9002\u7684\u8bad\u7ec3\u6570\u636e\u96c6. \u77e5\u8bc6\u56fe\u8c31\u7684\u878d\u5408\u4e0e\u6e05\u6d17\u4e5f\u5f80\u5f80\u9762\u4e34\u77e5\u8bc6\u56fe\u8c31\u89c4\u6a21\u8d85\u5927\u7684\u95ee\u9898, \u8fd9\u4f1a\u9020\u6210\u6574\u4f53\u5f00\u9500\u5341\u5206\u5de8\u5927. \u53e6\u4e00\u65b9\u9762, \u6570\u636e\u6e90\u7684\u5f02\u6784\u4ee5\u53ca\u6837\u672c\u5206\u5e03\u4e0d\u5747\u8861\u5f80\u5f80\u5bfc\u81f4\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7684\u7ed3\u679c\u8d28\u91cf\u4e0d\u4e00. \u6311\u9009\u673a\u5668\u6700\u4e0d\u64c5\u957f\u800c\u4eba\u6700\u64c5\u957f\u7684\u4efb\u52a1: \u4eba\u673a\u667a\u80fd\u662f\u6709\u7740\u663e\u8457\u5dee\u5f02\u7684, \u4eba\u64c5\u957f\u7406\u89e3\u5e38\u8bc6\u800c\u673a\u5668\u4e0d\u64c5\u957f; \u4eba\u64c5\u957f\u7406\u89e3\u4f3c\u662f\u800c\u975e\u7684\u4e8b\u5b9e, \u673a\u5668\u64c5\u957f\u5904\u7406\u7cbe\u786e\u7684\u77e5\u8bc6; \u4eba\u64c5\u957f\u7406\u89e3\u6982\u5ff5\u6027, \u6846\u67b6\u6027\u7684\u5143\u77e5\u8bc6, \u800c\u673a\u5668\u5728\u8fd9\u4e00\u65b9\u9762\u7684\u80fd\u529b\u4ecd\u7136\u5341\u5206\u6709\u9650. \u8865\u5145: \u5728\u4efb\u52a1\u6311\u9009\u4e2d, \u53ef\u4ee5\u901a\u8fc7\"\u4e0d\u786e\u5b9a\u56fe\"(Uncertain Graph)\u7684\u5efa\u6a21, \u5c06\u8282\u70b9\u4e4b\u95f4\u7684\u5173\u7cfb\u5efa\u6a21\u4e3a\u5e26\u6709\u7f6e\u4fe1\u5ea6\u7684\u8fb9, \u6700\u540e\u901a\u8fc7\u8fb9\u6982\u7387\u7684\u9009\u53d6\u6765\u6311\u9009\u51fa\u54ea\u4e9b\u4efb\u52a1\u9700\u8981\u88ab\u4f17\u5305.","title":"What(\u5bf9\u4ec0\u4e48\u4efb\u52a1\u8fdb\u884c\u4f17\u5305)"},{"location":"6_3.html#whom","text":"\u4f17\u5305\u4efb\u52a1\u6709\u4e24\u79cd\u4e0d\u540c\u7684\u53d1\u5305\u65b9\u5f0f: \u88ab\u52a8\u4f17\u5305: \u662f\u6307\u53d1\u5305\u65b9\u5c06\u4efb\u52a1\u6302\u5728\u4f17\u5305\u5e73\u53f0\u4e0a, \u7531\u5de5\u4eba\u6765\u8ba4\u9886\u4efb\u52a1\u5e76\u5b8c\u6210, \u53d1\u5305\u65b9\u4e0d\u5bf9\u5de5\u4eba\u505a\u8fc7\u591a\u9009\u62e9, \u6700\u591a\u8bbe\u8ba1\u4e00\u5957\u6d4b\u8bd5\u9898\u6765\u9a8c\u8bc1\u5de5\u4eba\u7684\u8d44\u683c. \u4e3b\u52a8\u4f17\u5305: \u662f\u6307\u7531\u53d1\u5305\u65b9\u901a\u8fc7\u4e00\u7cfb\u5217\u7b97\u6cd5\u7cbe\u5fc3\u6311\u9009\u5de5\u4eba\u5b9e\u73b0\u4efb\u52a1\u7684\u5206\u914d. \u5f53\u524d\u5927\u89c4\u6a21\u7684\u4f17\u5305\u5e73\u53f0, \u5982\u4e9a\u9a6c\u900a\u7684Mechanical Turk, \u963f\u91cc\u4f17\u5305\u7b49, \u5747\u91c7\u7528\u88ab\u52a8\u4f17\u5305\u7684\u65b9\u5f0f\u5206\u914d\u4efb\u52a1. \u4e3b\u8981\u539f\u56e0\u662f\u5176\u4e0a\u7684\u5927\u90e8\u5206\u4efb\u52a1\u7684\u5b8c\u6210\u95e8\u69db\u8f83\u4f4e, \u4e14\u5e73\u53f0\u7528\u6237\u6570\u91cf\u5e9e\u5927, \u96be\u4ee5\u6709\u6548\u7b5b\u9009. \u53cd\u4e4b, \u5728\u67d0\u4e9b\u8d28\u91cf\u6538\u5173\u4e14\u6240\u9700\u5de5\u4eba\u8f83\u5c11\u7684\u7279\u6b8a\u4efb\u52a1\u4e2d, \u9700\u8981\u91c7\u7528\u4e3b\u52a8\u4f17\u5305\u7684\u65b9\u5f0f, \u5bf9\u5de5\u4eba\u7cbe\u6311\u7ec6\u9009, \u5982\u9879\u76ee\u8bc4\u5ba1, \u4ee3\u7801\u4f17\u5305\u7b49. \u76ee\u524d\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u7814\u7a76\u70ed\u70b9\u4e3b\u8981\u96c6\u4e2d\u5728\u4e3b\u52a8\u4f17\u5305\u4e0a. \u51b7\u542f\u52a8\u95ee\u9898: \u4e0e\u63a8\u8350\u7cfb\u7edf\u4e00\u6837, \u4e3b\u52a8\u4f17\u5305\u7684\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u662f\u51b7\u542f\u52a8\u95ee\u9898. \u53ef\u4ee5\u91c7\u7528\u8fc1\u79fb\u5b66\u4e60\u7684\u65b9\u6cd5\u5c06\u5de5\u4eba\u5728\u67d0\u4e00\u9886\u57df\u7684\u7ecf\u9a8c\u8fc1\u79fb\u5230\u6570\u636e\u7a00\u7f3a\u7684\u9886\u57df, \u6bd4\u5982, \u5bf9\"\u53e3\u7ea2\"\u719f\u6089\u7684\u5de5\u4eba\u4e5f\u8bb8\u5bf9\"\u9ad8\u8ddf\u978b\"\u4e5f\u719f\u6089, \u56e0\u6b64\u53ef\u4ee5\u5c06\u5de5\u4eba\u5bf9\"\u53e3\u7ea2\"\u76f8\u5173\u95ee\u9898\u7684\u56de\u7b54\u8fc1\u79fb\u5230\u5bf9\"\u9ad8\u8ddf\u978b\"\u76f8\u5173\u95ee\u9898\u7684\u56de\u7b54\u4e2d. \u8fd9\u79cd\u65b9\u6cd5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u89e3\u51b3\u4e86\u51b7\u542f\u52a8\u95ee\u9898, \u53ef\u4ee5\u5e94\u7528\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u4f17\u5305\u6784\u5efa.","title":"Whom(\u5c06\u4efb\u52a1\u4ea4\u7ed9\u8c01\u5b8c\u6210)"},{"location":"6_3.html#how","text":"\u5f53\u524d\u5de5\u4e1a\u754c\u7ecf\u8fc7\u591a\u5e74\u7684\u5b9e\u8df5\u7ecf\u9a8c, \u5df2\u7ecf\u5c06\u4f17\u5305\u8fc7\u7a0b\u8fdb\u884c\u4e86\u9ad8\u6548\u7684\u8c03\u6574, \u4e3b\u8981\u5305\u62ec3\u4e2a\u65b9\u9762: \u5982\u4f55\u8bbe\u8ba1\u4efb\u52a1 \u5982\u4f55\u6fc0\u52b1\u5de5\u4eba \u5982\u4f55\u63a7\u5236\u8d28\u91cf","title":"How(\u5982\u4f55\u5b8c\u6210\u4f17\u5305)"},{"location":"6_3.html#_6","text":"\u4ece\u5de5\u4eba\u7684\u89c6\u89d2\u6765\u770b, \u4f17\u5305\u4efb\u52a1\u53ef\u4ee5\u5206\u4e3a\u663e\u5f0f\u4f17\u5305\u548c\u9690\u5f0f\u4f17\u5305: \u663e\u5f0f\u4f17\u5305: \u662f\u6307\u5de5\u4eba\u5728\u5b8c\u6210\u4f17\u5305\u4efb\u52a1\u65f6\u77e5\u6653\u81ea\u5df1\u6b63\u5728\u5b8c\u6210\u4f17\u5305\u4efb\u52a1. \u9690\u5f0f\u4f17\u5305: \u662f\u6307\u5de5\u4eba\u5728\u4e0d\u77e5\u4e0d\u89c9\u4e2d\u5b8c\u6210\u4f17\u5305\u4efb\u52a1. \u76ee\u524d\u5de5\u4e1a\u754c\u7684\u4f17\u5305\u5e73\u53f0\u5927\u591a\u6570\u91c7\u7528\u663e\u5f0f\u4f17\u5305, \u5de5\u4eba\u5b8c\u6210\u4efb\u52a1\u7684\u76ee\u7684\u4e5f\u4e3b\u8981\u662f\u4e3a\u4e86\u83b7\u5f97\u91d1\u94b1\u62a5\u916c. \u663e\u5f0f\u4f17\u5305\u9886\u57df\u6709\u4e00\u4e9b\u516c\u8ba4\u7684\u8bbe\u8ba1\u539f\u5219: \u504f\u597d\u66f4\u5c0f\u7684\u4efb\u52a1 \u5224\u65ad\u9898\u4f18\u4e8e\u9009\u62e9\u9898 \u5de5\u4eba\u4e0d\u559c\u6b22\u6709\u5927\u91cf\u4ea4\u4e92\u5408\u4f5c\u7684\u4efb\u52a1","title":"\u5982\u4f55\u8bbe\u8ba1\u4efb\u52a1"},{"location":"6_3.html#_7","text":"\u76ee\u524d\u5de5\u4e1a\u754c\u5e38\u7528\u7684\u6fc0\u52b1\u673a\u5236\u6709\u4ee5\u4e0b\u56db\u79cd: \u540d\u8a89\u5ea6 \u5feb\u4e50\u611f \u91d1\u94b1\u6fc0\u52b1 \u793e\u4ea4\u5f71\u54cd \u6700\u91cd\u8981\u7684\u91d1\u94b1\u6fc0\u52b1\u6709\u4e09\u7c7b: \u9759\u6001\u5956\u52b1 \u52a8\u6001\u5956\u52b1 \u6761\u4ef6\u5956\u52b1 \u7814\u7a76\u8f83\u591a\u7684\u793e\u4ea4\u5f71\u54cd\u6709\u4e24\u7c7b: \u5f3a\u8fde\u63a5\u7f51\u7edc: \u5fae\u4fe1, Facebook \u5f31\u8fde\u63a5\u7f51\u7edc: \u767e\u5ea6\u8d34\u5427, \u8bba\u575b \u7efc\u4e0a\u6240\u8ff0: \u4e3a\u4e86\u66f4\u6709\u6548\u7684\u6fc0\u53d1\u5de5\u4eba\u4e3b\u89c2\u80fd\u52a8\u6027, \u53ef\u4ee5\u6df7\u5408\u4f7f\u7528\u4e0a\u8ff0\u591a\u79cd\u6fc0\u52b1\u673a\u5236. \u6bd4\u5982, \u4efb\u52a1\u5f00\u59cb\u9636\u6bb5, \u4f7f\u7528\u5f3a\u8fde\u63a5\u7f51\u7edc\u548c\u91d1\u94b1\u6fc0\u52b1\u5438\u5f15\u5927\u91cf\u5de5\u4eba\u6ce8\u610f\u5230\u6b64\u4efb\u52a1. \u540e\u7eed\u53ef\u4ee5\u901a\u8fc7\u7559\u5b58\u7528\u6237, \u91c7\u7528\u540d\u8a89\u5ea6, \u5feb\u4e50\u611f\u7b49\u865a\u62df\u673a\u5236\u8282\u7701\u5f00\u9500.","title":"\u5982\u4f55\u6fc0\u52b1\u5de5\u4eba"},{"location":"6_3.html#_8","text":"\u77e5\u8bc6\u578b\u4f17\u5305\u6700\u5927\u7684\u95ee\u9898\u4e4b\u4e00\u5c31\u662f\u8d28\u91cf\u63a7\u5236, \u56e0\u4e3a\u53d1\u5305\u65b9\u4e5f\u6ca1\u6709\u4efb\u52a1\u7684\u6807\u51c6\u7b54\u6848, \u53ea\u80fd\u51ed\u501f\u5de5\u4eba\u8fd4\u56de\u7684\u7ed3\u679c\u63a8\u65ad\u51fa\u771f\u5b9e\u7684\u7b54\u6848. \u800c\u540c\u65f6\u5de5\u4eba\u7684\u7d20\u8d28\u548c\u6c34\u5e73\u53c8\u53c2\u5dee\u4e0d\u9f50, \u6240\u4ee5\u8d28\u91cf\u63a7\u5236\u5c31\u6210\u4e86\u5f88\u96be\u7684\u95ee\u9898. \u4e3b\u8981\u5206\u62103\u9636\u6bb5\u6765\u63a7\u5236: \u4f17\u5305\u524d\u7684\u8d28\u91cf\u63a7\u5236: \u4e3b\u8981\u662f\u5728\u4efb\u52a1\u53d1\u5305\u524d\u5236\u5b9a\u597d\u7684\u4efb\u52a1\u8bbe\u8ba1\u7b56\u7565\u548c\u6fc0\u52b1\u5206\u914d\u7b56\u7565. \u4f17\u5305\u8fc7\u7a0b\u4e2d\u7684\u8d28\u91cf\u63a7\u5236: \u662f\u6307\u5728\u4f17\u5305\u8fc7\u7a0b\u4e2d\u901a\u8fc7\u8bbe\u8ba1\u4e00\u4e9b\u7cbe\u7ec6\u7684\u8fc7\u7a0b\u63d0\u5347\u4f17\u5305\u4efb\u52a1\u5b8c\u6210\u7684\u8d28\u91cf. \u4f17\u5305\u540e\u7684\u8d28\u91cf\u63a7\u5236: \u662f\u6307\u5728\u83b7\u53d6\u4eba\u5de5\u8fd4\u56de\u7684\u7b54\u6848\u540e\u7efc\u5408\u63a8\u65ad\u51fa\u771f\u5b9e\u7684\u7ed3\u679c.","title":"\u5982\u4f55\u63a7\u5236\u8d28\u91cf"},{"location":"6_3.html#_9","text":"\u5728\u6784\u5efa\u4e0e\u7cbe\u5316\u77e5\u8bc6\u56fe\u8c31\u7684\u8fc7\u7a0b\u4e2d, \u6709\u4e09\u4e2a\u9636\u6bb5\u662f\u9700\u8981\u4eba\u5de5\u4ecb\u5165\u7684: \u672c\u4f53\u6784\u5efa\u9636\u6bb5 \u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u9636\u6bb5 \u77e5\u8bc6\u56fe\u8c31\u7cbe\u5316\u9636\u6bb5","title":"\u57fa\u4e8e\u4f17\u5305\u7684\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa"},{"location":"6_3.html#_10","text":"\u5728\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u4e4b\u521d, \u672c\u4f53\u8bbe\u8ba1\u662f\u4e0d\u53ef\u6216\u7f3a\u7684\u73af\u8282, \u6784\u5efa\u597d\u672c\u4f53\u540e, \u518d\u4ece\u6570\u636e\u4e2d\u62bd\u53d6\u5b9e\u4f8b\u6302\u63a5\u5230\u6982\u5ff5\u4e4b\u4e0b. \u5b9e\u4f8b\u4e4b\u95f4\u8fd8\u53ef\u4ee5\u7ee7\u627f\u672c\u4f53\u4e2d\u5bf9\u5e94\u7684\u6982\u5ff5\u4e0e\u6982\u5ff5\u4e4b\u95f4\u7684\u5173\u7cfb.","title":"\u672c\u4f53\u6784\u5efa\u9636\u6bb5"},{"location":"6_3.html#_11","text":"\u672c\u4f53\u8bbe\u8ba1\u5b8c\u6210\u540e, \u9700\u8981\u7528\u81ea\u52a8\u5316\u7684\u624b\u6bb5\u4ece\u5927\u89c4\u6a21\u6587\u672c\u4e2d\u62bd\u53d6\u77e5\u8bc6, \u4eba\u5de5\u4ecb\u5165\u7684\u4e24\u4e2a\u4f18\u52bf\u4efb\u52a1: \u4e09\u5143\u7ec4\u62bd\u53d6 \u5b9e\u4f53\u5bf9\u9f50 \u4e09\u5143\u7ec4\u62bd\u53d6: \u76ee\u524d\u5b66\u672f\u754c, \u5de5\u4e1a\u754c\u5173\u4e8e\u4e09\u5143\u7ec4\u62bd\u53d6\u4efb\u52a1, \u4e3b\u8981\u67092\u79cd\u65b9\u6cd5, \u57fa\u4e8e\u89c4\u5219\u6d3e\u7684\u65b9\u6cd5\u548c\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5, \u4f46\u90fd\u65e0\u6cd5\u907f\u514d\u9519\u8bef. \u4f17\u5305\u5e73\u53f0\u5c06\u4e0e\u771f\u5b9e\u4e09\u5143\u7ec4\u76f8\u5173\u7684\u4e0a\u4e0b\u6587\u878d\u5165\u95ee\u9898\u4e2d, \u5e76\u751f\u6210\u9009\u62e9\u9898\u7684\u9898\u76ee, \u5e76\u7ed9\u51fa\u82e5\u5e72\u4e2a\u5019\u9009\u7b54\u6848. \u6ce8\u610f: \u4e4b\u6240\u4ee5\u91c7\u7528\u9009\u62e9\u9898\u7684\u65b9\u5f0f\u8fdb\u884c\u4f17\u5305, \u662f\u4e3a\u4e86\u9632\u6b62\u5f00\u653e\u6027\u95ee\u9898\u9020\u6210\u4f17\u5305\u7b54\u6848\u4e94\u82b1\u516b\u95e8\u800c\u96be\u4ee5\u7edf\u4e00! \u5b9e\u4f53\u5bf9\u9f50: \u5b9e\u4f53\u5bf9\u9f50\u662f\u77e5\u8bc6\u578b\u4f17\u5305\u4e2d\u6700\u5e38\u89c1\u7684\u4efb\u52a1\u4e4b\u4e00, \u662f\u4e00\u9879\u5178\u578b\u7684\u4eba\u64c5\u957f\u800c\u673a\u5668\u4e0d\u5bb9\u6613\u51c6\u786e\u5b8c\u6210\u7684\u4efb\u52a1. \u6bd4\u5982, \u4eba\u53ef\u4ee5\u5f88\u5bb9\u6613\u7684\u628a\"\u82f9\u679c iPad 4\"\u548c\"\u82f9\u679c\u5e73\u677f\u7535\u81114\u4ee3\"\u5bf9\u5e94\u8d77\u6765, \u800c\u673a\u5668\u5374\u5f88\u96be\u505a\u5230. \u5b9e\u4f53\u5bf9\u9f50\u4efb\u52a1\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u96be\u70b9: \u4e92\u8054\u7f51\u4e2d\u65b0\u7684\u5b9e\u4f53\u5c42\u51fa\u4e0d\u7a77, \u8bad\u7ec3\u96c6\u5f88\u96be\u8986\u76d6\u8fd9\u4e9b\u65b0\u5b9e\u4f53. \u5b9e\u4f53\u7684\u7ed3\u6784\u590d\u6742, \u4e0d\u89c4\u8303, \u5f88\u96be\u7528\u89c4\u5219\u6a21\u677f\u6765\u9002\u914d. \u5b9e\u4f53\u8868\u8ff0\u4e00\u822c\u8f83\u77ed, \u9700\u8981\u7ed3\u5408\u4e0a\u4e0b\u6587\u6765\u5224\u65ad\u548c\u8bc6\u522b. \u4eba\u8111\u7531\u4e8e\u6709\u66f4\u5f3a\u5927\u7684\u8ba4\u77e5\u80fd\u529b\u548c\u66f4\u4e30\u5bcc\u7684\u5e38\u8bc6\u50a8\u5907, \u6240\u4ee5\u53ef\u4ee5\u975e\u5e38\u8f7b\u677e, \u51c6\u786e\u7684\u5b8c\u6210\u5b9e\u4f53\u5bf9\u9f50\u4efb\u52a1.","title":"\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u9636\u6bb5"},{"location":"6_3.html#_12","text":"\u5728\u77e5\u8bc6\u56fe\u8c31\u7cbe\u5316\u8fc7\u7a0b\u4e2d\u5f15\u5165\u4f17\u5305, \u53ef\u4ee5\u63d0\u9ad8\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u8fc7\u7a0b\u7684\u51c6\u786e\u5ea6\u548c\u8986\u76d6\u5ea6. \u67d0\u4e9b\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u9519\u8bef\u6216\u8005\u7f3a\u5931, \u53ef\u4ee5\u501f\u52a9\u7528\u6237\u5728\u5e94\u7528\u540e\u7684\u53cd\u9988\u6765\u5b8c\u6210. \u5229\u7528\u4f17\u5305\u65b9\u5f0f\u5b9e\u73b0\u77e5\u8bc6\u7cbe\u5316\u7684\u5178\u578b\u6848\u4f8b: Cyc OpenMind","title":"\u77e5\u8bc6\u56fe\u8c31\u7cbe\u5316\u9636\u6bb5"},{"location":"7_1.html","text":"\u77e5\u8bc6\u56fe\u8c31\u5efa\u6a21\u4e0e\u5b58\u50a8 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u77e5\u8bc6\u56fe\u8c31\u7684\u76f8\u5173\u6570\u636e\u6a21\u578b. \u7406\u89e3\u77e5\u8bc6\u56fe\u8c31\u7684\u4e3b\u6d41\u7269\u7406\u5b58\u50a8\u65b9\u6cd5\u548c\u539f\u7406. \u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u5e94\u7528\u7684\u524d\u63d0\u662f, \u8fd9\u4e9b\u6570\u636e\u7684\u6709\u6548\u8868\u793a\u4e0e\u5b58\u50a8. \u903b\u8f91\u5c42\u9762\u7684\u8868\u793a(\u5373\u6570\u636e\u6a21\u578b)\u662f\u4ece\u4eba\u7684\u89d2\u5ea6\u5bf9\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u8fdb\u884c\u63cf\u8ff0, \u7269\u7406\u5c42\u9762\u7684\u5b58\u50a8\u65f6\u4ece\u8ba1\u7b97\u673a\u7684\u89d2\u5ea6\u5bf9\u6570\u636e\u8fdb\u884c\u7ec4\u7ec7, \u4e24\u8005\u5bc6\u5207\u76f8\u5173. \u77e5\u8bc6\u56fe\u8c31\u7684\u6570\u636e\u6a21\u578b \u00b6 \u5b8f\u89c2\u6765\u770b, \u77e5\u8bc6\u56fe\u8c31\u7684\u6570\u636e\u6a21\u578b\u5305\u542b\u4e24\u5927\u7c7b: \u4e09\u5143\u7ec4\u6a21\u578b \u56fe\u6a21\u578b \u4e09\u5143\u7ec4\u6a21\u578b \u00b6 \u8fd9\u662f\u6211\u4eec\u6700\u4e3a\u719f\u6089\u7684\u6a21\u578b, \u6bd4\u5982\u7ecf\u5178\u4f8b\u5b50, (\"\u67cf\u62c9\u56fe\", \"\u51fa\u751f\u5730\", \"\u96c5\u5178\"), \u5c06\u4e24\u4e2a\u5b9e\u4f53\u548c\u4ed6\u4eec\u4e4b\u95f4\u7684\u5173\u7cfb\u5171\u540c\u7ec4\u6210\u4e00\u4e2a\u4e09\u5143\u7ec4. \u56e0\u6b64\u4e00\u4e2a\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u96c6\u53ef\u4ee5\u770b\u505a\u662f\u4e00\u4e2a\u4e09\u5143\u7ec4\u7684\u96c6\u5408. \u9664\u4e86\u4e0a\u8ff0\u6211\u4eec\u6700\u4e3a\u719f\u6089\u7684\u4e09\u5143\u7ec4\u6a21\u5f0f, \u5728\u77e5\u8bc6\u56fe\u8c31\u7684\u5b9e\u9645\u5e94\u7528\u4e2d, \u5e38\u5e38\u8fd8\u9700\u8981\u8868\u8fbe\u4e00\u4e9b\u76f8\u5bf9\u590d\u6742\u7684\u8bed\u4e49, \u5305\u62ec\u591a\u5143\u5173\u7cfb, \u65f6\u7a7a\u77e5\u8bc6, \u591a\u6a21\u6001\u77e5\u8bc6\u4ee5\u53ca\u5bf9\u8c61\u77e5\u8bc6\u7b49. \u4f8b\u5982: \u6211\u4eec\u5411\u4e09\u5143\u7ec4(\"\u4e9a\u91cc\u58eb\u591a\u5fb7\", \"\u5bfc\u5e08\", \"\u67cf\u62c9\u56fe\")\u4e2d\u6dfb\u52a0\u65f6\u7a7a\u7ebf\u7d22\u4fe1\u606f, \u5219\u53d8\u6210\u4e86\u4e94\u5143\u7ec4\u7684\u5f62\u5f0f(\"\u4e9a\u91cc\u58eb\u591a\u5fb7\", \"\u5bfc\u5e08\", \"\u67cf\u62c9\u56fe\", \"(\u5317\u7eac38\u00b002\u2032, \u4e1c\u7ecf23\u00b044\u2032)\", \"\u516c\u5143\u524d407\u5e74\"). \u4f8b\u5982: \u6211\u4eec\u5411\u4e09\u5143\u7ec4(\"\u67cf\u62c9\u56fe\", \"\u51fa\u751f\u5730\", \"\u96c5\u5178\")\u4e2d\u6dfb\u52a0\u56fe\u7247\u8d44\u6e90\u94fe\u63a5\u7684\u5173\u7cfb\u4fe1\u606f, \u5219\u53d8\u6210\u4e86\u56db\u5143\u7ec4\u7684\u5f62\u5f0f(\"\u67cf\u62c9\u56fe\", \"\u51fa\u751f\u5730\", \"\u96c5\u5178\", \"http://***.com/foaf/0.1/depiction\", \"wikiFile:Plato_MC1355.jpg\"). \u603b\u7ed3: \u4e09\u5143\u7ec4\u6a21\u578b\u7684\u4f18\u70b9\u5728\u4e8e\u6a21\u578b\u7b80\u5355, \u6613\u4e8e\u6269\u5c55, \u4f7f\u5f97\u57fa\u4e8e\u8fd9\u4e00\u6a21\u578b\u6784\u5efa\u5927\u89c4\u6a21\u6570\u636e\u96c6\u6210\u4e3a\u53ef\u80fd. \u4f46\u662f\u4e09\u5143\u7ec4\u6a21\u578b\u7684\u5c40\u9650\u6027\u4e5f\u5f88\u660e\u663e, \u4e3b\u8981\u662f\u5bf9\u4e8e\u6240\u6709\u77e5\u8bc6\u90fd\u53ea\u80fd\u62c6\u5206\u6210\u4e8c\u5143\u5173\u7cfb\u7684\u7ec4\u5408, \u96be\u4ee5\u8868\u8fbe\u590d\u6742\u8bed\u4e49. \u4e09\u5143\u7ec4\u4e3b\u8981\u8868\u8fbe\u7684\u662f\u4e8b\u5b9e\u6027\u77e5\u8bc6, \u5bf9\u4e8e\u4e8b\u7406\u903b\u8f91\u7684\u8868\u8fbe\u80fd\u529b\u6709\u9650, \u96be\u4ee5\u6709\u6548\u652f\u6491\u903b\u8f91\u63a8\u7406. \u5728\u5b9e\u9645\u5e94\u7528\u4e2d, \u9700\u8981\u8054\u5408\u4f7f\u7528\u5176\u4ed6\u77e5\u8bc6\u8868\u793a, \u5305\u62ec\u8c13\u8bcd\u903b\u8f91, \u5e76\u7ed9\u4e88\u4e09\u5143\u7ec4\u77e5\u8bc6\u5f00\u5c55\u6709\u6548\u7684\u63a8\u7406. \u56fe\u6a21\u578b \u00b6 \u77e5\u8bc6\u56fe\u8c31\u66f4\u52a0\u5929\u7136\u7684\u9002\u914d\u4e8e\u56fe\u6a21\u578b, \u5728\u5b9e\u9645\u5e94\u7528\u4e2d, \u7ecf\u5e38\u5c06\u4e09\u5143\u7ec4\u6570\u636e\u901a\u8fc7\u9884\u5148\u5b9a\u4e49\u7684\u8bed\u4e49\u5173\u8054\u8f6c\u6362\u6210\u4e00\u4e2a\u6216\u591a\u4e2a\u8fde\u901a\u56fe, \u6574\u4e2a\u77e5\u8bc6\u56fe\u8c31\u5c31\u53ef\u4ee5\u8868\u793a\u6210\u4e00\u5f20\u5de8\u5927\u7684\"\u56fe\"\u4e86. \u4e3b\u6d41\u7684\u8868\u8fbe\u65b9\u5f0f: \u6709\u5411\u56fe: \u5de5\u4e1a\u754c\u6700\u5e38\u7528\u7684\u6a21\u5f0f \u767e\u79d1\u56fe\u8c31DBPedia \u4e2d\u6587\u767e\u79d1\u56fe\u8c31CN-DBPedia \u836f\u54c1\u77e5\u8bc6\u56fe\u8c31Drugbank \u86cb\u767d\u8d28\u77e5\u8bc6\u56fe\u8c31UniPort \u5730\u7406\u4fe1\u606f\u77e5\u8bc6\u56fe\u8c31LinkedGeoData \u5c5e\u6027\u56fe: \u56fe\u6570\u636e\u5e93\u5de5\u4e1a\u754c\u5e7f\u6cdb\u91c7\u7528\u7684\u6a21\u5f0f \u6811\u72b6\u56fe: WordNet \u6709\u5411\u56fe: \u5e94\u7528\u9762\u4e5f\u5f88\u5e7f Probase YAGO \u77e5\u8bc6\u56fe\u8c31\u7684\u7269\u7406\u5b58\u50a8 \u00b6 \u76ee\u524d\u5de5\u4e1a\u754c\u7684\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u7684\u5b58\u50a8\u65b9\u5f0f\u5206\u4e3a\u4e24\u7c7b: \u57fa\u4e8e\u5173\u7cfb\u6a21\u578b\u7684\u5b58\u50a8 \u57fa\u4e8e\u56fe\u6a21\u578b\u7684\u5b58\u50a8 \u590d\u6742\u67e5\u8be2\u7684\u4f18\u5316\u95ee\u9898\u662f\u77e5\u8bc6\u56fe\u8c31\u7ba1\u7406\u7cfb\u7edf\u7684\u6838\u5fc3\u95ee\u9898\u4e4b\u4e00, \u53ef\u4ee5\u501f\u9274\u4f20\u7edf\u5173\u7cfb\u578b\u6570\u636e\u5e93\u4e2d\u7684SQL\u67e5\u8be2\u7684\u8ba1\u5212\u751f\u6210\u548c\u67e5\u8be2\u4f18\u5316\u7b56\u7565. \u5728\u5b9e\u9645\u5e94\u7528\u4e2d, \u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u7684\u67e5\u8be2\u8fd0\u7b97\u901a\u5e38\u5448\u73b0\u51fa\u5982\u4e0b\u7279\u70b9: \u9009\u62e9\u5ea6\u9ad8: \u77e5\u8bc6\u56fe\u8c31\u4e2d\u5e38\u89c1\u9009\u62e9\u64cd\u4f5c\u7684\u7b54\u6848\u4ec5\u6d89\u53ca\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5f88\u5c11\u7684\u4e09\u5143\u7ec4. \u8fde\u63a5\u6570\u91cf\u591a: \u77e5\u8bc6\u56fe\u8c31\u4e2d\u5e38\u89c1\u7684\u8fd0\u7b97\u7ecf\u5e38\u4f1a\u5305\u542b\u5927\u91cf\u7684\u8fde\u63a5\u64cd\u4f5c. \u5173\u7cfb\u8868\u5b58\u50a8 \u00b6 \u8003\u8651\u5230\u5e02\u9762\u4e0a\u5df2\u7ecf\u5b58\u5728\u5927\u91cf\u6210\u719f\u7684\u5173\u7cfb\u578b\u6570\u636e\u5e93\u7cfb\u7edf, \u800c\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u7684\u4e09\u5143\u7ec4\u5f88\u5bb9\u6613\u6620\u5c04\u5230\u5173\u7cfb\u6a21\u578b\u4e0a. \u90a3\u4e48\u57fa\u4e8e\u5173\u7cfb\u8868\u5bf9\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u8fdb\u884c\u7ec4\u7ec7\u7684\u65b9\u5f0f\u53ef\u4ee5\u5206\u6210\u56db\u7c7b: \u57fa\u4e8e\u4e09\u5217\u8868\u7684\u5b58\u50a8\u65b9\u5f0f \u57fa\u4e8e\u5c5e\u6027\u8868\u7684\u5b58\u50a8\u65b9\u5f0f \u57fa\u4e8e\u5782\u76f4\u8868\u7684\u5b58\u50a8\u65b9\u5f0f \u57fa\u4e8e\u5168\u7d22\u5f15\u7684\u5b58\u50a8\u65b9\u5f0f \u4e09\u5217\u8868\u5b58\u50a8 \u00b6 \u901a\u8fc7\u7ef4\u62a4\u4e00\u4e2a\u5de8\u5927\u7684\u4e09\u5143\u7ec4\u8868\u6765\u7ba1\u7406RDF\u77e5\u8bc6\u56fe\u8c31\u6570\u636e, \u8fd9\u4e2a\u4e09\u5143\u7ec4\u8868\u5305\u542b3\u5217, \u5206\u522b\u5bf9\u5e94\u4e3b\u4f53, \u8c13\u8bcd, \u5ba2\u4f53(\u5373SPO). \u5f53\u7cfb\u7edf\u63a5\u6536\u5230\u7528\u6237\u8f93\u5165\u7684\u67e5\u8be2\u8bf7\u6c42\u65f6, \u7cfb\u7edf\u5c06\u8be5\u67e5\u8be2\u8f6c\u6362\u4e3aSQL\u67e5\u8be2. \u8fd9\u4e9bSQL\u67e5\u8be2\u901a\u5e38\u9700\u8981\u5bf9\u4e09\u5143\u7ec4\u8868\u6267\u884c\u591a\u6b21\u81ea\u8fde\u63a5\u64cd\u4f5c(self-join)\u4ee5\u5f97\u5230\u6700\u7ec8\u7ed3\u679c. \u6838\u5fc3: \u4f7f\u7528\u4e00\u4e2a\u5de8\u5927\u7684\u4e09\u5143\u7ec4\u8868, \u9762\u4e34\u4e00\u4e2a\u5de8\u5927\u7684\u4ee3\u4ef7, \u7cfb\u7edf\u4e0d\u8bba\u6267\u884c\u4f55\u79cd\u64cd\u4f5c, \u90fd\u9700\u8981\u8fdb\u884c\u5168\u8868\u626b\u63cf!!! \u5de5\u4e1a\u754c\u7684\u89e3\u51b3\u65b9\u6848\u662f\u5efa\u7acb\u591a\u4e2a\u7d22\u5f15, \u4ee5\u589e\u52a0\u67e5\u8be2\u6548\u7387. \u4f46\u56e0\u4e3a\u77e5\u8bc6\u56fe\u8c31\u4e0a\u7684\u8fd0\u7b97\u7ecf\u5e38\u5305\u542b\u5927\u91cf\u7684\u8fde\u63a5\u64cd\u4f5c, \u800c\u8fd9\u79cd\u81ea\u8fde\u63a5\u64cd\u4f5c, \u7cfb\u7edf\u9700\u8981\u5c06\u4e09\u5217\u8868\u8fdb\u884c\u590d\u5236, \u7136\u540e\u518d\u4e24\u4e2a\u5de8\u5927\u7684\u4e09\u5217\u8868\u4e0a\u8fdb\u884c\u8fde\u63a5, \u975e\u5e38\u8017\u65f6. \u5c5e\u6027\u8868\u5b58\u50a8 \u00b6 \u4e3a\u4e86\u51cf\u5c11\u81ea\u8fde\u63a5\u64cd\u4f5c\u7684\u6b21\u6570, \u5f88\u591a\u77e5\u8bc6\u56fe\u8c31\u7ba1\u7406\u7cfb\u7edf\u5728\u5355\u4e2a\u4e09\u5143\u7ec4\u8868\u5916, \u8fd8\u6784\u5efa\u4e86\u989d\u5916\u7684\u5c5e\u6027\u8868\u6765\u7ba1\u7406\u6570\u636e, \u6709\u4e24\u5927\u7c7b: \u5206\u7c7b\u5c5e\u6027\u8868: \u6839\u636e\u5b9e\u4f53\u7c7b\u578b\u5c06\u4e09\u5143\u7ec4\u5206\u7c7b, \u76f8\u540c\u7c7b\u7684\u4e09\u5143\u7ec4\u653e\u5728\u540c\u4e00\u4e2a\u8868\u4e2d. \u805a\u7c7b\u5c5e\u6027\u8868: \u5c06\u76f8\u4f3c\u7684\u4e09\u5143\u7ec4\u805a\u7c7b, \u7136\u540e\u5c06\u6bcf\u7c7b\u4e09\u5143\u7ec4\u96c6\u4e2d\u5728\u4e00\u4e2a\u5c5e\u6027\u8868\u4e2d\u8fdb\u884c\u7ba1\u7406. \u5de5\u4e1a\u754c\u7684\u7ecf\u5178\u6848\u4f8b\u5f53\u5c5eJena: \u4e09\u5217\u8868 (s p o) \u5355\u503c\u5c5e\u6027\u8868 / / / / \u4e3b\u952e ---\u591a\u503c\u5c5e\u6027\u8868 \\ \\ \\ \\ \u5c5e\u6027\u7c7b\u8868 Jena: \u9996\u5148\u7ef4\u62a4\u4e86\u4e00\u4e2a\u5de8\u5927\u7684\u4e09\u5143\u7ec4\u8868, \u6b64\u5916Jena\u8fd8\u7ef4\u62a4\u4e86\u4e09\u79cd\u5c5e\u6027\u8868: \u5355\u503c\u5c5e\u6027\u8868, \u591a\u503c\u5c5e\u6027\u8868, \u5c5e\u6027\u7c7b\u8868. \u5355\u503c\u5c5e\u6027\u8868\u662f\u5c06\u5b9e\u4f53\u4e2d\u6240\u6709\u5ba2\u4f53\u503c\u552f\u4e00\u7684\u8c13\u8bcd\u805a\u96c6\u8d77\u6765\u7ec4\u7ec7\u800c\u6210\u7684\u4e00\u4e2a\u8868; \u591a\u503c\u5c5e\u6027\u8868\u662f\u4e3a\u6bcf\u4e00\u4e2a\u5ba2\u4f53\u503c\u4e0d\u552f\u4e00\u7684\u8c13\u8bcd\u6784\u5efa\u7684\u53ea\u6709\u4e24\u5217\u7684\u8868, \u5206\u522b\u5b58\u50a8\u4e3b\u4f53\u503c\u548c\u5ba2\u4f53\u503c; \u5c5e\u6027\u503c\u8868\u662f\u5728\u5355\u503c\u5c5e\u6027\u8868\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u5b58\u50a8\u5b9e\u4f53\u7c7b\u578b\u5217\u7684\u8868. \u5782\u76f4\u8868\u5b58\u50a8 \u00b6 \u9488\u5bf9\u4e09\u5217\u8868\u548c\u5c5e\u6027\u8868\u8fde\u63a5\u64cd\u4f5c\u6548\u7387\u4f4e\u7684\u95ee\u9898, SW-Store\u63d0\u51fa\u4e86\u6309\u7167\u8c13\u8bcd\u5206\u8868\u7684\u65b9\u6cd5. \u5177\u4f53\u6765\u8bf4, \u5c06\u4e09\u5143\u7ec4\u6309\u7167\u8c13\u8bcd\u5206\u6210\u4e0d\u540c\u7684\u8868, \u6bcf\u4e2a\u8868\u4fdd\u5b58\u8c13\u8bcd\u76f8\u540c\u7684\u4e09\u5143\u7ec4, SW-Store\u79f0\u8fd9\u79cd\u65b9\u6cd5\u4e3a\u5782\u76f4\u5206\u5272. \u51fa\u751f\u65f6\u95f4 \u4e3b\u4f53 \u5ba2\u4f53 \u82cf\u683c\u62c9\u5e95 \u516c\u5143\u524d469\u5e74 \u67cf\u62c9\u56fe \u516c\u5143\u524d427\u5e74 # --------------------------------------- \u51fa\u751f\u5730 \u4e3b\u4f53 \u5ba2\u4f53 \u82cf\u683c\u62c9\u5e95 \u96c5\u5178 \u67cf\u62c9\u56fe \u96c5\u5178 # -------------------------------------- \u5b66\u751f \u4e3b\u4f53 \u5ba2\u4f53 \u82cf\u683c\u62c9\u5e95 \u67cf\u62c9\u56fe # -------------------------------------- \u4ee3\u8868\u4f5c\u54c1 \u4e3b\u4f53 \u5ba2\u4f53 \u67cf\u62c9\u56fe \u7406\u60f3\u56fd \u6ce8\u610f: \u5782\u76f4\u8868\u7684\u4e00\u5927\u7f3a\u70b9\u662f\u65e0\u6cd5\u5f88\u597d\u7684\u652f\u6301\u8c13\u8bcd\u662f\u53d8\u91cf\u7684\u67e5\u8be2\u64cd\u4f5c! \u6bd4\u5982, \u67e5\u8be2\"\u67cf\u62c9\u56fe\u548c\u82cf\u683c\u62c9\u5e95\u7684\u5173\u7cfb\", \u5c31\u9700\u8981\u626b\u63cf\u6240\u6709\u8868\u624d\u80fd\u56de\u7b54, \u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b. \u5168\u7d22\u5f15\u5b58\u50a8 \u00b6 \u9664\u4e86\u91c7\u7528\u4e00\u822c\u7684\u5173\u7cfb\u578b\u6570\u636e\u5e93\u76f8\u5173\u6280\u672f, \u8fd8\u6709\u4e00\u4e9b\u7cfb\u7edf\u9488\u5bf9\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u548c\u8fd0\u7b97\u7279\u70b9\u63d0\u51fa\u4e86\u7279\u5b9a\u7684\u4f18\u5316\u6280\u672f. \u4e3a\u4e86\u52a0\u901f\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u5728\u8fd0\u7b97\u8fc7\u7a0b\u4e2d\u7684\u8fde\u63a5\u8fd0\u7b97, \u5c06\u4e09\u5143\u7ec4\u4e2dSPO\u7684\u5404\u79cd\u6392\u5217\u60c5\u51b5\u90fd\u679a\u4e3e\u51fa\u6765, \u7136\u540e\u4e3a\u5b83\u4eec\u4e00\u4e00\u6784\u5efa\u7d22\u5f15. \u4e3b\u4f53, \u8c13\u8bcd, \u5ba2\u4f53\u7684\u6392\u5217\u60c5\u51b5\u5171\u8ba16\u79cd, \u6bd4\u5982\u9488\u5bf9\u4e8e(s, p, o), \u989d\u5916\u5b58\u50a85\u4e2a\u5bf9\u5e94\u7684\u4e09\u5143\u7ec4(s, o ,p), (p, s, o), (p, o, s), (o, s, p), (o, p, s). \u8fd9\u4e9b\u7d22\u5f15\u5185\u5bb9\u6b63\u597d\u5bf9\u5e94\u77e5\u8bc6\u56fe\u8c31\u8fd0\u7b97\u4e2d\u5e26\u53d8\u91cf\u7684\u4e09\u5143\u7ec4\u6a21\u5f0f\u7684\u5404\u79cd\u53ef\u80fd. \u6309\u7167\u4e0a\u8ff0\u65b9\u5f0f\u5efa\u7acb\u7684\u7d22\u5f15, \u4e0d\u8bba\u662f\u57fa\u4e8e\u4e3b\u4f53\u6765\u67e5\u8be2\u8c13\u8bcd\u548c\u5ba2\u4f53, \u8fd8\u662f\u57fa\u4e8e\u8c13\u8bcd\u6765\u67e5\u8be2\u4e3b\u4f53\u548c\u5ba2\u4f53, \u6291\u6216\u662f\u57fa\u4e8e\u5ba2\u4f53\u6765\u67e5\u8be2\u8c13\u8bcd\u548c\u4e3b\u4f53, \u7cfb\u7edf\u90fd\u80fd\u5f88\u5feb\u7684\u627e\u5230\u76f8\u5e94\u7684\u7ed3\u679c. \u6ce8\u610f: \u56e0\u4e3a\u6784\u5efa\u4e86\u5927\u91cf\u7d22\u5f15, \u6240\u4ee5\u9009\u53d6\u6ee1\u8db3\u67e5\u8be2\u6761\u4ef6\u7684\u4e09\u5143\u7ec4\u7684\u6548\u7387\u6781\u9ad8! \u4f46\u662f\u8fde\u63a5\u64cd\u4f5c\u4f9d\u7136\u4f4e\u6548, \u4e14\u7d22\u5f15\u7ef4\u62a4\u4e0e\u66f4\u65b0\u7684\u4ee3\u4ef7\u9ad8\u6602! \u56fe\u5b58\u50a8 \u00b6 \u9488\u5bf9\u4e8e\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u56fe\u6a21\u578b\u8868\u793a, \u5f88\u591a\u7cfb\u7edf\u8bbe\u8ba1\u4e86\u76f8\u5e94\u7684\u56fe\u5b58\u50a8\u6a21\u5f0f, \u4e3b\u8981\u6709\u4e24\u79cd: \u90bb\u63a5\u8868: \u6bcf\u4e2a\u8282\u70b9(\u5b9e\u4f53)\u5bf9\u5e94\u4e00\u4e2a\u5217\u8868, \u5217\u8868\u4e2d\u5b58\u50a8\u4e0e\u8be5\u5b9e\u4f53\u76f8\u5173\u7684\u4fe1\u606f. \u90bb\u63a5\u77e9\u9635: \u5728\u8ba1\u7b97\u673a\u4e2d\u7ef4\u62a4\u591a\u4e2a(n, n)\u7684\u77e9\u9635, \u5176\u4e2dn\u4e3a\u77e5\u8bc6\u56fe\u8c31\u4e2d\u8282\u70b9\u7684\u6570\u91cf. \u6bcf\u4e2a\u77e9\u9635\u5bf9\u5e94\u4e00\u4e2a\u8c13\u8bcd, \u6bcf\u4e00\u884c\u6216\u6bcf\u4e00\u5217\u90fd\u5bf9\u5e94\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u4e00\u4e2a\u8282\u70b9. \u4f18\u5316\u6280\u5de7: \u5728\u5229\u7528\u90bb\u63a5\u8868\u6216\u90bb\u63a5\u77e9\u9635\u8fdb\u884c\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u7ba1\u7406\u65f6, \u4e00\u4e2a\u5173\u952e\u95ee\u9898\u662f\u5982\u4f55\u5bf9\u6307\u6570\u5019\u9009\u7a7a\u95f4\u7684\u67e5\u8be2\u64cd\u4f5c\u505a\u51fa\u6709\u6548\u7684\u526a\u679d! \u4e00\u822c\u90fd\u91c7\u7528\u57fa\u4e8e\u4f4d\u56fe\u7d22\u5f15\u7684\u65b9\u5f0f, \u914d\u5408\u54c8\u5e0c\u8868, \u6bd4\u7279\u538b\u635f\u7b49\u6280\u672f, \u4f7f\u5f97\u67e5\u8be2\u6548\u7387\u975e\u5e38\u9ad8! \u9488\u5bf9\u5c5e\u6027\u56fe\u6a21\u578b, Neo4j\u516c\u53f8\u7528Java\u8bed\u8a00\u5f00\u53d1\u4e86\u56fe\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf-Neo4j, \u5b83\u662f\u4e00\u4e2a\u7b26\u5408ACID\u6807\u51c6\u7684\u4e8b\u52a1\u578b\u56fe\u6570\u636e\u5e93, Neo4j\u5df2\u7ecf\u6210\u4e3a\u5f53\u524d\u6700\u53d7\u6b22\u8fce\u7684\u56fe\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u4e4b\u4e00. \u5728Neo4j\u4e2d, \u5c5e\u6027\u56fe\u4e2d\u7684\u8282\u70b9, \u8fb9, \u4ee5\u53ca\u5c5e\u6027\u90fd\u4ee5\u56fa\u5b9a\u957f\u5ea6\u8bb0\u5f55\u7684\u5f62\u5f0f\u5206\u522b\u5b58\u50a8\u5728\u4e0d\u540c\u7684\u6587\u4ef6\u4e2d. \u8282\u70b9\u8bb0\u5f55\u7ef4\u62a4\u7740\u6307\u5411\u5176\u76f8\u90bb\u8fb9\u548c\u5c5e\u6027\u7684\u6307\u9488; \u8fb9\u8bb0\u5f55\u7ef4\u62a4\u7740\u6307\u5411\u5176\u76f8\u90bb\u63a5\u70b9\u548c\u5c5e\u6027\u7684\u6307\u9488; \u5c5e\u6027\u8bb0\u5f55\u7ef4\u62a4\u7740\u6307\u5411\u5176\u6240\u5bf9\u5e94\u7684\u5177\u4f53\u5c5e\u6027\u503c. \u6838\u5fc3: \u56e0\u4e3a\u4e0d\u8bba\u8282\u70b9\u8bb0\u5f55, \u8fb9\u8bb0\u5f55, \u8fd8\u662f\u5c5e\u6027\u8bb0\u5f55\u90fd\u662f\u56fa\u5b9a\u957f\u5ea6\u7684, \u6240\u4ee5Neo4j\u5728\u78c1\u76d8\u4e2d\u8bfb\u53d6\u6570\u636e\u65f6\u53ef\u4ee5\u5feb\u901f\u8ba1\u7b97\u51fa\u504f\u79fb\u91cf, \u4f7f\u5f97Neo4j\u7684\u8bfb\u53d6\u6548\u7387\u5f88\u9ad8. \u5206\u5e03\u5f0f\u5b58\u50a8 \u00b6 \u77e5\u8bc6\u56fe\u8c31\u7684\u89c4\u6a21\u65e5\u76ca\u589e\u957f, \u5343\u4ebf\u8282\u70b9\u89c4\u6a21\u7684\u77e5\u8bc6\u56fe\u8c31\u5df2\u7ecf\u5f97\u5230\u5e94\u7528. \u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e9b\u5de8\u5927\u56fe\u8c31\u7ed9\u5b58\u50a8\u5e26\u6765\u7684\u6311\u6218, \u8d8a\u6765\u8d8a\u591a\u7684\u5206\u5e03\u5f0f\u89e3\u51b3\u65b9\u6848\u4e5f\u5728\u8fc5\u901f\u53d1\u5c55. \u5178\u578b\u7684\u80fd\u591f\u652f\u6491SPARQL\u67e5\u8be2\u5904\u7406\u7684\u4e91\u8ba1\u7b97\u5e73\u53f0\u5305\u62ecHadoop, Spark\u7b49: Hadoop: \u57fa\u4e8e\u90bb\u63a5\u8868\u7684\u5b58\u50a8 Spark: \u57fa\u4e8e\u5782\u76f4\u8868\u7684\u5b58\u50a8 Hadoop\u662f\u6700\u5e38\u89c1\u7684\u5b58\u50a8\u77e5\u8bc6\u56fe\u8c31\u7684\u4e91\u8ba1\u7b97\u5e73\u53f0, \u57fa\u4e8eHadoop\u5e73\u53f0\u7684\u5b58\u50a8\u65b9\u5f0f\u9996\u5148\u5c06\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u8f6c\u6362\u4e3a\u5e73\u9762\u6587\u4ef6, \u7136\u540e\u5b58\u50a8\u5728Hadoop\u5206\u5e03\u5f0f\u6587\u4ef6\u7cfb\u7edfHDFS\u4e0a. \u4f8b\u5982, SHARD\u7cfb\u7edf\u4ee5\u4e09\u5143\u7ec4\u4e2d\u7684\u4e3b\u4f53\u4e3a\u4f9d\u636e\u5212\u5206\u6570\u636e, \u4e0e\u4e00\u4e2a\u4e3b\u4f53\u76f8\u5173\u7684\u6240\u6709\u4e09\u5143\u7ec4\u88ab\u805a\u96c6\u5230\u4e00\u8d77\u5e76\u5b58\u50a8\u4e3aHDFS\u6587\u4ef6\u4e2d\u7684\u4e00\u884c.","title":"7.1 \u77e5\u8bc6\u56fe\u8c31\u5efa\u6a21\u4e0e\u5b58\u50a8"},{"location":"7_1.html#_1","text":"","title":"\u77e5\u8bc6\u56fe\u8c31\u5efa\u6a21\u4e0e\u5b58\u50a8"},{"location":"7_1.html#_2","text":"\u4e86\u89e3\u77e5\u8bc6\u56fe\u8c31\u7684\u76f8\u5173\u6570\u636e\u6a21\u578b. \u7406\u89e3\u77e5\u8bc6\u56fe\u8c31\u7684\u4e3b\u6d41\u7269\u7406\u5b58\u50a8\u65b9\u6cd5\u548c\u539f\u7406. \u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u5e94\u7528\u7684\u524d\u63d0\u662f, \u8fd9\u4e9b\u6570\u636e\u7684\u6709\u6548\u8868\u793a\u4e0e\u5b58\u50a8. \u903b\u8f91\u5c42\u9762\u7684\u8868\u793a(\u5373\u6570\u636e\u6a21\u578b)\u662f\u4ece\u4eba\u7684\u89d2\u5ea6\u5bf9\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u8fdb\u884c\u63cf\u8ff0, \u7269\u7406\u5c42\u9762\u7684\u5b58\u50a8\u65f6\u4ece\u8ba1\u7b97\u673a\u7684\u89d2\u5ea6\u5bf9\u6570\u636e\u8fdb\u884c\u7ec4\u7ec7, \u4e24\u8005\u5bc6\u5207\u76f8\u5173.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"7_1.html#_3","text":"\u5b8f\u89c2\u6765\u770b, \u77e5\u8bc6\u56fe\u8c31\u7684\u6570\u636e\u6a21\u578b\u5305\u542b\u4e24\u5927\u7c7b: \u4e09\u5143\u7ec4\u6a21\u578b \u56fe\u6a21\u578b","title":"\u77e5\u8bc6\u56fe\u8c31\u7684\u6570\u636e\u6a21\u578b"},{"location":"7_1.html#_4","text":"\u8fd9\u662f\u6211\u4eec\u6700\u4e3a\u719f\u6089\u7684\u6a21\u578b, \u6bd4\u5982\u7ecf\u5178\u4f8b\u5b50, (\"\u67cf\u62c9\u56fe\", \"\u51fa\u751f\u5730\", \"\u96c5\u5178\"), \u5c06\u4e24\u4e2a\u5b9e\u4f53\u548c\u4ed6\u4eec\u4e4b\u95f4\u7684\u5173\u7cfb\u5171\u540c\u7ec4\u6210\u4e00\u4e2a\u4e09\u5143\u7ec4. \u56e0\u6b64\u4e00\u4e2a\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u96c6\u53ef\u4ee5\u770b\u505a\u662f\u4e00\u4e2a\u4e09\u5143\u7ec4\u7684\u96c6\u5408. \u9664\u4e86\u4e0a\u8ff0\u6211\u4eec\u6700\u4e3a\u719f\u6089\u7684\u4e09\u5143\u7ec4\u6a21\u5f0f, \u5728\u77e5\u8bc6\u56fe\u8c31\u7684\u5b9e\u9645\u5e94\u7528\u4e2d, \u5e38\u5e38\u8fd8\u9700\u8981\u8868\u8fbe\u4e00\u4e9b\u76f8\u5bf9\u590d\u6742\u7684\u8bed\u4e49, \u5305\u62ec\u591a\u5143\u5173\u7cfb, \u65f6\u7a7a\u77e5\u8bc6, \u591a\u6a21\u6001\u77e5\u8bc6\u4ee5\u53ca\u5bf9\u8c61\u77e5\u8bc6\u7b49. \u4f8b\u5982: \u6211\u4eec\u5411\u4e09\u5143\u7ec4(\"\u4e9a\u91cc\u58eb\u591a\u5fb7\", \"\u5bfc\u5e08\", \"\u67cf\u62c9\u56fe\")\u4e2d\u6dfb\u52a0\u65f6\u7a7a\u7ebf\u7d22\u4fe1\u606f, \u5219\u53d8\u6210\u4e86\u4e94\u5143\u7ec4\u7684\u5f62\u5f0f(\"\u4e9a\u91cc\u58eb\u591a\u5fb7\", \"\u5bfc\u5e08\", \"\u67cf\u62c9\u56fe\", \"(\u5317\u7eac38\u00b002\u2032, \u4e1c\u7ecf23\u00b044\u2032)\", \"\u516c\u5143\u524d407\u5e74\"). \u4f8b\u5982: \u6211\u4eec\u5411\u4e09\u5143\u7ec4(\"\u67cf\u62c9\u56fe\", \"\u51fa\u751f\u5730\", \"\u96c5\u5178\")\u4e2d\u6dfb\u52a0\u56fe\u7247\u8d44\u6e90\u94fe\u63a5\u7684\u5173\u7cfb\u4fe1\u606f, \u5219\u53d8\u6210\u4e86\u56db\u5143\u7ec4\u7684\u5f62\u5f0f(\"\u67cf\u62c9\u56fe\", \"\u51fa\u751f\u5730\", \"\u96c5\u5178\", \"http://***.com/foaf/0.1/depiction\", \"wikiFile:Plato_MC1355.jpg\"). \u603b\u7ed3: \u4e09\u5143\u7ec4\u6a21\u578b\u7684\u4f18\u70b9\u5728\u4e8e\u6a21\u578b\u7b80\u5355, \u6613\u4e8e\u6269\u5c55, \u4f7f\u5f97\u57fa\u4e8e\u8fd9\u4e00\u6a21\u578b\u6784\u5efa\u5927\u89c4\u6a21\u6570\u636e\u96c6\u6210\u4e3a\u53ef\u80fd. \u4f46\u662f\u4e09\u5143\u7ec4\u6a21\u578b\u7684\u5c40\u9650\u6027\u4e5f\u5f88\u660e\u663e, \u4e3b\u8981\u662f\u5bf9\u4e8e\u6240\u6709\u77e5\u8bc6\u90fd\u53ea\u80fd\u62c6\u5206\u6210\u4e8c\u5143\u5173\u7cfb\u7684\u7ec4\u5408, \u96be\u4ee5\u8868\u8fbe\u590d\u6742\u8bed\u4e49. \u4e09\u5143\u7ec4\u4e3b\u8981\u8868\u8fbe\u7684\u662f\u4e8b\u5b9e\u6027\u77e5\u8bc6, \u5bf9\u4e8e\u4e8b\u7406\u903b\u8f91\u7684\u8868\u8fbe\u80fd\u529b\u6709\u9650, \u96be\u4ee5\u6709\u6548\u652f\u6491\u903b\u8f91\u63a8\u7406. \u5728\u5b9e\u9645\u5e94\u7528\u4e2d, \u9700\u8981\u8054\u5408\u4f7f\u7528\u5176\u4ed6\u77e5\u8bc6\u8868\u793a, \u5305\u62ec\u8c13\u8bcd\u903b\u8f91, \u5e76\u7ed9\u4e88\u4e09\u5143\u7ec4\u77e5\u8bc6\u5f00\u5c55\u6709\u6548\u7684\u63a8\u7406.","title":"\u4e09\u5143\u7ec4\u6a21\u578b"},{"location":"7_1.html#_5","text":"\u77e5\u8bc6\u56fe\u8c31\u66f4\u52a0\u5929\u7136\u7684\u9002\u914d\u4e8e\u56fe\u6a21\u578b, \u5728\u5b9e\u9645\u5e94\u7528\u4e2d, \u7ecf\u5e38\u5c06\u4e09\u5143\u7ec4\u6570\u636e\u901a\u8fc7\u9884\u5148\u5b9a\u4e49\u7684\u8bed\u4e49\u5173\u8054\u8f6c\u6362\u6210\u4e00\u4e2a\u6216\u591a\u4e2a\u8fde\u901a\u56fe, \u6574\u4e2a\u77e5\u8bc6\u56fe\u8c31\u5c31\u53ef\u4ee5\u8868\u793a\u6210\u4e00\u5f20\u5de8\u5927\u7684\"\u56fe\"\u4e86. \u4e3b\u6d41\u7684\u8868\u8fbe\u65b9\u5f0f: \u6709\u5411\u56fe: \u5de5\u4e1a\u754c\u6700\u5e38\u7528\u7684\u6a21\u5f0f \u767e\u79d1\u56fe\u8c31DBPedia \u4e2d\u6587\u767e\u79d1\u56fe\u8c31CN-DBPedia \u836f\u54c1\u77e5\u8bc6\u56fe\u8c31Drugbank \u86cb\u767d\u8d28\u77e5\u8bc6\u56fe\u8c31UniPort \u5730\u7406\u4fe1\u606f\u77e5\u8bc6\u56fe\u8c31LinkedGeoData \u5c5e\u6027\u56fe: \u56fe\u6570\u636e\u5e93\u5de5\u4e1a\u754c\u5e7f\u6cdb\u91c7\u7528\u7684\u6a21\u5f0f \u6811\u72b6\u56fe: WordNet \u6709\u5411\u56fe: \u5e94\u7528\u9762\u4e5f\u5f88\u5e7f Probase YAGO","title":"\u56fe\u6a21\u578b"},{"location":"7_1.html#_6","text":"\u76ee\u524d\u5de5\u4e1a\u754c\u7684\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u7684\u5b58\u50a8\u65b9\u5f0f\u5206\u4e3a\u4e24\u7c7b: \u57fa\u4e8e\u5173\u7cfb\u6a21\u578b\u7684\u5b58\u50a8 \u57fa\u4e8e\u56fe\u6a21\u578b\u7684\u5b58\u50a8 \u590d\u6742\u67e5\u8be2\u7684\u4f18\u5316\u95ee\u9898\u662f\u77e5\u8bc6\u56fe\u8c31\u7ba1\u7406\u7cfb\u7edf\u7684\u6838\u5fc3\u95ee\u9898\u4e4b\u4e00, \u53ef\u4ee5\u501f\u9274\u4f20\u7edf\u5173\u7cfb\u578b\u6570\u636e\u5e93\u4e2d\u7684SQL\u67e5\u8be2\u7684\u8ba1\u5212\u751f\u6210\u548c\u67e5\u8be2\u4f18\u5316\u7b56\u7565. \u5728\u5b9e\u9645\u5e94\u7528\u4e2d, \u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u7684\u67e5\u8be2\u8fd0\u7b97\u901a\u5e38\u5448\u73b0\u51fa\u5982\u4e0b\u7279\u70b9: \u9009\u62e9\u5ea6\u9ad8: \u77e5\u8bc6\u56fe\u8c31\u4e2d\u5e38\u89c1\u9009\u62e9\u64cd\u4f5c\u7684\u7b54\u6848\u4ec5\u6d89\u53ca\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5f88\u5c11\u7684\u4e09\u5143\u7ec4. \u8fde\u63a5\u6570\u91cf\u591a: \u77e5\u8bc6\u56fe\u8c31\u4e2d\u5e38\u89c1\u7684\u8fd0\u7b97\u7ecf\u5e38\u4f1a\u5305\u542b\u5927\u91cf\u7684\u8fde\u63a5\u64cd\u4f5c.","title":"\u77e5\u8bc6\u56fe\u8c31\u7684\u7269\u7406\u5b58\u50a8"},{"location":"7_1.html#_7","text":"\u8003\u8651\u5230\u5e02\u9762\u4e0a\u5df2\u7ecf\u5b58\u5728\u5927\u91cf\u6210\u719f\u7684\u5173\u7cfb\u578b\u6570\u636e\u5e93\u7cfb\u7edf, \u800c\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u7684\u4e09\u5143\u7ec4\u5f88\u5bb9\u6613\u6620\u5c04\u5230\u5173\u7cfb\u6a21\u578b\u4e0a. \u90a3\u4e48\u57fa\u4e8e\u5173\u7cfb\u8868\u5bf9\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u8fdb\u884c\u7ec4\u7ec7\u7684\u65b9\u5f0f\u53ef\u4ee5\u5206\u6210\u56db\u7c7b: \u57fa\u4e8e\u4e09\u5217\u8868\u7684\u5b58\u50a8\u65b9\u5f0f \u57fa\u4e8e\u5c5e\u6027\u8868\u7684\u5b58\u50a8\u65b9\u5f0f \u57fa\u4e8e\u5782\u76f4\u8868\u7684\u5b58\u50a8\u65b9\u5f0f \u57fa\u4e8e\u5168\u7d22\u5f15\u7684\u5b58\u50a8\u65b9\u5f0f","title":"\u5173\u7cfb\u8868\u5b58\u50a8"},{"location":"7_1.html#_8","text":"\u901a\u8fc7\u7ef4\u62a4\u4e00\u4e2a\u5de8\u5927\u7684\u4e09\u5143\u7ec4\u8868\u6765\u7ba1\u7406RDF\u77e5\u8bc6\u56fe\u8c31\u6570\u636e, \u8fd9\u4e2a\u4e09\u5143\u7ec4\u8868\u5305\u542b3\u5217, \u5206\u522b\u5bf9\u5e94\u4e3b\u4f53, \u8c13\u8bcd, \u5ba2\u4f53(\u5373SPO). \u5f53\u7cfb\u7edf\u63a5\u6536\u5230\u7528\u6237\u8f93\u5165\u7684\u67e5\u8be2\u8bf7\u6c42\u65f6, \u7cfb\u7edf\u5c06\u8be5\u67e5\u8be2\u8f6c\u6362\u4e3aSQL\u67e5\u8be2. \u8fd9\u4e9bSQL\u67e5\u8be2\u901a\u5e38\u9700\u8981\u5bf9\u4e09\u5143\u7ec4\u8868\u6267\u884c\u591a\u6b21\u81ea\u8fde\u63a5\u64cd\u4f5c(self-join)\u4ee5\u5f97\u5230\u6700\u7ec8\u7ed3\u679c. \u6838\u5fc3: \u4f7f\u7528\u4e00\u4e2a\u5de8\u5927\u7684\u4e09\u5143\u7ec4\u8868, \u9762\u4e34\u4e00\u4e2a\u5de8\u5927\u7684\u4ee3\u4ef7, \u7cfb\u7edf\u4e0d\u8bba\u6267\u884c\u4f55\u79cd\u64cd\u4f5c, \u90fd\u9700\u8981\u8fdb\u884c\u5168\u8868\u626b\u63cf!!! \u5de5\u4e1a\u754c\u7684\u89e3\u51b3\u65b9\u6848\u662f\u5efa\u7acb\u591a\u4e2a\u7d22\u5f15, \u4ee5\u589e\u52a0\u67e5\u8be2\u6548\u7387. \u4f46\u56e0\u4e3a\u77e5\u8bc6\u56fe\u8c31\u4e0a\u7684\u8fd0\u7b97\u7ecf\u5e38\u5305\u542b\u5927\u91cf\u7684\u8fde\u63a5\u64cd\u4f5c, \u800c\u8fd9\u79cd\u81ea\u8fde\u63a5\u64cd\u4f5c, \u7cfb\u7edf\u9700\u8981\u5c06\u4e09\u5217\u8868\u8fdb\u884c\u590d\u5236, \u7136\u540e\u518d\u4e24\u4e2a\u5de8\u5927\u7684\u4e09\u5217\u8868\u4e0a\u8fdb\u884c\u8fde\u63a5, \u975e\u5e38\u8017\u65f6.","title":"\u4e09\u5217\u8868\u5b58\u50a8"},{"location":"7_1.html#_9","text":"\u4e3a\u4e86\u51cf\u5c11\u81ea\u8fde\u63a5\u64cd\u4f5c\u7684\u6b21\u6570, \u5f88\u591a\u77e5\u8bc6\u56fe\u8c31\u7ba1\u7406\u7cfb\u7edf\u5728\u5355\u4e2a\u4e09\u5143\u7ec4\u8868\u5916, \u8fd8\u6784\u5efa\u4e86\u989d\u5916\u7684\u5c5e\u6027\u8868\u6765\u7ba1\u7406\u6570\u636e, \u6709\u4e24\u5927\u7c7b: \u5206\u7c7b\u5c5e\u6027\u8868: \u6839\u636e\u5b9e\u4f53\u7c7b\u578b\u5c06\u4e09\u5143\u7ec4\u5206\u7c7b, \u76f8\u540c\u7c7b\u7684\u4e09\u5143\u7ec4\u653e\u5728\u540c\u4e00\u4e2a\u8868\u4e2d. \u805a\u7c7b\u5c5e\u6027\u8868: \u5c06\u76f8\u4f3c\u7684\u4e09\u5143\u7ec4\u805a\u7c7b, \u7136\u540e\u5c06\u6bcf\u7c7b\u4e09\u5143\u7ec4\u96c6\u4e2d\u5728\u4e00\u4e2a\u5c5e\u6027\u8868\u4e2d\u8fdb\u884c\u7ba1\u7406. \u5de5\u4e1a\u754c\u7684\u7ecf\u5178\u6848\u4f8b\u5f53\u5c5eJena: \u4e09\u5217\u8868 (s p o) \u5355\u503c\u5c5e\u6027\u8868 / / / / \u4e3b\u952e ---\u591a\u503c\u5c5e\u6027\u8868 \\ \\ \\ \\ \u5c5e\u6027\u7c7b\u8868 Jena: \u9996\u5148\u7ef4\u62a4\u4e86\u4e00\u4e2a\u5de8\u5927\u7684\u4e09\u5143\u7ec4\u8868, \u6b64\u5916Jena\u8fd8\u7ef4\u62a4\u4e86\u4e09\u79cd\u5c5e\u6027\u8868: \u5355\u503c\u5c5e\u6027\u8868, \u591a\u503c\u5c5e\u6027\u8868, \u5c5e\u6027\u7c7b\u8868. \u5355\u503c\u5c5e\u6027\u8868\u662f\u5c06\u5b9e\u4f53\u4e2d\u6240\u6709\u5ba2\u4f53\u503c\u552f\u4e00\u7684\u8c13\u8bcd\u805a\u96c6\u8d77\u6765\u7ec4\u7ec7\u800c\u6210\u7684\u4e00\u4e2a\u8868; \u591a\u503c\u5c5e\u6027\u8868\u662f\u4e3a\u6bcf\u4e00\u4e2a\u5ba2\u4f53\u503c\u4e0d\u552f\u4e00\u7684\u8c13\u8bcd\u6784\u5efa\u7684\u53ea\u6709\u4e24\u5217\u7684\u8868, \u5206\u522b\u5b58\u50a8\u4e3b\u4f53\u503c\u548c\u5ba2\u4f53\u503c; \u5c5e\u6027\u503c\u8868\u662f\u5728\u5355\u503c\u5c5e\u6027\u8868\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u5b58\u50a8\u5b9e\u4f53\u7c7b\u578b\u5217\u7684\u8868.","title":"\u5c5e\u6027\u8868\u5b58\u50a8"},{"location":"7_1.html#_10","text":"\u9488\u5bf9\u4e09\u5217\u8868\u548c\u5c5e\u6027\u8868\u8fde\u63a5\u64cd\u4f5c\u6548\u7387\u4f4e\u7684\u95ee\u9898, SW-Store\u63d0\u51fa\u4e86\u6309\u7167\u8c13\u8bcd\u5206\u8868\u7684\u65b9\u6cd5. \u5177\u4f53\u6765\u8bf4, \u5c06\u4e09\u5143\u7ec4\u6309\u7167\u8c13\u8bcd\u5206\u6210\u4e0d\u540c\u7684\u8868, \u6bcf\u4e2a\u8868\u4fdd\u5b58\u8c13\u8bcd\u76f8\u540c\u7684\u4e09\u5143\u7ec4, SW-Store\u79f0\u8fd9\u79cd\u65b9\u6cd5\u4e3a\u5782\u76f4\u5206\u5272. \u51fa\u751f\u65f6\u95f4 \u4e3b\u4f53 \u5ba2\u4f53 \u82cf\u683c\u62c9\u5e95 \u516c\u5143\u524d469\u5e74 \u67cf\u62c9\u56fe \u516c\u5143\u524d427\u5e74 # --------------------------------------- \u51fa\u751f\u5730 \u4e3b\u4f53 \u5ba2\u4f53 \u82cf\u683c\u62c9\u5e95 \u96c5\u5178 \u67cf\u62c9\u56fe \u96c5\u5178 # -------------------------------------- \u5b66\u751f \u4e3b\u4f53 \u5ba2\u4f53 \u82cf\u683c\u62c9\u5e95 \u67cf\u62c9\u56fe # -------------------------------------- \u4ee3\u8868\u4f5c\u54c1 \u4e3b\u4f53 \u5ba2\u4f53 \u67cf\u62c9\u56fe \u7406\u60f3\u56fd \u6ce8\u610f: \u5782\u76f4\u8868\u7684\u4e00\u5927\u7f3a\u70b9\u662f\u65e0\u6cd5\u5f88\u597d\u7684\u652f\u6301\u8c13\u8bcd\u662f\u53d8\u91cf\u7684\u67e5\u8be2\u64cd\u4f5c! \u6bd4\u5982, \u67e5\u8be2\"\u67cf\u62c9\u56fe\u548c\u82cf\u683c\u62c9\u5e95\u7684\u5173\u7cfb\", \u5c31\u9700\u8981\u626b\u63cf\u6240\u6709\u8868\u624d\u80fd\u56de\u7b54, \u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b.","title":"\u5782\u76f4\u8868\u5b58\u50a8"},{"location":"7_1.html#_11","text":"\u9664\u4e86\u91c7\u7528\u4e00\u822c\u7684\u5173\u7cfb\u578b\u6570\u636e\u5e93\u76f8\u5173\u6280\u672f, \u8fd8\u6709\u4e00\u4e9b\u7cfb\u7edf\u9488\u5bf9\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u548c\u8fd0\u7b97\u7279\u70b9\u63d0\u51fa\u4e86\u7279\u5b9a\u7684\u4f18\u5316\u6280\u672f. \u4e3a\u4e86\u52a0\u901f\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u5728\u8fd0\u7b97\u8fc7\u7a0b\u4e2d\u7684\u8fde\u63a5\u8fd0\u7b97, \u5c06\u4e09\u5143\u7ec4\u4e2dSPO\u7684\u5404\u79cd\u6392\u5217\u60c5\u51b5\u90fd\u679a\u4e3e\u51fa\u6765, \u7136\u540e\u4e3a\u5b83\u4eec\u4e00\u4e00\u6784\u5efa\u7d22\u5f15. \u4e3b\u4f53, \u8c13\u8bcd, \u5ba2\u4f53\u7684\u6392\u5217\u60c5\u51b5\u5171\u8ba16\u79cd, \u6bd4\u5982\u9488\u5bf9\u4e8e(s, p, o), \u989d\u5916\u5b58\u50a85\u4e2a\u5bf9\u5e94\u7684\u4e09\u5143\u7ec4(s, o ,p), (p, s, o), (p, o, s), (o, s, p), (o, p, s). \u8fd9\u4e9b\u7d22\u5f15\u5185\u5bb9\u6b63\u597d\u5bf9\u5e94\u77e5\u8bc6\u56fe\u8c31\u8fd0\u7b97\u4e2d\u5e26\u53d8\u91cf\u7684\u4e09\u5143\u7ec4\u6a21\u5f0f\u7684\u5404\u79cd\u53ef\u80fd. \u6309\u7167\u4e0a\u8ff0\u65b9\u5f0f\u5efa\u7acb\u7684\u7d22\u5f15, \u4e0d\u8bba\u662f\u57fa\u4e8e\u4e3b\u4f53\u6765\u67e5\u8be2\u8c13\u8bcd\u548c\u5ba2\u4f53, \u8fd8\u662f\u57fa\u4e8e\u8c13\u8bcd\u6765\u67e5\u8be2\u4e3b\u4f53\u548c\u5ba2\u4f53, \u6291\u6216\u662f\u57fa\u4e8e\u5ba2\u4f53\u6765\u67e5\u8be2\u8c13\u8bcd\u548c\u4e3b\u4f53, \u7cfb\u7edf\u90fd\u80fd\u5f88\u5feb\u7684\u627e\u5230\u76f8\u5e94\u7684\u7ed3\u679c. \u6ce8\u610f: \u56e0\u4e3a\u6784\u5efa\u4e86\u5927\u91cf\u7d22\u5f15, \u6240\u4ee5\u9009\u53d6\u6ee1\u8db3\u67e5\u8be2\u6761\u4ef6\u7684\u4e09\u5143\u7ec4\u7684\u6548\u7387\u6781\u9ad8! \u4f46\u662f\u8fde\u63a5\u64cd\u4f5c\u4f9d\u7136\u4f4e\u6548, \u4e14\u7d22\u5f15\u7ef4\u62a4\u4e0e\u66f4\u65b0\u7684\u4ee3\u4ef7\u9ad8\u6602!","title":"\u5168\u7d22\u5f15\u5b58\u50a8"},{"location":"7_1.html#_12","text":"\u9488\u5bf9\u4e8e\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u56fe\u6a21\u578b\u8868\u793a, \u5f88\u591a\u7cfb\u7edf\u8bbe\u8ba1\u4e86\u76f8\u5e94\u7684\u56fe\u5b58\u50a8\u6a21\u5f0f, \u4e3b\u8981\u6709\u4e24\u79cd: \u90bb\u63a5\u8868: \u6bcf\u4e2a\u8282\u70b9(\u5b9e\u4f53)\u5bf9\u5e94\u4e00\u4e2a\u5217\u8868, \u5217\u8868\u4e2d\u5b58\u50a8\u4e0e\u8be5\u5b9e\u4f53\u76f8\u5173\u7684\u4fe1\u606f. \u90bb\u63a5\u77e9\u9635: \u5728\u8ba1\u7b97\u673a\u4e2d\u7ef4\u62a4\u591a\u4e2a(n, n)\u7684\u77e9\u9635, \u5176\u4e2dn\u4e3a\u77e5\u8bc6\u56fe\u8c31\u4e2d\u8282\u70b9\u7684\u6570\u91cf. \u6bcf\u4e2a\u77e9\u9635\u5bf9\u5e94\u4e00\u4e2a\u8c13\u8bcd, \u6bcf\u4e00\u884c\u6216\u6bcf\u4e00\u5217\u90fd\u5bf9\u5e94\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u4e00\u4e2a\u8282\u70b9. \u4f18\u5316\u6280\u5de7: \u5728\u5229\u7528\u90bb\u63a5\u8868\u6216\u90bb\u63a5\u77e9\u9635\u8fdb\u884c\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u7ba1\u7406\u65f6, \u4e00\u4e2a\u5173\u952e\u95ee\u9898\u662f\u5982\u4f55\u5bf9\u6307\u6570\u5019\u9009\u7a7a\u95f4\u7684\u67e5\u8be2\u64cd\u4f5c\u505a\u51fa\u6709\u6548\u7684\u526a\u679d! \u4e00\u822c\u90fd\u91c7\u7528\u57fa\u4e8e\u4f4d\u56fe\u7d22\u5f15\u7684\u65b9\u5f0f, \u914d\u5408\u54c8\u5e0c\u8868, \u6bd4\u7279\u538b\u635f\u7b49\u6280\u672f, \u4f7f\u5f97\u67e5\u8be2\u6548\u7387\u975e\u5e38\u9ad8! \u9488\u5bf9\u5c5e\u6027\u56fe\u6a21\u578b, Neo4j\u516c\u53f8\u7528Java\u8bed\u8a00\u5f00\u53d1\u4e86\u56fe\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf-Neo4j, \u5b83\u662f\u4e00\u4e2a\u7b26\u5408ACID\u6807\u51c6\u7684\u4e8b\u52a1\u578b\u56fe\u6570\u636e\u5e93, Neo4j\u5df2\u7ecf\u6210\u4e3a\u5f53\u524d\u6700\u53d7\u6b22\u8fce\u7684\u56fe\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u4e4b\u4e00. \u5728Neo4j\u4e2d, \u5c5e\u6027\u56fe\u4e2d\u7684\u8282\u70b9, \u8fb9, \u4ee5\u53ca\u5c5e\u6027\u90fd\u4ee5\u56fa\u5b9a\u957f\u5ea6\u8bb0\u5f55\u7684\u5f62\u5f0f\u5206\u522b\u5b58\u50a8\u5728\u4e0d\u540c\u7684\u6587\u4ef6\u4e2d. \u8282\u70b9\u8bb0\u5f55\u7ef4\u62a4\u7740\u6307\u5411\u5176\u76f8\u90bb\u8fb9\u548c\u5c5e\u6027\u7684\u6307\u9488; \u8fb9\u8bb0\u5f55\u7ef4\u62a4\u7740\u6307\u5411\u5176\u76f8\u90bb\u63a5\u70b9\u548c\u5c5e\u6027\u7684\u6307\u9488; \u5c5e\u6027\u8bb0\u5f55\u7ef4\u62a4\u7740\u6307\u5411\u5176\u6240\u5bf9\u5e94\u7684\u5177\u4f53\u5c5e\u6027\u503c. \u6838\u5fc3: \u56e0\u4e3a\u4e0d\u8bba\u8282\u70b9\u8bb0\u5f55, \u8fb9\u8bb0\u5f55, \u8fd8\u662f\u5c5e\u6027\u8bb0\u5f55\u90fd\u662f\u56fa\u5b9a\u957f\u5ea6\u7684, \u6240\u4ee5Neo4j\u5728\u78c1\u76d8\u4e2d\u8bfb\u53d6\u6570\u636e\u65f6\u53ef\u4ee5\u5feb\u901f\u8ba1\u7b97\u51fa\u504f\u79fb\u91cf, \u4f7f\u5f97Neo4j\u7684\u8bfb\u53d6\u6548\u7387\u5f88\u9ad8.","title":"\u56fe\u5b58\u50a8"},{"location":"7_1.html#_13","text":"\u77e5\u8bc6\u56fe\u8c31\u7684\u89c4\u6a21\u65e5\u76ca\u589e\u957f, \u5343\u4ebf\u8282\u70b9\u89c4\u6a21\u7684\u77e5\u8bc6\u56fe\u8c31\u5df2\u7ecf\u5f97\u5230\u5e94\u7528. \u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e9b\u5de8\u5927\u56fe\u8c31\u7ed9\u5b58\u50a8\u5e26\u6765\u7684\u6311\u6218, \u8d8a\u6765\u8d8a\u591a\u7684\u5206\u5e03\u5f0f\u89e3\u51b3\u65b9\u6848\u4e5f\u5728\u8fc5\u901f\u53d1\u5c55. \u5178\u578b\u7684\u80fd\u591f\u652f\u6491SPARQL\u67e5\u8be2\u5904\u7406\u7684\u4e91\u8ba1\u7b97\u5e73\u53f0\u5305\u62ecHadoop, Spark\u7b49: Hadoop: \u57fa\u4e8e\u90bb\u63a5\u8868\u7684\u5b58\u50a8 Spark: \u57fa\u4e8e\u5782\u76f4\u8868\u7684\u5b58\u50a8 Hadoop\u662f\u6700\u5e38\u89c1\u7684\u5b58\u50a8\u77e5\u8bc6\u56fe\u8c31\u7684\u4e91\u8ba1\u7b97\u5e73\u53f0, \u57fa\u4e8eHadoop\u5e73\u53f0\u7684\u5b58\u50a8\u65b9\u5f0f\u9996\u5148\u5c06\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u8f6c\u6362\u4e3a\u5e73\u9762\u6587\u4ef6, \u7136\u540e\u5b58\u50a8\u5728Hadoop\u5206\u5e03\u5f0f\u6587\u4ef6\u7cfb\u7edfHDFS\u4e0a. \u4f8b\u5982, SHARD\u7cfb\u7edf\u4ee5\u4e09\u5143\u7ec4\u4e2d\u7684\u4e3b\u4f53\u4e3a\u4f9d\u636e\u5212\u5206\u6570\u636e, \u4e0e\u4e00\u4e2a\u4e3b\u4f53\u76f8\u5173\u7684\u6240\u6709\u4e09\u5143\u7ec4\u88ab\u805a\u96c6\u5230\u4e00\u8d77\u5e76\u5b58\u50a8\u4e3aHDFS\u6587\u4ef6\u4e2d\u7684\u4e00\u884c.","title":"\u5206\u5e03\u5f0f\u5b58\u50a8"},{"location":"7_2.html","text":"7.2.1 neo4j\u4ecb\u7ecd \u00b6 \u5b66\u4e60\u76ee\u6807 \u4e86\u89e3neo4j\u56fe\u6570\u636e\u5e93\u7684\u7b80\u4ecb\uff0c\u7248\u672c\u8bf4\u660e\u3002 \u4e86\u89e3\u8282\u70b9\uff0c\u5173\u7cfb\uff0c\u5c5e\u6027\uff0c\u6807\u7b7e\u7684\u6709\u5173\u6982\u5ff5\u3002 1 neo4j\u7b80\u4ecb \u00b6 neo4j\u662f\u7531Java\u5b9e\u73b0\u7684\u5f00\u6e90NoSQL\u56fe\u6570\u636e\u5e93\u3002\u81ea\u4ece2003\u5e74\u5f00\u59cb\u7814\u53d1\uff0c\u52302007\u5e74\u53d1\u5e03\u7b2c\u4e00\u7248\u3002neo4j\u73b0\u5982\u4eca\u5df2\u7ecf\u88ab\u5404\u884c\u5404\u4e1a\u7684\u6570\u5341\u4e07\u5bb6\u516c\u53f8\u548c\u7ec4\u7ec7\u91c7\u7528\u3002 neo4j\u5b9e\u73b0\u4e86\u4e13\u4e1a\u6570\u636e\u5e93\u7ea7\u522b\u7684\u56fe\u6570\u636e\u6a21\u578b\u7684\u5b58\u50a8\u3002\u4e0e\u666e\u901a\u7684\u56fe\u5904\u7406\u6216\u5185\u5b58\u7ea7\u6570\u636e\u5e93\u4e0d\u540c\uff0cneo4j\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u6570\u636e\u5e93\u7279\u6027\uff0c\u5305\u62ecACID\u4e8b\u7269\u7684\u652f\u6301\uff0c\u96c6\u7fa4\u652f\u6301\uff0c\u5907\u4efd\u4e0e\u6545\u969c\u8f6c\u79fb\u7b49\u3002\u8fd9\u4f7f\u5176\u9002\u5408\u4e8e\u4f01\u4e1a\u7ea7\u751f\u4ea7\u73af\u5883\u4e0b\u7684\u5404\u79cd\u5e94\u7528\u3002 neo4j\u7684\u7248\u672c\u8bf4\u660e\uff1a \u4f01\u4e1a\u7248\uff1a\u9700\u8981\u9ad8\u989d\u7684\u4ed8\u8d39\u83b7\u5f97\u6388\u6743\uff0c\u63d0\u4f9b\u9ad8\u53ef\u7528\uff0c\u70ed\u5907\u4efd\u7b49\u6027\u80fd\u3002 \u793e\u533a\u5f00\u6e90\u7248\uff1a\u514d\u8d39\u4f7f\u7528\uff0c\u4f46\u53ea\u80fd\u5355\u70b9\u8fd0\u884c\u3002 2 neo4j\u56fe\u6570\u636e\u5e93\u6982\u5ff5 \u00b6 \u8282\u70b9 \u8282\u70b9\u662f\u4e3b\u8981\u7684\u6570\u636e\u5143\u7d20\uff0c\u8282\u70b9\u901a\u8fc7\u5173\u7cfb\u8fde\u63a5\u5230\u5176\u4ed6\u8282\u70b9\uff0c\u8282\u70b9\u53ef\u4ee5\u5177\u6709\u4e00\u4e2a\u6216\u591a\u4e2a\u5c5e\u6027 (\u5373\u5b58\u50a8\u4e3a\u952e/\u503c\u5bf9\u7684\u5c5e\u6027), \u8282\u70b9\u6709\u4e00\u4e2a\u6216\u591a\u4e2a\u6807\u7b7e\uff0c\u7528\u4e8e\u63cf\u8ff0\u5176\u5728\u56fe\u8868\u4e2d\u7684\u4f5c\u7528\u3002\u793a\u4f8b\uff1aPerson>\u8282\u70b9\u3002 \u53ef\u4ee5\u5c06\u8282\u70b9\u7c7b\u6bd4\u4e3a\u5173\u7cfb\u578b\u6570\u636e\u5e93\u4e2d\u7684\u8868\uff0c\u5bf9\u5e94\u7684\u6807\u7b7e\u53ef\u4ee5\u7c7b\u6bd4\u4e3a\u4e0d\u540c\u7684\u8868\u540d\uff0c\u5c5e\u6027\u5c31\u662f\u8868\u4e2d\u7684\u5217\u3002 \u5173\u7cfb \u5173\u7cfb\u8fde\u63a5\u4e24\u4e2a\u8282\u70b9\uff0c\u5173\u7cfb\u662f\u65b9\u5411\u6027\u7684\uff0c\u5173\u7cfb\u53ef\u4ee5\u6709\u4e00\u4e2a\u6216\u591a\u4e2a\u5c5e\u6027(\u5373\u5b58\u50a8\u4e3a\u952e/\u503c\u5bf9\u7684 \u5c5e\u6027). \u5c5e\u6027 \u5c5e\u6027\u662f\u547d\u540d\u503c\uff0c\u5176\u4e2d\u540d\u79f0(\u6216\u952e)\u662f\u5b57\u7b26\u4e32\uff0c\u5c5e\u6027\u53ef\u4ee5\u88ab\u7d22\u5f15\u548c\u7ea6\u675f\uff0c\u53ef\u4ee5\u4ece\u591a\u4e2a\u5c5e\u6027\u521b \u5efa\u590d\u5408\u7d22\u5f15\u3002 \u6807\u7b7e \u6807\u7b7e\u7528\u4e8e\u7ec4\u8282\u70b9\u5230\u96c6\uff0c\u8282\u70b9\u53ef\u4ee5\u5177\u6709\u591a\u4e2a\u6807\u7b7e\uff0c\u5bf9\u6807\u7b7e\u8fdb\u884c\u7d22\u5f15\u4ee5\u52a0\u901f\u5728\u56fe\u4e2d\u67e5\u627e\u8282\u70b9\u3002 7.2.2 neo4j\u56fe\u6570\u636e\u5e93\u7684\u5b89\u88c5 \u00b6 \u5b66\u4e60\u76ee\u6807 * \u638c\u63e1neo4j\u56fe\u6570\u636e\u5e93\u7684\u5b89\u88c5\u6d41\u7a0b\u53ca\u5176\u53ef\u89c6\u5316\u540e\u53f0\u7684\u767b\u9646 1 neo4j\u56fe\u6570\u636e\u5e93\u7684\u5b89\u88c5\u6d41\u7a0b \u00b6 \u7b2c\u4e00\u6b65\uff1a\u5c06neo4j\u5b89\u88c5\u4fe1\u606f\u8f7d\u5165\u5230yum\u68c0\u7d22\u5217\u8868\u3002 \u7b2c\u4e8c\u6b65\uff1a\u4f7f\u7528yum install\u547d\u4ee4\u5b89\u88c5\u3002 \u7b2c\u4e09\u6b65\uff1a\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u5185\u5bb9 /etc/neo4j/neo4j.conf. \u7b2c\u56db\u6b65\uff1a\u542f\u52a8neo4j\u6570\u636e\u5e93\u3002 \u7b2c\u4e00\u6b65\uff1a\u5c06neo4j\u5b89\u88c5\u4fe1\u606f\u8f7d\u5165\u5230yum\u68c0\u7d22\u5217\u8868 rpm --import http://debian.neo4j.org/neotechnology.gpg.key vim /etc/yum.repos.d/neo4j.repo # \u5199\u5165\u4e0b\u9762\u5185\u5bb9 [ neo4j ] name = Neo4j RPM Repository baseurl = http://yum.neo4j.org/stable enabled = 1 gpgcheck = 1 \u7b2c\u4e8c\u6b65\uff1a\u4f7f\u7528yum install\u547d\u4ee4\u5b89\u88c5 yum install neo4j \u7b2c\u4e09\u6b65\uff1a\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u9ed8\u8ba4\u5728/etc/neo4j/neo4j.conf, \u4e3a\u4e86\u65b9\u4fbf\u663e\u793a\u4e0b\u9762\u628a\u4e00\u4e9b\u4fee\u6539\u663e\u793a\u5728\u8fd9\u91cc # \u6570\u636e\u5e93\u7684\u5b58\u50a8\u5e93\u5b58\u50a8\u4f4d\u7f6e\u3001\u65e5\u5fd7\u4f4d\u7f6e\u7b49 dbms.directories.data = /var/lib/neo4j/data dbms.directories.plugins = /var/lib/neo4j/plugins dbms.directories.certificates = /var/lib/neo4j/certificates dbms.directories.logs = /var/log/neo4j dbms.directories.lib = /usr/share/neo4j/lib dbms.directories.run = /var/run/neo4j # \u5bfc\u5165\u7684\u4f4d\u7f6e dbms.directories.import = /var/lib/neo4j/import # \u521d\u59cb\u5316\u5185\u5b58\u5927\u5c0f dbms.memory.heap.initial_size = 512m # \u5c06\u8fd9\u4e00\u884c\u6ce8\u91ca\u53bb\u6389 # web\u9875\u9762\u5730\u5740 dbms.connectors.default_listen_address = 0 .0.0.0 # HTTP Connector. There can be zero or one HTTP connectors. dbms.connector.http.enabled = true dbms.connector.http.listen_address = :7474 # \u5c06\u8fd9\u4e00\u884c\u6ce8\u91ca\u53bb\u6389 # HTTPS Connector. There can be zero or one HTTPS connectors. dbms.connector.https.enabled = true dbms.connector.https.listen_address = :7473 # \u5c06\u8fd9\u4e00\u884c\u6ce8\u91ca\u53bb\u6389 # Bolt \u8fde\u63a5\u5730\u5740 dbms.connector.bolt.enabled = true # dbms.connector.bolt.tls_level=OPTIONAL dbms.connector.bolt.listen_address = :7687 # \u5c06\u8fd9\u4e00\u884c\u6ce8\u91ca\u53bb\u6389 \u7b2c\u56db\u6b65\uff1a\u542f\u52a8neo4j\u6570\u636e\u5e93 # \u542f\u52a8\u547d\u4ee4 neo4j start # \u7ec8\u7aef\u663e\u793a\u5982\u4e0b\uff0c\u4ee3\u8868\u542f\u52a8\u6210\u529f Active database: graph.db Directories in use: home: /var/lib/neo4j config: /etc/neo4j logs: /var/log/neo4j plugins: /var/lib/neo4j/plugins import: /var/lib/neo4j/import data: /var/lib/neo4j/data certificates: /var/lib/neo4j/certificates run: /var/run/neo4j Starting Neo4j. WARNING: Max 1024 open files allowed, minimum of 40000 recommended. See the Neo4j manual. Started neo4j ( pid 2463 ) . It is available at http://localhost:7474/ There may be a short delay until the server is ready. See /var/log/neo4j/neo4j.log for current status. 2 neo4j\u7684\u53ef\u89c6\u5316\u7ba1\u7406\u540e\u53f0\u767b\u9646 \u00b6 \u8bbf\u95ee\u5730\u5740\uff1a http://192.168.88.161:7474 ConnectURL: bolt://192.168.88.161:7687 Username: neo4j Password: neo4j (\u7b2c\u4e00\u6b21\u767b\u5f55)\uff0c\u865a\u62df\u673a\u4e2d\u5df2\u6539\u6210123456 3 \u5c0f\u8282\u603b\u7ed3 \u00b6 \u5b66\u4e60\u4e86neo4j\u56fe\u6570\u636e\u5e93\u7684\u5b89\u88c5\u6d41\u7a0b\uff1a \u7b2c\u4e00\u6b65\uff1a\u5c06neo4j\u5b89\u88c5\u4fe1\u606f\u8f7d\u5165\u5230yum\u68c0\u7d22\u5217\u8868\u3002 \u7b2c\u4e8c\u6b65\uff1a\u4f7f\u7528yum install\u547d\u4ee4\u5b89\u88c5\u3002 \u7b2c\u4e09\u6b65\uff1a\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u5185\u5bb9 /etc/neo4j/neo4j.conf. \u7b2c\u56db\u6b65\uff1a\u542f\u52a8neo4j\u6570\u636e\u5e93\u3002 \u5b66\u4e60\u4e86neo4j\u7684\u53ef\u89c6\u5316\u7ba1\u7406\u540e\u53f0\u767b\u9646\uff1a \u8bbf\u95ee\u5730\u5740\uff1a http://192.168.88.161:7474 . ConnectURL: bolt://192.168.88.161:7687 Username: neo4j Password: neo4j (\u9ed8\u8ba4) 7.2.3 Cypher\u4ecb\u7ecd\u4e0e\u4f7f\u7528 \u00b6 \u5b66\u4e60\u76ee\u6807 \u4e86\u89e3Cypher\u7684\u57fa\u672c\u6982\u5ff5\u3002 \u638c\u63e1Cypher\u7684\u57fa\u672c\u547d\u4ee4\u548c\u8bed\u6cd5\u3002 Cypher\u7684\u57fa\u672c\u6982\u5ff5\uff1a Cypher\u662fneo4j\u56fe\u6570\u636e\u7684\u67e5\u8be2\u8bed\u8a00\uff0c\u7c7b\u4f3c\u4e8emysql\u6570\u636e\u5e93\u7684sql\u8bed\u53e5\uff0c\u4f46\u662f\u5b83\u5141\u8bb8\u5bf9\u56fe\u5f62\u8fdb\u884c\u5bcc\u6709\u8868\u73b0\u529b\u548c\u6709\u6548\u7684\u67e5\u8be2\u548c\u66f4\u65b0\u3002 Cypher\u7684\u57fa\u672c\u547d\u4ee4\u548c\u8bed\u6cd5\uff1a create\u547d\u4ee4 match\u547d\u4ee4 merge\u547d\u4ee4 relationship\u5173\u7cfb\u547d\u4ee4 where\u547d\u4ee4 delete\u547d\u4ee4 sort\u547d\u4ee4 \u5b57\u7b26\u4e32\u51fd\u6570 \u805a\u5408\u51fd\u6570 index\u7d22\u5f15\u547d\u4ee4 1 create\u547d\u4ee4 \u00b6 \u521b\u5efa\u56fe\u6570\u636e\u4e2d\u7684\u8282\u70b9 \u6f14\u793a\uff1a # \u521b\u5efa\u547d\u4ee4\u683c\u5f0f\uff1a # \u6b64\u5904 create\u662f\u5173\u952e\u5b57 \uff0c\u521b\u5efa\u8282\u70b9\u540d\u79f0 node_name , \u8282\u70b9\u6807\u7b7e Node_Label , \u653e\u5728\u5c0f\u62ec\u53f7\u91cc\u9762 () # \u540e\u9762\u628a\u6240\u6709\u5c5e\u4e8e\u8282\u70b9\u6807\u7b7e\u7684\u5c5e\u6027\u653e\u5728\u5927\u62ec\u53f7 '{}' \u91cc\u9762\uff0c\u4f9d\u6b21\u5199\u51fa\u5c5e\u6027\u540d\u79f0\uff1a\u5c5e\u6027\u503c\uff0c\u4e0d\u540c\u5c5e\u6027\u7528\u9017\u53f7 ',' \u5206\u9694 # \u4f8b\u5982\u4e0b\u9762\u547d\u4ee4\u521b\u5efa\u4e00\u4e2a\u8282\u70b9 e , \u8282\u70b9\u6807\u7b7e\u662f Employee , \u62e5\u6709 id , name , salary , deptnp\u56db\u4e2a\u5c5e\u6027 \uff1a CREATE ( e : Employee { id : 222 , name : 'Bob' , salary : 6000 , deptnp : 12 } ) \u6548\u679c 2 match\u547d\u4ee4 \u00b6 \u5339\u914d(\u67e5\u8be2)\u5df2\u6709\u6570\u636e \u6f14\u793a\uff1a # match\u547d\u4ee4\u4e13\u95e8\u7528\u6765\u5339\u914d\u67e5\u8be2 \uff0c\u8282\u70b9\u540d\u79f0\uff1a\u8282\u70b9\u6807\u7b7e\uff0c\u4f9d\u7136\u653e\u5728\u5c0f\u62ec\u53f7\u5185\uff0c\u7136\u540e\u4f7f\u7528 return\u8bed\u53e5\u8fd4\u56de\u67e5\u8be2\u7ed3\u679c \uff0c\u548c SQL\u5f88\u76f8\u4f3c \u3002 MATCH ( e : Employee ) RETURN e . id , e . name , e . salary , e . deptno MATCH ( n ) return n # \u67e5\u8be2\u6240\u6709\u7ed3\u70b9 \u6548\u679c\uff1a 3 merge\u547d\u4ee4 \u00b6 \u82e5\u8282\u70b9\u5b58\u5728\uff0c\u5219\u7b49\u6548\u4e0ematch\u547d\u4ee4; \u8282\u70b9\u4e0d\u5b58\u5728\uff0c\u5219\u7b49\u6548\u4e8ecreate\u547d\u4ee4\u3002 \u6f14\u793a\uff1a MERGE ( e : Employee { id : 146 , name : 'Lucer' , salary : 3500 , deptno : 16 } ) \u6548\u679c\uff1a \u7136\u540e\u518d\u6b21\u7528merge\u67e5\u8be2\uff0c\u53d1\u73b0\u6570\u636e\u5e93\u4e2d\u7684\u6570\u636e\u5e76\u6ca1\u6709\u589e\u52a0\uff0c\u56e0\u4e3a\u5df2\u7ecf\u5b58\u5728\u76f8\u540c\u7684\u6570\u636e\u4e86\uff0cmerge\u5339\u914d\u6210\u529f\u3002 \u6f14\u793a\uff1a MERGE (e:Employee {id:146, name:'Lucer', salary:3500, deptno:16}) \u6548\u679c\uff1a 4 \u4f7f\u7528create\u521b\u5efa\u5173\u7cfb \u00b6 \u5fc5\u987b\u521b\u5efa\u6709\u65b9\u5411\u6027\u7684\u5173\u7cfb\uff0c\u5426\u5219\u62a5\u9519\u3002 \u6f14\u793a\uff1a # \u521b\u5efa\u4e00\u4e2a\u8282\u70b9 p1\u5230p2\u7684\u6709\u65b9\u5411\u5173\u7cfb \uff0c\u8fd9\u4e2a\u5173\u7cfb r\u7684\u6807\u7b7e\u4e3aBuy , \u4ee3\u8868 p1\u8d2d\u4e70\u4e86p2 , \u65b9\u5411\u4e3a p1\u6307\u5411p2 CREATE ( p1 : Profile1 ) - [ r : Buy ] -> ( p2 : Profile2 ) \u6548\u679c 5 \u4f7f\u7528merge\u521b\u5efa\u5173\u7cfb \u00b6 \u53ef\u4ee5\u521b\u5efa\u6709/\u65e0\u65b9\u5411\u6027\u7684\u5173\u7cfb\u3002 \u6f14\u793a\uff1a # \u521b\u5efa\u4e00\u4e2a\u8282\u70b9 p1\u5230p2\u7684\u65e0\u65b9\u5411\u5173\u7cfb \uff0c\u8fd9\u4e2a\u5173\u7cfb r\u7684\u6807\u7b7e\u4e3amiss , \u4ee3\u8868 p1 - miss - p2 , \u65b9\u5411\u4e3a\u76f8\u4e92\u7684 MERGE ( p1 : Profile1 ) - [ r : miss ] - ( p2 : Profile2 ) \u6548\u679c 6 where\u547d\u4ee4 \u00b6 \u7c7b\u4f3c\u4e8eSQL\u4e2d\u7684\u6dfb\u52a0\u67e5\u8be2\u6761\u4ef6\u3002 \u6f14\u793a\uff1a # \u67e5\u8be2\u8282\u70b9 Employee\u4e2d \uff0c id\u503c\u7b49\u4e8e123\u7684\u90a3\u4e2a\u8282\u70b9 MATCH ( e : Employee ) WHERE e . id = 123 RETURN e \u6548\u679c\uff1a 7 delete\u547d\u4ee4 \u00b6 \u5220\u9664\u8282\u70b9/\u5173\u7cfb\u53ca\u5176\u5173\u8054\u7684\u5c5e\u6027\u3002 \u6f14\u793a\uff1a # \u6ce8\u610f\uff1a\u5220\u9664\u8282\u70b9\u7684\u540c\u65f6\uff0c\u4e5f\u8981\u5220\u9664\u5173\u8054\u7684\u5173\u7cfb\u8fb9 MATCH ( p1 : Profile1 ) - [ r ] - ( p2 : Profile2 ) DELETE p1 , r , p2 \u6548\u679c\uff1a 8 sort\u547d\u4ee4 \u00b6 Cypher\u547d\u4ee4\u4e2d\u7684\u6392\u5e8f\u4f7f\u7528\u7684\u662forder by. \u6f14\u793a\uff1a # \u5339\u914d\u67e5\u8be2\u6807\u7b7e Employee , \u5c06\u6240\u6709\u5339\u914d\u7ed3\u679c\u6309\u7167 id\u503c\u5347\u5e8f\u6392\u5217\u540e\u8fd4\u56de\u7ed3\u679c MATCH ( e : Employee ) RETURN e . id , e . name , e . salary , e . deptno ORDER BY e . id # \u5982\u679c\u8981\u6309\u7167\u964d\u5e8f\u6392\u5e8f\uff0c\u53ea\u9700\u8981\u5c06 ORDER BY e . salary\u6539\u5199\u4e3aORDER BY e . salary DESC MATCH ( e : Employee ) RETURN e . id , e . name , e . salary , e . deptno ORDER BY e . salary DESC \u6548\u679c\uff1a 9 \u5b57\u7b26\u4e32\u51fd\u6570\uff1a \u00b6 toUpper()\u51fd\u6570 toLower()\u51fd\u6570 substring()\u51fd\u6570 replace()\u51fd\u6570 1 toUpper()\u51fd\u6570 \u00b6 \u5c06\u4e00\u4e2a\u8f93\u5165\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u5927\u5199\u5b57\u6bcd\u3002 \u6f14\u793a\uff1a MATCH ( e : Employee ) RETURN e . id , toUpper ( e . name ), e . salary , e . deptno \u6548\u679c\uff1a 2 toLower()\u51fd\u6570 \u00b6 \u5c06\u4e00\u4e2a\u8f93\u5165\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u5c0f\u5199\u5b57\u6bcd\u3002 \u6f14\u793a\uff1a MATCH ( e : Employee ) RETURN e . id , toLower ( e . name ), e . salary , e . deptno \u6548\u679c\uff1a 3 substring()\u51fd\u6570 \u00b6 \u8fd4\u56de\u4e00\u4e2a\u5b50\u5b57\u7b26\u4e32\u3002 \u6f14\u793a\uff1a # \u8f93\u5165\u5b57\u7b26\u4e32\u4e3a input_str , \u8fd4\u56de\u4ece\u7d22\u5f15 start_index\u5f00\u59cb \uff0c\u5230 end_index - 1 \u7ed3\u675f\u7684\u5b50\u5b57\u7b26\u4e32 substring ( input_str , start_index , end_index ) # \u793a\u4f8b\u4ee3\u7801\uff0c\u8fd4\u56de\u5458\u5de5\u540d\u5b57\u7684\u524d\u4e24\u4e2a\u5b57\u6bcd MATCH ( e : Employee ) RETURN e . id , substring ( e . name , 0 , 2 ), e . salary , e . deptno \u6548\u679c\uff1a 4 replace()\u51fd\u6570 \u00b6 \u66ff\u6362\u6389\u5b50\u5b57\u7b26\u4e32\u3002 \u6f14\u793a\uff1a # \u8f93\u5165\u5b57\u7b26\u4e32\u4e3a input_str , \u5c06\u8f93\u5165\u5b57\u7b26\u4e32\u4e2d\u7b26\u5408 origin_str\u7684\u90e8\u5206 \uff0c\u66ff\u6362\u6210 new_str replace ( input_str , origin_str , new_str ) # \u793a\u4f8b\u4ee3\u7801\uff0c\u5c06\u5458\u5de5\u540d\u5b57\u66ff\u6362\u4e3a\u6dfb\u52a0\u540e\u7f00 _HelloWorld MATCH ( e : Employee ) RETURN e . id , replace ( e . name , e . name , e . name + \"_HelloWorld\" ), e . salary , e . deptno # \u8fd8\u539f MATCH ( e : Employee ) RETURN e . id , replace ( e . name , \"_HelloWorld\" , \"\" ), e . salary , e . deptno \u6548\u679c\uff1a 10 \u805a\u5408\u51fd\u6570 \u00b6 count()\u51fd\u6570 max()\u51fd\u6570 min()\u51fd\u6570 sum()\u51fd\u6570 avg()\u51fd\u6570 1 count()\u51fd\u6570 \u00b6 \u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u6761\u6570\u3002 \u6f14\u793a\uff1a # \u8fd4\u56de\u5339\u914d\u6807\u7b7e Employee\u6210\u529f\u7684\u8bb0\u5f55\u4e2a\u6570 MATCH ( e : Employee ) RETURN count ( * ) \u6548\u679c\uff1a 2 max()\u51fd\u6570 \u00b6 \u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u8bb0\u5f55\u4e2d\u7684\u6700\u5927\u503c\u3002 \u6f14\u793a\uff1a # \u8fd4\u56de\u5339\u914d\u6807\u7b7e Employee\u6210\u529f\u7684\u8bb0\u5f55\u4e2d \uff0c\u6700\u9ad8\u7684\u5de5\u8d44\u6570\u5b57 MATCH ( e : Employee ) RETURN max ( e . salary ) \u6548\u679c\uff1a 3 min()\u51fd\u6570 \u00b6 \u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u8bb0\u5f55\u4e2d\u7684\u6700\u5c0f\u503c\u3002 \u6f14\u793a\uff1a # \u8fd4\u56de\u5339\u914d\u6807\u7b7e Employee\u6210\u529f\u7684\u8bb0\u5f55\u4e2d \uff0c\u6700\u4f4e\u7684\u5de5\u8d44\u6570\u5b57 MATCH ( e : Employee ) RETURN min ( e . salary ) \u6548\u679c\uff1a 4 sum()\u51fd\u6570 \u00b6 \u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u8bb0\u5f55\u4e2d\u67d0\u5b57\u6bb5\u7684\u5168\u90e8\u52a0\u548c\u503c\u3002 \u6f14\u793a\uff1a # \u8fd4\u56de\u5339\u914d\u6807\u7b7e Employee\u6210\u529f\u7684\u8bb0\u5f55\u4e2d \uff0c\u6240\u6709\u5458\u5de5\u5de5\u8d44\u7684\u548c MATCH ( e : Employee ) RETURN sum ( e . salary ) \u6548\u679c\uff1a 5 avg()\u51fd\u6570 \u00b6 \u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u8bb0\u5f55\u4e2d\u67d0\u5b57\u6bb5\u7684\u5e73\u5747\u503c\u3002 \u6f14\u793a\uff1a # \u8fd4\u56de\u5339\u914d\u6807\u7b7e Employee\u6210\u529f\u7684\u8bb0\u5f55\u4e2d \uff0c\u6240\u6709\u5458\u5de5\u5de5\u8d44\u7684\u5e73\u5747\u503c MATCH ( e : Employee ) RETURN avg ( e . salary ) \u6548\u679c\uff1a 11 \u7d22\u5f15index \u00b6 Neo4j\u652f\u6301\u5728\u8282\u70b9\u6216\u5173\u7cfb\u5c5e\u6027\u4e0a\u7684\u7d22\u5f15\uff0c\u4ee5\u63d0\u9ad8\u67e5\u8be2\u7684\u6027\u80fd\u3002 \u53ef\u4ee5\u4e3a\u5177\u6709\u76f8\u540c\u6807\u7b7e\u540d\u79f0\u7684\u6240\u6709\u8282\u70b9\u7684\u5c5e\u6027\u521b\u5efa\u7d22\u5f15\u3002 1 \u521b\u5efa\u7d22\u5f15 \u00b6 \u4f7f\u7528create index on\u6765\u521b\u5efa\u7d22\u5f15\u3002 \u6f14\u793a\uff1a # \u521b\u5efa\u8282\u70b9 Employee\u4e0a\u9762\u5c5e\u6027id\u7684\u7d22\u5f15 CREATE INDEX ON : Employee ( id ) \u6548\u679c\uff1a 2 \u5220\u9664\u7d22\u5f15 \u00b6 \u4f7f\u7528drop index on\u6765\u5220\u9664\u7d22\u5f15\u3002 \u6f14\u793a\uff1a # \u5220\u9664\u8282\u70b9 Employee\u4e0a\u9762\u5c5e\u6027id\u7684\u7d22\u5f15 DROP INDEX ON : Employee ( id ) \u6548\u679c\uff1a 12 \u5c0f\u8282\u603b\u7ed3 \u00b6 \u5b66\u4e60\u4e86Cypher\u7684\u57fa\u672c\u6982\u5ff5\uff1a Cypher\u662fneo4j\u56fe\u6570\u636e\u7684\u67e5\u8be2\u8bed\u8a00\uff0c\u7c7b\u4f3c\u4e8emysql\u6570\u636e\u5e93\u7684sql\u8bed\u53e5\uff0c\u4f46\u662f\u5b83\u5141\u8bb8\u5bf9\u56fe\u5f62\u8fdb\u884c\u5bcc\u6709\u8868\u73b0\u529b\u548c\u6709\u6548\u7684\u67e5\u8be2\u548c\u66f4\u65b0\u3002 Cypher\u7684\u57fa\u672c\u547d\u4ee4\u548c\u8bed\u6cd5\uff1a create\u547d\u4ee4\uff1a\u521b\u5efa\u56fe\u6570\u636e\u4e2d\u7684\u8282\u70b9\u3002 CREATE (e:Employee{id:222, name:'Bob', salary:6000, deptnp:12}) match\u547d\u4ee4\uff1a\u5339\u914d(\u67e5\u8be2)\u5df2\u6709\u6570\u636e\u3002 MATCH (e:Employee) RETURN e.id, e.name, e.salary, e.deptno merge\u547d\u4ee4\uff1a\u82e5\u8282\u70b9\u5b58\u5728\uff0c\u5219\u7b49\u6548\u4e0ematch\u547d\u4ee4; \u8282\u70b9\u4e0d\u5b58\u5728\uff0c\u5219\u7b49\u6548\u4e8ecreate\u547d\u4ee4\u3002 MERGE (e:Employee {id:145, name:'Lucy', salary:7500, deptno:12}) \u4f7f\u7528create\u521b\u5efa\u5173\u7cfb\uff1a\u5fc5\u987b\u521b\u5efa\u6709\u65b9\u5411\u6027\u7684\u5173\u7cfb\uff0c\u5426\u5219\u62a5\u9519\u3002 CREATE (p1:Profile1)-[r:Buy]->(p2:Profile2) \u4f7f\u7528merge\u521b\u5efa\u5173\u7cfb\uff1a\u53ef\u4ee5\u521b\u5efa\u6709/\u65e0\u65b9\u5411\u6027\u7684\u5173\u7cfb\u3002 MERGE (p1:Profile1)-[r:miss]-(p2:Profile2) where\u547d\u4ee4\uff1a\u7c7b\u4f3c\u4e8eSQL\u4e2d\u7684\u6dfb\u52a0\u67e5\u8be2\u6761\u4ef6\u3002 MATCH (e:Employee) WHERE e.id=123 RETURN e delete\u547d\u4ee4\uff1a\u5220\u9664\u8282\u70b9/\u5173\u7cfb\u53ca\u5176\u5173\u8054\u7684\u5c5e\u6027\u3002 MATCH (c1:CreditCard)-[r]-(c2:Customer) DELETE c1, r, c2 sort\u547d\u4ee4\uff1aCypher\u547d\u4ee4\u4e2d\u7684\u6392\u5e8f\u4f7f\u7528\u7684\u662forder by. MATCH (e:Employee) RETURN e.id, e.name, e.salary, e.deptno ORDER BY e.id toUpper()\u51fd\u6570\uff1a\u5c06\u4e00\u4e2a\u8f93\u5165\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u5927\u5199\u5b57\u6bcd\u3002 MATCH (e:Employee) RETURN e.id, toUpper(e.name), e.salary, e.deptno toLower()\u51fd\u6570\uff1a\u8bb2\u4e00\u4e2a\u8f93\u5165\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u5c0f\u5199\u5b57\u6bcd\u3002 MATCH (e:Employee) RETURN e.id, toLower(e.name), e.salary, e.deptno substring()\u51fd\u6570\uff1a\u8fd4\u56de\u4e00\u4e2a\u5b50\u5b57\u7b26\u4e32\u3002 MATCH (e:Employee) RETURN e.id, substring(e.name,0,2), e.salary, e.deptno replace()\u51fd\u6570\uff1a\u66ff\u6362\u6389\u5b50\u5b57\u7b26\u4e32\u3002 MATCH (e:Employee) RETURN e.id, replace(e.name,e.name,e.name + \"_HelloWorld\"), e.salary, e.deptno count()\u51fd\u6570\uff1a\u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u6761\u6570\u3002 MATCH (e:Employee) RETURN count( * ) max()\u51fd\u6570\uff1a\u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u8bb0\u5f55\u4e2d\u7684\u6700\u5927\u503c\u3002 MATCH (e:Employee) RETURN max(e.salary) min()\u51fd\u6570\uff1a\u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u8bb0\u5f55\u4e2d\u7684\u6700\u5c0f\u503c\u3002 MATCH (e:Employee) RETURN min(e.salary) sum()\u51fd\u6570\uff1a\u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u8bb0\u5f55\u4e2d\u67d0\u5b57\u6bb5\u7684\u5168\u90e8\u52a0\u548c\u503c\u3002 MATCH (e:Employee) RETURN sum(e.salary) avg()\u51fd\u6570\uff1a\u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u8bb0\u5f55\u4e2d\u67d0\u5b57\u6bb5\u7684\u5e73\u5747\u503c\u3002 MATCH (e:Employee) RETURN avg(e.salary) \u7d22\u5f15index Neo4j\u652f\u6301\u5728\u8282\u70b9\u6216\u5173\u7cfb\u5c5e\u6027\u4e0a\u7684\u7d22\u5f15\uff0c\u4ee5\u63d0\u9ad8\u67e5\u8be2\u7684\u6027\u80fd\u3002 \u53ef\u4ee5\u4e3a\u5177\u6709\u76f8\u540c\u6807\u7b7e\u540d\u79f0\u7684\u6240\u6709\u8282\u70b9\u7684\u5c5e\u6027\u521b\u5efa\u7d22\u5f15\u3002 \u521b\u5efa\u7d22\u5f15\uff1a\u4f7f\u7528create index on\u6765\u521b\u5efa\u7d22\u5f15\u3002 CREATE INDEX ON:Employee(id) \u5220\u9664\u7d22\u5f15\uff1a\u4f7f\u7528drop index on\u6765\u5220\u9664\u7d22\u5f15\u3002 DROP INDEX ON:Employee(id) 7.2.4 \u5728Python\u4e2d\u4f7f\u7528neo4j \u00b6 \u5b66\u4e60\u76ee\u6807 \u4e86\u89e3python\u4e2dneo4j-driver\u7684\u76f8\u5173\u77e5\u8bc6\u3002 \u638c\u63e1neo4j\u4e2d\u4e8b\u52a1\u6982\u5ff5\u548c\u64cd\u4f5c\u65b9\u6cd5\u3002 1 neo4j-driver\u7b80\u4ecb\uff1a \u00b6 neo4j-driver\u662f\u4e00\u4e2apython\u4e2d\u7684package, \u4f5c\u4e3apython\u4e2dneo4j\u7684\u9a71\u52a8\uff0c\u5e2e\u52a9\u6211\u4eec\u5728python\u7a0b\u5e8f\u4e2d\u66f4\u597d\u7684\u4f7f\u7528\u56fe\u6570\u636e\u5e93\u3002 neo4j-driver\u7684\u5b89\u88c5\uff1a pip install neo4j-driver neo4j-driver\u4f7f\u7528\u6f14\u793a\uff1a from neo4j import GraphDatabase # uri = \"neo4j://192.168.88.161:7687\" # 4.x\u7248\u672c\u7528\u8fd9\u4e2a uri = \"bolt://192.168.88.161:7687\" # 3.x\u7248\u672c\u7528\u8fd9\u4e2a driver = GraphDatabase . driver ( uri , auth = ( \"neo4j\" , \"123456\" ), max_connection_lifetime = 1000 ) # \u76f4\u63a5\u7528python\u4ee3\u7801\u5f62\u5f0f\u8bbf\u95ee\u8282\u70b9Company, \u5e76\u8fd4\u56de\u6240\u6709\u8282\u70b9\u4fe1\u606f with driver . session () as session : cypher = \"CREATE(c:Company) SET c.name='\u9ed1\u9a6c\u7a0b\u5e8f\u5458' RETURN c.name\" record = session . run ( cypher ) result = list ( map ( lambda x : x [ 0 ], record )) print ( \"result:\" , result ) \u8f93\u51fa\u6548\u679c\uff1a result: \u9ed1\u9a6c\u7a0b\u5e8f\u5458 2 \u4e8b\u52a1\u7684\u6982\u5ff5 \u00b6 \u5982\u679c\u4e00\u7ec4\u6570\u636e\u5e93\u64cd\u4f5c\u8981\u4e48\u5168\u90e8\u53d1\u751f\u8981\u4e48\u4e00\u6b65\u4e5f\u4e0d\u6267\u884c\uff0c\u6211\u4eec\u79f0\u8be5\u7ec4\u5904\u7406\u6b65\u9aa4\u4e3a\u4e00\u4e2a\u4e8b\u52a1\uff0c\u5b83\u662f\u6570\u636e\u5e93\u4e00\u81f4\u6027\u7684\u4fdd\u8bc1\u3002 \u4f7f\u7528\u4e8b\u52a1\u7684\u6f14\u793a\uff1a # \u4e0b\u9762\u53ef\u4ee5\u6b63\u5e38\u6267\u884c def _some_operations ( sess , cat_name , mouse_name ): sess . run ( \"MERGE (a:Cat{name: $cat_name})\" \"MERGE (b:Mouse{name: $mouse_name})\" \"MERGE (a)-[r:And]-(b)\" , cat_name = cat_name , mouse_name = mouse_name ) with driver . session () as session : session . write_transaction ( _some_operations , \"Tom\" , \"Jerry\" ) # \u4e0b\u9762\u6267\u884c\u65f6\u62a5\u9519 def _some_operations ( sess , cat_name , mouse_name ): sess . run ( \"MERGE (a:Cat{name: $cat_name})\" \"MERGE (b:Mouse{name: $mouse_name})\" \"CREATE (a)-[r:And]-(b)\" , cat_name = cat_name , mouse_name = mouse_name ) with driver . session () as session : session . write_transaction ( _some_operations , \"Tom1\" , \"Jerry1\" ) \u8f93\u51fa\u6548\u679c\uff1a 3 \u5c0f\u8282\u603b\u7ed3 \u00b6 \u5b66\u4e60\u4e86neo4j-driver\u7b80\u4ecb\uff1a neo4j-driver\u662f\u4e00\u4e2apython\u4e2d\u7684package, \u4f5c\u4e3apython\u4e2dneo4j\u7684\u9a71\u52a8\uff0c\u5e2e\u52a9\u6211\u4eec\u5728python\u7a0b\u5e8f\u4e2d\u66f4\u597d\u7684\u4f7f\u7528\u56fe\u6570\u636e\u5e93\u3002 \u5b66\u4e60\u4e86neo4j-driver\u7684\u5b89\u88c5\u548c\u4f7f\u7528\u65b9\u6cd5\u3002 \u5b66\u4e60\u4e86\u4e8b\u52a1\u7684\u6982\u5ff5\uff1a \u5982\u679c\u4e00\u7ec4\u6570\u636e\u5e93\u64cd\u4f5c\u8981\u4e48\u5168\u90e8\u53d1\u751f\u8981\u4e48\u4e00\u6b65\u4e5f\u4e0d\u6267\u884c\uff0c\u6211\u4eec\u79f0\u8be5\u7ec4\u5904\u7406\u6b65\u9aa4\u4e3a\u4e00\u4e2a\u4e8b\u52a1\uff0c\u5b83\u662f\u6570\u636e\u5e93\u4e00\u81f4\u6027\u7684\u4fdd\u8bc1\u3002 \u5b66\u4e60\u4e86\u5982\u4f55\u4f7f\u7528\u4e8b\u52a1\u6765\u5411\u56fe\u6570\u636e\u5e93\u4e2d\u5199\u5165\u6570\u636e\u3002","title":"7.2 neo4j\u6280\u672f\u89e3\u6790"},{"location":"7_2.html#721-neo4j","text":"\u5b66\u4e60\u76ee\u6807 \u4e86\u89e3neo4j\u56fe\u6570\u636e\u5e93\u7684\u7b80\u4ecb\uff0c\u7248\u672c\u8bf4\u660e\u3002 \u4e86\u89e3\u8282\u70b9\uff0c\u5173\u7cfb\uff0c\u5c5e\u6027\uff0c\u6807\u7b7e\u7684\u6709\u5173\u6982\u5ff5\u3002","title":"7.2.1 neo4j\u4ecb\u7ecd"},{"location":"7_2.html#1-neo4j","text":"neo4j\u662f\u7531Java\u5b9e\u73b0\u7684\u5f00\u6e90NoSQL\u56fe\u6570\u636e\u5e93\u3002\u81ea\u4ece2003\u5e74\u5f00\u59cb\u7814\u53d1\uff0c\u52302007\u5e74\u53d1\u5e03\u7b2c\u4e00\u7248\u3002neo4j\u73b0\u5982\u4eca\u5df2\u7ecf\u88ab\u5404\u884c\u5404\u4e1a\u7684\u6570\u5341\u4e07\u5bb6\u516c\u53f8\u548c\u7ec4\u7ec7\u91c7\u7528\u3002 neo4j\u5b9e\u73b0\u4e86\u4e13\u4e1a\u6570\u636e\u5e93\u7ea7\u522b\u7684\u56fe\u6570\u636e\u6a21\u578b\u7684\u5b58\u50a8\u3002\u4e0e\u666e\u901a\u7684\u56fe\u5904\u7406\u6216\u5185\u5b58\u7ea7\u6570\u636e\u5e93\u4e0d\u540c\uff0cneo4j\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u6570\u636e\u5e93\u7279\u6027\uff0c\u5305\u62ecACID\u4e8b\u7269\u7684\u652f\u6301\uff0c\u96c6\u7fa4\u652f\u6301\uff0c\u5907\u4efd\u4e0e\u6545\u969c\u8f6c\u79fb\u7b49\u3002\u8fd9\u4f7f\u5176\u9002\u5408\u4e8e\u4f01\u4e1a\u7ea7\u751f\u4ea7\u73af\u5883\u4e0b\u7684\u5404\u79cd\u5e94\u7528\u3002 neo4j\u7684\u7248\u672c\u8bf4\u660e\uff1a \u4f01\u4e1a\u7248\uff1a\u9700\u8981\u9ad8\u989d\u7684\u4ed8\u8d39\u83b7\u5f97\u6388\u6743\uff0c\u63d0\u4f9b\u9ad8\u53ef\u7528\uff0c\u70ed\u5907\u4efd\u7b49\u6027\u80fd\u3002 \u793e\u533a\u5f00\u6e90\u7248\uff1a\u514d\u8d39\u4f7f\u7528\uff0c\u4f46\u53ea\u80fd\u5355\u70b9\u8fd0\u884c\u3002","title":"1 neo4j\u7b80\u4ecb"},{"location":"7_2.html#2-neo4j","text":"\u8282\u70b9 \u8282\u70b9\u662f\u4e3b\u8981\u7684\u6570\u636e\u5143\u7d20\uff0c\u8282\u70b9\u901a\u8fc7\u5173\u7cfb\u8fde\u63a5\u5230\u5176\u4ed6\u8282\u70b9\uff0c\u8282\u70b9\u53ef\u4ee5\u5177\u6709\u4e00\u4e2a\u6216\u591a\u4e2a\u5c5e\u6027 (\u5373\u5b58\u50a8\u4e3a\u952e/\u503c\u5bf9\u7684\u5c5e\u6027), \u8282\u70b9\u6709\u4e00\u4e2a\u6216\u591a\u4e2a\u6807\u7b7e\uff0c\u7528\u4e8e\u63cf\u8ff0\u5176\u5728\u56fe\u8868\u4e2d\u7684\u4f5c\u7528\u3002\u793a\u4f8b\uff1aPerson>\u8282\u70b9\u3002 \u53ef\u4ee5\u5c06\u8282\u70b9\u7c7b\u6bd4\u4e3a\u5173\u7cfb\u578b\u6570\u636e\u5e93\u4e2d\u7684\u8868\uff0c\u5bf9\u5e94\u7684\u6807\u7b7e\u53ef\u4ee5\u7c7b\u6bd4\u4e3a\u4e0d\u540c\u7684\u8868\u540d\uff0c\u5c5e\u6027\u5c31\u662f\u8868\u4e2d\u7684\u5217\u3002 \u5173\u7cfb \u5173\u7cfb\u8fde\u63a5\u4e24\u4e2a\u8282\u70b9\uff0c\u5173\u7cfb\u662f\u65b9\u5411\u6027\u7684\uff0c\u5173\u7cfb\u53ef\u4ee5\u6709\u4e00\u4e2a\u6216\u591a\u4e2a\u5c5e\u6027(\u5373\u5b58\u50a8\u4e3a\u952e/\u503c\u5bf9\u7684 \u5c5e\u6027). \u5c5e\u6027 \u5c5e\u6027\u662f\u547d\u540d\u503c\uff0c\u5176\u4e2d\u540d\u79f0(\u6216\u952e)\u662f\u5b57\u7b26\u4e32\uff0c\u5c5e\u6027\u53ef\u4ee5\u88ab\u7d22\u5f15\u548c\u7ea6\u675f\uff0c\u53ef\u4ee5\u4ece\u591a\u4e2a\u5c5e\u6027\u521b \u5efa\u590d\u5408\u7d22\u5f15\u3002 \u6807\u7b7e \u6807\u7b7e\u7528\u4e8e\u7ec4\u8282\u70b9\u5230\u96c6\uff0c\u8282\u70b9\u53ef\u4ee5\u5177\u6709\u591a\u4e2a\u6807\u7b7e\uff0c\u5bf9\u6807\u7b7e\u8fdb\u884c\u7d22\u5f15\u4ee5\u52a0\u901f\u5728\u56fe\u4e2d\u67e5\u627e\u8282\u70b9\u3002","title":"2 neo4j\u56fe\u6570\u636e\u5e93\u6982\u5ff5"},{"location":"7_2.html#722-neo4j","text":"\u5b66\u4e60\u76ee\u6807 * \u638c\u63e1neo4j\u56fe\u6570\u636e\u5e93\u7684\u5b89\u88c5\u6d41\u7a0b\u53ca\u5176\u53ef\u89c6\u5316\u540e\u53f0\u7684\u767b\u9646","title":"7.2.2 neo4j\u56fe\u6570\u636e\u5e93\u7684\u5b89\u88c5"},{"location":"7_2.html#1-neo4j_1","text":"\u7b2c\u4e00\u6b65\uff1a\u5c06neo4j\u5b89\u88c5\u4fe1\u606f\u8f7d\u5165\u5230yum\u68c0\u7d22\u5217\u8868\u3002 \u7b2c\u4e8c\u6b65\uff1a\u4f7f\u7528yum install\u547d\u4ee4\u5b89\u88c5\u3002 \u7b2c\u4e09\u6b65\uff1a\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u5185\u5bb9 /etc/neo4j/neo4j.conf. \u7b2c\u56db\u6b65\uff1a\u542f\u52a8neo4j\u6570\u636e\u5e93\u3002 \u7b2c\u4e00\u6b65\uff1a\u5c06neo4j\u5b89\u88c5\u4fe1\u606f\u8f7d\u5165\u5230yum\u68c0\u7d22\u5217\u8868 rpm --import http://debian.neo4j.org/neotechnology.gpg.key vim /etc/yum.repos.d/neo4j.repo # \u5199\u5165\u4e0b\u9762\u5185\u5bb9 [ neo4j ] name = Neo4j RPM Repository baseurl = http://yum.neo4j.org/stable enabled = 1 gpgcheck = 1 \u7b2c\u4e8c\u6b65\uff1a\u4f7f\u7528yum install\u547d\u4ee4\u5b89\u88c5 yum install neo4j \u7b2c\u4e09\u6b65\uff1a\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u9ed8\u8ba4\u5728/etc/neo4j/neo4j.conf, \u4e3a\u4e86\u65b9\u4fbf\u663e\u793a\u4e0b\u9762\u628a\u4e00\u4e9b\u4fee\u6539\u663e\u793a\u5728\u8fd9\u91cc # \u6570\u636e\u5e93\u7684\u5b58\u50a8\u5e93\u5b58\u50a8\u4f4d\u7f6e\u3001\u65e5\u5fd7\u4f4d\u7f6e\u7b49 dbms.directories.data = /var/lib/neo4j/data dbms.directories.plugins = /var/lib/neo4j/plugins dbms.directories.certificates = /var/lib/neo4j/certificates dbms.directories.logs = /var/log/neo4j dbms.directories.lib = /usr/share/neo4j/lib dbms.directories.run = /var/run/neo4j # \u5bfc\u5165\u7684\u4f4d\u7f6e dbms.directories.import = /var/lib/neo4j/import # \u521d\u59cb\u5316\u5185\u5b58\u5927\u5c0f dbms.memory.heap.initial_size = 512m # \u5c06\u8fd9\u4e00\u884c\u6ce8\u91ca\u53bb\u6389 # web\u9875\u9762\u5730\u5740 dbms.connectors.default_listen_address = 0 .0.0.0 # HTTP Connector. There can be zero or one HTTP connectors. dbms.connector.http.enabled = true dbms.connector.http.listen_address = :7474 # \u5c06\u8fd9\u4e00\u884c\u6ce8\u91ca\u53bb\u6389 # HTTPS Connector. There can be zero or one HTTPS connectors. dbms.connector.https.enabled = true dbms.connector.https.listen_address = :7473 # \u5c06\u8fd9\u4e00\u884c\u6ce8\u91ca\u53bb\u6389 # Bolt \u8fde\u63a5\u5730\u5740 dbms.connector.bolt.enabled = true # dbms.connector.bolt.tls_level=OPTIONAL dbms.connector.bolt.listen_address = :7687 # \u5c06\u8fd9\u4e00\u884c\u6ce8\u91ca\u53bb\u6389 \u7b2c\u56db\u6b65\uff1a\u542f\u52a8neo4j\u6570\u636e\u5e93 # \u542f\u52a8\u547d\u4ee4 neo4j start # \u7ec8\u7aef\u663e\u793a\u5982\u4e0b\uff0c\u4ee3\u8868\u542f\u52a8\u6210\u529f Active database: graph.db Directories in use: home: /var/lib/neo4j config: /etc/neo4j logs: /var/log/neo4j plugins: /var/lib/neo4j/plugins import: /var/lib/neo4j/import data: /var/lib/neo4j/data certificates: /var/lib/neo4j/certificates run: /var/run/neo4j Starting Neo4j. WARNING: Max 1024 open files allowed, minimum of 40000 recommended. See the Neo4j manual. Started neo4j ( pid 2463 ) . It is available at http://localhost:7474/ There may be a short delay until the server is ready. See /var/log/neo4j/neo4j.log for current status.","title":"1 neo4j\u56fe\u6570\u636e\u5e93\u7684\u5b89\u88c5\u6d41\u7a0b"},{"location":"7_2.html#2-neo4j_1","text":"\u8bbf\u95ee\u5730\u5740\uff1a http://192.168.88.161:7474 ConnectURL: bolt://192.168.88.161:7687 Username: neo4j Password: neo4j (\u7b2c\u4e00\u6b21\u767b\u5f55)\uff0c\u865a\u62df\u673a\u4e2d\u5df2\u6539\u6210123456","title":"2 neo4j\u7684\u53ef\u89c6\u5316\u7ba1\u7406\u540e\u53f0\u767b\u9646"},{"location":"7_2.html#3","text":"\u5b66\u4e60\u4e86neo4j\u56fe\u6570\u636e\u5e93\u7684\u5b89\u88c5\u6d41\u7a0b\uff1a \u7b2c\u4e00\u6b65\uff1a\u5c06neo4j\u5b89\u88c5\u4fe1\u606f\u8f7d\u5165\u5230yum\u68c0\u7d22\u5217\u8868\u3002 \u7b2c\u4e8c\u6b65\uff1a\u4f7f\u7528yum install\u547d\u4ee4\u5b89\u88c5\u3002 \u7b2c\u4e09\u6b65\uff1a\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u5185\u5bb9 /etc/neo4j/neo4j.conf. \u7b2c\u56db\u6b65\uff1a\u542f\u52a8neo4j\u6570\u636e\u5e93\u3002 \u5b66\u4e60\u4e86neo4j\u7684\u53ef\u89c6\u5316\u7ba1\u7406\u540e\u53f0\u767b\u9646\uff1a \u8bbf\u95ee\u5730\u5740\uff1a http://192.168.88.161:7474 . ConnectURL: bolt://192.168.88.161:7687 Username: neo4j Password: neo4j (\u9ed8\u8ba4)","title":"3 \u5c0f\u8282\u603b\u7ed3"},{"location":"7_2.html#723-cypher","text":"\u5b66\u4e60\u76ee\u6807 \u4e86\u89e3Cypher\u7684\u57fa\u672c\u6982\u5ff5\u3002 \u638c\u63e1Cypher\u7684\u57fa\u672c\u547d\u4ee4\u548c\u8bed\u6cd5\u3002 Cypher\u7684\u57fa\u672c\u6982\u5ff5\uff1a Cypher\u662fneo4j\u56fe\u6570\u636e\u7684\u67e5\u8be2\u8bed\u8a00\uff0c\u7c7b\u4f3c\u4e8emysql\u6570\u636e\u5e93\u7684sql\u8bed\u53e5\uff0c\u4f46\u662f\u5b83\u5141\u8bb8\u5bf9\u56fe\u5f62\u8fdb\u884c\u5bcc\u6709\u8868\u73b0\u529b\u548c\u6709\u6548\u7684\u67e5\u8be2\u548c\u66f4\u65b0\u3002 Cypher\u7684\u57fa\u672c\u547d\u4ee4\u548c\u8bed\u6cd5\uff1a create\u547d\u4ee4 match\u547d\u4ee4 merge\u547d\u4ee4 relationship\u5173\u7cfb\u547d\u4ee4 where\u547d\u4ee4 delete\u547d\u4ee4 sort\u547d\u4ee4 \u5b57\u7b26\u4e32\u51fd\u6570 \u805a\u5408\u51fd\u6570 index\u7d22\u5f15\u547d\u4ee4","title":"7.2.3 Cypher\u4ecb\u7ecd\u4e0e\u4f7f\u7528"},{"location":"7_2.html#1-create","text":"\u521b\u5efa\u56fe\u6570\u636e\u4e2d\u7684\u8282\u70b9 \u6f14\u793a\uff1a # \u521b\u5efa\u547d\u4ee4\u683c\u5f0f\uff1a # \u6b64\u5904 create\u662f\u5173\u952e\u5b57 \uff0c\u521b\u5efa\u8282\u70b9\u540d\u79f0 node_name , \u8282\u70b9\u6807\u7b7e Node_Label , \u653e\u5728\u5c0f\u62ec\u53f7\u91cc\u9762 () # \u540e\u9762\u628a\u6240\u6709\u5c5e\u4e8e\u8282\u70b9\u6807\u7b7e\u7684\u5c5e\u6027\u653e\u5728\u5927\u62ec\u53f7 '{}' \u91cc\u9762\uff0c\u4f9d\u6b21\u5199\u51fa\u5c5e\u6027\u540d\u79f0\uff1a\u5c5e\u6027\u503c\uff0c\u4e0d\u540c\u5c5e\u6027\u7528\u9017\u53f7 ',' \u5206\u9694 # \u4f8b\u5982\u4e0b\u9762\u547d\u4ee4\u521b\u5efa\u4e00\u4e2a\u8282\u70b9 e , \u8282\u70b9\u6807\u7b7e\u662f Employee , \u62e5\u6709 id , name , salary , deptnp\u56db\u4e2a\u5c5e\u6027 \uff1a CREATE ( e : Employee { id : 222 , name : 'Bob' , salary : 6000 , deptnp : 12 } ) \u6548\u679c","title":"1 create\u547d\u4ee4"},{"location":"7_2.html#2-match","text":"\u5339\u914d(\u67e5\u8be2)\u5df2\u6709\u6570\u636e \u6f14\u793a\uff1a # match\u547d\u4ee4\u4e13\u95e8\u7528\u6765\u5339\u914d\u67e5\u8be2 \uff0c\u8282\u70b9\u540d\u79f0\uff1a\u8282\u70b9\u6807\u7b7e\uff0c\u4f9d\u7136\u653e\u5728\u5c0f\u62ec\u53f7\u5185\uff0c\u7136\u540e\u4f7f\u7528 return\u8bed\u53e5\u8fd4\u56de\u67e5\u8be2\u7ed3\u679c \uff0c\u548c SQL\u5f88\u76f8\u4f3c \u3002 MATCH ( e : Employee ) RETURN e . id , e . name , e . salary , e . deptno MATCH ( n ) return n # \u67e5\u8be2\u6240\u6709\u7ed3\u70b9 \u6548\u679c\uff1a","title":"2 match\u547d\u4ee4"},{"location":"7_2.html#3-merge","text":"\u82e5\u8282\u70b9\u5b58\u5728\uff0c\u5219\u7b49\u6548\u4e0ematch\u547d\u4ee4; \u8282\u70b9\u4e0d\u5b58\u5728\uff0c\u5219\u7b49\u6548\u4e8ecreate\u547d\u4ee4\u3002 \u6f14\u793a\uff1a MERGE ( e : Employee { id : 146 , name : 'Lucer' , salary : 3500 , deptno : 16 } ) \u6548\u679c\uff1a \u7136\u540e\u518d\u6b21\u7528merge\u67e5\u8be2\uff0c\u53d1\u73b0\u6570\u636e\u5e93\u4e2d\u7684\u6570\u636e\u5e76\u6ca1\u6709\u589e\u52a0\uff0c\u56e0\u4e3a\u5df2\u7ecf\u5b58\u5728\u76f8\u540c\u7684\u6570\u636e\u4e86\uff0cmerge\u5339\u914d\u6210\u529f\u3002 \u6f14\u793a\uff1a MERGE (e:Employee {id:146, name:'Lucer', salary:3500, deptno:16}) \u6548\u679c\uff1a","title":"3 merge\u547d\u4ee4"},{"location":"7_2.html#4-create","text":"\u5fc5\u987b\u521b\u5efa\u6709\u65b9\u5411\u6027\u7684\u5173\u7cfb\uff0c\u5426\u5219\u62a5\u9519\u3002 \u6f14\u793a\uff1a # \u521b\u5efa\u4e00\u4e2a\u8282\u70b9 p1\u5230p2\u7684\u6709\u65b9\u5411\u5173\u7cfb \uff0c\u8fd9\u4e2a\u5173\u7cfb r\u7684\u6807\u7b7e\u4e3aBuy , \u4ee3\u8868 p1\u8d2d\u4e70\u4e86p2 , \u65b9\u5411\u4e3a p1\u6307\u5411p2 CREATE ( p1 : Profile1 ) - [ r : Buy ] -> ( p2 : Profile2 ) \u6548\u679c","title":"4 \u4f7f\u7528create\u521b\u5efa\u5173\u7cfb"},{"location":"7_2.html#5-merge","text":"\u53ef\u4ee5\u521b\u5efa\u6709/\u65e0\u65b9\u5411\u6027\u7684\u5173\u7cfb\u3002 \u6f14\u793a\uff1a # \u521b\u5efa\u4e00\u4e2a\u8282\u70b9 p1\u5230p2\u7684\u65e0\u65b9\u5411\u5173\u7cfb \uff0c\u8fd9\u4e2a\u5173\u7cfb r\u7684\u6807\u7b7e\u4e3amiss , \u4ee3\u8868 p1 - miss - p2 , \u65b9\u5411\u4e3a\u76f8\u4e92\u7684 MERGE ( p1 : Profile1 ) - [ r : miss ] - ( p2 : Profile2 ) \u6548\u679c","title":"5 \u4f7f\u7528merge\u521b\u5efa\u5173\u7cfb"},{"location":"7_2.html#6-where","text":"\u7c7b\u4f3c\u4e8eSQL\u4e2d\u7684\u6dfb\u52a0\u67e5\u8be2\u6761\u4ef6\u3002 \u6f14\u793a\uff1a # \u67e5\u8be2\u8282\u70b9 Employee\u4e2d \uff0c id\u503c\u7b49\u4e8e123\u7684\u90a3\u4e2a\u8282\u70b9 MATCH ( e : Employee ) WHERE e . id = 123 RETURN e \u6548\u679c\uff1a","title":"6 where\u547d\u4ee4"},{"location":"7_2.html#7-delete","text":"\u5220\u9664\u8282\u70b9/\u5173\u7cfb\u53ca\u5176\u5173\u8054\u7684\u5c5e\u6027\u3002 \u6f14\u793a\uff1a # \u6ce8\u610f\uff1a\u5220\u9664\u8282\u70b9\u7684\u540c\u65f6\uff0c\u4e5f\u8981\u5220\u9664\u5173\u8054\u7684\u5173\u7cfb\u8fb9 MATCH ( p1 : Profile1 ) - [ r ] - ( p2 : Profile2 ) DELETE p1 , r , p2 \u6548\u679c\uff1a","title":"7 delete\u547d\u4ee4"},{"location":"7_2.html#8-sort","text":"Cypher\u547d\u4ee4\u4e2d\u7684\u6392\u5e8f\u4f7f\u7528\u7684\u662forder by. \u6f14\u793a\uff1a # \u5339\u914d\u67e5\u8be2\u6807\u7b7e Employee , \u5c06\u6240\u6709\u5339\u914d\u7ed3\u679c\u6309\u7167 id\u503c\u5347\u5e8f\u6392\u5217\u540e\u8fd4\u56de\u7ed3\u679c MATCH ( e : Employee ) RETURN e . id , e . name , e . salary , e . deptno ORDER BY e . id # \u5982\u679c\u8981\u6309\u7167\u964d\u5e8f\u6392\u5e8f\uff0c\u53ea\u9700\u8981\u5c06 ORDER BY e . salary\u6539\u5199\u4e3aORDER BY e . salary DESC MATCH ( e : Employee ) RETURN e . id , e . name , e . salary , e . deptno ORDER BY e . salary DESC \u6548\u679c\uff1a","title":"8 sort\u547d\u4ee4"},{"location":"7_2.html#9","text":"toUpper()\u51fd\u6570 toLower()\u51fd\u6570 substring()\u51fd\u6570 replace()\u51fd\u6570","title":"9 \u5b57\u7b26\u4e32\u51fd\u6570\uff1a"},{"location":"7_2.html#1-toupper","text":"\u5c06\u4e00\u4e2a\u8f93\u5165\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u5927\u5199\u5b57\u6bcd\u3002 \u6f14\u793a\uff1a MATCH ( e : Employee ) RETURN e . id , toUpper ( e . name ), e . salary , e . deptno \u6548\u679c\uff1a","title":"1 toUpper()\u51fd\u6570"},{"location":"7_2.html#2-tolower","text":"\u5c06\u4e00\u4e2a\u8f93\u5165\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u5c0f\u5199\u5b57\u6bcd\u3002 \u6f14\u793a\uff1a MATCH ( e : Employee ) RETURN e . id , toLower ( e . name ), e . salary , e . deptno \u6548\u679c\uff1a","title":"2 toLower()\u51fd\u6570"},{"location":"7_2.html#3-substring","text":"\u8fd4\u56de\u4e00\u4e2a\u5b50\u5b57\u7b26\u4e32\u3002 \u6f14\u793a\uff1a # \u8f93\u5165\u5b57\u7b26\u4e32\u4e3a input_str , \u8fd4\u56de\u4ece\u7d22\u5f15 start_index\u5f00\u59cb \uff0c\u5230 end_index - 1 \u7ed3\u675f\u7684\u5b50\u5b57\u7b26\u4e32 substring ( input_str , start_index , end_index ) # \u793a\u4f8b\u4ee3\u7801\uff0c\u8fd4\u56de\u5458\u5de5\u540d\u5b57\u7684\u524d\u4e24\u4e2a\u5b57\u6bcd MATCH ( e : Employee ) RETURN e . id , substring ( e . name , 0 , 2 ), e . salary , e . deptno \u6548\u679c\uff1a","title":"3 substring()\u51fd\u6570"},{"location":"7_2.html#4-replace","text":"\u66ff\u6362\u6389\u5b50\u5b57\u7b26\u4e32\u3002 \u6f14\u793a\uff1a # \u8f93\u5165\u5b57\u7b26\u4e32\u4e3a input_str , \u5c06\u8f93\u5165\u5b57\u7b26\u4e32\u4e2d\u7b26\u5408 origin_str\u7684\u90e8\u5206 \uff0c\u66ff\u6362\u6210 new_str replace ( input_str , origin_str , new_str ) # \u793a\u4f8b\u4ee3\u7801\uff0c\u5c06\u5458\u5de5\u540d\u5b57\u66ff\u6362\u4e3a\u6dfb\u52a0\u540e\u7f00 _HelloWorld MATCH ( e : Employee ) RETURN e . id , replace ( e . name , e . name , e . name + \"_HelloWorld\" ), e . salary , e . deptno # \u8fd8\u539f MATCH ( e : Employee ) RETURN e . id , replace ( e . name , \"_HelloWorld\" , \"\" ), e . salary , e . deptno \u6548\u679c\uff1a","title":"4 replace()\u51fd\u6570"},{"location":"7_2.html#10","text":"count()\u51fd\u6570 max()\u51fd\u6570 min()\u51fd\u6570 sum()\u51fd\u6570 avg()\u51fd\u6570","title":"10 \u805a\u5408\u51fd\u6570"},{"location":"7_2.html#1-count","text":"\u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u6761\u6570\u3002 \u6f14\u793a\uff1a # \u8fd4\u56de\u5339\u914d\u6807\u7b7e Employee\u6210\u529f\u7684\u8bb0\u5f55\u4e2a\u6570 MATCH ( e : Employee ) RETURN count ( * ) \u6548\u679c\uff1a","title":"1 count()\u51fd\u6570"},{"location":"7_2.html#2-max","text":"\u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u8bb0\u5f55\u4e2d\u7684\u6700\u5927\u503c\u3002 \u6f14\u793a\uff1a # \u8fd4\u56de\u5339\u914d\u6807\u7b7e Employee\u6210\u529f\u7684\u8bb0\u5f55\u4e2d \uff0c\u6700\u9ad8\u7684\u5de5\u8d44\u6570\u5b57 MATCH ( e : Employee ) RETURN max ( e . salary ) \u6548\u679c\uff1a","title":"2 max()\u51fd\u6570"},{"location":"7_2.html#3-min","text":"\u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u8bb0\u5f55\u4e2d\u7684\u6700\u5c0f\u503c\u3002 \u6f14\u793a\uff1a # \u8fd4\u56de\u5339\u914d\u6807\u7b7e Employee\u6210\u529f\u7684\u8bb0\u5f55\u4e2d \uff0c\u6700\u4f4e\u7684\u5de5\u8d44\u6570\u5b57 MATCH ( e : Employee ) RETURN min ( e . salary ) \u6548\u679c\uff1a","title":"3 min()\u51fd\u6570"},{"location":"7_2.html#4-sum","text":"\u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u8bb0\u5f55\u4e2d\u67d0\u5b57\u6bb5\u7684\u5168\u90e8\u52a0\u548c\u503c\u3002 \u6f14\u793a\uff1a # \u8fd4\u56de\u5339\u914d\u6807\u7b7e Employee\u6210\u529f\u7684\u8bb0\u5f55\u4e2d \uff0c\u6240\u6709\u5458\u5de5\u5de5\u8d44\u7684\u548c MATCH ( e : Employee ) RETURN sum ( e . salary ) \u6548\u679c\uff1a","title":"4 sum()\u51fd\u6570"},{"location":"7_2.html#5-avg","text":"\u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u8bb0\u5f55\u4e2d\u67d0\u5b57\u6bb5\u7684\u5e73\u5747\u503c\u3002 \u6f14\u793a\uff1a # \u8fd4\u56de\u5339\u914d\u6807\u7b7e Employee\u6210\u529f\u7684\u8bb0\u5f55\u4e2d \uff0c\u6240\u6709\u5458\u5de5\u5de5\u8d44\u7684\u5e73\u5747\u503c MATCH ( e : Employee ) RETURN avg ( e . salary ) \u6548\u679c\uff1a","title":"5 avg()\u51fd\u6570"},{"location":"7_2.html#11-index","text":"Neo4j\u652f\u6301\u5728\u8282\u70b9\u6216\u5173\u7cfb\u5c5e\u6027\u4e0a\u7684\u7d22\u5f15\uff0c\u4ee5\u63d0\u9ad8\u67e5\u8be2\u7684\u6027\u80fd\u3002 \u53ef\u4ee5\u4e3a\u5177\u6709\u76f8\u540c\u6807\u7b7e\u540d\u79f0\u7684\u6240\u6709\u8282\u70b9\u7684\u5c5e\u6027\u521b\u5efa\u7d22\u5f15\u3002","title":"11 \u7d22\u5f15index"},{"location":"7_2.html#1","text":"\u4f7f\u7528create index on\u6765\u521b\u5efa\u7d22\u5f15\u3002 \u6f14\u793a\uff1a # \u521b\u5efa\u8282\u70b9 Employee\u4e0a\u9762\u5c5e\u6027id\u7684\u7d22\u5f15 CREATE INDEX ON : Employee ( id ) \u6548\u679c\uff1a","title":"1 \u521b\u5efa\u7d22\u5f15"},{"location":"7_2.html#2","text":"\u4f7f\u7528drop index on\u6765\u5220\u9664\u7d22\u5f15\u3002 \u6f14\u793a\uff1a # \u5220\u9664\u8282\u70b9 Employee\u4e0a\u9762\u5c5e\u6027id\u7684\u7d22\u5f15 DROP INDEX ON : Employee ( id ) \u6548\u679c\uff1a","title":"2 \u5220\u9664\u7d22\u5f15"},{"location":"7_2.html#12","text":"\u5b66\u4e60\u4e86Cypher\u7684\u57fa\u672c\u6982\u5ff5\uff1a Cypher\u662fneo4j\u56fe\u6570\u636e\u7684\u67e5\u8be2\u8bed\u8a00\uff0c\u7c7b\u4f3c\u4e8emysql\u6570\u636e\u5e93\u7684sql\u8bed\u53e5\uff0c\u4f46\u662f\u5b83\u5141\u8bb8\u5bf9\u56fe\u5f62\u8fdb\u884c\u5bcc\u6709\u8868\u73b0\u529b\u548c\u6709\u6548\u7684\u67e5\u8be2\u548c\u66f4\u65b0\u3002 Cypher\u7684\u57fa\u672c\u547d\u4ee4\u548c\u8bed\u6cd5\uff1a create\u547d\u4ee4\uff1a\u521b\u5efa\u56fe\u6570\u636e\u4e2d\u7684\u8282\u70b9\u3002 CREATE (e:Employee{id:222, name:'Bob', salary:6000, deptnp:12}) match\u547d\u4ee4\uff1a\u5339\u914d(\u67e5\u8be2)\u5df2\u6709\u6570\u636e\u3002 MATCH (e:Employee) RETURN e.id, e.name, e.salary, e.deptno merge\u547d\u4ee4\uff1a\u82e5\u8282\u70b9\u5b58\u5728\uff0c\u5219\u7b49\u6548\u4e0ematch\u547d\u4ee4; \u8282\u70b9\u4e0d\u5b58\u5728\uff0c\u5219\u7b49\u6548\u4e8ecreate\u547d\u4ee4\u3002 MERGE (e:Employee {id:145, name:'Lucy', salary:7500, deptno:12}) \u4f7f\u7528create\u521b\u5efa\u5173\u7cfb\uff1a\u5fc5\u987b\u521b\u5efa\u6709\u65b9\u5411\u6027\u7684\u5173\u7cfb\uff0c\u5426\u5219\u62a5\u9519\u3002 CREATE (p1:Profile1)-[r:Buy]->(p2:Profile2) \u4f7f\u7528merge\u521b\u5efa\u5173\u7cfb\uff1a\u53ef\u4ee5\u521b\u5efa\u6709/\u65e0\u65b9\u5411\u6027\u7684\u5173\u7cfb\u3002 MERGE (p1:Profile1)-[r:miss]-(p2:Profile2) where\u547d\u4ee4\uff1a\u7c7b\u4f3c\u4e8eSQL\u4e2d\u7684\u6dfb\u52a0\u67e5\u8be2\u6761\u4ef6\u3002 MATCH (e:Employee) WHERE e.id=123 RETURN e delete\u547d\u4ee4\uff1a\u5220\u9664\u8282\u70b9/\u5173\u7cfb\u53ca\u5176\u5173\u8054\u7684\u5c5e\u6027\u3002 MATCH (c1:CreditCard)-[r]-(c2:Customer) DELETE c1, r, c2 sort\u547d\u4ee4\uff1aCypher\u547d\u4ee4\u4e2d\u7684\u6392\u5e8f\u4f7f\u7528\u7684\u662forder by. MATCH (e:Employee) RETURN e.id, e.name, e.salary, e.deptno ORDER BY e.id toUpper()\u51fd\u6570\uff1a\u5c06\u4e00\u4e2a\u8f93\u5165\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u5927\u5199\u5b57\u6bcd\u3002 MATCH (e:Employee) RETURN e.id, toUpper(e.name), e.salary, e.deptno toLower()\u51fd\u6570\uff1a\u8bb2\u4e00\u4e2a\u8f93\u5165\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u5c0f\u5199\u5b57\u6bcd\u3002 MATCH (e:Employee) RETURN e.id, toLower(e.name), e.salary, e.deptno substring()\u51fd\u6570\uff1a\u8fd4\u56de\u4e00\u4e2a\u5b50\u5b57\u7b26\u4e32\u3002 MATCH (e:Employee) RETURN e.id, substring(e.name,0,2), e.salary, e.deptno replace()\u51fd\u6570\uff1a\u66ff\u6362\u6389\u5b50\u5b57\u7b26\u4e32\u3002 MATCH (e:Employee) RETURN e.id, replace(e.name,e.name,e.name + \"_HelloWorld\"), e.salary, e.deptno count()\u51fd\u6570\uff1a\u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u6761\u6570\u3002 MATCH (e:Employee) RETURN count( * ) max()\u51fd\u6570\uff1a\u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u8bb0\u5f55\u4e2d\u7684\u6700\u5927\u503c\u3002 MATCH (e:Employee) RETURN max(e.salary) min()\u51fd\u6570\uff1a\u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u8bb0\u5f55\u4e2d\u7684\u6700\u5c0f\u503c\u3002 MATCH (e:Employee) RETURN min(e.salary) sum()\u51fd\u6570\uff1a\u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u8bb0\u5f55\u4e2d\u67d0\u5b57\u6bb5\u7684\u5168\u90e8\u52a0\u548c\u503c\u3002 MATCH (e:Employee) RETURN sum(e.salary) avg()\u51fd\u6570\uff1a\u8fd4\u56de\u7531match\u547d\u4ee4\u5339\u914d\u6210\u529f\u7684\u8bb0\u5f55\u4e2d\u67d0\u5b57\u6bb5\u7684\u5e73\u5747\u503c\u3002 MATCH (e:Employee) RETURN avg(e.salary) \u7d22\u5f15index Neo4j\u652f\u6301\u5728\u8282\u70b9\u6216\u5173\u7cfb\u5c5e\u6027\u4e0a\u7684\u7d22\u5f15\uff0c\u4ee5\u63d0\u9ad8\u67e5\u8be2\u7684\u6027\u80fd\u3002 \u53ef\u4ee5\u4e3a\u5177\u6709\u76f8\u540c\u6807\u7b7e\u540d\u79f0\u7684\u6240\u6709\u8282\u70b9\u7684\u5c5e\u6027\u521b\u5efa\u7d22\u5f15\u3002 \u521b\u5efa\u7d22\u5f15\uff1a\u4f7f\u7528create index on\u6765\u521b\u5efa\u7d22\u5f15\u3002 CREATE INDEX ON:Employee(id) \u5220\u9664\u7d22\u5f15\uff1a\u4f7f\u7528drop index on\u6765\u5220\u9664\u7d22\u5f15\u3002 DROP INDEX ON:Employee(id)","title":"12 \u5c0f\u8282\u603b\u7ed3"},{"location":"7_2.html#724-pythonneo4j","text":"\u5b66\u4e60\u76ee\u6807 \u4e86\u89e3python\u4e2dneo4j-driver\u7684\u76f8\u5173\u77e5\u8bc6\u3002 \u638c\u63e1neo4j\u4e2d\u4e8b\u52a1\u6982\u5ff5\u548c\u64cd\u4f5c\u65b9\u6cd5\u3002","title":"7.2.4 \u5728Python\u4e2d\u4f7f\u7528neo4j"},{"location":"7_2.html#1-neo4j-driver","text":"neo4j-driver\u662f\u4e00\u4e2apython\u4e2d\u7684package, \u4f5c\u4e3apython\u4e2dneo4j\u7684\u9a71\u52a8\uff0c\u5e2e\u52a9\u6211\u4eec\u5728python\u7a0b\u5e8f\u4e2d\u66f4\u597d\u7684\u4f7f\u7528\u56fe\u6570\u636e\u5e93\u3002 neo4j-driver\u7684\u5b89\u88c5\uff1a pip install neo4j-driver neo4j-driver\u4f7f\u7528\u6f14\u793a\uff1a from neo4j import GraphDatabase # uri = \"neo4j://192.168.88.161:7687\" # 4.x\u7248\u672c\u7528\u8fd9\u4e2a uri = \"bolt://192.168.88.161:7687\" # 3.x\u7248\u672c\u7528\u8fd9\u4e2a driver = GraphDatabase . driver ( uri , auth = ( \"neo4j\" , \"123456\" ), max_connection_lifetime = 1000 ) # \u76f4\u63a5\u7528python\u4ee3\u7801\u5f62\u5f0f\u8bbf\u95ee\u8282\u70b9Company, \u5e76\u8fd4\u56de\u6240\u6709\u8282\u70b9\u4fe1\u606f with driver . session () as session : cypher = \"CREATE(c:Company) SET c.name='\u9ed1\u9a6c\u7a0b\u5e8f\u5458' RETURN c.name\" record = session . run ( cypher ) result = list ( map ( lambda x : x [ 0 ], record )) print ( \"result:\" , result ) \u8f93\u51fa\u6548\u679c\uff1a result: \u9ed1\u9a6c\u7a0b\u5e8f\u5458","title":"1 neo4j-driver\u7b80\u4ecb\uff1a"},{"location":"7_2.html#2_1","text":"\u5982\u679c\u4e00\u7ec4\u6570\u636e\u5e93\u64cd\u4f5c\u8981\u4e48\u5168\u90e8\u53d1\u751f\u8981\u4e48\u4e00\u6b65\u4e5f\u4e0d\u6267\u884c\uff0c\u6211\u4eec\u79f0\u8be5\u7ec4\u5904\u7406\u6b65\u9aa4\u4e3a\u4e00\u4e2a\u4e8b\u52a1\uff0c\u5b83\u662f\u6570\u636e\u5e93\u4e00\u81f4\u6027\u7684\u4fdd\u8bc1\u3002 \u4f7f\u7528\u4e8b\u52a1\u7684\u6f14\u793a\uff1a # \u4e0b\u9762\u53ef\u4ee5\u6b63\u5e38\u6267\u884c def _some_operations ( sess , cat_name , mouse_name ): sess . run ( \"MERGE (a:Cat{name: $cat_name})\" \"MERGE (b:Mouse{name: $mouse_name})\" \"MERGE (a)-[r:And]-(b)\" , cat_name = cat_name , mouse_name = mouse_name ) with driver . session () as session : session . write_transaction ( _some_operations , \"Tom\" , \"Jerry\" ) # \u4e0b\u9762\u6267\u884c\u65f6\u62a5\u9519 def _some_operations ( sess , cat_name , mouse_name ): sess . run ( \"MERGE (a:Cat{name: $cat_name})\" \"MERGE (b:Mouse{name: $mouse_name})\" \"CREATE (a)-[r:And]-(b)\" , cat_name = cat_name , mouse_name = mouse_name ) with driver . session () as session : session . write_transaction ( _some_operations , \"Tom1\" , \"Jerry1\" ) \u8f93\u51fa\u6548\u679c\uff1a","title":"2 \u4e8b\u52a1\u7684\u6982\u5ff5"},{"location":"7_2.html#3_1","text":"\u5b66\u4e60\u4e86neo4j-driver\u7b80\u4ecb\uff1a neo4j-driver\u662f\u4e00\u4e2apython\u4e2d\u7684package, \u4f5c\u4e3apython\u4e2dneo4j\u7684\u9a71\u52a8\uff0c\u5e2e\u52a9\u6211\u4eec\u5728python\u7a0b\u5e8f\u4e2d\u66f4\u597d\u7684\u4f7f\u7528\u56fe\u6570\u636e\u5e93\u3002 \u5b66\u4e60\u4e86neo4j-driver\u7684\u5b89\u88c5\u548c\u4f7f\u7528\u65b9\u6cd5\u3002 \u5b66\u4e60\u4e86\u4e8b\u52a1\u7684\u6982\u5ff5\uff1a \u5982\u679c\u4e00\u7ec4\u6570\u636e\u5e93\u64cd\u4f5c\u8981\u4e48\u5168\u90e8\u53d1\u751f\u8981\u4e48\u4e00\u6b65\u4e5f\u4e0d\u6267\u884c\uff0c\u6211\u4eec\u79f0\u8be5\u7ec4\u5904\u7406\u6b65\u9aa4\u4e3a\u4e00\u4e2a\u4e8b\u52a1\uff0c\u5b83\u662f\u6570\u636e\u5e93\u4e00\u81f4\u6027\u7684\u4fdd\u8bc1\u3002 \u5b66\u4e60\u4e86\u5982\u4f55\u4f7f\u7528\u4e8b\u52a1\u6765\u5411\u56fe\u6570\u636e\u5e93\u4e2d\u5199\u5165\u6570\u636e\u3002","title":"3 \u5c0f\u8282\u603b\u7ed3"},{"location":"8_1.html","text":"\u7ecf\u5178\u77e5\u8bc6\u8865\u5168 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u7406\u89e3isA\u5173\u7cfb\u8865\u5168\u7684\u6982\u5ff5\u4e0e\u65b9\u6cd5. \u7406\u89e3isA\u5173\u7cfb\u7ea0\u9519\u7684\u6982\u5ff5\u4e0e\u65b9\u6cd5. isA\u5173\u7cfb\u8865\u5168 \u00b6 \u4e92\u8054\u7f51\u65f6\u4ee3, \u6d77\u91cf\u8bed\u6599\u52a0\u4e0a\u8d8a\u6765\u8d8a\u5f3a\u5927\u7684\u62bd\u53d6\u5de5\u5177, \u57fa\u4e8e\u81ea\u7531\u6587\u672c\u8bed\u6599\u901a\u8fc7\u81ea\u52a8\u5316\u62bd\u53d6\u800c\u5efa\u7acb\u7684\u77e5\u8bc6\u56fe\u8c31\u4ecd\u53ef\u80fd\u5b58\u5728isA\u5173\u7cfb\u7f3a\u5931\u7684\u60c5\u51b5. \u4f8b\u5982: \u867d\u7136Probase\u5305\u542b\u7ea61000\u4e07\u4e2a\u5b9e\u4f53\u548c\u7ea61600\u4e07\u6761isA\u5173\u7cfb, \u4f46\u5e73\u5747\u6bcf\u4e2a\u5b9e\u4f53\u53ea\u6709\u7ea61.6\u4e2a\u4e0a\u4f4d\u8bcd! \u4f46\u5bf9\u4e8e\u4eba\u7c7b\u6765\u8bf4, \u6240\u80fd\u679a\u4e3e\u7684\u6982\u5ff5\u663e\u7136\u8fdc\u8d85\u8fd9\u4e00\u6570\u503c! isA\u5173\u7cfb\u7f3a\u5931\u539f\u56e0 \u00b6 \u4efb\u4f55\u4ece\u6587\u672c\u8bed\u6599\u4e2d\u901a\u8fc7\u81ea\u52a8\u62bd\u53d6\u65b9\u6cd5\u6784\u5efa\u7684\u77e5\u8bc6\u56fe\u8c31\u90fd\u5b58\u5728\u4e00\u5b9a\u7a0b\u5ea6\u7684\u7f3a\u5931, \u6839\u672c\u539f\u56e0\u5728\u4e8e, \u67d0\u4e2a\u7279\u5b9a\u7684\u6587\u672c\u8bed\u6599\u53ea\u662f\u5bf9\u77e5\u8bc6\u5168\u96c6\u7684\u4e00\u4e2a\u4e0d\u5b8c\u6574\u7684\u8868\u8fbe. \u6bd4\u5982, \u4e2d\u56fd\u4eba\u65e5\u5e38\u751f\u6d3b\u4e2d\u7684\u6cb9\u6761, \u8c46\u6d46, \u5c0f\u7b3c\u5305\u7b49\u65e9\u9910\u77e5\u8bc6\u5728\u5176\u4ed6\u8bed\u79cd\u4e2d\u5b8c\u5168\u6ca1\u6709\u8fd9\u4e2a\u6982\u5ff5, \u6781\u5c11\u4f1a\u88ab\u63d0\u53ca. \u601d\u8003: \u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u589e\u52a0\u8bed\u6599\u7684\u66b4\u529b\u89e3\u6cd5\u6765\u89e3\u51b3\u77e5\u8bc6\u7f3a\u5931\u95ee\u9898\u5462? \u603b\u4f53\u6765\u8bf4\u67093\u4e2a\u539f\u56e0: \u7b2c\u4e00: \u8de8\u8bed\u8a00\u5b58\u5728\u6587\u5316\u754c\u9650 \u7b2c\u4e8c: \u4f4e\u9891\u5b9e\u4f53\u76f8\u5173\u77e5\u8bc6\u7f3a\u5931 \u7b2c\u4e09: \u5e38\u8bc6\u76f8\u5173\u77e5\u8bc6\u7f3a\u5931 \u76ee\u524d\u5b66\u672f\u754c, \u5de5\u4e1a\u754c\u89e3\u51b3isA\u5173\u7cfb\u7f3a\u5931\u7684\u4e3b\u6d41\u601d\u60f3\u5305\u62ec\u4e24\u79cd: \u5229\u7528isA\u5173\u7cfb\u7684\u4f20\u9012\u6027: \u6bd4\u5982, \"\u67cf\u62c9\u56fe\"\u662f\u4e00\u4e2a\"\u54f2\u5b66\u5bb6\", \u540c\u65f6\u8fd8\u6709\"\u54f2\u5b66\u5bb6\u662f\u4eba\", \u90a3\u4e48\u5c31\u53ef\u4ee5\u63a8\u7406\u51fa\"\u67cf\u62c9\u56fe\u662f\u4e00\u4e2a\u4eba\". \u5229\u7528\u76f8\u4f3c\u5b9e\u4f53: \u534f\u540c\u8fc7\u6ee4\u601d\u60f3 \u57fa\u4e8e\u4f20\u9012\u6027\u7684\u77e5\u8bc6\u8865\u5168 \u00b6 isA\u5173\u7cfb\u5728\u7406\u8bba\u4e0a\u5177\u6709\u4f20\u9012\u6027: \u82e5x isA y \u4e14 y isA z, \u5219x isA z\u6210\u7acb! \u4f8b\u5982, \u7231\u56e0\u65af\u5766\u662f\u7269\u7406\u5b66\u5bb6, \u7269\u7406\u5b66\u5bb6\u662f\u79d1\u5b66\u5bb6, \u5219\u53ef\u4ee5\u5c06\"\u7231\u56e0\u65af\u5766\u662f\u79d1\u5b66\u5bb6\"\u52a0\u5165\u56fe\u8c31\u4e2d. \u601d\u8003: \u4ece\u5927\u89c4\u6a21\u6587\u672c\u8bed\u6599\u81ea\u52a8\u62bd\u53d6\u6784\u5efa\u7684\u5927\u89c4\u6a21\u8bcd\u6c47\u56fe\u8c31\u4e2d, isA\u5173\u7cfb\u7684\u4f20\u9012\u6027\u662f\u5426\u603b\u662f\u6210\u7acb\u7684? \u4f8b\u5b50: Einstein isA Physicist, \u4e14Physicist isA Job, \u4f46\u662fEinstein isA Job\u4e0d\u6210\u7acb!!! \u601d\u8003: \u4e3a\u4e86\u63d0\u5347isA\u5173\u7cfb\u4f20\u9012\u6027\u7684\u53ef\u9760\u5ea6, \u6709\u4ec0\u4e48\u6709\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u5417? \u57fa\u4e8e\u534f\u540c\u8fc7\u6ee4\u7684\u77e5\u8bc6\u8865\u5168 \u00b6 \u57fa\u4e8e\u4f20\u9012\u6027\u8fdb\u884c\u8865\u5168\u7684\u65b9\u6cd5\u80fd\u627e\u5230\u5927\u91cf\u65b0\u7684isA\u5173\u7cfb, \u4f46\u662f\u6709\u4e00\u5b9a\u7684\u5c40\u9650\u6027: \u8fd9\u79cd\u65b9\u6cd5\u5fc5\u987b\u5b58\u5728\u4e00\u4e2a\u4e2d\u95f4\"\u6865\u6881\u6982\u5ff5\"\u7684isA\u5173\u7cfb!!! \u53e6\u4e00\u4e2a\u601d\u8def: \u76f8\u4f3c\u5b9e\u4f53\u62e5\u6709\u7c7b\u4f3c\u7684\u4e0a\u4f4d\u8bcd!!! \u6bd4\u5982, \u5728\u8003\u8651\"Steve Jobs\"\u65f6, \u4eba\u4eec\u5f88\u5bb9\u6613\u60f3\u5230\"Bill Gates\", \u7531\u4e8e\u540e\u8005\u5c5e\u4e8e\"Billionaire\"\u8fd9\u4e00\u6982\u5ff5, \u56e0\u6b64\u53ef\u4ee5\u63a8\u65ad\u51fa\"Steve Jobs isA Billionaire\". \u57fa\u4e8e\u534f\u540c\u8fc7\u6ee4\u601d\u60f3\u7684\u77e5\u8bc6\u8865\u5168\u7b97\u6cd5\u6846\u67b6: \u7b2c\u4e00\u6b65: \u5728\u56fe\u8c31\u4e2d\u5bfb\u627ec\u7684\u76f8\u4f3c\u6982\u5ff5\u6216\u5b9e\u4f53\u96c6\u5408Sim\u00a9 = {s1, s2, ...}, \u8fd9\u4e00\u8fc7\u7a0b\u7684\u6838\u5fc3\u662f\u76f8\u4f3c\u5ea6\u8ba1\u7b97. \u7b2c\u4e8c\u6b65: \u4eceSim\u00a9\u7684\u4e0a\u4f4d\u6982\u5ff5\u96c6\u5408\u4e2d, \u5bfb\u627ec\u7684\u5019\u9009\u7f3a\u5931\u4e0a\u4f4d\u8bcd, \u8fd9\u4e00\u8fc7\u7a0b\u7684\u6838\u5fc3\u662f\u8ba1\u7b97\u4e0a\u4f4d\u8bcd\u7684\u63a8\u8350\u5206\u6570. isA\u5173\u7cfb\u7ea0\u9519 \u00b6 \u4ece\u5927\u89c4\u6a21\u8bed\u6599, \u7279\u522b\u662f\u4e92\u8054\u7f51\u8bed\u6599\u4e2d, \u901a\u8fc7\u81ea\u52a8\u62bd\u53d6\u6280\u672f\u6784\u5efa\u51fa\u6765\u7684\u5343\u4e07\u8282\u70b9\u89c4\u6a21\u7684\u56fe\u8c31, \u4e0d\u53ef\u80fd\u6ca1\u6709\u9519\u8bef. \u5bf9\u4e8e\u4e00\u4e2a\u5343\u4e07\u8282\u70b9\u89c4\u6a21\u7684\u6982\u5ff5\u56fe\u8c31, \u5373\u4f7f\u662f1%\u7684\u9519\u8bef\u7387, \u9519\u8bef\u5173\u7cfb\u7684\u7edd\u5bf9\u6570\u91cf\u4e5f\u53ef\u80fd\u572810\u4e07\u7ea7\u522b. \u800c\u8fd9\u4e9b\u9519\u8bef\u4f1a\u5bf9\u4e0b\u6e38\u5e94\u7528\u4ea7\u751f\u663e\u8457\u7684\u8d1f\u9762\u5f71\u54cd. \u9519\u8bef\u7684\u6210\u56e0 \u00b6 \u56e0\u6b64, \u6709\u5fc5\u8981\u5bf9\u81ea\u52a8\u62bd\u53d6\u5230\u7684\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u6e05\u6d17, \u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u56fe\u8c31\u7684\u8d28\u91cf. \u81ea\u52a8\u5316\u6784\u5efa\u56fe\u8c31\u5305\u62ec3\u4e2a\u57fa\u672c\u6b65\u9aa4, \u6bcf\u4e00\u6b65\u90fd\u53ef\u80fd\u5f15\u5165\u9519\u8bef: \u7b2c\u4e00\u6b65: \u9996\u5148\u6536\u96c6\u5927\u91cf\u8bed\u6599. \u7b2c\u4e8c\u6b65: \u4f7f\u7528\u5404\u79cd\u62bd\u53d6\u7b97\u6cd5\u4ece\u8bed\u6599\u4e2d\u81ea\u52a8\u62bd\u53d6\u5b9e\u4f53, \u6982\u5ff5\u548cisA\u5173\u7cfb. \u7b2c\u4e09\u6b65: \u6700\u540e\u7528\u4e00\u4e9b\u81ea\u52a8\u63a8\u7406\u6280\u672f\u8865\u5168isA\u5173\u7cfb. \u6765\u81ea\u8bed\u6599\u7684\u9519\u8bef: \u73b0\u5b9e\u4e2d\u5f88\u591a\u4fee\u8f9e, \u6bd4\u55bb, \u4f1a\u62bd\u53d6\u51fa\u5f88\u591a\u4e0d\u73b0\u5b9e\u7684\u5173\u7cfb. \u4e92\u8054\u7f51\u4e2d\u5f80\u5f80\u8fd8\u5305\u542b\u9519\u8bef\u7684\u53e5\u5b50, \u4e0d\u6070\u5f53\u7684\u8868\u8fbe, \u751a\u81f3\u662f\u7b14\u8bef, \u8fd9\u4e9b\u90fd\u4f1a\u9020\u6210\u62bd\u53d6\u7684\u9519\u8bef. \u6765\u81ea\u62bd\u53d6\u7684\u9519\u8bef: \u81ea\u7136\u8bed\u8a00\u7684\u8868\u8fbe\u662f\u5341\u5206\u590d\u6742\u7684, \u800c\u62bd\u53d6\u65b9\u6cd5\u5f80\u5f80\u53c8\u662f\u5927\u91cf\u57fa\u672cNLP\u6a21\u5757(\u5206\u8bcd, \u8bcd\u6027\u6807\u6ce8, \u8bed\u6cd5\u6811\u6784\u5efa, \u8bcd\u5d4c\u5165, \u795e\u7ecf\u7f51\u7edc\u4f20\u64ad\u7b49)\u5806\u780c\u800c\u6210\u7684\u590d\u6742\u65b9\u6848, \u5bb9\u6613\u9020\u6210\u9519\u8bef\u4f20\u64ad, \u5f71\u54cd\u5230\u4e0b\u6e38\u4efb\u52a1, \u5bfc\u81f4\u6700\u7ec8\u62bd\u53d6\u51fa\u6765\u7684isA\u5173\u7cfb\u8d28\u91cf\u4f4e\u4e0b. \u6765\u81ea\u63a8\u7406\u7684\u9519\u8bef: \u4e00\u65b9\u9762\u539f\u59cb\u7684\u56fe\u8c31\u4e2d\u5c31\u5b58\u5728\u9519\u8bef, \u57fa\u4e8e\u9519\u8bef\u7684\u4e8b\u5b9e\u6240\u8fdb\u884c\u7684\u63a8\u7406\u7ed3\u679c\u5f80\u5f80\u4e5f\u662f\u9519\u7684; \u53e6\u4e00\u65b9\u9762, \u73b0\u5b9e\u4e16\u754c\u4e2d\u5f80\u5f80\u5b58\u5728\u5927\u91cf\u7279\u4f8b, \u5b83\u4eec\u4e0d\u7b26\u5408\u7b80\u5355\u7684\u63a8\u7406\u89c4\u5219. \u7efc\u4e0a\u6240\u8ff0, \u60f3\u81ea\u52a8\u627e\u5230\u6240\u6709\u9519\u8bef\u662f\u4e0d\u73b0\u5b9e\u7684, \u5de5\u4e1a\u754c\u4e2d\u4e00\u822c\u90fd\u5e0c\u671b\u80fd\u627e\u5230\u4e00\u4e9b\u673a\u5236\u548c\u65b9\u6cd5, \u5c3d\u53ef\u80fd\u591a\u5730\u8bc6\u522b\u67d0\u4e9b\u7c7b\u578b\u7684\u9519\u8bef\u4ece\u800c\u8fdb\u4e00\u6b65\u63d0\u77e5\u8bc6\u56fe\u8c31\u7684\u8d28\u91cf. \u57fa\u4e8e\u652f\u6301\u5ea6\u7684\u7ea0\u9519 \u00b6 \u4e00\u4e2a\u6709\u6548\u7684\u7ea0\u9519\u601d\u60f3, \u662f\u4e3a\u6bcf\u4e00\u6761\u77e5\u8bc6\u5bfb\u627e\u652f\u6301\u5b83\u7684\u8bc1\u636e, \u6765\u8bc1\u660e\u5b83\u7684\u6b63\u786e\u6027!!! \u6700\u76f4\u63a5\u7684\u8bc1\u636e\u662f\u8bed\u6599\u4e2d\u63d0\u53ca\u8fd9\u4e00\u6761\u77e5\u8bc6\u7684\u9891\u6b21. \u663e\u7136, \u5982\u679c\u4e00\u6761\u77e5\u8bc6\u5728\u5404\u79cd\u8bed\u6599\u7684\u5927\u91cf\u53e5\u5b50\u4e2d\u90fd\u53ef\u4ee5\u62bd\u53d6\u5230, \u90a3\u4e48\u5b83\u5f88\u6709\u53ef\u80fd\u662f\u6b63\u786e\u7684. \u5728\u7279\u5b9a\u8bed\u6599\u4e2d, \u5c06\u51fa\u73b0\u67d0\u6761\u77e5\u8bc6\u7684\u53e5\u5b50\u7684\u6570\u91cf\u4f5c\u4e3a\u8fd9\u6761\u77e5\u8bc6\u7684\u652f\u6301\u5ea6. \u7ecf\u8fc7\u5bf9Probase\u4e2d\u5177\u6709\u4e0d\u540c\u652f\u6301\u5ea6\u7684isA\u5173\u7cfb\u8fdb\u884c\u62bd\u6837\u9a8c\u8bc1, \u53d1\u73b0\u6709\u66f4\u9ad8\u652f\u6301\u5ea6\u7684isA\u5173\u7cfb\u901a\u5e38\u66f4\u53ef\u80fd\u662f\u6b63\u786e\u7684. \u601d\u8003: \u80fd\u5426\u51ed\u501f\u652f\u6301\u5ea6\u7b5b\u9009\u51fa\u9519\u8bef\u7684isA\u5173\u7cfb\u5462? \u6bd4\u5982\u652f\u6301\u5ea6\u4f4e\u4e8e\u67d0\u4e2a\u9608\u503c\u7684\u90fd\u7b97\u9519\u8bef\u5173\u7cfb. \u4ed4\u7ec6\u601d\u8003\u540e\u53d1\u73b0\u4e0d\u884c, \u5de5\u4e1a\u754c\u4e0a\u4e00\u822c\u4f1a\u91c7\u7528\u66f4\u53ef\u9760\u7684\u6307\u6807: \u53ef\u4fe1\u5ea6, \u6765\u5bf9isA\u5173\u7cfb\u8fdb\u884c\u5ea6\u91cf. \u4e00\u822c\u6765\u8bf4, \u4e00\u4e2a\u66f4\u5177\u4f53\u7684\u6982\u5ff5\u7684\u5b9e\u4f8b\u8981\u6bd4\u62bd\u8c61\u6982\u5ff5\u7684\u5b9e\u4f8b\u5c11! \u5bf9\u4e00\u6761isA\u5173\u7cfbx isA y, \u8bb0e(x)\u4e3ax\u7684\u76f4\u63a5\u4e0b\u4f4d\u8bcd\u6570\u91cf, \u4e00\u822c\u6709e(x) < e(y). \u56e0\u6b64, e(y)/e(x)\u503c\u8d8a\u5927, \u5219x isA y\u8d8a\u53ef\u4fe1! \u4f8b\u5982, \u5728Probase\u4e2d, \"juice\"\u6709173\u4e2a\u4e0b\u4f4d\u8bcd, \"tomato\"\u53ea\u670969\u4e2a\u4e0b\u4f4d\u8bcd, \u6240\u4ee5\"juice isA tomato\"\u660e\u663e\u4e0d\u53ef\u4fe1. \u6309\u7167\u516c\u53f8\u8fdb\u884c\u8ba1\u7b97\u53ef\u4fe1\u5ea6: P(x isA y) = log(1 + e(y)/e(x)). \u57fa\u4e8e\u56fe\u6a21\u578b\u7684\u7ea0\u9519 \u00b6 \u4e00\u4e2a\u7406\u60f3\u7684\u6982\u5ff5\u56fe\u8c31\u5f80\u5f80\u662f\u4e00\u4e2a\u6709\u5411\u65e0\u73af\u56fe(DAG). \u90a3\u4e48\u663e\u7136, \u73af\u4e2d\u7684isA\u5173\u7cfb\u4e4b\u95f4\u5b58\u5728\u903b\u8f91\u4e0a\u7684\u51b2\u7a81!!! \u7ed3\u8bba: \u81ea\u52a8\u5316\u6784\u5efa\u7684\u6982\u5ff5\u56fe\u8c31\u4e2d\u7684\u73af\u5f80\u5f80\u662f\u7531\u9519\u8bef\u7684isA\u5173\u7cfb\u5bfc\u81f4\u7684!!! \u91c7\u6837\u7edf\u8ba1: \u5728Probase\u4e2d, 97%\u7684\u957f\u5ea6\u4e3a2\u7684\u73af\u4e2d\u5b58\u5728\u9519\u8bef\u7684isA\u5173\u7cfb, \u800c96%\u7684\u957f\u5ea6\u4e3a3\u7684\u73af\u4e2d\u5b58\u5728\u9519\u8bef\u7684isA\u5173\u7cfb. \u5176\u5b9e, \u8fd9\u5e76\u4e0d\u662f\u4e00\u4e2a\u65b0\u95ee\u9898, \u4e8b\u5b9e\u4e0a, \u5b83\u662f\u56fe\u8bba\u4e2d\u7684\u4e00\u4e2a\u7ecf\u5178\u7684NP-Hard\u95ee\u9898\u7684\u5e26\u6743\u7248\u672c: \u6700\u5c0f\u53cd\u9988\u8fb9\u96c6\u95ee\u9898(Minimum Feedback Arc Set Problem). \u6709\u4e00\u4e9b\u8fd1\u4f3c\u89e3\u6cd5\u53ef\u4ee5\u5728\u77ed\u65f6\u95f4\u5185\u83b7\u5f97\u8fd9\u4e2a\u95ee\u9898\u7684\u8f83\u4f18\u89e3. \u8d2a\u5fc3\u7b97\u6cd5: \u6b65\u9aa41: \u4ee5\u968f\u673a\u987a\u5e8f\u679a\u4e3e\u56fe\u4e2d\u7684\u6bcf\u4e2a\u73af, \u6bcf\u6b21\u5c06\u73af\u4e2d\u6743\u503c\u6700\u5c0f\u7684\u8fb9\u5168\u90e8\u5220\u9664, \u76f4\u5230\u56fe\u4e2d\u4e0d\u5b58\u5728\u73af\u4e3a\u6b62. \u6b65\u9aa42: \u5c06\u6b65\u9aa41\u4e2d\u5220\u9664\u7684\u8fb9\u6309\u6743\u503c\u4ece\u5927\u5230\u5c0f\u6392\u5217, \u5c1d\u8bd5\u5c06\u8fd9\u4e9b\u8fb9\u9010\u4e2a\u52a0\u56de\u5230\u56fe\u4e2d. \u82e5\u4e0d\u4f1a\u4ea7\u751f\u73af, \u5219\u5c06\u5176\u52a0\u56de\u56fe\u4e2d, \u5426\u5219\u5c06\u8fd9\u6761\u8fb9\u52a0\u5165\u6700\u5c0f\u53cd\u9988\u8fb9\u96c6, \u4f5c\u4e3a\u6700\u7ec8\u8f93\u51fa\u7684\u4e00\u90e8\u5206.","title":"8.1 \u7ecf\u5178\u77e5\u8bc6\u8865\u5168"},{"location":"8_1.html#_1","text":"","title":"\u7ecf\u5178\u77e5\u8bc6\u8865\u5168"},{"location":"8_1.html#_2","text":"\u7406\u89e3isA\u5173\u7cfb\u8865\u5168\u7684\u6982\u5ff5\u4e0e\u65b9\u6cd5. \u7406\u89e3isA\u5173\u7cfb\u7ea0\u9519\u7684\u6982\u5ff5\u4e0e\u65b9\u6cd5.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"8_1.html#isa","text":"\u4e92\u8054\u7f51\u65f6\u4ee3, \u6d77\u91cf\u8bed\u6599\u52a0\u4e0a\u8d8a\u6765\u8d8a\u5f3a\u5927\u7684\u62bd\u53d6\u5de5\u5177, \u57fa\u4e8e\u81ea\u7531\u6587\u672c\u8bed\u6599\u901a\u8fc7\u81ea\u52a8\u5316\u62bd\u53d6\u800c\u5efa\u7acb\u7684\u77e5\u8bc6\u56fe\u8c31\u4ecd\u53ef\u80fd\u5b58\u5728isA\u5173\u7cfb\u7f3a\u5931\u7684\u60c5\u51b5. \u4f8b\u5982: \u867d\u7136Probase\u5305\u542b\u7ea61000\u4e07\u4e2a\u5b9e\u4f53\u548c\u7ea61600\u4e07\u6761isA\u5173\u7cfb, \u4f46\u5e73\u5747\u6bcf\u4e2a\u5b9e\u4f53\u53ea\u6709\u7ea61.6\u4e2a\u4e0a\u4f4d\u8bcd! \u4f46\u5bf9\u4e8e\u4eba\u7c7b\u6765\u8bf4, \u6240\u80fd\u679a\u4e3e\u7684\u6982\u5ff5\u663e\u7136\u8fdc\u8d85\u8fd9\u4e00\u6570\u503c!","title":"isA\u5173\u7cfb\u8865\u5168"},{"location":"8_1.html#isa_1","text":"\u4efb\u4f55\u4ece\u6587\u672c\u8bed\u6599\u4e2d\u901a\u8fc7\u81ea\u52a8\u62bd\u53d6\u65b9\u6cd5\u6784\u5efa\u7684\u77e5\u8bc6\u56fe\u8c31\u90fd\u5b58\u5728\u4e00\u5b9a\u7a0b\u5ea6\u7684\u7f3a\u5931, \u6839\u672c\u539f\u56e0\u5728\u4e8e, \u67d0\u4e2a\u7279\u5b9a\u7684\u6587\u672c\u8bed\u6599\u53ea\u662f\u5bf9\u77e5\u8bc6\u5168\u96c6\u7684\u4e00\u4e2a\u4e0d\u5b8c\u6574\u7684\u8868\u8fbe. \u6bd4\u5982, \u4e2d\u56fd\u4eba\u65e5\u5e38\u751f\u6d3b\u4e2d\u7684\u6cb9\u6761, \u8c46\u6d46, \u5c0f\u7b3c\u5305\u7b49\u65e9\u9910\u77e5\u8bc6\u5728\u5176\u4ed6\u8bed\u79cd\u4e2d\u5b8c\u5168\u6ca1\u6709\u8fd9\u4e2a\u6982\u5ff5, \u6781\u5c11\u4f1a\u88ab\u63d0\u53ca. \u601d\u8003: \u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u589e\u52a0\u8bed\u6599\u7684\u66b4\u529b\u89e3\u6cd5\u6765\u89e3\u51b3\u77e5\u8bc6\u7f3a\u5931\u95ee\u9898\u5462? \u603b\u4f53\u6765\u8bf4\u67093\u4e2a\u539f\u56e0: \u7b2c\u4e00: \u8de8\u8bed\u8a00\u5b58\u5728\u6587\u5316\u754c\u9650 \u7b2c\u4e8c: \u4f4e\u9891\u5b9e\u4f53\u76f8\u5173\u77e5\u8bc6\u7f3a\u5931 \u7b2c\u4e09: \u5e38\u8bc6\u76f8\u5173\u77e5\u8bc6\u7f3a\u5931 \u76ee\u524d\u5b66\u672f\u754c, \u5de5\u4e1a\u754c\u89e3\u51b3isA\u5173\u7cfb\u7f3a\u5931\u7684\u4e3b\u6d41\u601d\u60f3\u5305\u62ec\u4e24\u79cd: \u5229\u7528isA\u5173\u7cfb\u7684\u4f20\u9012\u6027: \u6bd4\u5982, \"\u67cf\u62c9\u56fe\"\u662f\u4e00\u4e2a\"\u54f2\u5b66\u5bb6\", \u540c\u65f6\u8fd8\u6709\"\u54f2\u5b66\u5bb6\u662f\u4eba\", \u90a3\u4e48\u5c31\u53ef\u4ee5\u63a8\u7406\u51fa\"\u67cf\u62c9\u56fe\u662f\u4e00\u4e2a\u4eba\". \u5229\u7528\u76f8\u4f3c\u5b9e\u4f53: \u534f\u540c\u8fc7\u6ee4\u601d\u60f3","title":"isA\u5173\u7cfb\u7f3a\u5931\u539f\u56e0"},{"location":"8_1.html#_3","text":"isA\u5173\u7cfb\u5728\u7406\u8bba\u4e0a\u5177\u6709\u4f20\u9012\u6027: \u82e5x isA y \u4e14 y isA z, \u5219x isA z\u6210\u7acb! \u4f8b\u5982, \u7231\u56e0\u65af\u5766\u662f\u7269\u7406\u5b66\u5bb6, \u7269\u7406\u5b66\u5bb6\u662f\u79d1\u5b66\u5bb6, \u5219\u53ef\u4ee5\u5c06\"\u7231\u56e0\u65af\u5766\u662f\u79d1\u5b66\u5bb6\"\u52a0\u5165\u56fe\u8c31\u4e2d. \u601d\u8003: \u4ece\u5927\u89c4\u6a21\u6587\u672c\u8bed\u6599\u81ea\u52a8\u62bd\u53d6\u6784\u5efa\u7684\u5927\u89c4\u6a21\u8bcd\u6c47\u56fe\u8c31\u4e2d, isA\u5173\u7cfb\u7684\u4f20\u9012\u6027\u662f\u5426\u603b\u662f\u6210\u7acb\u7684? \u4f8b\u5b50: Einstein isA Physicist, \u4e14Physicist isA Job, \u4f46\u662fEinstein isA Job\u4e0d\u6210\u7acb!!! \u601d\u8003: \u4e3a\u4e86\u63d0\u5347isA\u5173\u7cfb\u4f20\u9012\u6027\u7684\u53ef\u9760\u5ea6, \u6709\u4ec0\u4e48\u6709\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u5417?","title":"\u57fa\u4e8e\u4f20\u9012\u6027\u7684\u77e5\u8bc6\u8865\u5168"},{"location":"8_1.html#_4","text":"\u57fa\u4e8e\u4f20\u9012\u6027\u8fdb\u884c\u8865\u5168\u7684\u65b9\u6cd5\u80fd\u627e\u5230\u5927\u91cf\u65b0\u7684isA\u5173\u7cfb, \u4f46\u662f\u6709\u4e00\u5b9a\u7684\u5c40\u9650\u6027: \u8fd9\u79cd\u65b9\u6cd5\u5fc5\u987b\u5b58\u5728\u4e00\u4e2a\u4e2d\u95f4\"\u6865\u6881\u6982\u5ff5\"\u7684isA\u5173\u7cfb!!! \u53e6\u4e00\u4e2a\u601d\u8def: \u76f8\u4f3c\u5b9e\u4f53\u62e5\u6709\u7c7b\u4f3c\u7684\u4e0a\u4f4d\u8bcd!!! \u6bd4\u5982, \u5728\u8003\u8651\"Steve Jobs\"\u65f6, \u4eba\u4eec\u5f88\u5bb9\u6613\u60f3\u5230\"Bill Gates\", \u7531\u4e8e\u540e\u8005\u5c5e\u4e8e\"Billionaire\"\u8fd9\u4e00\u6982\u5ff5, \u56e0\u6b64\u53ef\u4ee5\u63a8\u65ad\u51fa\"Steve Jobs isA Billionaire\". \u57fa\u4e8e\u534f\u540c\u8fc7\u6ee4\u601d\u60f3\u7684\u77e5\u8bc6\u8865\u5168\u7b97\u6cd5\u6846\u67b6: \u7b2c\u4e00\u6b65: \u5728\u56fe\u8c31\u4e2d\u5bfb\u627ec\u7684\u76f8\u4f3c\u6982\u5ff5\u6216\u5b9e\u4f53\u96c6\u5408Sim\u00a9 = {s1, s2, ...}, \u8fd9\u4e00\u8fc7\u7a0b\u7684\u6838\u5fc3\u662f\u76f8\u4f3c\u5ea6\u8ba1\u7b97. \u7b2c\u4e8c\u6b65: \u4eceSim\u00a9\u7684\u4e0a\u4f4d\u6982\u5ff5\u96c6\u5408\u4e2d, \u5bfb\u627ec\u7684\u5019\u9009\u7f3a\u5931\u4e0a\u4f4d\u8bcd, \u8fd9\u4e00\u8fc7\u7a0b\u7684\u6838\u5fc3\u662f\u8ba1\u7b97\u4e0a\u4f4d\u8bcd\u7684\u63a8\u8350\u5206\u6570.","title":"\u57fa\u4e8e\u534f\u540c\u8fc7\u6ee4\u7684\u77e5\u8bc6\u8865\u5168"},{"location":"8_1.html#isa_2","text":"\u4ece\u5927\u89c4\u6a21\u8bed\u6599, \u7279\u522b\u662f\u4e92\u8054\u7f51\u8bed\u6599\u4e2d, \u901a\u8fc7\u81ea\u52a8\u62bd\u53d6\u6280\u672f\u6784\u5efa\u51fa\u6765\u7684\u5343\u4e07\u8282\u70b9\u89c4\u6a21\u7684\u56fe\u8c31, \u4e0d\u53ef\u80fd\u6ca1\u6709\u9519\u8bef. \u5bf9\u4e8e\u4e00\u4e2a\u5343\u4e07\u8282\u70b9\u89c4\u6a21\u7684\u6982\u5ff5\u56fe\u8c31, \u5373\u4f7f\u662f1%\u7684\u9519\u8bef\u7387, \u9519\u8bef\u5173\u7cfb\u7684\u7edd\u5bf9\u6570\u91cf\u4e5f\u53ef\u80fd\u572810\u4e07\u7ea7\u522b. \u800c\u8fd9\u4e9b\u9519\u8bef\u4f1a\u5bf9\u4e0b\u6e38\u5e94\u7528\u4ea7\u751f\u663e\u8457\u7684\u8d1f\u9762\u5f71\u54cd.","title":"isA\u5173\u7cfb\u7ea0\u9519"},{"location":"8_1.html#_5","text":"\u56e0\u6b64, \u6709\u5fc5\u8981\u5bf9\u81ea\u52a8\u62bd\u53d6\u5230\u7684\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u6e05\u6d17, \u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u56fe\u8c31\u7684\u8d28\u91cf. \u81ea\u52a8\u5316\u6784\u5efa\u56fe\u8c31\u5305\u62ec3\u4e2a\u57fa\u672c\u6b65\u9aa4, \u6bcf\u4e00\u6b65\u90fd\u53ef\u80fd\u5f15\u5165\u9519\u8bef: \u7b2c\u4e00\u6b65: \u9996\u5148\u6536\u96c6\u5927\u91cf\u8bed\u6599. \u7b2c\u4e8c\u6b65: \u4f7f\u7528\u5404\u79cd\u62bd\u53d6\u7b97\u6cd5\u4ece\u8bed\u6599\u4e2d\u81ea\u52a8\u62bd\u53d6\u5b9e\u4f53, \u6982\u5ff5\u548cisA\u5173\u7cfb. \u7b2c\u4e09\u6b65: \u6700\u540e\u7528\u4e00\u4e9b\u81ea\u52a8\u63a8\u7406\u6280\u672f\u8865\u5168isA\u5173\u7cfb. \u6765\u81ea\u8bed\u6599\u7684\u9519\u8bef: \u73b0\u5b9e\u4e2d\u5f88\u591a\u4fee\u8f9e, \u6bd4\u55bb, \u4f1a\u62bd\u53d6\u51fa\u5f88\u591a\u4e0d\u73b0\u5b9e\u7684\u5173\u7cfb. \u4e92\u8054\u7f51\u4e2d\u5f80\u5f80\u8fd8\u5305\u542b\u9519\u8bef\u7684\u53e5\u5b50, \u4e0d\u6070\u5f53\u7684\u8868\u8fbe, \u751a\u81f3\u662f\u7b14\u8bef, \u8fd9\u4e9b\u90fd\u4f1a\u9020\u6210\u62bd\u53d6\u7684\u9519\u8bef. \u6765\u81ea\u62bd\u53d6\u7684\u9519\u8bef: \u81ea\u7136\u8bed\u8a00\u7684\u8868\u8fbe\u662f\u5341\u5206\u590d\u6742\u7684, \u800c\u62bd\u53d6\u65b9\u6cd5\u5f80\u5f80\u53c8\u662f\u5927\u91cf\u57fa\u672cNLP\u6a21\u5757(\u5206\u8bcd, \u8bcd\u6027\u6807\u6ce8, \u8bed\u6cd5\u6811\u6784\u5efa, \u8bcd\u5d4c\u5165, \u795e\u7ecf\u7f51\u7edc\u4f20\u64ad\u7b49)\u5806\u780c\u800c\u6210\u7684\u590d\u6742\u65b9\u6848, \u5bb9\u6613\u9020\u6210\u9519\u8bef\u4f20\u64ad, \u5f71\u54cd\u5230\u4e0b\u6e38\u4efb\u52a1, \u5bfc\u81f4\u6700\u7ec8\u62bd\u53d6\u51fa\u6765\u7684isA\u5173\u7cfb\u8d28\u91cf\u4f4e\u4e0b. \u6765\u81ea\u63a8\u7406\u7684\u9519\u8bef: \u4e00\u65b9\u9762\u539f\u59cb\u7684\u56fe\u8c31\u4e2d\u5c31\u5b58\u5728\u9519\u8bef, \u57fa\u4e8e\u9519\u8bef\u7684\u4e8b\u5b9e\u6240\u8fdb\u884c\u7684\u63a8\u7406\u7ed3\u679c\u5f80\u5f80\u4e5f\u662f\u9519\u7684; \u53e6\u4e00\u65b9\u9762, \u73b0\u5b9e\u4e16\u754c\u4e2d\u5f80\u5f80\u5b58\u5728\u5927\u91cf\u7279\u4f8b, \u5b83\u4eec\u4e0d\u7b26\u5408\u7b80\u5355\u7684\u63a8\u7406\u89c4\u5219. \u7efc\u4e0a\u6240\u8ff0, \u60f3\u81ea\u52a8\u627e\u5230\u6240\u6709\u9519\u8bef\u662f\u4e0d\u73b0\u5b9e\u7684, \u5de5\u4e1a\u754c\u4e2d\u4e00\u822c\u90fd\u5e0c\u671b\u80fd\u627e\u5230\u4e00\u4e9b\u673a\u5236\u548c\u65b9\u6cd5, \u5c3d\u53ef\u80fd\u591a\u5730\u8bc6\u522b\u67d0\u4e9b\u7c7b\u578b\u7684\u9519\u8bef\u4ece\u800c\u8fdb\u4e00\u6b65\u63d0\u77e5\u8bc6\u56fe\u8c31\u7684\u8d28\u91cf.","title":"\u9519\u8bef\u7684\u6210\u56e0"},{"location":"8_1.html#_6","text":"\u4e00\u4e2a\u6709\u6548\u7684\u7ea0\u9519\u601d\u60f3, \u662f\u4e3a\u6bcf\u4e00\u6761\u77e5\u8bc6\u5bfb\u627e\u652f\u6301\u5b83\u7684\u8bc1\u636e, \u6765\u8bc1\u660e\u5b83\u7684\u6b63\u786e\u6027!!! \u6700\u76f4\u63a5\u7684\u8bc1\u636e\u662f\u8bed\u6599\u4e2d\u63d0\u53ca\u8fd9\u4e00\u6761\u77e5\u8bc6\u7684\u9891\u6b21. \u663e\u7136, \u5982\u679c\u4e00\u6761\u77e5\u8bc6\u5728\u5404\u79cd\u8bed\u6599\u7684\u5927\u91cf\u53e5\u5b50\u4e2d\u90fd\u53ef\u4ee5\u62bd\u53d6\u5230, \u90a3\u4e48\u5b83\u5f88\u6709\u53ef\u80fd\u662f\u6b63\u786e\u7684. \u5728\u7279\u5b9a\u8bed\u6599\u4e2d, \u5c06\u51fa\u73b0\u67d0\u6761\u77e5\u8bc6\u7684\u53e5\u5b50\u7684\u6570\u91cf\u4f5c\u4e3a\u8fd9\u6761\u77e5\u8bc6\u7684\u652f\u6301\u5ea6. \u7ecf\u8fc7\u5bf9Probase\u4e2d\u5177\u6709\u4e0d\u540c\u652f\u6301\u5ea6\u7684isA\u5173\u7cfb\u8fdb\u884c\u62bd\u6837\u9a8c\u8bc1, \u53d1\u73b0\u6709\u66f4\u9ad8\u652f\u6301\u5ea6\u7684isA\u5173\u7cfb\u901a\u5e38\u66f4\u53ef\u80fd\u662f\u6b63\u786e\u7684. \u601d\u8003: \u80fd\u5426\u51ed\u501f\u652f\u6301\u5ea6\u7b5b\u9009\u51fa\u9519\u8bef\u7684isA\u5173\u7cfb\u5462? \u6bd4\u5982\u652f\u6301\u5ea6\u4f4e\u4e8e\u67d0\u4e2a\u9608\u503c\u7684\u90fd\u7b97\u9519\u8bef\u5173\u7cfb. \u4ed4\u7ec6\u601d\u8003\u540e\u53d1\u73b0\u4e0d\u884c, \u5de5\u4e1a\u754c\u4e0a\u4e00\u822c\u4f1a\u91c7\u7528\u66f4\u53ef\u9760\u7684\u6307\u6807: \u53ef\u4fe1\u5ea6, \u6765\u5bf9isA\u5173\u7cfb\u8fdb\u884c\u5ea6\u91cf. \u4e00\u822c\u6765\u8bf4, \u4e00\u4e2a\u66f4\u5177\u4f53\u7684\u6982\u5ff5\u7684\u5b9e\u4f8b\u8981\u6bd4\u62bd\u8c61\u6982\u5ff5\u7684\u5b9e\u4f8b\u5c11! \u5bf9\u4e00\u6761isA\u5173\u7cfbx isA y, \u8bb0e(x)\u4e3ax\u7684\u76f4\u63a5\u4e0b\u4f4d\u8bcd\u6570\u91cf, \u4e00\u822c\u6709e(x) < e(y). \u56e0\u6b64, e(y)/e(x)\u503c\u8d8a\u5927, \u5219x isA y\u8d8a\u53ef\u4fe1! \u4f8b\u5982, \u5728Probase\u4e2d, \"juice\"\u6709173\u4e2a\u4e0b\u4f4d\u8bcd, \"tomato\"\u53ea\u670969\u4e2a\u4e0b\u4f4d\u8bcd, \u6240\u4ee5\"juice isA tomato\"\u660e\u663e\u4e0d\u53ef\u4fe1. \u6309\u7167\u516c\u53f8\u8fdb\u884c\u8ba1\u7b97\u53ef\u4fe1\u5ea6: P(x isA y) = log(1 + e(y)/e(x)).","title":"\u57fa\u4e8e\u652f\u6301\u5ea6\u7684\u7ea0\u9519"},{"location":"8_1.html#_7","text":"\u4e00\u4e2a\u7406\u60f3\u7684\u6982\u5ff5\u56fe\u8c31\u5f80\u5f80\u662f\u4e00\u4e2a\u6709\u5411\u65e0\u73af\u56fe(DAG). \u90a3\u4e48\u663e\u7136, \u73af\u4e2d\u7684isA\u5173\u7cfb\u4e4b\u95f4\u5b58\u5728\u903b\u8f91\u4e0a\u7684\u51b2\u7a81!!! \u7ed3\u8bba: \u81ea\u52a8\u5316\u6784\u5efa\u7684\u6982\u5ff5\u56fe\u8c31\u4e2d\u7684\u73af\u5f80\u5f80\u662f\u7531\u9519\u8bef\u7684isA\u5173\u7cfb\u5bfc\u81f4\u7684!!! \u91c7\u6837\u7edf\u8ba1: \u5728Probase\u4e2d, 97%\u7684\u957f\u5ea6\u4e3a2\u7684\u73af\u4e2d\u5b58\u5728\u9519\u8bef\u7684isA\u5173\u7cfb, \u800c96%\u7684\u957f\u5ea6\u4e3a3\u7684\u73af\u4e2d\u5b58\u5728\u9519\u8bef\u7684isA\u5173\u7cfb. \u5176\u5b9e, \u8fd9\u5e76\u4e0d\u662f\u4e00\u4e2a\u65b0\u95ee\u9898, \u4e8b\u5b9e\u4e0a, \u5b83\u662f\u56fe\u8bba\u4e2d\u7684\u4e00\u4e2a\u7ecf\u5178\u7684NP-Hard\u95ee\u9898\u7684\u5e26\u6743\u7248\u672c: \u6700\u5c0f\u53cd\u9988\u8fb9\u96c6\u95ee\u9898(Minimum Feedback Arc Set Problem). \u6709\u4e00\u4e9b\u8fd1\u4f3c\u89e3\u6cd5\u53ef\u4ee5\u5728\u77ed\u65f6\u95f4\u5185\u83b7\u5f97\u8fd9\u4e2a\u95ee\u9898\u7684\u8f83\u4f18\u89e3. \u8d2a\u5fc3\u7b97\u6cd5: \u6b65\u9aa41: \u4ee5\u968f\u673a\u987a\u5e8f\u679a\u4e3e\u56fe\u4e2d\u7684\u6bcf\u4e2a\u73af, \u6bcf\u6b21\u5c06\u73af\u4e2d\u6743\u503c\u6700\u5c0f\u7684\u8fb9\u5168\u90e8\u5220\u9664, \u76f4\u5230\u56fe\u4e2d\u4e0d\u5b58\u5728\u73af\u4e3a\u6b62. \u6b65\u9aa42: \u5c06\u6b65\u9aa41\u4e2d\u5220\u9664\u7684\u8fb9\u6309\u6743\u503c\u4ece\u5927\u5230\u5c0f\u6392\u5217, \u5c1d\u8bd5\u5c06\u8fd9\u4e9b\u8fb9\u9010\u4e2a\u52a0\u56de\u5230\u56fe\u4e2d. \u82e5\u4e0d\u4f1a\u4ea7\u751f\u73af, \u5219\u5c06\u5176\u52a0\u56de\u56fe\u4e2d, \u5426\u5219\u5c06\u8fd9\u6761\u8fb9\u52a0\u5165\u6700\u5c0f\u53cd\u9988\u8fb9\u96c6, \u4f5c\u4e3a\u6700\u7ec8\u8f93\u51fa\u7684\u4e00\u90e8\u5206.","title":"\u57fa\u4e8e\u56fe\u6a21\u578b\u7684\u7ea0\u9519"},{"location":"8_2.html","text":"\u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u63a7\u5236 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u63a7\u5236\u7684\u6982\u5ff5. \u4e86\u89e3\u7f3a\u5931\u77e5\u8bc6\u7684\u53d1\u73b0\u4e0e\u8865\u5168\u65b9\u6cd5. \u4e86\u89e3\u9519\u8bef\u77e5\u8bc6\u7684\u53d1\u73b0\u4e0e\u8865\u5168\u65b9\u6cd5. \u4e86\u89e3\u77e5\u8bc6\u66f4\u65b0\u7684\u610f\u4e49\u4e0e\u65b9\u6cd5. \u8d28\u91cf\u63a7\u5236\u6982\u8ff0 \u00b6 \u6240\u8c13\u77e5\u8bc6\u56fe\u8c31\u7684\u8d28\u91cf, \u6307\u77e5\u8bc6\u56fe\u8c31\u4e2d\u77e5\u8bc6\u7684\u8d28\u91cf. \u77e5\u8bc6\u56fe\u8c31\u7684\u8d28\u91cf\u63a7\u5236, \u6307\u7684\u662f\u5982\u4f55\u901a\u8fc7\u6280\u672f\u624b\u6bb5\u6765\u786e\u4fdd\u77e5\u8bc6\u56fe\u8c31\u4e2d\u77e5\u8bc6\u7684\u8d28\u91cf. \u4e0d\u8bba\u662f\u901a\u7528\u9886\u57df, \u8fd8\u662f\u5782\u76f4\u9886\u57df, \u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u90fd\u529b\u6c42\u505a\u5230\u81ea\u52a8\u5316, \u5373\u5c3d\u91cf\u5c11\u7528\u4eba\u529b, \u5c3d\u91cf\u4f9d\u9760\u673a\u5668\u5b8c\u6210. \u9700\u8981\u8003\u8651\u5982\u4e0b\u51e0\u4e2a\u65b9\u9762: \u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u8bc4\u4f30\u7684\u7ef4\u5ea6 \u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u8bc4\u4f30\u7684\u65b9\u6cd5 \u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u63a7\u5236\u5168\u5468\u671f \u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u8bc4\u4f30\u7684\u7ef4\u5ea6 \u00b6 \u8d28\u91cf\u8bc4\u4f30\u4e3b\u8981\u56f4\u7ed5\u6982\u5ff5, \u5b9e\u4f53, \u5c5e\u6027\u8fd9\u4e09\u7c7b\u4e2a\u4f53\u5bf9\u8c61, \u4ee5\u53ca\u6982\u5ff5\u4e4b\u95f4\u7684\u5173\u7cfb, \u6982\u5ff5\u548c\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb, \u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb\u8fd9\u4e09\u7c7b\u5173\u7cfb\u5bf9\u8c61. \u8003\u5bdf\u5982\u4e0b4\u4e2a\u7ef4\u5ea6: \u51c6\u786e\u6027 \u4e00\u81f4\u6027 \u5b8c\u6574\u6027 \u65f6\u6548\u6027 \u51c6\u786e\u6027(Accuracy): \u8003\u5bdf\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5404\u7c7b\u77e5\u8bc6\u7684\u51c6\u786e\u7a0b\u5ea6. \u4e00\u81f4\u6027(Consistency): \u8003\u5bdf\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u77e5\u8bc6\u8868\u8fbe\u662f\u5426\u4e00\u81f4, \u5373\u77e5\u8bc6\u56fe\u8c31\u4e2d\u662f\u5426\u5b58\u5728\u4e92\u76f8\u77db\u76fe\u7684\u77e5\u8bc6. \u5b8c\u6574\u6027(Integrity): \u8003\u5bdf\u77e5\u8bc6\u56fe\u8c31\u5bf9\u67d0\u4e2a\u9886\u57df\u77e5\u8bc6\u7684\u8986\u76d6\u7a0b\u5ea6. \u65f6\u6548\u6027(Freshness): \u8003\u5bdf\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5b8f\u7684\u77e5\u8bc6\u662f\u5426\u662f\u6700\u65b0\u77e5\u8bc6. \u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u8bc4\u4f30\u7684\u65b9\u6cd5 \u00b6 \u77e5\u8bc6\u56fe\u8c31\u7684\u8d28\u91cf\u8bc4\u4f30\u65e8\u5728\u5bf9\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u77e5\u8bc6\u7684\u8d28\u91cf\u8fdb\u884c\u91cf\u5316. \u6839\u636e\u91cf\u5316\u7ed3\u679c, \u4fdd\u7559\u7f6e\u4fe1\u5ea6\u8f83\u9ad8\u7684\u77e5\u8bc6, \u820d\u5f03\u7f6e\u4fe1\u5ea6\u8f83\u4f4e\u7684\u77e5\u8bc6. \u5e38\u7528\u7684\u4e09\u79cd\u65b9\u6cd5: \u4eba\u5de5\u62bd\u6837\u68c0\u6d4b\u6cd5 \u4e00\u81f4\u6027\u68c0\u6d4b\u6cd5 \u57fa\u4e8e\u5916\u90e8\u77e5\u8bc6\u7684\u5bf9\u6bd4\u8bc4\u4f30\u6cd5 \u4eba\u5de5\u62bd\u6837\u68c0\u6d4b\u6cd5: \u7531\u9886\u57df\u4e13\u5bb6\u8fdb\u884c\u62bd\u6837\u8d28\u91cf\u68c0\u6d4b\u4e0e\u8bc4\u4f30. \u6bd4\u5982, \u6309\u7167\u5b9e\u4f53\u7684\u6d41\u884c\u5ea6\u8fdb\u884c\u4f18\u5148\u91c7\u6837, \u786e\u4fdd\u5934\u90e8\u5b9e\u4f53\u5f97\u4ee5\u68c0\u9a8c. \u4e00\u81f4\u6027\u68c0\u6d4b\u6cd5: \u901a\u8fc7\u4e13\u5bb6\u9884\u5148\u5236\u5b9a\u7684\u4e00\u81f4\u6027\u68c0\u6d4b\u89c4\u5219\u68c0\u6d4b\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u77e5\u8bc6\u51b2\u7a81, \u4ee5\u53d1\u73b0\u8d28\u91cf\u95ee\u9898. \u6bd4\u5982, \u7ed9\u5b9a\u89c4\u5219\"\u5927\u5b66\u540c\u5b66\u7684\u6bd5\u4e1a\u9662\u6821\u5e94\u8be5\u662f\u540c\u4e00\u6240\u5927\u5b66\". \u57fa\u4e8e\u5916\u90e8\u77e5\u8bc6\u7684\u5bf9\u6bd4\u8bc4\u4f30\u6cd5: \u4f7f\u7528\u4e0e\u76ee\u6807\u77e5\u8bc6\u56fe\u8c31\u6709\u8f83\u9ad8\u91cd\u5408\u5ea6\u7684\u9ad8\u8d28\u91cf\u5916\u90e8\u77e5\u8bc6\u6e90\u4f5c\u4e3a\u57fa\u51c6\u6570\u636e, \u5bf9\u76ee\u6807\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u8d28\u91cf\u68c0\u6d4b. \u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u63a7\u5236\u5168\u5468\u671f \u00b6 \u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u63a7\u5236\u8d2f\u7a7f\u4e8e\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7684\u5168\u5468\u671f, \u6d89\u53ca\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u524d, \u4e2d, \u540e\u4e09\u4e2a\u9636\u6bb5\u7684\u8d28\u91cf\u63a7\u5236. \u4e3a\u4e86\u5c3d\u91cf\u907f\u514d\u5f15\u5165\u9519\u8bef, \u9700\u8981\u5bf9\u77e5\u8bc6\u83b7\u53d6\u7684\u65b9\u5f0f\u8fdb\u884c\u8d28\u91cf\u63a7\u5236\u4e0e\u7ba1\u7406. \u800c\u77e5\u8bc6\u878d\u5408\u662f\u5bf9\u5404\u6e90\u5934\u83b7\u53d6\u7684\u77e5\u8bc6\u8fdb\u884c\u878d\u5408, \u7edf\u4e00, \u6d89\u53ca\u5f88\u591a\u6570\u636e\u878d\u5408\u76f8\u5173\u7684\u8d28\u91cf\u95ee\u9898, \u5305\u62ec\u5b9e\u4f53\u5bf9\u9f50, \u5c5e\u6027\u878d\u5408\u53ca\u503c\u89c4\u8303\u5316\u7b49\u7b49. \u6784\u5efa\u524d\u7684\u8d28\u91cf\u63a7\u5236 \u00b6 \u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u524d\u7684\u8d28\u91cf\u63a7\u5236\u4e3b\u8981\u5173\u6ce8\u77e5\u8bc6\u6765\u6e90\u7684\u8d28\u91cf. \u5728\u65b0\u95fb\u548c\u4f20\u64ad\u9886\u57df\u5f88\u65e9\u5c31\u5f00\u59cb\u5173\u6ce8\u4fe1\u606f\u6765\u6e90\u7684\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u95ee\u9898, \u5e76\u63d0\u51fa\u8861\u91cf\u4fe1\u6e90\u53ef\u4fe1\u5ea6\u6700\u5173\u952e\u7684\u4e24\u4e2a\u56e0\u7d20: \u4e13\u4e1a(Expertise): \u8861\u91cf\u7684\u662f\u4fe1\u6e90\u5728\u67d0\u9886\u57df\u7684\u4e13\u4e1a\u6027. \u53ef\u4fe1\u8d56(Trustworthiness): \u8861\u91cf\u7684\u662f\u4fe1\u6e90\u6240\u63d0\u4f9b\u5185\u5bb9\u7684\u53ef\u9760\u6027. \u4e92\u8054\u7f51\u6570\u636e\u53ef\u5927\u6982\u5206\u4e3a\u4e24\u7c7b\u6570\u636e: \u6d45\u7f51(Surface Web)\u6570\u636e: \u6307\u5404\u7c7b\u7f51\u7ad9\u9759\u6001\u7f51\u9875\u6240\u5305\u542b\u7684\u6570\u636e\u4fe1\u606f. \u6df1\u7f51(Deep Web)\u6570\u636e: \u6307\u9690\u85cf\u5728\u5404\u7c7b\u7f51\u7ad9\u80cc\u540e\u7684\u7f51\u7edc\u6570\u636e\u5e93\u4e2d\u7684\u6570\u636e\u8bb0\u5f55. \u6d45\u7f51(Surface Web)\u6570\u636e: \u901a\u8fc7\u4eba\u5de5\u603b\u7ed3, \u53ef\u4fe1\u5ea6\u6392\u5e8f\u4e3a .mil(\u519b\u4e8b) > .int(\u56fd\u9645\u7ec4\u7ec7) > .gov(\u653f\u5e9c) > .org(\u975e\u8425\u5229\u673a\u6784) > .eud(\u6559\u80b2) > .com > .net \u6df1\u7f51(Deep Web)\u6570\u636e: \u6df1\u7f51\u4e2d\u5404\u7f51\u7edc\u6570\u636e\u5e93\u4e4b\u95f4\u7684\u6570\u636e\u8bb0\u5f55\u53ef\u4ee5\u901a\u8fc7\u6570\u636e\u8bb0\u5f55\u95f4\u7684\u5339\u914d\u4e0e\u5173\u8054\u5f62\u6210\u7f51\u7edc, \u518d\u5229\u7528PageRank\u6216Random Walk\u7b97\u6cd5\u8fdb\u884c\u8bc4\u4f30. \u4f17\u5305\u77e5\u8bc6\u7684\u53ef\u4fe1\u5ea6\u8bc4\u4f30: \u5de5\u4e1a\u754c\u7684\u4e3b\u6d41\u505a\u6cd5\u662f\u76f4\u63a5\u8bc4\u4f30\u4f17\u5305\u5de5\u4eba\u7684\u53ef\u4fe1\u5ea6, \u7136\u540e\u76f4\u63a5\u5c06\u4f17\u5305\u5de5\u4eba\u7684\u53ef\u4fe1\u670d\u8d4b\u4e88\u5176\u6240\u63d0\u4f9b\u7684\u77e5\u8bc6\u7684\u53ef\u4fe1\u5ea6. \u6784\u5efa\u4e2d\u7684\u8d28\u91cf\u63a7\u5236 \u00b6 \u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u4e2d\u7684\u4e3b\u8981\u4efb\u52a1\u662f\u77e5\u8bc6\u83b7\u53d6, \u4e3b\u8981\u6280\u672f\u6d41\u6d3e\u6709\u4e24\u79cd: \u57fa\u4e8e\u6a21\u5f0f\u5339\u914d\u7684\u77e5\u8bc6\u83b7\u53d6 \u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u77e5\u8bc6\u83b7\u53d6 \u57fa\u4e8e\u6a21\u5f0f\u5339\u914d\u7684\u77e5\u8bc6\u83b7\u53d6: \u53ef\u4ee5\u4f7f\u7528\u4e13\u5bb6\u7ed9\u5b9a\u7684\u9ad8\u8d28\u91cf\u6a21\u5f0f, \u76f4\u63a5\u4ece\u6587\u672c\u4e2d\u83b7\u53d6\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u6240\u9700\u7684\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb\u5b9e\u4f8b, \u5b9e\u4f53\u4e0e\u6982\u5ff5\u4e4b\u95f4\u7684\u4e0a\u4e0b\u4f4d\u5173\u7cfb\u5b9e\u4f8b, \u4ee5\u53ca\u5b9e\u4f53\u7684\u5c5e\u6027\u503c. \u53cd\u601d: \u57fa\u4e8e\u6a21\u5f0f\u7684\u81ea\u52a8\u62bd\u53d6\u5f80\u5f80\u4f1a\u53d1\u751f\u62bd\u53d6\u9519\u8bef, \u5176\u4e2d\u6700\u5e38\u89c1, \u5371\u5bb3\u6027\u6700\u5927\u7684\u9519\u8bef\u5f53\u5c5e\u8fed\u4ee3\u5f0f\u62bd\u53d6\u4e2d\u53d1\u751f\u7684\"\u8bed\u4e49\u6f02\u79fb\"\u95ee\u9898. \u8bed\u4e49\u6f02\u79fb: \u5373\u5728\u57fa\u4e8e\u6a21\u5f0f\u7684\u8fed\u4ee3\u5f0f\u62bd\u53d6\u8fc7\u7a0b\u4e2d\u7531\u4e8e\u4e0a\u4e00\u8f6e\u53d1\u751f\u62bd\u53d6\u9519\u8bef\u800c\u5f15\u5165\u5176\u4ed6\u8bed\u4e49\u7c7b\u7684\u591a\u4e49\u793a\u4f8b, \u8fd9\u5bfc\u81f4\u540e\u7eed\u8f6e\u6b21\u6240\u62bd\u53d6\u5b9e\u4f8b\u7684\u8bed\u4e49\u7c7b\u4e0e\u76ee\u6807\u8bed\u4e49\u7c7b\u76f8\u8ddd\u751a\u8fdc. \u4f8b\u5982: \u4e3a\u4e86\u53d1\u73b0\u548c\u62bd\u53d6\"Animal\"\u8bed\u4e49\u7c7b\u4e0b\u7684\u5b9e\u4f53, \u7ed9\u5b9a\u4e86\u79cd\u5b50\u96c6\u5408{\"dog\", \"cat\", \"hourse\"}, \u7ecf\u8fc7\u82e5\u5e72\u6761\u6837\u672c\u7684\u5b66\u4e60\u5f97\u5230\u4e24\u6761\u6a21\u5f0fP1: \"...X is a kind of mammal...\", P2: \"Sometime, X is as clever as human beings.\". \u7b2c\u4e8c\u8f6e\u5c31\u4f9d\u9760\u8fd9\u4e24\u6761\u6a21\u5f0f\u7ee7\u7eed\u5339\u914d\u51fa\u65b0\u7684\"Animal\"\u5b9e\u4f8b, \u7136\u540eP2\u89c4\u5219\u53ef\u80fd\u5f15\u5165\"computer\"\u548c\"robot\"\u8fd9\u4e24\u4e2a\u9519\u8bef\u7684\u62bd\u53d6\u7ed3\u679c, \u90a3\u4e48\u5f53\u8fd9\u4e24\u4e2a\u9519\u8bef\u62bd\u53d6\u7ed3\u679c\u8fdb\u5165\u5230\u79cd\u5b50\u96c6\u5408\u4e2d\u540e, \u5728\u7b2c\u4e09\u8f6e\u4e4b\u540e\u7684\u62bd\u53d6\u4e2d, \u5c31\u4f1a\u628a\u5f88\u591a\u8bed\u4e49\u7c7b\u4e3a\"Artefact\"\u4e0b\u7684\u5b9e\u4f8b\u5f52\u5165\u76ee\u6807\u7c7b\"Animal\"\u4e2d, \u9020\u6210\u62bd\u53d6\u7ed3\u679c\"\u8d8a\u6f02\u8d8a\u8fdc\". \u89e3\u51b3\u65b9\u6cd5: \u4f9d\u7136\u662f\u4f9d\u9760\u4eba\u5de5\u89c4\u5219\u5b9a\u4e49\u68c0\u67e5\u6cd5 - \u4e00\u4e2a\u5b9e\u4f8b\u4e0d\u5e94\u8be5\u5c5e\u4e8e\u4e92\u65a5\u7684\u4e24\u4e2a\u6982\u5ff5\u6216\u7c7b\u522b. \u6bd4\u5982, \u5982\u679c\u5b9e\u4f53\u7684\u7c7b\u578b\u88ab\u5224\u5b9a\u4e3a\"\u673a\u6784\", \u4f46\u62bd\u53d6\u51fa\u7684\u6982\u5ff5\u5374\u662f\"\u827a\u672f\u5bb6\", \u663e\u7136\u4e24\u8005\u662f\u77db\u76fe\u7684, \u8fd9\u5c31\u63d0\u793a\u5f53\u524d\u7684\u62bd\u53d6\u7ed3\u679c\u53ef\u80fd\u662f\u9519\u8bef\u7684. \u53cd\u4e4b, \u5982\u679c\"\u67cf\u62c9\u56fe\"\u7684\u7c7b\u578b\u88ab\u5224\u5b9a\u4e3a\"\u4eba\u7269\", \u5176\u7c7b\u578b\u4e0e\u62bd\u53d6\u51fa\u7684\u6982\u5ff5\"\u552f\u5fc3\u4e3b\u4e49\u54f2\u5b66\u5bb6\"\u548c\"\u54f2\u5b66\u5bb6\"\u662f\u4e0d\u77db\u76fe\u7684, \u5219\u53ef\u8ba4\u5b9a\u8fd9\u4e9b\u6982\u5ff5\u662f\u6b63\u786e\u7684. \u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u77e5\u8bc6\u83b7\u53d6: \u4f9d\u9760NER\u6a21\u578b, RE\u6a21\u578b, EE\u6a21\u578b\u76f4\u63a5\u5b8c\u6210\u77e5\u8bc6\u62bd\u53d6, \u62bd\u53d6\u8d28\u91cf\u53d6\u51b3\u4e8e\u6a21\u578b\u672c\u8eab\u7684\u8d28\u91cf. \u5728\u5de5\u4e1a\u754c, \u73b0\u5b9e\u4e2d\u4e3a\u4e86\u6784\u5efa\u6709\u6548\u7684\u4fe1\u606f\u62bd\u53d6\u6a21\u578b, \u5728\u77e5\u8bc6\u56fe\u8c31\u9886\u57df\u503e\u5411\u4e8e\u5229\u7528\u8fdc\u7a0b\u76d1\u7763\u5b66\u4e60, \u901a\u8fc7\u5c06\u77e5\u8bc6\u5e93\u4e2d\u7684\u7ed3\u6784\u5316\u4fe1\u606f\u4e0e\u81ea\u7531\u6587\u672c\u8fdb\u884c\u5bf9\u6bd4\u6765\u81ea\u52a8\u751f\u6210\u6807\u6ce8\u6837\u672c. \u4f46\u662f\u8fdc\u7a0b\u76d1\u7763\u5b66\u4e60\u751f\u6210\u7684\u6837\u672c\u5f80\u5f80\u5b58\u5728\u566a\u58f0, \u8fd8\u9700\u8981\u5bf9\u6837\u672c\u8fdb\u884c\u9009\u62e9. \u6784\u5efa\u540e\u7684\u8d28\u91cf\u63a7\u5236 \u00b6 \u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7684\u5168\u6d41\u7a0b, \u76ee\u524d\u5de5\u4e1a\u754c\u7684\u73b0\u72b6\u5f80\u5f80\u9075\u5faa\"\u5148\u6570\u91cf\u518d\u8d28\u91cf\"\u7684\u7b56\u7565, \u5373\"\u5148\u6784\u5efa\u5230\u4e00\u5b9a\u89c4\u6a21, \u518d\u63d0\u9ad8\u8d28\u91cf\"\u8fd9\u6837\u4e00\u79cd\u59a5\u534f\u7684\u7b56\u7565, \u56e0\u6b64\u81ea\u52a8\u6784\u5efa\u7684\u77e5\u8bc6\u56fe\u8c31\u4e0d\u53ef\u907f\u514d\u7684\u5b58\u5728\u5404\u79cd\u8d28\u91cf\u95ee\u9898, \u4e3b\u8981\u6709\u4ee5\u4e0b\u4e09\u79cd: \u77e5\u8bc6\u7f3a\u5931 \u77e5\u8bc6\u9519\u8bef \u77e5\u8bc6\u8fc7\u671f \u7f3a\u5931\u77e5\u8bc6\u53d1\u73b0\u4e0e\u8865\u5168 \u00b6 \u77e5\u8bc6\u56fe\u8c31\u5728\u5904\u7406\u7f3a\u5931\u77e5\u8bc6\u8865\u5168\u95ee\u9898\u65f6, \u4e0e\u4f20\u7edfNLP\u5904\u7406\u5b9e\u4f53\u8bc6\u522b, \u5173\u7cfb\u62bd\u53d6, \u5b9e\u4f53\u5206\u7c7b\u7b49\u95ee\u9898, \u662f\u6709\u5dee\u522b\u7684. \u7c7b\u578b\u8865\u5168 \u00b6 \u5b9e\u4f53\u7c7b\u578b\u8865\u5168\u662f\u5bf9\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u4e2d\u9057\u6f0f\u7684\u6982\u5ff5\u8fdb\u884c\u8865\u5168, \u901a\u5e38\u4e5f\u79f0\u4e3a\u5b9e\u4f53\u5224\u578b(Entity Typing). \u6839\u636e\u4f7f\u7528\u7684\u6280\u672f\u8def\u7ebf, \u5206\u4e3a\u4e24\u7c7b: \u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u4fe1\u606f\u7684\u542f\u53d1\u5f0f\u6982\u7387\u6a21\u578b \u5b9e\u4f53\u5206\u7c7b\u6a21\u578b \u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u4fe1\u606f\u7684\u542f\u53d1\u5f0f\u6982\u7387\u6a21\u578b: \u4e3b\u8981\u901a\u8fc7\u8003\u5bdf\u77e5\u8bc6\u56fe\u8c31\u4e2d\u4e0e\u5b9e\u4f53\u76f8\u5173\u7684\u4fe1\u606f\u6765\u6784\u5efa\u4e00\u4e9b\u542f\u53d1\u5f0f\u89c4\u5219\u6216\u6982\u7387\u6a21\u578b. \u4e00\u79cd\u6bd4\u8f83\u7ecf\u5178\u7684\u65b9\u6cd5\u662f\u57fa\u4e8e\u4e09\u5143\u7ec4\u8c13\u8bcd\u7684\u542f\u53d1\u5f0f\u5b9e\u4f53\u5224\u578b\u65b9\u6cd5SDType. SDType\u65b9\u6cd5\u7edf\u8ba1\u5b9e\u4f53\u7684\u53ef\u80fd\u8c13\u8bcd\u4f5c\u4e3a\u4e2d\u95f4\u53d8\u91cf, \u63a8\u65ad\u4e00\u4e2a\u5b9e\u4f53\u5177\u6709\u67d0\u4e2a\u7c7b\u578b\u7684\u53ef\u80fd\u6027. # e\u4e3a\u5934\u5b9e\u4f53\u7684\u6240\u6709\u4e09\u5143\u7ec4 (e, r1, o1) (e, r2, o2) (e, r3, o3) (e, r4, o4) (e, r5, o5) # r1,r2,r3,r4,r5\u7684\u5934\u5b9e\u4f53\u7c7b\u578b\u5206\u5e03\u8868\u5982\u4e0b: r1 Type1 20% Type2 40% Others ... r2 Type1 10% Type2 0% Others ... r3 Type1 40% Type2 30% Others ... r4 Type1 30% Type2 20% Others ... r5 Type1 0% Type2 50% Others ... \u7efc\u4e0a\u4e0a\u9762\u82e5\u5e72\u5f20\u8868, \u53ef\u4ee5\u6309\u7167\u5e73\u5747\u52a0\u6743\u7cfb\u6570\u5f97\u5230\u5b9e\u4f53e\u5206\u522b\u5c5e\u4e8eType1\u548cType2\u7684\u6982\u7387: P(e isA Type1) = 1/5 * (20% + 10% + 40% + 30% + 0%) = 20% P(e isA Type2) = 1/5 * (40% + 0% + 30% + 20% + 50%) = 28% \u5b9e\u4f53\u5206\u7c7b\u6a21\u578b: \u5c06\u5b9e\u4f53\u5224\u578b\u95ee\u9898\u5efa\u6a21\u6210\u5206\u7c7b\u95ee\u9898, \u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u5206\u7c7b\u6a21\u578b\u4e3a\u6bcf\u4e00\u4e2a\u5b9e\u4f53\u7ed9\u51fa\u5bf9\u5e94\u7684\u7c7b\u578b\u6807\u7b7e. \u8fd1\u51e0\u5e74, \u4ece\u5b66\u672f\u754c\u5230\u5de5\u4e1a\u754c, \u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u65e5\u76ca\u6210\u4e3a\u4e3b\u6d41\u5206\u7c7b\u5668. \u5bf9\u4e8e\u7c97\u7c92\u5ea6\u5b9e\u4f53\u5206\u7c7b\u4efb\u52a1(\u7c7b\u522b\u6570\u91cf\u8f83\u5c11), \u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5206\u7c7b\u6a21\u578b\u901a\u5e38\u80fd\u591f\u53d6\u5f97\u8f83\u4e3a\u7406\u60f3\u7684\u5206\u7c7b\u6548\u679c. \u4f46\u662f\u5bf9\u4e8e\u7ec6\u7c92\u5ea6\u5b9e\u4f53\u5206\u7c7b\u4efb\u52a1(\u5206\u7c7b\u8f83\u7ec6, \u7c7b\u522b\u6570\u91cf\u8f83\u591a), \u7531\u4e8e\u5f88\u591a\u7ec6\u7c92\u5ea6\u6982\u5ff5\u53ea\u6709\u5c11\u91cf\u5b9e\u4f8b, \u5f80\u5f80\u56e0\u4e3a\u8bad\u7ec3\u6837\u672c\u4e0d\u8db3, \u6570\u636e\u8fc7\u4e8e\u7a00\u758f\u800c\u8868\u73b0\u8f83\u5dee. \u4e3a\u4e86\u5e94\u5bf9\u6570\u636e\u7cfb\u6570\u7684\u6311\u6218, \u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u4e00\u4e9b\u65b9\u6cd5, \u6bd4\u5982\u501f\u9274\u591a\u4efb\u52a1\u8054\u5408\u8bad\u7ec3\u7684\u601d\u60f3: \u5bf9\u4e8e\u6bcf\u4e00\u79cd\u5b9e\u4f53\u7c7b\u578b\u90fd\u6784\u5efa\u4e00\u4e2a\u57fa\u7840\u5206\u7c7b\u5668, \u7528\u4e8e\u5224\u65ad\u5f53\u524d\u5b9e\u4f53\u662f\u5426\u5c5e\u4e8e\u8be5\u7c7b\u578b, \u5e76\u4e14\u6240\u6709\u7684\u57fa\u7840\u5206\u7c7b\u5668\u90fd\u5171\u4eab\u4e00\u4e2a\u9690\u5c42\u8fdb\u884c\u8054\u5408\u8bad\u7ec3, \u4f7f\u6a21\u578b\u80fd\u591f\u4e60\u5f97\u5bf9\u4e8e\u591a\u4e2a\u5b9e\u4f53\u7c7b\u578b\u5206\u7c7b\u5668\u666e\u904d\u6709\u6548\u7684\u8f93\u5165\u7279\u5f81\u7684\u7ec4\u5408, \u4ece\u800c\u6709\u6548\u7f13\u89e3\u90e8\u5206\u5b9e\u4f53\u7c7b\u578b\u4e2d\u7684\u6570\u636e\u7a00\u758f\u95ee\u9898. \u5173\u7cfb\u8865\u5168 \u00b6 \u5173\u7cfb\u8865\u5168\u662f\u5bf9\u77e5\u8bc6\u56fe\u8c31\u4e2d\u4e0d\u5b8c\u6574\u7684\u5173\u7cfb\u4e09\u5143\u7ec4(Subject, Predicate, Object)\u8fdb\u884c\u8865\u5168. \u76ee\u524d\u5b66\u672f\u754c, \u5de5\u4e1a\u754c\u4e3b\u8981\u7684\u7814\u7a76\u70ed\u70b9\u653e\u5728\u5173\u7cfb\u6216\u5c3e\u5b9e\u4f53\u7f3a\u5931\u7684\u573a\u666f. \u5173\u7cfb\u8865\u5168\u662fKG\u9886\u57df\u7684\u7814\u7a76\u70ed\u70b9, \u5927\u91cf\u7814\u7a76\u5de5\u4f5c\u96c6\u4e2d\u4e8e\u6b64. \u603b\u4f53\u5206\u4e24\u7c7b\u65b9\u6cd5: \u57fa\u4e8e\u5185\u90e8\u77e5\u8bc6\u7684\u5173\u7cfb\u8865\u5168 \u57fa\u4e8e\u5916\u90e8\u6570\u636e\u7684\u5173\u7cfb\u8865\u5168 \u57fa\u4e8e\u5185\u90e8\u77e5\u8bc6\u7684\u5173\u7cfb\u8865\u5168: \u4f20\u7edf\u7684\u8def\u5f84\u6392\u5e8f\u7b97\u6cd5, \u57fa\u672c\u601d\u60f3\u662f\u7528\u8fde\u63a5\u4e24\u4e2a\u5b9e\u4f53\u7684\u8def\u5f84\u4f5c\u4e3a\u7279\u5f81, \u6765\u9884\u6d4b\u4e24\u4e2a\u5b9e\u4f53\u95f4\u7684\u5173\u7cfb. \u6bd4\u5982\u6211\u4eec\u8981\u5224\u5b9a\"\u82cf\u683c\u62c9\u5e95\"\u7684\"\u51fa\u751f\u5730\"\u662f\u5426\u4e3a\"\u96c5\u5178\", \u90a3\u4e48\u9996\u5148\u6784\u9020\u8bad\u7ec3\u96c6, \u627e\u51fa\u6574\u4e2a\u77e5\u8bc6\u56fe\u8c31\u5185\u90e8\u6240\u6709\"\u51fa\u751f\u5730\"\u8fd9\u4e00\u5173\u7cfb\u7684\u76f8\u5173\u4e09\u5143\u7ec4\u4f5c\u4e3a\u6b63\u4f8b. \u7136\u540e\u91c7\u7528\u968f\u673a\u66ff\u6362\u6b63\u4f8b\u4e09\u5143\u7ec4\u4e2d\u5c3e\u5b9e\u4f53\u7684\u65b9\u6cd5\u6784\u9020\u8d1f\u4f8b. \u5c06\u4e24\u4e2a\u5b9e\u4f53\u4e4b\u95f4\u7684\u4e00\u6761\u8def\u5f84\u4f5c\u4e3a\u4e00\u4e2a\u7279\u5f81\u5411\u91cf, (\"\u82cf\u683c\u62c9\u5e95\", \"\u5b66\u751f\", \"\u67cf\u62c9\u56fe\", \"\u51fa\u751f\u5730\", \"\u96c5\u5178\")\u8fd9\u6837\u4e00\u6761\u8def\u5f84. \u901a\u8fc7\u679a\u4e3e\u4efb\u610f\u4e24\u4e2a\u5b9e\u4f53\u4e4b\u95f4\u6240\u6709\u7b26\u5408\u8bbe\u5b9a\u6761\u4ef6\u7684\u8def\u5f84, \u53ef\u4ee5\u6784\u5efa\u8be5\u5b9e\u4f53\u5bf9\u7684\u7279\u5f81\u96c6\u5408. \u901a\u8fc7\u7279\u5f81\u96c6\u5408\u83b7\u53d6\u7279\u5f81\u503c, \u6700\u540e\u4fbf\u53ef\u4ee5\u4f7f\u7528\u7279\u5f81\u6570\u636e\u8bad\u7ec3\u5206\u7c7b\u5668. \u57fa\u4e8e\u8868\u793a\u5b66\u4e60\u7684\u63a8\u7406\u8865\u5168\u6a21\u578b: \u8be5\u6a21\u578b\u4ee5\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\u5411\u91cf\u4f5c\u4e3a\u8f93\u5165, \u5bf9\u6bcf\u4e00\u79cd\u5173\u7cfb\u90fd\u7528\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u6765\u8868\u793a. \u4f7f\u7528\u8be5\u5173\u7cfb\u4e0b\u7684\u4e09\u5143\u7ec4\u4f5c\u4e3a\u6b63\u4f8b, \u751f\u6210\u4e00\u4e9b\u4e0d\u5c5e\u4e8e\u8be5\u5173\u7cfb\u7684\u4e09\u5143\u7ec4\u4f5c\u4e3a\u8d1f\u4f8b, \u8fdb\u884c\u6a21\u578b\u8bad\u7ec3. \u6bd4\u5982, \u5c06\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\"\u67cf\u62c9\u56fe\", \"\u552f\u5fc3\u4e3b\u4e49\", \"\u54f2\u5b66\u5bb6\"\u7b49\u8bcd\u6c47\u8fdb\u884c\u5d4c\u5165\u8868\u793a\u6210\u5f20\u91cf\u5f62\u5f0f, \u5229\u7528\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\"\u67cf\u62c9\u56fe\"\u548c\"\u552f\u5fc3\u4e3b\u4e49\u54f2\u5b66\u5bb6\"\u4e24\u4e2a\u5b9e\u4f53\u5b58\u5728\u4f55\u79cd\u5173\u7cfb. \u795e\u7ecf\u7f51\u7edc\u7684\u8f93\u51fa\u5c42\u7ecf\u5386\u8d2a\u5fc3\u89e3\u7801\u540e, \u5173\u7cfb\"\u804c\u4e1a\"\u7684\u5f97\u5206\u6700\u9ad8, \u56e0\u4e3a\u5f97\u5230\u9884\u6d4b\u4e09\u5143\u7ec4(\"\u67cf\u62c9\u56fe\", \"\u804c\u4e1a\", \"\u552f\u5fc3\u4e3b\u4e49\u54f2\u5b66\u5bb6\"). \u57fa\u4e8e\u5916\u90e8\u6570\u636e\u7684\u5173\u7cfb\u8865\u5168: \u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u5185\u90e8\u77e5\u8bc6\u63a8\u65ad\u51fa\u7684\u77e5\u8bc6\u662f\u6709\u9650\u7684, \u56e0\u6b64\u8fd8\u9700\u8981\u4ece\u5916\u90e8\u7684\u5f00\u653e\u4e16\u754c, \u7279\u522b\u662f\u5728\u7ebf\u767e\u79d1, \u6587\u672c\u8bed\u6599, \u7ed3\u6784\u5316\u8868\u683c\u6570\u636e\u53ca\u641c\u7d22\u5f15\u64ce\u7ed3\u679c\u7b49\u5916\u90e8\u8d44\u6e90, \u5bf9\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u8865\u5168. \u6838\u5fc3: \u5728\u7ebf\u767e\u79d1(\u767e\u5ea6\u767e\u79d1, \u7ef4\u57fa\u767e\u79d1)\u6240\u5305\u542b\u7684\u4fe1\u606f\u4e0d\u4ec5\u4e30\u5bcc\u4e14\u8d28\u91cf\u8f83\u9ad8, \u6210\u4e3a\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u6700\u6d41\u884c\u7684\u5916\u90e8\u6570\u636e\u6e90. \u5c5e\u6027\u503c\u8865\u5168 \u00b6 \u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5c5e\u6027\u503c\u8865\u5168\u95ee\u9898\u4e0e\u5173\u7cfb\u578b\u6570\u636e\u5e93\u9886\u57df\u7ecf\u5178\u7684\u5c5e\u6027\u503c\u8865\u5168\u95ee\u9898, \u5f88\u76f8\u4f3c, \u4f46\u53c8\u6709\u91cd\u5927\u533a\u522b! \u533a\u522b\u6709\u4e24\u70b9: \u7b2c\u4e00: \u5173\u7cfb\u578b\u6570\u636e\u5e93\u6a21\u5f0f, \u7ed3\u6784, \u4e25\u8c28\u4e14\u7edf\u4e00, \u4f46\u662f\u6570\u636e\u672c\u8eab\u662f\u5426\u6b63\u786e\u5e76\u4e0d\u5f88\u91cd\u8981. \u53cd\u8fc7\u6765, \u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5c5e\u6027\u503c\u6a21\u5f0f, \u7ed3\u6784, \u8981\u6c42\u5e76\u4e0d\u4e25\u683c, \u4f46\u662f\u6570\u636e\u672c\u8eab\u7684\u8d28\u91cf\u8981\u6c42\u5f88\u9ad8. \u6bd4\u5982, \u5bf9\u4e8e\"\u4e9a\u91cc\u58eb\u591a\u5fb7\"\u7684\u5c5e\u6027\"\u8eab\u9ad8\", \u5173\u7cfb\u578b\u6570\u636e\u5e93\u7684\u5904\u7406\u65b9\u6cd5\u5f88\u53ef\u80fd\u662f\u5e73\u5747\u5217\u8eab\u9ad8\u503c\u8865\u5168, \u4f46\u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5bf9\u4e8e\u5386\u53f2\u540d\u4eba\u51b3\u4e0d\u80fd\u8fd9\u6837\u5904\u7406! \u7b2c\u4e8c: \u5173\u7cfb\u578b\u6570\u636e\u5e93\u4e2d\u7684\u5c5e\u6027\u503c\u7f3a\u5931\u662f\u663e\u5f0f\u7684, \u4f46\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5c5e\u6027\u503c\u7f3a\u5931\u662f\u9690\u5f0f\u7684. \u7f3a\u5931\u5c5e\u6027\u7684\u53d1\u73b0\u4e0e\u8865\u5168, \u5f88\u591a\u65f6\u5019\u91c7\u7528\u4e00\u4e2a\u6982\u5ff5\u7684\u5fc5\u6709\u5c5e\u6027\u7684\u89c4\u5219. \u6bd4\u5982, \"\u4e0a\u4efb\u5e74\u4efd\"\u662f\"\u7f8e\u56fd\u603b\u7edf\"\u8fd9\u4e00\u5b9e\u4f53\u7684\u5fc5\u6709\u5c5e\u6027, \u5982\u679c\u7f3a\u5931\u5219\u5fc5\u987b\u8865\u5168. \u518d\u6bd4\u5982, \u67d0\u6982\u5ff5\u5b9e\u4f53\u4e0b\u7684\u6240\u6709\u5b9e\u4f53\u62e5\u6709\u67d0\u79cd\u5c5e\u6027A\u7684\u6bd4\u4f8b\u8d85\u8fc770%, \u5219\u53ef\u5224\u5b9a\u5c5e\u6027A\u4e3a\u8be5\u6982\u5ff5\u5b9e\u4f53\u7684\u5fc5\u6709\u5c5e\u6027. \u76ee\u524d\u5de5\u4e1a\u754c\u4f1a\u57fa\u4e8e\u4e00\u4e9b\u7279\u5b9a\u5047\u8bbe\u6765\u5efa\u7acb\u68c0\u67e5\u5b9e\u4f53\u5c5e\u6027\u6216\u5c5e\u6027\u503c\u5b8c\u6574\u7a0b\u5ea6\u7684\u5224\u5b9a\u89c4\u5219: \u5c5e\u6027\u7684\u91cd\u8981\u7a0b\u5ea6 \u53c2\u8003\u540c\u4e00\u6982\u5ff5\u4e0b\u7684\u5176\u4ed6\u5b9e\u4f53 \u53c2\u8003\u76f8\u4f3c\u5b9e\u4f53 \u6a21\u5f0f\u5339\u914d \u5c5e\u6027\u503c\u7684\u90e8\u5206\u5b8c\u6574\u6027 \u9519\u8bef\u77e5\u8bc6\u53d1\u73b0\u4e0e\u8865\u5168 \u00b6 \u9664\u4e86\u7f3a\u5931\u77e5\u8bc6\u9020\u6210\u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u7684\u4e0d\u826f\u5916, \u6709\u4e9b\u5df2\u7ecf\u5b58\u5728\u7684\u77e5\u8bc6\u4e0d\u53ef\u907f\u514d\u7684\u4f1a\u6709\u4e00\u4e9b\u9519\u8bef, \u4e0d\u7ea0\u6b63\u8fd9\u4e9b\u9519\u8bef, \u77e5\u8bc6\u56fe\u8c31\u7684\u8d28\u91cf\u5c06\u5927\u6253\u6298\u6263. \u4ece\u6d77\u91cf\u77e5\u8bc6\u56fe\u8c31\u4e2d\u53d1\u73b0\u9519\u8bef\u662f\u4e00\u4e2a\u6781\u5177\u6311\u6218\u7684\u4efb\u52a1. \u9519\u8bef\u5b9e\u4f53\u7c7b\u578b\u68c0\u6d4b \u00b6 \u53ef\u4ee5\u4f9d\u8d56\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u77e5\u8bc6\u6765\u63a8\u7406\u53ef\u80fd\u51fa\u9519\u7684\u5b9e\u4f53\u7c7b\u578b. \u6bd4\u5982, \u53ef\u4ee5\u6839\u636e\u77e5\u8bc6\u56fe\u8c31\u8ba1\u7b97\u5b9e\u4f53\u7684\u5c5e\u6027\u53ca\u5c5e\u6027\u503c\u4e0e\u5b9e\u4f53\u6982\u5ff5\u4e4b\u95f4\u7684\u6982\u7387\u5173\u7cfb, \u4ece\u800c\u6839\u636e\u5c5e\u6027\u6765\u63a8\u65ad\u5176\u6982\u5ff5. \u5047\u8bbe\u4e00\u4e2a\u5b9e\u4f53\u6709\"\u4ee3\u8868\u4f5c\u54c1\"\u8fd9\u4e00\u5c5e\u6027\u4e14\u5177\u4f53\u7684\u503c\u4e3a\u4e00\u4e9b\u7535\u5f71, \u5219\u5176\u6982\u5ff5\u662f\"\u6f14\u5458\"\u6216\"\u5bfc\u6f14\"\u7684\u53ef\u80fd\u6027\u8f83\u5927, \u662f\"\u7535\u5f71\"\u7684\u53ef\u80fd\u6027\u8f83\u5c0f. \u9519\u8bef\u5b9e\u4f53\u5173\u7cfb\u68c0\u6d4b \u00b6 \u6bd4\u8f83\u6709\u4ee3\u8868\u6027\u7684\u68c0\u6d4b\u65b9\u6cd5\u662f\u5c06\u77e5\u8bc6\u56fe\u8c31\u5efa\u6a21\u4e3a\u56fe, \u4ece\u4efb\u610f\u5b9e\u4f53\u51fa\u53d1\u8fdb\u884c\u968f\u673a\u6e38\u8d70, \u5982\u679c\u80fd\u591f\u901a\u8fc7\u4e00\u6761\u8def\u5f84\u8fbe\u5230\u76ee\u6807\u5b9e\u4f53, \u5c06\u5c06\u6b64\u8def\u5f84\u8bb0\u4e3a\u4e00\u6761\u53ef\u884c\u8def\u5f84. \u7ed9\u5b9a\u4e00\u79cd\u5b9e\u4f53\u5bf9\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u7cfb, \u82e5\u80fd\u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u627e\u5230\u5f88\u591a\u6761\u53ef\u884c\u8def\u5f84, \u5219\u8be5\u5173\u7cfb\u5f88\u53ef\u80fd\u662f\u6b63\u786e\u7684, \u5426\u5219\u5f88\u53ef\u80fd\u662f\u9519\u8bef\u7684. \u6bd4\u5982, \u5bf9\u4e8e(\"\u67cf\u62c9\u56fe\", \"\u8001\u5e08\", \"\u82cf\u683c\u62c9\u5e95\")\u8fd9\u4e2a\u4e09\u5143\u7ec4, \u53ef\u4ee5\u627e\u5230\u82e5\u5e72\u8def\u5f84(\"\u67cf\u62c9\u56fe\", isA, \"\u54f2\u5b66\u5bb6\", isA, \"\u82cf\u683c\u62c9\u5e95\"), (\"\u82cf\u683c\u62c9\u5e95\", \"\u5b66\u751f\", \"\u67cf\u62c9\u56fe\"), \u5219\u53ef\u4ee5\u8ba4\u4e3a\u8fd9\u4e2a\u4e09\u5143\u7ec4\u6210\u7acb\u7684\u53ef\u80fd\u6027\u8f83\u5927. \u9519\u8bef\u5c5e\u6027\u503c\u68c0\u6d4b \u00b6 \u79bb\u7fa4\u503c\u68c0\u6d4b: \u5373\u5c06\u4e0e\u76f8\u5173\u6570\u636e\u5206\u5e03\u4e0d\u76f8\u7b26\u7684\u79bb\u7fa4\u503c\u4f5c\u4e3a\u53ef\u80fd\u7684\u9519\u8bef\u503c. \u4f8b\u5982, \u5982\u679c\u4e00\u4f17\u53e4\u5e0c\u814a\u54f2\u5b66\u5bb6\u7684\u51fa\u751f\u65f6\u95f4\u90fd\u662f\"\u516c\u5143\u524dXXX\u5e74\", \u7136\u540e\u5728\u5b9e\u4f53\"\u82cf\u683c\u62c9\u5e95\"\u7684\u5bf9\u5e94\u5c5e\u6027\u503c\u5374\u662f\"\u516c\u5143469\u5e74\", \u5219\u53ef\u4ee5\u901a\u8fc7\u79bb\u7fa4\u503c\u68c0\u6d4b\u53d1\u73b0\u8be5\u503c\u5c5e\u4e8e\u79bb\u7fa4\u7684\u9519\u8bef\u5c5e\u6027\u503c. \u8fc7\u671f\u77e5\u8bc6\u66f4\u65b0 \u00b6 \u77e5\u8bc6\u662f\u52a8\u6001\u53d8\u5316\u7684, \u53d1\u73b0\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u8fc7\u671f\u77e5\u8bc6\u5e76\u53ca\u65f6\u66f4\u65b0, \u662f\u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u63a7\u5236\u7684\u91cd\u8981\u4e00\u73af. \u57fa\u4e8e\u66f4\u65b0\u9891\u7387: \u57fa\u672c\u601d\u60f3\u662f\u66f4\u65b0\u9891\u7387\u9ad8\u7684\u77e5\u8bc6\u5e94\u8be5\u4f18\u5148\u66f4\u65b0. \u4e00\u822c\u6839\u636e\u6cca\u677e\u5206\u5e03\u6765\u4f30\u8ba1\u77e5\u8bc6\u66f4\u65b0\u9891\u7387. \u57fa\u4e8e\u65f6\u95f4\u6807\u7b7e: \u5229\u7528\u4e8b\u5b9e\u95f4\u7684\u65f6\u5e8f\u5173\u7cfb\u9884\u6d4b\u5c06\u66f4\u65b0\u7684\u4e8b\u5b9e. \u4f8b\u5982, \u5bf9\u4e8e\u4e00\u4e2a\u4eba, \u4e8b\u5b9e\u5b58\u5728\u4ee5\u4e0b\u65f6\u5e8f\u5173\u7cfb - \u51fa\u751f, \u6c42\u5b66, \u5de5\u4f5c, \u6b7b\u4ea1. \u57fa\u4e8e\u70ed\u70b9\u4e8b\u4ef6\u53d1\u73b0: \u57fa\u672c\u601d\u60f3\u662f\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7ecf\u5e38\u66f4\u65b0\u7684\u77e5\u8bc6\u5f80\u5f80\u6e90\u81ea\u5c11\u6570\u70ed\u95e8\u5b9e\u4f53, \u4e14\u70ed\u95e8\u5b9e\u4f53\u7684\u4fe1\u606f\u66f4\u65b0\u5f80\u5f80\u4f34\u968f\u7740\u70ed\u70b9\u4e8b\u4ef6\u6216\u70ed\u8bcd\u7684\u51fa\u73b0. \u56e0\u6b64\u8be5\u673a\u5236\u63d0\u51fa\u5bf9\u4e92\u8054\u7f51\u4e0a\u7684\u70ed\u8bcd\u8fdb\u884c\u5b9e\u65f6\u76d1\u63a7, \u8bc6\u522b\u51fa\u70ed\u95e8\u5b9e\u4f53\u5e76\u5c06\u5176\u767e\u79d1\u9875\u9762\u4fe1\u606f\u540c\u6b65\u5230\u77e5\u8bc6\u5e93\u4e2d. \u603b\u7684\u6765\u8bf4\u52064\u4e2a\u6b65\u9aa4: \u79cd\u5b50\u5b9e\u4f53\u53d1\u73b0 \u79cd\u5b50\u5b9e\u4f53\u66f4\u65b0 \u5b9e\u4f53\u6269\u5c55 \u6269\u5c55\u5b9e\u4f53\u66f4\u65b0","title":"8.2 \u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u63a7\u5236"},{"location":"8_2.html#_1","text":"","title":"\u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u63a7\u5236"},{"location":"8_2.html#_2","text":"\u4e86\u89e3\u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u63a7\u5236\u7684\u6982\u5ff5. \u4e86\u89e3\u7f3a\u5931\u77e5\u8bc6\u7684\u53d1\u73b0\u4e0e\u8865\u5168\u65b9\u6cd5. \u4e86\u89e3\u9519\u8bef\u77e5\u8bc6\u7684\u53d1\u73b0\u4e0e\u8865\u5168\u65b9\u6cd5. \u4e86\u89e3\u77e5\u8bc6\u66f4\u65b0\u7684\u610f\u4e49\u4e0e\u65b9\u6cd5.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"8_2.html#_3","text":"\u6240\u8c13\u77e5\u8bc6\u56fe\u8c31\u7684\u8d28\u91cf, \u6307\u77e5\u8bc6\u56fe\u8c31\u4e2d\u77e5\u8bc6\u7684\u8d28\u91cf. \u77e5\u8bc6\u56fe\u8c31\u7684\u8d28\u91cf\u63a7\u5236, \u6307\u7684\u662f\u5982\u4f55\u901a\u8fc7\u6280\u672f\u624b\u6bb5\u6765\u786e\u4fdd\u77e5\u8bc6\u56fe\u8c31\u4e2d\u77e5\u8bc6\u7684\u8d28\u91cf. \u4e0d\u8bba\u662f\u901a\u7528\u9886\u57df, \u8fd8\u662f\u5782\u76f4\u9886\u57df, \u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u90fd\u529b\u6c42\u505a\u5230\u81ea\u52a8\u5316, \u5373\u5c3d\u91cf\u5c11\u7528\u4eba\u529b, \u5c3d\u91cf\u4f9d\u9760\u673a\u5668\u5b8c\u6210. \u9700\u8981\u8003\u8651\u5982\u4e0b\u51e0\u4e2a\u65b9\u9762: \u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u8bc4\u4f30\u7684\u7ef4\u5ea6 \u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u8bc4\u4f30\u7684\u65b9\u6cd5 \u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u63a7\u5236\u5168\u5468\u671f","title":"\u8d28\u91cf\u63a7\u5236\u6982\u8ff0"},{"location":"8_2.html#_4","text":"\u8d28\u91cf\u8bc4\u4f30\u4e3b\u8981\u56f4\u7ed5\u6982\u5ff5, \u5b9e\u4f53, \u5c5e\u6027\u8fd9\u4e09\u7c7b\u4e2a\u4f53\u5bf9\u8c61, \u4ee5\u53ca\u6982\u5ff5\u4e4b\u95f4\u7684\u5173\u7cfb, \u6982\u5ff5\u548c\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb, \u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb\u8fd9\u4e09\u7c7b\u5173\u7cfb\u5bf9\u8c61. \u8003\u5bdf\u5982\u4e0b4\u4e2a\u7ef4\u5ea6: \u51c6\u786e\u6027 \u4e00\u81f4\u6027 \u5b8c\u6574\u6027 \u65f6\u6548\u6027 \u51c6\u786e\u6027(Accuracy): \u8003\u5bdf\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5404\u7c7b\u77e5\u8bc6\u7684\u51c6\u786e\u7a0b\u5ea6. \u4e00\u81f4\u6027(Consistency): \u8003\u5bdf\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u77e5\u8bc6\u8868\u8fbe\u662f\u5426\u4e00\u81f4, \u5373\u77e5\u8bc6\u56fe\u8c31\u4e2d\u662f\u5426\u5b58\u5728\u4e92\u76f8\u77db\u76fe\u7684\u77e5\u8bc6. \u5b8c\u6574\u6027(Integrity): \u8003\u5bdf\u77e5\u8bc6\u56fe\u8c31\u5bf9\u67d0\u4e2a\u9886\u57df\u77e5\u8bc6\u7684\u8986\u76d6\u7a0b\u5ea6. \u65f6\u6548\u6027(Freshness): \u8003\u5bdf\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5b8f\u7684\u77e5\u8bc6\u662f\u5426\u662f\u6700\u65b0\u77e5\u8bc6.","title":"\u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u8bc4\u4f30\u7684\u7ef4\u5ea6"},{"location":"8_2.html#_5","text":"\u77e5\u8bc6\u56fe\u8c31\u7684\u8d28\u91cf\u8bc4\u4f30\u65e8\u5728\u5bf9\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u77e5\u8bc6\u7684\u8d28\u91cf\u8fdb\u884c\u91cf\u5316. \u6839\u636e\u91cf\u5316\u7ed3\u679c, \u4fdd\u7559\u7f6e\u4fe1\u5ea6\u8f83\u9ad8\u7684\u77e5\u8bc6, \u820d\u5f03\u7f6e\u4fe1\u5ea6\u8f83\u4f4e\u7684\u77e5\u8bc6. \u5e38\u7528\u7684\u4e09\u79cd\u65b9\u6cd5: \u4eba\u5de5\u62bd\u6837\u68c0\u6d4b\u6cd5 \u4e00\u81f4\u6027\u68c0\u6d4b\u6cd5 \u57fa\u4e8e\u5916\u90e8\u77e5\u8bc6\u7684\u5bf9\u6bd4\u8bc4\u4f30\u6cd5 \u4eba\u5de5\u62bd\u6837\u68c0\u6d4b\u6cd5: \u7531\u9886\u57df\u4e13\u5bb6\u8fdb\u884c\u62bd\u6837\u8d28\u91cf\u68c0\u6d4b\u4e0e\u8bc4\u4f30. \u6bd4\u5982, \u6309\u7167\u5b9e\u4f53\u7684\u6d41\u884c\u5ea6\u8fdb\u884c\u4f18\u5148\u91c7\u6837, \u786e\u4fdd\u5934\u90e8\u5b9e\u4f53\u5f97\u4ee5\u68c0\u9a8c. \u4e00\u81f4\u6027\u68c0\u6d4b\u6cd5: \u901a\u8fc7\u4e13\u5bb6\u9884\u5148\u5236\u5b9a\u7684\u4e00\u81f4\u6027\u68c0\u6d4b\u89c4\u5219\u68c0\u6d4b\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u77e5\u8bc6\u51b2\u7a81, \u4ee5\u53d1\u73b0\u8d28\u91cf\u95ee\u9898. \u6bd4\u5982, \u7ed9\u5b9a\u89c4\u5219\"\u5927\u5b66\u540c\u5b66\u7684\u6bd5\u4e1a\u9662\u6821\u5e94\u8be5\u662f\u540c\u4e00\u6240\u5927\u5b66\". \u57fa\u4e8e\u5916\u90e8\u77e5\u8bc6\u7684\u5bf9\u6bd4\u8bc4\u4f30\u6cd5: \u4f7f\u7528\u4e0e\u76ee\u6807\u77e5\u8bc6\u56fe\u8c31\u6709\u8f83\u9ad8\u91cd\u5408\u5ea6\u7684\u9ad8\u8d28\u91cf\u5916\u90e8\u77e5\u8bc6\u6e90\u4f5c\u4e3a\u57fa\u51c6\u6570\u636e, \u5bf9\u76ee\u6807\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u8d28\u91cf\u68c0\u6d4b.","title":"\u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u8bc4\u4f30\u7684\u65b9\u6cd5"},{"location":"8_2.html#_6","text":"\u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u63a7\u5236\u8d2f\u7a7f\u4e8e\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7684\u5168\u5468\u671f, \u6d89\u53ca\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u524d, \u4e2d, \u540e\u4e09\u4e2a\u9636\u6bb5\u7684\u8d28\u91cf\u63a7\u5236. \u4e3a\u4e86\u5c3d\u91cf\u907f\u514d\u5f15\u5165\u9519\u8bef, \u9700\u8981\u5bf9\u77e5\u8bc6\u83b7\u53d6\u7684\u65b9\u5f0f\u8fdb\u884c\u8d28\u91cf\u63a7\u5236\u4e0e\u7ba1\u7406. \u800c\u77e5\u8bc6\u878d\u5408\u662f\u5bf9\u5404\u6e90\u5934\u83b7\u53d6\u7684\u77e5\u8bc6\u8fdb\u884c\u878d\u5408, \u7edf\u4e00, \u6d89\u53ca\u5f88\u591a\u6570\u636e\u878d\u5408\u76f8\u5173\u7684\u8d28\u91cf\u95ee\u9898, \u5305\u62ec\u5b9e\u4f53\u5bf9\u9f50, \u5c5e\u6027\u878d\u5408\u53ca\u503c\u89c4\u8303\u5316\u7b49\u7b49.","title":"\u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u63a7\u5236\u5168\u5468\u671f"},{"location":"8_2.html#_7","text":"\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u524d\u7684\u8d28\u91cf\u63a7\u5236\u4e3b\u8981\u5173\u6ce8\u77e5\u8bc6\u6765\u6e90\u7684\u8d28\u91cf. \u5728\u65b0\u95fb\u548c\u4f20\u64ad\u9886\u57df\u5f88\u65e9\u5c31\u5f00\u59cb\u5173\u6ce8\u4fe1\u606f\u6765\u6e90\u7684\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u95ee\u9898, \u5e76\u63d0\u51fa\u8861\u91cf\u4fe1\u6e90\u53ef\u4fe1\u5ea6\u6700\u5173\u952e\u7684\u4e24\u4e2a\u56e0\u7d20: \u4e13\u4e1a(Expertise): \u8861\u91cf\u7684\u662f\u4fe1\u6e90\u5728\u67d0\u9886\u57df\u7684\u4e13\u4e1a\u6027. \u53ef\u4fe1\u8d56(Trustworthiness): \u8861\u91cf\u7684\u662f\u4fe1\u6e90\u6240\u63d0\u4f9b\u5185\u5bb9\u7684\u53ef\u9760\u6027. \u4e92\u8054\u7f51\u6570\u636e\u53ef\u5927\u6982\u5206\u4e3a\u4e24\u7c7b\u6570\u636e: \u6d45\u7f51(Surface Web)\u6570\u636e: \u6307\u5404\u7c7b\u7f51\u7ad9\u9759\u6001\u7f51\u9875\u6240\u5305\u542b\u7684\u6570\u636e\u4fe1\u606f. \u6df1\u7f51(Deep Web)\u6570\u636e: \u6307\u9690\u85cf\u5728\u5404\u7c7b\u7f51\u7ad9\u80cc\u540e\u7684\u7f51\u7edc\u6570\u636e\u5e93\u4e2d\u7684\u6570\u636e\u8bb0\u5f55. \u6d45\u7f51(Surface Web)\u6570\u636e: \u901a\u8fc7\u4eba\u5de5\u603b\u7ed3, \u53ef\u4fe1\u5ea6\u6392\u5e8f\u4e3a .mil(\u519b\u4e8b) > .int(\u56fd\u9645\u7ec4\u7ec7) > .gov(\u653f\u5e9c) > .org(\u975e\u8425\u5229\u673a\u6784) > .eud(\u6559\u80b2) > .com > .net \u6df1\u7f51(Deep Web)\u6570\u636e: \u6df1\u7f51\u4e2d\u5404\u7f51\u7edc\u6570\u636e\u5e93\u4e4b\u95f4\u7684\u6570\u636e\u8bb0\u5f55\u53ef\u4ee5\u901a\u8fc7\u6570\u636e\u8bb0\u5f55\u95f4\u7684\u5339\u914d\u4e0e\u5173\u8054\u5f62\u6210\u7f51\u7edc, \u518d\u5229\u7528PageRank\u6216Random Walk\u7b97\u6cd5\u8fdb\u884c\u8bc4\u4f30. \u4f17\u5305\u77e5\u8bc6\u7684\u53ef\u4fe1\u5ea6\u8bc4\u4f30: \u5de5\u4e1a\u754c\u7684\u4e3b\u6d41\u505a\u6cd5\u662f\u76f4\u63a5\u8bc4\u4f30\u4f17\u5305\u5de5\u4eba\u7684\u53ef\u4fe1\u5ea6, \u7136\u540e\u76f4\u63a5\u5c06\u4f17\u5305\u5de5\u4eba\u7684\u53ef\u4fe1\u670d\u8d4b\u4e88\u5176\u6240\u63d0\u4f9b\u7684\u77e5\u8bc6\u7684\u53ef\u4fe1\u5ea6.","title":"\u6784\u5efa\u524d\u7684\u8d28\u91cf\u63a7\u5236"},{"location":"8_2.html#_8","text":"\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u4e2d\u7684\u4e3b\u8981\u4efb\u52a1\u662f\u77e5\u8bc6\u83b7\u53d6, \u4e3b\u8981\u6280\u672f\u6d41\u6d3e\u6709\u4e24\u79cd: \u57fa\u4e8e\u6a21\u5f0f\u5339\u914d\u7684\u77e5\u8bc6\u83b7\u53d6 \u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u77e5\u8bc6\u83b7\u53d6 \u57fa\u4e8e\u6a21\u5f0f\u5339\u914d\u7684\u77e5\u8bc6\u83b7\u53d6: \u53ef\u4ee5\u4f7f\u7528\u4e13\u5bb6\u7ed9\u5b9a\u7684\u9ad8\u8d28\u91cf\u6a21\u5f0f, \u76f4\u63a5\u4ece\u6587\u672c\u4e2d\u83b7\u53d6\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u6240\u9700\u7684\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb\u5b9e\u4f8b, \u5b9e\u4f53\u4e0e\u6982\u5ff5\u4e4b\u95f4\u7684\u4e0a\u4e0b\u4f4d\u5173\u7cfb\u5b9e\u4f8b, \u4ee5\u53ca\u5b9e\u4f53\u7684\u5c5e\u6027\u503c. \u53cd\u601d: \u57fa\u4e8e\u6a21\u5f0f\u7684\u81ea\u52a8\u62bd\u53d6\u5f80\u5f80\u4f1a\u53d1\u751f\u62bd\u53d6\u9519\u8bef, \u5176\u4e2d\u6700\u5e38\u89c1, \u5371\u5bb3\u6027\u6700\u5927\u7684\u9519\u8bef\u5f53\u5c5e\u8fed\u4ee3\u5f0f\u62bd\u53d6\u4e2d\u53d1\u751f\u7684\"\u8bed\u4e49\u6f02\u79fb\"\u95ee\u9898. \u8bed\u4e49\u6f02\u79fb: \u5373\u5728\u57fa\u4e8e\u6a21\u5f0f\u7684\u8fed\u4ee3\u5f0f\u62bd\u53d6\u8fc7\u7a0b\u4e2d\u7531\u4e8e\u4e0a\u4e00\u8f6e\u53d1\u751f\u62bd\u53d6\u9519\u8bef\u800c\u5f15\u5165\u5176\u4ed6\u8bed\u4e49\u7c7b\u7684\u591a\u4e49\u793a\u4f8b, \u8fd9\u5bfc\u81f4\u540e\u7eed\u8f6e\u6b21\u6240\u62bd\u53d6\u5b9e\u4f8b\u7684\u8bed\u4e49\u7c7b\u4e0e\u76ee\u6807\u8bed\u4e49\u7c7b\u76f8\u8ddd\u751a\u8fdc. \u4f8b\u5982: \u4e3a\u4e86\u53d1\u73b0\u548c\u62bd\u53d6\"Animal\"\u8bed\u4e49\u7c7b\u4e0b\u7684\u5b9e\u4f53, \u7ed9\u5b9a\u4e86\u79cd\u5b50\u96c6\u5408{\"dog\", \"cat\", \"hourse\"}, \u7ecf\u8fc7\u82e5\u5e72\u6761\u6837\u672c\u7684\u5b66\u4e60\u5f97\u5230\u4e24\u6761\u6a21\u5f0fP1: \"...X is a kind of mammal...\", P2: \"Sometime, X is as clever as human beings.\". \u7b2c\u4e8c\u8f6e\u5c31\u4f9d\u9760\u8fd9\u4e24\u6761\u6a21\u5f0f\u7ee7\u7eed\u5339\u914d\u51fa\u65b0\u7684\"Animal\"\u5b9e\u4f8b, \u7136\u540eP2\u89c4\u5219\u53ef\u80fd\u5f15\u5165\"computer\"\u548c\"robot\"\u8fd9\u4e24\u4e2a\u9519\u8bef\u7684\u62bd\u53d6\u7ed3\u679c, \u90a3\u4e48\u5f53\u8fd9\u4e24\u4e2a\u9519\u8bef\u62bd\u53d6\u7ed3\u679c\u8fdb\u5165\u5230\u79cd\u5b50\u96c6\u5408\u4e2d\u540e, \u5728\u7b2c\u4e09\u8f6e\u4e4b\u540e\u7684\u62bd\u53d6\u4e2d, \u5c31\u4f1a\u628a\u5f88\u591a\u8bed\u4e49\u7c7b\u4e3a\"Artefact\"\u4e0b\u7684\u5b9e\u4f8b\u5f52\u5165\u76ee\u6807\u7c7b\"Animal\"\u4e2d, \u9020\u6210\u62bd\u53d6\u7ed3\u679c\"\u8d8a\u6f02\u8d8a\u8fdc\". \u89e3\u51b3\u65b9\u6cd5: \u4f9d\u7136\u662f\u4f9d\u9760\u4eba\u5de5\u89c4\u5219\u5b9a\u4e49\u68c0\u67e5\u6cd5 - \u4e00\u4e2a\u5b9e\u4f8b\u4e0d\u5e94\u8be5\u5c5e\u4e8e\u4e92\u65a5\u7684\u4e24\u4e2a\u6982\u5ff5\u6216\u7c7b\u522b. \u6bd4\u5982, \u5982\u679c\u5b9e\u4f53\u7684\u7c7b\u578b\u88ab\u5224\u5b9a\u4e3a\"\u673a\u6784\", \u4f46\u62bd\u53d6\u51fa\u7684\u6982\u5ff5\u5374\u662f\"\u827a\u672f\u5bb6\", \u663e\u7136\u4e24\u8005\u662f\u77db\u76fe\u7684, \u8fd9\u5c31\u63d0\u793a\u5f53\u524d\u7684\u62bd\u53d6\u7ed3\u679c\u53ef\u80fd\u662f\u9519\u8bef\u7684. \u53cd\u4e4b, \u5982\u679c\"\u67cf\u62c9\u56fe\"\u7684\u7c7b\u578b\u88ab\u5224\u5b9a\u4e3a\"\u4eba\u7269\", \u5176\u7c7b\u578b\u4e0e\u62bd\u53d6\u51fa\u7684\u6982\u5ff5\"\u552f\u5fc3\u4e3b\u4e49\u54f2\u5b66\u5bb6\"\u548c\"\u54f2\u5b66\u5bb6\"\u662f\u4e0d\u77db\u76fe\u7684, \u5219\u53ef\u8ba4\u5b9a\u8fd9\u4e9b\u6982\u5ff5\u662f\u6b63\u786e\u7684. \u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u77e5\u8bc6\u83b7\u53d6: \u4f9d\u9760NER\u6a21\u578b, RE\u6a21\u578b, EE\u6a21\u578b\u76f4\u63a5\u5b8c\u6210\u77e5\u8bc6\u62bd\u53d6, \u62bd\u53d6\u8d28\u91cf\u53d6\u51b3\u4e8e\u6a21\u578b\u672c\u8eab\u7684\u8d28\u91cf. \u5728\u5de5\u4e1a\u754c, \u73b0\u5b9e\u4e2d\u4e3a\u4e86\u6784\u5efa\u6709\u6548\u7684\u4fe1\u606f\u62bd\u53d6\u6a21\u578b, \u5728\u77e5\u8bc6\u56fe\u8c31\u9886\u57df\u503e\u5411\u4e8e\u5229\u7528\u8fdc\u7a0b\u76d1\u7763\u5b66\u4e60, \u901a\u8fc7\u5c06\u77e5\u8bc6\u5e93\u4e2d\u7684\u7ed3\u6784\u5316\u4fe1\u606f\u4e0e\u81ea\u7531\u6587\u672c\u8fdb\u884c\u5bf9\u6bd4\u6765\u81ea\u52a8\u751f\u6210\u6807\u6ce8\u6837\u672c. \u4f46\u662f\u8fdc\u7a0b\u76d1\u7763\u5b66\u4e60\u751f\u6210\u7684\u6837\u672c\u5f80\u5f80\u5b58\u5728\u566a\u58f0, \u8fd8\u9700\u8981\u5bf9\u6837\u672c\u8fdb\u884c\u9009\u62e9.","title":"\u6784\u5efa\u4e2d\u7684\u8d28\u91cf\u63a7\u5236"},{"location":"8_2.html#_9","text":"\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7684\u5168\u6d41\u7a0b, \u76ee\u524d\u5de5\u4e1a\u754c\u7684\u73b0\u72b6\u5f80\u5f80\u9075\u5faa\"\u5148\u6570\u91cf\u518d\u8d28\u91cf\"\u7684\u7b56\u7565, \u5373\"\u5148\u6784\u5efa\u5230\u4e00\u5b9a\u89c4\u6a21, \u518d\u63d0\u9ad8\u8d28\u91cf\"\u8fd9\u6837\u4e00\u79cd\u59a5\u534f\u7684\u7b56\u7565, \u56e0\u6b64\u81ea\u52a8\u6784\u5efa\u7684\u77e5\u8bc6\u56fe\u8c31\u4e0d\u53ef\u907f\u514d\u7684\u5b58\u5728\u5404\u79cd\u8d28\u91cf\u95ee\u9898, \u4e3b\u8981\u6709\u4ee5\u4e0b\u4e09\u79cd: \u77e5\u8bc6\u7f3a\u5931 \u77e5\u8bc6\u9519\u8bef \u77e5\u8bc6\u8fc7\u671f","title":"\u6784\u5efa\u540e\u7684\u8d28\u91cf\u63a7\u5236"},{"location":"8_2.html#_10","text":"\u77e5\u8bc6\u56fe\u8c31\u5728\u5904\u7406\u7f3a\u5931\u77e5\u8bc6\u8865\u5168\u95ee\u9898\u65f6, \u4e0e\u4f20\u7edfNLP\u5904\u7406\u5b9e\u4f53\u8bc6\u522b, \u5173\u7cfb\u62bd\u53d6, \u5b9e\u4f53\u5206\u7c7b\u7b49\u95ee\u9898, \u662f\u6709\u5dee\u522b\u7684.","title":"\u7f3a\u5931\u77e5\u8bc6\u53d1\u73b0\u4e0e\u8865\u5168"},{"location":"8_2.html#_11","text":"\u5b9e\u4f53\u7c7b\u578b\u8865\u5168\u662f\u5bf9\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u4e2d\u9057\u6f0f\u7684\u6982\u5ff5\u8fdb\u884c\u8865\u5168, \u901a\u5e38\u4e5f\u79f0\u4e3a\u5b9e\u4f53\u5224\u578b(Entity Typing). \u6839\u636e\u4f7f\u7528\u7684\u6280\u672f\u8def\u7ebf, \u5206\u4e3a\u4e24\u7c7b: \u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u4fe1\u606f\u7684\u542f\u53d1\u5f0f\u6982\u7387\u6a21\u578b \u5b9e\u4f53\u5206\u7c7b\u6a21\u578b \u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u4fe1\u606f\u7684\u542f\u53d1\u5f0f\u6982\u7387\u6a21\u578b: \u4e3b\u8981\u901a\u8fc7\u8003\u5bdf\u77e5\u8bc6\u56fe\u8c31\u4e2d\u4e0e\u5b9e\u4f53\u76f8\u5173\u7684\u4fe1\u606f\u6765\u6784\u5efa\u4e00\u4e9b\u542f\u53d1\u5f0f\u89c4\u5219\u6216\u6982\u7387\u6a21\u578b. \u4e00\u79cd\u6bd4\u8f83\u7ecf\u5178\u7684\u65b9\u6cd5\u662f\u57fa\u4e8e\u4e09\u5143\u7ec4\u8c13\u8bcd\u7684\u542f\u53d1\u5f0f\u5b9e\u4f53\u5224\u578b\u65b9\u6cd5SDType. SDType\u65b9\u6cd5\u7edf\u8ba1\u5b9e\u4f53\u7684\u53ef\u80fd\u8c13\u8bcd\u4f5c\u4e3a\u4e2d\u95f4\u53d8\u91cf, \u63a8\u65ad\u4e00\u4e2a\u5b9e\u4f53\u5177\u6709\u67d0\u4e2a\u7c7b\u578b\u7684\u53ef\u80fd\u6027. # e\u4e3a\u5934\u5b9e\u4f53\u7684\u6240\u6709\u4e09\u5143\u7ec4 (e, r1, o1) (e, r2, o2) (e, r3, o3) (e, r4, o4) (e, r5, o5) # r1,r2,r3,r4,r5\u7684\u5934\u5b9e\u4f53\u7c7b\u578b\u5206\u5e03\u8868\u5982\u4e0b: r1 Type1 20% Type2 40% Others ... r2 Type1 10% Type2 0% Others ... r3 Type1 40% Type2 30% Others ... r4 Type1 30% Type2 20% Others ... r5 Type1 0% Type2 50% Others ... \u7efc\u4e0a\u4e0a\u9762\u82e5\u5e72\u5f20\u8868, \u53ef\u4ee5\u6309\u7167\u5e73\u5747\u52a0\u6743\u7cfb\u6570\u5f97\u5230\u5b9e\u4f53e\u5206\u522b\u5c5e\u4e8eType1\u548cType2\u7684\u6982\u7387: P(e isA Type1) = 1/5 * (20% + 10% + 40% + 30% + 0%) = 20% P(e isA Type2) = 1/5 * (40% + 0% + 30% + 20% + 50%) = 28% \u5b9e\u4f53\u5206\u7c7b\u6a21\u578b: \u5c06\u5b9e\u4f53\u5224\u578b\u95ee\u9898\u5efa\u6a21\u6210\u5206\u7c7b\u95ee\u9898, \u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u5206\u7c7b\u6a21\u578b\u4e3a\u6bcf\u4e00\u4e2a\u5b9e\u4f53\u7ed9\u51fa\u5bf9\u5e94\u7684\u7c7b\u578b\u6807\u7b7e. \u8fd1\u51e0\u5e74, \u4ece\u5b66\u672f\u754c\u5230\u5de5\u4e1a\u754c, \u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u65e5\u76ca\u6210\u4e3a\u4e3b\u6d41\u5206\u7c7b\u5668. \u5bf9\u4e8e\u7c97\u7c92\u5ea6\u5b9e\u4f53\u5206\u7c7b\u4efb\u52a1(\u7c7b\u522b\u6570\u91cf\u8f83\u5c11), \u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5206\u7c7b\u6a21\u578b\u901a\u5e38\u80fd\u591f\u53d6\u5f97\u8f83\u4e3a\u7406\u60f3\u7684\u5206\u7c7b\u6548\u679c. \u4f46\u662f\u5bf9\u4e8e\u7ec6\u7c92\u5ea6\u5b9e\u4f53\u5206\u7c7b\u4efb\u52a1(\u5206\u7c7b\u8f83\u7ec6, \u7c7b\u522b\u6570\u91cf\u8f83\u591a), \u7531\u4e8e\u5f88\u591a\u7ec6\u7c92\u5ea6\u6982\u5ff5\u53ea\u6709\u5c11\u91cf\u5b9e\u4f8b, \u5f80\u5f80\u56e0\u4e3a\u8bad\u7ec3\u6837\u672c\u4e0d\u8db3, \u6570\u636e\u8fc7\u4e8e\u7a00\u758f\u800c\u8868\u73b0\u8f83\u5dee. \u4e3a\u4e86\u5e94\u5bf9\u6570\u636e\u7cfb\u6570\u7684\u6311\u6218, \u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u4e00\u4e9b\u65b9\u6cd5, \u6bd4\u5982\u501f\u9274\u591a\u4efb\u52a1\u8054\u5408\u8bad\u7ec3\u7684\u601d\u60f3: \u5bf9\u4e8e\u6bcf\u4e00\u79cd\u5b9e\u4f53\u7c7b\u578b\u90fd\u6784\u5efa\u4e00\u4e2a\u57fa\u7840\u5206\u7c7b\u5668, \u7528\u4e8e\u5224\u65ad\u5f53\u524d\u5b9e\u4f53\u662f\u5426\u5c5e\u4e8e\u8be5\u7c7b\u578b, \u5e76\u4e14\u6240\u6709\u7684\u57fa\u7840\u5206\u7c7b\u5668\u90fd\u5171\u4eab\u4e00\u4e2a\u9690\u5c42\u8fdb\u884c\u8054\u5408\u8bad\u7ec3, \u4f7f\u6a21\u578b\u80fd\u591f\u4e60\u5f97\u5bf9\u4e8e\u591a\u4e2a\u5b9e\u4f53\u7c7b\u578b\u5206\u7c7b\u5668\u666e\u904d\u6709\u6548\u7684\u8f93\u5165\u7279\u5f81\u7684\u7ec4\u5408, \u4ece\u800c\u6709\u6548\u7f13\u89e3\u90e8\u5206\u5b9e\u4f53\u7c7b\u578b\u4e2d\u7684\u6570\u636e\u7a00\u758f\u95ee\u9898.","title":"\u7c7b\u578b\u8865\u5168"},{"location":"8_2.html#_12","text":"\u5173\u7cfb\u8865\u5168\u662f\u5bf9\u77e5\u8bc6\u56fe\u8c31\u4e2d\u4e0d\u5b8c\u6574\u7684\u5173\u7cfb\u4e09\u5143\u7ec4(Subject, Predicate, Object)\u8fdb\u884c\u8865\u5168. \u76ee\u524d\u5b66\u672f\u754c, \u5de5\u4e1a\u754c\u4e3b\u8981\u7684\u7814\u7a76\u70ed\u70b9\u653e\u5728\u5173\u7cfb\u6216\u5c3e\u5b9e\u4f53\u7f3a\u5931\u7684\u573a\u666f. \u5173\u7cfb\u8865\u5168\u662fKG\u9886\u57df\u7684\u7814\u7a76\u70ed\u70b9, \u5927\u91cf\u7814\u7a76\u5de5\u4f5c\u96c6\u4e2d\u4e8e\u6b64. \u603b\u4f53\u5206\u4e24\u7c7b\u65b9\u6cd5: \u57fa\u4e8e\u5185\u90e8\u77e5\u8bc6\u7684\u5173\u7cfb\u8865\u5168 \u57fa\u4e8e\u5916\u90e8\u6570\u636e\u7684\u5173\u7cfb\u8865\u5168 \u57fa\u4e8e\u5185\u90e8\u77e5\u8bc6\u7684\u5173\u7cfb\u8865\u5168: \u4f20\u7edf\u7684\u8def\u5f84\u6392\u5e8f\u7b97\u6cd5, \u57fa\u672c\u601d\u60f3\u662f\u7528\u8fde\u63a5\u4e24\u4e2a\u5b9e\u4f53\u7684\u8def\u5f84\u4f5c\u4e3a\u7279\u5f81, \u6765\u9884\u6d4b\u4e24\u4e2a\u5b9e\u4f53\u95f4\u7684\u5173\u7cfb. \u6bd4\u5982\u6211\u4eec\u8981\u5224\u5b9a\"\u82cf\u683c\u62c9\u5e95\"\u7684\"\u51fa\u751f\u5730\"\u662f\u5426\u4e3a\"\u96c5\u5178\", \u90a3\u4e48\u9996\u5148\u6784\u9020\u8bad\u7ec3\u96c6, \u627e\u51fa\u6574\u4e2a\u77e5\u8bc6\u56fe\u8c31\u5185\u90e8\u6240\u6709\"\u51fa\u751f\u5730\"\u8fd9\u4e00\u5173\u7cfb\u7684\u76f8\u5173\u4e09\u5143\u7ec4\u4f5c\u4e3a\u6b63\u4f8b. \u7136\u540e\u91c7\u7528\u968f\u673a\u66ff\u6362\u6b63\u4f8b\u4e09\u5143\u7ec4\u4e2d\u5c3e\u5b9e\u4f53\u7684\u65b9\u6cd5\u6784\u9020\u8d1f\u4f8b. \u5c06\u4e24\u4e2a\u5b9e\u4f53\u4e4b\u95f4\u7684\u4e00\u6761\u8def\u5f84\u4f5c\u4e3a\u4e00\u4e2a\u7279\u5f81\u5411\u91cf, (\"\u82cf\u683c\u62c9\u5e95\", \"\u5b66\u751f\", \"\u67cf\u62c9\u56fe\", \"\u51fa\u751f\u5730\", \"\u96c5\u5178\")\u8fd9\u6837\u4e00\u6761\u8def\u5f84. \u901a\u8fc7\u679a\u4e3e\u4efb\u610f\u4e24\u4e2a\u5b9e\u4f53\u4e4b\u95f4\u6240\u6709\u7b26\u5408\u8bbe\u5b9a\u6761\u4ef6\u7684\u8def\u5f84, \u53ef\u4ee5\u6784\u5efa\u8be5\u5b9e\u4f53\u5bf9\u7684\u7279\u5f81\u96c6\u5408. \u901a\u8fc7\u7279\u5f81\u96c6\u5408\u83b7\u53d6\u7279\u5f81\u503c, \u6700\u540e\u4fbf\u53ef\u4ee5\u4f7f\u7528\u7279\u5f81\u6570\u636e\u8bad\u7ec3\u5206\u7c7b\u5668. \u57fa\u4e8e\u8868\u793a\u5b66\u4e60\u7684\u63a8\u7406\u8865\u5168\u6a21\u578b: \u8be5\u6a21\u578b\u4ee5\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\u5411\u91cf\u4f5c\u4e3a\u8f93\u5165, \u5bf9\u6bcf\u4e00\u79cd\u5173\u7cfb\u90fd\u7528\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u6765\u8868\u793a. \u4f7f\u7528\u8be5\u5173\u7cfb\u4e0b\u7684\u4e09\u5143\u7ec4\u4f5c\u4e3a\u6b63\u4f8b, \u751f\u6210\u4e00\u4e9b\u4e0d\u5c5e\u4e8e\u8be5\u5173\u7cfb\u7684\u4e09\u5143\u7ec4\u4f5c\u4e3a\u8d1f\u4f8b, \u8fdb\u884c\u6a21\u578b\u8bad\u7ec3. \u6bd4\u5982, \u5c06\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\"\u67cf\u62c9\u56fe\", \"\u552f\u5fc3\u4e3b\u4e49\", \"\u54f2\u5b66\u5bb6\"\u7b49\u8bcd\u6c47\u8fdb\u884c\u5d4c\u5165\u8868\u793a\u6210\u5f20\u91cf\u5f62\u5f0f, \u5229\u7528\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\"\u67cf\u62c9\u56fe\"\u548c\"\u552f\u5fc3\u4e3b\u4e49\u54f2\u5b66\u5bb6\"\u4e24\u4e2a\u5b9e\u4f53\u5b58\u5728\u4f55\u79cd\u5173\u7cfb. \u795e\u7ecf\u7f51\u7edc\u7684\u8f93\u51fa\u5c42\u7ecf\u5386\u8d2a\u5fc3\u89e3\u7801\u540e, \u5173\u7cfb\"\u804c\u4e1a\"\u7684\u5f97\u5206\u6700\u9ad8, \u56e0\u4e3a\u5f97\u5230\u9884\u6d4b\u4e09\u5143\u7ec4(\"\u67cf\u62c9\u56fe\", \"\u804c\u4e1a\", \"\u552f\u5fc3\u4e3b\u4e49\u54f2\u5b66\u5bb6\"). \u57fa\u4e8e\u5916\u90e8\u6570\u636e\u7684\u5173\u7cfb\u8865\u5168: \u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u5185\u90e8\u77e5\u8bc6\u63a8\u65ad\u51fa\u7684\u77e5\u8bc6\u662f\u6709\u9650\u7684, \u56e0\u6b64\u8fd8\u9700\u8981\u4ece\u5916\u90e8\u7684\u5f00\u653e\u4e16\u754c, \u7279\u522b\u662f\u5728\u7ebf\u767e\u79d1, \u6587\u672c\u8bed\u6599, \u7ed3\u6784\u5316\u8868\u683c\u6570\u636e\u53ca\u641c\u7d22\u5f15\u64ce\u7ed3\u679c\u7b49\u5916\u90e8\u8d44\u6e90, \u5bf9\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u8865\u5168. \u6838\u5fc3: \u5728\u7ebf\u767e\u79d1(\u767e\u5ea6\u767e\u79d1, \u7ef4\u57fa\u767e\u79d1)\u6240\u5305\u542b\u7684\u4fe1\u606f\u4e0d\u4ec5\u4e30\u5bcc\u4e14\u8d28\u91cf\u8f83\u9ad8, \u6210\u4e3a\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u6700\u6d41\u884c\u7684\u5916\u90e8\u6570\u636e\u6e90.","title":"\u5173\u7cfb\u8865\u5168"},{"location":"8_2.html#_13","text":"\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5c5e\u6027\u503c\u8865\u5168\u95ee\u9898\u4e0e\u5173\u7cfb\u578b\u6570\u636e\u5e93\u9886\u57df\u7ecf\u5178\u7684\u5c5e\u6027\u503c\u8865\u5168\u95ee\u9898, \u5f88\u76f8\u4f3c, \u4f46\u53c8\u6709\u91cd\u5927\u533a\u522b! \u533a\u522b\u6709\u4e24\u70b9: \u7b2c\u4e00: \u5173\u7cfb\u578b\u6570\u636e\u5e93\u6a21\u5f0f, \u7ed3\u6784, \u4e25\u8c28\u4e14\u7edf\u4e00, \u4f46\u662f\u6570\u636e\u672c\u8eab\u662f\u5426\u6b63\u786e\u5e76\u4e0d\u5f88\u91cd\u8981. \u53cd\u8fc7\u6765, \u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5c5e\u6027\u503c\u6a21\u5f0f, \u7ed3\u6784, \u8981\u6c42\u5e76\u4e0d\u4e25\u683c, \u4f46\u662f\u6570\u636e\u672c\u8eab\u7684\u8d28\u91cf\u8981\u6c42\u5f88\u9ad8. \u6bd4\u5982, \u5bf9\u4e8e\"\u4e9a\u91cc\u58eb\u591a\u5fb7\"\u7684\u5c5e\u6027\"\u8eab\u9ad8\", \u5173\u7cfb\u578b\u6570\u636e\u5e93\u7684\u5904\u7406\u65b9\u6cd5\u5f88\u53ef\u80fd\u662f\u5e73\u5747\u5217\u8eab\u9ad8\u503c\u8865\u5168, \u4f46\u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5bf9\u4e8e\u5386\u53f2\u540d\u4eba\u51b3\u4e0d\u80fd\u8fd9\u6837\u5904\u7406! \u7b2c\u4e8c: \u5173\u7cfb\u578b\u6570\u636e\u5e93\u4e2d\u7684\u5c5e\u6027\u503c\u7f3a\u5931\u662f\u663e\u5f0f\u7684, \u4f46\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5c5e\u6027\u503c\u7f3a\u5931\u662f\u9690\u5f0f\u7684. \u7f3a\u5931\u5c5e\u6027\u7684\u53d1\u73b0\u4e0e\u8865\u5168, \u5f88\u591a\u65f6\u5019\u91c7\u7528\u4e00\u4e2a\u6982\u5ff5\u7684\u5fc5\u6709\u5c5e\u6027\u7684\u89c4\u5219. \u6bd4\u5982, \"\u4e0a\u4efb\u5e74\u4efd\"\u662f\"\u7f8e\u56fd\u603b\u7edf\"\u8fd9\u4e00\u5b9e\u4f53\u7684\u5fc5\u6709\u5c5e\u6027, \u5982\u679c\u7f3a\u5931\u5219\u5fc5\u987b\u8865\u5168. \u518d\u6bd4\u5982, \u67d0\u6982\u5ff5\u5b9e\u4f53\u4e0b\u7684\u6240\u6709\u5b9e\u4f53\u62e5\u6709\u67d0\u79cd\u5c5e\u6027A\u7684\u6bd4\u4f8b\u8d85\u8fc770%, \u5219\u53ef\u5224\u5b9a\u5c5e\u6027A\u4e3a\u8be5\u6982\u5ff5\u5b9e\u4f53\u7684\u5fc5\u6709\u5c5e\u6027. \u76ee\u524d\u5de5\u4e1a\u754c\u4f1a\u57fa\u4e8e\u4e00\u4e9b\u7279\u5b9a\u5047\u8bbe\u6765\u5efa\u7acb\u68c0\u67e5\u5b9e\u4f53\u5c5e\u6027\u6216\u5c5e\u6027\u503c\u5b8c\u6574\u7a0b\u5ea6\u7684\u5224\u5b9a\u89c4\u5219: \u5c5e\u6027\u7684\u91cd\u8981\u7a0b\u5ea6 \u53c2\u8003\u540c\u4e00\u6982\u5ff5\u4e0b\u7684\u5176\u4ed6\u5b9e\u4f53 \u53c2\u8003\u76f8\u4f3c\u5b9e\u4f53 \u6a21\u5f0f\u5339\u914d \u5c5e\u6027\u503c\u7684\u90e8\u5206\u5b8c\u6574\u6027","title":"\u5c5e\u6027\u503c\u8865\u5168"},{"location":"8_2.html#_14","text":"\u9664\u4e86\u7f3a\u5931\u77e5\u8bc6\u9020\u6210\u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u7684\u4e0d\u826f\u5916, \u6709\u4e9b\u5df2\u7ecf\u5b58\u5728\u7684\u77e5\u8bc6\u4e0d\u53ef\u907f\u514d\u7684\u4f1a\u6709\u4e00\u4e9b\u9519\u8bef, \u4e0d\u7ea0\u6b63\u8fd9\u4e9b\u9519\u8bef, \u77e5\u8bc6\u56fe\u8c31\u7684\u8d28\u91cf\u5c06\u5927\u6253\u6298\u6263. \u4ece\u6d77\u91cf\u77e5\u8bc6\u56fe\u8c31\u4e2d\u53d1\u73b0\u9519\u8bef\u662f\u4e00\u4e2a\u6781\u5177\u6311\u6218\u7684\u4efb\u52a1.","title":"\u9519\u8bef\u77e5\u8bc6\u53d1\u73b0\u4e0e\u8865\u5168"},{"location":"8_2.html#_15","text":"\u53ef\u4ee5\u4f9d\u8d56\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u77e5\u8bc6\u6765\u63a8\u7406\u53ef\u80fd\u51fa\u9519\u7684\u5b9e\u4f53\u7c7b\u578b. \u6bd4\u5982, \u53ef\u4ee5\u6839\u636e\u77e5\u8bc6\u56fe\u8c31\u8ba1\u7b97\u5b9e\u4f53\u7684\u5c5e\u6027\u53ca\u5c5e\u6027\u503c\u4e0e\u5b9e\u4f53\u6982\u5ff5\u4e4b\u95f4\u7684\u6982\u7387\u5173\u7cfb, \u4ece\u800c\u6839\u636e\u5c5e\u6027\u6765\u63a8\u65ad\u5176\u6982\u5ff5. \u5047\u8bbe\u4e00\u4e2a\u5b9e\u4f53\u6709\"\u4ee3\u8868\u4f5c\u54c1\"\u8fd9\u4e00\u5c5e\u6027\u4e14\u5177\u4f53\u7684\u503c\u4e3a\u4e00\u4e9b\u7535\u5f71, \u5219\u5176\u6982\u5ff5\u662f\"\u6f14\u5458\"\u6216\"\u5bfc\u6f14\"\u7684\u53ef\u80fd\u6027\u8f83\u5927, \u662f\"\u7535\u5f71\"\u7684\u53ef\u80fd\u6027\u8f83\u5c0f.","title":"\u9519\u8bef\u5b9e\u4f53\u7c7b\u578b\u68c0\u6d4b"},{"location":"8_2.html#_16","text":"\u6bd4\u8f83\u6709\u4ee3\u8868\u6027\u7684\u68c0\u6d4b\u65b9\u6cd5\u662f\u5c06\u77e5\u8bc6\u56fe\u8c31\u5efa\u6a21\u4e3a\u56fe, \u4ece\u4efb\u610f\u5b9e\u4f53\u51fa\u53d1\u8fdb\u884c\u968f\u673a\u6e38\u8d70, \u5982\u679c\u80fd\u591f\u901a\u8fc7\u4e00\u6761\u8def\u5f84\u8fbe\u5230\u76ee\u6807\u5b9e\u4f53, \u5c06\u5c06\u6b64\u8def\u5f84\u8bb0\u4e3a\u4e00\u6761\u53ef\u884c\u8def\u5f84. \u7ed9\u5b9a\u4e00\u79cd\u5b9e\u4f53\u5bf9\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u7cfb, \u82e5\u80fd\u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u627e\u5230\u5f88\u591a\u6761\u53ef\u884c\u8def\u5f84, \u5219\u8be5\u5173\u7cfb\u5f88\u53ef\u80fd\u662f\u6b63\u786e\u7684, \u5426\u5219\u5f88\u53ef\u80fd\u662f\u9519\u8bef\u7684. \u6bd4\u5982, \u5bf9\u4e8e(\"\u67cf\u62c9\u56fe\", \"\u8001\u5e08\", \"\u82cf\u683c\u62c9\u5e95\")\u8fd9\u4e2a\u4e09\u5143\u7ec4, \u53ef\u4ee5\u627e\u5230\u82e5\u5e72\u8def\u5f84(\"\u67cf\u62c9\u56fe\", isA, \"\u54f2\u5b66\u5bb6\", isA, \"\u82cf\u683c\u62c9\u5e95\"), (\"\u82cf\u683c\u62c9\u5e95\", \"\u5b66\u751f\", \"\u67cf\u62c9\u56fe\"), \u5219\u53ef\u4ee5\u8ba4\u4e3a\u8fd9\u4e2a\u4e09\u5143\u7ec4\u6210\u7acb\u7684\u53ef\u80fd\u6027\u8f83\u5927.","title":"\u9519\u8bef\u5b9e\u4f53\u5173\u7cfb\u68c0\u6d4b"},{"location":"8_2.html#_17","text":"\u79bb\u7fa4\u503c\u68c0\u6d4b: \u5373\u5c06\u4e0e\u76f8\u5173\u6570\u636e\u5206\u5e03\u4e0d\u76f8\u7b26\u7684\u79bb\u7fa4\u503c\u4f5c\u4e3a\u53ef\u80fd\u7684\u9519\u8bef\u503c. \u4f8b\u5982, \u5982\u679c\u4e00\u4f17\u53e4\u5e0c\u814a\u54f2\u5b66\u5bb6\u7684\u51fa\u751f\u65f6\u95f4\u90fd\u662f\"\u516c\u5143\u524dXXX\u5e74\", \u7136\u540e\u5728\u5b9e\u4f53\"\u82cf\u683c\u62c9\u5e95\"\u7684\u5bf9\u5e94\u5c5e\u6027\u503c\u5374\u662f\"\u516c\u5143469\u5e74\", \u5219\u53ef\u4ee5\u901a\u8fc7\u79bb\u7fa4\u503c\u68c0\u6d4b\u53d1\u73b0\u8be5\u503c\u5c5e\u4e8e\u79bb\u7fa4\u7684\u9519\u8bef\u5c5e\u6027\u503c.","title":"\u9519\u8bef\u5c5e\u6027\u503c\u68c0\u6d4b"},{"location":"8_2.html#_18","text":"\u77e5\u8bc6\u662f\u52a8\u6001\u53d8\u5316\u7684, \u53d1\u73b0\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u8fc7\u671f\u77e5\u8bc6\u5e76\u53ca\u65f6\u66f4\u65b0, \u662f\u77e5\u8bc6\u56fe\u8c31\u8d28\u91cf\u63a7\u5236\u7684\u91cd\u8981\u4e00\u73af. \u57fa\u4e8e\u66f4\u65b0\u9891\u7387: \u57fa\u672c\u601d\u60f3\u662f\u66f4\u65b0\u9891\u7387\u9ad8\u7684\u77e5\u8bc6\u5e94\u8be5\u4f18\u5148\u66f4\u65b0. \u4e00\u822c\u6839\u636e\u6cca\u677e\u5206\u5e03\u6765\u4f30\u8ba1\u77e5\u8bc6\u66f4\u65b0\u9891\u7387. \u57fa\u4e8e\u65f6\u95f4\u6807\u7b7e: \u5229\u7528\u4e8b\u5b9e\u95f4\u7684\u65f6\u5e8f\u5173\u7cfb\u9884\u6d4b\u5c06\u66f4\u65b0\u7684\u4e8b\u5b9e. \u4f8b\u5982, \u5bf9\u4e8e\u4e00\u4e2a\u4eba, \u4e8b\u5b9e\u5b58\u5728\u4ee5\u4e0b\u65f6\u5e8f\u5173\u7cfb - \u51fa\u751f, \u6c42\u5b66, \u5de5\u4f5c, \u6b7b\u4ea1. \u57fa\u4e8e\u70ed\u70b9\u4e8b\u4ef6\u53d1\u73b0: \u57fa\u672c\u601d\u60f3\u662f\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7ecf\u5e38\u66f4\u65b0\u7684\u77e5\u8bc6\u5f80\u5f80\u6e90\u81ea\u5c11\u6570\u70ed\u95e8\u5b9e\u4f53, \u4e14\u70ed\u95e8\u5b9e\u4f53\u7684\u4fe1\u606f\u66f4\u65b0\u5f80\u5f80\u4f34\u968f\u7740\u70ed\u70b9\u4e8b\u4ef6\u6216\u70ed\u8bcd\u7684\u51fa\u73b0. \u56e0\u6b64\u8be5\u673a\u5236\u63d0\u51fa\u5bf9\u4e92\u8054\u7f51\u4e0a\u7684\u70ed\u8bcd\u8fdb\u884c\u5b9e\u65f6\u76d1\u63a7, \u8bc6\u522b\u51fa\u70ed\u95e8\u5b9e\u4f53\u5e76\u5c06\u5176\u767e\u79d1\u9875\u9762\u4fe1\u606f\u540c\u6b65\u5230\u77e5\u8bc6\u5e93\u4e2d. \u603b\u7684\u6765\u8bf4\u52064\u4e2a\u6b65\u9aa4: \u79cd\u5b50\u5b9e\u4f53\u53d1\u73b0 \u79cd\u5b50\u5b9e\u4f53\u66f4\u65b0 \u5b9e\u4f53\u6269\u5c55 \u6269\u5c55\u5b9e\u4f53\u66f4\u65b0","title":"\u8fc7\u671f\u77e5\u8bc6\u66f4\u65b0"},{"location":"9_1.html","text":"\u77e5\u8bc6\u63a8\u7406\u65b9\u6cd5 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u77e5\u8bc6\u63a8\u7406\u7684\u6982\u5ff5. \u4e86\u89e3\u51e0\u79cd\u5e38\u89c1\u7684\u63a8\u7406\u65b9\u6cd5. \u77e5\u8bc6\u63a8\u7406\u6982\u5ff5 \u00b6 \u4ee5\u6df1\u5ea6\u5b66\u4e60\u4e3a\u4ee3\u8868\u7684\u4eba\u5de5\u667a\u80fd, \u4ece\u672c\u8d28\u4e0a\u770b\u53ea\u662f\u4e00\u79cd\u6a21\u4eff\u795e\u7ecf\u5b66\u7684\u66f4\u4e3a\u590d\u6742\u7684\u6570\u5b66\u6a21\u578b. \u73b0\u5b9e\u4e2d\u4e00\u4e9b\u5bf9\u4eba\u7c7b\u6765\u8bf4\u5341\u5206\u7b80\u5355\u7684\u95ee\u9898, \u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5e38\u5e38\u9700\u8981\u5229\u7528\u6d77\u91cf\u7684\u6570\u636e\u8fdb\u884c\u5b66\u4e60\u624d\u80fd\u6709\u597d\u7684\u8868\u73b0. \u8fd9\u4e0e\u4eba\u7c7b\u7684\u5b66\u4e60\u6a21\u5f0f\u5dee\u5f02\u975e\u5e38\u4e4b\u5927, \u4eba\u7c7b\u5e38\u5e38\u81ea\u5df1\u603b\u7ed3, \u5f52\u7eb3, \u63a8\u7406\u548c\u4e3e\u4e00\u53cd\u4e09, \u4ece\u5c11\u91cf\u7684\u6837\u672c\u548c\u8bad\u7ec3\u4e2d, \u771f\u6b63\u4e60\u5f97\u4e00\u4e9b\u6280\u80fd. \u4f8b\u5982, \u6ca1\u6709\u4eba\u8981\u5148\u5f00\u4e2a\u51e0\u4e07\u516c\u91cc\u7684\u8f66\u624d\u80fd\u62ff\u5230\u9a7e\u7167. \u901a\u4fd7\u7684\u7406\u89e3, \u6240\u8c13\u63a8\u7406, \u5c31\u662f\u4ece\u73b0\u6709\u7684\u77e5\u8bc6\u51fa\u53d1, \u8fd0\u7528\u903b\u8f91\u601d\u7ef4\u80fd\u529b\u5f97\u51fa\u4e00\u4e9b\u9690\u6027\u7684\u7ed3\u8bba. \u5177\u4f53\u5230\u77e5\u8bc6\u56fe\u8c31\u4e2d, \u6240\u8c13\u7684\u77e5\u8bc6\u63a8\u7406, \u5c31\u662f\u5229\u7528\u56fe\u8c31\u4e2d\u73b0\u6709\u7684\u77e5\u8bc6(\u4e09\u5143\u7ec4), \u5f97\u5230\u4e00\u4e9b\u65b0\u7684\u5b9e\u4f53\u95f4\u7684\u5173\u7cfb\u6216\u8005\u5b9e\u4f53\u7684\u5c5e\u6027(\u4e09\u5143\u7ec4). \u4f8b\u5982, \u77e5\u8bc6\u56fe\u8c31\u4e2d\u6709\u8fd9\u6837\u4e24\u4e2a\u4e09\u5143\u7ec4, (\u5468\u6770\u4f26, \u8001\u5a46, \u6606\u51cc)\u548c(\u5468\u6770\u4f26, \u5988\u5988, \u53f6\u60e0\u7f8e), \u901a\u8fc7\u77e5\u8bc6\u63a8\u7406, \u53ef\u4ee5\u5f97\u5230(\u6606\u51cc, \u5a46\u5a46, \u53f6\u60e0\u7f8e). \u57fa\u4e8e\u89c4\u5219\u7684\u63a8\u7406 \u00b6 \u90a3\u4e48, \u5982\u4f55\u4ece\u73b0\u6709\u7684\u77e5\u8bc6\u4e2d, \u63a8\u7406\u51fa\u6765\u65b0\u7684\u77e5\u8bc6\u548c\u7ed3\u8bba\u5462? \u53ef\u4ee5\u9884\u5148\u5b9a\u4e49\u597d\u51c6\u786e\u7684\u63a8\u7406\u89c4\u5219, \u7136\u540e\u57fa\u4e8e\u8fd9\u4e9b\u89c4\u5219\u548c\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5df2\u6709\u7684\u77e5\u8bc6\u63a8\u5bfc\u51fa\u65b0\u7684\u7ed3\u8bba\u548c\u77e5\u8bc6. \u4f8b\u5982, \u9884\u5148\u5b9a\u4e49\u597d\u8fd9\u6837\u7684\u89c4\u5219 (\u5b9e\u4f531:\u8001\u5a46:\u5b9e\u4f532; \u5b9e\u4f531:\u5988\u5988:\u5b9e\u4f533 -> \u5b9e\u4f532:\u5a46\u5a46:\u5b9e\u4f533) \u8fdb\u4e00\u6b65\u7ec6\u60f3, \u4f1a\u89c9\u5f97\u8fd9\u6837\u7684\u65b9\u5f0f\u6548\u7387\u592a\u4f4e. \u56e0\u6b64, \u57fa\u4e8e\u903b\u8f91\u63a8\u7406\u81f4\u529b\u4e8e\u5982\u4f55\u81ea\u52a8\u63a8\u7406\u83b7\u53d6\u4e0a\u8ff0\u7684\u89c4\u5219, \u6bd4\u8f83\u6709\u540d\u7684\u5305\u62ec\u57fa\u4e8e\u53ef\u6ee1\u8db3\u6027\u7684GSAT\u548cWALKSAT, \u7528\u4e8e\u6c42\u89e3\u903b\u8f91\u63a8\u7406\u7684\u89c4\u5219. \u901a\u5e38\u6765\u8bf4, \u5728\u5de5\u7a0b\u9886\u57df\u4f1a\u5c06\u77e5\u8bc6\u63a8\u7406\u7cfb\u7edf\u4ece\u77e5\u8bc6\u4f53\u7cfb\u4e2d\u5355\u72ec\u5206\u79bb\u51fa\u6765, \u8fd9\u6837\u5c31\u53ef\u4ee5\u8ba9\u77e5\u8bc6\u4e13\u5bb6\u4e13\u6ce8\u4e8e\u77e5\u8bc6\u5efa\u8bbe, \u63a8\u7406\u89c4\u5219\u7531\u63a8\u7406\u7cfb\u7edf\u7684\u8bbe\u8ba1\u8005\u4e13\u95e8\u5efa\u7acb. \u76ee\u524d\u6bd4\u8f83\u6709\u540d\u7684\u63a8\u7406\u7cfb\u7edf\u6709ELK, DLV, Pellet\u7b49. \u57fa\u4e8e\u89c4\u5219\u7684\u903b\u8f91\u63a8\u7406\u7684\u4f18\u70b9\u5728\u4e8e\u51c6\u786e\u6027\u9ad8, \u63a8\u7406\u901f\u5ea6\u5feb; \u7f3a\u70b9\u5728\u4e8e\u80fd\u591f\u5904\u7406\u7684\u77e5\u8bc6\u6709\u9650, \u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u7684\u7f51\u7edc\u77e5\u8bc6\u56fe\u8c31, \u6709\u4e00\u5b9a\u6982\u7387\u83b7\u53d6\u5230\u4e0d\u51c6\u786e\u7684\u77e5\u8bc6\u548c\u4e8b\u5b9e, \u8fd9\u4e9b\u77e5\u8bc6\u57fa\u4e8e\u786e\u5b9a\u7684\u903b\u8f91\u63a8\u7406\u65e0\u6cd5\u5904\u7406, \u9700\u8981\u52a0\u5165\u7edf\u8ba1\u6216\u8005\u6982\u7387\u7684\u65b9\u5f0f\u5c06\u89c4\u5219\u8f6f\u5316. \u57fa\u4e8e\u6982\u7387\u56fe\u7684\u63a8\u7406 \u00b6 \u4e00\u65b9\u9762, \u73b0\u6709\u7684NLP\u6280\u672f\u8fd8\u5f88\u96be\u51c6\u786e\u7684\u5c06\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u6210\u786e\u5b9a\u6027\u7684\u63a8\u7406\u9700\u6c42; \u53e6\u4e00\u65b9\u9762, \u73b0\u5b9e\u4e16\u754c\u672c\u8eab\u7684\u4e0d\u786e\u5b9a\u6027, \u51b3\u5b9a\u4e86\u5f88\u591a\u95ee\u9898\u65e0\u6cd5\u4f7f\u7528\u786e\u5b9a\u6027\u7684\u63a8\u7406\u6280\u672f\u8fdb\u884c\u56de\u7b54. \u57fa\u4e8e\u6982\u7387\u6a21\u578b\u7684\u63a8\u7406\u5e76\u4e0d\u662f\u4e25\u683c\u7684\u6309\u7167\u89c4\u5219\u8fdb\u884c\u63a8\u7406, \u800c\u662f\u6839\u636e\u4ee5\u5f80\u7684\u7ecf\u9a8c\u548c\u5206\u6790, \u7ed3\u5408\u4e13\u5bb6\u5148\u9a8c\u77e5\u8bc6\u6784\u5efa\u6982\u7387\u6a21\u578b, \u5e76\u5229\u7528\u7edf\u8ba1\u8ba1\u6570, \u6700\u5927\u5316\u540e\u9a8c\u6982\u7387\u7b49\u7edf\u8ba1\u5b66\u7684\u624b\u6bb5\u5bf9\u63a8\u7406\u5047\u8bbe\u8fdb\u884c\u9a8c\u8bc1\u6216\u8005\u63a8\u6d4b. \u603b\u7684\u6765\u8bf4, \u57fa\u4e8e\u6982\u7387\u7684\u6a21\u578b\u63a8\u7406, \u5c31\u662f\u4e13\u5bb6\u57fa\u4e8e\u73b0\u6709\u7684\u5148\u9a8c\u77e5\u8bc6, \u5efa\u7acb\u76f8\u5173\u7684\u89c4\u5219\u6982\u7387\u6a21\u578b\u5bf9\u786e\u5b9a\u7684\u89c4\u5219\u8fdb\u884c\u6240\u8c13\u8f6f\u5316. \u5bf9\u4e8e\u89e3\u51b3\u63a8\u7406\u95ee\u9898\u7684\u903b\u8f91\u4e0e\u524d\u9762\u4ecb\u7ecd\u7684\u57fa\u4e8e\u786e\u5b9a\u903b\u8f91\u63a8\u7406\u7684\u65b9\u6cd5\u5e76\u6ca1\u6709\u672c\u8d28\u7684\u533a\u522b. \u57fa\u4e8e\u6570\u503c\u8ba1\u7b97\u7684\u63a8\u7406 \u00b6 \u6240\u8c13\u57fa\u4e8e\u6570\u503c\u8ba1\u7b97\u7684\u77e5\u8bc6\u63a8\u7406, \u5c31\u662f\u5c06\u79bb\u6563\u7684\u5143\u7d20(\u5b9e\u4f53, \u5c5e\u6027, \u5173\u7cfb)\u7528\u4f4e\u7ef4\u7684\u5411\u91cf\u6765\u8868\u793a, \u901a\u8fc7\u5404\u79cd\u6709\u76d1\u7763\u6216\u8005\u65e0\u76d1\u7763\u7684\u65b9\u5f0f, \u5efa\u6a21\u548c\u5b66\u4e60\u4e0d\u540c\u5143\u7d20\u7684\u8868\u793a, \u4ece\u800c\u53ef\u4ee5\u6355\u6349\u5230\u5143\u7d20\u4e4b\u95f4\u7684\u9690\u6027\u5173\u8054. \u8fd9\u4e2a\u8fc7\u7a0b\u53ef\u4ee5\u548c\u8bcd\u5411\u91cf\u7684\u5b66\u4e60\u8fc7\u7a0b\u7c7b\u6bd4. \u6ce8\u610f: \u57fa\u4e8e\u6570\u503c\u8ba1\u7b97\u7684\u63a8\u7406\u662f\u4e00\u4e2a\u6bd4\u8f83\u65b0\u7684\u8bfe\u9898, \u662f\u76ee\u524d\u5b66\u672f\u754c\u7814\u7a76\u7684\u70ed\u70b9, \u6bcf\u5e74\u90fd\u4f1a\u6709\u5927\u91cf\u65b0\u7684\u6a21\u578b\u548c\u65b9\u6cd5\u88ab\u63d0\u51fa, \u611f\u5174\u8da3\u7684\u8bfb\u8005\u53ef\u4ee5\u641c\u7d22\"Knowledge Embedding\"\u8fdb\u4e00\u6b65\u4e86\u89e3. \u77e5\u8bc6\u56fe\u8c31\u662f\u4eba\u5de5\u667a\u80fd\u6280\u672f\u6700\u91cd\u8981\u7684\u57fa\u7840\u8bbe\u65bd, \u662f\u8ba1\u7b97\u673a\u80fd\u591f\u5b9e\u73b0\u63a8\u7406, \u9884\u6d4b\u7b49\u7c7b\u4f3c\u4eba\u7c7b\u601d\u8003\u80fd\u529b\u7684\u5173\u952e. \u5173\u952e: \u77e5\u8bc6\u63a8\u7406\u662f\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u4e00\u5927\u96be\u70b9, \u76ee\u524d\u7684\u7814\u7a76\u70ed\u70b9\u5728\u4e8e\u57fa\u4e8e\u6570\u503c\u8ba1\u7b97\u7684\u77e5\u8bc6\u63a8\u7406, \u8fc7\u7a0b\u5e94\u7528\u6bd4\u8f83\u591a\u7684\u8fd8\u662f\u57fa\u4e8e\u786e\u5b9a\u903b\u8f91\u7684\u63a8\u7406\u6784\u5efa\u7684\u63a8\u7406\u7cfb\u7edf. \u63a8\u7406\u4efb\u52a1 \u00b6 \u77e5\u8bc6\u8865\u5168 \u00b6 \u9762\u5411\u77e5\u8bc6\u5e93\u6216\u8005\u77e5\u8bc6\u56fe\u8c31\u7684\u4e8b\u5b9e\u8865\u5168, \u5982\u56fe\u8c31\u4e2d\u7ed9\u51fa\u4e86\u51fa\u751f\u5730\u4f46\u6ca1\u6709\u56fd\u7c4d, \u5373\u53ef\u4ee5\u901a\u8fc7\u63a8\u7406\u7684\u65b9\u6cd5\u628a\u5b9e\u4f53\u6216\u5173\u7cfb\u9884\u6d4b\u51fa\u6765, \u79f0\u4e3a\u94fe\u63a5\u9884\u6d4b. \u5b83\u662f\u5229\u7528\u5df2\u77e5\u77e5\u8bc6\u9884\u6d4b\u672a\u77e5\u7684\u9690\u542b\u77e5\u8bc6, \u6709\u5229\u4e8e\u5b8c\u5584\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31. \u4e09\u5143\u7ec4\u5206\u7c7b: \u5224\u65ad\u4e09\u5143\u7ec4\u662f\u5426\u6b63\u786e, \u9996\u90fd(\u5317\u4eac, \u4e2d\u56fd)\u662f\u6b63\u4f8b, \u9996\u90fd(\u6210\u90fd, \u4e2d\u56fd)\u662f\u8d1f\u4f8b. \u4e8c\u5206\u7c7b\u95ee\u9898. \u6a21\u578b\u7684\u9884\u6d4b\u8fc7\u7a0b\u662f\u53ef\u4ee5\u9009\u53d6\u4e00\u6761\u8fb9, \u8fde\u63a5\u4efb\u610f\u4e24\u4e2a\u5b9e\u4f53, \u6784\u6210\u65b0\u7684\u4e09\u5143\u7ec4, \u5224\u65ad\u8fd9\u4e2a\u4e09\u5143\u7ec4\u662f\u5426\u6b63\u786e. \u94fe\u63a5\u9884\u6d4b: \u9884\u6d4b\u4e09\u5143\u7ec4\u7684\u5934\u5b9e\u4f53\u6216\u5c3e\u5b9e\u4f53, \u80fd\u6210\u529f\u9884\u6d4b\u51fa\u6765, \u5219\u6dfb\u52a0\u65b0\u7684\u5173\u7cfb\u8fb9. \u77e5\u8bc6\u95ee\u7b54 \u00b6 \u7b80\u5355\u63a8\u7406: \u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u56fe\u8c31\u4e0a\u4e09\u5143\u7ec4\u7684\u67e5\u8be2\u6216\u8005\u4e09\u5143\u7ec4\u5e8f\u7684\u67e5\u8be2. \u5bf9\u4e8e\u7f3a\u5931\u7684\u9700\u8981\u4f7f\u7528\u63a8\u7406, \u4f8b\u5982\u5510\u671d\u5f00\u56fd\u7687\u5e1d\u662f\u8c01, \u82e5(\u5510\u671d, \u5f00\u56fd\u7687\u5e1d, \u674e\u6e0a)\u662f\u7f3a\u5931\u7684, \u901a\u8fc7\u524d\u6587\u7684\u94fe\u63a5\u9884\u6d4b(\u5510\u671d, \u5f00\u56fd\u7687\u5e1d, X). \u82e5\u95ee\u5f00\u56fd\u7687\u5e1d\u7684\u7236\u4eb2\u662f\u8c01, \u63a8\u7406(\u5510\u671d, \u5f00\u56fd\u7687\u5e1d, \u674e\u6e0a), \u518d\u5bf9(\u674e\u6e0a, \u7236\u4eb2, X)\u8fdb\u884c\u67e5\u8be2\u548c\u63a8\u7406. \u590d\u6742\u63a8\u7406: \u8868\u793a\u6210\u591a\u4e2a\u94fe\u63a5\u7ec4\u6210\u7684\u975e\u94fe\u5f0f\u6216\u6709\u5d4c\u5957\u7684\u590d\u6742\u7ed3\u6784\u65f6\u9700\u8981\u63a8\u7406. \u4f8b\u5982, \u6843\u82b1\u5f00\u82b1\u540e\u7ed3\u679c, \u95ee\u5f00\u82b1\u7684\u76ee\u7684\u662f\u4ec0\u4e48? \u7b54\u6848\u662f\u5438\u5f15\u871c\u8702\u91c7\u871c, \u5c31\u662f\u4e00\u4e2a\u590d\u6742\u63a8\u7406\u95ee\u9898. \u5f52\u7eb3\u4e0e\u6f14\u7ece\u63a8\u7406 \u00b6 \u5f52\u7eb3\u63a8\u7406: \u4ece\u7279\u6b8a\u5230\u4e00\u822c\u7684\u8fc7\u7a0b. \u6839\u636e\u90e8\u5206\u5bf9\u8c61\u5177\u6709\u7684\u6027\u8d28, \u63a8\u51fa\u4e00\u7c7b\u4e8b\u7269\u4e2d\u6240\u6709\u5bf9\u8c61\u90fd\u5177\u6709\u7684\u8fd9\u7c7b\u6027\u8d28\u7684\u63a8\u7406\u65b9\u5f0f. \u4f8b\u5982(\u84dd\u9cb8, \u53ef\u4ee5\u55b7\u5c04, \u6c34\u67f1), \u4e14\u6709(\u62b9\u9999\u9cb8, \u53ef\u4ee5\u55b7\u5c04, \u6c34\u67f1), \u89c2\u5bdf\u6574\u7406\u51fa\u89c4\u5219: (xx\u9cb8, \u53ef\u4ee5\u55b7\u5c04, \u6c34\u67f1). \u4f8b\u5982, \u5df2\u77e5\u4e09\u5143\u7ec4(\u9f7f\u9cb8, \u662f\u4e00\u79cd, \u9cb8\u9c7c), \u7ed3\u5408\u521a\u521a\u5f97\u5230\u7684\u89c4\u5219(xx\u9cb8, \u53ef\u4ee5\u55b7\u5c04, \u6c34\u67f1), \u5f97\u5230(\u9f7f\u9cb8, \u53ef\u4ee5\u55b7\u5c04, \u6c34\u67f1). \u6f14\u7ece\u63a8\u7406: \u4ece\u4e00\u822c\u5230\u7279\u6b8a, P1=\"\u864e\u9cb8\u80cc\u90e8\u6709\u80cc\u9ccd\", P2=\"\u80cc\u90e8\u6709\u80cc\u9ccd\u7684\u9cb8\u9c7c\u90fd\u5c5e\u4e8e\u6d77\u8c5a\u79d1\", \u7ed3\u8bba\"\u864e\u9cb8\u5c5e\u4e8e\u6d77\u8c5a\u79d1\". \u4e0d\u786e\u5b9a\u6027\u63a8\u7406 \u00b6 \u4e0d\u786e\u5b9a\u6027\u63a8\u7406: \u6839\u636e\u4ee5\u5f80\u7684\u7ecf\u9a8c\u548c\u5206\u6790, \u7ed3\u5408\u4e13\u5bb6\u5148\u9a8c\u77e5\u8bc6\u6784\u5efa\u6982\u7387\u6a21\u578b, \u5e76\u5229\u7528\u7edf\u8ba1\u8ba1\u6570, \u6700\u5927\u5316\u540e\u9a8c\u6982\u7387\u7b49\u7edf\u8ba1\u5b66\u4e60\u7684\u624b\u6bb5\u5bf9\u63a8\u7406\u5047\u8bbe\u8fdb\u884c\u9a8c\u8bc1\u6216\u63a8\u6d4b. \u6982\u7387\u56fe\u6a21\u578b: \u6709\u5411\u56fe\u7684\u8d1d\u53f6\u65af\u7f51\u7edc\u4ee5\u53ca\u65e0\u5411\u56fe\u7684\u9a6c\u5c14\u79d1\u592b\u7f51\u7edc. \u6982\u7387\u56fe\u6a21\u578b\u672c\u8eab\u662fNP\u56f0\u96be\u95ee\u9898, \u4e3b\u8981\u7684\u6539\u8fdb\u6709: \u57fa\u4e8e\u548c\u79ef\u53d8\u91cf\u6d88\u9664\u7684\u65b9\u6cd5, \u901a\u8fc7\u5bf9\u4e00\u4e2a\u53d8\u91cf\u6c42\u548c, \u5e76\u548c\u5176\u4ed6\u56e0\u5b50\u76f8\u4e58\u4ee5\u6d88\u9664\u53d8\u91cf. \u7b80\u5316\u57fa\u4e8e\u6982\u7387\u56fe\u7ed3\u6784\u7684\u7f6e\u4fe1\u4f20\u64ad\u6216\u671f\u671b\u4f20\u64ad\u7684\u65b9\u6cd5, \u5c06\u539f\u6709\u7684\u63a8\u7406\u95ee\u9898\u8f6c\u4e3a\u4f18\u5316\u95ee\u9898, \u4f18\u5316 \u7684\u65b9\u5f0f\u5305\u62ec\u8bbe\u8ba1\u597d\u7684\u80fd\u529b\u51fd\u6570\u6216\u52bf\u51fd\u6570\u6c42\u89e3\u6982\u7387\u6700\u5927\u4ee5\u8fbe\u5230\u63a8\u7406\u7684\u76ee\u7684, \u4ece\u6240\u6709\u5b9e\u4f8b\u51fa\u53d1, \u5bf9\u5176\u8fdb\u884c\u7edf\u8ba1\u6216\u91c7\u6837\u4ee5\u4f30\u8ba1\u63a8\u7406\u76ee\u6807\u6982\u7387, \u5982\u8499\u7279\u5361\u6d1b\u91c7\u6837\u7b49. \u7f3a\u70b9\u662f\u53ea\u5bf9\u5177\u6709\u76f4\u63a5\u6982\u7387\u4f9d\u8d56\u7684\u5b9e\u4f8b\u7ea7\u5143\u7d20, \u5e76\u6ca1\u6709\u5bf9\u66f4\u9ad8\u5c42\u6b21\u7684\u8bed\u4e49\u6846\u67b6\u8fdb\u884c\u62bd\u8c61, \u4f46\u9700\u8981\u5927\u91cf\u7684\u91cd\u590d\u7684\u6982\u7387\u4f9d\u8d56\u5173\u7cfb, \u9700\u8981\u5927\u91cf\u8ba1\u7b97. \u6982\u7387\u903b\u8f91\u63a8\u7406: \u5f25\u8865\u4e86\u6982\u7387\u56fe\u6a21\u578b\u4e2d\u7f3a\u4e4f\u53ef\u590d\u7528\u89c4\u5219\u7684\u7279\u70b9. \u7ed3\u6784\u5b66\u4e60\u53c8\u53ef\u4ee5\u79f0\u4e3a\u6982\u7387\u903b\u8f91\u63a8\u7406\u6a21\u578b\u4e0b\u7684\u89c4\u5219\u81ea\u52a8\u6316\u6398, \u7528\u8fed\u4ee3\u5c40\u90e8\u641c\u7d22\u4ee3\u66ff\u5168\u5c40\u641c\u7d22. \u5173\u8054\u89c4\u5219\u6316\u6398: \u8def\u5f84\u6392\u5e8f\u7b97\u6cd5\u662f\u57fa\u4e8e\u56fe\u6a21\u578b\u4e0a\u968f\u673a\u6e38\u8d70\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5, \u901a\u8fc7\u679a\u4e3e\u6216\u62bd\u6837\u56fe\u4e0a\u7684\u4e24\u4e2a\u8282\u70b9\u95f4\u7684\u8def\u5f84, \u9012\u5f52\u5730\u8ba1\u7b97\u4e24\u4e2a\u70b9\u95f4\u7684\u5230\u8fbe\u6982\u7387, \u5bf9\u6bcf\u4e2a\u8def\u5f84\u8fdb\u884c\u6253\u5206, \u6700\u7ec8\u5f97\u5230\u5173\u8054\u89c4\u5219. \u7ecf\u5178\u56fe\u7b97\u6cd5 \u00b6 \u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u7ecf\u5178\u56fe\u76f8\u5173\u7684\u7b97\u6cd5, \u4ece\u5e94\u7528\u7684\u89d2\u5ea6\u770b\u5206\u4e3a\u4e09\u7c7b: \u8def\u5f84\u67e5\u627e\u7b97\u6cd5 \u4e2d\u5fc3\u5ea6\u7b97\u6cd5 \u793e\u533a\u53d1\u73b0\u7b97\u6cd5 \u8def\u5f84\u67e5\u627e\u7b97\u6cd5 \u00b6 \u6700\u6838\u5fc3\u7684\u5c31\u662fDijkstra\u7b97\u6cd5, \u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u8d2a\u5fc3\u7b97\u6cd5, \u7528\u4e8e\u5728\u52a0\u6743\u7684\u56fe\u4e2d\u67e5\u627e\u6700\u77ed\u8def\u5f84. \u7b97\u6cd5\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(V*V), \u4ec5\u5f53\u6743\u503c\u4e3a\u6b63\u65f6\u6709\u6548. \u5c0f\u4f18\u5148\u961f\u5217\u5b9e\u73b0\u7248\u672c\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(E+VlogV). \u5f53\u6743\u91cd\u6709\u8d1f\u503c\u65f6, \u4f7f\u7528Bellman-Ford\u7b97\u6cd5. \u4e2d\u5fc3\u5ea6\u7b97\u6cd5 \u00b6 \u95ee\u9898\u5b9a\u4e49: \u5982\u4f55\u786e\u8ba4\u6d77\u91cf\u7f51\u7ad9\u7684\u6392\u540d? \u5982\u4f55\u8bc4\u4f30\u4e00\u4e2a\u4eba\u5728\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u5f71\u54cd\u529b\u6392\u540d? \u7ecf\u5178\u89e3\u51b3\u65b9\u6848: PageRank\u7b97\u6cd5. \u4e5f\u5c31\u662f\u8c37\u6b4c\u641c\u7d22\u7684\u4f69\u5947\u6392\u5e8f\u7b97\u6cd5, \u7528\u4ee5\u8bc4\u4f30\u7f51\u9875\u91cd\u8981\u5ea6\u7684\u7b97\u6cd5. \u793e\u533a\u53d1\u73b0\u7b97\u6cd5 \u00b6 LPA\u7b97\u6cd5\u662f\u4e00\u4e2a\u6781\u5176\u7b80\u5355\u7684\u56fe\u4f20\u64ad\u7b97\u6cd5, \u5176\u7ecf\u9a8c\u5047\u8bbe\u662f\u4ee5\u8282\u70b9\u4e3a\u4e2d\u5fc3, \u8fdb\u884c\u6295\u7968\u5236, \u5341\u5206\u9ad8\u6548. \u7b97\u6cd5\u6d41\u7a0b: 1: \u521d\u59cb\u5316, \u5c06\u56fe\u4e2d\u7684\u6bcf\u4e2a\u8282\u70b9\u770b\u6210\u4e00\u4e2a\u72ec\u7acb\u7684\u793e\u533a. 2: While \u6240\u6709\u8282\u70b9\u7684\u793e\u533a\u6807\u7b7e\u4e0d\u518d\u53d8\u5316: \u7edf\u8ba1\u6bcf\u4e2a\u8282\u70b9\u90bb\u5c45\u7684\u793e\u533a, \u5c06\u51fa\u73b0\u6700\u591a\u6b21\u7684\u793e\u533a\u8d4b\u503c\u7ed9\u8be5\u8282\u70b9; \u5982\u679c\u51fa\u73b0\u6700\u591a\u6b21\u7684\u793e\u533a\u6709\u591a\u4e2a, \u968f\u673a\u9009\u62e9\u4e00\u4e2a\u793e\u533a\u8d4b\u503c\u7ed9\u8be5\u8282\u70b9. \u6ce8\u610f: LPA\u7b97\u6cd5\u672c\u8eab\u5f88\u7b80\u5355, \u5206\u5e03\u5f0f\u5b9e\u73b0\u4e5f\u5f88\u5bb9\u6613. \u4f46\u662f\u8fd9\u4e2a\u7b97\u6cd5\u4e5f\u6709\u7f3a\u9677, \u7531\u4e8e\u5b58\u5728\u968f\u673a\u9009\u62e9\u7684\u60c5\u51b5, \u6240\u4ee5\u7b97\u6cd5\u5f88\u5bb9\u6613\u51fa\u73b0\u632f\u8361. \u4f46\u7b97\u6cd5\u7684\u8fd0\u884c\u5f00\u9500\u5f88\u4f4e, \u62ff\u6765\u505abaseline\u53c2\u8003\u975e\u5e38\u4e0d\u9519.","title":"9.1 \u5e38\u7528\u63a8\u7406\u65b9\u6cd5"},{"location":"9_1.html#_1","text":"","title":"\u77e5\u8bc6\u63a8\u7406\u65b9\u6cd5"},{"location":"9_1.html#_2","text":"\u4e86\u89e3\u77e5\u8bc6\u63a8\u7406\u7684\u6982\u5ff5. \u4e86\u89e3\u51e0\u79cd\u5e38\u89c1\u7684\u63a8\u7406\u65b9\u6cd5.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"9_1.html#_3","text":"\u4ee5\u6df1\u5ea6\u5b66\u4e60\u4e3a\u4ee3\u8868\u7684\u4eba\u5de5\u667a\u80fd, \u4ece\u672c\u8d28\u4e0a\u770b\u53ea\u662f\u4e00\u79cd\u6a21\u4eff\u795e\u7ecf\u5b66\u7684\u66f4\u4e3a\u590d\u6742\u7684\u6570\u5b66\u6a21\u578b. \u73b0\u5b9e\u4e2d\u4e00\u4e9b\u5bf9\u4eba\u7c7b\u6765\u8bf4\u5341\u5206\u7b80\u5355\u7684\u95ee\u9898, \u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5e38\u5e38\u9700\u8981\u5229\u7528\u6d77\u91cf\u7684\u6570\u636e\u8fdb\u884c\u5b66\u4e60\u624d\u80fd\u6709\u597d\u7684\u8868\u73b0. \u8fd9\u4e0e\u4eba\u7c7b\u7684\u5b66\u4e60\u6a21\u5f0f\u5dee\u5f02\u975e\u5e38\u4e4b\u5927, \u4eba\u7c7b\u5e38\u5e38\u81ea\u5df1\u603b\u7ed3, \u5f52\u7eb3, \u63a8\u7406\u548c\u4e3e\u4e00\u53cd\u4e09, \u4ece\u5c11\u91cf\u7684\u6837\u672c\u548c\u8bad\u7ec3\u4e2d, \u771f\u6b63\u4e60\u5f97\u4e00\u4e9b\u6280\u80fd. \u4f8b\u5982, \u6ca1\u6709\u4eba\u8981\u5148\u5f00\u4e2a\u51e0\u4e07\u516c\u91cc\u7684\u8f66\u624d\u80fd\u62ff\u5230\u9a7e\u7167. \u901a\u4fd7\u7684\u7406\u89e3, \u6240\u8c13\u63a8\u7406, \u5c31\u662f\u4ece\u73b0\u6709\u7684\u77e5\u8bc6\u51fa\u53d1, \u8fd0\u7528\u903b\u8f91\u601d\u7ef4\u80fd\u529b\u5f97\u51fa\u4e00\u4e9b\u9690\u6027\u7684\u7ed3\u8bba. \u5177\u4f53\u5230\u77e5\u8bc6\u56fe\u8c31\u4e2d, \u6240\u8c13\u7684\u77e5\u8bc6\u63a8\u7406, \u5c31\u662f\u5229\u7528\u56fe\u8c31\u4e2d\u73b0\u6709\u7684\u77e5\u8bc6(\u4e09\u5143\u7ec4), \u5f97\u5230\u4e00\u4e9b\u65b0\u7684\u5b9e\u4f53\u95f4\u7684\u5173\u7cfb\u6216\u8005\u5b9e\u4f53\u7684\u5c5e\u6027(\u4e09\u5143\u7ec4). \u4f8b\u5982, \u77e5\u8bc6\u56fe\u8c31\u4e2d\u6709\u8fd9\u6837\u4e24\u4e2a\u4e09\u5143\u7ec4, (\u5468\u6770\u4f26, \u8001\u5a46, \u6606\u51cc)\u548c(\u5468\u6770\u4f26, \u5988\u5988, \u53f6\u60e0\u7f8e), \u901a\u8fc7\u77e5\u8bc6\u63a8\u7406, \u53ef\u4ee5\u5f97\u5230(\u6606\u51cc, \u5a46\u5a46, \u53f6\u60e0\u7f8e).","title":"\u77e5\u8bc6\u63a8\u7406\u6982\u5ff5"},{"location":"9_1.html#_4","text":"\u90a3\u4e48, \u5982\u4f55\u4ece\u73b0\u6709\u7684\u77e5\u8bc6\u4e2d, \u63a8\u7406\u51fa\u6765\u65b0\u7684\u77e5\u8bc6\u548c\u7ed3\u8bba\u5462? \u53ef\u4ee5\u9884\u5148\u5b9a\u4e49\u597d\u51c6\u786e\u7684\u63a8\u7406\u89c4\u5219, \u7136\u540e\u57fa\u4e8e\u8fd9\u4e9b\u89c4\u5219\u548c\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5df2\u6709\u7684\u77e5\u8bc6\u63a8\u5bfc\u51fa\u65b0\u7684\u7ed3\u8bba\u548c\u77e5\u8bc6. \u4f8b\u5982, \u9884\u5148\u5b9a\u4e49\u597d\u8fd9\u6837\u7684\u89c4\u5219 (\u5b9e\u4f531:\u8001\u5a46:\u5b9e\u4f532; \u5b9e\u4f531:\u5988\u5988:\u5b9e\u4f533 -> \u5b9e\u4f532:\u5a46\u5a46:\u5b9e\u4f533) \u8fdb\u4e00\u6b65\u7ec6\u60f3, \u4f1a\u89c9\u5f97\u8fd9\u6837\u7684\u65b9\u5f0f\u6548\u7387\u592a\u4f4e. \u56e0\u6b64, \u57fa\u4e8e\u903b\u8f91\u63a8\u7406\u81f4\u529b\u4e8e\u5982\u4f55\u81ea\u52a8\u63a8\u7406\u83b7\u53d6\u4e0a\u8ff0\u7684\u89c4\u5219, \u6bd4\u8f83\u6709\u540d\u7684\u5305\u62ec\u57fa\u4e8e\u53ef\u6ee1\u8db3\u6027\u7684GSAT\u548cWALKSAT, \u7528\u4e8e\u6c42\u89e3\u903b\u8f91\u63a8\u7406\u7684\u89c4\u5219. \u901a\u5e38\u6765\u8bf4, \u5728\u5de5\u7a0b\u9886\u57df\u4f1a\u5c06\u77e5\u8bc6\u63a8\u7406\u7cfb\u7edf\u4ece\u77e5\u8bc6\u4f53\u7cfb\u4e2d\u5355\u72ec\u5206\u79bb\u51fa\u6765, \u8fd9\u6837\u5c31\u53ef\u4ee5\u8ba9\u77e5\u8bc6\u4e13\u5bb6\u4e13\u6ce8\u4e8e\u77e5\u8bc6\u5efa\u8bbe, \u63a8\u7406\u89c4\u5219\u7531\u63a8\u7406\u7cfb\u7edf\u7684\u8bbe\u8ba1\u8005\u4e13\u95e8\u5efa\u7acb. \u76ee\u524d\u6bd4\u8f83\u6709\u540d\u7684\u63a8\u7406\u7cfb\u7edf\u6709ELK, DLV, Pellet\u7b49. \u57fa\u4e8e\u89c4\u5219\u7684\u903b\u8f91\u63a8\u7406\u7684\u4f18\u70b9\u5728\u4e8e\u51c6\u786e\u6027\u9ad8, \u63a8\u7406\u901f\u5ea6\u5feb; \u7f3a\u70b9\u5728\u4e8e\u80fd\u591f\u5904\u7406\u7684\u77e5\u8bc6\u6709\u9650, \u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u7684\u7f51\u7edc\u77e5\u8bc6\u56fe\u8c31, \u6709\u4e00\u5b9a\u6982\u7387\u83b7\u53d6\u5230\u4e0d\u51c6\u786e\u7684\u77e5\u8bc6\u548c\u4e8b\u5b9e, \u8fd9\u4e9b\u77e5\u8bc6\u57fa\u4e8e\u786e\u5b9a\u7684\u903b\u8f91\u63a8\u7406\u65e0\u6cd5\u5904\u7406, \u9700\u8981\u52a0\u5165\u7edf\u8ba1\u6216\u8005\u6982\u7387\u7684\u65b9\u5f0f\u5c06\u89c4\u5219\u8f6f\u5316.","title":"\u57fa\u4e8e\u89c4\u5219\u7684\u63a8\u7406"},{"location":"9_1.html#_5","text":"\u4e00\u65b9\u9762, \u73b0\u6709\u7684NLP\u6280\u672f\u8fd8\u5f88\u96be\u51c6\u786e\u7684\u5c06\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u6210\u786e\u5b9a\u6027\u7684\u63a8\u7406\u9700\u6c42; \u53e6\u4e00\u65b9\u9762, \u73b0\u5b9e\u4e16\u754c\u672c\u8eab\u7684\u4e0d\u786e\u5b9a\u6027, \u51b3\u5b9a\u4e86\u5f88\u591a\u95ee\u9898\u65e0\u6cd5\u4f7f\u7528\u786e\u5b9a\u6027\u7684\u63a8\u7406\u6280\u672f\u8fdb\u884c\u56de\u7b54. \u57fa\u4e8e\u6982\u7387\u6a21\u578b\u7684\u63a8\u7406\u5e76\u4e0d\u662f\u4e25\u683c\u7684\u6309\u7167\u89c4\u5219\u8fdb\u884c\u63a8\u7406, \u800c\u662f\u6839\u636e\u4ee5\u5f80\u7684\u7ecf\u9a8c\u548c\u5206\u6790, \u7ed3\u5408\u4e13\u5bb6\u5148\u9a8c\u77e5\u8bc6\u6784\u5efa\u6982\u7387\u6a21\u578b, \u5e76\u5229\u7528\u7edf\u8ba1\u8ba1\u6570, \u6700\u5927\u5316\u540e\u9a8c\u6982\u7387\u7b49\u7edf\u8ba1\u5b66\u7684\u624b\u6bb5\u5bf9\u63a8\u7406\u5047\u8bbe\u8fdb\u884c\u9a8c\u8bc1\u6216\u8005\u63a8\u6d4b. \u603b\u7684\u6765\u8bf4, \u57fa\u4e8e\u6982\u7387\u7684\u6a21\u578b\u63a8\u7406, \u5c31\u662f\u4e13\u5bb6\u57fa\u4e8e\u73b0\u6709\u7684\u5148\u9a8c\u77e5\u8bc6, \u5efa\u7acb\u76f8\u5173\u7684\u89c4\u5219\u6982\u7387\u6a21\u578b\u5bf9\u786e\u5b9a\u7684\u89c4\u5219\u8fdb\u884c\u6240\u8c13\u8f6f\u5316. \u5bf9\u4e8e\u89e3\u51b3\u63a8\u7406\u95ee\u9898\u7684\u903b\u8f91\u4e0e\u524d\u9762\u4ecb\u7ecd\u7684\u57fa\u4e8e\u786e\u5b9a\u903b\u8f91\u63a8\u7406\u7684\u65b9\u6cd5\u5e76\u6ca1\u6709\u672c\u8d28\u7684\u533a\u522b.","title":"\u57fa\u4e8e\u6982\u7387\u56fe\u7684\u63a8\u7406"},{"location":"9_1.html#_6","text":"\u6240\u8c13\u57fa\u4e8e\u6570\u503c\u8ba1\u7b97\u7684\u77e5\u8bc6\u63a8\u7406, \u5c31\u662f\u5c06\u79bb\u6563\u7684\u5143\u7d20(\u5b9e\u4f53, \u5c5e\u6027, \u5173\u7cfb)\u7528\u4f4e\u7ef4\u7684\u5411\u91cf\u6765\u8868\u793a, \u901a\u8fc7\u5404\u79cd\u6709\u76d1\u7763\u6216\u8005\u65e0\u76d1\u7763\u7684\u65b9\u5f0f, \u5efa\u6a21\u548c\u5b66\u4e60\u4e0d\u540c\u5143\u7d20\u7684\u8868\u793a, \u4ece\u800c\u53ef\u4ee5\u6355\u6349\u5230\u5143\u7d20\u4e4b\u95f4\u7684\u9690\u6027\u5173\u8054. \u8fd9\u4e2a\u8fc7\u7a0b\u53ef\u4ee5\u548c\u8bcd\u5411\u91cf\u7684\u5b66\u4e60\u8fc7\u7a0b\u7c7b\u6bd4. \u6ce8\u610f: \u57fa\u4e8e\u6570\u503c\u8ba1\u7b97\u7684\u63a8\u7406\u662f\u4e00\u4e2a\u6bd4\u8f83\u65b0\u7684\u8bfe\u9898, \u662f\u76ee\u524d\u5b66\u672f\u754c\u7814\u7a76\u7684\u70ed\u70b9, \u6bcf\u5e74\u90fd\u4f1a\u6709\u5927\u91cf\u65b0\u7684\u6a21\u578b\u548c\u65b9\u6cd5\u88ab\u63d0\u51fa, \u611f\u5174\u8da3\u7684\u8bfb\u8005\u53ef\u4ee5\u641c\u7d22\"Knowledge Embedding\"\u8fdb\u4e00\u6b65\u4e86\u89e3. \u77e5\u8bc6\u56fe\u8c31\u662f\u4eba\u5de5\u667a\u80fd\u6280\u672f\u6700\u91cd\u8981\u7684\u57fa\u7840\u8bbe\u65bd, \u662f\u8ba1\u7b97\u673a\u80fd\u591f\u5b9e\u73b0\u63a8\u7406, \u9884\u6d4b\u7b49\u7c7b\u4f3c\u4eba\u7c7b\u601d\u8003\u80fd\u529b\u7684\u5173\u952e. \u5173\u952e: \u77e5\u8bc6\u63a8\u7406\u662f\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u4e00\u5927\u96be\u70b9, \u76ee\u524d\u7684\u7814\u7a76\u70ed\u70b9\u5728\u4e8e\u57fa\u4e8e\u6570\u503c\u8ba1\u7b97\u7684\u77e5\u8bc6\u63a8\u7406, \u8fc7\u7a0b\u5e94\u7528\u6bd4\u8f83\u591a\u7684\u8fd8\u662f\u57fa\u4e8e\u786e\u5b9a\u903b\u8f91\u7684\u63a8\u7406\u6784\u5efa\u7684\u63a8\u7406\u7cfb\u7edf.","title":"\u57fa\u4e8e\u6570\u503c\u8ba1\u7b97\u7684\u63a8\u7406"},{"location":"9_1.html#_7","text":"","title":"\u63a8\u7406\u4efb\u52a1"},{"location":"9_1.html#_8","text":"\u9762\u5411\u77e5\u8bc6\u5e93\u6216\u8005\u77e5\u8bc6\u56fe\u8c31\u7684\u4e8b\u5b9e\u8865\u5168, \u5982\u56fe\u8c31\u4e2d\u7ed9\u51fa\u4e86\u51fa\u751f\u5730\u4f46\u6ca1\u6709\u56fd\u7c4d, \u5373\u53ef\u4ee5\u901a\u8fc7\u63a8\u7406\u7684\u65b9\u6cd5\u628a\u5b9e\u4f53\u6216\u5173\u7cfb\u9884\u6d4b\u51fa\u6765, \u79f0\u4e3a\u94fe\u63a5\u9884\u6d4b. \u5b83\u662f\u5229\u7528\u5df2\u77e5\u77e5\u8bc6\u9884\u6d4b\u672a\u77e5\u7684\u9690\u542b\u77e5\u8bc6, \u6709\u5229\u4e8e\u5b8c\u5584\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31. \u4e09\u5143\u7ec4\u5206\u7c7b: \u5224\u65ad\u4e09\u5143\u7ec4\u662f\u5426\u6b63\u786e, \u9996\u90fd(\u5317\u4eac, \u4e2d\u56fd)\u662f\u6b63\u4f8b, \u9996\u90fd(\u6210\u90fd, \u4e2d\u56fd)\u662f\u8d1f\u4f8b. \u4e8c\u5206\u7c7b\u95ee\u9898. \u6a21\u578b\u7684\u9884\u6d4b\u8fc7\u7a0b\u662f\u53ef\u4ee5\u9009\u53d6\u4e00\u6761\u8fb9, \u8fde\u63a5\u4efb\u610f\u4e24\u4e2a\u5b9e\u4f53, \u6784\u6210\u65b0\u7684\u4e09\u5143\u7ec4, \u5224\u65ad\u8fd9\u4e2a\u4e09\u5143\u7ec4\u662f\u5426\u6b63\u786e. \u94fe\u63a5\u9884\u6d4b: \u9884\u6d4b\u4e09\u5143\u7ec4\u7684\u5934\u5b9e\u4f53\u6216\u5c3e\u5b9e\u4f53, \u80fd\u6210\u529f\u9884\u6d4b\u51fa\u6765, \u5219\u6dfb\u52a0\u65b0\u7684\u5173\u7cfb\u8fb9.","title":"\u77e5\u8bc6\u8865\u5168"},{"location":"9_1.html#_9","text":"\u7b80\u5355\u63a8\u7406: \u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u56fe\u8c31\u4e0a\u4e09\u5143\u7ec4\u7684\u67e5\u8be2\u6216\u8005\u4e09\u5143\u7ec4\u5e8f\u7684\u67e5\u8be2. \u5bf9\u4e8e\u7f3a\u5931\u7684\u9700\u8981\u4f7f\u7528\u63a8\u7406, \u4f8b\u5982\u5510\u671d\u5f00\u56fd\u7687\u5e1d\u662f\u8c01, \u82e5(\u5510\u671d, \u5f00\u56fd\u7687\u5e1d, \u674e\u6e0a)\u662f\u7f3a\u5931\u7684, \u901a\u8fc7\u524d\u6587\u7684\u94fe\u63a5\u9884\u6d4b(\u5510\u671d, \u5f00\u56fd\u7687\u5e1d, X). \u82e5\u95ee\u5f00\u56fd\u7687\u5e1d\u7684\u7236\u4eb2\u662f\u8c01, \u63a8\u7406(\u5510\u671d, \u5f00\u56fd\u7687\u5e1d, \u674e\u6e0a), \u518d\u5bf9(\u674e\u6e0a, \u7236\u4eb2, X)\u8fdb\u884c\u67e5\u8be2\u548c\u63a8\u7406. \u590d\u6742\u63a8\u7406: \u8868\u793a\u6210\u591a\u4e2a\u94fe\u63a5\u7ec4\u6210\u7684\u975e\u94fe\u5f0f\u6216\u6709\u5d4c\u5957\u7684\u590d\u6742\u7ed3\u6784\u65f6\u9700\u8981\u63a8\u7406. \u4f8b\u5982, \u6843\u82b1\u5f00\u82b1\u540e\u7ed3\u679c, \u95ee\u5f00\u82b1\u7684\u76ee\u7684\u662f\u4ec0\u4e48? \u7b54\u6848\u662f\u5438\u5f15\u871c\u8702\u91c7\u871c, \u5c31\u662f\u4e00\u4e2a\u590d\u6742\u63a8\u7406\u95ee\u9898.","title":"\u77e5\u8bc6\u95ee\u7b54"},{"location":"9_1.html#_10","text":"\u5f52\u7eb3\u63a8\u7406: \u4ece\u7279\u6b8a\u5230\u4e00\u822c\u7684\u8fc7\u7a0b. \u6839\u636e\u90e8\u5206\u5bf9\u8c61\u5177\u6709\u7684\u6027\u8d28, \u63a8\u51fa\u4e00\u7c7b\u4e8b\u7269\u4e2d\u6240\u6709\u5bf9\u8c61\u90fd\u5177\u6709\u7684\u8fd9\u7c7b\u6027\u8d28\u7684\u63a8\u7406\u65b9\u5f0f. \u4f8b\u5982(\u84dd\u9cb8, \u53ef\u4ee5\u55b7\u5c04, \u6c34\u67f1), \u4e14\u6709(\u62b9\u9999\u9cb8, \u53ef\u4ee5\u55b7\u5c04, \u6c34\u67f1), \u89c2\u5bdf\u6574\u7406\u51fa\u89c4\u5219: (xx\u9cb8, \u53ef\u4ee5\u55b7\u5c04, \u6c34\u67f1). \u4f8b\u5982, \u5df2\u77e5\u4e09\u5143\u7ec4(\u9f7f\u9cb8, \u662f\u4e00\u79cd, \u9cb8\u9c7c), \u7ed3\u5408\u521a\u521a\u5f97\u5230\u7684\u89c4\u5219(xx\u9cb8, \u53ef\u4ee5\u55b7\u5c04, \u6c34\u67f1), \u5f97\u5230(\u9f7f\u9cb8, \u53ef\u4ee5\u55b7\u5c04, \u6c34\u67f1). \u6f14\u7ece\u63a8\u7406: \u4ece\u4e00\u822c\u5230\u7279\u6b8a, P1=\"\u864e\u9cb8\u80cc\u90e8\u6709\u80cc\u9ccd\", P2=\"\u80cc\u90e8\u6709\u80cc\u9ccd\u7684\u9cb8\u9c7c\u90fd\u5c5e\u4e8e\u6d77\u8c5a\u79d1\", \u7ed3\u8bba\"\u864e\u9cb8\u5c5e\u4e8e\u6d77\u8c5a\u79d1\".","title":"\u5f52\u7eb3\u4e0e\u6f14\u7ece\u63a8\u7406"},{"location":"9_1.html#_11","text":"\u4e0d\u786e\u5b9a\u6027\u63a8\u7406: \u6839\u636e\u4ee5\u5f80\u7684\u7ecf\u9a8c\u548c\u5206\u6790, \u7ed3\u5408\u4e13\u5bb6\u5148\u9a8c\u77e5\u8bc6\u6784\u5efa\u6982\u7387\u6a21\u578b, \u5e76\u5229\u7528\u7edf\u8ba1\u8ba1\u6570, \u6700\u5927\u5316\u540e\u9a8c\u6982\u7387\u7b49\u7edf\u8ba1\u5b66\u4e60\u7684\u624b\u6bb5\u5bf9\u63a8\u7406\u5047\u8bbe\u8fdb\u884c\u9a8c\u8bc1\u6216\u63a8\u6d4b. \u6982\u7387\u56fe\u6a21\u578b: \u6709\u5411\u56fe\u7684\u8d1d\u53f6\u65af\u7f51\u7edc\u4ee5\u53ca\u65e0\u5411\u56fe\u7684\u9a6c\u5c14\u79d1\u592b\u7f51\u7edc. \u6982\u7387\u56fe\u6a21\u578b\u672c\u8eab\u662fNP\u56f0\u96be\u95ee\u9898, \u4e3b\u8981\u7684\u6539\u8fdb\u6709: \u57fa\u4e8e\u548c\u79ef\u53d8\u91cf\u6d88\u9664\u7684\u65b9\u6cd5, \u901a\u8fc7\u5bf9\u4e00\u4e2a\u53d8\u91cf\u6c42\u548c, \u5e76\u548c\u5176\u4ed6\u56e0\u5b50\u76f8\u4e58\u4ee5\u6d88\u9664\u53d8\u91cf. \u7b80\u5316\u57fa\u4e8e\u6982\u7387\u56fe\u7ed3\u6784\u7684\u7f6e\u4fe1\u4f20\u64ad\u6216\u671f\u671b\u4f20\u64ad\u7684\u65b9\u6cd5, \u5c06\u539f\u6709\u7684\u63a8\u7406\u95ee\u9898\u8f6c\u4e3a\u4f18\u5316\u95ee\u9898, \u4f18\u5316 \u7684\u65b9\u5f0f\u5305\u62ec\u8bbe\u8ba1\u597d\u7684\u80fd\u529b\u51fd\u6570\u6216\u52bf\u51fd\u6570\u6c42\u89e3\u6982\u7387\u6700\u5927\u4ee5\u8fbe\u5230\u63a8\u7406\u7684\u76ee\u7684, \u4ece\u6240\u6709\u5b9e\u4f8b\u51fa\u53d1, \u5bf9\u5176\u8fdb\u884c\u7edf\u8ba1\u6216\u91c7\u6837\u4ee5\u4f30\u8ba1\u63a8\u7406\u76ee\u6807\u6982\u7387, \u5982\u8499\u7279\u5361\u6d1b\u91c7\u6837\u7b49. \u7f3a\u70b9\u662f\u53ea\u5bf9\u5177\u6709\u76f4\u63a5\u6982\u7387\u4f9d\u8d56\u7684\u5b9e\u4f8b\u7ea7\u5143\u7d20, \u5e76\u6ca1\u6709\u5bf9\u66f4\u9ad8\u5c42\u6b21\u7684\u8bed\u4e49\u6846\u67b6\u8fdb\u884c\u62bd\u8c61, \u4f46\u9700\u8981\u5927\u91cf\u7684\u91cd\u590d\u7684\u6982\u7387\u4f9d\u8d56\u5173\u7cfb, \u9700\u8981\u5927\u91cf\u8ba1\u7b97. \u6982\u7387\u903b\u8f91\u63a8\u7406: \u5f25\u8865\u4e86\u6982\u7387\u56fe\u6a21\u578b\u4e2d\u7f3a\u4e4f\u53ef\u590d\u7528\u89c4\u5219\u7684\u7279\u70b9. \u7ed3\u6784\u5b66\u4e60\u53c8\u53ef\u4ee5\u79f0\u4e3a\u6982\u7387\u903b\u8f91\u63a8\u7406\u6a21\u578b\u4e0b\u7684\u89c4\u5219\u81ea\u52a8\u6316\u6398, \u7528\u8fed\u4ee3\u5c40\u90e8\u641c\u7d22\u4ee3\u66ff\u5168\u5c40\u641c\u7d22. \u5173\u8054\u89c4\u5219\u6316\u6398: \u8def\u5f84\u6392\u5e8f\u7b97\u6cd5\u662f\u57fa\u4e8e\u56fe\u6a21\u578b\u4e0a\u968f\u673a\u6e38\u8d70\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5, \u901a\u8fc7\u679a\u4e3e\u6216\u62bd\u6837\u56fe\u4e0a\u7684\u4e24\u4e2a\u8282\u70b9\u95f4\u7684\u8def\u5f84, \u9012\u5f52\u5730\u8ba1\u7b97\u4e24\u4e2a\u70b9\u95f4\u7684\u5230\u8fbe\u6982\u7387, \u5bf9\u6bcf\u4e2a\u8def\u5f84\u8fdb\u884c\u6253\u5206, \u6700\u7ec8\u5f97\u5230\u5173\u8054\u89c4\u5219.","title":"\u4e0d\u786e\u5b9a\u6027\u63a8\u7406"},{"location":"9_1.html#_12","text":"\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u7ecf\u5178\u56fe\u76f8\u5173\u7684\u7b97\u6cd5, \u4ece\u5e94\u7528\u7684\u89d2\u5ea6\u770b\u5206\u4e3a\u4e09\u7c7b: \u8def\u5f84\u67e5\u627e\u7b97\u6cd5 \u4e2d\u5fc3\u5ea6\u7b97\u6cd5 \u793e\u533a\u53d1\u73b0\u7b97\u6cd5","title":"\u7ecf\u5178\u56fe\u7b97\u6cd5"},{"location":"9_1.html#_13","text":"\u6700\u6838\u5fc3\u7684\u5c31\u662fDijkstra\u7b97\u6cd5, \u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u8d2a\u5fc3\u7b97\u6cd5, \u7528\u4e8e\u5728\u52a0\u6743\u7684\u56fe\u4e2d\u67e5\u627e\u6700\u77ed\u8def\u5f84. \u7b97\u6cd5\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(V*V), \u4ec5\u5f53\u6743\u503c\u4e3a\u6b63\u65f6\u6709\u6548. \u5c0f\u4f18\u5148\u961f\u5217\u5b9e\u73b0\u7248\u672c\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(E+VlogV). \u5f53\u6743\u91cd\u6709\u8d1f\u503c\u65f6, \u4f7f\u7528Bellman-Ford\u7b97\u6cd5.","title":"\u8def\u5f84\u67e5\u627e\u7b97\u6cd5"},{"location":"9_1.html#_14","text":"\u95ee\u9898\u5b9a\u4e49: \u5982\u4f55\u786e\u8ba4\u6d77\u91cf\u7f51\u7ad9\u7684\u6392\u540d? \u5982\u4f55\u8bc4\u4f30\u4e00\u4e2a\u4eba\u5728\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u5f71\u54cd\u529b\u6392\u540d? \u7ecf\u5178\u89e3\u51b3\u65b9\u6848: PageRank\u7b97\u6cd5. \u4e5f\u5c31\u662f\u8c37\u6b4c\u641c\u7d22\u7684\u4f69\u5947\u6392\u5e8f\u7b97\u6cd5, \u7528\u4ee5\u8bc4\u4f30\u7f51\u9875\u91cd\u8981\u5ea6\u7684\u7b97\u6cd5.","title":"\u4e2d\u5fc3\u5ea6\u7b97\u6cd5"},{"location":"9_1.html#_15","text":"LPA\u7b97\u6cd5\u662f\u4e00\u4e2a\u6781\u5176\u7b80\u5355\u7684\u56fe\u4f20\u64ad\u7b97\u6cd5, \u5176\u7ecf\u9a8c\u5047\u8bbe\u662f\u4ee5\u8282\u70b9\u4e3a\u4e2d\u5fc3, \u8fdb\u884c\u6295\u7968\u5236, \u5341\u5206\u9ad8\u6548. \u7b97\u6cd5\u6d41\u7a0b: 1: \u521d\u59cb\u5316, \u5c06\u56fe\u4e2d\u7684\u6bcf\u4e2a\u8282\u70b9\u770b\u6210\u4e00\u4e2a\u72ec\u7acb\u7684\u793e\u533a. 2: While \u6240\u6709\u8282\u70b9\u7684\u793e\u533a\u6807\u7b7e\u4e0d\u518d\u53d8\u5316: \u7edf\u8ba1\u6bcf\u4e2a\u8282\u70b9\u90bb\u5c45\u7684\u793e\u533a, \u5c06\u51fa\u73b0\u6700\u591a\u6b21\u7684\u793e\u533a\u8d4b\u503c\u7ed9\u8be5\u8282\u70b9; \u5982\u679c\u51fa\u73b0\u6700\u591a\u6b21\u7684\u793e\u533a\u6709\u591a\u4e2a, \u968f\u673a\u9009\u62e9\u4e00\u4e2a\u793e\u533a\u8d4b\u503c\u7ed9\u8be5\u8282\u70b9. \u6ce8\u610f: LPA\u7b97\u6cd5\u672c\u8eab\u5f88\u7b80\u5355, \u5206\u5e03\u5f0f\u5b9e\u73b0\u4e5f\u5f88\u5bb9\u6613. \u4f46\u662f\u8fd9\u4e2a\u7b97\u6cd5\u4e5f\u6709\u7f3a\u9677, \u7531\u4e8e\u5b58\u5728\u968f\u673a\u9009\u62e9\u7684\u60c5\u51b5, \u6240\u4ee5\u7b97\u6cd5\u5f88\u5bb9\u6613\u51fa\u73b0\u632f\u8361. \u4f46\u7b97\u6cd5\u7684\u8fd0\u884c\u5f00\u9500\u5f88\u4f4e, \u62ff\u6765\u505abaseline\u53c2\u8003\u975e\u5e38\u4e0d\u9519.","title":"\u793e\u533a\u53d1\u73b0\u7b97\u6cd5"},{"location":"9_2.html","text":"\u63a8\u7406\u5f15\u64ce \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u51e0\u79cd\u5e38\u89c1\u7684\u63a8\u7406\u5f15\u64ce. RDFox \u00b6 RDFox\u662f\u4e00\u4e2a\u9ad8\u5ea6\u53ef\u6269\u5c55\u7684\u5185\u5b58RDF\u4e09\u5143\u7ec4\u5b58\u50a8, \u652f\u6301\u5171\u4eab\u5185\u5b58\u5e76\u884cOWL 2 RL\u63a8\u7406. \u5b83\u662f\u7528C++\u7f16\u5199\u7684\u8de8\u5e73\u53f0\u8f6f\u4ef6, \u5e26\u6709\u4e00\u4e2aJava\u5305\u88c5\u5668, \u5141\u8bb8\u4e0e\u4efb\u4f55\u57fa\u4e8eJava\u7684\u89e3\u51b3\u65b9\u6848(\u5305\u62ecOWL API)\u8f7b\u677e\u96c6\u6210. \u6570\u636e\u8bb0\u5f55\u662f\u4e00\u79cd\u7528\u4e8e\u77e5\u8bc6\u8868\u793a\u7684\u89c4\u5219\u8bed\u8a00. \u81ea1980\u5e74\u4ee3\u4ee5\u6765, \u5728\u6570\u636e\u7ba1\u7406\u548c\u4eba\u5de5\u667a\u80fd\u9886\u57df\u4e00\u76f4\u4f7f\u7528\u89c4\u5219\u8bed\u8a00. \u6570\u636e\u8bb0\u5f55\u89c4\u5219\u662f\u4e00\u79cd\u903b\u8f91\u542b\u4e49, \u5176\u4e2d\u542b\u4e49\u7684\"if\"\u90e8\u5206(\u89c4\u5219\u4e3b\u4f53)\u548c\u542b\u4e49\u7684\"then\"\u90e8\u5206(\u89c4\u5219\u5934)\u90fd\u7531\u6761\u4ef6\u7684\u7ec4\u5408\u7ec4\u6210. \u5728RDF\u7684\u4e0a\u4e0b\u6587\u4e2d, Datalog\u89c4\u5219\u4f20\u8fbe\u4e86\u8fd9\u6837\u7684\u601d\u60f3, \u5373\u4ece\u8f93\u5165RDF\u56fe\u4e2d\u7684\u4e09\u5143\u7ec4\u7684\u67d0\u4e9b\u7ec4\u5408\u4e2d, \u6211\u4eec\u53ef\u4ee5\u4ece\u903b\u8f91\u4e0a\u63a8\u65ad\u51fa\u67d0\u4e9b\u5176\u4ed6\u4e09\u5143\u7ec4\u4e5f\u5fc5\u987b\u662f\u56fe\u7684\u4e00\u90e8\u5206. RDFox\u662f\u9ad8\u6027\u80fd\u7684\u77e5\u8bc6\u56fe\u548c\u8bed\u4e49\u63a8\u7406\u5f15\u64ce. \u63a8\u7406\u662f\u8ba1\u7b97\u5bf9\u4e00\u7ec4\u4e8b\u5b9e\u5e94\u7528\u4e00\u7ec4\u89c4\u5219\u7684\u903b\u8f91\u7ed3\u679c\u7684\u80fd\u529b. RDFox\u4f7f\u7528Datalog\u89c4\u5219\u8bed\u8a00\u6765\u8868\u8fbe\u89c4\u5219, \u89c4\u5219\u63d0\u4f9b\u4e86\u4e00\u79cd\u8868\u8fbe\u65b9\u5f0f\u6765\u5904\u7406\u548c\u64cd\u7eb5\u77e5\u8bc6\u56fe. \u89c4\u5219\u4f7f\u60c5\u62a5\u5c42\u66f4\u63a5\u8fd1\u6570\u636e, \u5e76\u4e14\u8fd8\u53ef\u4ee5\u7b80\u5316\u67e5\u8be2\u8868\u8ff0\u548c\u6570\u636e\u7ba1\u7406. \u7531\u4e8eDatalog\u662f\u4e00\u79cd\u57fa\u4e8e\u58f0\u660e\u6027\u903b\u8f91\u7684\u8bed\u8a00, \u4ee5\u5176\u7b80\u5355\u6027\u548c\u5728\u77e5\u8bc6\u8868\u793a\u4e2d\u7684\u4f7f\u7528\u800c\u95fb\u540d, \u56e0\u6b64\u5b83\u4f5c\u4e3a\u58f0\u660e\u6027\u89e3\u51b3\u65b9\u6848\u8865\u5145\u4e86RDFox. \u58f0\u660e\u6027\u5de5\u5177\u5728\u5e7f\u6cdb\u7684\u7528\u4f8b\u4e2d\u5f88\u6709\u7528, \u4f8b\u5982, \u5e94\u7528\u4e1a\u52a1\u903b\u8f91, \u673a\u5668\u5b66\u4e60\u6a21\u578b, \u4e1a\u52a1\u89c4\u5219, \u5185\u90e8\u5f00\u53d1\u6216\u5408\u89c4\u6027\u5de5\u5177\u6216\u6d41\u5c5e\u6027\u7b49\u7b49. Oxford Semantic Technologies\u80cc\u540e\u7684\u56e2\u961f\u4e8e2011\u5e74\u5f00\u59cb\u5728\u725b\u6d25\u5927\u5b66\u8ba1\u7b97\u673a\u79d1\u5b66\u7cfb\u4ece\u4e8bRDFox\u7684\u7814\u7a76, \u575a\u4fe1\u7075\u6d3b\u800c\u9ad8\u6027\u80fd\u7684\u63a8\u7406\u662f\u6570\u636e\u5bc6\u96c6\u578b\u5e94\u7528\u7a0b\u5e8f\u7684\u4e00\u79cd\u53ef\u80fd\u6027, \u800c\u4e0d\u4f1a\u635f\u5bb3\u7ed3\u679c\u7684\u6b63\u786e\u6027. RDFox\u662f\u7b2c\u4e00\u4e2a\u5b8c\u5168\u4ece\u5934\u5f00\u59cb\u8bbe\u8ba1\u5e76\u8003\u8651\u5230\u63a8\u7406\u7684\u77e5\u8bc6\u56fe. Oxford Semantic Technologies\u662f\u725b\u6d25\u5927\u5b66\u7684\u4e00\u90e8\u5206, \u5b83\u5f97\u5230\u4e86\u5305\u62ec\u4e09\u661f\u98ce\u9669\u6295\u8d44\u516c\u53f8(SVIC), \u725b\u6d25\u79d1\u5b66\u521b\u65b0(OSI)\u548c\u725b\u6d25\u5927\u5b66\u7684\u6295\u8d44\u90e8\u95e8(OUI)\u5728\u5185\u7684\u9886\u5148\u6295\u8d44\u8005\u7684\u652f\u6301. Drools \u00b6 Drools\u662f\u4e00\u6b3e\u7531JBoss\u7ec4\u7ec7\u63d0\u4f9b\u7684\u57fa\u4e8ejava\u8bed\u8a00\u5f00\u53d1\u7684\u5f00\u6e90\u89c4\u5219\u5f15\u64ce, \u53ef\u4ee5\u5c06\u590d\u6742\u4e14\u591a\u53d8\u7684\u4e1a\u52a1\u89c4\u5219\u4ece\u786c\u7f16\u7801\u4e2d\u89e3\u653e\u51fa\u6765, \u4ee5\u89c4\u5219\u811a\u672c\u7684\u5f62\u5f0f\u5b58\u653e\u5728\u6587\u4ef6\u6216\u7279\u5b9a\u7684\u5b58\u50a8\u4ecb\u8d28\u4e2d(\u5982\u5b58\u653e\u5728\u6570\u636e\u5e93\u4e2d), \u4f7f\u5f97\u4e1a\u52a1\u89c4\u5219\u7684\u53d8\u66f4\u4e0d\u9700\u8981\u4fee\u6539\u9879\u76ee\u4ee3\u7801, \u91cd\u542f\u670d\u52a1\u5668\u5c31\u53ef\u4ee5\u5728\u7ebf\u4e0a\u73af\u5883\u7acb\u5373\u751f\u6548. \u5728\u9879\u76ee\u4e2d\u4f7f\u7528Drools\u65f6, \u65e2\u53ef\u4ee5\u5355\u72ec\u4f7f\u7528\u4e5f\u53ef\u4ee5\u6574\u5408spring\u4f7f\u7528, \u5982\u679c\u5355\u72ec\u4f7f\u7528\u53ea\u9700\u5bfc\u5165\u5982\u4e0bmaven\u5750\u6807\u5373\u53ef < dependency > < groupId > org . drools </ groupId > < artifactId > drools - compiler </ artifactId > < version > 7.6.0 . Final </ version > </ dependency > \u4f7f\u7528drools\u5f15\u64ce\u89c4\u5219\u4e3b\u8981\u5de5\u4f5c\u5c31\u662f\u7f16\u5199\u89c4\u5219\u6587\u4ef6, \u5728\u89c4\u5219\u6587\u4ef6\u4e2d\u5b9a\u4e49\u548c\u4e1a\u52a1\u76f8\u5173\u7684\u4e1a\u52a1\u89c4\u5219. \u89c4\u5219\u5b9a\u4e49\u597d\u540e\u5c31\u9700\u8981\u8c03\u7528drools\u63d0\u4f9b\u7684api\u5c06\u6570\u636e\u63d0\u4f9b\u7ed9\u89c4\u5219\u5f15\u64ce\u8fdb\u884c\u89c4\u5219\u6a21\u5f0f\u5339\u914d, \u89c4\u5219\u5f15\u64ce\u4f1a\u6267\u884c\u5339\u914d\u6210\u529f\u7684\u89c4\u5219, \u5e76\u5c06\u8ba1\u7b97\u7684\u7ed3\u679c\u8fd4\u56de. \u4f7f\u7528Drools\u5f15\u64ce\u7684\u65f6\u5019\u53ef\u80fd\u5927\u5bb6\u4f1a\u6709\u7591\u95ee, \u867d\u7136\u6ca1\u6709\u5728\u4ee3\u7801\u4e2d\u7f16\u5199\u89c4\u5219\u7684\u5224\u65ad\u903b\u8f91, \u4f46\u662f\u8fd8\u662f\u5728\u89c4\u5219\u6587\u4ef6\u4e2d\u7f16\u5199\u4e86\u4e1a\u52a1\u89c4\u5219, \u8fd9\u8ddf\u5728\u4ee3\u7801\u4e2d\u7f16\u5199\u89c4\u5219\u6709\u4ec0\u4e48\u672c\u8d28\u7684\u533a\u522b? \u4f7f\u7528\u89c4\u5219\u5f15\u64ce\u65f6, \u89c4\u5219\u53ef\u4ee5\u505a\u5230\u52a8\u6001\u7ba1\u7406. \u4e1a\u52a1\u4eba\u5458\u53ef\u4ee5\u50cf\u7ba1\u7406\u6570\u636e\u4e00\u6837\u5bf9\u4e1a\u52a1\u89c4\u5219\u8fdb\u884c\u7ba1\u7406, \u6bd4\u5982\u67e5\u8be2, \u6dfb\u52a0, \u66f4\u65b0, \u7edf\u8ba1, \u63d0\u4ea4\u4e1a\u52a1\u89c4\u5219\u7b49, \u8fd9\u6837\u5c31\u53ef\u4ee5\u505a\u5230\u5728\u4e0d\u91cd\u542f\u670d\u52a1\u7684\u60c5\u51b5\u4e0b\u8c03\u6574\u4e1a\u52a1\u89c4\u5219. \u5728\u4f7f\u7528Drools\u65f6\u975e\u5e38\u91cd\u8981\u7684\u4e00\u4e2a\u5de5\u4f5c\u5c31\u662f\u7f16\u5199\u89c4\u5219\u6587\u4ef6, \u901a\u5e38\u89c4\u5219\u6587\u4ef6\u7684\u540e\u7f00\u4e3a.drl. drl\u662fDrools Rule Language\u7684\u7f29\u5199, \u5728\u89c4\u5219\u6587\u4ef6\u4e2d\u7f16\u5199\u5177\u4f53\u7684\u89c4\u5219\u5185\u5bb9. \u5c0f\u8282\u603b\u7ed3 \u00b6 \u672c\u5c0f\u8282\u521d\u6b65\u4ecb\u7ecd\u4e86\u4e24\u6b3e\u63a8\u7406\u5f15\u64ceRDFox\u548cDrools, \u5bf9\u5177\u4f53\u5e94\u7528\u611f\u5174\u8da3\u7684\u540c\u5b66\u53ef\u4ee5\u81ea\u884c\u4e86\u89e3\u548c\u6df1\u5165\u5b66\u4e60.","title":"9.2 \u5e38\u7528\u63a8\u7406\u5f15\u64ce"},{"location":"9_2.html#_1","text":"","title":"\u63a8\u7406\u5f15\u64ce"},{"location":"9_2.html#_2","text":"\u4e86\u89e3\u51e0\u79cd\u5e38\u89c1\u7684\u63a8\u7406\u5f15\u64ce.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"9_2.html#rdfox","text":"RDFox\u662f\u4e00\u4e2a\u9ad8\u5ea6\u53ef\u6269\u5c55\u7684\u5185\u5b58RDF\u4e09\u5143\u7ec4\u5b58\u50a8, \u652f\u6301\u5171\u4eab\u5185\u5b58\u5e76\u884cOWL 2 RL\u63a8\u7406. \u5b83\u662f\u7528C++\u7f16\u5199\u7684\u8de8\u5e73\u53f0\u8f6f\u4ef6, \u5e26\u6709\u4e00\u4e2aJava\u5305\u88c5\u5668, \u5141\u8bb8\u4e0e\u4efb\u4f55\u57fa\u4e8eJava\u7684\u89e3\u51b3\u65b9\u6848(\u5305\u62ecOWL API)\u8f7b\u677e\u96c6\u6210. \u6570\u636e\u8bb0\u5f55\u662f\u4e00\u79cd\u7528\u4e8e\u77e5\u8bc6\u8868\u793a\u7684\u89c4\u5219\u8bed\u8a00. \u81ea1980\u5e74\u4ee3\u4ee5\u6765, \u5728\u6570\u636e\u7ba1\u7406\u548c\u4eba\u5de5\u667a\u80fd\u9886\u57df\u4e00\u76f4\u4f7f\u7528\u89c4\u5219\u8bed\u8a00. \u6570\u636e\u8bb0\u5f55\u89c4\u5219\u662f\u4e00\u79cd\u903b\u8f91\u542b\u4e49, \u5176\u4e2d\u542b\u4e49\u7684\"if\"\u90e8\u5206(\u89c4\u5219\u4e3b\u4f53)\u548c\u542b\u4e49\u7684\"then\"\u90e8\u5206(\u89c4\u5219\u5934)\u90fd\u7531\u6761\u4ef6\u7684\u7ec4\u5408\u7ec4\u6210. \u5728RDF\u7684\u4e0a\u4e0b\u6587\u4e2d, Datalog\u89c4\u5219\u4f20\u8fbe\u4e86\u8fd9\u6837\u7684\u601d\u60f3, \u5373\u4ece\u8f93\u5165RDF\u56fe\u4e2d\u7684\u4e09\u5143\u7ec4\u7684\u67d0\u4e9b\u7ec4\u5408\u4e2d, \u6211\u4eec\u53ef\u4ee5\u4ece\u903b\u8f91\u4e0a\u63a8\u65ad\u51fa\u67d0\u4e9b\u5176\u4ed6\u4e09\u5143\u7ec4\u4e5f\u5fc5\u987b\u662f\u56fe\u7684\u4e00\u90e8\u5206. RDFox\u662f\u9ad8\u6027\u80fd\u7684\u77e5\u8bc6\u56fe\u548c\u8bed\u4e49\u63a8\u7406\u5f15\u64ce. \u63a8\u7406\u662f\u8ba1\u7b97\u5bf9\u4e00\u7ec4\u4e8b\u5b9e\u5e94\u7528\u4e00\u7ec4\u89c4\u5219\u7684\u903b\u8f91\u7ed3\u679c\u7684\u80fd\u529b. RDFox\u4f7f\u7528Datalog\u89c4\u5219\u8bed\u8a00\u6765\u8868\u8fbe\u89c4\u5219, \u89c4\u5219\u63d0\u4f9b\u4e86\u4e00\u79cd\u8868\u8fbe\u65b9\u5f0f\u6765\u5904\u7406\u548c\u64cd\u7eb5\u77e5\u8bc6\u56fe. \u89c4\u5219\u4f7f\u60c5\u62a5\u5c42\u66f4\u63a5\u8fd1\u6570\u636e, \u5e76\u4e14\u8fd8\u53ef\u4ee5\u7b80\u5316\u67e5\u8be2\u8868\u8ff0\u548c\u6570\u636e\u7ba1\u7406. \u7531\u4e8eDatalog\u662f\u4e00\u79cd\u57fa\u4e8e\u58f0\u660e\u6027\u903b\u8f91\u7684\u8bed\u8a00, \u4ee5\u5176\u7b80\u5355\u6027\u548c\u5728\u77e5\u8bc6\u8868\u793a\u4e2d\u7684\u4f7f\u7528\u800c\u95fb\u540d, \u56e0\u6b64\u5b83\u4f5c\u4e3a\u58f0\u660e\u6027\u89e3\u51b3\u65b9\u6848\u8865\u5145\u4e86RDFox. \u58f0\u660e\u6027\u5de5\u5177\u5728\u5e7f\u6cdb\u7684\u7528\u4f8b\u4e2d\u5f88\u6709\u7528, \u4f8b\u5982, \u5e94\u7528\u4e1a\u52a1\u903b\u8f91, \u673a\u5668\u5b66\u4e60\u6a21\u578b, \u4e1a\u52a1\u89c4\u5219, \u5185\u90e8\u5f00\u53d1\u6216\u5408\u89c4\u6027\u5de5\u5177\u6216\u6d41\u5c5e\u6027\u7b49\u7b49. Oxford Semantic Technologies\u80cc\u540e\u7684\u56e2\u961f\u4e8e2011\u5e74\u5f00\u59cb\u5728\u725b\u6d25\u5927\u5b66\u8ba1\u7b97\u673a\u79d1\u5b66\u7cfb\u4ece\u4e8bRDFox\u7684\u7814\u7a76, \u575a\u4fe1\u7075\u6d3b\u800c\u9ad8\u6027\u80fd\u7684\u63a8\u7406\u662f\u6570\u636e\u5bc6\u96c6\u578b\u5e94\u7528\u7a0b\u5e8f\u7684\u4e00\u79cd\u53ef\u80fd\u6027, \u800c\u4e0d\u4f1a\u635f\u5bb3\u7ed3\u679c\u7684\u6b63\u786e\u6027. RDFox\u662f\u7b2c\u4e00\u4e2a\u5b8c\u5168\u4ece\u5934\u5f00\u59cb\u8bbe\u8ba1\u5e76\u8003\u8651\u5230\u63a8\u7406\u7684\u77e5\u8bc6\u56fe. Oxford Semantic Technologies\u662f\u725b\u6d25\u5927\u5b66\u7684\u4e00\u90e8\u5206, \u5b83\u5f97\u5230\u4e86\u5305\u62ec\u4e09\u661f\u98ce\u9669\u6295\u8d44\u516c\u53f8(SVIC), \u725b\u6d25\u79d1\u5b66\u521b\u65b0(OSI)\u548c\u725b\u6d25\u5927\u5b66\u7684\u6295\u8d44\u90e8\u95e8(OUI)\u5728\u5185\u7684\u9886\u5148\u6295\u8d44\u8005\u7684\u652f\u6301.","title":"RDFox"},{"location":"9_2.html#drools","text":"Drools\u662f\u4e00\u6b3e\u7531JBoss\u7ec4\u7ec7\u63d0\u4f9b\u7684\u57fa\u4e8ejava\u8bed\u8a00\u5f00\u53d1\u7684\u5f00\u6e90\u89c4\u5219\u5f15\u64ce, \u53ef\u4ee5\u5c06\u590d\u6742\u4e14\u591a\u53d8\u7684\u4e1a\u52a1\u89c4\u5219\u4ece\u786c\u7f16\u7801\u4e2d\u89e3\u653e\u51fa\u6765, \u4ee5\u89c4\u5219\u811a\u672c\u7684\u5f62\u5f0f\u5b58\u653e\u5728\u6587\u4ef6\u6216\u7279\u5b9a\u7684\u5b58\u50a8\u4ecb\u8d28\u4e2d(\u5982\u5b58\u653e\u5728\u6570\u636e\u5e93\u4e2d), \u4f7f\u5f97\u4e1a\u52a1\u89c4\u5219\u7684\u53d8\u66f4\u4e0d\u9700\u8981\u4fee\u6539\u9879\u76ee\u4ee3\u7801, \u91cd\u542f\u670d\u52a1\u5668\u5c31\u53ef\u4ee5\u5728\u7ebf\u4e0a\u73af\u5883\u7acb\u5373\u751f\u6548. \u5728\u9879\u76ee\u4e2d\u4f7f\u7528Drools\u65f6, \u65e2\u53ef\u4ee5\u5355\u72ec\u4f7f\u7528\u4e5f\u53ef\u4ee5\u6574\u5408spring\u4f7f\u7528, \u5982\u679c\u5355\u72ec\u4f7f\u7528\u53ea\u9700\u5bfc\u5165\u5982\u4e0bmaven\u5750\u6807\u5373\u53ef < dependency > < groupId > org . drools </ groupId > < artifactId > drools - compiler </ artifactId > < version > 7.6.0 . Final </ version > </ dependency > \u4f7f\u7528drools\u5f15\u64ce\u89c4\u5219\u4e3b\u8981\u5de5\u4f5c\u5c31\u662f\u7f16\u5199\u89c4\u5219\u6587\u4ef6, \u5728\u89c4\u5219\u6587\u4ef6\u4e2d\u5b9a\u4e49\u548c\u4e1a\u52a1\u76f8\u5173\u7684\u4e1a\u52a1\u89c4\u5219. \u89c4\u5219\u5b9a\u4e49\u597d\u540e\u5c31\u9700\u8981\u8c03\u7528drools\u63d0\u4f9b\u7684api\u5c06\u6570\u636e\u63d0\u4f9b\u7ed9\u89c4\u5219\u5f15\u64ce\u8fdb\u884c\u89c4\u5219\u6a21\u5f0f\u5339\u914d, \u89c4\u5219\u5f15\u64ce\u4f1a\u6267\u884c\u5339\u914d\u6210\u529f\u7684\u89c4\u5219, \u5e76\u5c06\u8ba1\u7b97\u7684\u7ed3\u679c\u8fd4\u56de. \u4f7f\u7528Drools\u5f15\u64ce\u7684\u65f6\u5019\u53ef\u80fd\u5927\u5bb6\u4f1a\u6709\u7591\u95ee, \u867d\u7136\u6ca1\u6709\u5728\u4ee3\u7801\u4e2d\u7f16\u5199\u89c4\u5219\u7684\u5224\u65ad\u903b\u8f91, \u4f46\u662f\u8fd8\u662f\u5728\u89c4\u5219\u6587\u4ef6\u4e2d\u7f16\u5199\u4e86\u4e1a\u52a1\u89c4\u5219, \u8fd9\u8ddf\u5728\u4ee3\u7801\u4e2d\u7f16\u5199\u89c4\u5219\u6709\u4ec0\u4e48\u672c\u8d28\u7684\u533a\u522b? \u4f7f\u7528\u89c4\u5219\u5f15\u64ce\u65f6, \u89c4\u5219\u53ef\u4ee5\u505a\u5230\u52a8\u6001\u7ba1\u7406. \u4e1a\u52a1\u4eba\u5458\u53ef\u4ee5\u50cf\u7ba1\u7406\u6570\u636e\u4e00\u6837\u5bf9\u4e1a\u52a1\u89c4\u5219\u8fdb\u884c\u7ba1\u7406, \u6bd4\u5982\u67e5\u8be2, \u6dfb\u52a0, \u66f4\u65b0, \u7edf\u8ba1, \u63d0\u4ea4\u4e1a\u52a1\u89c4\u5219\u7b49, \u8fd9\u6837\u5c31\u53ef\u4ee5\u505a\u5230\u5728\u4e0d\u91cd\u542f\u670d\u52a1\u7684\u60c5\u51b5\u4e0b\u8c03\u6574\u4e1a\u52a1\u89c4\u5219. \u5728\u4f7f\u7528Drools\u65f6\u975e\u5e38\u91cd\u8981\u7684\u4e00\u4e2a\u5de5\u4f5c\u5c31\u662f\u7f16\u5199\u89c4\u5219\u6587\u4ef6, \u901a\u5e38\u89c4\u5219\u6587\u4ef6\u7684\u540e\u7f00\u4e3a.drl. drl\u662fDrools Rule Language\u7684\u7f29\u5199, \u5728\u89c4\u5219\u6587\u4ef6\u4e2d\u7f16\u5199\u5177\u4f53\u7684\u89c4\u5219\u5185\u5bb9.","title":"Drools"},{"location":"9_2.html#_3","text":"\u672c\u5c0f\u8282\u521d\u6b65\u4ecb\u7ecd\u4e86\u4e24\u6b3e\u63a8\u7406\u5f15\u64ceRDFox\u548cDrools, \u5bf9\u5177\u4f53\u5e94\u7528\u611f\u5174\u8da3\u7684\u540c\u5b66\u53ef\u4ee5\u81ea\u884c\u4e86\u89e3\u548c\u6df1\u5165\u5b66\u4e60.","title":"\u5c0f\u8282\u603b\u7ed3"},{"location":"9_3.html","text":"\u77e5\u8bc6\u63a8\u7406\u5c55\u671b \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u77e5\u8bc6\u63a8\u7406\u5b66\u672f\u754c\u524d\u6cbf \u4e86\u89e3\u672a\u6765\u5de5\u4e1a\u754c\u7684\u4e3b\u8981\u524d\u6cbf\u95ee\u9898. \u77e5\u8bc6\u63a8\u7406\u524d\u6cbf\u70ed\u70b9 \u00b6 \u7b80\u5355\u63a8\u7406\u7684\u5173\u952e\u95ee\u9898: \u6709\u4e00\u4e2a\u5934\u5b9e\u4f53\u548c\u4e00\u4e2a\u5c3e\u5b9e\u4f53, \u5e0c\u671b\u8865\u5168\u4e0e\u4e4b\u5bf9\u5e94\u7684\u5173\u7cfb, \u4f7f\u5f97\u4e09\u5143\u7ec4\u62e5\u6709\u6700\u5927\u6210\u7acb\u7684\u53ef\u80fd\u6027. \u4f8b\u5982: \u5df2\u77e5(\u8bad\u7ec3\u6570\u636e)\"\u848b\u82f1\u7684\u4e08\u592b\u662f\u94b1\u5b66\u68ee, \u848b\u82f1\u7684\u7236\u4eb2\u662f\u848b\u767e\u91cc\", \u8bf7\u95ee\"\u94b1\u5b66\u68ee\u548c\u848b\u767e\u91cc\u4e4b\u95f4\u662f\u4ec0\u4e48\u5173\u7cfb?\" \u4e3a\u4e86\u8f83\u597d\u89e3\u51b3\u8fd9\u4e00\u94fe\u63a5\u9884\u6d4b\u95ee\u9898, \u9700\u8981\u5bf9\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u952e\u6027\u8d28\u8fdb\u884c\u5efa\u6a21. \u590d\u6742\u63a8\u7406\u7684\u5173\u952e\u95ee\u9898: \u5f52\u7eb3\u5f0f\u63a8\u7406 \u591a\u6b65\u63a8\u7406 \u81ea\u7136\u8bed\u8a00\u67e5\u8be2 \u5f52\u7eb3\u5f0f\u63a8\u7406: \u6838\u5fc3\u95ee\u9898\u5728\u4e8e\u5b66\u4e60\u5173\u7cfb\u7684\u8bed\u4e49\u7ed3\u6784. \u5f52\u7eb3\u5f0f\u63a8\u7406\u548c\u7b80\u5355\u63a8\u7406\u6709\u7c7b\u4f3c\u4e4b\u5904, \u90fd\u662f\u8fdb\u884c\u8fde\u63a5\u9884\u6d4b\u7684\u4efb\u52a1. \u4f46\u662f\u5f52\u7eb3\u5f0f\u63a8\u7406\u6d4b\u8bd5\u6570\u636e\u96c6\u7684\u5b9e\u4f53\u548c\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u5b9e\u4f53\u4e0d\u91cd\u5408, \u96be\u70b9\u5728\u4e8e\u5982\u4f55\u5c06\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u77e5\u8bc6\u8fc1\u79fb\u6216\u6cdb\u5316\u81f3\u6d4b\u8bd5\u6570\u636e\u96c6. \u4f8b\u5982: \u5de6\u4fa7\u7ea2\u697c\u68a6\u548c\u53f3\u4fa7\u7684\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u4eba\u7269\u4e0d\u91cd\u5408, \u4f46\u4e24\u8005\u5173\u7cfb\u786e\u5b9e\u5b58\u5728\u4e00\u4e9b\u5171\u540c\u7684\u7279\u70b9, \u4e24\u8005\u90fd\u7b26\u5408\u6bcd\u4eb2, \u7236\u4eb2, \u4e08\u592b\u5173\u7cfb\u6a21\u5f0f, \u90fd\u53ef\u4ee5\u5c06\u5176\u63d0\u53d6\u4e0e\u5e94\u7528. \u591a\u6b65\u63a8\u7406: \u590d\u6742\u7ed3\u6784\u5316\u95ee\u9898\u7684\u8f93\u5165\u5bf9\u5e94\u7684\u590d\u6742\u63a8\u7406\u5f62\u5f0f\u662f\u591a\u6b65\u63a8\u7406. \u4f8b\u5982, \u5bf9\u4e8e\u67e5\u8be2\u4efb\u52a1\"\u5217\u51fa\u5b89\u5fbd\u7701\u5185\u4e3a211\u4f46\u975e985\u9ad8\u6821\u7684\u6821\u957f\". \u5bf9\u4e8e\u8fd9\u4e00\u4efb\u52a1, \u53ef\u4ee5\u901a\u8fc7\u4f20\u7edf\u6784\u5efa\u8ba1\u7b97\u56fe\u65b9\u6cd5\u8fdb\u884c\u89e3\u51b3, \u4f46\u4f1a\u9047\u5230\u7ed3\u6784\u591a\u6837, \u4e0e\u6216\u975e\u903b\u8f91\u8fd0\u7b97\u7b49\u95ee\u9898, \u4ece\u800c\u5e26\u6765\u975e\u5e38\u9ad8\u7684\u8ba1\u7b97\u590d\u6742\u5ea6. \u4f8b\u5b50, \u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u63a8\u7406\u5f97\u5230\u4e2d\u56fd\u4e1c\u90e8\u7701\u4efd\u7684\u9ad8\u6821, \u968f\u7740\u63a8\u7406\u6b65\u9aa4\u7684\u8fdb\u884c, \u5b9e\u4f53\u7684\u6570\u76ee\u4f1a\u4ece\u4e2d\u56fd\u8282\u70b9\u5f00\u59cb, \u5448\u6307\u6570\u7ea7\u4e0a\u5347. \u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898, \u6211\u4eec\u63d0\u51fa\u57fa\u4e8e\u8868\u793a\u5b66\u4e60\u7684\u65b9\u6cd5, \u5728\u9002\u5f53\u7684\u5411\u91cf\u7a7a\u95f4\u8fdb\u884c\u63a8\u7406. \u57fa\u4e8e\u8868\u793a\u5b66\u4e60\u7684\u591a\u6b65\u63a8\u7406\u6709\u4e24\u4e2a\u5173\u952e\u7684\u6b65\u9aa4: \u7b2c\u4e00: \u5b9a\u4e49\u5411\u91cf\u7a7a\u95f4 \u7b2c\u4e8c: \u5728\u5411\u91cf\u7a7a\u95f4\u4e2d\u5b9a\u4e49\u63a8\u7406\u64cd\u4f5c \u6838\u5fc3: \u5177\u4f53\u800c\u8a00, \u9996\u5148\u5c06\u5b9e\u4f53\u548c\u5b9e\u4f53\u7684\u96c6\u5408\u6620\u5c04\u5230\u5411\u91cf\u7a7a\u95f4, \u5b9e\u4f53\u7528\u51e0\u4f55\u56fe\u5f62\u6216\u8005\u6982\u7387\u5206\u5e03\u8fdb\u884c\u8868\u793a. \u7136\u540e\u5728\u5411\u91cf\u7a7a\u95f4\u4e2d\u901a\u8fc7\u76f8\u4f3c\u5ea6\u6bd4\u8f83\u5f97\u5230\u7b54\u6848, \u4ece\u800c\u907f\u514d\u5de8\u5927\u7684\u8ba1\u7b97\u5f00\u9500; \u4e4b\u540e, \u5c06\u63a8\u7406\u64cd\u4f5c\u5b9a\u4e49\u4e3a\u5b9e\u4f53\u96c6\u5408\u4e4b\u95f4\u7684\u53d8\u6362, \u4f8b\u5982\"\u4e0e\"\u5bf9\u5e94\u5b9e\u4f53\u96c6\u5408\u7684\u4ea4; \"\u6216\"\u5bf9\u5e94\u5b9e\u4f53\u96c6\u5408\u7684\u5e76; \"\u975e\"\u5bf9\u5e94\u5b9e\u4f53\u96c6\u5408\u7684\u8865. \u56e0\u6b64, \u5728\u57fa\u4e8e\u8868\u793a\u5b66\u4e60\u7684\u591a\u6b65\u63a8\u7406\u6a21\u578b\u4e2d, \u7ed9\u5b9a\u95ee\u9898\u7ed3\u6784, \u901a\u8fc7\u903b\u8f91\u64cd\u4f5c\u5f97\u5230\u6700\u7ec8\u95ee\u9898\u8868\u793a, \u7136\u540e\u901a\u8fc7\u5b9e\u4f53\u8868\u793a\u548c\u95ee\u9898\u8868\u793a\u4e4b\u95f4\u7684\u8ddd\u79bb, \u5f97\u5230\u6700\u7ec8\u95ee\u9898\u7684\u7b54\u6848. \u4e00\u822c\u800c\u8a00, \u95ee\u9898\u7b54\u6848\u662f\u5b9e\u4f53\u7684\u96c6\u5408, \u95ee\u9898\u8868\u793a\u672c\u8d28\u4e0a\u662f\u5b9e\u4f53\u96c6\u5408\u7684\u8868\u793a. \u6240\u4ee5\u5982\u4f55\u8868\u793a\u95ee\u9898\u7684\u96c6\u5408\u5c31\u53d8\u5f97\u975e\u5e38\u91cd\u8981. \u81ea\u7136\u8bed\u8a00\u67e5\u8be2: \u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u7684\u96be\u70b9\u5728\u5efa\u6a21\u975e\u7ed3\u6784\u5316\u95ee\u9898, \u5176\u4efb\u52a1\u9488\u5bf9\u7ed9\u5b9a\u7684\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u4f5c\u4e3a\u8f93\u5165(\u533a\u522b\u4e8e\u7ed3\u6784\u5316\u67e5\u8be2), \u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u591a\u8df3\u63a8\u7406\u7684\u65b9\u5f0f\u7ed9\u51fa\u7b54\u6848. \u4f46\u968f\u7740\u95ee\u9898\u8df3\u6570\u589e\u52a0, \u5019\u9009\u5b9e\u4f53\u6570\u91cf\u5448\u6307\u6570\u589e\u957f. \u73b0\u6709\u7684GNN\u65b9\u6cd5\u901a\u8fc7\u5b50\u56fe\u88c1\u526a\u4ee5\u964d\u4f4e\u5019\u9009\u5b9e\u4f53\u6570\u91cf\u4f46\u727a\u7272\u4e86\u6b63\u786e\u7b54\u6848\u7684\u53ec\u56de\u7387. \u53d7\u4eba\u7c7b\u8ba4\u77e5\u7406\u8bba\u542f\u53d1, \u63d0\u51fa\u4e24\u9636\u6bb5\u65b9\u6cd5: \u7b2c\u4e00\u9636\u6bb5: \u5bf9\u5e94\u7cfb\u7edf1(\u65e0\u610f\u8bc6, \u76f4\u89c9\u7684, \u5feb\u601d\u8003), \u5feb\u901f\u7b5b\u9009, \u901a\u8fc7query-answer\u8bed\u4e49\u5339\u914d\u6253\u5206. \u7b2c\u4e8c\u9636\u6bb5: \u5bf9\u5e94\u7cfb\u7edf2(\u6709\u610f\u8bc6, \u903b\u8f91\u7684, \u6162\u601d\u8003), \u901a\u8fc7\u8d1d\u53f6\u65af\u7f51\u7edc, \u57fa\u4e8e\u63a8\u7406\u8def\u5f84\u7684\u6253\u5206. \u672a\u6765\u5c55\u671b: \u5728\u77e5\u8bc6\u56fe\u8c31\u4e0a\u8fdb\u884c\u63a8\u7406, \u9664\u4e86\u57fa\u4e8e\u8868\u793a\u5b66\u4e60\u7684\u65b9\u6cd5\u4e4b\u5916, \u8fd8\u6709\u4e00\u79cd\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5. \u867d\u7136\u57fa\u4e8e\u8868\u793a\u5b66\u4e60\u76f8\u6bd4\u89c4\u5219\u63a8\u7406\u7684\u65b9\u6cd5, \u53ef\u4ee5\u66f4\u597d\u5730\u5efa\u6a21\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u6f5c\u5728\u8bed\u4e49\u4fe1\u606f, \u4f46\u5728\u771f\u5b9e\u7684\u5e94\u7528\u573a\u666f\u4e2d, \u89c4\u5219\u63a8\u7406\u5f80\u5f80\u66f4\u53d7\u6b22\u8fce. \u539f\u56e0\u662f\u5b83\u7684\u7cbe\u5ea6\u9ad8, \u53ef\u89e3\u91ca\u6027\u5f3a. \u56e0\u6b64\u5b66\u672f\u754c\u7684\u76ee\u6807\u5e94\u8be5\u662f\u4f7f\u8868\u793a\u5b66\u4e60\u63a8\u7406\u6a21\u578b\u5728\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u6027\u80fd\u4e0e\u89c4\u5219\u63a8\u7406\u6a21\u578b\u5ab2\u7f8e. \u9996\u5148, \u5f53\u524d\u5e7f\u6cdb\u4f7f\u7528\u7684\u6570\u636e\u96c6\u65e0\u6cd5\u51c6\u786e\u5730\u53cd\u6620\u771f\u5b9e\u573a\u666f\u6a21\u578b, \u73b0\u6709\u7684\u6a21\u578b\u6d4b\u8bd5\u65f6\u57fa\u672c\u91c7\u7528\u5c01\u95ed\u4e16\u754c\u5047\u8bbe, \u5373\u4e0d\u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u4e09\u5143\u7ec4\u90fd\u662f\u9519\u8bef\u7684, \u8fd9\u663e\u7136\u4e0d\u7b26\u5408\u771f\u5b9e\u5e94\u7528\u573a\u666f, \u56e0\u6b64\u4f1a\u5bfc\u81f4\u672c\u8be5\u6b63\u786e\u7684\u7ed3\u679c\u88ab\u5224\u65ad\u4e3a\u9519\u8bef. \u6240\u4ee5\u5982\u4f55\u7528\"\u5019\u9009\u6570\u636e\u96c6\"\u7684\u6027\u80fd\u5ba2\u89c2\u53cd\u6620\u6a21\u578b\u6027\u80fd, \u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22. \u518d\u8005, \u5f53\u524d\u5e7f\u6cdb\u4f7f\u7528\u7684\u8bc4\u6d4b\u6307\u6807\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u7684\u4f18\u52a3. \u4f8b\u5982, \u6d4b\u8bd5\u96c6\u4e2d\u6b63\u786e\u4e09\u5143\u7ec4\u7684\u6392\u540d\u8d8a\u9ad8, \u6a21\u578b\u5728\u8fd9\u4e9b\u8bc4\u6d4b\u6307\u6807\u4e0a\u7684\u8868\u73b0\u5c31\u8d8a\u597d, \u7136\u800c\u8fd9\u662f\u4e0d\u5168\u9762\u7684. \u6b64\u5916, \u5728\u5c01\u95ed\u4e16\u754c\u5047\u8bbe\u4e0b, \u4e00\u4e9b\u672c\u5e94\u6027\u80fd\u8f83\u597d\u7684\u6a21\u578b\u5728\u8fd9\u4e9b\u6307\u6807\u4e0b\u4e5f\u53ef\u80fd\u4f1a\u6709\u8f83\u5dee\u7684\u8868\u73b0. \u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u53ea\u6d89\u53ca\u6587\u672c\u4fe1\u606f, \u672a\u6765\u53d1\u5c55\u8d8b\u52bf\u662f\u6269\u5c55\u5230\u591a\u6a21\u6001\u4fe1\u606f. \u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa, \u4f9d\u8d56\u4e8e\u591a\u79cd\u6a21\u6001\u6570\u636e\u7684\u6536\u96c6, \u5176\u4e2d\u5173\u952e\u95ee\u9898\u662f\u5982\u4f55\u8fdb\u884c\u4e0d\u540c\u6a21\u6001\u6570\u636e\u4e4b\u95f4\u7684\u5bf9\u9f50. \u6b64\u5916, \u4e5f\u9700\u8981\u9ad8\u6027\u80fd\u7684\u6570\u636e\u5e93, \u5e2e\u52a9\u5b58\u50a8\u591a\u6a21\u6001\u6570\u636e, \u76ee\u524d\u8fd9\u65b9\u9762\u56fd\u5185\u5df2\u7ecf\u6709\u4f01\u4e1a\u5f00\u59cb\u6280\u672f\u653b\u5173. \u77e5\u8bc6\u56fe\u8c31\u548c\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u7ed3\u5408\u4e5f\u662f\u63a5\u4e0b\u6765\u7684\u53d1\u5c55\u8d8b\u52bf. \u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5df2\u7ecf\u6bd4\u8f83\u6210\u719f, \u4f46\u5728\u6d89\u53ca\u7279\u5b9a\u9886\u57df\u7684\u77e5\u8bc6\u6216\u8005\u5e38\u8bc6\u65f6, \u8868\u73b0\u5e76\u4e0d\u4ee4\u4eba\u6ee1\u610f. \u5982\u4f55\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b, \u6216\u8005\u600e\u6837\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5e2e\u52a9\u66f4\u597d\u5730\u5728\u77e5\u8bc6\u56fe\u8c31\u4e0a\u8fdb\u884c\u63a8\u7406, \u4e5f\u662f\u63a5\u4e0b\u6765\u9700\u8981\u91cd\u70b9\u5173\u6ce8\u7684\u65b9\u5411. \u6700\u540e, \u77e5\u8bc6\u56fe\u8c31\u4e0e\u5bf9\u8bdd\u573a\u666f\u7684\u7ed3\u5408\u4e5f\u662f\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u6240\u671f\u5f85\u7684. \u7528\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u8868\u793a\u5bf9\u8bdd\u72b6\u6001, \u76f8\u6bd4\u4f20\u7edf\u952e\u503c\u5bf9\u7684\u7ed3\u6784, \u53ef\u4ee5\u66f4\u5b8c\u6574\u5730\u8ddf\u8e2a\u8868\u793a\u5bf9\u8bdd\u7684\u72b6\u6001\u4ee5\u53ca\u53d8\u5316, \u5b9e\u73b0\u66f4\u52a0\u63a5\u8fd1\"\u56fe\u7075\u6d4b\u8bd5\"\u7684\u5bf9\u8bdd\u7cfb\u7edf. \u5c0f\u8282\u603b\u7ed3 \u00b6 \u672c\u5c0f\u8282\u5e26\u7740\u540c\u5b66\u4eec\u4e86\u89e3\u4e86\u77e5\u8bc6\u63a8\u7406\u7684\u5b66\u672f\u754c, \u5de5\u4e1a\u754c\u524d\u6cbf\u70ed\u70b9, \u4ee5\u53ca\u672a\u6765\u5f85\u89e3\u51b3\u7684\u95ee\u9898\u548c\u4e3b\u6d41\u601d\u8def.","title":"9.3 \u77e5\u8bc6\u63a8\u7406\u5c55\u671b"},{"location":"9_3.html#_1","text":"","title":"\u77e5\u8bc6\u63a8\u7406\u5c55\u671b"},{"location":"9_3.html#_2","text":"\u4e86\u89e3\u77e5\u8bc6\u63a8\u7406\u5b66\u672f\u754c\u524d\u6cbf \u4e86\u89e3\u672a\u6765\u5de5\u4e1a\u754c\u7684\u4e3b\u8981\u524d\u6cbf\u95ee\u9898.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"9_3.html#_3","text":"\u7b80\u5355\u63a8\u7406\u7684\u5173\u952e\u95ee\u9898: \u6709\u4e00\u4e2a\u5934\u5b9e\u4f53\u548c\u4e00\u4e2a\u5c3e\u5b9e\u4f53, \u5e0c\u671b\u8865\u5168\u4e0e\u4e4b\u5bf9\u5e94\u7684\u5173\u7cfb, \u4f7f\u5f97\u4e09\u5143\u7ec4\u62e5\u6709\u6700\u5927\u6210\u7acb\u7684\u53ef\u80fd\u6027. \u4f8b\u5982: \u5df2\u77e5(\u8bad\u7ec3\u6570\u636e)\"\u848b\u82f1\u7684\u4e08\u592b\u662f\u94b1\u5b66\u68ee, \u848b\u82f1\u7684\u7236\u4eb2\u662f\u848b\u767e\u91cc\", \u8bf7\u95ee\"\u94b1\u5b66\u68ee\u548c\u848b\u767e\u91cc\u4e4b\u95f4\u662f\u4ec0\u4e48\u5173\u7cfb?\" \u4e3a\u4e86\u8f83\u597d\u89e3\u51b3\u8fd9\u4e00\u94fe\u63a5\u9884\u6d4b\u95ee\u9898, \u9700\u8981\u5bf9\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u952e\u6027\u8d28\u8fdb\u884c\u5efa\u6a21. \u590d\u6742\u63a8\u7406\u7684\u5173\u952e\u95ee\u9898: \u5f52\u7eb3\u5f0f\u63a8\u7406 \u591a\u6b65\u63a8\u7406 \u81ea\u7136\u8bed\u8a00\u67e5\u8be2 \u5f52\u7eb3\u5f0f\u63a8\u7406: \u6838\u5fc3\u95ee\u9898\u5728\u4e8e\u5b66\u4e60\u5173\u7cfb\u7684\u8bed\u4e49\u7ed3\u6784. \u5f52\u7eb3\u5f0f\u63a8\u7406\u548c\u7b80\u5355\u63a8\u7406\u6709\u7c7b\u4f3c\u4e4b\u5904, \u90fd\u662f\u8fdb\u884c\u8fde\u63a5\u9884\u6d4b\u7684\u4efb\u52a1. \u4f46\u662f\u5f52\u7eb3\u5f0f\u63a8\u7406\u6d4b\u8bd5\u6570\u636e\u96c6\u7684\u5b9e\u4f53\u548c\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u5b9e\u4f53\u4e0d\u91cd\u5408, \u96be\u70b9\u5728\u4e8e\u5982\u4f55\u5c06\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u77e5\u8bc6\u8fc1\u79fb\u6216\u6cdb\u5316\u81f3\u6d4b\u8bd5\u6570\u636e\u96c6. \u4f8b\u5982: \u5de6\u4fa7\u7ea2\u697c\u68a6\u548c\u53f3\u4fa7\u7684\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u4eba\u7269\u4e0d\u91cd\u5408, \u4f46\u4e24\u8005\u5173\u7cfb\u786e\u5b9e\u5b58\u5728\u4e00\u4e9b\u5171\u540c\u7684\u7279\u70b9, \u4e24\u8005\u90fd\u7b26\u5408\u6bcd\u4eb2, \u7236\u4eb2, \u4e08\u592b\u5173\u7cfb\u6a21\u5f0f, \u90fd\u53ef\u4ee5\u5c06\u5176\u63d0\u53d6\u4e0e\u5e94\u7528. \u591a\u6b65\u63a8\u7406: \u590d\u6742\u7ed3\u6784\u5316\u95ee\u9898\u7684\u8f93\u5165\u5bf9\u5e94\u7684\u590d\u6742\u63a8\u7406\u5f62\u5f0f\u662f\u591a\u6b65\u63a8\u7406. \u4f8b\u5982, \u5bf9\u4e8e\u67e5\u8be2\u4efb\u52a1\"\u5217\u51fa\u5b89\u5fbd\u7701\u5185\u4e3a211\u4f46\u975e985\u9ad8\u6821\u7684\u6821\u957f\". \u5bf9\u4e8e\u8fd9\u4e00\u4efb\u52a1, \u53ef\u4ee5\u901a\u8fc7\u4f20\u7edf\u6784\u5efa\u8ba1\u7b97\u56fe\u65b9\u6cd5\u8fdb\u884c\u89e3\u51b3, \u4f46\u4f1a\u9047\u5230\u7ed3\u6784\u591a\u6837, \u4e0e\u6216\u975e\u903b\u8f91\u8fd0\u7b97\u7b49\u95ee\u9898, \u4ece\u800c\u5e26\u6765\u975e\u5e38\u9ad8\u7684\u8ba1\u7b97\u590d\u6742\u5ea6. \u4f8b\u5b50, \u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u63a8\u7406\u5f97\u5230\u4e2d\u56fd\u4e1c\u90e8\u7701\u4efd\u7684\u9ad8\u6821, \u968f\u7740\u63a8\u7406\u6b65\u9aa4\u7684\u8fdb\u884c, \u5b9e\u4f53\u7684\u6570\u76ee\u4f1a\u4ece\u4e2d\u56fd\u8282\u70b9\u5f00\u59cb, \u5448\u6307\u6570\u7ea7\u4e0a\u5347. \u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898, \u6211\u4eec\u63d0\u51fa\u57fa\u4e8e\u8868\u793a\u5b66\u4e60\u7684\u65b9\u6cd5, \u5728\u9002\u5f53\u7684\u5411\u91cf\u7a7a\u95f4\u8fdb\u884c\u63a8\u7406. \u57fa\u4e8e\u8868\u793a\u5b66\u4e60\u7684\u591a\u6b65\u63a8\u7406\u6709\u4e24\u4e2a\u5173\u952e\u7684\u6b65\u9aa4: \u7b2c\u4e00: \u5b9a\u4e49\u5411\u91cf\u7a7a\u95f4 \u7b2c\u4e8c: \u5728\u5411\u91cf\u7a7a\u95f4\u4e2d\u5b9a\u4e49\u63a8\u7406\u64cd\u4f5c \u6838\u5fc3: \u5177\u4f53\u800c\u8a00, \u9996\u5148\u5c06\u5b9e\u4f53\u548c\u5b9e\u4f53\u7684\u96c6\u5408\u6620\u5c04\u5230\u5411\u91cf\u7a7a\u95f4, \u5b9e\u4f53\u7528\u51e0\u4f55\u56fe\u5f62\u6216\u8005\u6982\u7387\u5206\u5e03\u8fdb\u884c\u8868\u793a. \u7136\u540e\u5728\u5411\u91cf\u7a7a\u95f4\u4e2d\u901a\u8fc7\u76f8\u4f3c\u5ea6\u6bd4\u8f83\u5f97\u5230\u7b54\u6848, \u4ece\u800c\u907f\u514d\u5de8\u5927\u7684\u8ba1\u7b97\u5f00\u9500; \u4e4b\u540e, \u5c06\u63a8\u7406\u64cd\u4f5c\u5b9a\u4e49\u4e3a\u5b9e\u4f53\u96c6\u5408\u4e4b\u95f4\u7684\u53d8\u6362, \u4f8b\u5982\"\u4e0e\"\u5bf9\u5e94\u5b9e\u4f53\u96c6\u5408\u7684\u4ea4; \"\u6216\"\u5bf9\u5e94\u5b9e\u4f53\u96c6\u5408\u7684\u5e76; \"\u975e\"\u5bf9\u5e94\u5b9e\u4f53\u96c6\u5408\u7684\u8865. \u56e0\u6b64, \u5728\u57fa\u4e8e\u8868\u793a\u5b66\u4e60\u7684\u591a\u6b65\u63a8\u7406\u6a21\u578b\u4e2d, \u7ed9\u5b9a\u95ee\u9898\u7ed3\u6784, \u901a\u8fc7\u903b\u8f91\u64cd\u4f5c\u5f97\u5230\u6700\u7ec8\u95ee\u9898\u8868\u793a, \u7136\u540e\u901a\u8fc7\u5b9e\u4f53\u8868\u793a\u548c\u95ee\u9898\u8868\u793a\u4e4b\u95f4\u7684\u8ddd\u79bb, \u5f97\u5230\u6700\u7ec8\u95ee\u9898\u7684\u7b54\u6848. \u4e00\u822c\u800c\u8a00, \u95ee\u9898\u7b54\u6848\u662f\u5b9e\u4f53\u7684\u96c6\u5408, \u95ee\u9898\u8868\u793a\u672c\u8d28\u4e0a\u662f\u5b9e\u4f53\u96c6\u5408\u7684\u8868\u793a. \u6240\u4ee5\u5982\u4f55\u8868\u793a\u95ee\u9898\u7684\u96c6\u5408\u5c31\u53d8\u5f97\u975e\u5e38\u91cd\u8981. \u81ea\u7136\u8bed\u8a00\u67e5\u8be2: \u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u7684\u96be\u70b9\u5728\u5efa\u6a21\u975e\u7ed3\u6784\u5316\u95ee\u9898, \u5176\u4efb\u52a1\u9488\u5bf9\u7ed9\u5b9a\u7684\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u4f5c\u4e3a\u8f93\u5165(\u533a\u522b\u4e8e\u7ed3\u6784\u5316\u67e5\u8be2), \u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u591a\u8df3\u63a8\u7406\u7684\u65b9\u5f0f\u7ed9\u51fa\u7b54\u6848. \u4f46\u968f\u7740\u95ee\u9898\u8df3\u6570\u589e\u52a0, \u5019\u9009\u5b9e\u4f53\u6570\u91cf\u5448\u6307\u6570\u589e\u957f. \u73b0\u6709\u7684GNN\u65b9\u6cd5\u901a\u8fc7\u5b50\u56fe\u88c1\u526a\u4ee5\u964d\u4f4e\u5019\u9009\u5b9e\u4f53\u6570\u91cf\u4f46\u727a\u7272\u4e86\u6b63\u786e\u7b54\u6848\u7684\u53ec\u56de\u7387. \u53d7\u4eba\u7c7b\u8ba4\u77e5\u7406\u8bba\u542f\u53d1, \u63d0\u51fa\u4e24\u9636\u6bb5\u65b9\u6cd5: \u7b2c\u4e00\u9636\u6bb5: \u5bf9\u5e94\u7cfb\u7edf1(\u65e0\u610f\u8bc6, \u76f4\u89c9\u7684, \u5feb\u601d\u8003), \u5feb\u901f\u7b5b\u9009, \u901a\u8fc7query-answer\u8bed\u4e49\u5339\u914d\u6253\u5206. \u7b2c\u4e8c\u9636\u6bb5: \u5bf9\u5e94\u7cfb\u7edf2(\u6709\u610f\u8bc6, \u903b\u8f91\u7684, \u6162\u601d\u8003), \u901a\u8fc7\u8d1d\u53f6\u65af\u7f51\u7edc, \u57fa\u4e8e\u63a8\u7406\u8def\u5f84\u7684\u6253\u5206. \u672a\u6765\u5c55\u671b: \u5728\u77e5\u8bc6\u56fe\u8c31\u4e0a\u8fdb\u884c\u63a8\u7406, \u9664\u4e86\u57fa\u4e8e\u8868\u793a\u5b66\u4e60\u7684\u65b9\u6cd5\u4e4b\u5916, \u8fd8\u6709\u4e00\u79cd\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5. \u867d\u7136\u57fa\u4e8e\u8868\u793a\u5b66\u4e60\u76f8\u6bd4\u89c4\u5219\u63a8\u7406\u7684\u65b9\u6cd5, \u53ef\u4ee5\u66f4\u597d\u5730\u5efa\u6a21\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u6f5c\u5728\u8bed\u4e49\u4fe1\u606f, \u4f46\u5728\u771f\u5b9e\u7684\u5e94\u7528\u573a\u666f\u4e2d, \u89c4\u5219\u63a8\u7406\u5f80\u5f80\u66f4\u53d7\u6b22\u8fce. \u539f\u56e0\u662f\u5b83\u7684\u7cbe\u5ea6\u9ad8, \u53ef\u89e3\u91ca\u6027\u5f3a. \u56e0\u6b64\u5b66\u672f\u754c\u7684\u76ee\u6807\u5e94\u8be5\u662f\u4f7f\u8868\u793a\u5b66\u4e60\u63a8\u7406\u6a21\u578b\u5728\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u6027\u80fd\u4e0e\u89c4\u5219\u63a8\u7406\u6a21\u578b\u5ab2\u7f8e. \u9996\u5148, \u5f53\u524d\u5e7f\u6cdb\u4f7f\u7528\u7684\u6570\u636e\u96c6\u65e0\u6cd5\u51c6\u786e\u5730\u53cd\u6620\u771f\u5b9e\u573a\u666f\u6a21\u578b, \u73b0\u6709\u7684\u6a21\u578b\u6d4b\u8bd5\u65f6\u57fa\u672c\u91c7\u7528\u5c01\u95ed\u4e16\u754c\u5047\u8bbe, \u5373\u4e0d\u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u4e09\u5143\u7ec4\u90fd\u662f\u9519\u8bef\u7684, \u8fd9\u663e\u7136\u4e0d\u7b26\u5408\u771f\u5b9e\u5e94\u7528\u573a\u666f, \u56e0\u6b64\u4f1a\u5bfc\u81f4\u672c\u8be5\u6b63\u786e\u7684\u7ed3\u679c\u88ab\u5224\u65ad\u4e3a\u9519\u8bef. \u6240\u4ee5\u5982\u4f55\u7528\"\u5019\u9009\u6570\u636e\u96c6\"\u7684\u6027\u80fd\u5ba2\u89c2\u53cd\u6620\u6a21\u578b\u6027\u80fd, \u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22. \u518d\u8005, \u5f53\u524d\u5e7f\u6cdb\u4f7f\u7528\u7684\u8bc4\u6d4b\u6307\u6807\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u7684\u4f18\u52a3. \u4f8b\u5982, \u6d4b\u8bd5\u96c6\u4e2d\u6b63\u786e\u4e09\u5143\u7ec4\u7684\u6392\u540d\u8d8a\u9ad8, \u6a21\u578b\u5728\u8fd9\u4e9b\u8bc4\u6d4b\u6307\u6807\u4e0a\u7684\u8868\u73b0\u5c31\u8d8a\u597d, \u7136\u800c\u8fd9\u662f\u4e0d\u5168\u9762\u7684. \u6b64\u5916, \u5728\u5c01\u95ed\u4e16\u754c\u5047\u8bbe\u4e0b, \u4e00\u4e9b\u672c\u5e94\u6027\u80fd\u8f83\u597d\u7684\u6a21\u578b\u5728\u8fd9\u4e9b\u6307\u6807\u4e0b\u4e5f\u53ef\u80fd\u4f1a\u6709\u8f83\u5dee\u7684\u8868\u73b0. \u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u53ea\u6d89\u53ca\u6587\u672c\u4fe1\u606f, \u672a\u6765\u53d1\u5c55\u8d8b\u52bf\u662f\u6269\u5c55\u5230\u591a\u6a21\u6001\u4fe1\u606f. \u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa, \u4f9d\u8d56\u4e8e\u591a\u79cd\u6a21\u6001\u6570\u636e\u7684\u6536\u96c6, \u5176\u4e2d\u5173\u952e\u95ee\u9898\u662f\u5982\u4f55\u8fdb\u884c\u4e0d\u540c\u6a21\u6001\u6570\u636e\u4e4b\u95f4\u7684\u5bf9\u9f50. \u6b64\u5916, \u4e5f\u9700\u8981\u9ad8\u6027\u80fd\u7684\u6570\u636e\u5e93, \u5e2e\u52a9\u5b58\u50a8\u591a\u6a21\u6001\u6570\u636e, \u76ee\u524d\u8fd9\u65b9\u9762\u56fd\u5185\u5df2\u7ecf\u6709\u4f01\u4e1a\u5f00\u59cb\u6280\u672f\u653b\u5173. \u77e5\u8bc6\u56fe\u8c31\u548c\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u7ed3\u5408\u4e5f\u662f\u63a5\u4e0b\u6765\u7684\u53d1\u5c55\u8d8b\u52bf. \u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5df2\u7ecf\u6bd4\u8f83\u6210\u719f, \u4f46\u5728\u6d89\u53ca\u7279\u5b9a\u9886\u57df\u7684\u77e5\u8bc6\u6216\u8005\u5e38\u8bc6\u65f6, \u8868\u73b0\u5e76\u4e0d\u4ee4\u4eba\u6ee1\u610f. \u5982\u4f55\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b, \u6216\u8005\u600e\u6837\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5e2e\u52a9\u66f4\u597d\u5730\u5728\u77e5\u8bc6\u56fe\u8c31\u4e0a\u8fdb\u884c\u63a8\u7406, \u4e5f\u662f\u63a5\u4e0b\u6765\u9700\u8981\u91cd\u70b9\u5173\u6ce8\u7684\u65b9\u5411. \u6700\u540e, \u77e5\u8bc6\u56fe\u8c31\u4e0e\u5bf9\u8bdd\u573a\u666f\u7684\u7ed3\u5408\u4e5f\u662f\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u6240\u671f\u5f85\u7684. \u7528\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u8868\u793a\u5bf9\u8bdd\u72b6\u6001, \u76f8\u6bd4\u4f20\u7edf\u952e\u503c\u5bf9\u7684\u7ed3\u6784, \u53ef\u4ee5\u66f4\u5b8c\u6574\u5730\u8ddf\u8e2a\u8868\u793a\u5bf9\u8bdd\u7684\u72b6\u6001\u4ee5\u53ca\u53d8\u5316, \u5b9e\u73b0\u66f4\u52a0\u63a5\u8fd1\"\u56fe\u7075\u6d4b\u8bd5\"\u7684\u5bf9\u8bdd\u7cfb\u7edf.","title":"\u77e5\u8bc6\u63a8\u7406\u524d\u6cbf\u70ed\u70b9"},{"location":"9_3.html#_4","text":"\u672c\u5c0f\u8282\u5e26\u7740\u540c\u5b66\u4eec\u4e86\u89e3\u4e86\u77e5\u8bc6\u63a8\u7406\u7684\u5b66\u672f\u754c, \u5de5\u4e1a\u754c\u524d\u6cbf\u70ed\u70b9, \u4ee5\u53ca\u672a\u6765\u5f85\u89e3\u51b3\u7684\u95ee\u9898\u548c\u4e3b\u6d41\u601d\u8def.","title":"\u5c0f\u8282\u603b\u7ed3"}]}