<!DOCTYPE html>
<!-- saved from url=(0031)http://121.199.45.168:8818/4_3/ -->
<html lang="zh" class="js json svg checked target dataset details fetch supports csstransforms3d no-ios" style=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
      
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
        <link rel="canonical" href="http://0.0.0.0:8818/4_3/">
      
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="ja">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="./index_files/AI.jpg">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-4.4.0">
    
    
      
        <title>4.3 PGN实现baseline-2模型 - 文本摘要项目</title>
      
    
    
      <link rel="stylesheet" href="./index_files/application.0284f74d.css">
      
      
    
    
      <script src="./index_files/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin="">
        <link rel="stylesheet" href="./index_files/css">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="./index_files/material-icons.css">
    
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "UA-36723568-3", "mkdocs.org")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async="" src="./index_files/analytics.js"></script>
      
    
    
  <script type="text/javascript">(function(){var s=document.createElement("script");var port=window.location.port;s.src="//"+window.location.hostname+":"+port+ "/livereload.js?port=" + port;document.head.appendChild(s);})();</script><script src="./index_files/livereload.js"></script></head>
  
    <body dir="ltr" data-md-state="">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"></path></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#pgn" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header" data-md-state="shadow">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="./1_1.html" title="文本摘要项目" class="md-header-nav__button md-logo">
          
            <img src="./index_files/AI.jpg" width="24" height="24">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic" style="width: 648px;">
              文本摘要项目
            </span>
            <span class="md-header-nav__topic" style="width: 648px;">
              
                4.3 PGN实现baseline-2模型
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix="">
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/AITutorials/manuals" title="前往 Github 仓库" class="md-source" data-md-source="github" data-md-state="done">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    Github
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation" style="height: 509px;">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="./1_1.html" title="文本摘要项目" class="md-nav__button md-logo">
      
        <img src="./index_files/AI.jpg" width="48" height="48">
      
    </a>
    文本摘要项目
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/AITutorials/manuals" title="前往 Github 仓库" class="md-source" data-md-source="github" data-md-state="done">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    Github
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix="">
    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1">
    
    <label class="md-nav__link" for="nav-1">
      第一章:文本摘要项目简介
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: none; overflow: hidden;">
      <label class="md-nav__title" for="nav-1">
        第一章:文本摘要项目简介
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./1_1.html" title="1.1 项目背景介绍" class="md-nav__link">
      1.1 项目背景介绍
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./1_2.html" title="1.2 项目中的数据集初探" class="md-nav__link">
      1.2 项目中的数据集初探
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      第二章:TextRank模型
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: none; overflow: hidden;">
      <label class="md-nav__title" for="nav-2">
        第二章:TextRank模型
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./2_1.html" title="2.1 TextRank算法理论基础" class="md-nav__link">
      2.1 TextRank算法理论基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./2_2.html" title="2.2 TextRank实现baseline-0模型" class="md-nav__link">
      2.2 TextRank实现baseline-0模型
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      第三章:seq2seq经典架构
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: none; overflow: hidden;">
      <label class="md-nav__title" for="nav-3">
        第三章:seq2seq经典架构
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./3_1.html" title="3.1 seq2seq实现baseline-1模型" class="md-nav__link">
      3.1 seq2seq实现baseline-1模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./3_2.html" title="3.2 baseline-1模型的优化" class="md-nav__link">
      3.2 baseline-1模型的优化
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4" checked="">
    
    <label class="md-nav__link" for="nav-4">
      第四章:PGN先进架构
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: block; overflow: visible;">
      <label class="md-nav__title" for="nav-4">
        第四章:PGN先进架构
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./4_1.html" title="4.1 PGN架构解析" class="md-nav__link">
      4.1 PGN架构解析
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./4_2.html" title="4.2 PGN模型的数据处理" class="md-nav__link">
      4.2 PGN模型的数据处理
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        4.3 PGN实现baseline-2模型
      </label>
    
    <a href="" title="4.3 PGN实现baseline-2模型" class="md-nav__link md-nav__link--active">
      4.3 PGN实现baseline-2模型
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix="">
      
        <li class="md-nav__item">
  <a href="#pgn" title="PGN模型的实现" class="md-nav__link">
    PGN模型的实现
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" title="学习目标" class="md-nav__link">
    学习目标
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pgn_1" title="PGN模型类创建" class="md-nav__link">
    PGN模型类创建
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#encoder" title="第一步: 编码器类Encoder" class="md-nav__link">
    第一步: 编码器类Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention" title="第二步: 注意力层类Attention" class="md-nav__link">
    第二步: 注意力层类Attention
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decoder" title="第三步: 解码器类Decoder" class="md-nav__link">
    第三步: 解码器类Decoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reducestate" title="第四步: 降维加和类ReduceState" class="md-nav__link">
    第四步: 降维加和类ReduceState
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pgn_2" title="第五步: 完整的PGN网络类" class="md-nav__link">
    第五步: 完整的PGN网络类
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pgn_3" title="PGN模型训练" class="md-nav__link">
    PGN模型训练
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#configpy" title="第一步: 配置文件config.py" class="md-nav__link">
    第一步: 配置文件config.py
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluatepy" title="第二步: 评估代码evaluate.py" class="md-nav__link">
    第二步: 评估代码evaluate.py
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trainpy" title="第三步: 训练代码train.py" class="md-nav__link">
    第三步: 训练代码train.py
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pgn_4" title="PGN模型预测" class="md-nav__link">
    PGN模型预测
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" title="小节总结" class="md-nav__link">
    小节总结
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      第五章:生成式模型的评估方法
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: none; overflow: hidden;">
      <label class="md-nav__title" for="nav-5">
        第五章:生成式模型的评估方法
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./5_1.html" title="5.1 文本摘要评估方法" class="md-nav__link">
      5.1 文本摘要评估方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./5_2.html" title="5.2 ROUGE评估算法实现" class="md-nav__link">
      5.2 ROUGE评估算法实现
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      第六章:模型的迭代优化
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: none; overflow: hidden;">
      <label class="md-nav__title" for="nav-6">
        第六章:模型的迭代优化
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./6_1.html" title="6.1 PGN + coverage的优化模型" class="md-nav__link">
      6.1 PGN + coverage的优化模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./6_2.html" title="6.2 PGN + beam-search的优化模型" class="md-nav__link">
      6.2 PGN + beam-search的优化模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./6_3.html" title="6.3 数据增强的优化" class="md-nav__link">
      6.3 数据增强的优化
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./6_4.html" title="6.4 训练策略的优化" class="md-nav__link">
      6.4 训练策略的优化
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7" type="checkbox" id="nav-7">
    
    <label class="md-nav__link" for="nav-7">
      第七章:模型的部署与总结
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: none; overflow: hidden;">
      <label class="md-nav__title" for="nav-7">
        第七章:模型的部署与总结
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./7_1.html" title="7.1 硬件优化与模型部署" class="md-nav__link">
      7.1 硬件优化与模型部署
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./7_2.html" title="7.2 项目总结" class="md-nav__link">
      7.2 项目总结
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc" style="height: 509px;">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix="">
      
        <li class="md-nav__item">
  <a href="#pgn" title="PGN模型的实现" class="md-nav__link">
    PGN模型的实现
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" title="学习目标" class="md-nav__link">
    学习目标
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pgn_1" title="PGN模型类创建" class="md-nav__link">
    PGN模型类创建
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#encoder" title="第一步: 编码器类Encoder" class="md-nav__link">
    第一步: 编码器类Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention" title="第二步: 注意力层类Attention" class="md-nav__link">
    第二步: 注意力层类Attention
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decoder" title="第三步: 解码器类Decoder" class="md-nav__link">
    第三步: 解码器类Decoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reducestate" title="第四步: 降维加和类ReduceState" class="md-nav__link">
    第四步: 降维加和类ReduceState
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pgn_2" title="第五步: 完整的PGN网络类" class="md-nav__link">
    第五步: 完整的PGN网络类
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pgn_3" title="PGN模型训练" class="md-nav__link">
    PGN模型训练
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#configpy" title="第一步: 配置文件config.py" class="md-nav__link">
    第一步: 配置文件config.py
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluatepy" title="第二步: 评估代码evaluate.py" class="md-nav__link">
    第二步: 评估代码evaluate.py
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trainpy" title="第三步: 训练代码train.py" class="md-nav__link">
    第三步: 训练代码train.py
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pgn_4" title="PGN模型预测" class="md-nav__link">
    PGN模型预测
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" title="小节总结" class="md-nav__link">
    小节总结
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>4.3 PGN实现baseline-2模型</h1>
                
                <h2 id="pgn">PGN模型的实现</h2>
<hr>
<h3 id="_1">学习目标</h3>
<ul>
<li>掌握PGN模型类的创建.</li>
<li>掌握对PGN实现文本摘要的训练过程.</li>
<li>掌握对PGN实现文本摘要的预测过程.</li>
</ul>
<hr>
<h3 id="pgn_1">PGN模型类创建</h3>
<ul>
<li>PGN模型的构建也要分别编写几个子层类:<ul>
<li>第一步: 编码器类Encoder.</li>
<li>第二步: 注意力层类Attention.</li>
<li>第三步: 解码器类Decoder.</li>
<li>第四步: 降维加和类ReduceState.</li>
<li>第五步: 完整的PGN网络类.</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>五个步骤的全部代码都在model.py中:<ul>
<li>代码文件路径: /home/ec2-user/text_summary/pgn/src/model.py</li>
</ul>
</li>
</ul>
<hr>
<h4 id="encoder">第一步: 编码器类Encoder</h4>
<ul>
<li>编码器类Encoder的创建:</li>
</ul>
<div class="codehilite" id="__code_0"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_0 pre, #__code_0 code"><span class="md-clipboard__message"></span></button><pre id="__code_1"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_1 pre, #__code_1 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 构建编码器类</span>
<span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">rnn_drop</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 词嵌入层采用跟随模型一起训练的模式</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="c1"># 编码器的主体采用单层, 双向LSTM结构</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">rnn_drop</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>
</code></pre></div>


<hr>
<h4 id="attention">第二步: 注意力层类Attention</h4>
<ul>
<li>注意力层类Attention的创建:</li>
</ul>
<div class="codehilite" id="__code_2"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_2 pre, #__code_2 code"><span class="md-clipboard__message"></span></button><pre id="__code_3"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_3 pre, #__code_3 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 构建注意力类</span>
<span class="k">class</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Attention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 定义前向传播层, 对应论文中的公式1中的Wh, Ws</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">hidden_units</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">hidden_units</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Ws</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">hidden_units</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">hidden_units</span><span class="p">)</span>
        <span class="c1"># 定义全连接层, 对应论文中的公式1中最外层的v</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">hidden_units</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">decoder_states</span><span class="p">,</span> <span class="n">encoder_output</span><span class="p">,</span> <span class="n">x_padding_masks</span><span class="p">):</span>
        <span class="n">h_dec</span><span class="p">,</span> <span class="n">c_dec</span> <span class="o">=</span> <span class="n">decoder_states</span>
        <span class="c1"># 将两个张量在最后一个维度拼接, 得到deocder state St: (1, batch_size, 2*hidden_units)</span>
        <span class="n">s_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">h_dec</span><span class="p">,</span> <span class="n">c_dec</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="c1"># 将batch_size置于第一个维度上: (batch_size, 1, 2*hidden_units)</span>
        <span class="n">s_t</span> <span class="o">=</span> <span class="n">s_t</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># 按照hi的维度扩展St的维度: (batch_size, seq_length, 2*hidden_units)</span>
        <span class="n">s_t</span> <span class="o">=</span> <span class="n">s_t</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">encoder_output</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

         <span class="c1"># 根据论文中的公式1来计算et, 总共有三步</span>
        <span class="c1"># 第一步: 分别经历各自的全连接层矩阵乘法</span>
        <span class="c1"># Wh * h_i: (batch_size, seq_length, 2*hidden_units)</span>
        <span class="n">encoder_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Wh</span><span class="p">(</span><span class="n">encoder_output</span><span class="o">.</span><span class="n">contiguous</span><span class="p">())</span>
        <span class="c1"># Ws * s_t: (batch_size, seq_length, 2*hidden_units)</span>
        <span class="n">decoder_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ws</span><span class="p">(</span><span class="n">s_t</span><span class="p">)</span>

        <span class="c1"># 第二步: 两部分执行加和运算</span>
        <span class="c1"># (batch_size, seq_length, 2*hidden_units)</span>
        <span class="n">attn_inputs</span> <span class="o">=</span> <span class="n">encoder_features</span> <span class="o">+</span> <span class="n">decoder_features</span>

        <span class="c1"># 第三步: 执行tanh运算和一个全连接层的运算</span>
        <span class="c1"># (batch_size, seq_length, 1)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">attn_inputs</span><span class="p">))</span>

        <span class="c1"># 得到score后, 执行论文中的公式2</span>
        <span class="c1"># (batch_size, seq_length)</span>
        <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># 添加一步执行padding mask的运算, 将编码器端无效的PAD字符全部遮掩掉</span>
        <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">attention_weights</span> <span class="o">*</span> <span class="n">x_padding_masks</span>

        <span class="c1"># 最整个注意力层执行一次正则化操作</span>
        <span class="n">normalization_factor</span> <span class="o">=</span> <span class="n">attention_weights</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">attention_weights</span> <span class="o">/</span> <span class="n">normalization_factor</span>

        <span class="c1"># 执行论文中的公式3,将上一步得到的attention distributon应用在encoder hidden states上,得到context_vector</span>
        <span class="c1"># (batch_size, 1, 2*hidden_units)</span>
        <span class="n">context_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">attention_weights</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">encoder_output</span><span class="p">)</span>
        <span class="c1"># (batch_size, 2*hidden_units)</span>
        <span class="n">context_vector</span> <span class="o">=</span> <span class="n">context_vector</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">context_vector</span><span class="p">,</span> <span class="n">attention_weights</span>
</code></pre></div>


<hr>
<h4 id="decoder">第三步: 解码器类Decoder</h4>
<ul>
<li>解码器类Decoder的创建:</li>
</ul>
<div class="codehilite" id="__code_4"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_4 pre, #__code_4 code"><span class="md-clipboard__message"></span></button><pre id="__code_5"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_5 pre, #__code_5 code"><span class="md-clipboard__message"></span></button><code><span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">enc_hidden_size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 解码器端也采用跟随模型一起训练的方式, 得到词嵌入层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>

        <span class="c1"># 解码器的主体结构采用单向LSTM, 区别于编码器端的双向LSTM</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="c1"># 因为要将decoder hidden state和context vector进行拼接, 因此需要3倍的hidden_size维度设置</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">pointer</span><span class="p">:</span>
            <span class="c1"># 因为要根据论文中的公式8进行运算, 所谓输入维度上匹配的是4 * hidden_size + embed_size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">w_gen</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="n">embed_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">decoder_states</span><span class="p">,</span> <span class="n">context_vector</span><span class="p">):</span>
        <span class="c1"># 首先计算Decoder的前向传播输出张量</span>
        <span class="n">decoder_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x_t</span><span class="p">)</span>
        <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">decoder_emb</span><span class="p">,</span> <span class="n">decoder_states</span><span class="p">)</span>

        <span class="c1"># 接下来就是论文中的公式4的计算.</span>
        <span class="c1"># 将context vector和decoder state进行拼接, (batch_size, 3*hidden_units)</span>
        <span class="n">decoder_output</span> <span class="o">=</span> <span class="n">decoder_output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="n">concat_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">decoder_output</span><span class="p">,</span> <span class="n">context_vector</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># 经历两个全连接层V和V1后,再进行softmax运算, 得到vocabulary distribution</span>
        <span class="c1"># (batch_size, hidden_units)</span>
        <span class="n">FF1_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W1</span><span class="p">(</span><span class="n">concat_vector</span><span class="p">)</span>
        <span class="c1"># (batch_size, vocab_size)</span>
        <span class="n">FF2_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W2</span><span class="p">(</span><span class="n">FF1_out</span><span class="p">)</span>
        <span class="c1"># (batch_size, vocab_size)</span>
        <span class="n">p_vocab</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">FF2_out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># 构造decoder state s_t.</span>
        <span class="n">h_dec</span><span class="p">,</span> <span class="n">c_dec</span> <span class="o">=</span> <span class="n">decoder_states</span>
        <span class="c1"># (1, batch_size, 2*hidden_units)</span>
        <span class="n">s_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">h_dec</span><span class="p">,</span> <span class="n">c_dec</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># p_gen是通过context vector h_t, decoder state s_t, decoder input x_t, 三个部分共同计算出来的.</span>
        <span class="c1"># 下面的部分是计算论文中的公式8.</span>
        <span class="n">p_gen</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">pointer</span><span class="p">:</span>
            <span class="c1"># 这里面采用了直接拼接3部分输入张量, 然后经历一个共同的全连接层w_gen, 和原始论文的计算不同.</span>
            <span class="c1"># 这也给了大家提示, 可以提高模型的复杂度, 完全模拟原始论文中的3个全连接层来实现代码.</span>
            <span class="n">x_gen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">context_vector</span><span class="p">,</span> <span class="n">s_t</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">decoder_emb</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">p_gen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w_gen</span><span class="p">(</span><span class="n">x_gen</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">p_vocab</span><span class="p">,</span> <span class="n">decoder_states</span><span class="p">,</span> <span class="n">p_gen</span>
</code></pre></div>


<hr>
<h4 id="reducestate">第四步: 降维加和类ReduceState</h4>
<ul>
<li>降维加和类ReduceState的创建:</li>
</ul>
<div class="codehilite" id="__code_6"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_6 pre, #__code_6 code"><span class="md-clipboard__message"></span></button><pre id="__code_7"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_7 pre, #__code_7 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 构造加和state的类, 方便模型运算</span>
<span class="k">class</span> <span class="nc">ReduceState</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ReduceState</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">hidden</span>
        <span class="n">h_reduced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">c_reduced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">h_reduced</span><span class="p">,</span> <span class="n">c_reduced</span><span class="p">)</span>
</code></pre></div>


<hr>
<h4 id="pgn_2">第五步: 完整的PGN网络类</h4>
<ul>
<li>PGN类的创建:</li>
</ul>
<div class="codehilite" id="__code_8"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_8 pre, #__code_8 code"><span class="md-clipboard__message"></span></button><pre id="__code_9"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_9 pre, #__code_9 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 导入系统工具包</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="c1"># 设置项目的root路径, 方便后续相关代码文件的导入</span>
<span class="n">root_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">root_path</span><span class="p">)</span>

<span class="c1"># 导入若干工具包</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>
<span class="c1"># 导入项目中的相关代码文件</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">config</span>
<span class="kn">from</span> <span class="nn">utils.func_utils</span> <span class="kn">import</span> <span class="n">timer</span><span class="p">,</span> <span class="n">replace_oovs</span>
<span class="kn">from</span> <span class="nn">utils.vocab</span> <span class="kn">import</span> <span class="n">Vocab</span>


<span class="c1"># 构建PGN类</span>
<span class="k">class</span> <span class="nc">PGN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PGN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 初始化字典对象</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">v</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">DEVICE</span>

        <span class="c1"># 依次初始化4个类对象</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="n">config</span><span class="o">.</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="n">config</span><span class="o">.</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduce_state</span> <span class="o">=</span> <span class="n">ReduceState</span><span class="p">()</span>

    <span class="c1"># 计算最终分布的函数</span>
    <span class="k">def</span> <span class="nf">get_final_distribution</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">p_gen</span><span class="p">,</span> <span class="n">p_vocab</span><span class="p">,</span> <span class="n">attention_weights</span><span class="p">,</span> <span class="n">max_oov</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">pointer</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">p_vocab</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># 进行p_gen概率值的裁剪, 具体取值范围可以调参</span>
        <span class="n">p_gen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">p_gen</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)</span>
        <span class="c1"># 接下来两行代码是论文中公式9的计算.</span>
        <span class="n">p_vocab_weighted</span> <span class="o">=</span> <span class="n">p_gen</span> <span class="o">*</span> <span class="n">p_vocab</span>
        <span class="c1"># (batch_size, seq_len)</span>
        <span class="n">attention_weighted</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p_gen</span><span class="p">)</span> <span class="o">*</span> <span class="n">attention_weights</span>

        <span class="c1"># 得到扩展后的单词概率分布(extended-vocab probability distribution)</span>
        <span class="c1"># extended_size = len(self.v) + max_oovs</span>
        <span class="n">extension</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_oov</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="c1"># (batch_size, extended_vocab_size)</span>
        <span class="n">p_vocab_extended</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">p_vocab_weighted</span><span class="p">,</span> <span class="n">extension</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># 根据论文中的公式9, 累加注意力值attention_weighted到对应的单词位置x</span>
        <span class="n">final_distribution</span> <span class="o">=</span> <span class="n">p_vocab_extended</span><span class="o">.</span><span class="n">scatter_add_</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="n">attention_weighted</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">final_distribution</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_len</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">len_oovs</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">num_batches</span><span class="p">,</span> <span class="n">teacher_forcing</span><span class="p">):</span>
        <span class="n">x_copy</span> <span class="o">=</span> <span class="n">replace_oovs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>
        <span class="n">x_padding_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="c1"># 第一步: 进行Encoder的编码计算</span>
        <span class="n">encoder_output</span><span class="p">,</span> <span class="n">encoder_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x_copy</span><span class="p">)</span>
        <span class="n">decoder_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduce_state</span><span class="p">(</span><span class="n">encoder_states</span><span class="p">)</span>
        <span class="c1"># 初始化每一步的损失值</span>
        <span class="n">step_losses</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># 第二步: 循环解码, 每一个时间步都经历注意力的计算, 解码器层的计算.</span>
        <span class="c1"># 初始化解码器的输入, 是ground truth中的第一列, 即真实摘要的第一个字符</span>
        <span class="n">x_t</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="c1"># 如果使用Teacher_forcing, 则每一个时间步用真实标签来指导训练</span>
            <span class="k">if</span> <span class="n">teacher_forcing</span><span class="p">:</span>
                <span class="n">x_t</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="n">t</span><span class="p">]</span>

            <span class="n">x_t</span> <span class="o">=</span> <span class="n">replace_oovs</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>
            <span class="n">y_t</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
            <span class="c1"># 通过注意力层计算context vector</span>
            <span class="n">context_vector</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">decoder_states</span><span class="p">,</span><span class="n">encoder_output</span><span class="p">,</span><span class="n">x_padding_masks</span><span class="p">)</span>

            <span class="c1"># 通过解码器层计算得到vocab distribution和hidden states</span>
            <span class="n">p_vocab</span><span class="p">,</span> <span class="n">decoder_states</span><span class="p">,</span> <span class="n">p_gen</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x_t</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">decoder_states</span><span class="p">,</span> <span class="n">context_vector</span><span class="p">)</span>

            <span class="c1"># 得到最终的概率分布</span>
            <span class="n">final_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_final_distribution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">p_gen</span><span class="p">,</span><span class="n">p_vocab</span><span class="p">,</span><span class="n">attention_weights</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">len_oovs</span><span class="p">))</span>

            <span class="c1"># 第t个时间步的预测结果, 将作为第t + 1个时间步的输入(如果采用Teacher-forcing则不同).</span>
            <span class="n">x_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">final_dist</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>

            <span class="c1"># 根据模型对target tokens的预测, 来获取到预测的概率</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">pointer</span><span class="p">:</span>
                <span class="n">y_t</span> <span class="o">=</span> <span class="n">replace_oovs</span><span class="p">(</span><span class="n">y_t</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>
            <span class="n">target_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">final_dist</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">y_t</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">target_probs</span> <span class="o">=</span> <span class="n">target_probs</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># 将解码器端的PAD用padding mask遮掩掉, 防止计算loss时的干扰</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">y_t</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span>
            <span class="c1"># 为防止计算log(0)而做的数学上的平滑处理</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">target_probs</span> <span class="o">+</span> <span class="n">config</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>

            <span class="c1"># 先遮掩, 再添加损失值</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">*</span> <span class="n">mask</span>
            <span class="n">step_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="c1"># 第三步: 计算一个批次样本的损失值, 为反向传播做准备.</span>
        <span class="n">sample_losses</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">step_losses</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># 统计非PAD的字符个数, 作为当前批次序列的有效长度</span>
        <span class="n">seq_len_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">batch_seq_len</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">seq_len_mask</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># 计算批次样本的平均损失值</span>
        <span class="n">batch_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample_losses</span> <span class="o">/</span> <span class="n">batch_seq_len</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">batch_loss</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_10"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_10 pre, #__code_10 code"><span class="md-clipboard__message"></span></button><pre id="__code_11"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_11 pre, #__code_11 code"><span class="md-clipboard__message"></span></button><code><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">Vocab</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">PGN</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_12"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_12 pre, #__code_12 code"><span class="md-clipboard__message"></span></button><pre id="__code_13"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_13 pre, #__code_13 code"><span class="md-clipboard__message"></span></button><code>PGN(
  (attention): Attention(
    (Wh): Linear(in_features=1024, out_features=1024, bias=False)
    (Ws): Linear(in_features=1024, out_features=1024, bias=True)
    (v): Linear(in_features=1024, out_features=1, bias=False)
  )
  (encoder): Encoder(
    (embedding): Embedding(4, 512)
    (lstm): LSTM(512, 512, batch_first=True, bidirectional=True)
  )
  (decoder): Decoder(
    (embedding): Embedding(4, 512)
    (lstm): LSTM(512, 512, batch_first=True)
    (W1): Linear(in_features=1536, out_features=512, bias=True)
    (W2): Linear(in_features=512, out_features=4, bias=True)
    (w_gen): Linear(in_features=2560, out_features=1, bias=True)
  )
  (reduce_state): ReduceState()
)
</code></pre></div>


<hr>
<blockquote>
<ul>
<li>结论: 搭建完整的PGN网络后, 发现本质上就是4个子层共同构成了PGN. 参数量主要集中在Attention和Decoder.</li>
</ul>
</blockquote>
<hr>
<hr>
<h3 id="pgn_3">PGN模型训练</h3>
<ul>
<li>完成了PGN模型类的构建后, 其实训练过程无非就是将数据迭代器DataLoader和模型类Model结合起来, 再加上"老三样"而已.</li>
</ul>
<hr>
<ul>
<li>整个训练模型的相关代码需要完成3个文件的编写:<ul>
<li>第一步: 配置文件config.py</li>
<li>第二步: 评估代码evaluate.py</li>
<li>第三步: 训练代码train.py</li>
</ul>
</li>
</ul>
<hr>
<h4 id="configpy">第一步: 配置文件config.py</h4>
<ul>
<li>代码文件路径: /home/ec2-user/text_summary/pgn/utils/config.py</li>
</ul>
<hr>
<div class="codehilite" id="__code_14"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_14 pre, #__code_14 code"><span class="md-clipboard__message"></span></button><pre id="__code_15"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_15 pre, #__code_15 code"><span class="md-clipboard__message"></span></button><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">root_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">root_path</span><span class="p">)</span>

<span class="c1"># 神经网络通用参数</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">dec_hidden_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">embed_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">pointer</span> <span class="o">=</span> <span class="bp">True</span>

<span class="c1"># 模型相关配置参数</span>
<span class="n">max_vocab_size</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s1">'pgn_model'</span>
<span class="n">embed_file</span> <span class="o">=</span> <span class="n">root_path</span> <span class="o">+</span> <span class="s1">'/wv/word2vec_pad.model'</span>
<span class="n">source</span> <span class="o">=</span> <span class="s1">'train'</span>
<span class="n">train_data_path</span> <span class="o">=</span> <span class="n">root_path</span> <span class="o">+</span> <span class="s1">'/data/train.txt'</span>
<span class="n">val_data_path</span> <span class="o">=</span> <span class="n">root_path</span> <span class="o">+</span> <span class="s1">'/data/dev.txt'</span>
<span class="n">test_data_path</span> <span class="o">=</span> <span class="n">root_path</span> <span class="o">+</span> <span class="s1">'/data/test.txt'</span>
<span class="n">stop_word_file</span> <span class="o">=</span> <span class="n">root_path</span> <span class="o">+</span> <span class="s1">'/data/stopwords.txt'</span>
<span class="n">losses_path</span> <span class="o">=</span> <span class="n">root_path</span> <span class="o">+</span> <span class="s1">'/data/loss.txt'</span>
<span class="n">log_path</span> <span class="o">=</span> <span class="n">root_path</span> <span class="o">+</span> <span class="s1">'/data/log_train.txt'</span>
<span class="n">word_vector_model_path</span> <span class="o">=</span> <span class="n">root_path</span> <span class="o">+</span> <span class="s1">'/wv/word2vec_pad.model'</span>
<span class="n">encoder_save_name</span> <span class="o">=</span> <span class="n">root_path</span> <span class="o">+</span> <span class="s1">'/saved_model/model_encoder.pt'</span>
<span class="n">decoder_save_name</span> <span class="o">=</span> <span class="n">root_path</span> <span class="o">+</span> <span class="s1">'/saved_model/model_decoder.pt'</span>
<span class="n">attention_save_name</span> <span class="o">=</span> <span class="n">root_path</span> <span class="o">+</span> <span class="s1">'/saved_model/model_attention.pt'</span>
<span class="n">reduce_state_save_name</span> <span class="o">=</span> <span class="n">root_path</span> <span class="o">+</span> <span class="s1">'/saved_model/model_reduce_state.pt'</span>
<span class="n">model_save_path</span> <span class="o">=</span> <span class="n">root_path</span> <span class="o">+</span> <span class="s1">'/saved_model/pgn_model.pt'</span>
<span class="n">max_enc_len</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">max_dec_len</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">truncate_enc</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">truncate_dec</span> <span class="o">=</span> <span class="bp">True</span>
<span class="c1"># 下面两个参数关系到predict阶段的展示效果, 需要按业务场景调参</span>
<span class="n">min_dec_steps</span> <span class="o">=</span> <span class="mi">30</span>
<span class="c1"># 在Greedy Decode的时候设置为50</span>
<span class="c1"># max_dec_steps = 50</span>
<span class="c1"># 在Beam-search Decode的时候设置为30</span>
<span class="n">max_dec_steps</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">enc_rnn_dropout</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">enc_attn</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">dec_attn</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">dec_in_dropout</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">dec_rnn_dropout</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">dec_out_dropout</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># 训练参数</span>
<span class="n">trunc_norm_init_std</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-31</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">lr_decay</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">initial_accumulator_value</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">is_cuda</span> <span class="o">=</span> <span class="bp">True</span>

<span class="c1"># 下面4个参数都是第六章的优化策略</span>
<span class="n">coverage</span> <span class="o">=</span> <span class="bp">False</span>
<span class="n">fine_tune</span> <span class="o">=</span> <span class="bp">False</span>
<span class="n">scheduled_sampling</span> <span class="o">=</span> <span class="bp">False</span>
<span class="n">weight_tying</span> <span class="o">=</span> <span class="bp">False</span>

<span class="n">max_grad_norm</span> <span class="o">=</span> <span class="mf">2.0</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
<span class="n">LAMBDA</span> <span class="o">=</span> <span class="mi">1</span>
</code></pre></div>


<hr>
<h4 id="evaluatepy">第二步: 评估代码evaluate.py</h4>
<ul>
<li>代码文件路径: /home/ec2-user/text_summary/pgn/src/evaluate.py</li>
</ul>
<hr>
<div class="codehilite" id="__code_16"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_16 pre, #__code_16 code"><span class="md-clipboard__message"></span></button><pre id="__code_17"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_17 pre, #__code_17 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 导入工具包</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="c1"># 设定项目的root路径, 方便后续代码文件的导入</span>
<span class="n">root_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">root_path</span><span class="p">)</span>

<span class="c1"># 导入项目的相关代码文件</span>
<span class="kn">from</span> <span class="nn">utils.dataset</span> <span class="kn">import</span> <span class="n">collate_fn</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">config</span>


<span class="c1"># 编写评估函数</span>
<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_data</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'validating'</span><span class="p">)</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># 评估模型需要设定参数不变</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">DEVICE</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">DEVICE</span>
        <span class="c1"># 创建数据迭代器, pin_memory=True是对于GPU机器的优化设置</span>
        <span class="c1"># 为了PGN模型数据的特殊性, 传入自定义的collate_fn提供个性化服务</span>
        <span class="n">val_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">val_data</span><span class="p">,</span>
                                    <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                    <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                    <span class="n">pin_memory</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                    <span class="n">drop_last</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">)</span>

        <span class="c1"># 遍历测试集数据进行评估</span>
        <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">val_dataloader</span><span class="p">)):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_len</span><span class="p">,</span> <span class="n">y_len</span><span class="p">,</span> <span class="n">oov</span><span class="p">,</span> <span class="n">len_oovs</span> <span class="o">=</span> <span class="n">data</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">is_cuda</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
                <span class="n">x_len</span> <span class="o">=</span> <span class="n">x_len</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
                <span class="n">len_oovs</span> <span class="o">=</span> <span class="n">len_oovs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
            <span class="n">total_num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_dataloader</span><span class="p">)</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_len</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">len_oovs</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">num_batches</span><span class="o">=</span><span class="n">total_num</span><span class="p">,</span> <span class="n">teacher_forcing</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">val_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="c1"># 返回整个测试集的平均损失值</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
</code></pre></div>


<hr>
<h4 id="trainpy">第三步: 训练代码train.py</h4>
<ul>
<li>代码文件路径: /home/ec2-user/text_summary/pgn/src/train.py </li>
</ul>
<hr>
<div class="codehilite" id="__code_18"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_18 pre, #__code_18 code"><span class="md-clipboard__message"></span></button><pre id="__code_19"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_19 pre, #__code_19 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 导入系统工具包</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="c1"># 设置项目的root路径, 方便后续相关代码文件的导入</span>
<span class="n">root_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">root_path</span><span class="p">)</span>

<span class="c1"># 导入项目中用到的工具包</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.nn.utils</span> <span class="kn">import</span> <span class="n">clip_grad_norm_</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">tensorboardX</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>

<span class="c1"># 导入项目中自定义的代码文件, 类, 函数等</span>
<span class="kn">from</span> <span class="nn">src.model</span> <span class="kn">import</span> <span class="n">PGN</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">config</span>
<span class="kn">from</span> <span class="nn">src.evaluate</span> <span class="kn">import</span> <span class="n">evaluate</span>
<span class="kn">from</span> <span class="nn">utils.dataset</span> <span class="kn">import</span> <span class="n">PairDataset</span><span class="p">,</span> <span class="n">collate_fn</span><span class="p">,</span> <span class="n">SampleDataset</span>
<span class="kn">from</span> <span class="nn">utils.func_utils</span> <span class="kn">import</span> <span class="n">config_info</span>


<span class="c1"># 编写训练模型的主逻辑函数.</span>
<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">val_dataset</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">start_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">DEVICE</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">DEVICE</span>

    <span class="c1"># 实例化PGN类对象并移动到GPU上(CPU).</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">PGN</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">"loading data......"</span><span class="p">)</span>
    <span class="n">train_data</span> <span class="o">=</span> <span class="n">SampleDataset</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">pairs</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
    <span class="n">val_data</span> <span class="o">=</span> <span class="n">SampleDataset</span><span class="p">(</span><span class="n">val_dataset</span><span class="o">.</span><span class="n">pairs</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">"initializing optimizer......"</span><span class="p">)</span>

    <span class="c1"># 定义模型训练的优化器.</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="c1"># 定义训练集的数据迭代器(这里用到了自定义的collate_fn以服务于PGN特殊的数据结构).</span>
    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span>
                                  <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                  <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                  <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">)</span>

    <span class="c1"># 验证集上的损失值初始化为一个大整数.</span>
    <span class="n">val_losses</span> <span class="o">=</span> <span class="mf">10000000.0</span>

    <span class="c1"># SummaryWriter: 为服务于TensorboardX写日志的可视化工具.</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">log_path</span><span class="p">)</span>

    <span class="n">num_epochs</span> <span class="o">=</span>  <span class="nb">len</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">epochs</span><span class="p">))</span>

    <span class="c1"># 训练阶段采用Teacher-forcing的策略</span>
    <span class="n">teacher_forcing</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'teacher_forcing = {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">teacher_forcing</span><span class="p">))</span>

    <span class="c1"># 根据配置文件config.py中的设置, 对整个数据集进行一定轮次的迭代训练.</span>
    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">epochs</span><span class="p">)</span> <span class="k">as</span> <span class="n">epoch_progress</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>
            <span class="c1"># 每一个epoch之前打印模型训练的相关配置信息.</span>
            <span class="k">print</span><span class="p">(</span><span class="n">config_info</span><span class="p">(</span><span class="n">config</span><span class="p">))</span>

            <span class="c1"># 初始化每一个batch损失值的存放列表</span>
            <span class="n">batch_losses</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span>

            <span class="c1"># 针对每一个epoch, 按batch读取数据迭代训练模型</span>
            <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">num_batches</span><span class="o">//</span><span class="mi">100</span><span class="p">)</span> <span class="k">as</span> <span class="n">batch_progress</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)):</span>
                    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_len</span><span class="p">,</span> <span class="n">y_len</span><span class="p">,</span> <span class="n">oov</span><span class="p">,</span> <span class="n">len_oovs</span> <span class="o">=</span> <span class="n">data</span>
                    <span class="k">assert</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>

                    <span class="c1"># 如果配置有GPU, 则加速训练</span>
                    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">is_cuda</span><span class="p">:</span>
                        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
                        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
                        <span class="n">x_len</span> <span class="o">=</span> <span class="n">x_len</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
                        <span class="n">len_oovs</span> <span class="o">=</span> <span class="n">len_oovs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

                    <span class="c1"># 设置模型进入训练模式(参数参与反向传播和更新)</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

                    <span class="c1"># "老三样"中的第一步: 梯度清零</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                    <span class="c1"># 调用模型进行训练并返回损失值</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_len</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
                                 <span class="n">len_oovs</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
                                 <span class="n">num_batches</span><span class="o">=</span><span class="n">num_batches</span><span class="p">,</span>
                                 <span class="n">teacher_forcing</span><span class="o">=</span><span class="n">teacher_forcing</span><span class="p">)</span>

                    <span class="n">batch_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

                    <span class="c1"># "老三样"中的第二步: 反向传播</span>
                    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

                    <span class="c1"># 为防止梯度爆炸(gradient explosion)而进行梯度裁剪.</span>
                    <span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">config</span><span class="o">.</span><span class="n">max_grad_norm</span><span class="p">)</span>
                    <span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">config</span><span class="o">.</span><span class="n">max_grad_norm</span><span class="p">)</span>
                    <span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">config</span><span class="o">.</span><span class="n">max_grad_norm</span><span class="p">)</span>

                    <span class="c1"># "老三样"中的第三步: 参数更新</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                    <span class="c1"># 每隔100个batch记录一下损失值信息.</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">batch</span> <span class="o">%</span> <span class="mi">100</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">batch_progress</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="n">f</span><span class="s1">'Epoch {epoch}'</span><span class="p">)</span>
                        <span class="n">batch_progress</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">Batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">Loss</span><span class="o">=</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                        <span class="n">batch_progress</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
                        <span class="c1"># 向tensorboard中写入损失值信息.</span>
                        <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="n">f</span><span class="s1">'Average loss for epoch {epoch}'</span><span class="p">,</span>
                                           <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">batch_losses</span><span class="p">),</span>
                                           <span class="n">global_step</span><span class="o">=</span><span class="n">batch</span><span class="p">)</span>

            <span class="c1"># 将一个轮次中所有batch的平均损失值作为这个epoch的损失值.</span>
            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">batch_losses</span><span class="p">)</span>

            <span class="n">epoch_progress</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="n">f</span><span class="s1">'Epoch {epoch}'</span><span class="p">)</span>
            <span class="n">epoch_progress</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">Loss</span><span class="o">=</span><span class="n">epoch_loss</span><span class="p">)</span>
            <span class="n">epoch_progress</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

            <span class="c1"># 结束每一个epoch训练后, 直接在验证集上跑一下模型效果</span>
            <span class="n">avg_val_loss</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_data</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>

            <span class="k">print</span><span class="p">(</span><span class="s1">'training loss:{}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">),</span> <span class="s1">'validation loss:{}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">avg_val_loss</span><span class="p">))</span>

            <span class="c1"># 更新更小的验证集损失值evaluating loss.</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">avg_val_loss</span> <span class="o">&lt;</span> <span class="n">val_losses</span><span class="p">):</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">encoder_save_name</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">decoder</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">decoder_save_name</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">attention</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">attention_save_name</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">reduce_state</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">reduce_state_save_name</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">config</span><span class="o">.</span><span class="n">model_save_path</span><span class="p">)</span>
                <span class="n">val_losses</span> <span class="o">=</span> <span class="n">avg_val_loss</span>

                <span class="c1"># 将更小的损失值写入文件中</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">losses_path</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">val_losses</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

    <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_20"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_20 pre, #__code_20 code"><span class="md-clipboard__message"></span></button><pre id="__code_21"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_21 pre, #__code_21 code"><span class="md-clipboard__message"></span></button><code><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
    <span class="n">DEVICE</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'DEVICE: '</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">)</span>

    <span class="c1"># 构建训练用的数据集对</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">PairDataset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">train_data_path</span><span class="p">,</span>
                          <span class="n">max_enc_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_enc_len</span><span class="p">,</span>
                          <span class="n">max_dec_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_dec_len</span><span class="p">,</span>
                          <span class="n">truncate_enc</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">truncate_enc</span><span class="p">,</span>
                          <span class="n">truncate_dec</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">truncate_dec</span><span class="p">)</span>

    <span class="c1"># 构建测试用的数据集对</span>
    <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">PairDataset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">val_data_path</span><span class="p">,</span>
                              <span class="n">max_enc_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_enc_len</span><span class="p">,</span>
                              <span class="n">max_dec_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_dec_len</span><span class="p">,</span>
                              <span class="n">truncate_enc</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">truncate_enc</span><span class="p">,</span>
                              <span class="n">truncate_dec</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">truncate_dec</span><span class="p">)</span>

    <span class="c1"># 创建模型的单词字典</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">embed_file</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">embed_file</span><span class="p">)</span>

    <span class="c1"># 调用训练函数进行训练并测试</span>
    <span class="n">train</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">val_dataset</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">start_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>


<hr>
<blockquote>
<ul>
<li>注意: 当前设置的batch_size = 64, 在本项目中报错, 说明16GB显存大小的GPU无法支持, 只能减小到batch_size = 32.</li>
</ul>
</blockquote>
<div class="codehilite" id="__code_22"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_22 pre, #__code_22 code"><span class="md-clipboard__message"></span></button><pre id="__code_23"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_23 pre, #__code_23 code"><span class="md-clipboard__message"></span></button><code>RuntimeError: CUDA out of memory. Tried to allocate 76.00 MiB (GPU 0; 14.76 GiB total capacity; 13.93 GiB already allocated; 9.75 MiB free; 13.99 GiB reserved in total by PyTorch)
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_24"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_24 pre, #__code_24 code"><span class="md-clipboard__message"></span></button><pre id="__code_25"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_25 pre, #__code_25 code"><span class="md-clipboard__message"></span></button><code>DEVICCE:  cuda
Reading dataset /home/ec2-user/text_summary/pgn/data/train.txt... 70000 pairs.
Reading dataset /home/ec2-user/text_summary/pgn/data/dev.txt...
0%|          | 0/8 [00:00&lt;?, ?it/s]

0%|          | 0/2188 [00:00&lt;?, ?it/s]

[[Epoch 0:   0%|          | 0/21 [00:01&lt;?, ?it/s]
[[Epoch 0:   0%|          | 0/21 [00:01&lt;?, ?it/s, Batch=0, Loss=5.64]
[[Epoch 0:   5%|▍         | 1/21 [00:01&lt;00:32,  1.63s/it, Batch=0, Loss=5.64]

[[[[0%|          | 1/2188 [00:01&lt;59:29,  1.63s/it]
[[[[0%|          | 2/2188 [00:03&lt;57:50,  1.59s/it]
[[[[0%|          | 3/2188 [00:04&lt;53:04,  1.46s/it]
[[[[0%|          | 4/2188 [00:06&lt;1:03:04,  1.73s/it]
[[[[0%|          | 5/2188 [00:08&lt;1:01:03,  1.68s/it]


......
......
......

[[[[100%|█████████▉| 2186/2188 [1:00:34&lt;00:03,  1.93s/it]
[[[[100%|█████████▉| 2187/2188 [1:00:35&lt;00:01,  1.68s/it]
[[[[100%|██████████| 2188/2188 [1:00:35&lt;00:00,  1.36s/it]
[[[[100%|██████████| 2188/2188 [1:00:35&lt;00:00,  1.66s/it]
Epoch 0: : 22it [1:00:35, 165.27s/it, Batch=2100, Loss=3.46]
Epoch 0:   0%|          | 0/8 [1:00:35&lt;?, ?it/s]
Epoch 0:   0%|          | 0/8 [1:00:35&lt;?, ?it/s, Loss=3.49]
Epoch 0:  12%|█▎        | 1/8 [1:00:35&lt;7:04:11, 3635.92s/it, Loss=3.49]
[[0%|          | 0/402 [00:00&lt;?, ?it/s]
[[0%|          | 1/402 [00:00&lt;02:20,  2.85it/s]
[[0%|          | 2/402 [00:01&lt;03:41,  1.81it/s]
[[1%|          | 3/402 [00:02&lt;03:51,  1.72it/s]
[[1%|          | 4/402 [00:02&lt;04:32,  1.46it/s]
[[1%|          | 5/402 [00:03&lt;04:49,  1.37it/s]
[[1%|▏         | 6/402 [00:04&lt;04:02,  1.63it/s]^[[A


......
......
......


[[[[100%|█████████▉| 2186/2188 [1:00:50&lt;00:03,  1.61s/it]
[[[[100%|█████████▉| 2187/2188 [1:00:51&lt;00:01,  1.57s/it]
[[[[100%|██████████| 2188/2188 [1:00:52&lt;00:00,  1.41s/it]
[[[[100%|██████████| 2188/2188 [1:00:52&lt;00:00,  1.67s/it]
Epoch 7: : 22it [1:00:52, 166.03s/it, Batch=2100, Loss=1.22]
Epoch 7:  88%|████████▊ | 7/8 [8:33:08&lt;1:04:10, 3850.63s/it, Loss=1.34]
Epoch 7:  88%|████████▊ | 7/8 [8:33:08&lt;1:04:10, 3850.63s/it, Loss=1.22]
Epoch 7: 100%|██████████| 8/8 [8:33:08&lt;00:00, 3860.46s/it, Loss=1.22]
[[0%|          | 0/402 [00:00&lt;?, ?it/s]
[[0%|          | 1/402 [00:00&lt;05:03,  1.32it/s]
[[0%|          | 2/402 [00:01&lt;04:27,  1.49it/s]
[[1%|          | 3/402 [00:01&lt;03:59,  1.67it/s]
[[1%|          | 4/402 [00:02&lt;03:46,  1.75it/s]
[[1%|          | 5/402 [00:02&lt;03:41,  1.79it/s]
[[1%|▏         | 6/402 [00:03&lt;03:39,  1.80it/s]
[[2%|▏         | 7/402 [00:03&lt;03:22,  1.95it/s]
[[2%|▏         | 8/402 [00:04&lt;03:17,  1.99it/s]


......
......
......


[[99%|█████████▊| 396/402 [03:46&lt;00:03,  1.87it/s]
[[99%|█████████▉| 397/402 [03:46&lt;00:02,  1.96it/s]
[[99%|█████████▉| 398/402 [03:47&lt;00:02,  1.92it/s]
[[99%|█████████▉| 399/402 [03:48&lt;00:01,  1.57it/s]
[[100%|█████████▉| 400/402 [03:48&lt;00:01,  1.74it/s]
[[100%|█████████▉| 401/402 [03:49&lt;00:00,  1.90it/s]
[[100%|██████████| 402/402 [03:49&lt;00:00,  2.11it/s]
[[100%|██████████| 402/402 [03:49&lt;00:00,  1.75it/s]
^MEpoch 7: 100%|██████████| 8/8 [8:36:57&lt;00:00, 3877.20s/it, Loss=1.22]
12870 pairs.
loading data......
initializing optimizer......
model_name = pgn_model, pointer = True, coverage = False, fine_tune = False, scheduled_sampling = False, weight_tying = False,source = train
teacher_forcing = True
validating
training loss:3.4892952252567575 validation loss:3.344072110024258
model_name = pgn_model, pointer = True, coverage = False, fine_tune = False, scheduled_sampling = False, weight_tying = False,source = train
teacher_forcing = True
validating
training loss:2.835234389444592 validation loss:3.267519224342422
model_name = pgn_model, pointer = True, coverage = False, fine_tune = False, scheduled_sampling = False, weight_tying = False,source = train
teacher_forcing = True
validating
training loss:2.4213740300434816 validation loss:3.3334008900087273
model_name = pgn_model, pointer = True, coverage = False, fine_tune = False, scheduled_sampling = False, weight_tying = False,source = train
teacher_forcing = True
validating
training loss:2.0445967139012198 validation loss:3.5206758821781596
model_name = pgn_model, pointer = True, coverage = False, fine_tune = False, scheduled_sampling = False, weight_tying = False,source = train
teacher_forcing = True
validating
training loss:1.7436198293617917 validation loss:3.7173273100781796
model_name = pgn_model, pointer = True, coverage = False, fine_tune = False, scheduled_sampling = False, weight_tying = False,source = train
teacher_forcing = True
validating
training loss:1.516176729386424 validation loss:3.9629455300705945
model_name = pgn_model, pointer = True, coverage = False, fine_tune = False, scheduled_sampling = False, weight_tying = False,source = train
teacher_forcing = True
validating
training loss:1.3425214516724266 validation loss:4.164657424338421
model_name = pgn_model, pointer = True, coverage = False, fine_tune = False, scheduled_sampling = False, weight_tying = False,source = train
teacher_forcing = True
validating
training loss:1.215759369011771 validation loss:4.379757683075483
</code></pre></div>


<hr>
<ul>
<li>查看GPU的运行信息: nvidia-smi</li>
</ul>
<div class="codehilite" id="__code_26"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_26 pre, #__code_26 code"><span class="md-clipboard__message"></span></button><pre id="__code_27"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_27 pre, #__code_27 code"><span class="md-clipboard__message"></span></button><code>+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:00:08.0 Off |                    0 |
| N/A   68C    P0    68W /  70W |  14336MiB / 15109MiB |     95%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A     13392      C   python                          14333MiB |
+-----------------------------------------------------------------------------+
</code></pre></div>


<hr>
<blockquote>
<ul>
<li>模型训练结论: 随着训练的进行, 训练集损失值一路下降, 但是注意到在关键的验证集上, 我们的最小损失值在第2个epoch出现, 后续反倒一路上升, 可以认为出现了过拟合的现象. 因此在当前任务, 当前数据集的情况下, 后续保持3-4个epoch训练模型即可.</li>
</ul>
</blockquote>
<hr>
<hr>
<h3 id="pgn_4">PGN模型预测</h3>
<ul>
<li>当PGN模型训练结束后, 就可以在测试集上进行预测了.<ul>
<li>代码文件路径: /home/ec2-user/text_summary/pgn/src/predict.py</li>
</ul>
</li>
</ul>
<hr>
<div class="codehilite" id="__code_28"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_28 pre, #__code_28 code"><span class="md-clipboard__message"></span></button><pre id="__code_29"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_29 pre, #__code_29 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 导入工具包</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">jieba</span>

<span class="c1"># 设定项目的root路径, 方便后续相关代码文件的导入</span>
<span class="n">root_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">root_path</span><span class="p">)</span>

<span class="c1"># 导入项目的相关代码文件</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">config</span>
<span class="kn">from</span> <span class="nn">src.model</span> <span class="kn">import</span> <span class="n">PGN</span>
<span class="kn">from</span> <span class="nn">utils.dataset</span> <span class="kn">import</span> <span class="n">PairDataset</span>
<span class="kn">from</span> <span class="nn">utils.func_utils</span> <span class="kn">import</span> <span class="n">source2ids</span><span class="p">,</span> <span class="n">outputids2words</span><span class="p">,</span> <span class="n">timer</span><span class="p">,</span> <span class="n">add2heap</span><span class="p">,</span> <span class="n">replace_oovs</span>


<span class="c1"># 构建预测类</span>
<span class="k">class</span> <span class="nc">Predict</span><span class="p">():</span>
    <span class="nd">@timer</span><span class="p">(</span><span class="n">module</span><span class="o">=</span><span class="s1">'initalize predicter'</span><span class="p">)</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">DEVICE</span>

        <span class="n">dataset</span> <span class="o">=</span> <span class="n">PairDataset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">train_data_path</span><span class="p">,</span>
                              <span class="n">max_enc_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_enc_len</span><span class="p">,</span>
                              <span class="n">max_dec_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_dec_len</span><span class="p">,</span>
                              <span class="n">truncate_enc</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">truncate_enc</span><span class="p">,</span>
                              <span class="n">truncate_dec</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">truncate_dec</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">embed_file</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">embed_file</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">PGN</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop_word</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">strip</span><span class="p">()]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">stop_word_file</span><span class="p">)</span><span class="o">.</span><span class="n">readlines</span><span class="p">()]))</span>

        <span class="c1"># 导入已经训练好的模型, 并转移到GPU上.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">model_save_path</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">greedy_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">max_sum_len</span><span class="p">,</span> <span class="n">len_oovs</span><span class="p">,</span> <span class="n">x_padding_masks</span><span class="p">):</span>
        <span class="n">encoder_output</span><span class="p">,</span> <span class="n">encoder_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">replace_oovs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">))</span>

        <span class="c1"># 用encoder的hidden state初始化decoder的hidden state</span>
        <span class="n">decoder_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reduce_state</span><span class="p">(</span><span class="n">encoder_states</span><span class="p">)</span>

        <span class="c1"># 利用SOS作为解码器的初始化输入字符</span>
        <span class="n">x_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">SOS</span>
        <span class="n">x_t</span> <span class="o">=</span> <span class="n">x_t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">summary</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">SOS</span><span class="p">]</span>

        <span class="c1"># 循环解码, 最多解码max_sum_len步</span>
        <span class="k">while</span> <span class="nb">int</span><span class="p">(</span><span class="n">x_t</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="o">!=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">EOS</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">max_sum_len</span><span class="p">:</span>
            <span class="n">context_vector</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">decoder_states</span><span class="p">,</span>
                                                                     <span class="n">encoder_output</span><span class="p">,</span>
                                                                     <span class="n">x_padding_masks</span><span class="p">)</span>

            <span class="n">p_vocab</span><span class="p">,</span> <span class="n">decoder_states</span><span class="p">,</span> <span class="n">p_gen</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x_t</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
                                                                <span class="n">decoder_states</span><span class="p">,</span>
                                                                <span class="n">context_vector</span><span class="p">)</span>

            <span class="n">final_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_final_distribution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p_gen</span><span class="p">,</span> <span class="n">p_vocab</span><span class="p">,</span>
                                                           <span class="n">attention_weights</span><span class="p">,</span>
                                                           <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">len_oovs</span><span class="p">))</span>

            <span class="c1"># 以贪心解码策略预测字符</span>
            <span class="n">x_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">final_dist</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
            <span class="n">decoder_word_idx</span> <span class="o">=</span> <span class="n">x_t</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

            <span class="c1"># 将预测的字符添加进结果摘要中</span>
            <span class="n">summary</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decoder_word_idx</span><span class="p">)</span>
            <span class="n">x_t</span> <span class="o">=</span> <span class="n">replace_oovs</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">summary</span>

    <span class="nd">@timer</span><span class="p">(</span><span class="n">module</span><span class="o">=</span><span class="s1">'doing prediction'</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">tokenize</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>

        <span class="c1"># 将原始文本映射成数字化张量</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">oov</span> <span class="o">=</span> <span class="n">source2ids</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>

        <span class="c1"># 获取OOV的长度和padding mask张量</span>
        <span class="n">len_oovs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">oov</span><span class="p">)])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">x_padding_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="c1"># 利用贪心解码函数得到摘要结果.</span>
        <span class="n">summary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_search</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                                     <span class="n">max_sum_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_dec_steps</span><span class="p">,</span>
                                     <span class="n">len_oovs</span><span class="o">=</span><span class="n">len_oovs</span><span class="p">,</span>
                                     <span class="n">x_padding_masks</span><span class="o">=</span><span class="n">x_padding_masks</span><span class="p">)</span>

        <span class="c1"># 将得到的摘要数字化张量转换成自然语言文本</span>
        <span class="n">summary</span> <span class="o">=</span> <span class="n">outputids2words</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="n">oov</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>

        <span class="c1"># 删除掉特殊字符&lt;SOS&gt;和&lt;EOS&gt;</span>
        <span class="k">return</span> <span class="n">summary</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'&lt;SOS&gt;'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'&lt;EOS&gt;'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_30"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_30 pre, #__code_30 code"><span class="md-clipboard__message"></span></button><pre id="__code_31"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_31 pre, #__code_31 code"><span class="md-clipboard__message"></span></button><code><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'实例化Predict对象, 构建dataset和vocab......'</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">Predict</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'vocab_size: '</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">vocab</span><span class="p">))</span>
    <span class="c1"># Randomly pick a sample in test set to predict.</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">val_data_path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">test</span><span class="p">:</span>
        <span class="n">picked</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">test</span><span class="p">))</span>
        <span class="n">source</span><span class="p">,</span> <span class="n">ref</span> <span class="o">=</span> <span class="n">picked</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'&lt;SEP&gt;'</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s1">'source: '</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'---------------------------------------------------------------'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'ref: '</span><span class="p">,</span> <span class="n">ref</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'---------------------------------------------------------------'</span><span class="p">)</span>
    <span class="n">greedy_prediction</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">source</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'greedy: '</span><span class="p">,</span> <span class="n">greedy_prediction</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_32"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_32 pre, #__code_32 code"><span class="md-clipboard__message"></span></button><pre id="__code_33"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_33 pre, #__code_33 code"><span class="md-clipboard__message"></span></button><code>实例化Predict对象, 构建dataset和vocab......
Reading dataset /home/ec2-user/text_summary/pgn/data/train.txt... 70000 pairs.
9.547770738601685 secs used for  initalize predicter
vocab_size:  20004
source:  18 款 斯柯达 明锐 旅行 版 ， 通电 时 发动机 舱内 会 呜呜 响 ， 重新 通电 后 异响 消失 。 280tsi 豪华版 ， 车主 。 异响 持续 时间 不会 很长 ， ？ 属于 用电器 接通 电源 工作 声音 ， 仪表 里面 后面 汽油 泵 发出 。 响声 会 车 打着 以后 存在 ， 存在 ， 建议您 去 检查一下 ， 看 是不是 接通 电源 之后 ， 用电器 工作 引起 共振 。 位置 打开 引擎盖 看 一下 。 加 冷却液 下面 一点 位置 检测 状态 ， 属于 正常 ， 持续时间 5 10 秒 冷却液 下面 一点 位置 ， 没 问题 。 响 不会 响去 检查 检查 不 出来 大众 斯 科达 现在 新车 ， 冷却液 基本 都 下 刻度 线下 一点点 。 ， 上面 操作 一下 试试 。 加 冷却液 地方 下面 一点 地方 响用 扎 带 扎起来 。 EA211 发动机 很多 都 地方 共振 ， 试试 。 看到 我发 。 意思 管子 响 ？ 看到 谢谢 客气 ， 车 扎起来 。 管子 发出 声音 ？ 管子 产生 共振 。 有时候 响 ， 有时候 不响 ， 响 关了 电门 重新 通电 以后 不会 响 感觉 电流 声放 不 方便 加 一下 微信 录音 听听 ， 响 间歇性 。 好 ， 谢谢 请问 一下 换 机油 时 换 30 40 比较 好 一点 跑 一万八千 公里 差不多 都 加 0.5 升 机油 跑 八千 公里 不是 一万八千 新车 建议 使用 30 ， 粘稠度 低 一点 ， 增加 发动机 润滑 ， 降低 发动机 磨损 平台 相关 规定 ， 无法 留下 联系方式 地址 ， 请 谅解 8000 公里 消耗 0.6 升 机油 算 正常 ？ 不 ， 1.41 . 4T 高功率 发动机 ， 没有 出现 烧 机油 现象 。 机油 冷车 看 热车 看 ？ 冷车 看 全部 看 都 冷车 看 加个 weixin ？ 973788701 冷车 看 ， 机油 消耗 不 正常 。 这种 办法 维权 ？ 去 检测 ， 检测 问题 ， 免费 维修 更换 发动机 。 下次 保养 4s店 称重 ？ 说 出现 烧 机油 现象 ， 师傅 会 做 相关 检测 。 上次 说 4s店 一点 ， 不够 加点 。 。 。 。 去 ！ 8000km 加 0.6 L 机油 。 都 不到 机油 尺 目前 8000km 目前 车子 开 8000km ？ 总共 跑 一万二 。 首保 过后 跑 八千 不到 点 ！ 想会 不会 30 机油 太稀 容易 蒸发 EA211 涡轮 增压 发动机 烧 机油 可能性 很小 ， 加 发动机 抗磨损 剂 使用 。 30 机油 ， 嘉实多 极护 5w 30 。 我用 4s店 极护 感觉 有点 怪 ， 正面 英文版 进口 。 问 说 厂家 发 背面 中文 不是 进口 中文 标签 纸 ？ 不是 师傅 发现 灯 响 副 驾 自动 头灯 开着 会响 。 关 以后 重新 打开 不响 原车 氙气灯 ？ 原车 led 没有 改过 原车 led LED 灯 灯光 响 ， 灯头 问题 ， BCM 控制器 控制 大灯 参数 问题 。 无论是 一种 ， 都 需要 检查 。 好 谢谢 。 客气 。 

---------------------------------------------------------------
ref:  描述 对话 ， 建议 检查 副 水壶 下面 油管 ， 很多 EA211 发动机 油管 都 震动 问题 。 灯光 灯头 声音 ， 建议 检查 灯头 BCM 控制器 。 

---------------------------------------------------------------
0.14189767837524414 secs used for  doing prediction
greedy:  ， BCM 发动机 内部 ， 电源 ， 引起 ， 需要 检查 发动机 是否 烧 机油 ， 建议 更换 。 ， 建议 使用 30 ， 粘稠度 低 ， 增加 发动机 烧 机油 。 降低 油耗 。 增加 发动机 烧 机油 。 降低 油耗 。 消耗 ， 建议 去 修理厂 检查 ， 质量 问题 ， 免费 保修 
</code></pre></div>


<hr>
<blockquote>
<ul>
<li>模型预测结论: PGN模型的预测效果相比于seq2seq已经有了很大的进步, 但是重复描述同一个短语的问题依然还在, 需要后续的进一步优化.</li>
</ul>
</blockquote>
<hr>
<hr>
<h3 id="_2">小节总结</h3>
<ul>
<li>小节总结: 4.3小节实现了PGN模型的搭建, 并完整的训练出baseline-2模型, 效果得到了很大的改进, 但仍有不足.</li>
</ul>
<hr>
<hr>
<hr>
<hr>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="./4_2.html" title="4.2 PGN模型的数据处理" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  上一页
                </span>
                4.2 PGN模型的数据处理
              </span>
            </div>
          </a>
        
        
          <a href="./5_1.html" title="5.1 文本摘要评估方法" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  下一页
                </span>
                5.1 文本摘要评估方法
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            ©Copyright 2020, AITutorials.CN This website has been reviewed by the review agency. 京ICP备19006137号
          </div>
        
        powered by
        <a href="https://www.mkdocs.org/">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="./index_files/font-awesome.css">
    
      <a href="https://www.linkedin.com/in/%E7%A7%91%E6%8A%80%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8-%E5%8C%97%E4%BA%AC%E6%A9%98%E6%98%9F-6bb7081a1/" class="md-footer-social__link fa fa-linkedin"></a>
    
      <a href="https://weibo.com/u/3469990762?is_all=1" class="md-footer-social__link fa fa-weibo"></a>
    
      <a href="http://bitbucket.org/AITutorials" class="md-footer-social__link fa fa-bitbucket"></a>
    
      <a href="https://github.com/AITutorials/datasets/issues" class="md-footer-social__link fa fa-gitlab"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="./index_files/application.245445c6.js"></script>
      
        
        
          
          <script src="./index_files/lunr.stemmer.support.js"></script>
          
            
              
                <script src="./index_files/tinyseg.js"></script>
              
              
                <script src="./index_files/lunr.ja.js"></script>
              
            
          
          
        
      
      <script>app.initialize({version:"1.1.2",url:{base:".."}})</script>
      
    
  
</body></html>