<!DOCTYPE html>
<!-- saved from url=(0031)http://121.199.45.168:8818/3_1/ -->
<html lang="zh" class="js json svg checked target dataset details fetch supports csstransforms3d no-ios" style=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
      
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
        <link rel="canonical" href="http://0.0.0.0:8818/3_1/">
      
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="ja">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="./index_files/AI.jpg">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-4.4.0">
    
    
      
        <title>3.1 seq2seq实现baseline-1模型 - 文本摘要项目</title>
      
    
    
      <link rel="stylesheet" href="./index_files/application.0284f74d.css">
      
      
    
    
      <script src="./index_files/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin="">
        <link rel="stylesheet" href="./index_files/css">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="./index_files/material-icons.css">
    
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "UA-36723568-3", "mkdocs.org")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async="" src="./index_files/analytics.js"></script>
      
    
    
  <script type="text/javascript">(function(){var s=document.createElement("script");var port=window.location.port;s.src="//"+window.location.hostname+":"+port+ "/livereload.js?port=" + port;document.head.appendChild(s);})();</script><script src="./index_files/livereload.js"></script></head>
  
    <body dir="ltr" data-md-state="">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"></path></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#seq2seq" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header" data-md-state="shadow">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="./1_1.html" title="文本摘要项目" class="md-header-nav__button md-logo">
          
            <img src="./index_files/AI.jpg" width="24" height="24">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic" style="width: 648px;">
              文本摘要项目
            </span>
            <span class="md-header-nav__topic" style="width: 648px;">
              
                3.1 seq2seq实现baseline-1模型
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix="">
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/AITutorials/manuals" title="前往 Github 仓库" class="md-source" data-md-source="github" data-md-state="done">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    Github
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation" style="height: 509px;">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="./1_1.html" title="文本摘要项目" class="md-nav__button md-logo">
      
        <img src="./index_files/AI.jpg" width="48" height="48">
      
    </a>
    文本摘要项目
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/AITutorials/manuals" title="前往 Github 仓库" class="md-source" data-md-source="github" data-md-state="done">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    Github
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix="">
    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1">
    
    <label class="md-nav__link" for="nav-1">
      第一章:文本摘要项目简介
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: none; overflow: hidden;">
      <label class="md-nav__title" for="nav-1">
        第一章:文本摘要项目简介
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./1_1.html" title="1.1 项目背景介绍" class="md-nav__link">
      1.1 项目背景介绍
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./1_2.html" title="1.2 项目中的数据集初探" class="md-nav__link">
      1.2 项目中的数据集初探
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      第二章:TextRank模型
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: none; overflow: hidden;">
      <label class="md-nav__title" for="nav-2">
        第二章:TextRank模型
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./2_1.html" title="2.1 TextRank算法理论基础" class="md-nav__link">
      2.1 TextRank算法理论基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./2_2.html" title="2.2 TextRank实现baseline-0模型" class="md-nav__link">
      2.2 TextRank实现baseline-0模型
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3" checked="">
    
    <label class="md-nav__link" for="nav-3">
      第三章:seq2seq经典架构
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: block; overflow: visible;">
      <label class="md-nav__title" for="nav-3">
        第三章:seq2seq经典架构
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        3.1 seq2seq实现baseline-1模型
      </label>
    
    <a href="" title="3.1 seq2seq实现baseline-1模型" class="md-nav__link md-nav__link--active">
      3.1 seq2seq实现baseline-1模型
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix="">
      
        <li class="md-nav__item">
  <a href="#seq2seq" title="seq2seq架构实现文本摘要" class="md-nav__link">
    seq2seq架构实现文本摘要
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" title="学习目标" class="md-nav__link">
    学习目标
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#seq2seq_1" title="seq2seq实现文本摘要的架构" class="md-nav__link">
    seq2seq实现文本摘要的架构
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#seq2seqbaseline-1" title="seq2seq实现baseline-1模型" class="md-nav__link">
    seq2seq实现baseline-1模型
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" title="若干工具函数的实现" class="md-nav__link">
    若干工具函数的实现
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" title="模型类的实现" class="md-nav__link">
    模型类的实现
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" title="训练和测试函数的实现" class="md-nav__link">
    训练和测试函数的实现
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" title="小节总结" class="md-nav__link">
    小节总结
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./3_2.html" title="3.2 baseline-1模型的优化" class="md-nav__link">
      3.2 baseline-1模型的优化
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      第四章:PGN先进架构
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: none; overflow: hidden;">
      <label class="md-nav__title" for="nav-4">
        第四章:PGN先进架构
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./4_1.html" title="4.1 PGN架构解析" class="md-nav__link">
      4.1 PGN架构解析
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./4_2.html" title="4.2 PGN模型的数据处理" class="md-nav__link">
      4.2 PGN模型的数据处理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./4_3.html" title="4.3 PGN实现baseline-2模型" class="md-nav__link">
      4.3 PGN实现baseline-2模型
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      第五章:生成式模型的评估方法
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: none; overflow: hidden;">
      <label class="md-nav__title" for="nav-5">
        第五章:生成式模型的评估方法
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./5_1.html" title="5.1 文本摘要评估方法" class="md-nav__link">
      5.1 文本摘要评估方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./5_2.html" title="5.2 ROUGE评估算法实现" class="md-nav__link">
      5.2 ROUGE评估算法实现
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      第六章:模型的迭代优化
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: none; overflow: hidden;">
      <label class="md-nav__title" for="nav-6">
        第六章:模型的迭代优化
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./6_1.html" title="6.1 PGN + coverage的优化模型" class="md-nav__link">
      6.1 PGN + coverage的优化模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./6_2.html" title="6.2 PGN + beam-search的优化模型" class="md-nav__link">
      6.2 PGN + beam-search的优化模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./6_3.html" title="6.3 数据增强的优化" class="md-nav__link">
      6.3 数据增强的优化
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./6_4.html" title="6.4 训练策略的优化" class="md-nav__link">
      6.4 训练策略的优化
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7" type="checkbox" id="nav-7">
    
    <label class="md-nav__link" for="nav-7">
      第七章:模型的部署与总结
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: none; overflow: hidden;">
      <label class="md-nav__title" for="nav-7">
        第七章:模型的部署与总结
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./7_1.html" title="7.1 硬件优化与模型部署" class="md-nav__link">
      7.1 硬件优化与模型部署
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./7_2.html" title="7.2 项目总结" class="md-nav__link">
      7.2 项目总结
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc" style="height: 509px;">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix="">
      
        <li class="md-nav__item">
  <a href="#seq2seq" title="seq2seq架构实现文本摘要" class="md-nav__link">
    seq2seq架构实现文本摘要
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" title="学习目标" class="md-nav__link">
    学习目标
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#seq2seq_1" title="seq2seq实现文本摘要的架构" class="md-nav__link">
    seq2seq实现文本摘要的架构
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#seq2seqbaseline-1" title="seq2seq实现baseline-1模型" class="md-nav__link">
    seq2seq实现baseline-1模型
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" title="若干工具函数的实现" class="md-nav__link">
    若干工具函数的实现
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" title="模型类的实现" class="md-nav__link">
    模型类的实现
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" title="训练和测试函数的实现" class="md-nav__link">
    训练和测试函数的实现
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" title="小节总结" class="md-nav__link">
    小节总结
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>3.1 seq2seq实现baseline-1模型</h1>
                
                <h2 id="seq2seq">seq2seq架构实现文本摘要</h2>
<hr>
<h3 id="_1">学习目标</h3>
<ul>
<li>掌握seq2seq实现文本摘要的架构.</li>
<li>掌握seq2seq的代码实现文本摘要baseline-1模型.</li>
</ul>
<hr>
<h3 id="seq2seq_1">seq2seq实现文本摘要的架构</h3>
<ul>
<li>首选回顾一下在英译法任务中的经典seq2seq架构图:</li>
</ul>
<p></p><center><img alt="" src="./index_files/s2s.png"></center><p></p>
<hr>
<blockquote>
<ul>
<li>
<p>编码器端负责将输入数据进行编码, 得到中间语义张量.</p>
</li>
<li>
<p>解码器端负责一次次的循环解析中间语义张量, 得到最终的结果语句.</p>
</li>
<li>
<p>一般来说, 我们将注意力机制添加在解码器端.</p>
</li>
</ul>
</blockquote>
<hr>
<ul>
<li>对比于英译法任务, 我们再来看文本摘要任务下的seq2seq架构图:</li>
</ul>
<hr>
<p></p><center><img alt="" src="./index_files/2.png"></center><p></p>
<hr>
<blockquote>
<ul>
<li>
<p>编码器端负责进行原始文本的编码.</p>
</li>
<li>
<p>注意力层结合编码张量和解码器端的当前输入, 得到总体上的内容张量.</p>
</li>
<li>
<p>最后在注意力机制的指导下, 解码器端得到完整的单词分布, 解码出当前时间步的单词.</p>
</li>
</ul>
</blockquote>
<hr>
<hr>
<h3 id="seq2seqbaseline-1">seq2seq实现baseline-1模型</h3>
<ul>
<li>为了完整的搭建baselins-1模型, 接下来要完成三大块的工作:<ul>
<li>若干工具函数的实现.</li>
<li>模型类的实现.</li>
<li>训练和测试函数的实现.</li>
</ul>
</li>
</ul>
<hr>
<h4 id="_2">若干工具函数的实现</h4>
<ul>
<li>在这一部分中我们要实现如下几个工具函数:<ul>
<li>第一步: 实现配置函数config.py</li>
<li>第二步: 实现多核并行处理的函数multi_proc_utils.py</li>
<li>第三步: 实现参数配置函数params_utils.py</li>
<li>第四步: 实现保存字典的函数word2vec_utils.py</li>
<li>第五步: 实现数据加载的函数data_loader.py</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>第一步: 实现配置函数config.py<ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/utils/config.py</li>
</ul>
</li>
</ul>
<div class="codehilite" id="__code_0"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_0 pre, #__code_0 code"><span class="md-clipboard__message"></span></button><pre id="__code_1"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_1 pre, #__code_1 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 导入os工具包</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># 设置项目代码库的root路径, 为后续所有的包导入提供便利</span>
<span class="n">root_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="n">root_path</span><span class="p">)</span>

<span class="c1"># 设置原始数据文件的路径, 通过以项目root路径为基础, 逐级添加到文件路径</span>
<span class="n">train_raw_data_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_path</span><span class="p">,</span> <span class="s1">'data'</span><span class="p">,</span> <span class="s1">'train.csv'</span><span class="p">)</span>
<span class="n">test_raw_data_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_path</span><span class="p">,</span> <span class="s1">'data'</span><span class="p">,</span> <span class="s1">'test.csv'</span><span class="p">)</span>

<span class="c1"># 停用词路径和jieba分词用户自定义字典路径</span>
<span class="n">stop_words_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_path</span><span class="p">,</span> <span class="s1">'data'</span><span class="p">,</span> <span class="s1">'stopwords.txt'</span><span class="p">)</span>
<span class="n">user_dict_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_path</span><span class="p">,</span> <span class="s1">'data'</span><span class="p">,</span> <span class="s1">'user_dict.txt'</span><span class="p">)</span>

<span class="c1"># 预处理+切分后的训练测试数据路径</span>
<span class="n">train_seg_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_path</span><span class="p">,</span> <span class="s1">'data'</span><span class="p">,</span> <span class="s1">'train_seg_data.csv'</span><span class="p">)</span>
<span class="n">test_seg_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_path</span><span class="p">,</span> <span class="s1">'data'</span><span class="p">,</span> <span class="s1">'test_seg_data.csv'</span><span class="p">)</span>

<span class="c1"># 将训练集和测试机数据混合后的文件路径</span>
<span class="n">merged_seg_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_path</span><span class="p">,</span> <span class="s1">'data'</span><span class="p">,</span> <span class="s1">'merged_seg_data.csv'</span><span class="p">)</span>

<span class="c1"># 样本与标签分离，并经过pad处理后的数据路径</span>
<span class="n">train_x_pad_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_path</span><span class="p">,</span> <span class="s1">'data'</span><span class="p">,</span> <span class="s1">'train_X_pad_data.csv'</span><span class="p">)</span>
<span class="n">train_y_pad_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_path</span><span class="p">,</span> <span class="s1">'data'</span><span class="p">,</span> <span class="s1">'train_Y_pad_data.csv'</span><span class="p">)</span>
<span class="n">test_x_pad_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_path</span><span class="p">,</span> <span class="s1">'data'</span><span class="p">,</span> <span class="s1">'test_X_pad_data.csv'</span><span class="p">)</span>

<span class="c1"># numpy转换为数字后最终使用的的数据路径</span>
<span class="n">train_x_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_path</span><span class="p">,</span> <span class="s1">'data'</span><span class="p">,</span> <span class="s1">'train_X.npy'</span><span class="p">)</span>
<span class="n">train_y_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_path</span><span class="p">,</span> <span class="s1">'data'</span><span class="p">,</span> <span class="s1">'train_Y.npy'</span><span class="p">)</span>
<span class="n">test_x_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_path</span><span class="p">,</span> <span class="s1">'data'</span><span class="p">,</span> <span class="s1">'test_X.npy'</span><span class="p">)</span>

<span class="c1"># 正向词典和反向词典路径</span>
<span class="n">vocab_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_path</span><span class="p">,</span> <span class="s1">'data'</span><span class="p">,</span> <span class="s1">'wv'</span><span class="p">,</span> <span class="s1">'vocab.txt'</span><span class="p">)</span>
<span class="n">reverse_vocab_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_path</span><span class="p">,</span> <span class="s1">'data'</span><span class="p">,</span> <span class="s1">'wv'</span><span class="p">,</span> <span class="s1">'reverse_vocab.txt'</span><span class="p">)</span>

<span class="c1"># 测试集结果保存路径</span>
<span class="n">result_save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_path</span><span class="p">,</span> <span class="s1">'data'</span><span class="p">,</span> <span class="s1">'result'</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_2"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_2 pre, #__code_2 code"><span class="md-clipboard__message"></span></button><pre id="__code_3"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_3 pre, #__code_3 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 切换到当前文件目录下</span>
<span class="nb">cd</span> /home/ec2-user/text_summary/seq2seq/utils

<span class="c1"># 执行程序</span>
python config.py
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_4"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_4 pre, #__code_4 code"><span class="md-clipboard__message"></span></button><pre id="__code_5"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_5 pre, #__code_5 code"><span class="md-clipboard__message"></span></button><code>/home/ec2-user/text_summary/seq2seq
</code></pre></div>


<hr>
<ul>
<li>第二步: 实现多核并行处理的函数multi_proc_utils.py<ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/utils/multi_proc_utils.py</li>
</ul>
</li>
</ul>
<div class="codehilite" id="__code_6"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_6 pre, #__code_6 code"><span class="md-clipboard__message"></span></button><pre id="__code_7"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_7 pre, #__code_7 code"><span class="md-clipboard__message"></span></button><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="kn">import</span> <span class="n">cpu_count</span><span class="p">,</span> <span class="n">Pool</span>

<span class="c1"># 计算当前服务器CPU的数量</span>
<span class="n">cores</span> <span class="o">=</span> <span class="n">cpu_count</span><span class="p">()</span>
<span class="c1"># 将分块个数设置为CPU的数量</span>
<span class="n">partitions</span> <span class="o">=</span> <span class="n">cores</span>
<span class="k">print</span><span class="p">(</span><span class="n">cores</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">parallelize</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">func</span><span class="p">):</span>
    <span class="c1"># 数据切分</span>
    <span class="n">data_split</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">partitions</span><span class="p">)</span>
    <span class="c1"># 初始化线程池</span>
    <span class="n">pool</span> <span class="o">=</span> <span class="n">Pool</span><span class="p">(</span><span class="n">cores</span><span class="p">)</span>
    <span class="c1"># 数据分发, 处理, 再合并</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">data_split</span><span class="p">))</span>
    <span class="c1"># 关闭线程池</span>
    <span class="n">pool</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="c1"># 执行完close后不会有新的进程加入到pool, join函数等待所有子进程结束</span>
    <span class="n">pool</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
    <span class="c1"># 返回处理后的数据</span>
    <span class="k">return</span> <span class="n">data</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_8"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_8 pre, #__code_8 code"><span class="md-clipboard__message"></span></button><pre id="__code_9"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_9 pre, #__code_9 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 切换到当前文件目录下</span>
<span class="nb">cd</span> /home/ec2-user/text_summary/seq2seq/utils

<span class="c1"># 执行程序</span>
python multi_proc_utils.py
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_10"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_10 pre, #__code_10 code"><span class="md-clipboard__message"></span></button><pre id="__code_11"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_11 pre, #__code_11 code"><span class="md-clipboard__message"></span></button><code># 当前服务器是一个8核CPU, 32GB内存的机器
8
</code></pre></div>


<hr>
<ul>
<li>第三步: 实现参数配置函数params_utils.py<ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/utils/params_utils.py</li>
</ul>
</li>
</ul>
<div class="codehilite" id="__code_12"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_12 pre, #__code_12 code"><span class="md-clipboard__message"></span></button><pre id="__code_13"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_13 pre, #__code_13 code"><span class="md-clipboard__message"></span></button><code><span class="kn">import</span> <span class="nn">argparse</span>

<span class="k">def</span> <span class="nf">get_params</span><span class="p">():</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
    <span class="c1"># 编码器和解码器的最大序列长度</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--max_enc_len"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">"Encoder input max sequence length"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--max_dec_len"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">"Decoder input max sequence length"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="c1"># 一个训练批次的大小</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--batch_size"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">"Batch size"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="c1"># seq2seq训练轮数</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--seq2seq_train_epochs"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">"Seq2seq model training epochs"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="c1"># 词嵌入大小</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--embed_size"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">"Words embeddings dimension"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="c1"># 编码器、解码器以及attention的隐含层单元数</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--enc_units"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">"Encoder GRU cell units number"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--dec_units"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">"Decoder GRU cell units number"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--attn_units"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">"Used to compute the attention weights"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="c1"># 学习率</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--learning_rate"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">"Learning rate"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

    <span class="c1"># param是一个字典类型的变量，键为参数名，值为参数值</span>
    <span class="n">params</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">params</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_14"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_14 pre, #__code_14 code"><span class="md-clipboard__message"></span></button><pre id="__code_15"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_15 pre, #__code_15 code"><span class="md-clipboard__message"></span></button><code><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">get_params</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_16"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_16 pre, #__code_16 code"><span class="md-clipboard__message"></span></button><pre id="__code_17"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_17 pre, #__code_17 code"><span class="md-clipboard__message"></span></button><code>{'max_enc_len': 300, 'max_dec_len': 50, 'batch_size': 64, 'seq2seq_train_epochs': 20, 'embed_size': 500, 'enc_units': 512, 'dec_units': 512, 'attn_units': 20, 'learning_rate': 0.001}
</code></pre></div>


<hr>
<ul>
<li>第四步: 实现保存字典的函数word2vec_utils.py<ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/utils/word2vec_utils.py</li>
</ul>
</li>
</ul>
<div class="codehilite" id="__code_18"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_18 pre, #__code_18 code"><span class="md-clipboard__message"></span></button><pre id="__code_19"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_19 pre, #__code_19 code"><span class="md-clipboard__message"></span></button><code><span class="kn">from</span> <span class="nn">gensim.models.word2vec</span> <span class="kn">import</span> <span class="n">Word2Vec</span>


<span class="k">def</span> <span class="nf">load_embedding_matrix_from_model</span><span class="p">(</span><span class="n">wv_model_path</span><span class="p">):</span>
    <span class="c1"># 从word2vec模型中获取词向量矩阵</span>
    <span class="c1"># wv_model_path: word2vec模型的路径</span>
    <span class="n">wv_model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">wv_model_path</span><span class="p">)</span>
    <span class="c1"># wv_model.wv.vectors包含词向量矩阵</span>
    <span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">wv_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">vectors</span>
    <span class="k">return</span> <span class="n">embedding_matrix</span>


<span class="k">def</span> <span class="nf">get_vocab_from_model</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">,</span> <span class="n">reverse_vocab_path</span><span class="p">):</span>
    <span class="c1"># 提取映射字典</span>
    <span class="c1"># vocab_path: word_to_id的文件存储路径</span>
    <span class="c1"># reverse_vocab_path: id_to_word的文件存储路径</span>
    <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span> <span class="o">=</span> <span class="p">{},</span> <span class="p">{}</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f1</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f1</span><span class="o">.</span><span class="n">readlines</span><span class="p">():</span>
            <span class="n">w</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">)</span>
            <span class="n">word_to_id</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">reverse_vocab_path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f2</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f2</span><span class="o">.</span><span class="n">readlines</span><span class="p">():</span>
            <span class="n">v</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">)</span>
            <span class="n">id_to_word</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">v</span><span class="p">)]</span> <span class="o">=</span> <span class="n">w</span>

    <span class="k">return</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span>


<span class="k">def</span> <span class="nf">save_vocab_as_txt</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">):</span>
    <span class="c1"># 保存字典</span>
    <span class="c1"># filename: 目标txt文件路径</span>
    <span class="c1"># word_to_id: 要保存的字典</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">word_to_id</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">"{}</span><span class="se">\t</span><span class="s2">{}</span><span class="se">\n</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">))</span>
</code></pre></div>


<hr>
<ul>
<li>第五步: 实现数据加载的函数data_loader.py</li>
</ul>
<hr>
<ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/utils/data_loader.py<ul>
<li>1: 获取最大长度的函数.</li>
<li>2: 完成文本语句单词到id的数字映射函数.</li>
<li>3: 填充特殊标识符的函数.</li>
<li>4: 加载停用词表的函数.</li>
<li>5: 清洗文本的函数.</li>
<li>6: 过滤停用词的函数.</li>
<li>7: 语句处理的函数.</li>
<li>8: 加载构建好的训练集和测试集的函数.</li>
<li>9: 完成本步骤总体逻辑的函数build_dataset()函数.</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>1: 获取最大长度的函数</li>
</ul>
<div class="codehilite" id="__code_20"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_20 pre, #__code_20 code"><span class="md-clipboard__message"></span></button><pre id="__code_21"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_21 pre, #__code_21 code"><span class="md-clipboard__message"></span></button><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="n">root_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">root_path</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_max_len</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="c1"># 获得合适的最大长度值(被build_dataset调用)</span>
    <span class="c1"># data: 待统计的数据train_df['Question']</span>
    <span class="c1"># 句子最大长度为空格数+1</span>
    <span class="n">max_lens</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s1">' '</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># 平均值+2倍方差的方式</span>
    <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">max_lens</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">max_lens</span><span class="p">))</span>
</code></pre></div>


<hr>
<ul>
<li>输入数据data的样式:</li>
</ul>
<div class="codehilite" id="__code_22"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_22 pre, #__code_22 code"><span class="md-clipboard__message"></span></button><pre id="__code_23"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_23 pre, #__code_23 code"><span class="md-clipboard__message"></span></button><code>0    方向机 重 ， 助力 泵 ， 方向机 都 换 新 都 换 助力 泵 ， 方向机 换 方向机 ...
1    奔驰 ML500 排气 凸轮轴 调节 错误 有没有 电脑 检测 故障 代码 。 有发 一下 ...
2    2010 款 宝马X1 ， 2011 年 出厂 ， 2.0 排量 ， 通用 6L45 变速箱...
3    3.0 V6 发动机 号 位置 ， 照片 最好 ！ 右侧 排气管 上方 ， 缸体 上 靠近 ...
4    2012 款 奔驰 c180 ， 维修保养 ， 动力 ， 值得 拥有 家庭 用车 ， 入手 ...
</code></pre></div>


<hr>
<ul>
<li>2: 完成文本语句单词到id的数字映射函数</li>
</ul>
<div class="codehilite" id="__code_24"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_24 pre, #__code_24 code"><span class="md-clipboard__message"></span></button><pre id="__code_25"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_25 pre, #__code_25 code"><span class="md-clipboard__message"></span></button><code><span class="k">def</span> <span class="nf">transform_data</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">):</span>
    <span class="c1"># 句子转换为index序列(被build_dataset调用)</span>
    <span class="c1"># sentence: 'word1 word2 word3 ...'  -&gt;  [index1, index2, index3 ...]</span>
    <span class="c1"># word_to_id: 映射字典</span>

    <span class="c1"># 字符串切分成词</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)</span>

    <span class="c1"># 按照word_to_id的id进行转换, 到未知词就填充unk的索引</span>
    <span class="n">ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">word_to_id</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">word_to_id</span> <span class="k">else</span> <span class="n">word_to_id</span><span class="p">[</span><span class="s1">'&lt;UNK&gt;'</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>

    <span class="c1"># 返回映射后的文本id值列表</span>
    <span class="k">return</span> <span class="n">ids</span>
</code></pre></div>


<hr>
<ul>
<li>3: 填充特殊标识符的函数</li>
</ul>
<div class="codehilite" id="__code_26"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_26 pre, #__code_26 code"><span class="md-clipboard__message"></span></button><pre id="__code_27"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_27 pre, #__code_27 code"><span class="md-clipboard__message"></span></button><code><span class="k">def</span> <span class="nf">pad_proc</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">):</span>
    <span class="c1"># 根据max_len和vocab填充&lt;START&gt; &lt;STOP&gt; &lt;PAD&gt; &lt;UNK&gt;</span>

    <span class="c1"># 0. 按空格统计切分出词</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)</span>

    <span class="c1"># 1. 截取规定长度的词数</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">words</span><span class="p">[:</span><span class="n">max_len</span><span class="p">]</span>

    <span class="c1"># 2. 填充&lt;UNK&gt;</span>
    <span class="n">sentence</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">word_to_id</span> <span class="k">else</span> <span class="s1">'&lt;UNK&gt;'</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>

    <span class="c1"># 3. 填充&lt;START&gt; &lt;END&gt;</span>
    <span class="n">sentence</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'&lt;START&gt;'</span><span class="p">]</span> <span class="o">+</span> <span class="n">sentence</span> <span class="o">+</span> <span class="p">[</span><span class="s1">'&lt;STOP&gt;'</span><span class="p">]</span>

    <span class="c1"># 4. 判断长度，填充&lt;PAD&gt;</span>
    <span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span> <span class="o">+</span> <span class="p">[</span><span class="s1">'&lt;PAD&gt;'</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">))</span>

    <span class="c1"># 以空格连接列表, 返回结果字符串</span>
    <span class="k">return</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>4: 加载停用词表的函数</li>
</ul>
<div class="codehilite" id="__code_28"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_28 pre, #__code_28 code"><span class="md-clipboard__message"></span></button><pre id="__code_29"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_29 pre, #__code_29 code"><span class="md-clipboard__message"></span></button><code><span class="k">def</span> <span class="nf">load_stop_words</span><span class="p">(</span><span class="n">stop_word_path</span><span class="p">):</span>
    <span class="c1"># 加载停用词(程序调用)</span>
    <span class="c1"># stop_word_path: 停用词路径</span>

    <span class="c1"># 打开停用词文件</span>
    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">stop_word_path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span>
    <span class="c1"># 读取所有行</span>
    <span class="n">stop_words</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>

    <span class="c1"># 去除每一个停用词前后 空格 换行符</span>
    <span class="n">stop_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">stop_word</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">stop_word</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">stop_words</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_30"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_30 pre, #__code_30 code"><span class="md-clipboard__message"></span></button><pre id="__code_31"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_31 pre, #__code_31 code"><span class="md-clipboard__message"></span></button><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="n">root_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">root_path</span><span class="p">)</span>

<span class="c1"># 配置模块</span>
<span class="kn">from</span> <span class="nn">utils.config</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># 加载停用词, 这里面的stop_words_path是早已在config.py文件中配置好的</span>
<span class="n">stop_words</span> <span class="o">=</span> <span class="n">load_stop_words</span><span class="p">(</span><span class="n">stop_words_path</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">'stop_words: '</span><span class="p">,</span> <span class="n">stop_words</span><span class="p">[:</span><span class="mi">20</span><span class="p">])</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_32"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_32 pre, #__code_32 code"><span class="md-clipboard__message"></span></button><pre id="__code_33"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_33 pre, #__code_33 code"><span class="md-clipboard__message"></span></button><code>stop_words:  [':', '：', '———', '》），', '）÷（１－', '”，', '）、', '＝（', '→', '℃', '&amp;', '*', '一一', '~~~~', '『', '.一', './', '--', '』', '＝″']
</code></pre></div>


<hr>
<ul>
<li>5: 清洗文本的函数</li>
</ul>
<div class="codehilite" id="__code_34"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_34 pre, #__code_34 code"><span class="md-clipboard__message"></span></button><pre id="__code_35"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_35 pre, #__code_35 code"><span class="md-clipboard__message"></span></button><code><span class="k">def</span> <span class="nf">clean_sentence</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
    <span class="c1"># 特殊符号去除(被sentence_proc调用)</span>
    <span class="c1"># sentence: 待处理的字符串</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="c1"># 删除1. 2. 3. 这些标题</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s2">"\D(\d\.)\D"</span><span class="p">)</span>
        <span class="n">sentence</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">""</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>

        <span class="c1"># 删除带括号的 进口 海外</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">"[(（]进口[)）]|\(海外\)"</span><span class="p">)</span>
        <span class="n">sentence</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">""</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>
        <span class="c1"># 删除除了汉字数字字母和，！？。.- 以外的字符</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s2">"[^，！？。\.\-</span><span class="se">\u4e00</span><span class="s2">-</span><span class="se">\u9fa5</span><span class="s2">_a-zA-Z0-9]"</span><span class="p">)</span>
        <span class="c1"># 用中文输入法下的，！？来替换英文输入法下的,!?</span>
        <span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">","</span><span class="p">,</span> <span class="s2">"，"</span><span class="p">)</span>
        <span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"!"</span><span class="p">,</span> <span class="s2">"！"</span><span class="p">)</span>
        <span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"?"</span><span class="p">,</span> <span class="s2">"？"</span><span class="p">)</span>
        <span class="n">sentence</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">""</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>

        <span class="c1"># 删除 车主说 技师说 语音 图片 你好 您好</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">"车主说|技师说|语音|图片|你好|您好"</span><span class="p">)</span>
        <span class="n">sentence</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">""</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">sentence</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">''</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_36"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_36 pre, #__code_36 code"><span class="md-clipboard__message"></span></button><pre id="__code_37"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_37 pre, #__code_37 code"><span class="md-clipboard__message"></span></button><code><span class="n">sentence</span> <span class="o">=</span> <span class="s1">'技师说：你好！以前也出现过该故障吗？|技师说：缸压多少有没有测量一下?|车主说：没有过|车主说：没测缸</span>
<span class="err">压</span><span class="o">|</span><span class="err">技师说：测量一下缸压</span> <span class="err">看一四缸缸压是否偏低</span><span class="o">|</span><span class="err">车主说：用电脑测，只是</span><span class="mi">14</span><span class="err">缸缺火</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">技师</span>
<span class="err">说：点火线圈</span>  <span class="err">火花塞</span> <span class="err">喷油嘴不用干活</span>  <span class="err">直接和二三缸对倒一下</span>  <span class="err">跑一段在测量一下故障码进行排除</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主</span><span class="o">&gt;</span><span class="err">说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：师傅还在吗</span><span class="o">|</span><span class="err">技师说：调一下喷油嘴</span>  <span class="err">测一下缸压</span>  <span class="err">都正常则为发动机</span>
<span class="err">电脑板问题</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">技师说：这个影响不大的</span><span class="o">|</span><span class="err">技师说：缸压八个以上正常</span><span class="o">|</span><span class="err">车主说</span>
<span class="err">：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">技师说：所以说让你测量缸压</span>  <span class="err">只要缸压正常则没有问题</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">技师说：可以点击头像</span>
<span class="err">关注我</span>  <span class="err">有什么问题随时询问</span>  <span class="err">一定真诚用心为你解决</span><span class="o">|</span><span class="err">车主说：师傅，谢谢了</span><span class="o">|</span><span class="err">技师说：不用客气</span><span class="s1">'</span>

<span class="n">res</span> <span class="o">=</span> <span class="n">clean_sentence</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">'res='</span><span class="p">,</span> <span class="n">res</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_38"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_38 pre, #__code_38 code"><span class="md-clipboard__message"></span></button><pre id="__code_39"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_39 pre, #__code_39 code"><span class="md-clipboard__message"></span></button><code>res= ！以前也出现过该故障吗？缸压多少有没有测量一下？没有过没测缸压测量一下缸压看一四缸缸压是否偏低用电脑测，只是14缸缺火点火线圈火花塞喷油嘴不用干活直接和二三缸对倒一下跑一段在测量一下故障码进行排除师傅还在吗调一下喷油嘴测一下缸压都正常则为发动机电脑板问题这个影响不大的缸压八个以上正常所以说让你测量缸压只要缸压正常则没有问题可以点击头像关注我有什么问题随时询问一定真诚用心为你解决师傅，谢谢了不用客气
</code></pre></div>


<hr>
<ul>
<li>6: 过滤停用词的函数</li>
</ul>
<div class="codehilite" id="__code_40"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_40 pre, #__code_40 code"><span class="md-clipboard__message"></span></button><pre id="__code_41"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_41 pre, #__code_41 code"><span class="md-clipboard__message"></span></button><code><span class="k">def</span> <span class="nf">filter_stopwords</span><span class="p">(</span><span class="n">seg_list</span><span class="p">):</span>
    <span class="c1"># 过滤一句切好词的话中的停用词(被sentence_proc调用)</span>
    <span class="c1"># seg_list: 切好词的列表 [word1 ,word2 .......]</span>
    <span class="c1"># 首先去掉多余空字符</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">seg_list</span> <span class="k">if</span> <span class="n">word</span><span class="p">]</span>
    <span class="c1"># 去掉停用词</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">]</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_42"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_42 pre, #__code_42 code"><span class="md-clipboard__message"></span></button><pre id="__code_43"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_43 pre, #__code_43 code"><span class="md-clipboard__message"></span></button><code><span class="n">sentence</span> <span class="o">=</span> <span class="s1">'技师说：你好！以前也出现过该故障吗？|技师说：缸压多少有没有测量一下?|车主说：没有过|车主说：没测缸</span>
<span class="err">压</span><span class="o">|</span><span class="err">技师说：测量一下缸压</span> <span class="err">看一四缸缸压是否偏低</span><span class="o">|</span><span class="err">车主说：用电脑测，只是</span><span class="mi">14</span><span class="err">缸缺火</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">技师</span>
<span class="err">说：点火线圈</span>  <span class="err">火花塞</span> <span class="err">喷油嘴不用干活</span>  <span class="err">直接和二三缸对倒一下</span>  <span class="err">跑一段在测量一下故障码进行排除</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主</span><span class="o">&gt;</span><span class="err">说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：师傅还在吗</span><span class="o">|</span><span class="err">技师说：调一下喷油嘴</span>  <span class="err">测一下缸压</span>  <span class="err">都正常则为发动机</span>
<span class="err">电脑板问题</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">技师说：这个影响不大的</span><span class="o">|</span><span class="err">技师说：缸压八个以上正常</span><span class="o">|</span><span class="err">车主说</span>
<span class="err">：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">技师说：所以说让你测量缸压</span>  <span class="err">只要缸压正常则没有问题</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">技师说：可以点击头像</span>
<span class="err">关注我</span>  <span class="err">有什么问题随时询问</span>  <span class="err">一定真诚用心为你解决</span><span class="o">|</span><span class="err">车主说：师傅，谢谢了</span><span class="o">|</span><span class="err">技师说：不用客气</span><span class="s1">'</span>

<span class="c1"># 第一步: 先将原始文本执行清洗操作</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">clean_sentence</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>

<span class="c1"># 第二步: 对清洗结果进行分词, 默认是精确模式, 当设置cut_all=True时, 采用全模式</span>
<span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>

<span class="c1"># 第三步: 将分词的结果传入过滤停用词函数中, 并打印结果</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">filter_stopwords</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_44"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_44 pre, #__code_44 code"><span class="md-clipboard__message"></span></button><pre id="__code_45"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_45 pre, #__code_45 code"><span class="md-clipboard__message"></span></button><code>['！', '以前', '出现', '过该', '故障', '？', '缸', '压', '有没有', '测量', '一下', '？', '没有', '没测', '缸', '压', '测量', '一下', '缸', '压', '看', '一四缸', '缸', '压', '是否', '偏低', '电脑', '测', '，', '14', '缸', '缺火', '点火', '线圈', '火花塞', '喷油嘴', '不用', '干活', '直接', '二三', '缸', '倒', '一下', '跑', '一段', '测量', '一下', '故障', '码', '进行', '排除', '师傅', '还', '调', '一下', '喷油嘴', '测', '一下', '缸', '压', '都', '正常', '发动机', '电脑板', '问题', '影响', '不大', '缸', '压', '八个', '以上', '正常', '说', '测量', '缸', '压', '缸', '压', '正常', '没有', '问题', '点击', '头像', '关注', '问题', '随时', '询问', '一定', '真诚', '用心', '解决', '师傅', '，', '谢谢', '不用', '客气']
</code></pre></div>


<hr>
<ul>
<li>7: 语句处理的函数(1)</li>
</ul>
<div class="codehilite" id="__code_46"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_46 pre, #__code_46 code"><span class="md-clipboard__message"></span></button><pre id="__code_47"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_47 pre, #__code_47 code"><span class="md-clipboard__message"></span></button><code><span class="k">def</span> <span class="nf">sentence_proc</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
    <span class="c1"># 预处理模块(处理一条句子, 被sentences_proc调用)</span>
    <span class="c1"># sentence: 待处理字符串</span>

    <span class="c1"># 第一步: 执行清洗原始文本的操作</span>
    <span class="n">sentence</span> <span class="o">=</span> <span class="n">clean_sentence</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>

    <span class="c1"># 第二步: 执行分词操作, 默认精确模式, 全模式cut参数cut_all=True</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>

    <span class="c1"># 第三步: 将分词结果输入过滤停用词函数中</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">filter_stopwords</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>

    <span class="c1"># 返回字符串结果, 按空格分隔, 将过滤停用词后的列表拼接</span>
    <span class="k">return</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_48"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_48 pre, #__code_48 code"><span class="md-clipboard__message"></span></button><pre id="__code_49"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_49 pre, #__code_49 code"><span class="md-clipboard__message"></span></button><code><span class="n">sentence</span> <span class="o">=</span> <span class="s1">'技师说：你好！以前也出现过该故障吗？|技师说：缸压多少有没有测量一下?|车主说：没有过|车主说：没测缸</span>
<span class="err">压</span><span class="o">|</span><span class="err">技师说：测量一下缸压</span> <span class="err">看一四缸缸压是否偏低</span><span class="o">|</span><span class="err">车主说：用电脑测，只是</span><span class="mi">14</span><span class="err">缸缺火</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">技师</span>
<span class="err">说：点火线圈</span>  <span class="err">火花塞</span> <span class="err">喷油嘴不用干活</span>  <span class="err">直接和二三缸对倒一下</span>  <span class="err">跑一段在测量一下故障码进行排除</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主</span><span class="o">&gt;</span><span class="err">说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：师傅还在吗</span><span class="o">|</span><span class="err">技师说：调一下喷油嘴</span>  <span class="err">测一下缸压</span>  <span class="err">都正常则为发动机</span>
<span class="err">电脑板问题</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">技师说：这个影响不大的</span><span class="o">|</span><span class="err">技师说：缸压八个以上正常</span><span class="o">|</span><span class="err">车主说</span>
<span class="err">：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">技师说：所以说让你测量缸压</span>  <span class="err">只要缸压正常则没有问题</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">车主说：</span><span class="p">[</span><span class="err">语音</span><span class="p">]</span><span class="o">|</span><span class="err">技师说：可以点击头像</span>
<span class="err">关注我</span>  <span class="err">有什么问题随时询问</span>  <span class="err">一定真诚用心为你解决</span><span class="o">|</span><span class="err">车主说：师傅，谢谢了</span><span class="o">|</span><span class="err">技师说：不用客气</span><span class="s1">'</span>

<span class="n">res</span> <span class="o">=</span> <span class="n">sentence_proc</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">'res='</span><span class="p">,</span> <span class="n">res</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_50"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_50 pre, #__code_50 code"><span class="md-clipboard__message"></span></button><pre id="__code_51"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_51 pre, #__code_51 code"><span class="md-clipboard__message"></span></button><code>res= ！ 以前 出现 过该 故障 ？ 缸 压 有没有 测量 一下 ？ 没有 没测 缸 压 测量 一下 缸 压 看 一四缸 缸 压 是否 偏低 电脑 测 ， 14 缸 缺火 点火 线圈 火花塞 喷油嘴 不用 干活 直接 二三 缸 倒 一下 跑 一段 测量 一下 故障 码 进行 排除 师傅 还 调 一下 喷油嘴 测 一下 缸 压 都 正常 发动机 电脑板 问题 影响 不大 缸 压 八个 以上 正常 说 测量 缸 压 缸 压 正常 没有 问题 点击 头像 关注 问题 随时 询问 一定 真诚 用心 解决 师傅 ， 谢谢 不用 客气
</code></pre></div>


<hr>
<ul>
<li>7: 语句处理的函数(2)</li>
</ul>
<div class="codehilite" id="__code_52"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_52 pre, #__code_52 code"><span class="md-clipboard__message"></span></button><pre id="__code_53"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_53 pre, #__code_53 code"><span class="md-clipboard__message"></span></button><code><span class="k">def</span> <span class="nf">sentences_proc</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="c1"># 预处理模块(处理一个句子列表, 对每个句子调用sentence_proc操作)</span>
    <span class="c1"># df: 数据集</span>

    <span class="c1"># 批量预处理训练集和测试集</span>
    <span class="k">for</span> <span class="n">col_name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'Brand'</span><span class="p">,</span> <span class="s1">'Model'</span><span class="p">,</span> <span class="s1">'Question'</span><span class="p">,</span> <span class="s1">'Dialogue'</span><span class="p">]:</span>
        <span class="n">df</span><span class="p">[</span><span class="n">col_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">col_name</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">sentence_proc</span><span class="p">)</span>

    <span class="c1"># 训练集Report预处理</span>
    <span class="k">if</span> <span class="s1">'Report'</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">'Report'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'Report'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">sentence_proc</span><span class="p">)</span>

    <span class="c1"># 以Pandas的DataFrame格式返回</span>
    <span class="k">return</span> <span class="n">df</span>
</code></pre></div>


<hr>
<ul>
<li>8: 加载构建好的训练集和测试集的函数</li>
</ul>
<div class="codehilite" id="__code_54"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_54 pre, #__code_54 code"><span class="md-clipboard__message"></span></button><pre id="__code_55"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_55 pre, #__code_55 code"><span class="md-clipboard__message"></span></button><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="c1"># 加载处理好的训练样本和训练标签.npy文件(执行完build_dataset后才能使用)</span>
<span class="k">def</span> <span class="nf">load_train_dataset</span><span class="p">(</span><span class="n">max_enc_len</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">max_dec_len</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
    <span class="c1"># max_enc_len: 最长样本长度, 后面的截断</span>
    <span class="c1"># max_dec_len: 最长标签长度, 后面的截断</span>
    <span class="n">train_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">train_x_path</span><span class="p">)</span>
    <span class="n">train_Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">train_y_path</span><span class="p">)</span>

    <span class="n">train_X</span> <span class="o">=</span> <span class="n">train_X</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_enc_len</span><span class="p">]</span>
    <span class="n">train_Y</span> <span class="o">=</span> <span class="n">train_Y</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_dec_len</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span>

<span class="c1"># 加载处理好的测试样本.npy文件(执行完build_dataset后才能使用)</span>
<span class="k">def</span> <span class="nf">load_test_dataset</span><span class="p">(</span><span class="n">max_enc_len</span><span class="o">=</span><span class="mi">300</span><span class="p">):</span>
    <span class="c1"># max_enc_len: 最长样本长度, 后面的截断</span>
    <span class="n">test_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">test_x_path</span><span class="p">)</span>
    <span class="n">test_X</span> <span class="o">=</span> <span class="n">test_X</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_enc_len</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">test_X</span>
</code></pre></div>


<hr>
<ul>
<li>9: 完成本步骤总体逻辑的函数build_dataset()函数</li>
</ul>
<div class="codehilite" id="__code_56"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_56 pre, #__code_56 code"><span class="md-clipboard__message"></span></button><pre id="__code_57"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_57 pre, #__code_57 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 数据预处理总函数, 用于数据加载 + 预处理 (注意: 只需执行一次)</span>
<span class="k">def</span> <span class="nf">build_dataset</span><span class="p">(</span><span class="n">train_raw_data_path</span><span class="p">,</span> <span class="n">test_raw_data_path</span><span class="p">):</span>
    <span class="c1"># 1. 加载原始数据</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'1. 加载原始数据'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">train_raw_data_path</span><span class="p">)</span>
    <span class="c1"># 必须设定数据格式为utf-8</span>
    <span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">train_raw_data_path</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s1">'python'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span>
    <span class="n">test_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">test_raw_data_path</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s1">'python'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span>

    <span class="c1"># 82943, 20000</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'原始训练集行数 {}, 测试集行数 {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_df</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_df</span><span class="p">)))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

    <span class="c1"># 2. 空值去除(对于一行数据, 任意列只要有空值就去掉该行)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'2. 空值去除（对于一行数据，任意列只要有空值就去掉该行）'</span><span class="p">)</span>
    <span class="n">train_df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">'Question'</span><span class="p">,</span> <span class="s1">'Dialogue'</span><span class="p">,</span> <span class="s1">'Report'</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s1">'any'</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">test_df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">'Question'</span><span class="p">,</span> <span class="s1">'Dialogue'</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s1">'any'</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'空值去除后训练集行数 {}, 测试集行数 {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_df</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_df</span><span class="p">)))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

    <span class="c1"># 3. 多线程, 批量数据预处理(对每个句子执行sentence_proc, 清除无用词, 分词, 过滤停用词, 再用空格拼接为一个字符串)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'3. 多线程, 批量数据预处理(对每个句子执行sentence_proc, 清除无用词, 分词, 过滤停用词, 再用空格拼接为一个字符串)'</span><span class="p">)</span>
    <span class="n">train_df</span> <span class="o">=</span> <span class="n">parallelize</span><span class="p">(</span><span class="n">train_df</span><span class="p">,</span> <span class="n">sentences_proc</span><span class="p">)</span>
    <span class="n">test_df</span> <span class="o">=</span> <span class="n">parallelize</span><span class="p">(</span><span class="n">test_df</span><span class="p">,</span> <span class="n">sentences_proc</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'sentences_proc has done!'</span><span class="p">)</span>

    <span class="c1"># 4. 合并训练测试集, 用于构造映射字典word_to_id</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'4. 合并训练测试集, 用于构造映射字典word_to_id'</span><span class="p">)</span>
    <span class="c1"># 新建一列, 按行堆积</span>
    <span class="n">train_df</span><span class="p">[</span><span class="s1">'merged'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[[</span><span class="s1">'Question'</span><span class="p">,</span> <span class="s1">'Dialogue'</span><span class="p">,</span> <span class="s1">'Report'</span><span class="p">]]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># 新建一列, 按行堆积</span>
    <span class="n">test_df</span><span class="p">[</span><span class="s1">'merged'</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[[</span><span class="s1">'Question'</span><span class="p">,</span> <span class="s1">'Dialogue'</span><span class="p">]]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># merged列是训练集三列和测试集两列按行连接在一起再按列堆积, 用于构造映射字典</span>
    <span class="c1"># 按列堆积, 用于构造映射字典</span>
    <span class="n">merged_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">train_df</span><span class="p">[[</span><span class="s1">'merged'</span><span class="p">]],</span> <span class="n">test_df</span><span class="p">[[</span><span class="s1">'merged'</span><span class="p">]]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'训练集行数{}, 测试集行数{}, 合并数据集行数{}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_df</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_df</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">merged_df</span><span class="p">)))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

    <span class="c1"># 5. 保存分割处理好的train_seg_data.csv, test_set_data.csv</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'5. 保存分割处理好的train_seg_data.csv, test_set_data.csv'</span><span class="p">)</span>
    <span class="c1"># 把建立的列merged去掉, 该列对于神经网络无用</span>
    <span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">'merged'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">'merged'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># 将处理后的数据存入持久化文件</span>
    <span class="n">train_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">train_seg_path</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">test_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">test_seg_path</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'The csv_file has saved!'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

    <span class="c1"># 6. 保存合并数据merged_seg_data.csv, 用于构造映射字典word_to_id</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'6. 保存合并数据merged_seg_data.csv, 用于构造映射字典word_to_id'</span><span class="p">)</span>
    <span class="n">merged_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">merged_seg_path</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'The word_to_vector file has saved!'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

    <span class="c1"># 7. 构建word_to_id字典和id_to_word字典, 根据第6步存储的合并文件数据来完成.</span>
    <span class="n">word_to_id</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># 对训练集数据X进行处理</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">merged_seg_path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f1</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f1</span><span class="o">.</span><span class="n">readlines</span><span class="p">():</span>
            <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">line</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">word_to_id</span><span class="p">:</span>
                    <span class="n">word_to_id</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
                    <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">word_to_id</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">print</span><span class="p">(</span><span class="s1">'总体单词总数count='</span><span class="p">,</span> <span class="n">count</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

    <span class="n">res_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">number</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">word_to_id</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">:</span>
            <span class="n">res_dict</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
            <span class="n">number</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">print</span><span class="p">(</span><span class="s1">'进入到字典中的单词总数number='</span><span class="p">,</span> <span class="n">number</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'合并数据集的字典构造完毕, word_to_id容量: '</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">res_dict</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

    <span class="n">word_to_id</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">res_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">word_to_id</span><span class="p">:</span>
            <span class="n">word_to_id</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="n">count</span>
            <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">print</span><span class="p">(</span><span class="s1">'最终构造完毕字典, word_to_id容量='</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'count='</span><span class="p">,</span> <span class="n">count</span><span class="p">)</span>

    <span class="c1"># 8. 将Question和Dialogue用空格连接作为模型输入形成train_df['X']</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">"8. 将Question和Dialogue用空格连接作为模型输入形成train_df['X']"</span><span class="p">)</span>
    <span class="n">train_df</span><span class="p">[</span><span class="s1">'X'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[[</span><span class="s1">'Question'</span><span class="p">,</span> <span class="s1">'Dialogue'</span><span class="p">]]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_df</span><span class="p">[</span><span class="s1">'X'</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[[</span><span class="s1">'Question'</span><span class="p">,</span> <span class="s1">'Dialogue'</span><span class="p">]]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

    <span class="c1"># 9. 填充&lt;START&gt;, &lt;STOP&gt;, &lt;UNK&gt;和&lt;PAD&gt;, 使数据变为等长</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'9. 填充&lt;START&gt;, &lt;STOP&gt;, &lt;UNK&gt; 和 &lt;PAD&gt;, 使数据变为等长'</span><span class="p">)</span>

    <span class="c1"># 获取适当的最大长度</span>
    <span class="n">train_x_max_len</span> <span class="o">=</span> <span class="n">get_max_len</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">'X'</span><span class="p">])</span>
    <span class="n">test_x_max_len</span> <span class="o">=</span> <span class="n">get_max_len</span><span class="p">(</span><span class="n">test_df</span><span class="p">[</span><span class="s1">'X'</span><span class="p">])</span>
    <span class="n">train_y_max_len</span> <span class="o">=</span> <span class="n">get_max_len</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">'Report'</span><span class="p">])</span>

    <span class="k">print</span><span class="p">(</span><span class="s1">'填充前训练集样本的最大长度为: '</span><span class="p">,</span> <span class="n">train_x_max_len</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'填充前测试集样本的最大长度为: '</span><span class="p">,</span> <span class="n">test_x_max_len</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'填充前训练集标签的最大长度为: '</span><span class="p">,</span> <span class="n">train_y_max_len</span><span class="p">)</span>

    <span class="c1"># 选训练集和测试集中较大的值</span>
    <span class="n">x_max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">train_x_max_len</span><span class="p">,</span> <span class="n">test_x_max_len</span><span class="p">)</span>

    <span class="c1"># 训练集X填充处理</span>
    <span class="c1"># train_df['X'] = train_df['X'].apply(lambda x: pad_proc(x, x_max_len, vocab))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'训练集X填充PAD, START, STOP, UNK处理中...'</span><span class="p">)</span>
    <span class="n">train_df</span><span class="p">[</span><span class="s1">'X'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">'X'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">pad_proc</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_max_len</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">))</span>
    <span class="c1"># 测试集X填充处理</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'测试集X填充PAD, START, STOP, UNK处理中...'</span><span class="p">)</span>
    <span class="n">test_df</span><span class="p">[</span><span class="s1">'X'</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s1">'X'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">pad_proc</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_max_len</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">))</span>
    <span class="c1"># 训练集Y填充处理</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'训练集Y填充PAD, START, STOP, UNK处理中...'</span><span class="p">)</span>
    <span class="n">train_df</span><span class="p">[</span><span class="s1">'Y'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">'Report'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">pad_proc</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">train_y_max_len</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

    <span class="c1"># 10. 保存填充&lt;START&gt;, &lt;STOP&gt;, &lt;UNK&gt;和&lt;PAD&gt;后的X和Y</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'10. 保存填充&lt;START&gt;, &lt;STOP&gt;, &lt;UNK&gt; 和 &lt;PAD&gt;后的X和Y'</span><span class="p">)</span>
    <span class="n">train_df</span><span class="p">[</span><span class="s1">'X'</span><span class="p">]</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">train_x_pad_path</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">train_df</span><span class="p">[</span><span class="s1">'Y'</span><span class="p">]</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">train_y_pad_path</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">test_df</span><span class="p">[</span><span class="s1">'X'</span><span class="p">]</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">test_x_pad_path</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'填充后的三个文件保存完毕!'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

    <span class="c1"># 11. 重新构建word_to_id字典和id_to_word字典, 根据第10步存储的3个文件数据来完成.</span>
    <span class="n">word_to_id</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># 对训练集数据X进行处理</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">train_x_pad_path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f1</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f1</span><span class="o">.</span><span class="n">readlines</span><span class="p">():</span>
            <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">line</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">word_to_id</span><span class="p">:</span>
                    <span class="n">word_to_id</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="n">count</span>
                    <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">print</span><span class="p">(</span><span class="s1">'训练集X字典构造完毕, word_to_id容量: '</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">))</span>

    <span class="c1"># 对训练集数据Y进行处理</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">train_y_pad_path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f2</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f2</span><span class="o">.</span><span class="n">readlines</span><span class="p">():</span>
            <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">line</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">word_to_id</span><span class="p">:</span>
                    <span class="n">word_to_id</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="n">count</span>
                    <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">print</span><span class="p">(</span><span class="s1">'训练集Y字典构造完毕, word_to_id容量: '</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">))</span>

    <span class="c1"># 对测试集数据X进行处理</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">test_x_pad_path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f3</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f3</span><span class="o">.</span><span class="n">readlines</span><span class="p">():</span>
            <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">line</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">word_to_id</span><span class="p">:</span>
                    <span class="n">word_to_id</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="n">count</span>
                    <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">print</span><span class="p">(</span><span class="s1">'测试集X字典构造完毕, word_to_id容量: '</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'单词总数量count= '</span><span class="p">,</span> <span class="n">count</span><span class="p">)</span>

    <span class="c1"># 构造逆向字典id_to_word</span>
    <span class="n">id_to_word</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">word_to_id</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">id_to_word</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span>

    <span class="k">print</span><span class="p">(</span><span class="s1">'逆向字典构造完毕, id_to_word容量: '</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">id_to_word</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

    <span class="c1"># 12. 更新vocab并保存</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'12. 更新vocab并保存'</span><span class="p">)</span>
    <span class="n">save_vocab_as_txt</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">)</span>
    <span class="n">save_vocab_as_txt</span><span class="p">(</span><span class="n">reverse_vocab_path</span><span class="p">,</span> <span class="n">id_to_word</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'字典映射器word_to_id, id_to_word保存完毕!'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>


    <span class="c1"># 13. 数据集转换 将词转换成索引[&lt;START&gt; 方向机 重 ...] -&gt; [32800, 403, 986, 246, 231]</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'13. 数据集转换 将词转换成索引[&lt;START&gt; 方向机 重 ...] -&gt; [32800, 403, 986, 246, 231]'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'训练集X执行transform_data中......'</span><span class="p">)</span>
    <span class="n">train_ids_x</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">'X'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">transform_data</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'训练集Y执行transform_data中......'</span><span class="p">)</span>
    <span class="n">train_ids_y</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">'Y'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">transform_data</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'测试集X执行transform_data中......'</span><span class="p">)</span>
    <span class="n">test_ids_x</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s1">'X'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">transform_data</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

    <span class="c1"># 14. 数据转换成numpy数组(需等长)</span>
    <span class="c1"># 将索引列表转换成矩阵 [32800, 403, 986, 246, 231] --&gt; array([[32800, 403, 986, 246, 231], ...])</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'14. 数据转换成numpy数组(需等长)'</span><span class="p">)</span>
    <span class="n">train_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_ids_x</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
    <span class="n">train_Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_ids_y</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
    <span class="n">test_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_ids_x</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'转换为numpy数组的形状如下: </span><span class="se">\n</span><span class="s1">train_X的shape为: '</span><span class="p">,</span> <span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">train_Y的shape为: '</span><span class="p">,</span> <span class="n">train_Y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">test_X的shape为: '</span><span class="p">,</span> <span class="n">test_X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

    <span class="c1"># 15. 保存数据</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'15. 保存数据......'</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">train_x_path</span><span class="p">,</span> <span class="n">train_X</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">train_y_path</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">test_x_path</span><span class="p">,</span> <span class="n">test_X</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'数据集构造完毕, 存储于seq2seq/data/目录下.'</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_58"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_58 pre, #__code_58 code"><span class="md-clipboard__message"></span></button><pre id="__code_59"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_59 pre, #__code_59 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 导入若干工具包</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="c1"># 设定项目的root路径, 方便后续各个模块代码的导入</span>
<span class="n">root_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">root_path</span><span class="p">)</span>

<span class="c1"># 并行处理模块</span>
<span class="kn">from</span> <span class="nn">utils.multi_proc_utils</span> <span class="kn">import</span> <span class="n">parallelize</span>
<span class="c1"># 配置模块</span>
<span class="kn">from</span> <span class="nn">utils.config</span> <span class="kn">import</span> <span class="o">*</span>
<span class="c1"># 参数模块</span>
<span class="kn">from</span> <span class="nn">utils.params_utils</span> <span class="kn">import</span> <span class="n">get_params</span>
<span class="c1"># 保存字典为txt</span>
<span class="kn">from</span> <span class="nn">utils.word2vec_utils</span> <span class="kn">import</span> <span class="n">save_vocab_as_txt</span>

<span class="c1"># 载入词向量参数</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">get_params</span><span class="p">()</span>
<span class="c1"># jieba载入自定义切词表</span>
<span class="n">jieba</span><span class="o">.</span><span class="n">load_userdict</span><span class="p">(</span><span class="n">user_dict_path</span><span class="p">)</span>


<span class="c1"># ----------------------------------------------------</span>
<span class="c1"># 中间部分就是将前面1-8步的所有函数依然罗列在这里即可.</span>
<span class="c1"># ----------------------------------------------------</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
    <span class="n">build_dataset</span><span class="p">(</span><span class="n">train_raw_data_path</span><span class="p">,</span> <span class="n">test_raw_data_path</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_60"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_60 pre, #__code_60 code"><span class="md-clipboard__message"></span></button><pre id="__code_61"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_61 pre, #__code_61 code"><span class="md-clipboard__message"></span></button><code>Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.753 seconds.
Prefix dict has been built successfully.
1. 加载原始数据
/home/ec2-user/text_summary/seq2seq/data/train.csv
原始训练集行数 82943, 测试集行数 20000


2. 空值去除（对于一行数据，任意列只要有空值就去掉该行）
空值去除后训练集行数 82871, 测试集行数 20000


3. 多线程, 批量数据预处理(对每个句子执行sentence_proc，清除无用词，切词，过滤停用词，再用空格拼接为一个字符串)


sentences_proc has done!
4. 合并训练测试集，用于训练词向量
训练集行数82871, 测试集行数20000, 合并数据集行数102871


5. 保存分割处理好的train_seg_data.csv、test_set_data.csv
The csv_file has saved!


6. 保存合并数据merged_seg_data.csv，用于训练词向量
The word_to_vector file has saved!


总体单词总数count= 124520


进入到字典中的单词总数number= 32227
合并数据集的字典构造完毕, word_to_id容量:  32227


最终构造完毕字典, word_to_id容量= 32227
count= 32227
8. 将Question和Dialogue用空格连接作为模型输入形成train_df['X']


9. 填充&lt;START&gt;, &lt;STOP&gt;, &lt;UNK&gt;和&lt;PAD&gt;，使数据变为等长
填充前训练集样本的最大长度为:  298
填充前测试集样本的最大长度为:  312
填充前训练集标签的最大长度为:  38
训练集X填充PAD,START,STOP,UNK处理中...
测试集X填充PAD,START,STOP,UNK处理中...
训练集Y填充PAD,START,STOP,UNK处理中...


10. 保存填充&lt;START&gt;, &lt;STOP&gt;, &lt;UNK&gt;和&lt;PAD&gt;后的X和Y
填充后的三个文件保存完毕!


训练集X字典构造完毕, word_to_id容量:  32101
训练集Y字典构造完毕, word_to_id容量:  32130
测试集X字典构造完毕, word_to_id容量:  32217
单词总数量count=  32217
逆向字典构造完毕, id_to_word容量:  32217


字典映射器word_to_id, id_to_word保存完毕!


13. 数据集转换 将词转换成索引  [&lt;START&gt; 方向机 重 ...] -&gt; [32800, 403, 986, 246, 231]
训练集X执行transform_data中......
训练集Y执行transform_data中......
测试集X执行transform_data中......


14. 数据转换成numpy数组(需等长)
转换为numpy数组的形状如下: 
train_X的shape为:  (82871, 314) 
train_Y的shape为:  (82871, 40) 
test_X的shape为:  (20000, 314)


15. 保存数据


数据集构造完毕，于seq2seq/data/目录下
</code></pre></div>


<hr>
<blockquote>
<ul>
<li>结论: 通过五个步骤实现了全部的工具函数, 并完成了数据预处理. 后续模型类需要数据的时候, 可以直接通过加载文件的方式读取数据, 非常方便. 对于任意工业级别的项目来说, 数据预处理都处于非常重要的地位, 代码量和耗费的时间也占了整个项目很大的比例.</li>
</ul>
</blockquote>
<hr>
<hr>
<h4 id="_3">模型类的实现</h4>
<ul>
<li>在模型类的实现过程中, 为了代码的解耦和结构清晰, 总共需要完成以下几个函数的实现:<ul>
<li>第一步: 实现批次数据加载的函数batcher.py</li>
<li>第二步: 实现模型中子层的函数layers.py</li>
<li>第三步: 实现模型类的函数model.py</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>第一步: 实现批次数据加载的函数batcher.py<ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/src/batcher.py</li>
</ul>
</li>
</ul>
<hr>
<div class="codehilite" id="__code_62"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_62 pre, #__code_62 code"><span class="md-clipboard__message"></span></button><pre id="__code_63"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_63 pre, #__code_63 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 导入工具包</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>

<span class="c1"># 设定项目的rootL路径, 方便后续相关代码文件的导入</span>
<span class="n">root_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">root_path</span><span class="p">)</span>

<span class="c1"># 导入项目相关的代码文件</span>
<span class="kn">from</span> <span class="nn">utils.data_loader</span> <span class="kn">import</span> <span class="n">load_train_dataset</span><span class="p">,</span> <span class="n">load_test_dataset</span>

<span class="c1"># 训练批次数据生成器函数</span>
<span class="k">def</span> <span class="nf">train_batch_generator</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_enc_len</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">max_dec_len</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">sample_num</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="c1"># batch_size: batch大小</span>
    <span class="c1"># max_enc_len: 样本最大长度</span>
    <span class="c1"># max_dec_len: 标签最大长度</span>
    <span class="c1"># sample_num: 限定样本个数大小</span>

    <span class="c1"># 直接从已经预处理好的数据文件中加载训练集数据</span>
    <span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span> <span class="o">=</span> <span class="n">load_train_dataset</span><span class="p">(</span><span class="n">max_enc_len</span><span class="p">,</span> <span class="n">max_dec_len</span><span class="p">)</span>
    <span class="c1"># 对数据进行限定长度的切分</span>
    <span class="k">if</span> <span class="n">sample_num</span><span class="p">:</span>
        <span class="n">train_X</span> <span class="o">=</span> <span class="n">train_X</span><span class="p">[:</span><span class="n">sample_num</span><span class="p">]</span>
        <span class="n">train_Y</span> <span class="o">=</span> <span class="n">train_Y</span><span class="p">[:</span><span class="n">sample_num</span><span class="p">]</span>

    <span class="c1"># 将numpy类型的数据转换为Pytorch下的tensor类型, 因为TensorDataset只接收tensor类型数据</span>
    <span class="n">x_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span>
    <span class="n">y_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">train_Y</span><span class="p">)</span>

    <span class="c1"># 第一步: 先对数据进行封装</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span>

    <span class="c1"># 第二步: 再对dataset进行迭代器的构建</span>
    <span class="c1"># 如果机器没有GPU, 请采用下面的注释行代码</span>
    <span class="c1"># dataset = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)</span>

    <span class="c1"># 如果机器有GPU, 请采用下面的代码, 可以加速训练流程</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                         <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="c1"># 计算每个epoch要循环多少次</span>
    <span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>

    <span class="c1"># 将封装好的数据集和次数返回</span>
    <span class="k">return</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">steps_per_epoch</span>

<span class="c1"># 测试批次数据生成器函数</span>
<span class="k">def</span> <span class="nf">test_batch_generator</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_enc_len</span><span class="o">=</span><span class="mi">300</span><span class="p">):</span>
    <span class="c1"># batch_size: batch大小</span>
    <span class="c1"># max_enc_len: 样本最大长度</span>

    <span class="c1"># 直接从已经预处理好的数据文件中加载测试集数据</span>
    <span class="n">test_X</span> <span class="o">=</span> <span class="n">load_test_dataset</span><span class="p">(</span><span class="n">max_enc_len</span><span class="p">)</span>

    <span class="c1"># 将numpy类型的数据转换为Pytorch下的tensor类型, 因为TensorDataset只接收tensor类型数据</span>
    <span class="n">x_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>

    <span class="c1"># 第一步: 先对数据进行封装</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span>

    <span class="c1"># 第二步: 再对dataset进行迭代器的构建</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="c1"># 计算每个epoch要循环多少次</span>
    <span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>

    <span class="c1"># 将封装好的数据集和次数返回</span>
    <span class="k">return</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">steps_per_epoch</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_64"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_64 pre, #__code_64 code"><span class="md-clipboard__message"></span></button><pre id="__code_65"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_65 pre, #__code_65 code"><span class="md-clipboard__message"></span></button><code><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
    <span class="n">dataset1</span><span class="p">,</span> <span class="n">length1</span> <span class="o">=</span> <span class="n">train_batch_generator</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
    <span class="n">dataset2</span><span class="p">,</span> <span class="n">length2</span> <span class="o">=</span> <span class="n">test_batch_generator</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">dataset1</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">length1</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">dataset2</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">length2</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_66"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_66 pre, #__code_66 code"><span class="md-clipboard__message"></span></button><pre id="__code_67"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_67 pre, #__code_67 code"><span class="md-clipboard__message"></span></button><code>/home/ec2-user/text_summary/seq2seq
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.743 seconds.
Prefix dict has been built successfully.
&lt;torch.utils.data.dataloader.DataLoader object at 0x7fcd0c862048&gt;
1294
&lt;torch.utils.data.dataloader.DataLoader object at 0x7fcd0473ca58&gt;
312
</code></pre></div>


<hr>
<hr>
<ul>
<li>第二步: 实现模型中子层的函数layers.py<ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/src/layers.py</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>为了完成模型中子层的构建, 我们需要分3个小步骤:<ul>
<li>1: 实现编码器类Encoder.</li>
<li>2: 实现注意力类Attention.</li>
<li>3: 实现解码器类Decoder.</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>1: 实现编码器类Encoder.</li>
</ul>
<div class="codehilite" id="__code_68"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_68 pre, #__code_68 code"><span class="md-clipboard__message"></span></button><pre id="__code_69"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_69 pre, #__code_69 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 导入工具包</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="c1"># 设定项目的root路径, 方便后续的代码文件导入</span>
<span class="n">root_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">root_path</span><span class="p">)</span>

<span class="c1"># 导入项目相关的代码文件</span>
<span class="kn">from</span> <span class="nn">utils.config</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">utils.word2vec_utils</span> <span class="kn">import</span> <span class="n">get_vocab_from_model</span>


<span class="c1"># 构建编码器类</span>
<span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">enc_units</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">embedding_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_units</span> <span class="o">=</span> <span class="n">enc_units</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>

        <span class="c1"># 第一层: 词嵌入层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>

        <span class="c1"># 第二层: GRU层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">enc_units</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="p">):</span>
        <span class="c1"># x.shape: (batch_size, sequence_length)</span>
        <span class="c1"># h0.shape: (num_layers, batch_size, enc_units)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hn</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">initialize_hidden_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># hidden state张量形状: (num_layers, batch_size, enc_units)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_units</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_70"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_70 pre, #__code_70 code"><span class="md-clipboard__message"></span></button><pre id="__code_71"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_71 pre, #__code_71 code"><span class="md-clipboard__message"></span></button><code><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
    <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span> <span class="o">=</span> <span class="n">get_vocab_from_model</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">,</span> <span class="n">reverse_vocab_path</span><span class="p">)</span>
    <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'vocab_size: '</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

    <span class="c1"># 测试用参数</span>
    <span class="n">EXAMPLE_INPUT_SEQUENCE_LEN</span> <span class="o">=</span> <span class="mi">300</span>
    <span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">EMBEDDING_DIM</span> <span class="o">=</span> <span class="mi">500</span>
    <span class="n">GRU_UNITS</span> <span class="o">=</span> <span class="mi">512</span>
    <span class="n">ATTENTION_UNITS</span> <span class="o">=</span> <span class="mi">20</span>

    <span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">EMBEDDING_DIM</span><span class="p">,</span> <span class="n">GRU_UNITS</span><span class="p">,</span> <span class="n">BATCH_SIZE</span><span class="p">)</span>

    <span class="n">input0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">EXAMPLE_INPUT_SEQUENCE_LEN</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
    <span class="n">h0</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">initialize_hidden_state</span><span class="p">()</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input0</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">hn</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_72"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_72 pre, #__code_72 code"><span class="md-clipboard__message"></span></button><pre id="__code_73"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_73 pre, #__code_73 code"><span class="md-clipboard__message"></span></button><code>vocab_size:  32217
torch.Size([64, 300, 512])
torch.Size([64, 1, 512])
</code></pre></div>


<hr>
<ul>
<li>2: 实现注意力类Attention.</li>
</ul>
<div class="codehilite" id="__code_74"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_74 pre, #__code_74 code"><span class="md-clipboard__message"></span></button><pre id="__code_75"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_75 pre, #__code_75 code"><span class="md-clipboard__message"></span></button><code><span class="k">class</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_units</span><span class="p">,</span> <span class="n">dec_units</span><span class="p">,</span> <span class="n">attn_units</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Attention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_units</span> <span class="o">=</span> <span class="n">enc_units</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dec_units</span> <span class="o">=</span> <span class="n">dec_units</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_units</span> <span class="o">=</span> <span class="n">attn_units</span>

        <span class="c1"># 计算注意力的三次矩阵乘法, 对应着3个全连接层.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">enc_units</span><span class="p">,</span> <span class="n">attn_units</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dec_units</span><span class="p">,</span> <span class="n">attn_units</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">attn_units</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="c1"># query为上次的decoder隐藏层，shape: (batch_size, dec_units)</span>
        <span class="c1"># values为编码器的编码结果enc_output，shape: (batch_size, enc_seq_len, enc_units)</span>
        <span class="c1"># 在应用self.V之前，张量的形状是(batch_size, enc_seq_len, attention_units)</span>
        <span class="c1"># 得到score的shape: (batch_size, seq_len, 1)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w1</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2</span><span class="p">(</span><span class="n">query</span><span class="p">)))</span>

        <span class="c1"># 注意力权重，是score经过softmax，但是要作用在第一个轴上(seq_len的轴)</span>
        <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># (batch_size, enc_seq_len, 1) * (batch_size, enc_seq_len, enc_units)</span>
        <span class="c1"># 广播, encoder unit的每个位置都对应相乘</span>
        <span class="n">context_vector</span> <span class="o">=</span> <span class="n">attention_weights</span> <span class="o">*</span> <span class="n">value</span>
        <span class="c1"># 在最大长度enc_seq_len这一维度上求和</span>
        <span class="n">context_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">context_vector</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># context_vector求和之后的shape: (batch_size, enc_units)</span>

        <span class="k">return</span> <span class="n">context_vector</span><span class="p">,</span> <span class="n">attention_weights</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_76"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_76 pre, #__code_76 code"><span class="md-clipboard__message"></span></button><pre id="__code_77"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_77 pre, #__code_77 code"><span class="md-clipboard__message"></span></button><code><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
    <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span> <span class="o">=</span> <span class="n">get_vocab_from_model</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">,</span> <span class="n">reverse_vocab_path</span><span class="p">)</span>
    <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">)</span>

    <span class="c1"># 测试用参数</span>
    <span class="n">EXAMPLE_INPUT_SEQUENCE_LEN</span> <span class="o">=</span> <span class="mi">300</span>
    <span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">EMBEDDING_DIM</span> <span class="o">=</span> <span class="mi">500</span>
    <span class="n">GRU_UNITS</span> <span class="o">=</span> <span class="mi">512</span>
    <span class="n">ATTENTION_UNITS</span> <span class="o">=</span> <span class="mi">20</span>

    <span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">EMBEDDING_DIM</span><span class="p">,</span> <span class="n">GRU_UNITS</span><span class="p">,</span> <span class="n">BATCH_SIZE</span><span class="p">)</span>

    <span class="n">input0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">EXAMPLE_INPUT_SEQUENCE_LEN</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
    <span class="n">h0</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">initialize_hidden_state</span><span class="p">()</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input0</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>

    <span class="n">attention</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">GRU_UNITS</span><span class="p">,</span> <span class="n">GRU_UNITS</span><span class="p">,</span> <span class="n">ATTENTION_UNITS</span><span class="p">)</span>
    <span class="n">context_vector</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">attention</span><span class="p">(</span><span class="n">hn</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">context_vector</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">attention_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_78"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_78 pre, #__code_78 code"><span class="md-clipboard__message"></span></button><pre id="__code_79"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_79 pre, #__code_79 code"><span class="md-clipboard__message"></span></button><code>torch.Size([64, 512])
torch.Size([64, 300, 1])
</code></pre></div>


<hr>
<ul>
<li>3: 实现解码器类Decoder.</li>
</ul>
<div class="codehilite" id="__code_80"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_80 pre, #__code_80 code"><span class="md-clipboard__message"></span></button><pre id="__code_81"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_81 pre, #__code_81 code"><span class="md-clipboard__message"></span></button><code><span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">dec_units</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">embedding_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dec_units</span> <span class="o">=</span> <span class="n">dec_units</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">embedding_dim</span> <span class="o">+</span> <span class="n">dec_units</span><span class="p">,</span>
                          <span class="n">hidden_size</span><span class="o">=</span><span class="n">dec_units</span><span class="p">,</span>
                          <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                          <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dec_units</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">context_vector</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># x.shape after passing through embedding: (batch_size, 1, embedding_dim)，1指的是一次只解码一个单词</span>
        <span class="c1"># 将上一循环的预测结果跟注意力权重值结合在一起作为本次的GRU网络输入</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">context_vector</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">x</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">hn</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_82"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_82 pre, #__code_82 code"><span class="md-clipboard__message"></span></button><pre id="__code_83"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_83 pre, #__code_83 code"><span class="md-clipboard__message"></span></button><code><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
    <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span> <span class="o">=</span> <span class="n">get_vocab_from_model</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">,</span> <span class="n">reverse_vocab_path</span><span class="p">)</span>
    <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">)</span>

    <span class="c1"># 测试用参数</span>
    <span class="n">EXAMPLE_INPUT_SEQUENCE_LEN</span> <span class="o">=</span> <span class="mi">300</span>
    <span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">EMBEDDING_DIM</span> <span class="o">=</span> <span class="mi">500</span>
    <span class="n">GRU_UNITS</span> <span class="o">=</span> <span class="mi">512</span>
    <span class="n">ATTENTION_UNITS</span> <span class="o">=</span> <span class="mi">20</span>

    <span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">EMBEDDING_DIM</span><span class="p">,</span> <span class="n">GRU_UNITS</span><span class="p">,</span> <span class="n">BATCH_SIZE</span><span class="p">)</span>

    <span class="n">input0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">EXAMPLE_INPUT_SEQUENCE_LEN</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
    <span class="n">h0</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">initialize_hidden_state</span><span class="p">()</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input0</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>

    <span class="n">attention</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">GRU_UNITS</span><span class="p">,</span> <span class="n">GRU_UNITS</span><span class="p">,</span> <span class="n">ATTENTION_UNITS</span><span class="p">)</span>
    <span class="n">context_vector</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">attention</span><span class="p">(</span><span class="n">hn</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>

    <span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">EMBEDDING_DIM</span><span class="p">,</span> <span class="n">GRU_UNITS</span><span class="p">,</span> <span class="n">BATCH_SIZE</span><span class="p">)</span>
    <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
    <span class="n">output1</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">context_vector</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">output1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">hn</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_84"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_84 pre, #__code_84 code"><span class="md-clipboard__message"></span></button><pre id="__code_85"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_85 pre, #__code_85 code"><span class="md-clipboard__message"></span></button><code>torch.Size([64, 32217])
torch.Size([64, 1, 512])
</code></pre></div>


<hr>
<blockquote>
<ul>
<li>结论: 分别实现了编码器层, 注意力层, 解码器层, 通过这三个类可以在未来完整的构建模型.</li>
</ul>
</blockquote>
<hr>
<hr>
<ul>
<li>第三步: 实现模型类的函数model.py<ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/src/model.py</li>
</ul>
</li>
</ul>
<hr>
<div class="codehilite" id="__code_86"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_86 pre, #__code_86 code"><span class="md-clipboard__message"></span></button><pre id="__code_87"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_87 pre, #__code_87 code"><span class="md-clipboard__message"></span></button><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="c1"># 设定项目的root路径, 方便后续代码文件的导入</span>
<span class="n">root_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">root_path</span><span class="p">)</span>

<span class="c1"># 导入工具包和项目相关的代码文件</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">src.layers</span> <span class="kn">import</span> <span class="n">Encoder</span><span class="p">,</span> <span class="n">Attention</span><span class="p">,</span> <span class="n">Decoder</span>
<span class="kn">from</span> <span class="nn">utils.config</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">utils.word2vec_utils</span> <span class="kn">import</span> <span class="n">get_vocab_from_model</span>


<span class="c1"># 构建完整的seq2seq模型</span>
<span class="k">class</span> <span class="nc">Seq2Seq</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Seq2Seq</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>

        <span class="c1"># 第一层: 编码器层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">'vocab_size'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">'embed_size'</span><span class="p">],</span>
                               <span class="n">params</span><span class="p">[</span><span class="s1">'enc_units'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">'batch_size'</span><span class="p">])</span>

        <span class="c1"># 第二层: 注意力机制层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">'enc_units'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">'dec_units'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">'attn_units'</span><span class="p">])</span>

        <span class="c1"># 第三层: 解码器层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">'vocab_size'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">'embed_size'</span><span class="p">],</span>
                               <span class="n">params</span><span class="p">[</span><span class="s1">'dec_units'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">'batch_size'</span><span class="p">])</span>

    <span class="c1"># 实质上是在调用解码器,因为需要注意力机制,直接封装到forward中. 要调用编码器直接encoder()即可</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">,</span> <span class="n">dec_hidden</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">dec_target</span><span class="p">):</span>
        <span class="c1"># 这里的dec_input实质是(batch_size, 1)大小的&lt;START&gt;</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># 拿编码器的输出和最终隐含层向量来计算</span>
        <span class="n">context_vector</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">dec_hidden</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">)</span>

        <span class="c1"># 循环解码</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dec_target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="c1"># dec_input (batch_size, 1); dec_hidden (batch_size, hidden_units)</span>
            <span class="n">pred</span><span class="p">,</span> <span class="n">dec_hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">context_vector</span><span class="p">)</span>

            <span class="n">context_vector</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">dec_hidden</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">)</span>

            <span class="c1"># 使用teacher forcing, 并扩展维度到三维张量</span>
            <span class="n">dec_input</span> <span class="o">=</span> <span class="n">dec_target</span><span class="p">[:,</span> <span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dec_hidden</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_88"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_88 pre, #__code_88 code"><span class="md-clipboard__message"></span></button><pre id="__code_89"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_89 pre, #__code_89 code"><span class="md-clipboard__message"></span></button><code><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
    <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span> <span class="o">=</span> <span class="n">get_vocab_from_model</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">,</span> <span class="n">reverse_vocab_path</span><span class="p">)</span>

    <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">)</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">input_seq_len</span> <span class="o">=</span> <span class="mi">300</span>

    <span class="c1"># 模拟测试参数</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"vocab_size"</span><span class="p">:</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="s2">"embed_size"</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span> <span class="s2">"enc_units"</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span>
              <span class="s2">"attn_units"</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="s2">"dec_units"</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span><span class="s2">"batch_size"</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">}</span>

    <span class="c1"># 实例化类对象</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Seq2Seq</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

    <span class="c1"># 初始化测试输入数据</span>
    <span class="n">sample_input_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">input_seq_len</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
    <span class="n">sample_hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">initialize_hidden_state</span><span class="p">()</span>

    <span class="c1"># 调用Encoder进行编码</span>
    <span class="n">sample_output</span><span class="p">,</span> <span class="n">sample_hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">sample_input_batch</span><span class="p">,</span> <span class="n">sample_hidden</span><span class="p">)</span>

    <span class="c1"># 打印输出张量维度</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'Encoder output shape: (batch_size, enc_seq_len, enc_units) {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sample_output</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'Encoder Hidden state shape: (batch_size, enc_units) {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sample_hidden</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

    <span class="c1"># 调用Attention进行注意力张量</span>
    <span class="n">context_vector</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">sample_hidden</span><span class="p">,</span> <span class="n">sample_output</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">"Attention context_vector shape: (batch_size, enc_units) {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">context_vector</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">"Attention weights shape: (batch_size, sequence_length, 1) {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">attention_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

    <span class="c1"># 调用Decoder进行解码</span>
    <span class="n">dec_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
    <span class="n">sample_decoder_output</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">context_vector</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s1">'Decoder output shape: (batch_size, vocab_size) {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sample_decoder_output</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="c1"># 这里仅测试一步，没有用到dec_seq_len</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_90"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_90 pre, #__code_90 code"><span class="md-clipboard__message"></span></button><pre id="__code_91"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_91 pre, #__code_91 code"><span class="md-clipboard__message"></span></button><code>Encoder output shape: (batch_size, enc_seq_len, enc_units) torch.Size([64, 300, 512])
Encoder Hidden state shape: (batch_size, enc_units) torch.Size([64, 1, 512])
Attention context_vector shape: (batch_size, enc_units) torch.Size([64, 512])
Attention weights shape: (batch_size, sequence_length, 1) torch.Size([64, 300, 1])
Decoder output shape: (batch_size, vocab_size) torch.Size([64, 32217])
</code></pre></div>


<hr>
<hr>
<h4 id="_4">训练和测试函数的实现</h4>
<ul>
<li>构建完成模型类后, 我们要分别实现训练函数和测试函数:<ul>
<li>第一步: 编写训练辅助函数train_helper.py</li>
<li>第二步: 编写训练主函数train.py</li>
<li>第三步: 编写测试辅助函数test_helper.py</li>
<li>第四步: 编写测试主函数test.py</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>第一步: 编写训练辅助函数train_helper.py<ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/src/train_helper.py </li>
</ul>
</li>
</ul>
<hr>
<div class="codehilite" id="__code_92"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_92 pre, #__code_92 code"><span class="md-clipboard__message"></span></button><pre id="__code_93"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_93 pre, #__code_93 code"><span class="md-clipboard__message"></span></button><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">root_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">root_path</span><span class="p">)</span>
<span class="c1"># print(root_path)</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="kn">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">batcher</span> <span class="kn">import</span> <span class="n">train_batch_generator</span>
<span class="kn">import</span> <span class="nn">time</span>


<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="c1"># 载入参数：seq2seq模型的训练轮次以及batch大小</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'seq2seq_train_epochs'</span><span class="p">]</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'batch_size'</span><span class="p">]</span>

    <span class="n">pad_index</span> <span class="o">=</span> <span class="n">word_to_id</span><span class="p">[</span><span class="s1">'&lt;PAD&gt;'</span><span class="p">]</span>
    <span class="n">unk_index</span> <span class="o">=</span> <span class="n">word_to_id</span><span class="p">[</span><span class="s1">'&lt;UNK&gt;'</span><span class="p">]</span>
    <span class="n">start_index</span> <span class="o">=</span> <span class="n">word_to_id</span><span class="p">[</span><span class="s1">'&lt;START&gt;'</span><span class="p">]</span>

    <span class="n">params</span><span class="p">[</span><span class="s1">'vocab_size'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">)</span>

    <span class="c1"># 如果有GPU则将模型放在GPU上训练</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'Model has put to GPU...'</span><span class="p">)</span>

    <span class="c1"># 选定Adam优化器, 和交叉熵损失函数</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">'learning_rate'</span><span class="p">])</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

     <span class="c1"># 定义损失函数</span>
    <span class="k">def</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">real</span><span class="p">):</span>
        <span class="c1"># 相同为1, 不同为0. 则0的位置天然形成了掩码</span>
        <span class="n">pad_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">pad_index</span><span class="p">)</span>
        <span class="n">unk_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">unk_index</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="n">pad_mask</span><span class="p">,</span> <span class="n">unk_mask</span><span class="p">))</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># 真实标签乘以掩码后, 表达的是真实参与损失计算的序列</span>
        <span class="n">real</span> <span class="o">=</span> <span class="n">real</span> <span class="o">*</span> <span class="n">mask</span>
        <span class="n">loss_</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">real</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss_</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">enc_input</span><span class="p">,</span> <span class="n">dec_target</span><span class="p">):</span>
        <span class="n">initial_hidden_state</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">initialize_hidden_state</span><span class="p">()</span>
        <span class="n">initial_hidden_state</span> <span class="o">=</span> <span class="n">initial_hidden_state</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># 老三样: 1.梯度归零</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">enc_output</span><span class="p">,</span> <span class="n">enc_hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">enc_input</span><span class="p">,</span> <span class="n">initial_hidden_state</span><span class="p">)</span>

        <span class="c1"># 第一个decoder输入, 构造(batch_size, 1)的&lt;START&gt;标签作为起始</span>
        <span class="n">dec_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">start_index</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">dec_input</span> <span class="o">=</span> <span class="n">dec_input</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># 第一个隐藏层输入</span>
        <span class="n">dec_hidden</span> <span class="o">=</span> <span class="n">enc_hidden</span>

        <span class="c1"># for循环逐个预测序列</span>
        <span class="n">dec_input</span> <span class="o">=</span> <span class="n">dec_input</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">dec_hidden</span> <span class="o">=</span> <span class="n">dec_hidden</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">enc_output</span> <span class="o">=</span> <span class="n">enc_output</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">dec_target</span> <span class="o">=</span> <span class="n">dec_target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">predictions</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">dec_hidden</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">dec_target</span><span class="p">)</span>

        <span class="c1"># 计算损失, 两个张量形状均为(batch, dec_target的len-1)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">dec_target</span><span class="p">)</span>

        <span class="c1"># 老三样: 2.反向传播 + 3.梯度更新</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>


    <span class="c1"># 读取数据</span>
    <span class="n">dataset</span><span class="p">,</span> <span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="n">train_batch_generator</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># 按批次数据进行训练</span>
        <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="c1"># 将标签张量的类型转变成和输入张量一致</span>
            <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">batch_loss</span> <span class="o">=</span> <span class="n">train_step</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
            <span class="n">total_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">+</span> <span class="n">batch_loss</span>

            <span class="c1"># 每50个batch打印一次训练信息</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">batch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="s1">'Epoch {} Batch {} Loss {:.4f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_loss</span><span class="p">))</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">MODEL_PATH</span> <span class="o">=</span> <span class="n">root_path</span> <span class="o">+</span> <span class="s1">'/src/saved_model/'</span> <span class="o">+</span> <span class="s1">'model_'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="o">+</span> <span class="s1">'.pt'</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">MODEL_PATH</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">'The model has saved for epoch {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">'Epoch {} Total Loss {:.4f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">))</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">'*************************************'</span><span class="p">)</span>

        <span class="c1"># 打印一个epoch所用时间</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">'Time taken for 1 epoch {} sec</span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">))</span>
</code></pre></div>


<hr>
<ul>
<li>第二步: 编写训练主函数train.py<ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/src/train.py</li>
</ul>
</li>
</ul>
<hr>
<div class="codehilite" id="__code_94"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_94 pre, #__code_94 code"><span class="md-clipboard__message"></span></button><pre id="__code_95"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_95 pre, #__code_95 code"><span class="md-clipboard__message"></span></button><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">root_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">root_path</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="kn">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">batcher</span> <span class="kn">import</span> <span class="n">train_batch_generator</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">src.model</span> <span class="kn">import</span> <span class="n">Seq2Seq</span>
<span class="kn">from</span> <span class="nn">src.train_helper</span> <span class="kn">import</span> <span class="n">train_model</span>
<span class="kn">from</span> <span class="nn">utils.config</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">utils.params_utils</span> <span class="kn">import</span> <span class="n">get_params</span>
<span class="kn">from</span> <span class="nn">utils.word2vec_utils</span> <span class="kn">import</span> <span class="n">get_vocab_from_model</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
    <span class="c1"># 读取word_to_id训练</span>
    <span class="n">word_to_id</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_vocab_from_model</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">,</span> <span class="n">reverse_vocab_path</span><span class="p">)</span>
    <span class="c1"># 动态添加字典大小参数</span>
    <span class="n">params</span><span class="p">[</span><span class="s1">'vocab_size'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">)</span>

    <span class="c1"># 构建模型</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">"Building the model ..."</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Seq2Seq</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

    <span class="c1"># 训练模型</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'开始训练模型'</span><span class="p">)</span>
    <span class="n">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_96"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_96 pre, #__code_96 code"><span class="md-clipboard__message"></span></button><pre id="__code_97"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_97 pre, #__code_97 code"><span class="md-clipboard__message"></span></button><code><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">get_params</span><span class="p">()</span>
    <span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_98"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_98 pre, #__code_98 code"><span class="md-clipboard__message"></span></button><pre id="__code_99"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_99 pre, #__code_99 code"><span class="md-clipboard__message"></span></button><code>/home/ec2-user/text_summary/seq2seq
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.742 seconds.
Prefix dict has been built successfully.
Building the model ...
开始训练模型
Model has put to GPU...
Epoch 1 Batch 50 Loss 2.5331
Epoch 1 Batch 100 Loss 2.0350
Epoch 1 Batch 150 Loss 2.2551
Epoch 1 Batch 200 Loss 2.1686
Epoch 1 Batch 250 Loss 2.2025
Epoch 1 Batch 300 Loss 2.1249
Epoch 1 Batch 350 Loss 1.9619
Epoch 1 Batch 400 Loss 1.6834
Epoch 1 Batch 450 Loss 2.2918
Epoch 1 Batch 500 Loss 2.1169
Epoch 1 Batch 550 Loss 2.1105
Epoch 1 Batch 600 Loss 2.0083
Epoch 1 Batch 650 Loss 1.8262
Epoch 1 Batch 700 Loss 1.7211
Epoch 1 Batch 750 Loss 2.0747
Epoch 1 Batch 800 Loss 1.7324
Epoch 1 Batch 850 Loss 2.1359
Epoch 1 Batch 900 Loss 1.8689
Epoch 1 Batch 950 Loss 1.8645
Epoch 1 Batch 1000 Loss 1.8017
Epoch 1 Batch 1050 Loss 1.9226
Epoch 1 Batch 1100 Loss 1.7405
Epoch 1 Batch 1150 Loss 1.5623
Epoch 1 Batch 1200 Loss 1.6556
Epoch 1 Batch 1250 Loss 1.7291
Time taken for 1 epoch 656.5679984092712 sec


......
......
......


Epoch 10 Batch 50 Loss 0.8314
Epoch 10 Batch 100 Loss 0.7645
Epoch 10 Batch 150 Loss 0.7843
Epoch 10 Batch 200 Loss 0.8006
Epoch 10 Batch 250 Loss 0.7855
Epoch 10 Batch 300 Loss 0.8918
Epoch 10 Batch 350 Loss 0.8440
Epoch 10 Batch 400 Loss 0.8019
Epoch 10 Batch 450 Loss 0.7360
Epoch 10 Batch 500 Loss 0.7858
Epoch 10 Batch 550 Loss 0.9141
Epoch 10 Batch 600 Loss 0.8353
Epoch 10 Batch 650 Loss 0.8990
Epoch 10 Batch 700 Loss 0.8440
Epoch 10 Batch 750 Loss 0.7974
Epoch 10 Batch 800 Loss 0.8453
Epoch 10 Batch 850 Loss 0.9953
Epoch 10 Batch 900 Loss 0.9022
Epoch 10 Batch 950 Loss 0.8742
Epoch 10 Batch 1000 Loss 0.7762
Epoch 10 Batch 1050 Loss 0.9823
Epoch 10 Batch 1100 Loss 0.8812
Epoch 10 Batch 1150 Loss 0.8549
Epoch 10 Batch 1200 Loss 0.9965
Epoch 10 Batch 1250 Loss 0.8885
The model has saved for epoch 10
Epoch 10 Total Loss 1079.8954
*************************************
Time taken for 1 epoch 662.4355807304382 sec


......
......
......


Epoch 30 Batch 50 Loss 0.4469
Epoch 30 Batch 100 Loss 0.4077
Epoch 30 Batch 150 Loss 0.3973
Epoch 30 Batch 200 Loss 0.3445
Epoch 30 Batch 250 Loss 0.5289
Epoch 30 Batch 300 Loss 0.4306
Epoch 30 Batch 350 Loss 0.4639
Epoch 30 Batch 400 Loss 0.3316
Epoch 30 Batch 450 Loss 0.3984
Epoch 30 Batch 500 Loss 0.4391
Epoch 30 Batch 550 Loss 0.4079
Epoch 30 Batch 600 Loss 0.4483
Epoch 30 Batch 650 Loss 0.4407
Epoch 30 Batch 700 Loss 0.4505
Epoch 30 Batch 750 Loss 0.3744
Epoch 30 Batch 800 Loss 0.4040
Epoch 30 Batch 850 Loss 0.4668
Epoch 30 Batch 900 Loss 0.4470
Epoch 30 Batch 950 Loss 0.4438
Epoch 30 Batch 1000 Loss 0.4224
Epoch 30 Batch 1050 Loss 0.4048
Epoch 30 Batch 1100 Loss 0.4809
Epoch 30 Batch 1150 Loss 0.5258
Epoch 30 Batch 1200 Loss 0.4406
Epoch 30 Batch 1250 Loss 0.3827
The model has saved for epoch 30
Epoch 30 Total Loss 552.6610
*************************************
Time taken for 1 epoch 661.1436426639557 sec
</code></pre></div>


<hr>
<ul>
<li>模型存储结果: /home/ec2-user/text_summary/seq2seq/src/saved_model/</li>
</ul>
<div class="codehilite" id="__code_100"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_100 pre, #__code_100 code"><span class="md-clipboard__message"></span></button><pre id="__code_101"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_101 pre, #__code_101 code"><span class="md-clipboard__message"></span></button><code>-rw-rw-r-- 1 ec2-user ec2-user 210670299 3月   3 15:33 model_1.pt
-rw-rw-r-- 1 ec2-user ec2-user 210670299 3月   3 15:55 model_3.pt
-rw-rw-r-- 1 ec2-user ec2-user 210670299 3月   3 16:17 model_5.pt
-rw-rw-r-- 1 ec2-user ec2-user 210670299 3月   3 16:39 model_7.pt
-rw-rw-r-- 1 ec2-user ec2-user 210670299 3月   3 17:01 model_9.pt
-rw-rw-r-- 1 ec2-user ec2-user 210670299 3月   3 17:23 model_11.pt
-rw-rw-r-- 1 ec2-user ec2-user 210670299 3月   3 17:45 model_13.pt
-rw-rw-r-- 1 ec2-user ec2-user 210670299 3月   3 18:07 model_15.pt
-rw-rw-r-- 1 ec2-user ec2-user 210670299 3月   3 18:29 model_17.pt
-rw-rw-r-- 1 ec2-user ec2-user 210670299 3月   3 18:51 model_19.pt
-rw-rw-r-- 1 ec2-user ec2-user 210670299 3月   3 19:13 model_21.pt
-rw-rw-r-- 1 ec2-user ec2-user 210670299 3月   3 19:35 model_23.pt
-rw-rw-r-- 1 ec2-user ec2-user 210670299 3月   3 19:57 model_25.pt
-rw-rw-r-- 1 ec2-user ec2-user 210670299 3月   3 20:19 model_27.pt
-rw-rw-r-- 1 ec2-user ec2-user 210670299 3月   3 20:41 model_29.pt
</code></pre></div>


<hr>
<blockquote>
<ul>
<li>训练模型结论: 每个epoch损失都在稳步下降, 经历30个epoch之后, 训练集上的损失已经下降到每个batch只有0.4左右, 相比于最初的2.2左右, 效果明显.</li>
</ul>
</blockquote>
<hr>
<ul>
<li>第三步: 编写测试辅助函数test_helper.py<ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/src/test_helper.py</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>首先要明确一点, 测试任务的本质是什么?<ul>
<li>1: 模型参数不变, 衡量模型表现(准确率, 召回率, 泛化性能等).</li>
<li>2: 对于生成式任务, 经典模式就是"贪心解码".</li>
</ul>
</li>
</ul>
<hr>
<div class="codehilite" id="__code_102"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_102 pre, #__code_102 code"><span class="md-clipboard__message"></span></button><pre id="__code_103"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_103 pre, #__code_103 code"><span class="md-clipboard__message"></span></button><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">tqdm</span>


<span class="k">def</span> <span class="nf">greedy_decode</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'batch_size'</span><span class="p">]</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">total_test_num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>
    <span class="c1"># batch操作轮数math.ceil向上取整+1, 因为最后一个batch可能不足一个batch size大小, 但是依然需要计算</span>
    <span class="n">step_epoch</span> <span class="o">=</span> <span class="n">total_test_num</span> <span class="o">//</span> <span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">step_epoch</span><span class="p">):</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">test_x</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">results</span> <span class="o">+=</span> <span class="n">batch_predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">'i = '</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">results</span>


<span class="k">def</span> <span class="nf">batch_predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="n">data_num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="c1"># 开辟结果存储list</span>
    <span class="n">predicts</span> <span class="o">=</span> <span class="p">[</span><span class="s1">''</span><span class="p">]</span> <span class="o">*</span> <span class="n">data_num</span>

    <span class="c1"># 输入参数inputs是从文件中加载的numpy类型数据, 需要转换成tensor类型</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

    <span class="c1"># 注意这里的batch_size与config中的batch_size不一定一致</span>
    <span class="c1"># 原因是最后一个batch可能不是64, 因此应当按以下形式初始化隐藏层, 而不要直接调用类内函数</span>
    <span class="n">initial_hidden_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">data_num</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">enc_units</span><span class="p">)</span>

    <span class="c1"># 第一步: 首先经过编码器的处理</span>
    <span class="n">enc_output</span><span class="p">,</span> <span class="n">enc_hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">initial_hidden_state</span><span class="p">)</span>

    <span class="c1"># 为注意力层和解码器层处理准备数据</span>
    <span class="n">dec_hidden</span> <span class="o">=</span> <span class="n">enc_hidden</span>
    <span class="n">dec_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">word_to_id</span><span class="p">[</span><span class="s1">'&lt;START&gt;'</span><span class="p">]]</span> <span class="o">*</span> <span class="n">data_num</span><span class="p">)</span>
    <span class="n">dec_input</span> <span class="o">=</span> <span class="n">dec_input</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># 第二步: 经过注意力层的处理, 得到语义内容分布张量context_vector</span>
    <span class="n">context_vector</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">dec_hidden</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">)</span>

    <span class="c1"># 第三步: 解码器的解码流程是经典的"自回归"模式, 以for循环连续解码max_dec_len次.</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">'max_dec_len'</span><span class="p">]):</span>
        <span class="c1"># 计算上下文</span>
        <span class="n">context_vector</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">dec_hidden</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">)</span>
        <span class="c1"># 单步预测</span>
        <span class="n">predictions</span><span class="p">,</span> <span class="n">dec_hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">context_vector</span><span class="p">)</span>
        <span class="c1"># id转换成字符, 采用贪心解码</span>
        <span class="n">predict_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># 内层for循环是为了处理batch中的每一条数据.</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">p_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">predict_ids</span><span class="o">.</span><span class="n">numpy</span><span class="p">()):</span>
            <span class="n">predicts</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">+=</span> <span class="n">id_to_word</span><span class="p">[</span><span class="n">p_id</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' '</span>

        <span class="n">dec_input</span> <span class="o">=</span> <span class="n">predict_ids</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">predicts</span><span class="p">:</span>
        <span class="c1"># 去掉句子前后空格</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="c1"># 句子小于max_len就结束, 直接截断</span>
        <span class="k">if</span> <span class="s1">'&lt;STOP&gt;'</span> <span class="ow">in</span> <span class="n">pred</span><span class="p">:</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[:</span><span class="n">pred</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s1">'&lt;STOP&gt;'</span><span class="p">)]</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">results</span>
</code></pre></div>


<hr>
<ul>
<li>第四步: 编写测试主函数test.py<ul>
<li>代码文件路径: /home/ec2-user/text_summary/seq2seq/src/test.py</li>
</ul>
</li>
</ul>
<hr>
<div class="codehilite" id="__code_104"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_104 pre, #__code_104 code"><span class="md-clipboard__message"></span></button><pre id="__code_105"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_105 pre, #__code_105 code"><span class="md-clipboard__message"></span></button><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">root_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">root_path</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">src.model</span> <span class="kn">import</span> <span class="n">Seq2Seq</span>
<span class="kn">from</span> <span class="nn">src.test_helper</span> <span class="kn">import</span> <span class="n">greedy_decode</span>
<span class="kn">from</span> <span class="nn">utils.data_loader</span> <span class="kn">import</span> <span class="n">load_test_dataset</span>
<span class="kn">from</span> <span class="nn">utils.config</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">utils.params_utils</span> <span class="kn">import</span> <span class="n">get_params</span>
<span class="kn">from</span> <span class="nn">utils.word2vec_utils</span> <span class="kn">import</span> <span class="n">get_vocab_from_model</span>

<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">"创建字典"</span><span class="p">)</span>
    <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span> <span class="o">=</span> <span class="n">get_vocab_from_model</span><span class="p">(</span><span class="n">word_vector_path</span><span class="p">)</span>

    <span class="c1"># 动态添加字典大小参数</span>
    <span class="n">params</span><span class="p">[</span><span class="s1">'vocab_size'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">"创建模型"</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Seq2Seq</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

    <span class="n">MODEL_PATH</span> <span class="o">=</span> <span class="n">root_path</span> <span class="o">+</span> <span class="s1">'/src/saved_model/'</span> <span class="o">+</span> <span class="s1">'model_29.pt'</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">MODEL_PATH</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">"模型加载完毕!"</span><span class="p">)</span>

    <span class="c1"># 预测结果、保存结果并返回</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">"生成测试数据迭代器"</span><span class="p">)</span>
    <span class="n">test_x</span> <span class="o">=</span> <span class="n">load_test_dataset</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">"开始解码......"</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">greedy_decode</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

    <span class="c1"># 去掉预测结果之间的空格</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">"解码完毕, 开始保存结果......"</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">" "</span><span class="p">,</span> <span class="s2">""</span><span class="p">),</span> <span class="n">results</span><span class="p">))</span>
    <span class="n">save_predict_result</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">results</span>


<span class="k">def</span> <span class="nf">save_predict_result</span><span class="p">(</span><span class="n">results</span><span class="p">):</span>
    <span class="c1"># 读取原始文件(使用其QID列，合并新增的Prediction后再保存)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">"读取原始测试数据..."</span><span class="p">)</span>
    <span class="n">test_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">test_raw_data_path</span><span class="p">)</span>

    <span class="c1"># 填充结果</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">"构建新的DataFrame并保存文件..."</span><span class="p">)</span>
    <span class="n">test_df</span><span class="p">[</span><span class="s1">'Prediction'</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span>

    <span class="c1"># 提取ID和预测结果两列</span>
    <span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[[</span><span class="s1">'QID'</span><span class="p">,</span> <span class="s1">'Prediction'</span><span class="p">]]</span>

    <span class="c1"># 保存结果, 这里自动生成一个结果名</span>
    <span class="n">test_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">get_result_filename</span><span class="p">(),</span> <span class="n">index</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">','</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">"保存测试结果完毕!"</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_result_filename</span><span class="p">():</span>
    <span class="n">now_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">'%Y_%m_</span><span class="si">%d</span><span class="s1">_%H_%M_%S'</span><span class="p">)</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="s1">'seq2seq_'</span> <span class="o">+</span> <span class="n">now_time</span> <span class="o">+</span> <span class="s1">'.csv'</span>
    <span class="n">result_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">result_save_path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result_path</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_106"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_106 pre, #__code_106 code"><span class="md-clipboard__message"></span></button><pre id="__code_107"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_107 pre, #__code_107 code"><span class="md-clipboard__message"></span></button><code><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">get_params</span><span class="p">()</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">results</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_108"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_108 pre, #__code_108 code"><span class="md-clipboard__message"></span></button><pre id="__code_109"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_109 pre, #__code_109 code"><span class="md-clipboard__message"></span></button><code>Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.743 seconds.
Prefix dict has been built successfully.
创建字典
创建模型
模型加载完毕!
生成测试数据迭代器
开始解码......
i =  10
i =  20
i =  30
i =  40
i =  50
i =  60
i =  70
i =  80
i =  90
i =  100
i =  110
i =  120
i =  130
i =  140
i =  150
i =  160
i =  170
i =  180
i =  190
i =  200
i =  210
i =  220
i =  230
i =  240
i =  250
i =  260
i =  270
i =  280
i =  290
i =  300
i =  310
解码完毕, 开始保存结果......
读取原始测试数据...
构建新的DataFrame并保存文件...
保存测试结果完毕!
['&lt;START&gt;发动机烧机油质量不好，建议发动机烧机油，需要分解发动机检查，发动机烧机油，需要分解发动机检查，发动机烧机油，需要分解发动机检查，发动机烧机油，需要分解发动机检查，发动机烧机油，需要分解',
'&lt;START&gt;更换&lt;START&gt;&lt;START&gt;更换&lt;START&gt;&lt;START&gt;更换&lt;START&gt;&lt;START&gt;更换&lt;START&gt;&lt;START&gt;更换&lt;START&gt;&lt;START&gt;更换&lt;START&gt;&lt;START&gt;更换&lt;START&gt;&lt;START&gt;更换&lt;START&gt;&lt;START&gt;更换&lt;START&gt;&lt;START&gt;更换&lt;START&gt;&lt;START&gt;更换&lt;START&gt;&lt;START&gt;更换&lt;START&gt;&lt;START&gt;更换&lt;START&gt;&lt;START&gt;更换&lt;START&gt;&lt;START&gt;更换&lt;START&gt;&lt;START&gt;更换&lt;START&gt;&lt;START&gt;更换',
'&lt;START&gt;更换转向柱上面，更换方向盘，质量好。',
'&lt;START&gt;发动机散热风扇发动机怠速不稳，导致缸压堵塞。',
'&lt;START&gt;，这种情况来看，这种情况来看，这种情况来看，这种情况来看，这种情况来看，这种情况来看，这种情况来看，这种情况来看，这种情况来看，这种情况来看，这种情况来看，这种情况来看，',
'&lt;START&gt;排气管&lt;START&gt;&lt;START&gt;排气管&lt;START&gt;&lt;START&gt;排气管&lt;START&gt;&lt;START&gt;排气管&lt;START&gt;&lt;START&gt;排气管&lt;START&gt;&lt;START&gt;排气管&lt;START&gt;&lt;START&gt;排气管&lt;START&gt;&lt;START&gt;排气管&lt;START&gt;&lt;START&gt;排气管&lt;START&gt;&lt;START&gt;排气管&lt;START&gt;&lt;START&gt;排气管&lt;START&gt;&lt;START&gt;排气管&lt;START&gt;&lt;START&gt;排气管&lt;START&gt;&lt;START&gt;排气管&lt;START&gt;&lt;START&gt;排气管&lt;START&gt;&lt;START&gt;排气管&lt;START&gt;&lt;START&gt;排气管',
'&lt;START&gt;，添加，加，加，加，加，加，加，加，加，加，加，加，加，加，加，加，加，加，加，加，加，加，加，加，',
'&lt;START&gt;情况发动机本身发动机进行检查修理，检查燃油液位',
'&lt;START&gt;轮胎出现裂纹，轮胎使用寿命，轮胎使用寿命，轮胎使用寿命，轮胎使用寿命，轮胎使用寿命，轮胎使用寿命，轮胎使用寿命，轮胎使用寿命，轮胎使用寿命，轮胎使用寿命，轮胎使用寿命，轮胎使用寿命，轮胎使用寿命，轮胎使用寿命，轮胎使用寿命，',
'&lt;START&gt;这种情况主要发动机舱没有声音。属于正常，声音大主要受到碰撞发出声音。']
</code></pre></div>


<hr>
<ul>
<li>模型测试结果: /home/ec2-user/text_summary/seq2seq/data/result/</li>
</ul>
<div class="codehilite" id="__code_110"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_110 pre, #__code_110 code"><span class="md-clipboard__message"></span></button><pre id="__code_111"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_111 pre, #__code_111 code"><span class="md-clipboard__message"></span></button><code>-rw-rw-r-- 1 ec2-user ec2-user 3129895 3月   4 03:41 seq2seq_2021_03_04_03_41_22.csv

Q19,&lt;START&gt;检查一下变速箱油是否问题
Q20,&lt;START&gt;描述，应该雨刷器不回位，受外力喇叭线路故障
Q21,&lt;START&gt;变速箱油清洗，油门踏板传感器清洗，油门踏板传感器清洗，油门踏板传感器清洗，油门踏板传感器清洗，油门&gt;踏板传感器清洗，油门踏板传感器清洗，油门踏板传感器清洗，油门踏板传感器清洗，油门踏板传感器清洗，
Q22,&lt;START&gt;，描述情况分析，现在比较假机油试试，
Q23,&lt;START&gt;先电脑匹配一下，
Q24,&lt;START&gt;，这种情况需要电脑检测一下故障码，才能确定具体故障，具体故障码，检测一下故障码，才能确定具体故障，&gt;具体故障码，检测一下故障码，才能确定具体故障，具体故障码，检测一下
Q25,&lt;START&gt;这款车无法调节螺丝，两侧单，取下
Q26,&lt;START&gt;这种情况，这种情况，这种情况，这种情况，这种情况，这种情况，这种情况，这种情况，这种情况，这种情况&gt;，这种情况，这种情况，这种情况，这种情况，这种情况，这种情况，这种
Q27,&lt;START&gt;二手车检查是否漏油性能是否少
Q28,&lt;START&gt;电瓶没电，电瓶没电，电瓶没电，电瓶没电，电瓶没电，电瓶没电，电瓶没电，电瓶没电，电瓶没电，电瓶没电&gt;，电瓶没电，电瓶没电，电瓶没电，电瓶没电，电瓶没电，电瓶没电，电瓶
Q29,&lt;START&gt;600左右
Q30,&lt;START&gt;汽车汽车汽车汽车汽车汽车&lt;START&gt;&lt;START&gt;汽车汽车汽车汽车汽车汽车&lt;START&gt;&lt;START&gt;汽车汽车汽车汽车汽车汽&gt;车&lt;START&gt;&lt;START&gt;汽车汽车汽车汽车汽车汽车&lt;START&gt;&lt;START&gt;汽车汽车汽车汽车汽车汽车&lt;START&gt;&lt;START&gt;汽车汽车汽车汽车汽
车汽车&lt;START&gt;&lt;START&gt;汽车
Q31,&lt;START&gt;首保，首保，首保做首保，首保
</code></pre></div>


<hr>
<blockquote>
<ul>
<li>测试模型结论: 相比于第二章的textRank模型, seq2seq模型的优点是可以自由生成语句, 不受限于原始文本的表达. 但是肉眼可见的缺点是"重复子串生成", 这也是经典seq2seq模型解决文本摘要问题最大的痛点!!!</li>
</ul>
</blockquote>
<hr>
<hr>
<h3 id="_5">小节总结</h3>
<ul>
<li>
<p>实现文本摘要的seq2seq架构:</p>
<ul>
<li>经典的seq2seq实现文本摘要, 优点在于这是生成式模型, 可以摆脱对于原文的依赖.</li>
<li>学习了seq2seq架构不仅仅可以实现机器翻译任务, 诗歌生成任务, 还可以实现关键信息总结的任务.</li>
</ul>
</li>
<li>
<p>关于baseline-1模型的实现:</p>
<ul>
<li>很大的代码篇幅都在进行数据预处理, 将原始数据处理成模型需要的形式, 是整个数据预处理的核心任务主线.</li>
<li>完成了数据清洗, 有用信息列汇总, 分词, 填充, 数字化映射等一系列处理流程, 并最终将模型要用的数据以文件格式存储, 模型训练, 预测时直接加载即可.</li>
<li>整个模型类采用了经典seq2seq架构中的三个子层类, Encoder, Attention, Decoder, 分贝实现了相关代码.</li>
<li>分开实现训练代码, 预测代码. 预测阶段采用自回归模式, 并采用贪心解码策略.</li>
</ul>
</li>
<li>
<p>关于baseline-1模型效果:</p>
<ul>
<li>优点:<ul>
<li>可以不限于原文自由生成摘要文本.</li>
<li>摘要中也展示了原文中的关键信息.</li>
</ul>
</li>
<li>缺点:<ul>
<li>最大痛点就是"重复子串生成"问题.</li>
<li>这种摘要"看上去"还不如baseline-0的效果更易读.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<hr>
<hr>
<hr>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="./2_2.html" title="2.2 TextRank实现baseline-0模型" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  上一页
                </span>
                2.2 TextRank实现baseline-0模型
              </span>
            </div>
          </a>
        
        
          <a href="./3_2.html" title="3.2 baseline-1模型的优化" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  下一页
                </span>
                3.2 baseline-1模型的优化
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            ©Copyright 2020, AITutorials.CN This website has been reviewed by the review agency. 京ICP备19006137号
          </div>
        
        powered by
        <a href="https://www.mkdocs.org/">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="./index_files/font-awesome.css">
    
      <a href="https://www.linkedin.com/in/%E7%A7%91%E6%8A%80%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8-%E5%8C%97%E4%BA%AC%E6%A9%98%E6%98%9F-6bb7081a1/" class="md-footer-social__link fa fa-linkedin"></a>
    
      <a href="https://weibo.com/u/3469990762?is_all=1" class="md-footer-social__link fa fa-weibo"></a>
    
      <a href="http://bitbucket.org/AITutorials" class="md-footer-social__link fa fa-bitbucket"></a>
    
      <a href="https://github.com/AITutorials/datasets/issues" class="md-footer-social__link fa fa-gitlab"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="./index_files/application.245445c6.js"></script>
      
        
        
          
          <script src="./index_files/lunr.stemmer.support.js"></script>
          
            
              
                <script src="./index_files/tinyseg.js"></script>
              
              
                <script src="./index_files/lunr.ja.js"></script>
              
            
          
          
        
      
      <script>app.initialize({version:"1.1.2",url:{base:".."}})</script>
      
    
  
</body></html>