<!DOCTYPE html>
<!-- saved from url=(0031)http://121.199.45.168:8818/6_4/ -->
<html lang="zh" class="js json svg checked target dataset details fetch supports csstransforms3d no-ios" style=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
      
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
        <link rel="canonical" href="http://0.0.0.0:8818/6_4/">
      
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="ja">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="./index_files/AI.jpg">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-4.4.0">
    
    
      
        <title>6.4 训练策略的优化 - 文本摘要项目</title>
      
    
    
      <link rel="stylesheet" href="./index_files/application.0284f74d.css">
      
      
    
    
      <script src="./index_files/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin="">
        <link rel="stylesheet" href="./index_files/css">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="./index_files/material-icons.css">
    
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "UA-36723568-3", "mkdocs.org")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async="" src="./index_files/analytics.js"></script>
      
    
    
  <script type="text/javascript">(function(){var s=document.createElement("script");var port=window.location.port;s.src="//"+window.location.hostname+":"+port+ "/livereload.js?port=" + port;document.head.appendChild(s);})();</script><script src="./index_files/livereload.js"></script></head>
  
    <body dir="ltr" data-md-state="">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"></path></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#_1" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header" data-md-state="shadow">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="./1_1.html" title="文本摘要项目" class="md-header-nav__button md-logo">
          
            <img src="./index_files/AI.jpg" width="24" height="24">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic" style="width: 648px;">
              文本摘要项目
            </span>
            <span class="md-header-nav__topic" style="width: 648px;">
              
                6.4 训练策略的优化
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix="">
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/AITutorials/manuals" title="前往 Github 仓库" class="md-source" data-md-source="github" data-md-state="done">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    Github
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation" style="height: 509px;">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="./1_1.html" title="文本摘要项目" class="md-nav__button md-logo">
      
        <img src="./index_files/AI.jpg" width="48" height="48">
      
    </a>
    文本摘要项目
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/AITutorials/manuals" title="前往 Github 仓库" class="md-source" data-md-source="github" data-md-state="done">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    Github
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix="">
    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1">
    
    <label class="md-nav__link" for="nav-1">
      第一章:文本摘要项目简介
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: none; overflow: hidden;">
      <label class="md-nav__title" for="nav-1">
        第一章:文本摘要项目简介
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./1_1.html" title="1.1 项目背景介绍" class="md-nav__link">
      1.1 项目背景介绍
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./1_2.html" title="1.2 项目中的数据集初探" class="md-nav__link">
      1.2 项目中的数据集初探
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      第二章:TextRank模型
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: none; overflow: hidden;">
      <label class="md-nav__title" for="nav-2">
        第二章:TextRank模型
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./2_1.html" title="2.1 TextRank算法理论基础" class="md-nav__link">
      2.1 TextRank算法理论基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./2_2.html" title="2.2 TextRank实现baseline-0模型" class="md-nav__link">
      2.2 TextRank实现baseline-0模型
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      第三章:seq2seq经典架构
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: none; overflow: hidden;">
      <label class="md-nav__title" for="nav-3">
        第三章:seq2seq经典架构
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./3_1.html" title="3.1 seq2seq实现baseline-1模型" class="md-nav__link">
      3.1 seq2seq实现baseline-1模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./3_2.html" title="3.2 baseline-1模型的优化" class="md-nav__link">
      3.2 baseline-1模型的优化
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      第四章:PGN先进架构
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: none; overflow: hidden;">
      <label class="md-nav__title" for="nav-4">
        第四章:PGN先进架构
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./4_1.html" title="4.1 PGN架构解析" class="md-nav__link">
      4.1 PGN架构解析
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./4_2.html" title="4.2 PGN模型的数据处理" class="md-nav__link">
      4.2 PGN模型的数据处理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./4_3.html" title="4.3 PGN实现baseline-2模型" class="md-nav__link">
      4.3 PGN实现baseline-2模型
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      第五章:生成式模型的评估方法
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: none; overflow: hidden;">
      <label class="md-nav__title" for="nav-5">
        第五章:生成式模型的评估方法
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./5_1.html" title="5.1 文本摘要评估方法" class="md-nav__link">
      5.1 文本摘要评估方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./5_2.html" title="5.2 ROUGE评估算法实现" class="md-nav__link">
      5.2 ROUGE评估算法实现
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6" checked="">
    
    <label class="md-nav__link" for="nav-6">
      第六章:模型的迭代优化
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: block; overflow: visible;">
      <label class="md-nav__title" for="nav-6">
        第六章:模型的迭代优化
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./6_1.html" title="6.1 PGN + coverage的优化模型" class="md-nav__link">
      6.1 PGN + coverage的优化模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./6_2.html" title="6.2 PGN + beam-search的优化模型" class="md-nav__link">
      6.2 PGN + beam-search的优化模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./6_3.html" title="6.3 数据增强的优化" class="md-nav__link">
      6.3 数据增强的优化
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        6.4 训练策略的优化
      </label>
    
    <a href="" title="6.4 训练策略的优化" class="md-nav__link md-nav__link--active">
      6.4 训练策略的优化
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix="">
      
        <li class="md-nav__item">
  <a href="#_1" title="训练策略优化模型" class="md-nav__link">
    训练策略优化模型
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" title="学习目标" class="md-nav__link">
    学习目标
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scheduled-sampling" title="Scheduled sampling优化策略" class="md-nav__link">
    Scheduled sampling优化策略
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#scheduled-sampling_1" title="Scheduled sampling方法和实现" class="md-nav__link">
    Scheduled sampling方法和实现
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#baseline-7" title="训练baseline-7模型" class="md-nav__link">
    训练baseline-7模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#baseline-7_1" title="评估baseline-7模型" class="md-nav__link">
    评估baseline-7模型
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#weight-tying" title="Weight tying优化策略" class="md-nav__link">
    Weight tying优化策略
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#weight-tying_1" title="Weight tying方法和实现" class="md-nav__link">
    Weight tying方法和实现
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#baseline-8" title="训练baseline-8模型" class="md-nav__link">
    训练baseline-8模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#baseline-8_1" title="评估baseline-8模型" class="md-nav__link">
    评估baseline-8模型
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" title="小节总结" class="md-nav__link">
    小节总结
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7" type="checkbox" id="nav-7">
    
    <label class="md-nav__link" for="nav-7">
      第七章:模型的部署与总结
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1" style="display: none; overflow: hidden;">
      <label class="md-nav__title" for="nav-7">
        第七章:模型的部署与总结
      </label>
      <ul class="md-nav__list" data-md-scrollfix="">
        
        
          
          
          


  <li class="md-nav__item">
    <a href="./7_1.html" title="7.1 硬件优化与模型部署" class="md-nav__link">
      7.1 硬件优化与模型部署
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="./7_2.html" title="7.2 项目总结" class="md-nav__link">
      7.2 项目总结
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc" style="height: 509px;">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix="">
      
        <li class="md-nav__item">
  <a href="#_1" title="训练策略优化模型" class="md-nav__link">
    训练策略优化模型
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" title="学习目标" class="md-nav__link">
    学习目标
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scheduled-sampling" title="Scheduled sampling优化策略" class="md-nav__link">
    Scheduled sampling优化策略
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#scheduled-sampling_1" title="Scheduled sampling方法和实现" class="md-nav__link">
    Scheduled sampling方法和实现
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#baseline-7" title="训练baseline-7模型" class="md-nav__link">
    训练baseline-7模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#baseline-7_1" title="评估baseline-7模型" class="md-nav__link">
    评估baseline-7模型
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#weight-tying" title="Weight tying优化策略" class="md-nav__link">
    Weight tying优化策略
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#weight-tying_1" title="Weight tying方法和实现" class="md-nav__link">
    Weight tying方法和实现
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#baseline-8" title="训练baseline-8模型" class="md-nav__link">
    训练baseline-8模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#baseline-8_1" title="评估baseline-8模型" class="md-nav__link">
    评估baseline-8模型
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" title="小节总结" class="md-nav__link">
    小节总结
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>6.4 训练策略的优化</h1>
                
                <h2 id="_1">训练策略优化模型</h2>
<hr>
<h3 id="_2">学习目标</h3>
<ul>
<li>理解几种优化模型的训练策略.</li>
<li>掌握训练策略实现的代码.</li>
</ul>
<hr>
<p></p><center><img alt="" src="./index_files/30.png"></center><p></p>
<hr>
<h3 id="scheduled-sampling">Scheduled sampling优化策略</h3>
<h4 id="scheduled-sampling_1">Scheduled sampling方法和实现</h4>
<ul>
<li>Scheduled sampling方法介绍: 在生成式模型训练阶段, 常采用Teacher-forcing的策略辅助模型更快的收敛. 但是一直使用Teacher-forcing的策略, 会造成训练和预测的输入样本分布不一致, 也就是著名的"Exposure bias".</li>
</ul>
<hr>
<ul>
<li>解决方法: 对于"Exposure bias", 很好的一个解决策略就是采用"Scheduled sampling", 即在训练阶段, 将ground truth和decoder predict混合起来使用, 作为下一个时间步的decoder input. 具体做法是每个时间步以一个p值概率进行Teacher forcing, 以(1 - p)值概率不进行Teacher forcing. 同时p值的大小随着batch或者epoch衰减.</li>
</ul>
<hr>
<ul>
<li>策略有效性分析: 采用"Scheduled sampling", 在刚开始训练的阶段, 模型所具有的知识很少, 需要采用Teacher forcing的方式, 使用ground truth加速模型的学习和收敛. 到了训练后期, 模型已经掌握了很多数据分布的特征和数据本身的特征, 这个时候将decoder input替换成decoder predict, 保持和预测阶段一致, 来解决"Exposure bias"的问题.</li>
</ul>
<hr>
<ul>
<li>实现相关的核心代码逻辑:<ul>
<li>代码文件路径: /home/ec2-user/text_summary/pgn/utils/func_utils.py</li>
</ul>
</li>
</ul>
<div class="codehilite" id="__code_0"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_0 pre, #__code_0 code"><span class="md-clipboard__message"></span></button><pre id="__code_1"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_1 pre, #__code_1 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 随着训练迭代步数的增长, 计算是否使用Teacher-forcing的概率大小</span>
<span class="k">class</span> <span class="nc">ScheduledSampler</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">phases</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">phases</span> <span class="o">=</span> <span class="n">phases</span>
        <span class="c1"># 通过超参数phases来提前计算出每一个epoch是否采用Teacher forcing的阈值概率</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduled_probs</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">phases</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">phases</span><span class="p">)]</span>

    <span class="k">def</span> <span class="nf">teacher_forcing</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">phase</span><span class="p">):</span>
        <span class="c1"># 生成随机数</span>
        <span class="n">sampling_prob</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="c1"># 每一轮训练时, 通过随机数和阈值概率比较, 来决定是否采用Teacher forcing</span>
        <span class="k">if</span> <span class="n">sampling_prob</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduled_probs</span><span class="p">[</span><span class="n">phase</span><span class="p">]:</span>
            <span class="k">return</span> <span class="bp">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">False</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_2"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_2 pre, #__code_2 code"><span class="md-clipboard__message"></span></button><pre id="__code_3"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_3 pre, #__code_3 code"><span class="md-clipboard__message"></span></button><code><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
    <span class="n">ss</span> <span class="o">=</span> <span class="n">ScheduledSampler</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'scheduled_probs: '</span><span class="p">,</span> <span class="n">ss</span><span class="o">.</span><span class="n">scheduled_probs</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'phases: '</span><span class="p">,</span> <span class="n">ss</span><span class="o">.</span><span class="n">phases</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'teacher_forcing: '</span><span class="p">,</span> <span class="n">ss</span><span class="o">.</span><span class="n">teacher_forcing</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'teacher_forcing: '</span><span class="p">,</span> <span class="n">ss</span><span class="o">.</span><span class="n">teacher_forcing</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_4"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_4 pre, #__code_4 code"><span class="md-clipboard__message"></span></button><pre id="__code_5"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_5 pre, #__code_5 code"><span class="md-clipboard__message"></span></button><code>scheduled_probs:  [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777778, 0.8888888888888888, 1.0]
phases:  10
teacher_forcing:  True
teacher_forcing:  False
</code></pre></div>


<hr>
<h4 id="baseline-7">训练baseline-7模型</h4>
<ul>
<li>Scheduled sampling代码实现.<ul>
<li>第一步: 修改配置文件config.py</li>
<li>第二步: 修改训练代码train.py</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>第一步: 修改配置文件config.py<ul>
<li>代码文件路径: /home/ec2-user/text_summary/pgn/utils/config.py</li>
</ul>
</li>
</ul>
<div class="codehilite" id="__code_6"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_6 pre, #__code_6 code"><span class="md-clipboard__message"></span></button><pre id="__code_7"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_7 pre, #__code_7 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 对这一行做出修改, 设置为True</span>
<span class="n">scheduled_sampling</span> <span class="o">=</span> <span class="bp">True</span>
</code></pre></div>


<hr>
<ul>
<li>第二步: 修改训练代码train.py<ul>
<li>代码文件路径: /home/ec2-user/text_summary/pgn/src/train.py</li>
</ul>
</li>
</ul>
<div class="codehilite" id="__code_8"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_8 pre, #__code_8 code"><span class="md-clipboard__message"></span></button><pre id="__code_9"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_9 pre, #__code_9 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 导入系统工具包</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="c1"># 设置项目的root路径, 方便后续相关代码文件的导入</span>
<span class="n">root_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">root_path</span><span class="p">)</span>

<span class="c1"># 导入项目中用到的工具包</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.nn.utils</span> <span class="kn">import</span> <span class="n">clip_grad_norm_</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">tensorboardX</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>

<span class="c1"># 导入项目中自定义的代码文件, 类, 函数等</span>
<span class="kn">from</span> <span class="nn">src.model</span> <span class="kn">import</span> <span class="n">PGN</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">config</span>
<span class="kn">from</span> <span class="nn">src.evaluate</span> <span class="kn">import</span> <span class="n">evaluate</span>
<span class="kn">from</span> <span class="nn">utils.dataset</span> <span class="kn">import</span> <span class="n">PairDataset</span><span class="p">,</span> <span class="n">collate_fn</span><span class="p">,</span> <span class="n">SampleDataset</span>
<span class="kn">from</span> <span class="nn">utils.func_utils</span> <span class="kn">import</span> <span class="n">ScheduledSampler</span><span class="p">,</span> <span class="n">config_info</span>


<span class="c1"># 编写训练模型的主逻辑函数.</span>
<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">val_dataset</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">start_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">DEVICE</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">DEVICE</span>

    <span class="c1"># 实例化PGN类对象并移动到GPU上(CPU).</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">PGN</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">"loading data......"</span><span class="p">)</span>
    <span class="n">train_data</span> <span class="o">=</span> <span class="n">SampleDataset</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">pairs</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
    <span class="n">val_data</span> <span class="o">=</span> <span class="n">SampleDataset</span><span class="p">(</span><span class="n">val_dataset</span><span class="o">.</span><span class="n">pairs</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">"initializing optimizer......"</span><span class="p">)</span>

    <span class="c1"># 定义模型训练的优化器.</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="c1"># 定义训练集的数据迭代器(这里用到了自定义的collate_fn以服务于PGN特殊的数据结构).</span>
    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span>
                                  <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                  <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                  <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">)</span>

    <span class="c1"># 验证集上的损失值初始化为一个大整数.</span>
    <span class="n">val_losses</span> <span class="o">=</span> <span class="mf">10000000.0</span>

    <span class="c1"># SummaryWriter: 为服务于TensorboardX写日志的可视化工具.</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">log_path</span><span class="p">)</span>

    <span class="n">num_epochs</span> <span class="o">=</span>  <span class="nb">len</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">epochs</span><span class="p">))</span>


    <span class="c1"># ---------------------------------------------------------------------------------------</span>
    <span class="c1"># 下面的代码是6.4小节添加的关于训练策略Scheduled sampling的优化代码.</span>
    <span class="c1"># 工具函数ScheduledSampler()根据当前模型训练epoch的推进, 来决定Teacher-forcing的策略选择</span>
    <span class="n">scheduled_sampler</span> <span class="o">=</span> <span class="n">ScheduledSampler</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">scheduled_sampling</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">'scheduled_sampling mode.'</span><span class="p">)</span>
    <span class="c1"># ---------------------------------------------------------------------------------------</span>


    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">epochs</span><span class="p">)</span> <span class="k">as</span> <span class="n">epoch_progress</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>
            <span class="c1"># 每一个epoch之前打印模型训练的相关配置信息.</span>
            <span class="k">print</span><span class="p">(</span><span class="n">config_info</span><span class="p">(</span><span class="n">config</span><span class="p">))</span>

            <span class="c1"># 初始化每一个batch损失值的存放列表</span>
            <span class="n">batch_losses</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span>


            <span class="c1"># ----------------------------------------------------------------------------</span>
            <span class="c1"># 下面的代码是6.4小节添加的关于训练策略Scheduled sampling的优化代码.</span>
            <span class="c1"># 调用工具函数决定是否使用Teacher-forcing策略.</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">scheduled_sampling</span><span class="p">:</span>
                <span class="n">teacher_forcing</span> <span class="o">=</span> <span class="n">scheduled_sampler</span><span class="o">.</span><span class="n">teacher_forcing</span><span class="p">(</span><span class="n">epoch</span> <span class="o">-</span> <span class="n">start_epoch</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">teacher_forcing</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">'teacher_forcing = {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">teacher_forcing</span><span class="p">))</span>
            <span class="c1"># ----------------------------------------------------------------------------</span>


            <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">num_batches</span><span class="o">//</span><span class="mi">100</span><span class="p">)</span> <span class="k">as</span> <span class="n">batch_progress</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)):</span>
                    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_len</span><span class="p">,</span> <span class="n">y_len</span><span class="p">,</span> <span class="n">oov</span><span class="p">,</span> <span class="n">len_oovs</span> <span class="o">=</span> <span class="n">data</span>
                    <span class="k">assert</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>

                    <span class="c1"># 如果配置有GPU, 则加速训练</span>
                    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">is_cuda</span><span class="p">:</span>
                        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
                        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
                        <span class="n">x_len</span> <span class="o">=</span> <span class="n">x_len</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
                        <span class="n">len_oovs</span> <span class="o">=</span> <span class="n">len_oovs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

                    <span class="c1"># 设置模型进入训练模式(参数参与反向传播和更新)</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

                    <span class="c1"># "老三样"中的第一步: 梯度清零</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                    <span class="c1"># 调用模型进行训练并返回损失值</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_len</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
                                 <span class="n">len_oovs</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
                                 <span class="n">num_batches</span><span class="o">=</span><span class="n">num_batches</span><span class="p">,</span>
                                 <span class="n">teacher_forcing</span><span class="o">=</span><span class="n">teacher_forcing</span><span class="p">)</span>

                    <span class="n">batch_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

                    <span class="c1"># "老三样"中的第二步: 反向传播</span>
                    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

                    <span class="c1"># 为防止梯度爆炸(gradient explosion)而进行梯度裁剪.</span>
                    <span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">config</span><span class="o">.</span><span class="n">max_grad_norm</span><span class="p">)</span>
                    <span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">config</span><span class="o">.</span><span class="n">max_grad_norm</span><span class="p">)</span>
                    <span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">config</span><span class="o">.</span><span class="n">max_grad_norm</span><span class="p">)</span>

                    <span class="c1"># "老三样"中的第三步: 参数更新</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                    <span class="c1"># 每隔100个batch记录一下损失值信息.</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">batch</span> <span class="o">%</span> <span class="mi">100</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">batch_progress</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="n">f</span><span class="s1">'Epoch {epoch}'</span><span class="p">)</span>
                        <span class="n">batch_progress</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">Batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">Loss</span><span class="o">=</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                        <span class="n">batch_progress</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
                        <span class="c1"># 向tensorboard中写入损失值信息.</span>
                        <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="n">f</span><span class="s1">'Average loss for epoch {epoch}'</span><span class="p">,</span>
                                           <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">batch_losses</span><span class="p">),</span>
                                           <span class="n">global_step</span><span class="o">=</span><span class="n">batch</span><span class="p">)</span>

            <span class="c1"># 将一个轮次中所有batch的平均损失值作为这个epoch的损失值.</span>
            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">batch_losses</span><span class="p">)</span>

            <span class="n">epoch_progress</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="n">f</span><span class="s1">'Epoch {epoch}'</span><span class="p">)</span>
            <span class="n">epoch_progress</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">Loss</span><span class="o">=</span><span class="n">epoch_loss</span><span class="p">)</span>
            <span class="n">epoch_progress</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

            <span class="c1"># 结束每一个epoch训练后, 直接在验证集上跑一下模型效果</span>
            <span class="n">avg_val_loss</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_data</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>

            <span class="k">print</span><span class="p">(</span><span class="s1">'training loss:{}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">),</span> <span class="s1">'validation loss:{}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">avg_val_loss</span><span class="p">))</span>

            <span class="c1"># 更新更小的验证集损失值evaluating loss.</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">avg_val_loss</span> <span class="o">&lt;</span> <span class="n">val_losses</span><span class="p">):</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">encoder_save_name</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">decoder</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">decoder_save_name</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">attention</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">attention_save_name</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">reduce_state</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">reduce_state_save_name</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">config</span><span class="o">.</span><span class="n">model_save_path</span><span class="p">)</span>
                <span class="n">val_losses</span> <span class="o">=</span> <span class="n">avg_val_loss</span>

                <span class="c1"># 将更小的损失值写入文件中</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">losses_path</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">val_losses</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

    <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_10"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_10 pre, #__code_10 code"><span class="md-clipboard__message"></span></button><pre id="__code_11"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_11 pre, #__code_11 code"><span class="md-clipboard__message"></span></button><code><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
    <span class="c1"># Prepare dataset for training.</span>
    <span class="n">DEVICE</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'DEVICE: '</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">)</span>

    <span class="c1"># 将构建数据集的路径改为config.train_data_path, 具体采用单词替换后的训练集</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">PairDataset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">train_data_path</span><span class="p">,</span>
                          <span class="n">max_enc_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_enc_len</span><span class="p">,</span>
                          <span class="n">max_dec_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_dec_len</span><span class="p">,</span>
                          <span class="n">truncate_enc</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">truncate_enc</span><span class="p">,</span>
                          <span class="n">truncate_dec</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">truncate_dec</span><span class="p">)</span>
    <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">PairDataset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">val_data_path</span><span class="p">,</span>
                              <span class="n">max_enc_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_enc_len</span><span class="p">,</span>
                              <span class="n">max_dec_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_dec_len</span><span class="p">,</span>
                              <span class="n">truncate_enc</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">truncate_enc</span><span class="p">,</span>
                              <span class="n">truncate_dec</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">truncate_dec</span><span class="p">)</span>

    <span class="n">vocab</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">embed_file</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">embed_file</span><span class="p">)</span>

    <span class="n">train</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">val_dataset</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">start_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_12"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_12 pre, #__code_12 code"><span class="md-clipboard__message"></span></button><pre id="__code_13"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_13 pre, #__code_13 code"><span class="md-clipboard__message"></span></button><code>DEVICE:  cuda
Reading dataset /home/ec2-user/text_summary/pgn/data/train.txt... 140000 pairs.
Reading dataset /home/ec2-user/text_summary/pgn/data/dev.txt...
[[0%|          | 0/4375 [00:00&lt;?, ?it/s]
[[Epoch 0:   0%|          | 0/43 [00:01&lt;?, ?it/s]
[[Epoch 0:   0%|          | 0/43 [00:01&lt;?, ?it/s, Batch=0, Loss=7.2]
[[Epoch 0:   2%|▏         | 1/43 [00:01&lt;01:05,  1.55s/it, Batch=0, Loss=7.2]
[[0%|          | 1/4375 [00:01&lt;1:53:09,  1.55s/it]
[[0%|          | 2/4375 [00:02&lt;1:47:52,  1.48s/it]
[[0%|          | 3/4375 [00:04&lt;1:45:31,  1.45s/it]
[[0%|          | 4/4375 [00:05&lt;1:42:08,  1.40s/it]
[[0%|          | 5/4375 [00:06&lt;1:39:37,  1.37s/it]
[[0%|          | 6/4375 [00:08&lt;1:51:42,  1.53s/it]


......
......
......


[[99%|█████████▊| 396/402 [03:58&lt;00:03,  1.95it/s]
[[99%|█████████▉| 397/402 [03:59&lt;00:02,  1.73it/s]
[[99%|█████████▉| 398/402 [04:00&lt;00:02,  1.44it/s]
[[99%|█████████▉| 399/402 [04:01&lt;00:01,  1.54it/s]
[[100%|█████████▉| 400/402 [04:01&lt;00:01,  1.66it/s]
[[100%|█████████▉| 401/402 [04:02&lt;00:00,  1.60it/s]
[[100%|██████████| 402/402 [04:03&lt;00:00,  1.27it/s]
[[100%|██████████| 402/402 [04:03&lt;00:00,  1.65it/s]
Epoch 9: 100%|██████████| 10/10 [21:27:18&lt;00:00, 7723.90s/it, Loss=3.7]
12870 pairs.
loading data......
initializing optimizer......
scheduled_sampling mode.
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = False,source = train
teacher_forcing = True
validating
training loss:4.552305130713327 validation loss:4.524957228655839
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = False,source = train
teacher_forcing = True
validating
training loss:3.7868157992226736 validation loss:4.627957730744016
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = False,source = train
teacher_forcing = True
validating
training loss:3.3115914395468575 validation loss:4.873124810000557
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = False,source = train
teacher_forcing = True
validating
training loss:2.9778448364257812 validation loss:5.174075812249634
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = False,source = train
teacher_forcing = True
validating
training loss:2.732732899093628 validation loss:5.468189263225195
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = False,source = train
teacher_forcing = True
validating
training loss:2.5524693885530745 validation loss:5.7531704665416505
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = False,source = train
teacher_forcing = True
validating
training loss:2.4137240750721523 validation loss:6.042709622217055
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = False,source = train
teacher_forcing = False
validating
training loss:4.1108463183266775 validation loss:5.622990067325421
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = False,source = train
teacher_forcing = False
validating
training loss:3.85217619972229 validation loss:5.791738596721668
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = False,source = train
teacher_forcing = False
validating
training loss:3.6952303215571813 validation loss:5.919977106265168
</code></pre></div>


<hr>
<blockquote>
<ul>
<li>结论: 我们发现前7轮epoch的时候teacher_forcing=True, 最后3轮epoch的时候teacher_forcing=False. 并且我们验证集上最小的损失恰恰在第一个epoch就出现了. 结合前面几章的经验, 提示我们在当前数据集和任务上, 每次迭代训练2-3个epoch就足够了.</li>
</ul>
</blockquote>
<hr>
<h4 id="baseline-7_1">评估baseline-7模型</h4>
<ul>
<li>关于baseline-7模型的评估代码:<ul>
<li>代码文件predict.py只需要对参数beam_search做出设定, 其他全部不变.</li>
<li>代码文件rouge_eval.py全部保持不变.</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>首先评估贪心解码的模型效果:<ul>
<li>在代码文件predict.py中, 只需要对参数beam_search设置为False即可.</li>
<li>代码文件路径: /home/ec2-user/text_summary/pgn/src/predict.py</li>
</ul>
</li>
</ul>
<hr>
<div class="codehilite" id="__code_14"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_14 pre, #__code_14 code"><span class="md-clipboard__message"></span></button><pre id="__code_15"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_15 pre, #__code_15 code"><span class="md-clipboard__message"></span></button><code>    <span class="c1"># ---------------------------------------------------------------------</span>
    <span class="c1"># 只需要将最后一个形参beam_search设置为False, 即可以贪心解码预测.</span>
    <span class="nd">@timer</span><span class="p">(</span><span class="n">module</span><span class="o">=</span><span class="s1">'doing prediction'</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">beam_search</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="c1"># ---------------------------------------------------------------------</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">tokenize</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">oov</span> <span class="o">=</span> <span class="n">source2ids</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">len_oovs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">oov</span><span class="p">)])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">x_padding_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">beam_search</span><span class="p">:</span>
            <span class="n">summary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beam_search</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                                       <span class="n">max_sum_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_dec_steps</span><span class="p">,</span>
                                       <span class="n">beam_width</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">beam_size</span><span class="p">,</span>
                                       <span class="n">len_oovs</span><span class="o">=</span><span class="n">len_oovs</span><span class="p">,</span>
                                       <span class="n">x_padding_masks</span><span class="o">=</span><span class="n">x_padding_masks</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">summary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_search</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                                         <span class="n">max_sum_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_dec_steps</span><span class="p">,</span>
                                         <span class="n">len_oovs</span><span class="o">=</span><span class="n">len_oovs</span><span class="p">,</span>
                                         <span class="n">x_padding_masks</span><span class="o">=</span><span class="n">x_padding_masks</span><span class="p">)</span>

        <span class="n">summary</span> <span class="o">=</span> <span class="n">outputids2words</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="n">oov</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">summary</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'&lt;SOS&gt;'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'&lt;EOS&gt;'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_16"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_16 pre, #__code_16 code"><span class="md-clipboard__message"></span></button><pre id="__code_17"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_17 pre, #__code_17 code"><span class="md-clipboard__message"></span></button><code><span class="n">cd</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ec2</span><span class="o">-</span><span class="n">user</span><span class="o">/</span><span class="n">text_summary</span><span class="o">/</span><span class="n">pgn</span><span class="o">/</span><span class="n">src</span><span class="o">/</span>

<span class="n">python</span> <span class="n">rouge_eval</span><span class="o">.</span><span class="n">py</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_18"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_18 pre, #__code_18 code"><span class="md-clipboard__message"></span></button><pre id="__code_19"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_19 pre, #__code_19 code"><span class="md-clipboard__message"></span></button><code>实例化Rouge对象......
Reading from  /home/ec2-user/text_summary/pgn/data/dev.txt
self.refs[]包含的样本数:  3000
Test set contains 3000 samples.
实例化Predict对象......
Reading dataset /home/ec2-user/text_summary/pgn/data/train.txt... 140000 pairs.
15.963327169418335 secs used for  initalize predicter
利用模型对article进行预测, 并通过Rouge对象进行评估......
Building hypotheses.
0.07332539558410645 secs used for  doing prediction
0.055742502212524414 secs used for  doing prediction
0.037644386291503906 secs used for  doing prediction
0.05304408073425293 secs used for  doing prediction
0.030008316040039062 secs used for  doing prediction
0.05388140678405762 secs used for  doing prediction
0.01584935188293457 secs used for  doing prediction
0.06547999382019043 secs used for  doing prediction
0.05590486526489258 secs used for  doing prediction
0.021546125411987305 secs used for  doing prediction
0.04329800605773926 secs used for  doing prediction
0.05656576156616211 secs used for  doing prediction


......
......
......


0.05123019218444824 secs used for  doing prediction
0.009801626205444336 secs used for  doing prediction
0.05459141731262207 secs used for  doing prediction
0.05174136161804199 secs used for  doing prediction
0.05583930015563965 secs used for  doing prediction
0.05422520637512207 secs used for  doing prediction
0.052309513092041016 secs used for  doing prediction
0.01446390151977539 secs used for  doing prediction
116.43013048171997 secs used for  building hypotheses
开始用Rouge规则进行评估......
Calculating average rouge scores.
rouge1:  {'f': 0.20571242815278154, 'p': 0.22165821440593508, 'r': 0.2691005485951501}
rouge2:  {'f': 0.05577086927945189, 'p': 0.05833918727814196, 'r': 0.07897281222802614}
rougeL:  {'f': 0.23440123410369454, 'p': 0.3021595446736551, 'r': 0.22998070380868565}
将评估结果写入结果文件中......
</code></pre></div>


<hr>
<ul>
<li>再评估Beam search解码的效果:<ul>
<li>在代码文件predict.py中, 只需要对参数beam_search设置为True即可.</li>
<li>代码文件路径: /home/ec2-user/text_summary/pgn/src/predict.py</li>
</ul>
</li>
</ul>
<hr>
<div class="codehilite" id="__code_20"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_20 pre, #__code_20 code"><span class="md-clipboard__message"></span></button><pre id="__code_21"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_21 pre, #__code_21 code"><span class="md-clipboard__message"></span></button><code>    <span class="c1"># ---------------------------------------------------------------------</span>
    <span class="c1"># 只需要将最后一个形参beam_search设置为True, 即可以Beam search解码预测.</span>
    <span class="nd">@timer</span><span class="p">(</span><span class="n">module</span><span class="o">=</span><span class="s1">'doing prediction'</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">beam_search</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="c1"># ---------------------------------------------------------------------</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">tokenize</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">oov</span> <span class="o">=</span> <span class="n">source2ids</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">len_oovs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">oov</span><span class="p">)])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">x_padding_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">beam_search</span><span class="p">:</span>
            <span class="n">summary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beam_search</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                                       <span class="n">max_sum_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_dec_steps</span><span class="p">,</span>
                                       <span class="n">beam_width</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">beam_size</span><span class="p">,</span>
                                       <span class="n">len_oovs</span><span class="o">=</span><span class="n">len_oovs</span><span class="p">,</span>
                                       <span class="n">x_padding_masks</span><span class="o">=</span><span class="n">x_padding_masks</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">summary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_search</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                                         <span class="n">max_sum_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_dec_steps</span><span class="p">,</span>
                                         <span class="n">len_oovs</span><span class="o">=</span><span class="n">len_oovs</span><span class="p">,</span>
                                         <span class="n">x_padding_masks</span><span class="o">=</span><span class="n">x_padding_masks</span><span class="p">)</span>

        <span class="n">summary</span> <span class="o">=</span> <span class="n">outputids2words</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="n">oov</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">summary</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'&lt;SOS&gt;'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'&lt;EOS&gt;'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_22"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_22 pre, #__code_22 code"><span class="md-clipboard__message"></span></button><pre id="__code_23"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_23 pre, #__code_23 code"><span class="md-clipboard__message"></span></button><code><span class="nb">cd</span> /home/ec2-user/text_summary/pgn/src/

python rouge_eval.py
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_24"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_24 pre, #__code_24 code"><span class="md-clipboard__message"></span></button><pre id="__code_25"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_25 pre, #__code_25 code"><span class="md-clipboard__message"></span></button><code>实例化Rouge对象......
Reading from  /home/ec2-user/ec2-user/zhudejun/text_summary/text_summary/pgn/data/dev.txt
self.refs[]包含的样本数:  3000
Test set contains 3000 samples.
实例化Predict对象......
Reading dataset /home/ec2-user/ec2-user/zhudejun/text_summary/text_summary/pgn/data/train.txt... 139998 pairs.
15.918241024017334 secs used for  initalize predicter
利用模型对article进行预测, 并通过Rouge对象进行评估......
Building hypotheses.
0.3589177131652832 secs used for  doing prediction
0.3374664783477783 secs used for  doing prediction
0.3456692695617676 secs used for  doing prediction
0.3331456184387207 secs used for  doing prediction
0.34146881103515625 secs used for  doing prediction
0.334575891494751 secs used for  doing prediction
0.33663010597229004 secs used for  doing prediction
0.3577096462249756 secs used for  doing prediction
0.3289070129394531 secs used for  doing prediction
0.3339529037475586 secs used for  doing prediction


......
......
......


0.3524472713470459 secs used for  doing prediction
0.35205864906311035 secs used for  doing prediction
0.36118149757385254 secs used for  doing prediction
0.40877795219421387 secs used for  doing prediction
0.3536827564239502 secs used for  doing prediction
0.366757869720459 secs used for  doing prediction
0.35179853439331055 secs used for  doing prediction
0.35098910331726074 secs used for  doing prediction
0.35169148445129395 secs used for  doing prediction
0.35124707221984863 secs used for  doing prediction
0.3597400188446045 secs used for  doing prediction
0.3530762195587158 secs used for  doing prediction
0.35770344734191895 secs used for  doing prediction
0.3506617546081543 secs used for  doing prediction
1024.457626581192 secs used for  building hypotheses
开始用Rouge规则进行评估......
Calculating average rouge scores.
rouge1:  {'f': 0.19552847393917322, 'p': 0.1587446851587022, 'r': 0.33453045142923926}
rouge2:  {'f': 0.05518565025066199, 'p': 0.04381349206349152, 'r': 0.10198874959312032}
rougeL:  {'f': 0.24967671068636252, 'p': 0.27878950788684004, 'r': 0.2761432124695714}
将评估结果写入结果文件中......
</code></pre></div>


<hr>
<hr>
<h3 id="weight-tying">Weight tying优化策略</h3>
<h4 id="weight-tying_1">Weight tying方法和实现</h4>
<ul>
<li>Weight tying方法介绍: 其实这个策略要解决的问题还是上面提出来的"Exposure bias"问题, 除了用训练后期去除掉Teacher forcing的方法. 我们还可以通过让Encoder和Decoder的词嵌入尽量一致来纠正这种偏差.</li>
</ul>
<hr>
<ul>
<li>解决方法: 对于"Exposure bias"另一个很好的解决策略就是采用"Weight tying", 字面意思就是权重的绑定, 具体做法是将Encoder和Decoder的embedding权重矩阵进行共享.</li>
</ul>
<hr>
<ul>
<li>策略有效性分析: 对embedding权重矩阵进行共享, 这样就使得Encoder和Decoder的输入词向量表达完全相同了, 一定程度上可以缓解"Exposure bias".</li>
</ul>
<hr>
<h4 id="baseline-8">训练baseline-8模型</h4>
<ul>
<li>Weight tying代码实现.<ul>
<li>第一步: 修改配置文件config.py</li>
<li>第二步: 修改模型代码model.py</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>第一步: 修改配置文件config.py<ul>
<li>代码文件路径: /home/ec2-user/text_summary/pgn/utils/config.py</li>
</ul>
</li>
</ul>
<div class="codehilite" id="__code_26"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_26 pre, #__code_26 code"><span class="md-clipboard__message"></span></button><pre id="__code_27"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_27 pre, #__code_27 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 对这一行做出修改, 设置为True</span>
<span class="n">weight_tying</span> <span class="o">=</span> <span class="bp">True</span>
</code></pre></div>


<hr>
<ul>
<li>第二步: 修改模型代码model.py<ul>
<li>代码文件路径: /home/ec2-user/text_summary/pgn/src/model.py</li>
<li>具体来说, 只有Encoder, Decoder, PGN这三个类需要作出修改, 其他保持不变.</li>
</ul>
</li>
</ul>
<div class="codehilite" id="__code_28"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_28 pre, #__code_28 code"><span class="md-clipboard__message"></span></button><pre id="__code_29"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_29 pre, #__code_29 code"><span class="md-clipboard__message"></span></button><code><span class="c1"># 第1处修改: 在Encoder中的forward()函数中.</span>
<span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">rnn_drop</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">rnn_drop</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">decoder_embedding</span><span class="p">):</span>
        <span class="c1"># ---------------------------------------------------------------------------</span>
        <span class="c1"># 下面的代码是6.4小节添加的关于weight tying训练策略的代码. </span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">weight_tying</span><span class="p">:</span>
            <span class="n">embedded</span> <span class="o">=</span> <span class="n">decoder_embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>
        <span class="c1"># ---------------------------------------------------------------------------</span>

        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>


<span class="c1"># 第2处修改: 在Decoder中的forward()函数中.</span>
<span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">enc_hidden_size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 解码器端也采用跟随模型一起训练的方式, 得到词嵌入层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="c1"># self.DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>

        <span class="c1"># 解码器的主体结构采用单向LSTM, 区别于编码器端的双向LSTM</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="c1"># 因为要将decoder hidden state和context vector进行拼接, 因此需要3倍的hidden_size维度设置</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">pointer</span><span class="p">:</span>
            <span class="c1"># 因为要根据论文中的公式8进行运算, 所谓输入维度上匹配的是4 * hidden_size + embed_size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">w_gen</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="n">embed_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">decoder_states</span><span class="p">,</span> <span class="n">context_vector</span><span class="p">):</span>
        <span class="c1"># 首先计算Decoder的前向传播输出张量</span>
        <span class="n">decoder_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x_t</span><span class="p">)</span>
        <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">decoder_emb</span><span class="p">,</span> <span class="n">decoder_states</span><span class="p">)</span>

        <span class="c1"># 接下来就是论文中的公式4的计算.</span>
        <span class="c1"># 将context vector和decoder state进行拼接, (batch_size, 3*hidden_units)</span>
        <span class="n">decoder_output</span> <span class="o">=</span> <span class="n">decoder_output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="n">concat_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">decoder_output</span><span class="p">,</span> <span class="n">context_vector</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># 经历两个全连接层V和V1后,再进行softmax运算, 得到vocabulary distribution</span>
        <span class="c1"># (batch_size, hidden_units)</span>
        <span class="n">FF1_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W1</span><span class="p">(</span><span class="n">concat_vector</span><span class="p">)</span>


        <span class="c1"># ---------------------------------------------------------------------------</span>
        <span class="c1"># 下面的代码是6.4小节添加的关于weight tying训练策略的代码.</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">weight_tying</span><span class="p">:</span>
            <span class="n">FF2_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">FF1_out</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">weight</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">FF2_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W2</span><span class="p">(</span><span class="n">FF1_out</span><span class="p">)</span>
        <span class="c1"># (batch_size, vocab_size)</span>
        <span class="n">p_vocab</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">FF2_out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># ---------------------------------------------------------------------------</span>


        <span class="c1"># 构造decoder state s_t.</span>
        <span class="n">h_dec</span><span class="p">,</span> <span class="n">c_dec</span> <span class="o">=</span> <span class="n">decoder_states</span>
        <span class="c1"># (1, batch_size, 2*hidden_units)</span>
        <span class="n">s_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">h_dec</span><span class="p">,</span> <span class="n">c_dec</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># p_gen是通过context vector h_t, decoder state s_t, decoder input x_t, 三个部分共同计算出来的.</span>
        <span class="c1"># 下面的部分是计算论文中的公式8.</span>
        <span class="n">p_gen</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">pointer</span><span class="p">:</span>
            <span class="c1"># 这里面采用了直接拼接3部分输入张量, 然后经历一个共同的全连接层w_gen, 和原始论文的计算不同.</span>
            <span class="c1"># 这也给了大家提示, 可以提高模型的复杂度, 完全模拟原始论文中的3个全连接层来实现代码.</span>
            <span class="n">x_gen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">context_vector</span><span class="p">,</span> <span class="n">s_t</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">decoder_emb</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">p_gen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w_gen</span><span class="p">(</span><span class="n">x_gen</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">p_vocab</span><span class="p">,</span> <span class="n">decoder_states</span><span class="p">,</span> <span class="n">p_gen</span>


<span class="c1"># 第3处修改: 在Decoder中的forward()函数中.</span>
<span class="k">class</span> <span class="nc">PGN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PGN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 初始化字典对象</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">v</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">DEVICE</span>

        <span class="c1"># 依次初始化4个类对象</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="n">config</span><span class="o">.</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="n">config</span><span class="o">.</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduce_state</span> <span class="o">=</span> <span class="n">ReduceState</span><span class="p">()</span>

    <span class="c1"># 计算最终分布的函数</span>
    <span class="k">def</span> <span class="nf">get_final_distribution</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">p_gen</span><span class="p">,</span> <span class="n">p_vocab</span><span class="p">,</span> <span class="n">attention_weights</span><span class="p">,</span> <span class="n">max_oov</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">pointer</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">p_vocab</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># 进行p_gen概率值的裁剪, 具体取值范围可以调参</span>
        <span class="n">p_gen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">p_gen</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)</span>
        <span class="c1"># 接下来两行代码是论文中公式9的计算.</span>
        <span class="n">p_vocab_weighted</span> <span class="o">=</span> <span class="n">p_gen</span> <span class="o">*</span> <span class="n">p_vocab</span>
        <span class="c1"># (batch_size, seq_len)</span>
        <span class="n">attention_weighted</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p_gen</span><span class="p">)</span> <span class="o">*</span> <span class="n">attention_weights</span>

        <span class="c1"># 得到扩展后的单词概率分布(extended-vocab probability distribution)</span>
        <span class="c1"># extended_size = len(self.v) + max_oovs</span>
        <span class="n">extension</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_oov</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="c1"># (batch_size, extended_vocab_size)</span>
        <span class="n">p_vocab_extended</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">p_vocab_weighted</span><span class="p">,</span> <span class="n">extension</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># 根据论文中的公式9, 累加注意力值attention_weighted到对应的单词位置x</span>
        <span class="n">final_distribution</span> <span class="o">=</span> <span class="n">p_vocab_extended</span><span class="o">.</span><span class="n">scatter_add_</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="n">attention_weighted</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">final_distribution</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_len</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">len_oovs</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">num_batches</span><span class="p">,</span> <span class="n">teacher_forcing</span><span class="p">):</span>
        <span class="n">x_copy</span> <span class="o">=</span> <span class="n">replace_oovs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>
        <span class="n">x_padding_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>


        <span class="c1"># --------------------------------------------------------------------------------</span>
        <span class="c1"># 下面一行代码修改, 加入self.decoder.embedding是整个PGN类中唯一一行需要修改的代码.</span>
        <span class="c1"># 下面一行代码是6.4小节添加的关于weight tying训练策略的代码.</span>
        <span class="c1"># 第一步: 进行Encoder的编码计算</span>
        <span class="n">encoder_output</span><span class="p">,</span> <span class="n">encoder_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x_copy</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">embedding</span><span class="p">)</span>
        <span class="c1"># --------------------------------------------------------------------------------</span>


        <span class="n">decoder_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduce_state</span><span class="p">(</span><span class="n">encoder_states</span><span class="p">)</span>

        <span class="c1"># 用全零张量初始化coverage vector.</span>
        <span class="n">coverage_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">())</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>

        <span class="c1"># 初始化每一步的损失值</span>
        <span class="n">step_losses</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># 第二步: 循环解码, 每一个时间步都经历注意力的计算, 解码器层的计算.</span>
        <span class="c1"># 初始化解码器的输入, 是ground truth中的第一列, 即真实摘要的第一个字符</span>
        <span class="n">x_t</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="c1"># 如果使用Teacher_forcing, 则每一个时间步用真实标签来指导训练</span>
            <span class="k">if</span> <span class="n">teacher_forcing</span><span class="p">:</span>
                <span class="n">x_t</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="n">t</span><span class="p">]</span>

            <span class="n">x_t</span> <span class="o">=</span> <span class="n">replace_oovs</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>
            <span class="n">y_t</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>

            <span class="c1"># 通过注意力层计算context vector.</span>
            <span class="n">context_vector</span><span class="p">,</span> <span class="n">attention_weights</span><span class="p">,</span> <span class="n">coverage_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">decoder_states</span><span class="p">,</span>
                                                                                <span class="n">encoder_output</span><span class="p">,</span>
                                                                                <span class="n">x_padding_masks</span><span class="p">,</span>
                                                                                <span class="n">coverage_vector</span><span class="p">)</span>

            <span class="c1"># 通过解码器层计算得到vocab distribution和hidden states</span>
            <span class="n">p_vocab</span><span class="p">,</span> <span class="n">decoder_states</span><span class="p">,</span> <span class="n">p_gen</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x_t</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">decoder_states</span><span class="p">,</span> <span class="n">context_vector</span><span class="p">)</span>

            <span class="c1"># 得到最终的概率分布</span>
            <span class="n">final_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_final_distribution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">p_gen</span><span class="p">,</span><span class="n">p_vocab</span><span class="p">,</span><span class="n">attention_weights</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">len_oovs</span><span class="p">))</span>

            <span class="c1"># 第t个时间步的预测结果, 将作为第t + 1个时间步的输入(如果采用Teacher-forcing则不同).</span>
            <span class="n">x_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">final_dist</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>

            <span class="c1"># 根据模型对target tokens的预测, 来获取到预测的概率</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">pointer</span><span class="p">:</span>
                <span class="n">y_t</span> <span class="o">=</span> <span class="n">replace_oovs</span><span class="p">(</span><span class="n">y_t</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>
            <span class="n">target_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">final_dist</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">y_t</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">target_probs</span> <span class="o">=</span> <span class="n">target_probs</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># 将解码器端的PAD用padding mask遮掩掉, 防止计算loss时的干扰</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">y_t</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span>
            <span class="c1"># 为防止计算log(0)而做的数学上的平滑处理</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">target_probs</span> <span class="o">+</span> <span class="n">config</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>

            <span class="c1"># 关于coverage loss的处理逻辑代码.</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">coverage</span><span class="p">:</span>
                <span class="c1"># 按照论文中的公式12, 计算covloss.</span>
                <span class="n">ct_min</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">,</span> <span class="n">coverage_vector</span><span class="p">)</span>
                <span class="n">cov_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ct_min</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="c1"># 按照论文中的公式13, 计算加入coverage机制后整个模型的损失值.</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="n">config</span><span class="o">.</span><span class="n">LAMBDA</span> <span class="o">*</span> <span class="n">cov_loss</span>


            <span class="c1"># 先遮掩, 再添加损失值</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">*</span> <span class="n">mask</span>
            <span class="n">step_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="c1"># 第三步: 计算一个批次样本的损失值, 为反向传播做准备.</span>
        <span class="n">sample_losses</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">step_losses</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># 统计非PAD的字符个数, 作为当前批次序列的有效长度</span>
        <span class="n">seq_len_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">batch_seq_len</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">seq_len_mask</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># 计算批次样本的平均损失值</span>
        <span class="n">batch_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample_losses</span> <span class="o">/</span> <span class="n">batch_seq_len</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">batch_loss</span>
</code></pre></div>


<hr>
<ul>
<li>训练部分的主要逻辑代码train.py完全和之前保持一致, 无需修改.<ul>
<li>代码文件路径: /home/ec2-user/text_summary/pgn/src/train.py</li>
</ul>
</li>
</ul>
<div class="codehilite" id="__code_30"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_30 pre, #__code_30 code"><span class="md-clipboard__message"></span></button><pre id="__code_31"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_31 pre, #__code_31 code"><span class="md-clipboard__message"></span></button><code><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
    <span class="c1"># Prepare dataset for training.</span>
    <span class="n">DEVICE</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'DEVICE: '</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">)</span>

    <span class="c1"># 将构建数据集的路径改为config.train_data_path, 具体采用单词替换后的14万样本训练集</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">PairDataset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">train_data_path</span><span class="p">,</span>
                          <span class="n">max_enc_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_enc_len</span><span class="p">,</span>
                          <span class="n">max_dec_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_dec_len</span><span class="p">,</span>
                          <span class="n">truncate_enc</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">truncate_enc</span><span class="p">,</span>
                          <span class="n">truncate_dec</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">truncate_dec</span><span class="p">)</span>
    <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">PairDataset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">val_data_path</span><span class="p">,</span>
                              <span class="n">max_enc_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_enc_len</span><span class="p">,</span>
                              <span class="n">max_dec_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_dec_len</span><span class="p">,</span>
                              <span class="n">truncate_enc</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">truncate_enc</span><span class="p">,</span>
                              <span class="n">truncate_dec</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">truncate_dec</span><span class="p">)</span>

    <span class="n">vocab</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">embed_file</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">embed_file</span><span class="p">)</span>

    <span class="n">train</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">val_dataset</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">start_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_32"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_32 pre, #__code_32 code"><span class="md-clipboard__message"></span></button><pre id="__code_33"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_33 pre, #__code_33 code"><span class="md-clipboard__message"></span></button><code>DEVICE:  cuda
Reading dataset /home/ec2-user/text_summary/pgn/data/train.txt... 140000 pairs.
Reading dataset /home/ec2-user/text_summary/pgn/data/dev.txt...
[[0%|          | 0/4375 [00:00&lt;?, ?it/s]
[[Epoch 0:   0%|          | 0/43 [00:01&lt;?, ?it/s]
[[Epoch 0:   0%|          | 0/43 [00:01&lt;?, ?it/s, Batch=0, Loss=7.2]
[[Epoch 0:   2%|▏         | 1/43 [00:01&lt;01:05,  1.55s/it, Batch=0, Loss=7.2]
[[0%|          | 1/4375 [00:01&lt;1:53:09,  1.55s/it]
[[0%|          | 2/4375 [00:02&lt;1:47:52,  1.48s/it]
[[0%|          | 3/4375 [00:04&lt;1:45:31,  1.45s/it]
[[0%|          | 4/4375 [00:05&lt;1:42:08,  1.40s/it]
[[0%|          | 5/4375 [00:06&lt;1:39:37,  1.37s/it]
[[0%|          | 6/4375 [00:08&lt;1:51:42,  1.53s/it]


......
......
......


[[99%|█████████▊| 396/402 [03:58&lt;00:03,  1.95it/s]
[[99%|█████████▉| 397/402 [03:59&lt;00:02,  1.73it/s]
[[99%|█████████▉| 398/402 [04:00&lt;00:02,  1.44it/s]
[[99%|█████████▉| 399/402 [04:01&lt;00:01,  1.54it/s]
[[100%|█████████▉| 400/402 [04:01&lt;00:01,  1.66it/s]
[[100%|█████████▉| 401/402 [04:02&lt;00:00,  1.60it/s]
[[100%|██████████| 402/402 [04:03&lt;00:00,  1.27it/s]
[[100%|██████████| 402/402 [04:03&lt;00:00,  1.65it/s]
Epoch 9: 100%|██████████| 10/10 [21:27:18&lt;00:00, 7723.90s/it, Loss=3.7]
12870 pairs.
loading data......
initializing optimizer......
scheduled_sampling mode.
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = True,source = train
teacher_forcing = True
validating
training loss:4.523505130713327 validation loss:4.524958001655839
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = True,source = train
teacher_forcing = True
validating
training loss:3.7671157992226736 validation loss:4.681057730733016
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = True,source = train
teacher_forcing = True
validating
training loss:3.3115914395468575 validation loss:4.873124810000557
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = True,source = train
teacher_forcing = True
validating
training loss:2.8917448364257812 validation loss:5.104775812249634
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = True,source = train
teacher_forcing = True
validating
training loss:2.612732899093628 validation loss:5.468801263225195
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = True,source = train
teacher_forcing = True
validating
training loss:2.5488693885530745 validation loss:5.7531706645416505
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = True,source = train
teacher_forcing = True
validating
training loss:2.4237240751256523 validation loss:6.024709622127055
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = True,source = train
teacher_forcing = False
validating
training loss:4.1108463181256775 validation loss:5.6224401267325421
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = True,source = train
teacher_forcing = False
validating
training loss:3.87217611147229 validation loss:5.691734581721668
model_name = pgn_model, pointer = True, coverage = True, fine_tune = False, scheduled_sampling = True, weight_tying = True,source = train
teacher_forcing = False
validating
training loss:3.6852303215571813 validation loss:5.83677106265168
</code></pre></div>


<hr>
<blockquote>
<ul>
<li>结论: 我们发现前7轮epoch的时候teacher_forcing=True, 最后3轮epoch的时候teacher_forcing=False. 并且我们验证集上最小的损失恰恰在第一个epoch就出现了. 结合前面几章的经验, 提示我们在当前数据集和任务上, 每次迭代训练2-3个epoch就足够了.</li>
</ul>
</blockquote>
<hr>
<h4 id="baseline-8_1">评估baseline-8模型</h4>
<ul>
<li>关于baseline-8模型的评估代码:<ul>
<li>代码文件predict.py只需要对参数beam_search做出设定. 同时要对几行代码做出修改.</li>
<li>代码文件rouge_eval.py全部保持不变.</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>首先评估贪心解码的模型效果:<ul>
<li>在代码文件predict.py中, 首先要对参数beam_search设置为False.</li>
<li>然后要在对应的位置改变embedding的代码.</li>
<li>代码文件路径: /home/ec2-user/text_summary/pgn/src/predict.py</li>
</ul>
</li>
</ul>
<hr>
<div class="codehilite" id="__code_34"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_34 pre, #__code_34 code"><span class="md-clipboard__message"></span></button><pre id="__code_35"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_35 pre, #__code_35 code"><span class="md-clipboard__message"></span></button><code><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">jieba</span>

<span class="n">root_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">root_path</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">config</span>
<span class="kn">from</span> <span class="nn">src.model</span> <span class="kn">import</span> <span class="n">PGN</span>
<span class="kn">from</span> <span class="nn">utils.dataset</span> <span class="kn">import</span> <span class="n">PairDataset</span>
<span class="kn">from</span> <span class="nn">utils.func_utils</span> <span class="kn">import</span> <span class="n">source2ids</span><span class="p">,</span> <span class="n">outputids2words</span><span class="p">,</span> <span class="n">timer</span><span class="p">,</span> <span class="n">add2heap</span><span class="p">,</span> <span class="n">replace_oovs</span>


<span class="k">class</span> <span class="nc">Predict</span><span class="p">():</span>
    <span class="nd">@timer</span><span class="p">(</span><span class="n">module</span><span class="o">=</span><span class="s1">'initalize predicter'</span><span class="p">)</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">DEVICE</span>

        <span class="n">dataset</span> <span class="o">=</span> <span class="n">PairDataset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">train_data_path</span><span class="p">,</span>
                              <span class="n">max_enc_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_enc_len</span><span class="p">,</span>
                              <span class="n">max_dec_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_dec_len</span><span class="p">,</span>
                              <span class="n">truncate_enc</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">truncate_enc</span><span class="p">,</span>
                              <span class="n">truncate_dec</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">truncate_dec</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">embed_file</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">embed_file</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">PGN</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop_word</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">strip</span><span class="p">()]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">stop_word_file</span><span class="p">)</span><span class="o">.</span><span class="n">readlines</span><span class="p">()]))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">model_save_path</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">greedy_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">max_sum_len</span><span class="p">,</span> <span class="n">len_oovs</span><span class="p">,</span> <span class="n">x_padding_masks</span><span class="p">):</span>

        <span class="c1"># -------------------------------------------------------------------------------------------</span>
        <span class="c1"># 下面一行代码是6.4小节采用weight tying策略时需要修改的, 最后一个参数传入Decoder的词嵌入参数</span>
        <span class="n">encoder_output</span><span class="p">,</span> <span class="n">encoder_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">replace_oovs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span>
                                                            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">embedding</span><span class="p">)</span>
        <span class="c1"># -------------------------------------------------------------------------------------------</span>


        <span class="c1"># 用encoder的hidden state初始化decoder的hidden state</span>
        <span class="n">decoder_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reduce_state</span><span class="p">(</span><span class="n">encoder_states</span><span class="p">)</span>

        <span class="c1"># 利用SOS作为解码器的初始化输入字符</span>
        <span class="n">x_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">SOS</span>
        <span class="n">x_t</span> <span class="o">=</span> <span class="n">x_t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">summary</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">SOS</span><span class="p">]</span>
        <span class="n">coverage_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>

        <span class="c1"># 循环解码, 最多解码max_sum_len步</span>
        <span class="k">while</span> <span class="nb">int</span><span class="p">(</span><span class="n">x_t</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="o">!=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">EOS</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">max_sum_len</span><span class="p">:</span>
            <span class="n">context_vector</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">decoder_states</span><span class="p">,</span>
                                                                     <span class="n">encoder_output</span><span class="p">,</span>
                                                                     <span class="n">x_padding_masks</span><span class="p">,</span>
                                                                     <span class="n">coverage_vector</span><span class="p">)</span>

            <span class="n">p_vocab</span><span class="p">,</span> <span class="n">decoder_states</span><span class="p">,</span> <span class="n">p_gen</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x_t</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
                                                                <span class="n">decoder_states</span><span class="p">,</span>
                                                                <span class="n">context_vector</span><span class="p">)</span>

            <span class="n">final_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_final_distribution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p_gen</span><span class="p">,</span> <span class="n">p_vocab</span><span class="p">,</span>
                                                           <span class="n">attention_weights</span><span class="p">,</span>
                                                           <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">len_oovs</span><span class="p">))</span>

            <span class="c1"># 以贪心解码策略预测字符</span>
            <span class="n">x_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">final_dist</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
            <span class="n">decoder_word_idx</span> <span class="o">=</span> <span class="n">x_t</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

            <span class="c1"># 将预测的字符添加进结果摘要中</span>
            <span class="n">summary</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decoder_word_idx</span><span class="p">)</span>
            <span class="n">x_t</span> <span class="o">=</span> <span class="n">replace_oovs</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">summary</span>

    <span class="c1"># ---------------------------------------------------------------------</span>
    <span class="c1"># 只需要将最后一个形参beam_search设置为False, 即可以贪心解码预测.</span>
    <span class="nd">@timer</span><span class="p">(</span><span class="n">module</span><span class="o">=</span><span class="s1">'doing prediction'</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">beam_search</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="c1"># ---------------------------------------------------------------------</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">tokenize</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">oov</span> <span class="o">=</span> <span class="n">source2ids</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">len_oovs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">oov</span><span class="p">)])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">x_padding_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">beam_search</span><span class="p">:</span>
            <span class="n">summary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beam_search</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                                       <span class="n">max_sum_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_dec_steps</span><span class="p">,</span>
                                       <span class="n">beam_width</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">beam_size</span><span class="p">,</span>
                                       <span class="n">len_oovs</span><span class="o">=</span><span class="n">len_oovs</span><span class="p">,</span>
                                       <span class="n">x_padding_masks</span><span class="o">=</span><span class="n">x_padding_masks</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">summary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_search</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                                         <span class="n">max_sum_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_dec_steps</span><span class="p">,</span>
                                         <span class="n">len_oovs</span><span class="o">=</span><span class="n">len_oovs</span><span class="p">,</span>
                                         <span class="n">x_padding_masks</span><span class="o">=</span><span class="n">x_padding_masks</span><span class="p">)</span>

        <span class="n">summary</span> <span class="o">=</span> <span class="n">outputids2words</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="n">oov</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">summary</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'&lt;SOS&gt;'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'&lt;EOS&gt;'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_36"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_36 pre, #__code_36 code"><span class="md-clipboard__message"></span></button><pre id="__code_37"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_37 pre, #__code_37 code"><span class="md-clipboard__message"></span></button><code><span class="nb">cd</span> /home/ec2-user/text_summary/pgn/src/

python rouge_eval.py
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_38"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_38 pre, #__code_38 code"><span class="md-clipboard__message"></span></button><pre id="__code_39"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_39 pre, #__code_39 code"><span class="md-clipboard__message"></span></button><code>实例化Rouge对象......
Reading from  /home/ec2-user/text_summary/pgn/data/dev.txt
self.refs[]包含的样本数:  3000
Test set contains 3000 samples.
实例化Predict对象......
Reading dataset /home/ec2-user/text_summary/pgn/data/train.txt... 140000 pairs.
15.963327169418335 secs used for  initalize predicter
利用模型对article进行预测, 并通过Rouge对象进行评估......
Building hypotheses.
0.07332539558410645 secs used for  doing prediction
0.055742502212524414 secs used for  doing prediction
0.037644386291503906 secs used for  doing prediction
0.05304408073425293 secs used for  doing prediction
0.030008316040039062 secs used for  doing prediction
0.05388140678405762 secs used for  doing prediction
0.01584935188293457 secs used for  doing prediction
0.06547999382019043 secs used for  doing prediction
0.05590486526489258 secs used for  doing prediction
0.021546125411987305 secs used for  doing prediction
0.04329800605773926 secs used for  doing prediction
0.05656576156616211 secs used for  doing prediction


......
......
......


0.05123019218444824 secs used for  doing prediction
0.009801626205444336 secs used for  doing prediction
0.05459141731262207 secs used for  doing prediction
0.05174136161804199 secs used for  doing prediction
0.05583930015563965 secs used for  doing prediction
0.05422520637512207 secs used for  doing prediction
0.052309513092041016 secs used for  doing prediction
0.01446390151977539 secs used for  doing prediction
116.43013048171997 secs used for  building hypotheses
开始用Rouge规则进行评估......
Calculating average rouge scores.
rouge1:  {'f': 0.20431242815278154, 'p': 0.21685821440593508, 'r': 0.2639005485159501}
rouge2:  {'f': 0.05269086927945189, 'p': 0.05963918727814196, 'r': 0.07997281111602614}
rougeL:  {'f': 0.24340123445669454, 'p': 0.3171595446736551, 'r': 0.23198070380849265}
将评估结果写入结果文件中......
</code></pre></div>


<hr>
<ul>
<li>再评估Beam search解码的效果:<ul>
<li>在代码文件predict.py中, 第一步对参数beam_search设置为True.</li>
<li>在代码文件predict.py中, 第二步对beam_search()函数做一行代码修改.</li>
<li>代码文件路径: /home/ec2-user/text_summary/pgn/src/predict.py</li>
</ul>
</li>
</ul>
<hr>
<div class="codehilite" id="__code_40"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_40 pre, #__code_40 code"><span class="md-clipboard__message"></span></button><pre id="__code_41"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_41 pre, #__code_41 code"><span class="md-clipboard__message"></span></button><code><span class="k">class</span> <span class="nc">Predict</span><span class="p">():</span>
    <span class="c1"># 支持beam-search解码策略的主逻辑函数.</span>
    <span class="k">def</span> <span class="nf">beam_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">max_sum_len</span><span class="p">,</span> <span class="n">beam_width</span><span class="p">,</span> <span class="n">len_oovs</span><span class="p">,</span> <span class="n">x_padding_masks</span><span class="p">):</span>
        <span class="c1"># x: 编码器的输入张量, 即article(source document)</span>
        <span class="c1"># max_sum_len: 本质上就是最大解码长度max_dec_len</span>
        <span class="c1"># beam_size: 采用beam-search策略下的搜索宽度k</span>
        <span class="c1"># len_oovs: OOV列表的长度</span>
        <span class="c1"># x_padding_masks: 针对编码器的掩码张量, 把无效的PAD字符遮掩掉.</span>


        <span class="c1"># ------------------------------------------------------------------------------------------------------</span>
        <span class="c1"># 下面一行代码是6.4小节采用weight tying策略时唯一需要修改的一行代码, 第二个参数传入Decoder的词嵌入参数.</span>
        <span class="c1"># 第一步: 通过Encoder计算得到编码器的输出张量.</span>
        <span class="n">encoder_output</span><span class="p">,</span> <span class="n">encoder_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">replace_oovs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span>
                                                            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">embedding</span><span class="p">)</span>
        <span class="c1"># -----------------------------------------------------------------------------------------------------</span>


        <span class="c1"># 全零张量初始化coverage vector</span>
        <span class="n">coverage_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="c1"># 对encoder_states进行加和降维处理, 赋值给decoder_states.</span>
        <span class="n">decoder_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reduce_state</span><span class="p">(</span><span class="n">encoder_states</span><span class="p">)</span>

        <span class="c1"># 初始化hypothesis, 第一个token给SOS, 分数给0.</span>
        <span class="n">init_beam</span> <span class="o">=</span> <span class="n">Beam</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">SOS</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">decoder_states</span><span class="p">,</span> <span class="n">coverage_vector</span><span class="p">)</span>

        <span class="c1"># beam_size本质上就是搜索宽度k</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">beam_size</span>
        <span class="c1"># 初始化curr作为当前候选集, completed作为最终的hypothesis列表</span>
        <span class="n">curr</span><span class="p">,</span> <span class="n">completed</span> <span class="o">=</span> <span class="p">[</span><span class="n">init_beam</span><span class="p">],</span> <span class="p">[]</span>

        <span class="c1"># 通过for循环连续解码max_sum_len步, 每一步应用beam-search策略产生预测token.</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_sum_len</span><span class="p">):</span>
            <span class="c1"># 初始化当前时间步的topk列表为空, 后续将beam-search的解码结果存储在topk中.</span>
            <span class="n">topk</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">beam</span> <span class="ow">in</span> <span class="n">curr</span><span class="p">:</span>
                <span class="c1"># 如果产生了一个EOS token, 则将beam对象追加进最终的hypothesis列表, 并将k值减1, 然后继续搜索.</span>
                <span class="k">if</span> <span class="n">beam</span><span class="o">.</span><span class="n">tokens</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">EOS</span><span class="p">:</span>
                    <span class="n">completed</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">beam</span><span class="p">)</span>
                    <span class="n">k</span> <span class="o">-=</span> <span class="mi">1</span>
                    <span class="k">continue</span>

                <span class="c1"># 遍历最好的k个候选集序列.</span>
                <span class="k">for</span> <span class="n">can</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_k</span><span class="p">(</span><span class="n">beam</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">encoder_output</span><span class="p">,</span> <span class="n">x_padding_masks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">len_oovs</span><span class="p">)):</span>
                    <span class="c1"># 利用小顶堆来维护一个top_k的candidates.</span>
                    <span class="c1"># 小顶堆的值以当前序列的得分为准, 顺便也把候选集的id和候选集本身存储起来.</span>
                    <span class="n">add2heap</span><span class="p">(</span><span class="n">topk</span><span class="p">,</span> <span class="p">(</span><span class="n">can</span><span class="o">.</span><span class="n">seq_score</span><span class="p">(),</span> <span class="nb">id</span><span class="p">(</span><span class="n">can</span><span class="p">),</span> <span class="n">can</span><span class="p">),</span> <span class="n">k</span><span class="p">)</span>

            <span class="c1"># 当前候选集是堆元素的index=2的值can.</span>
            <span class="n">curr</span> <span class="o">=</span> <span class="p">[</span><span class="n">items</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">items</span> <span class="ow">in</span> <span class="n">topk</span><span class="p">]</span>
            <span class="c1"># 候选集数量已经达到搜索宽度的时候, 停止搜索.</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">completed</span><span class="p">)</span> <span class="o">==</span> <span class="n">beam_size</span><span class="p">:</span>
                <span class="k">break</span>

        <span class="c1"># 将最后产生的候选集追加进completed中.</span>
        <span class="n">completed</span> <span class="o">+=</span> <span class="n">curr</span>

        <span class="c1"># 按照得分进行降序排列, 取分数最高的作为当前解码结果序列.</span>
        <span class="n">result</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">completed</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">seq_score</span><span class="p">(),</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tokens</span>
        <span class="k">return</span> <span class="n">result</span>


    <span class="c1"># ---------------------------------------------------------------------</span>
    <span class="c1"># 只需要将最后一个形参beam_search设置为True, 即可以Beam search解码预测.</span>
    <span class="nd">@timer</span><span class="p">(</span><span class="n">module</span><span class="o">=</span><span class="s1">'doing prediction'</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">beam_search</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="c1"># ---------------------------------------------------------------------</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">tokenize</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">oov</span> <span class="o">=</span> <span class="n">source2ids</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">len_oovs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">oov</span><span class="p">)])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">x_padding_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">beam_search</span><span class="p">:</span>
            <span class="n">summary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beam_search</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                                       <span class="n">max_sum_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_dec_steps</span><span class="p">,</span>
                                       <span class="n">beam_width</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">beam_size</span><span class="p">,</span>
                                       <span class="n">len_oovs</span><span class="o">=</span><span class="n">len_oovs</span><span class="p">,</span>
                                       <span class="n">x_padding_masks</span><span class="o">=</span><span class="n">x_padding_masks</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">summary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_search</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                                         <span class="n">max_sum_len</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_dec_steps</span><span class="p">,</span>
                                         <span class="n">len_oovs</span><span class="o">=</span><span class="n">len_oovs</span><span class="p">,</span>
                                         <span class="n">x_padding_masks</span><span class="o">=</span><span class="n">x_padding_masks</span><span class="p">)</span>

        <span class="n">summary</span> <span class="o">=</span> <span class="n">outputids2words</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="n">oov</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">summary</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'&lt;SOS&gt;'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'&lt;EOS&gt;'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</code></pre></div>


<hr>
<ul>
<li>调用:</li>
</ul>
<div class="codehilite" id="__code_42"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_42 pre, #__code_42 code"><span class="md-clipboard__message"></span></button><pre id="__code_43"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_43 pre, #__code_43 code"><span class="md-clipboard__message"></span></button><code><span class="nb">cd</span> /home/ec2-user/text_summary/pgn/src/

python rouge_eval.py
</code></pre></div>


<hr>
<ul>
<li>输出结果:</li>
</ul>
<div class="codehilite" id="__code_44"><button class="md-clipboard" title="复制" data-clipboard-target="#__code_44 pre, #__code_44 code"><span class="md-clipboard__message"></span></button><pre id="__code_45"><span></span><button class="md-clipboard" title="复制" data-clipboard-target="#__code_45 pre, #__code_45 code"><span class="md-clipboard__message"></span></button><code>实例化Rouge对象......
Reading from  /home/ec2-user/ec2-user/zhudejun/text_summary/text_summary/pgn/data/dev.txt
self.refs[]包含的样本数:  3000
Test set contains 3000 samples.
实例化Predict对象......
Reading dataset /home/ec2-user/ec2-user/zhudejun/text_summary/text_summary/pgn/data/train.txt... 139998 pairs.
15.918241024017334 secs used for  initalize predicter
利用模型对article进行预测, 并通过Rouge对象进行评估......
Building hypotheses.
0.3589177131652832 secs used for  doing prediction
0.3374664783477783 secs used for  doing prediction
0.3456692695617676 secs used for  doing prediction
0.3331456184387207 secs used for  doing prediction
0.34146881103515625 secs used for  doing prediction
0.334575891494751 secs used for  doing prediction
0.33663010597229004 secs used for  doing prediction
0.3577096462249756 secs used for  doing prediction
0.3289070129394531 secs used for  doing prediction
0.3339529037475586 secs used for  doing prediction


......
......
......


0.40102291107177734 secs used for  doing prediction
0.3524472713470459 secs used for  doing prediction
0.35205864906311035 secs used for  doing prediction
0.36118149757385254 secs used for  doing prediction
0.40877795219421387 secs used for  doing prediction
0.3536827564239502 secs used for  doing prediction
0.366757869720459 secs used for  doing prediction
0.35179853439331055 secs used for  doing prediction
0.35098910331726074 secs used for  doing prediction
0.35169148445129395 secs used for  doing prediction
0.35124707221984863 secs used for  doing prediction
0.3597400188446045 secs used for  doing prediction
0.3530762195587158 secs used for  doing prediction
0.35770344734191895 secs used for  doing prediction
0.3506617546081543 secs used for  doing prediction
1022.312926581192 secs used for  building hypotheses
开始用Rouge规则进行评估......
Calculating average rouge scores.
rouge1:  {'f': 0.19442847393917322, 'p': 0.1617446851444022, 'r': 0.34453045149293926}
rouge2:  {'f': 0.05718565052066199, 'p': 0.04481349203649152, 'r': 0.11018874395912032}
rougeL:  {'f': 0.24767991068636252, 'p': 0.28778950788684004, 'r': 0.2861432124810714}
将评估结果写入结果文件中......
</code></pre></div>


<hr>
<hr>
<h3 id="_3">小节总结</h3>
<ul>
<li>
<p>小节总结:</p>
</li>
<li>
<p>Scheduled sampling优化策略:</p>
<ul>
<li>策略介绍: 在生成式模型训练阶段, 常采用Teacher-forcing的策略辅助模型更快的收敛. 但是一直使用Teacher-forcing的策略, 会造成训练和预测的输入样本分布不一致, 也就是著名的"Exposure bias".</li>
<li>具体方法: 对于"Exposure bias", 很好的一个解决策略就是采用"Scheduled sampling", 即在训练阶段, 将ground truth和decoder predict混合起来使用, 作为下一个时间步的decoder input. 具体做法是每个时间步以一个p值概率进行Teacher forcing, 以(1 - p)值概率不进行Teacher forcing. 同时p值的大小随着batch或者epoch衰减.</li>
<li>有效性分析: 采用"Scheduled sampling", 在刚开始训练的阶段, 模型所具有的知识很少, 需要采用Teacher forcing的方式, 使用ground truth加速模型的学习和收敛. 到了训练后期, 模型已经掌握了很多数据分布的特征和数据本身的特征, 这个时候将decoder input替换成decoder predict, 保持和预测阶段一致, 来解决"Exposure bias"的问题.</li>
</ul>
</li>
<li>
<p>Weight tying优化策略:</p>
<ul>
<li>策略介绍: 这个策略要解决的还是"Exposure bias"问题, 除了用训练后期去除掉Teacher forcing的方法. 我们还可以通过让Encoder和Decoder的词嵌入尽量一致来纠正这种偏差.</li>
<li>具体方法: "Weight tying"的字面意思就是权重的绑定, 具体做法是将Encoder和Decoder的embedding权重矩阵进行共享.</li>
<li>有效性分析: 对embedding权重矩阵进行共享, 这样就使得Encoder和Decoder的输入词向量表达完全相同了, 一定程度上可以缓解"Exposure bias".</li>
</ul>
</li>
</ul>
<hr>
<hr>
<hr>
<hr>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="./6_3.html" title="6.3 数据增强的优化" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  上一页
                </span>
                6.3 数据增强的优化
              </span>
            </div>
          </a>
        
        
          <a href="./7_1.html" title="7.1 硬件优化与模型部署" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  下一页
                </span>
                7.1 硬件优化与模型部署
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            ©Copyright 2020, AITutorials.CN This website has been reviewed by the review agency. 京ICP备19006137号
          </div>
        
        powered by
        <a href="https://www.mkdocs.org/">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="./index_files/font-awesome.css">
    
      <a href="https://www.linkedin.com/in/%E7%A7%91%E6%8A%80%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8-%E5%8C%97%E4%BA%AC%E6%A9%98%E6%98%9F-6bb7081a1/" class="md-footer-social__link fa fa-linkedin"></a>
    
      <a href="https://weibo.com/u/3469990762?is_all=1" class="md-footer-social__link fa fa-weibo"></a>
    
      <a href="http://bitbucket.org/AITutorials" class="md-footer-social__link fa fa-bitbucket"></a>
    
      <a href="https://github.com/AITutorials/datasets/issues" class="md-footer-social__link fa fa-gitlab"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="./index_files/application.245445c6.js"></script>
      
        
        
          
          <script src="./index_files/lunr.stemmer.support.js"></script>
          
            
              
                <script src="./index_files/tinyseg.js"></script>
              
              
                <script src="./index_files/lunr.ja.js"></script>
              
            
          
          
        
      
      <script>app.initialize({version:"1.1.2",url:{base:".."}})</script>
      
    
  
</body></html>